diff --git a/CMakeLists.txt b/CMakeLists.txt
index a13b52b..3c14fb4 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -1,9 +1,19 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 include(cmake/thirdparty_version.cmake)
-cmake_minimum_required(VERSION ${MIN_CMAKE_V} FATAL_ERROR)
-project(ANAKIN C CXX) 
+project(ANAKIN C CXX)
 include(cmake/msg_color.cmake)
 include(cmake/utils.cmake)
 include(cmake/statistic.cmake)
@@ -11,10 +21,10 @@ include(cmake/statistic.cmake)
 # ----------------------------------------------------------------------------
 # section: global anakin version and lib name
 # ----------------------------------------------------------------------------
-# global anakin version 2.0.1
-set(VERSION_MAJOR "2")
-set(VERSION_MINOR "0")
-set(VERSION_PATCH "1")
+# global anakin version 0.1.0
+set(VERSION_MAJOR "0")
+set(VERSION_MINOR "1")
+set(VERSION_PATCH "0")
 set(VERSION "${VERSION_MAJOR}.${VERSION_MINOR}.${VERSION_PATCH}")
 
 # anakin lib name and global directories
@@ -31,6 +41,8 @@ set(ANAKIN_THIRD_PARTY_PATH ${ANAKIN_ROOT}/third-party)
 set(ANAKIN_MODEL_PARSER ${ANAKIN_FRAMEWORK}/model_parser)
 set(ANAKIN_SABER ${ANAKIN_ROOT}/saber)
 set(ANAKIN_UNIT_TEST ${ANAKIN_ROOT}/test)
+set(ANAKIN_EXAMPLES ${ANAKIN_ROOT}/examples)
+
 
 # ----------------------------------------------------------------------------
 # section: options for anakin
@@ -60,13 +72,16 @@ anakin_option(USE_CUFFT "Use CuFFT libs." YES if USE_CUDA)
 anakin_option(USE_CUDNN "Use Cudnn libs." YES if USE_CUDA)
 anakin_option(BUILD_CROSS_PLANTFORM "Build anakin lib for any nvidia device plantform." YES if USE_CUDA)
 anakin_option(BUILD_FAT_BIN "Build anakin cuda fat-bin lib for all device plantform" NO if BUILD_CROSS_PLANTFORM)
+
+cmake_minimum_required(VERSION ${MIN_CMAKE_V} FATAL_ERROR)
+
 if(USE_CUDA)
     # Select gpu target arch for local high performance implement sass code . Now we have checked on sm_61 sm_50 and it works well.
     set(SELECTED_SASS_TARGET_ARCH "61")
 endif()
 if((NOT BUILD_FAT_BIN) AND (NOT BUILD_CROSS_PLANTFORM) AND USE_CUDA)
     # Select the only nvidia gpu arch you want to be built on
-    set(TARGET_GPUARCH 6.1) 
+    set(TARGET_GPUARCH 6.1)
 endif()
 
 # build options for cuda.
@@ -86,7 +101,7 @@ anakin_option(USE_GLOG "Build Glog components." NO if NOT USE_LOGGER)
 anakin_option(USE_PROTOBUF "Build Google protobuf components." YES)
 anakin_option(USE_OPENCV "Use static opencv libs." NO)
 anakin_option(USE_BOOST "Use static BOOST libs." NO)
-anakin_option(USE_OPENMP "Use Openmp when in andriod environment." YES if TARGET_ANDROID)
+anakin_option(USE_OPENMP "Use Openmp when in android environment." YES if TARGET_ANDROID)
 anakin_option(USE_GTEST "Use googletest libs." NO if BUILD_WITH_UNIT_TEST)
 anakin_option(USE_PYTHON "Generate py wrappers." NO)
 anakin_option(USE_OPENCL "Use OpenCL ." NO)
@@ -94,11 +109,15 @@ anakin_option(USE_GFLAGS "Build Google gflags components." NO)
 anakin_option(USE_MKL "Use mkl libs." NO if USE_X86_PLACE)
 anakin_option(USE_MKLML "Use MKLML libs." YES if USE_X86_PLACE)
 anakin_option(USE_XBYAK "Use XBYAK libs." YES if USE_X86_PLACE)
-anakin_option(USE_OPENMP "Use Openmp when in andriod environment." YES if TARGET_ANDROID)
+anakin_option(USE_OPENMP "Use Openmp when in android environment." YES if TARGET_ANDROID)
 
 # build components
 anakin_option(BUILD_WITH_UNIT_TEST "Build anakin unit test components." YES)
-anakin_option(BUILD_WITH_LITE "Build anakin lite components." YES)
+
+anakin_option(BUILD_WITH_LITE "Build anakin lite components." YES if USE_GPU_PLACE)
+
+# build examples
+anakin_option(BUILD_EXAMPLES "build detection and classification examples" NO)
 
 # build target
 anakin_option(BUILD_SHARED "Build anakin shared lib." YES)
@@ -110,9 +129,9 @@ anakin_option(ENABLE_OP_TIMER "Enable op timer mode." NO)
 # section: anakin compiler and linker options
 # ----------------------------------------------------------------------------
 if(ENABLE_DEBUG)
-	set(CMAKE_BUILD_TYPE Debug FORCE)
+    set(CMAKE_BUILD_TYPE Debug FORCE)
 else()
-	set(CMAKE_BUILD_TYPE Release FORCE)
+    set(CMAKE_BUILD_TYPE Release FORCE)
 endif()
 
 if(USE_LOGGER) 
@@ -125,8 +144,8 @@ endif()
 # 		  code
 # ----------------------------------------------------------------------------
 configure_file (
-  "${PROJECT_SOURCE_DIR}/cmake/config/anakin_config.h.in"
-  "${PROJECT_BINARY_DIR}/anakin_config.h"
+        "${PROJECT_SOURCE_DIR}/cmake/config/anakin_config.h.in"
+        "${PROJECT_BINARY_DIR}/anakin_config.h"
 )
 # add the binary tree to the search path so that anakin will find ak_config.h
 include_directories(${PROJECT_BINARY_DIR})
@@ -176,6 +195,10 @@ if(BUILD_WITH_LITE)
 	add_subdirectory(${ANAKIN_LITE})
 endif()
 
+if (BUILD_EXAMPLES)
+    add_subdirectory(${ANAKIN_EXAMPLES})
+endif()
+
 anakin_print_statistic()
 
 
diff --git a/README.md b/README.md
index 4cabf24..144339e 100644
--- a/README.md
+++ b/README.md
@@ -7,63 +7,65 @@
 
 Welcome to the Anakin GitHub.
 
-Anakin is an cross-platform, high-performance inference engine, which is originally
+Anakin is a cross-platform, high-performance inference engine, which is originally
 developed by Baidu engineers and is a large-scale application of industrial products.
 
-Please refer to our [release announcement]() to track the latest feature of Anakin.
+Please refer to our [release announcement](https://github.com/PaddlePaddle/Anakin/releases) to track the latest feature of Anakin.
 
 ## Features
 
 - **Flexibility**
 
     Anakin supports a wide range of neural network architectures and
-    diffrent hardware platform. It is easy to run Anakin at GPU/x86/ARM platform.
+    different hardware platforms. It is easy to run Anakin on GPU / x86 / ARM platform.
 
 -  **High performance**
 
-    In order to giving full play to the performance of hardware, we optimize the
-    forward prediction at diffrent levels.
-      - Automatic graph fusion. The goal of all performance optimization under a 
-      given algorithm is to make ALU as busy as possible, Operator fusion 
-      can effectively reduce memory access and keep ALU busy.
-      
-      - Memory reuse. Forward prediction is a one-way calculation. We reuse 
-      the memory between the input and output of different operators, thus 
+    In order to give full play to the performance of hardware, we optimized the
+    forward prediction at different levels.
+      - Automatic graph fusion. The goal of all performance optimizations under a
+      given algorithm is to make the ALU as busy as possible. Operator fusion
+      can effectively reduce memory access and keep the ALU busy.
+
+      - Memory reuse. Forward prediction is a one-way calculation. We reuse
+      the memory between the input and output of different operators, thus
       reducing the overall memory overhead.
 
-      - Assembly level optimization. Saber is Anakin's underlying DNN library, which
+      - Assembly level optimization. Saber is a underlying DNN library for Anakin, which
       is deeply optimized at assembly level. Performance comparison between Anakin, TensorRT
-      and Tensorflow-lite, please refer to the benchmark tests.
+      and Tensorflow-lite, please refer to the [benchmark tests](benchmark/README.md).
 
 
 ## Installation
 
 It is recommended to check out the
-[Docker installation guide](docker/README.md).
+[docker installation guide](docker/README.md).
 before looking into the
 [build from source guide](docs/Manual/INSTALL_en.md).
 
+For ARM, please refer [run on arm](docs/Manual/run_on_arm_en.md).
+
 ## Benchmark
-It is recommended to check out the [Benchmark Readme](benchmark/README.md)
+It is recommended to check out the [readme of benchmark](benchmark/README.md).
 
 ## Documentation
 
-We provide [English](docs/Manual/Tutorial_en.md) and
-[Chinese](docs/Manual/Tutorial_ch.md) documentation.
+We provide [English](docs/Manual/Tutorial_en.md) and [Chinese](docs/Manual/Tutorial_ch.md) documentation.
 
-- [Anakin developer guide]()
+- Developer guide
 
-  You might want to know more details of Anakin and make it better.
+  You might want to know more details of Anakin and make it better. Please refer to [how to add custom devices](docs/Manual/addCustomDevice.md) and [how to add custom device operators](docs/Manual/addCustomOp.md).
 
-- [C++ API]()
+- User guide
 
-   Python API is under-developing.
+   You can get the working principle of the project, C++ interface description and code examples from [here](docs/Manual/Tutorial_ch.md). You can also learn about the model converter [here](docs/Manual/Converter_ch.md).
 
-- [How to Contribute]()
+- [How to Contribute](docs/Manual/Contribution_ch.md)
 
    We appreciate your contributions!
 
 
+
 ## Ask Questions
 
 You are welcome to submit questions and bug reports as [Github Issues](https://github.com/PaddlePaddle/Anakin/issues).
diff --git a/benchmark/README.md b/benchmark/README.md
index 5dcf61d..94f5793 100644
--- a/benchmark/README.md
+++ b/benchmark/README.md
@@ -1,173 +1,42 @@
 # Benchmark
 
-## Machine:
-
-This time, we only provide benchmark on GPU. In the near future, we will add benchmark on ARM and CPU.
-
->  CPU: `12-core Intel(R) Xeon(R) CPU E5-2620 v2 @2.10GHz`
->  GPU: `Tesla P4`  
->  cuDNN: `v7`  
-
-## Counterpart of anakin  :
-The counterpart of **`Anakin`** is the acknowledged high performance inference engine **`NVIDIA TensorRT 3`** ,   The models which TensorRT 3 doesn't support we use the custom plugins  to support.  
-
 ## Benchmark Model  
 
-The following convolutional neural networks are tested with both `Anakin` and `TenorRT3`.
- You can use pretrained caffe model or the model trained by youself.
-
 > Please note that you should transform caffe model or others into anakin model with the help of [`external converter ->`](#)
 
+### GPU 
 
-- [Vgg16](#1)   *caffe model can be found [here->](https://gist.github.com/jimmie33/27c1c0a7736ba66c2395)*
-- [Yolo](#2)  *caffe model can be found [here->](https://github.com/hojel/caffe-yolo-model)*
-- [Resnet50](#3)  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
-- [Resnet101](#4)  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
-- [Mobilenet v1](#5)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
-- [Mobilenet v2](#6)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
-- [RNN](#7)  *not support yet*
-
-We tested them on single-GPU with single-thread. 
-
-### <span id = '1'>VGG16 </span>  
-
-- Latency (`ms`) of different batch  
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: |
-    1 | 8.8690 | 8.2815
-    2 | 15.5344 | 13.9116
-    4 | 26.6000 | 21.8747 
-    8 | 49.8279 | 40.4076 
-    32 | 188.6270 | 163.7660 
-
-- GPU Memory Used (`MB`)
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 963 | 997
-    2 | 965 | 1039
-    4 | 991 | 1115
-    8 | 1067 | 1269
-    32 | 1715 | 2193
-
-    
-### <span id = '2'>Yolo </span>  
-
-- Latency (`ms`) of different batch  
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 16.4596| 15.2124
-    2 | 26.6347| 25.0442 
-    4 | 43.3695| 43.5017
-    8 | 80.9139 | 80.9880
-    32 | 293.8080| 310.8810
-
-- GPU Memory Used (`MB`)
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 1569 | 1775
-    2 | 1649 | 1815
-    4 | 1709 | 1887
-    8 | 1731 | 2031
-    32 | 2253 | 2907
-
-### <span id = '3'> Resnet50 </span> 
-
-- Latency (`ms`) of different batch  
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 4.2459   |  4.1061 
-    2 |  6.2627  |  6.5159 
-    4 | 10.1277  | 11.3327
-    8 | 17.8209 |   20.6680 
-    32 | 65.8582 | 77.8858
-
-- GPU Memory Used (`MB`)
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 531  | 503
-    2 | 543  | 517
-    4 | 583 | 541
-    8 | 611 | 589
-    32 |  809 | 879
-
-### <span id = '4'> Resnet101 </span> 
-
-- Latency (`ms`) of different batch  
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 7.5562 | 7.0837  
-    2 | 11.6023 | 11.4079
-    4 | 18.3650 | 20.0493 
-    8 | 32.7632 | 36.0648
-    32 | 123.2550 | 135.4880
-
-- GPU Memory Used (`MB)`
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 701  | 683
-    2 | 713  | 697
-    4 | 793 | 721
-    8 | 819 | 769
-    32 | 1043 | 1059
- 
-
-###  <span id = '5'> MobileNet V1 </span> 
-
-- Latency (`ms`) of different batch  
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 45.5156  |  1.3947
-    2 |  46.5585  |  2.5483
-    4 | 48.4242  | 4.3404
-    8 |  52.7957 |  8.1513
-    32 | 83.2519 | 31.3178
-
-- GPU Memory Used (`MB`)
-
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 329  | 283
-    2 | 345   | 289
-    4 | 371 | 299
-    8 | 393 | 319
-    32 |  531 | 433
-
-###  <span id = '6'> MobileNet V2</span> 
-
-- Latency (`ms`) of different batch  
+The following convolutional neural networks are tested with both `Anakin` and `TenorRT3` on GPU.
+ You can use pretrained caffe model or the model trained by youself.
 
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 65.6861 | 2.9842
-    2 | 66.6814 | 4.7472
-    4 | 69.7114 | 7.4163
-    8 | 76.1092 | 12.8779
-    32 | 124.9810 | 47.2142
+- [Vgg16]()  *caffe model can be found [here->](https://gist.github.com/jimmie33/27c1c0a7736ba66c2395)*
+- [Yolo]()  *caffe model can be found [here->](https://github.com/hojel/caffe-yolo-model)*
+- [Resnet50]()  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
+- [Resnet101]()  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
+- [Mobilenet v1]()  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [Mobilenet v2]()  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [RNN]()  *not support yet*
 
-- GPU Memory Used (`MB`)
+### CPU
 
-    BatchSize | TensorRT | Anakin
-    :---: | :---: | :---: | 
-    1 | 341 | 293
-    2 | 353 | 301
-    4 | 385 | 319
-    8 | 421 | 351
-    32 | 637 | 551
+The following convolutional neural networks are tested with `Anakin`, 'Tensorflow' and `Tensorflow`.
+ You can use pretrained model or the model trained by youself.
 
+- [Language model]()   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/tree/develop/fluid/language_model)*
+- [Chinese_ner]()   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/blob/develop/fluid/chinese_ner)*
+- [text_classification]()   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/blob/develop/fluid/text_classification)*
 
-### <span id = '8'> RNN </span>
+### ARM
 
-The benchmark of rnn network will be added later.
+The following convolutional neural networks are tested with `Anakin`, 'Tensorflow' and `Tensorflow`.
+ You can use pretrained model or the model trained by youself.
 
-## How to run those Benchmark models?
+- [Mobilenet v1]()  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [Mobilenet v2]()  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [mobilenet-ssd]()  *caffe model can be found [here->](https://github.com/chuanqi305/MobileNet-SSD)*
 
-> Please refer to [Instructions](CNN/README.md)
+## Test Results
+The detailed test results can be seen here.
+- [GPU](./README_GPU.md)
+- [CPU](./README_CPU.md)
+- [ARM](./README_ARM.md) 
diff --git a/benchmark/README_ARM.md b/benchmark/README_ARM.md
new file mode 100644
index 0000000..3687065
--- /dev/null
+++ b/benchmark/README_ARM.md
@@ -0,0 +1,66 @@
+# BenchMark
+
+## Machine:
+
++ Compile circumstance: Android ndk cross compile，gcc 4.9，enable neon
++ ABI： armveabi-v7a with neon -mfloat-abi=softfp
++ Testing platform
+   - honor v9(root): Kirin960, 4 big cores in 2.36GHz, 4 little cores in 1.8GHz
+   - nubia z17:Qualcomm835, 4 big cores in 2.36GHz, 4 little cores in 1.9GHz
+   - 360 N5:Qualcomm653, 4 big cores in 1.8GHz, 4 little cores in 1.4GHz
++ Time：warmup 10，running 10 times to get average time
++ ncnn ：git clone on github master branch and commits ID is 307a77f04be29875f40d337cfff6df747df09de6（msg:convert            LogisticRegressionOutput)
++ TFlite：git clone on github master branch and commits ID is 65c05bc2ac19f51f7027e66350bc71652662125c（msg:Removed unneeded file copy that was causing failure in Pi builds)
+
+## Counterpart of Anakin
+
+The counterpart of **`Anakin`** are **`ncnn`** and **`TFlite`**.
+
+## BenchMark model
+
+> Please note that you should transform caffe model or others into anakin model with the help of [`external converter ->`](../docs/Manual/Converter_en.md)
+
+- [Mobilenet v1](#11)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [Mobilenet v2](#22)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [mobilenet-ssd](#33)  *caffe model can be found [here->](https://github.com/chuanqi305/MobileNet-SSD)*
+
+We tested them on ARM with multi-thread and single-batchsize.
+
+### <span id = '11'> mobilenetv1 </span>
+
+- Latency (`ms`) of different thread  
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |Kirin960|107.7|61.1ms|38.2 |152.8 |85.2 |51.9 |152.6 |nan|nan|
+   |Qualcomm835|105.7 |63.1 |~~46.8 ~~|152.7 |87.0 |~~92.7 ~~|146.9 |nan|nan|
+   |Qualcomm653|120.3 |64.2 |46.6 |202.5 |117.6 |84.8 |158.6 |nan|nan| 
+
+### <span id = '22'> mobilenetv2 </span>
+
+- Latency (`ms`) of different thread  
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |Kirin960|93.1 |53.9 |34.8 |144.4 |84.3 |55.3 |100.6 |nan|nan|
+   |Qualcomm835|93.0 |55.6 |41.1 |139.1 |88.4 |58.1 |95.2 |nan|nan|
+   |Qualcomm653|106.6 |64.2 |48.0 |199.9 |125.1 |98.9 |108.5 |nan|nan|
+
+### <span id = '33'> mobilenet-ssd </span>
+
+- Latency (`ms`) of different thread  
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |Kirin960|213.9 |120.5 |74.5 |307.9 |166.5 |104.2 |nan|nan|nan|
+   |Qualcomm835|213.0 |125.7 |~~98.4 ~~|292.9 |177.9 |~~167.8 ~~|nan|nan|nan|
+   |Qualcomm653|236.0 |129.6 |96.0 |377.7 |228.9 |165.0 |nan|nan|nan
+
+## How to run those Benchmark models?
+
+1. At first, you should parse the caffe model with [External Converter](../docs/Manual/Converter_en.md)
+2. Second, adb push Anakin model and benchmark_arm bin to testing phone
+3. Then, switch to /data/local/tmp/ directory on testing phone, run `./benchmark_arm ./ anakin_model.anakin.bin 1 10 10 1` command
+4. Finally，model latency summary will be displayed on the screen.
+5. You can see the detailed parameters meaning by running `/benchmark_arm`
+
diff --git a/benchmark/README_CPU.md b/benchmark/README_CPU.md
new file mode 100644
index 0000000..f607abb
--- /dev/null
+++ b/benchmark/README_CPU.md
@@ -0,0 +1,256 @@
+# Benchmark 
+
+## Machine:
+
+This time, we only provide benchmark on CPU. In the near future, we will add benchmark on ARM and GPU.
+
+## Counterpart of anakin  :
+
+The counterpart of **`Anakin`** is `Tensorflow 1.8.0`, which installed by Anaconda 4.5.4, run by Python 3.6
+
+## Benchmark Model
+
+ You can use pretrained model or the model trained by youself.
+
+> Please note that you should transform fluid model or others into anakin model with the help of [`external converter ->`](../docs/Manual/Converter_en.md)
+
+- [Language model](#1)   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/tree/develop/fluid/language_model)*
+- [Chinese_ner](#4)   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/blob/develop/fluid/chinese_ner)*
+- [text_classification](#7)   *fluid model can be found [here->](https://github.com/PaddlePaddle/models/blob/develop/fluid/text_classification)*
+
+We tested them on single-CPU with different thread numbers.
+
+1. **`Anakin`** VS **`Tensorflow`**
+
+### <span id = '1'>language model in i7-7700 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 5.64    | 2.44
+    2 | 8.29    | 4.44
+    4 | 14.23   | 9.91
+    6 | 19.83   | 15.51
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 3459 | 8536
+    2 | 4772 | 9399
+    4 | 5498 | 8418
+    6 | 5764 | 8070
+
+### <span id = '2'>language model in E5-2620 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 6.31    | 2.84
+    2 | 7.94    | 2.678
+    4 | 8.66    | 4.32
+    6 | 12.33   | 7.12
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 2890 | 7257
+    2 | 4726 | 15439
+    4 | 8659 | 18351
+    6 | 9414 | 17461
+
+### <span id = '3'>language model in E5-2650 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 3.69    | 2.84
+    2 | 4.62    | 2.85
+    4 | 7.78    | 3.48
+    6 | 13.54   | 4.79
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 4456 | 7300
+    2 | 7522 | 14556
+    4 | 9580 | 22086
+    6 | 8664 | 23938
+
+### <span id = '4'>text_classfication model in i7-7700 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 1.25    | 0.32
+    2 | 1.87    | 0.33
+    4 | 2.01   | 0.35
+    6 | 2.81   | 0.58
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 12797 | 53506
+    2 | 17933 | 95898
+    4 | 31965 | 148427
+    6 | 31784 | 118684
+
+### <span id = '5'>text_classfication in E5-2620 v4</span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 3.89    | 0.58
+    2 | 3.77    | 0.61
+    4 | 3.05   | 0.62
+    6 | 3.84   | 0.66
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 4281 | 28192
+    2 | 8804 | 49840
+    4 | 19949 | 89710
+    6 | 24798 | 116975
+
+### <span id = '6'>text_classfication in E5-2650 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 2.26    | 0.67
+    2 | 2.34    | 0.7
+    4 | 2.25   | 0.72
+    6 | 2.47   | 0.73
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 6337 | 24636
+    2 | 12266 | 45368
+    4 | 24869 | 81952
+    6 | 34872 | 109993
+
+### <span id = '7'>chinese_ner model in i7-7700 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 1.96    | 0.094
+    2 | 2.59    | 0.098
+    4 | 3.74   | 0.1
+    6 | 3.95   | 0.13
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 8747 | 156564
+    2 | 13293 | 208484
+    4 | 18294 | 114348
+    6 | 25338 | 66480
+
+### <span id = '8'>chinese_ner in E5-2620 v4</span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 5.44    | 0.13
+    2 | 5.45    | 0.14
+    4 | 4.84   | 0.15
+    6 | 5.18   | 0.16
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 4281 | 93527
+    2 | 8804 | 127232
+    4 | 19949 | 118649
+    6 | 24798 | 99553
+
+### <span id = '9'>chinese_ner in E5-2650 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 3.61    | 0.16
+    2 | 3.78    | 0.16
+    4 | 3.74   | 0.17
+    6 | 3.78   | 0.16
+
+- Throughput (`words/s`)
+
+    ThreadNum | Tensorflow | Anakin
+    :---: | :---: | :---: |
+    1 | 4669 | 79225
+    2 | 8953 | 115761
+    4 | 18074 | 118696
+    6 | 26607 | 102044
+
+2. **`Anakin`** VS **`PaddlePaddle/Fluid\`**
+
+### <span id = '1'>language model in E5-2650 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Fluid | Anakin
+    :---: | :---: | :---: |
+    1 | 42.09    | 1.90
+    2 | 42.14    | 2.16
+    6 | 42.15   | 4.21
+    10 | 42.14   | 9.26
+    12 | 42.34   | 11.17
+
+- Throughput (`sentence/s`)
+
+    ThreadNum | Fluid | Anakin
+    :---: | :---: | :---: |
+    1 | 23 | 524
+    2 | 47 | 916
+    6 | 141 | 1402
+    10 | 236   | 1063
+    12 | 282   | 1044
+
+### <span id = '2'>Chinese_ner model in E5-2650 v4 </span>
+
+- Latency (`ms`) of one batch
+
+    ThreadNum | Fluid | Anakin
+    :---: | :---: | :---: |
+    1 | 0.47    | 0.17
+    4 | 0.26    | 0.17
+    6 | 0.36    | 0.17
+    10 | 0.59   | 0.17
+    12 | 0.72   | 0.17
+
+- Throughput (`sentence/s`)
+    
+    ThreadNum | Fluid | Anakin
+    :---: | :---: | :---: |
+    1 | 2129  | 5819
+    4 | 3866  | 11182
+    6 | 8095  | 30948
+    10 | 8250 | 44093
+    12 | 8112  | 47185
+
+## How to run those Benchmark models?
+
+> 1. You can just run `sh benchmark_tensorflow.sh` and  `sh benchmark_anakin.sh`
+> 2. Get the model of caffe or fluid, convert model to anakin model, use net_test_*** to test your model.
+
+
diff --git a/benchmark/README_GPU.md b/benchmark/README_GPU.md
new file mode 100644
index 0000000..a1f67c1
--- /dev/null
+++ b/benchmark/README_GPU.md
@@ -0,0 +1,176 @@
+# Benchmark
+
+## Machine:
+
+>  CPU: `12-core Intel(R) Xeon(R) CPU E5-2620 v2 @2.10GHz`
+>  GPU: `Tesla P4`  
+>  cuDNN: `v7`  
+
+
+## Counterpart of anakin  :
+
+The counterpart of **`Anakin`** is the acknowledged high performance inference engine **`NVIDIA TensorRT 3`** ,   The models which TensorRT 3 doesn't support we use the custom plugins  to support.  
+
+## Benchmark Model  
+
+The following convolutional neural networks are tested with both `Anakin` and `TenorRT3`.
+ You can use pretrained caffe model or the model trained by youself.
+
+> Please note that you should transform caffe model or others into anakin model with the help of [`external converter ->`](../docs/Manual/Converter_en.md)
+
+
+- [Vgg16](#1)   *caffe model can be found [here->](https://gist.github.com/jimmie33/27c1c0a7736ba66c2395)*
+- [Yolo](#2)  *caffe model can be found [here->](https://github.com/hojel/caffe-yolo-model)*
+- [Resnet50](#3)  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
+- [Resnet101](#4)  *caffe model can be found [here->](https://github.com/KaimingHe/deep-residual-networks#models)*
+- [Mobilenet v1](#5)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [Mobilenet v2](#6)  *caffe model can be found [here->](https://github.com/shicai/MobileNet-Caffe)*
+- [RNN](#7)  *not support yet*
+
+We tested them on single-GPU with single-thread. 
+
+### <span id = '1'>VGG16 </span>  
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: |
+    1 | 8.8690 | 8.2815
+    2 | 15.5344 | 13.9116
+    4 | 26.6000 | 21.8747 
+    8 | 49.8279 | 40.4076 
+    32 | 188.6270 | 163.7660 
+
+- GPU Memory Used (`MB`)
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 963 | 997
+    2 | 965 | 1039
+    4 | 991 | 1115
+    8 | 1067 | 1269
+    32 | 1715 | 2193
+
+    
+### <span id = '2'>Yolo </span>  
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 16.4596| 15.2124
+    2 | 26.6347| 25.0442 
+    4 | 43.3695| 43.5017
+    8 | 80.9139 | 80.9880
+    32 | 293.8080| 310.8810
+
+- GPU Memory Used (`MB`)
+
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 1569 | 1775
+    2 | 1649 | 1815
+    4 | 1709 | 1887
+    8 | 1731 | 2031
+    32 | 2253 | 2907
+
+### <span id = '3'> Resnet50 </span> 
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 4.2459   |  4.1061 
+    2 |  6.2627  |  6.5159 
+    4 | 10.1277  | 11.3327
+    8 | 17.8209 |   20.6680 
+    32 | 65.8582 | 77.8858
+
+- GPU Memory Used (`MB`)
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 531  | 503
+    2 | 543  | 517
+    4 | 583 | 541
+    8 | 611 | 589
+    32 |  809 | 879
+
+### <span id = '4'> Resnet101 </span> 
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 7.5562 | 7.0837  
+    2 | 11.6023 | 11.4079
+    4 | 18.3650 | 20.0493 
+    8 | 32.7632 | 36.0648
+    32 | 123.2550 | 135.4880
+
+- GPU Memory Used (`MB)`
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 701  | 683
+    2 | 713  | 697
+    4 | 793 | 721
+    8 | 819 | 769
+    32 | 1043 | 1059
+
+###  <span id = '5'> MobileNet V1 </span> 
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 45.5156  |  1.3947
+    2 |  46.5585  |  2.5483
+    4 | 48.4242  | 4.3404
+    8 |  52.7957 |  8.1513
+    32 | 83.2519 | 31.3178
+
+- GPU Memory Used (`MB`)
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 329  | 283
+    2 | 345   | 289
+    4 | 371 | 299
+    8 | 393 | 319
+    32 |  531 | 433
+
+###  <span id = '6'> MobileNet V2</span> 
+
+- Latency (`ms`) of different batch  
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 65.6861 | 2.9842
+    2 | 66.6814 | 4.7472
+    4 | 69.7114 | 7.4163
+    8 | 76.1092 | 12.8779
+    32 | 124.9810 | 47.2142
+
+- GPU Memory Used (`MB`)
+
+    BatchSize | TensorRT | Anakin
+    :---: | :---: | :---: | 
+    1 | 341 | 293
+    2 | 353 | 301
+    4 | 385 | 319
+    8 | 421 | 351
+    32 | 637 | 551
+
+## How to run those Benchmark models?
+
+> 1. At first, you should parse the caffe model with [`external converter ->`](../docs/Manual/Converter_en.md).
+> 2. Switch to *source_root/benchmark/CNN* directory. Use 'mkdir ./models' to create ./models and put anakin models into this file.
+> 3. Use command 'sh run.sh', we will create files in logs to save model log with different batch size. Finally, model latency summary will be displayed on the screen.
+> 4. If you want to get more detailed information with op time, you can modify CMakeLists.txt with setting `ENABLE_OP_TIMER` to `YES`, then recompile and run. You will find detailed information in  model log file.
+
+
+
+
+
diff --git a/benchmark/RNN/README.md b/benchmark/RNN/README.md
new file mode 100644
index 0000000..0232d7d
--- /dev/null
+++ b/benchmark/RNN/README.md
@@ -0,0 +1,10 @@
+# RNN BenchMark
+
+
+## 1. How to run
+
+Two way to run anakin
+
+> 1.You can just run `sh benchmark_tensorflow.sh` `sh benchmark_anakin.sh`
+> 2.Get the model of caffe or fluid, convert model to anakin model, use net_test_*** to test your model
+
diff --git a/benchmark/RNN/Tokenizer.py b/benchmark/RNN/Tokenizer.py
new file mode 100644
index 0000000..cceac53
--- /dev/null
+++ b/benchmark/RNN/Tokenizer.py
@@ -0,0 +1,384 @@
+# -*- coding: utf-8 -*-
+"""Utilities for text input preprocessing.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import string
+import sys
+import warnings
+from collections import OrderedDict
+from hashlib import md5
+
+import numpy as np
+from six.moves import range
+from six.moves import zip
+
+if sys.version_info < (3,):
+    maketrans = string.maketrans
+else:
+    maketrans = str.maketrans
+
+
+def text_to_word_sequence(text,
+                          filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
+                          lower=True, split=" "):
+    """Converts a text to a sequence of words (or tokens).
+
+    # Arguments
+        text: Input text (string).
+        filters: list (or concatenation) of characters to filter out, such as
+            punctuation. Default: `!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n`,
+            includes basic punctuation, tabs, and newlines.
+        lower: boolean. Whether to convert the input to lowercase.
+        split: str. Separator for word splitting.
+
+    # Returns
+        A list of words (or tokens).
+    """
+    if lower:
+        text = text.lower()
+
+    if sys.version_info < (3,):
+        if isinstance(text, unicode):
+            translate_map = dict((ord(c), unicode(split)) for c in filters)
+            text = text.translate(translate_map)
+        elif len(split) == 1:
+            translate_map = maketrans(filters, split * len(filters))
+            text = text.translate(translate_map)
+        else:
+            for c in filters:
+                text = text.replace(c, split)
+    else:
+        translate_dict = dict((c, split) for c in filters)
+        translate_map = maketrans(translate_dict)
+        text = text.translate(translate_map)
+
+    seq = text.split(split)
+    return [i for i in seq if i]
+
+
+def one_hot(text, n,
+            filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
+            lower=True,
+            split=' '):
+    """One-hot encodes a text into a list of word indexes of size n.
+
+    This is a wrapper to the `hashing_trick` function using `hash` as the
+    hashing function; unicity of word to index mapping non-guaranteed.
+
+    # Arguments
+        text: Input text (string).
+        n: int. Size of vocabulary.
+        filters: list (or concatenation) of characters to filter out, such as
+            punctuation. Default: `!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n`,
+            includes basic punctuation, tabs, and newlines.
+        lower: boolean. Whether to set the text to lowercase.
+        split: str. Separator for word splitting.
+
+    # Returns
+        List of integers in [1, n]. Each integer encodes a word
+        (unicity non-guaranteed).
+    """
+    return hashing_trick(text, n,
+                         hash_function=hash,
+                         filters=filters,
+                         lower=lower,
+                         split=split)
+
+
+def hashing_trick(text, n,
+                  hash_function=None,
+                  filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
+                  lower=True,
+                  split=' '):
+    """Converts a text to a sequence of indexes in a fixed-size hashing space.
+
+    # Arguments
+        text: Input text (string).
+        n: Dimension of the hashing space.
+        hash_function: defaults to python `hash` function, can be 'md5' or
+            any function that takes in input a string and returns a int.
+            Note that 'hash' is not a stable hashing function, so
+            it is not consistent across different runs, while 'md5'
+            is a stable hashing function.
+        filters: list (or concatenation) of characters to filter out, such as
+            punctuation. Default: `!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n`,
+            includes basic punctuation, tabs, and newlines.
+        lower: boolean. Whether to set the text to lowercase.
+        split: str. Separator for word splitting.
+
+    # Returns
+        A list of integer word indices (unicity non-guaranteed).
+
+    `0` is a reserved index that won't be assigned to any word.
+
+    Two or more words may be assigned to the same index, due to possible
+    collisions by the hashing function.
+    The [probability](
+        https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)
+    of a collision is in relation to the dimension of the hashing space and
+    the number of distinct objects.
+    """
+    if hash_function is None:
+        hash_function = hash
+    elif hash_function == 'md5':
+        hash_function = lambda w: int(md5(w.encode()).hexdigest(), 16)
+
+    seq = text_to_word_sequence(text,
+                                filters=filters,
+                                lower=lower,
+                                split=split)
+    return [(hash_function(w) % (n - 1) + 1) for w in seq]
+
+
+class Tokenizer(object):
+    """Text tokenization utility class.
+
+    This class allows to vectorize a text corpus, by turning each
+    text into either a sequence of integers (each integer being the index
+    of a token in a dictionary) or into a vector where the coefficient
+    for each token could be binary, based on word count, based on tf-idf...
+
+    # Arguments
+        num_words: the maximum number of words to keep, based
+            on word frequency. Only the most common `num_words` words will
+            be kept.
+        filters: a string where each element is a character that will be
+            filtered from the texts. The default is all punctuation, plus
+            tabs and line breaks, minus the `'` character.
+        lower: boolean. Whether to convert the texts to lowercase.
+        split: str. Separator for word splitting.
+        char_level: if True, every character will be treated as a token.
+        oov_token: if given, it will be added to word_index and used to
+            replace out-of-vocabulary words during text_to_sequence calls
+
+    By default, all punctuation is removed, turning the texts into
+    space-separated sequences of words
+    (words maybe include the `'` character). These sequences are then
+    split into lists of tokens. They will then be indexed or vectorized.
+
+    `0` is a reserved index that won't be assigned to any word.
+    """
+
+    def __init__(self, num_words=None,
+                 filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
+                 lower=True,
+                 split=' ',
+                 char_level=False,
+                 oov_token=None,
+                 **kwargs):
+        # Legacy support
+        if 'nb_words' in kwargs:
+            warnings.warn('The `nb_words` argument in `Tokenizer` '
+                          'has been renamed `num_words`.')
+            num_words = kwargs.pop('nb_words')
+        if kwargs:
+            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))
+
+        self.word_counts = OrderedDict()
+        self.word_docs = {}
+        self.filters = filters
+        self.split = split
+        self.lower = lower
+        self.num_words = num_words
+        self.document_count = 0
+        self.char_level = char_level
+        self.oov_token = oov_token
+        self.index_docs = {}
+
+    def fit_on_texts(self, texts):
+        """Updates internal vocabulary based on a list of texts.
+
+        In the case where texts contains lists,
+        we assume each entry of the lists to be a token.
+
+        Required before using `texts_to_sequences` or `texts_to_matrix`.
+
+        # Arguments
+            texts: can be a list of strings,
+                a generator of strings (for memory-efficiency),
+                or a list of list of strings.
+        """
+        for text in texts:
+            self.document_count += 1
+            if self.char_level or isinstance(text, list):
+                seq = text
+            else:
+                seq = text_to_word_sequence(text,
+                                            self.filters,
+                                            self.lower,
+                                            self.split)
+            for w in seq:
+                if w in self.word_counts:
+                    self.word_counts[w] += 1
+                else:
+                    self.word_counts[w] = 1
+            for w in set(seq):
+                if w in self.word_docs:
+                    self.word_docs[w] += 1
+                else:
+                    self.word_docs[w] = 1
+
+        wcounts = list(self.word_counts.items())
+        wcounts.sort(key=lambda x: x[1], reverse=True)
+        sorted_voc = [wc[0] for wc in wcounts]
+        # note that index 0 is reserved, never assigned to an existing word
+        self.word_index = dict(
+            list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))
+
+        if self.oov_token is not None:
+            i = self.word_index.get(self.oov_token)
+            if i is None:
+                self.word_index[self.oov_token] = len(self.word_index) + 1
+
+        for w, c in list(self.word_docs.items()):
+            self.index_docs[self.word_index[w]] = c
+        # print(self.word_index)
+        # print(self.index_docs)
+
+    def fit_on_sequences(self, sequences):
+        """Updates internal vocabulary based on a list of sequences.
+
+        Required before using `sequences_to_matrix`
+        (if `fit_on_texts` was never called).
+
+        # Arguments
+            sequences: A list of sequence.
+                A "sequence" is a list of integer word indices.
+        """
+        self.document_count += len(sequences)
+        for seq in sequences:
+            seq = set(seq)
+            for i in seq:
+                if i not in self.index_docs:
+                    self.index_docs[i] = 1
+                else:
+                    self.index_docs[i] += 1
+
+    def texts_to_sequences(self, texts):
+        """Transforms each text in texts in a sequence of integers.
+
+        Only top "num_words" most frequent words will be taken into account.
+        Only words known by the tokenizer will be taken into account.
+
+        # Arguments
+            texts: A list of texts (strings).
+
+        # Returns
+            A list of sequences.
+        """
+        res = []
+        for vect in self.texts_to_sequences_generator(texts):
+            res.append(vect)
+        return res
+
+    def texts_to_sequences_generator(self, texts):
+        """Transforms each text in `texts` in a sequence of integers.
+
+        Each item in texts can also be a list,
+        in which case we assume each item of that list to be a token.
+
+        Only top "num_words" most frequent words will be taken into account.
+        Only words known by the tokenizer will be taken into account.
+
+        # Arguments
+            texts: A list of texts (strings).
+
+        # Yields
+            Yields individual sequences.
+        """
+        num_words = self.num_words
+        for text in texts:
+            if self.char_level or isinstance(text, list):
+                seq = text
+            else:
+                seq = text_to_word_sequence(text,
+                                            self.filters,
+                                            self.lower,
+                                            self.split)
+            vect = []
+            # print(self.word_index)
+            for w in seq:
+                i = self.word_index.get(w)
+
+                if num_words and i >= num_words:
+                    if self.oov_token==None:
+                        continue
+                    else:
+                        vect.append(num_words)
+                else:
+                    vect.append(i)
+            yield vect
+
+    def texts_to_matrix(self, texts, mode='binary'):
+        """Convert a list of texts to a Numpy matrix.
+
+        # Arguments
+            texts: list of strings.
+            mode: one of "binary", "count", "tfidf", "freq".
+
+        # Returns
+            A Numpy matrix.
+        """
+        sequences = self.texts_to_sequences(texts)
+        return self.sequences_to_matrix(sequences, mode=mode)
+
+    def sequences_to_matrix(self, sequences, mode='binary'):
+        """Converts a list of sequences into a Numpy matrix.
+
+        # Arguments
+            sequences: list of sequences
+                (a sequence is a list of integer word indices).
+            mode: one of "binary", "count", "tfidf", "freq"
+
+        # Returns
+            A Numpy matrix.
+
+        # Raises
+            ValueError: In case of invalid `mode` argument,
+                or if the Tokenizer requires to be fit to sample data.
+        """
+        if not self.num_words:
+            if self.word_index:
+                num_words = len(self.word_index) + 1
+            else:
+                raise ValueError('Specify a dimension (num_words argument), '
+                                 'or fit on some text data first.')
+        else:
+            num_words = self.num_words
+
+        if mode == 'tfidf' and not self.document_count:
+            raise ValueError('Fit the Tokenizer on some data '
+                             'before using tfidf mode.')
+
+        x = np.zeros((len(sequences), num_words))
+        for i, seq in enumerate(sequences):
+            if not seq:
+                continue
+            counts = {}
+            for j in seq:
+                if j >= num_words:
+                    continue
+                if j not in counts:
+                    counts[j] = 1.
+                else:
+                    counts[j] += 1
+            for j, c in list(counts.items()):
+                if mode == 'count':
+                    x[i][j] = c
+                elif mode == 'freq':
+                    x[i][j] = c / len(seq)
+                elif mode == 'binary':
+                    x[i][j] = 1
+                elif mode == 'tfidf':
+                    # Use weighting scheme 2 in
+                    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf
+                    tf = 1 + np.log(c)
+                    idf = np.log(1 + self.document_count /
+                                 (1 + self.index_docs.get(j, 0)))
+                    x[i][j] = tf * idf
+                else:
+                    raise ValueError('Unknown vectorization mode:', mode)
+        return x
diff --git a/benchmark/RNN/benchmark_anakin.sh b/benchmark/RNN/benchmark_anakin.sh
new file mode 100755
index 0000000..51a8bc1
--- /dev/null
+++ b/benchmark/RNN/benchmark_anakin.sh
@@ -0,0 +1,23 @@
+#!/bin/bash
+set -e
+set -x
+sdir=$(cd `dirname $0`; pwd)
+
+sh $sdir/prepare.sh
+
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 1 $sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/language_model/ $sdir/data/ptb.valid_tokenlize.txt 1
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 2 $sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/language_model/ $sdir/data/ptb.valid_tokenlize.txt 2
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 4 $sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/language_model/ $sdir/data/ptb.valid_tokenlize.txt 4
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 6 $sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/language_model/ $sdir/data/ptb.valid_tokenlize.txt 6
+
+for i in {1,2,4,6} ;do
+$sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/language_model/ $sdir/data/ptb.valid_tokenlize.txt $i
+done
+
+for i in {1,2,4,6} ;do
+$sdir/../../output/unit_test/net_exec_test_chinese_ner $sdir/model/chinese_ner_model/ $sdir/data/ner_data.txt $i 1
+done
+
+for i in {1,2,4,6} ;do
+$sdir/../../output/unit_test/net_exec_x86_oneinput $sdir/model/text_classfication/ $sdir/data/ptb.valid_tokenlize.txt $i
+done
\ No newline at end of file
diff --git a/benchmark/RNN/benchmark_tensorflow.sh b/benchmark/RNN/benchmark_tensorflow.sh
new file mode 100755
index 0000000..0d874dc
--- /dev/null
+++ b/benchmark/RNN/benchmark_tensorflow.sh
@@ -0,0 +1,24 @@
+#!/bin/bash
+set -e
+set -x
+
+sdir=$(cd `dirname $0`; pwd)
+
+sh $sdir/prepare.sh
+
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 1 python $sdir/tensorflow_language_model.py 1
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 2 python $sdir/tensorflow_language_model.py 2
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 4 python $sdir/tensorflow_language_model.py 4
+#sh $sdir/sh_base/cpu_benchmark_base_some_thread.sh 6 python $sdir/tensorflow_language_model.py 6
+
+for i in {1,2,4,6};do
+python $sdir/tensorflow_language_model.py --process_num=$i
+done
+
+for i in {1,2,4,6};do
+python $sdir/tensorflow_chinese_ner.py --process_num=$i
+done
+
+for i in {1,2,4,6};do
+python $sdir/tensorflow_text_classfication.py --process_num=$i
+done
\ No newline at end of file
diff --git a/benchmark/RNN/prepare.sh b/benchmark/RNN/prepare.sh
new file mode 100755
index 0000000..7762fff
--- /dev/null
+++ b/benchmark/RNN/prepare.sh
@@ -0,0 +1,20 @@
+#!/bin/bash
+sdir=$(cd `dirname $0`; pwd)
+
+if [ ! -e $sdir/data/ptb.valid.txt ]; then
+echo "can not find language_data download now"
+wget -P $sdir/data/ http://ojf1xbmzo.bkt.clouddn.com/ptb.valid.txt
+fi
+
+if [ ! -e $sdir/data/ner_data.txt ]; then
+echo "can not find language_data download now"
+wget -P $sdir/data/ https://raw.githubusercontent.com/PaddlePaddle/models/develop/fluid/chinese_ner/data/test_files/test_part_1
+for n in $(seq 30); do cat $sdir/data/test_part_1 >> $sdir/data/ner_data.txt; done
+rm $sdir/data/test_part_1
+fi
+
+if [ ! -e $sdir/data/ptb.valid_tokenlize.txt ]; then
+python $sdir/read_ptb_data.py
+fi
+
+
diff --git a/benchmark/RNN/read_ptb_data.py b/benchmark/RNN/read_ptb_data.py
new file mode 100644
index 0000000..f2c4ad9
--- /dev/null
+++ b/benchmark/RNN/read_ptb_data.py
@@ -0,0 +1,36 @@
+from Tokenizer import Tokenizer
+# from keras.preprocessing.text import Tokenizer
+import os
+import sys
+class PTB_Data_Reader():
+
+    def read(self):
+        # print('!',sys.argv[0])
+        # print(os.path.dirname(__file__)+'/data/ptb.valid.txt')
+        file=open(os.path.dirname(__file__)+'/data/ptb.valid.txt')
+        lines=file.readlines()
+        tokenizer=Tokenizer(9999,oov_token=1)
+        tokenizer.fit_on_texts(lines)
+        self.seqs=tokenizer.texts_to_sequences(lines)
+        return self.seqs
+
+    def save_to(self):
+        save_file=open(os.path.dirname(__file__)+'/data/ptb.valid_tokenlize.txt','w')
+        for line in self.seqs:
+            line_str=''.join(str(i)+' ' for i in line)
+            line_str=line_str[:-1]
+            save_file.write(line_str+'\n')
+
+class NER_Data_Reader():
+    def read(self):
+        # print(os.path.dirname(__file__)+'/data/ptb.valid.txt')
+        file=open(os.path.dirname(__file__)+'/data/ner_data.txt')
+        self.seqs=[[[int(i) for i in line.split(';')[1].split(' ')],[int(i) for i in line.split(';')[3].split(' ')]] for line in file.readlines()]
+
+        return self.seqs
+
+if __name__ == '__main__':
+    read=PTB_Data_Reader()
+    read.read()
+    read.save_to()
+
diff --git a/benchmark/RNN/sh_base/cpu_benchmark_base_one_socket.sh b/benchmark/RNN/sh_base/cpu_benchmark_base_one_socket.sh
new file mode 100755
index 0000000..49beef0
--- /dev/null
+++ b/benchmark/RNN/sh_base/cpu_benchmark_base_one_socket.sh
@@ -0,0 +1,19 @@
+#!/bin/bash
+
+set -e
+core_per_socker=`lscpu | grep "Core(s) per socket" | awk -F ':' '{print $2}' | sed 's/^ *\| *$//g'`
+core_num=$core_per_socker
+
+echo $core_num
+core_idx=$[$core_num-1]
+echo $core_idx
+core_range='0-'${core_idx}
+
+echo ${core_range}
+
+unset OMP_NUM_THREADS
+export OMP_NUM_THREADS=${core_num}
+unset MKL_NUM_THREADS
+export MKL_NUM_THREADS=${core_num}
+
+taskset -c ${core_range} numactl -l $*
\ No newline at end of file
diff --git a/benchmark/RNN/sh_base/cpu_benchmark_base_some_thread.sh b/benchmark/RNN/sh_base/cpu_benchmark_base_some_thread.sh
new file mode 100755
index 0000000..9b6d759
--- /dev/null
+++ b/benchmark/RNN/sh_base/cpu_benchmark_base_some_thread.sh
@@ -0,0 +1,21 @@
+#!/bin/bash
+
+set -e
+set -x
+core_num=$1
+shift
+
+
+
+core_range='1-'$core_num
+
+
+echo ${core_range}
+
+unset OMP_NUM_THREADS
+export OMP_NUM_THREADS=${core_num}
+unset MKL_NUM_THREADS
+export MKL_NUM_THREADS=${core_num}
+
+#taskset -c ${core_range} numactl -l $*
+taskset -c ${core_range}  $*
diff --git a/benchmark/RNN/tensorflow_c_benchmark/benchmark_tensorflow.sh b/benchmark/RNN/tensorflow_c_benchmark/benchmark_tensorflow.sh
new file mode 100755
index 0000000..1631f9f
--- /dev/null
+++ b/benchmark/RNN/tensorflow_c_benchmark/benchmark_tensorflow.sh
@@ -0,0 +1,14 @@
+#!/bin/bash
+set -e
+set -x
+
+sdir=$(cd `dirname $0`; pwd)
+
+
+for i in {1,2,4,6};do
+bazel run //tensorflow/cc:example_model /root/tf_mount/RNN/model/language_model_tf/all.pb /root/tf_mount/RNN/data/ptb.valid_tokenlize.txt  $i
+done
+
+for i in {1,2,4,6};do
+bazel run //tensorflow/cc:example_model /root/tf_mount/RNN/model/text_classfi_model_tf/all.pb /root/tf_mount/RNN/data/ptb.valid_tokenlize.txt  $i
+done
diff --git a/benchmark/RNN/tensorflow_c_benchmark/example_model.cc b/benchmark/RNN/tensorflow_c_benchmark/example_model.cc
new file mode 100644
index 0000000..291f89e
--- /dev/null
+++ b/benchmark/RNN/tensorflow_c_benchmark/example_model.cc
@@ -0,0 +1,295 @@
+#include "tensorflow/core/public/session.h"
+#include "tensorflow/core/platform/env.h"
+#include "vector"
+#include <fstream>
+#include <thread>
+#include "sys/time.h"
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+DEFINE_GLOBAL(std::string, split_word, "\t");
+DEFINE_GLOBAL(std::string, output_name, "");
+DEFINE_GLOBAL(std::string, run_mode, "instance");
+DEFINE_GLOBAL(int, split_index, 0);
+
+using namespace tensorflow;
+int read_file(std::vector<float>& results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+
+    LOG(INFO) << "found filename: " << file_name;
+    std::string line;
+
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c) {
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+
+    while (std::string::npos != pos2) {
+        v.push_back(s.substr(pos1, pos2 - pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+
+    if (pos1 != s.length()) {
+        v.push_back(s.substr(pos1));
+    }
+}
+
+int split_word_from_file(
+    std::vector<std::vector<float> >& word_idx,
+    const std::string input_file_path,
+    const std::string split_token,
+    const std::string inner_split_token,
+    const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+
+    LOG(INFO) << "found filename: " << input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count = 0;
+
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+        CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+            //            printf("%d,",atoi(w.c_str()));
+        }
+
+        //        printf("\n");
+        //        exit(0);
+        word_idx.push_back(word);
+    }
+
+    GLB_word_count = word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+    std::vector<float>& out_data,
+    const std::vector<std::vector<float> >& seq_data,
+    std::vector<int>& seq_offset,
+    const int start_idx,
+    const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+            //            printf("%.0f, ",d);
+        }
+
+        //        printf("\n");
+        seq_offset.push_back(len);
+    }
+
+    return len;
+}
+std::vector<std::vector<float> > get_input_data() {
+    std::vector<std::vector<float> > word_idx;
+
+    if (split_word_from_file(word_idx, GLB_input_file, GLB_split_word, " ", GLB_split_index)) {
+        LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+
+    return word_idx;
+};
+void sess_thread(std::vector<tensorflow::Tensor*>* tensor_vec) {
+    SessionOptions opts;
+    opts.config.set_intra_op_parallelism_threads(1);
+    opts.config.set_inter_op_parallelism_threads(1);
+    opts.config.set_use_per_session_threads(true);
+    Session* session;
+    Status status = NewSession(opts, &session);
+
+    if (!status.ok()) {
+        std::cerr << status.ToString() << std::endl;
+        return ;
+    } else {
+        std::cout << "Session created successfully" << std::endl;
+    }
+
+    // Load the protobuf graph
+    GraphDef graph_def;
+    std::string graph_path = GLB_model_dir;//argv[1];
+    status = ReadBinaryProto(Env::Default(), graph_path, &graph_def);
+
+    if (!status.ok()) {
+        std::cerr << status.ToString() << std::endl;
+        return ;
+    } else {
+        std::cout << "Load graph protobuf successfully" << std::endl;
+    }
+
+    // Add the graph to the session
+    status = session->Create(graph_def);
+
+    if (!status.ok()) {
+        std::cerr << status.ToString() << std::endl;
+        return ;
+    } else {
+        std::cout << "Add graph to session successfully" << std::endl;
+    }
+
+    {
+        //warm up
+        std::vector<std::pair<string, tensorflow::Tensor>> inputs = {
+            { "x_input", *(*tensor_vec)[0] },
+        };
+        std::vector<tensorflow::Tensor> outputs;
+        session->Run(inputs, {"Softmax"}, {}, &outputs);
+
+        if (!status.ok()) {
+            std::cerr << status.ToString() << std::endl;
+            return ;
+        } else {
+            //  std::cout << "Run session successfully i" << std::endl;
+        }
+
+
+    }
+
+    std::cout << "thread ready to run " << std::endl;
+    struct timeval time_start, time_end;
+
+    gettimeofday(&time_start, nullptr);
+    {
+        for (int i = 0; i < tensor_vec->size(); i++) {
+            std::vector<std::pair<string, tensorflow::Tensor>> inputs = {
+                { "x_input", *(*tensor_vec)[i] },
+            };
+            std::vector<tensorflow::Tensor> outputs;
+            session->Run(inputs, {"Softmax"}, {}, &outputs);
+
+            if (!status.ok()) {
+                std::cerr << status.ToString() << std::endl;
+                return ;
+            } else {
+                //  std::cout << "Run session successfully i" << std::endl;
+            }
+        }
+
+
+    }
+    gettimeofday(&time_end, nullptr);
+
+    float use_ms = (time_end.tv_sec - time_start.tv_sec) * 1000.f + (time_end.tv_usec -
+                   time_start.tv_usec) / 1000.f;
+    std::cout << "thread summary : " << "usetime = " << use_ms << " ms," << "word_sum = " <<
+              GLB_word_count << ",delay = " << (use_ms / tensor_vec->size()) << ", QPS = " <<
+              (GLB_word_count / use_ms * 1000) << std::endl;
+
+    session->Close();
+}
+/**
+ * @brief deep model for click through rate prediction
+ * @details [long description]
+ *
+ * @param argv[1] graph protobuf
+ *
+ * @return [description]
+ */
+int main(int argc, char* argv[]) {
+    if (argc < 3) {
+        LOG(INFO) << "Example of Usage:\n \
+						./output/unit_test/model_test\n \
+						anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+
+    if (argc >= 4) {
+        GLB_run_threads = atoi(argv[3]);
+    }
+
+    // Initialize a tensorflow session
+
+    std::vector<std::vector<float> > word_idx;
+    word_idx = get_input_data();
+    std::vector<tensorflow::Tensor*> tensor_vec;
+
+    for (int i = 0; i < word_idx.size(); i++) {
+        tensorflow::Tensor* t_tensor_p = new Tensor(DT_INT32, TensorShape({1, word_idx[i].size()}));
+        auto input_tensor_mapped = t_tensor_p->tensor<int, 2>();
+
+        for (int j = 0; j < word_idx[i].size(); j++) {
+            input_tensor_mapped(0, j) = word_idx[i][j];
+
+        }
+
+        tensor_vec.push_back(t_tensor_p);
+    }
+
+    std::cout << "get word success!" << std::endl;
+    std::cout << "first data = " << tensor_vec[0]->tensor<int, 2>()(0, 0) << std::endl;
+    // Setup inputs and outputs:
+    // Our graph doesn't require any inputs, since it specifies default values,
+    // but we'll change an input to demonstrate.
+    std::vector<std::unique_ptr<std::thread>> threads;
+    int thread_num = GLB_run_threads;
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads.emplace_back(
+            new std::thread(&sess_thread, &tensor_vec));
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+
+    // Grab the first output (we only evaluated one graph node: "c")
+    // and convert the node to a scalar representation.
+    //auto output_c = outputs[0].scalar<float>();
+
+    // (There are similar methods for vectors and matrices here:
+    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/tensor.h)
+
+    // Print the results
+    //std::cout << outputs[0].DebugString() << std::endl; // Tensor<type: float shape: [] values: 30>
+    //std::cout << "output value: " << output_c() << std::endl; // 30
+
+    // Free any resources used by the session
+
+    return 0;
+}
diff --git a/benchmark/RNN/tensorflow_chinese_ner.py b/benchmark/RNN/tensorflow_chinese_ner.py
new file mode 100644
index 0000000..e939290
--- /dev/null
+++ b/benchmark/RNN/tensorflow_chinese_ner.py
@@ -0,0 +1,167 @@
+
+# coding: utf-8
+
+# In[1]:
+
+
+import tensorflow as tf
+import numpy as np
+import time
+import timeit
+
+# In[2]:
+
+def language_run(data_set):
+    word_voc_size=1942562
+    mention_voc_size=57
+    word_hidden_size=32
+    mention_hidden_size=20
+    gru_hidden_size=36
+
+    fc1_hidden_size=49
+
+
+    batch_size=1
+    tf.device('/cpu:0')
+
+
+    # In[3]:
+
+
+    x_input = tf.placeholder(
+        tf.int32, [1,None], name="x_input")
+    x_input_len = tf.placeholder(
+        tf.int32, [None],name="x_input_len")
+    mention_input = tf.placeholder(
+        tf.int32, [1,None], name="mention_input")
+
+    # In[4]:
+
+
+    embedding_table_word_r = tf.get_variable('emb_w_r', [word_voc_size, word_hidden_size], dtype=tf.float32)
+    embedding_out_r=tf.nn.embedding_lookup(embedding_table_word_r, x_input)
+
+    embedding_table_mention_r = tf.get_variable('emb_m_r', [mention_voc_size, mention_hidden_size], dtype=tf.float32)
+    embedding_mention_out_r=tf.nn.embedding_lookup(embedding_table_mention_r, mention_input)
+    ##
+    embedding_table_word_l = tf.get_variable('emb_w_l', [word_voc_size, word_hidden_size], dtype=tf.float32)
+    embedding_out_l=tf.nn.embedding_lookup(embedding_table_word_l, x_input)
+
+    embedding_table_mention_l = tf.get_variable('emb_m_l', [mention_voc_size, mention_hidden_size], dtype=tf.float32)
+    embedding_mention_out_l=tf.nn.embedding_lookup(embedding_table_mention_l, mention_input)
+
+    emb_r=tf.concat([embedding_out_r,embedding_mention_out_r],axis=-1)
+    emb_l=tf.concat([embedding_out_l,embedding_mention_out_l],axis=-1)
+    # In[5]:
+    with tf.variable_scope('forward'):
+        gru_cell_r = tf.contrib.rnn.GRUCell(gru_hidden_size)
+        gru_init_state_r = gru_cell_r.zero_state(batch_size, dtype=tf.float32)
+        gru_out_r, _ = tf.nn.dynamic_rnn(gru_cell_r, emb_r, initial_state=gru_init_state_r)
+
+    with tf.variable_scope('backward'):
+        gru_cell_l = tf.contrib.rnn.GRUCell(gru_hidden_size)
+        gru_init_state_l = gru_cell_l.zero_state(batch_size, dtype=tf.float32)
+        gru_out_l, _ = tf.nn.dynamic_rnn(gru_cell_l, emb_l, initial_state=gru_init_state_l)
+
+    bi_gru_out=tf.concat([gru_out_l,gru_out_r],axis=-1)
+
+    # In[6]:
+
+
+    fc_weights = tf.get_variable(
+        'fc_weights', [ gru_hidden_size*2,fc1_hidden_size],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.01, dtype=tf.float32),
+        dtype=tf.float32)
+    fc_bias = tf.get_variable(
+        'fc_bias', [fc1_hidden_size],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.0, dtype=tf.float32),
+        dtype=tf.float32)
+    bi_gru_out=tf.squeeze(bi_gru_out,[0])
+    fc1_out=tf.matmul(bi_gru_out,fc_weights) + fc_bias
+
+
+    # In[7]:
+    crf_weights = tf.get_variable(
+        'crf_weights', [ fc1_hidden_size,fc1_hidden_size],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.01, dtype=tf.float32),
+        dtype=tf.float32)
+
+    fc1_out=tf.reshape(fc1_out,[batch_size,-1,fc1_hidden_size])
+    crf_out,_=tf.contrib.crf.crf_decode(fc1_out,crf_weights,x_input_len)
+
+
+
+
+
+    # In[8]:
+
+    init = tf.global_variables_initializer()
+    sess = tf.Session()
+    sess.run(init)
+
+    # In[9]:
+
+
+    def clock(func):
+        def clocked(*args):
+            t0 = timeit.default_timer()
+            result = func(*args)
+            elapsed = timeit.default_timer() - t0
+            name = func.__name__
+            arg_str = ', '.join(repr(arg) for arg in args)
+            print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, 'arg_str', result))
+            lines=len(args[0])
+            counter=sum(len(line) for line in args[0])
+            print('Delay = '+str(elapsed*1000/lines)+'ms')
+            return result
+        return clocked
+
+
+    # In[10]:
+
+
+    @clock
+    def benchmark(data_set):
+        for one_batch in data_set:
+            word_vec,mention_vec=one_batch[0],one_batch[1]
+            sess.run([crf_out],{x_input:np.array(word_vec).reshape(1,len(word_vec)),mention_input:np.array(mention_vec).reshape(1,len(mention_vec)),x_input_len:[len(word_vec)]})
+
+            # tf.train.write_graph(sess.graph.as_graph_def(), 'model/language_model_tf/', 'graph.pb', as_text=False)
+            # saver=tf.train.Saver()
+            # saver.save(sess, "model/chinese_ner_model_tf/")
+            # exit()
+
+    benchmark(data_set)
+if __name__=='__main__':
+    import getopt
+    import sys
+    proc_num=1
+    try:
+        opts, args = getopt.getopt(sys.argv[1:], "ho:", ["help", "process_num="])
+        for key,arg in opts:
+            if key in ('-h','--help'):
+                print('usage --process_num=k ,default=1')
+            if key in ('--process_num'):
+                proc_num=int(arg)
+        print(opts)
+    except getopt.GetoptError:
+        pass
+
+    from read_ptb_data import NER_Data_Reader
+    data_set=NER_Data_Reader().read()
+    word_sum=sum(len(i[0]) for i in data_set)
+    from multiprocessing import Process
+    threads=[]
+    t0 = timeit.default_timer()
+    for i in range(proc_num):
+        t =Process(target=language_run,args=(data_set,))
+        t.start()
+        threads.append(t)
+
+    for t in threads:
+        t.join()
+    elapsed = timeit.default_timer() - t0
+    print(__file__,'process = ',proc_num,',QPS = ',len(data_set)/elapsed*proc_num,' line / second ,',word_sum/elapsed*proc_num,'words/second')
\ No newline at end of file
diff --git a/benchmark/RNN/tensorflow_language_model.py b/benchmark/RNN/tensorflow_language_model.py
new file mode 100644
index 0000000..31b4997
--- /dev/null
+++ b/benchmark/RNN/tensorflow_language_model.py
@@ -0,0 +1,136 @@
+
+# coding: utf-8
+
+# In[1]:
+
+
+import tensorflow as tf
+import numpy as np
+import time
+import timeit
+
+# In[2]:
+
+def language_run(data_set):
+    voc_size=10001
+    hidden_size=200
+    batch_size=1
+    tf.device('/cpu:0')
+
+
+    # In[3]:
+
+
+    x_input = tf.placeholder(
+        tf.int32, [1,None], name="x_input")
+    # x_input_len = tf.placeholder(
+    #                 tf.int32, name="x_input_len")
+
+
+    # In[4]:
+
+
+    embedding_table = tf.get_variable('emb', [voc_size, hidden_size], dtype=tf.float32)
+    embedding_out=tf.nn.embedding_lookup(embedding_table, x_input)
+
+
+    # In[5]:
+
+
+    gru_cell = tf.contrib.rnn.GRUCell(hidden_size)
+    gru_init_state=gru_cell.zero_state(batch_size, dtype=tf.float32)
+    gru_out,_=tf.nn.dynamic_rnn(gru_cell,embedding_out,initial_state=gru_init_state)
+
+
+    # In[6]:
+
+
+    fc_weights = tf.get_variable(
+        'fc_weights', [ hidden_size,voc_size],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.01, dtype=tf.float32),
+        dtype=tf.float32)
+    fc_bias = tf.get_variable(
+        'fc_bias', [voc_size],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.0, dtype=tf.float32),
+        dtype=tf.float32)
+    gru_out=tf.squeeze(gru_out,[0])
+    fc_out=tf.matmul(gru_out,fc_weights) + fc_bias
+
+
+    # In[7]:
+
+
+    softmax=tf.nn.softmax(fc_out)
+
+
+    # In[8]:
+
+    init = tf.global_variables_initializer()
+    sess = tf.Session()
+    sess.run(init)
+
+    # In[9]:
+
+
+    def clock(func):
+        def clocked(*args):
+            t0 = timeit.default_timer()
+            result = func(*args)
+            elapsed = timeit.default_timer() - t0
+            name = func.__name__
+            arg_str = ', '.join(repr(arg) for arg in args)
+            print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, 'arg_str', result))
+            lines=len(args[0])
+            counter=sum(len(line) for line in args[0])
+            print('Delay = '+str(elapsed*1000/lines)+'ms')
+            return result
+        return clocked
+
+
+    # In[10]:
+
+
+    @clock
+    def benchmark(data_set):
+        for one_batch in data_set:
+            sess.run([softmax],{x_input:np.array(one_batch).reshape(1,len(one_batch))})
+
+            # tf.train.write_graph(sess.graph.as_graph_def(), 'model/language_model_tf/', 'graph.pb', as_text=False)
+            # saver=tf.train.Saver()
+            # saver.save(sess, "model/language_model_tf/model.cpkt")
+            # exit()
+
+
+    benchmark(data_set)
+if __name__=='__main__':
+    import getopt
+    import sys
+    proc_num=1
+    try:
+        opts, args = getopt.getopt(sys.argv[1:], "ho:", ["help", "process_num="])
+        for key,arg in opts:
+            if key in ('-h','--help'):
+                print('usage --process_num=k ,default=1')
+            if key in ('--process_num'):
+                proc_num=int(arg)
+        print(opts)
+    except getopt.GetoptError:
+        pass
+
+    from read_ptb_data import PTB_Data_Reader
+    data_set=PTB_Data_Reader().read()
+    word_sum=sum(len(i) for i in data_set)
+    from multiprocessing import Process
+    threads=[]
+    t0 = timeit.default_timer()
+    for i in range(proc_num):
+        t =Process(target=language_run,args=(data_set,))
+        t.start()
+        threads.append(t)
+
+    for t in threads:
+        t.join()
+    elapsed = timeit.default_timer() - t0
+    print(__file__,'process = ',proc_num,',QPS = ',len(data_set)/elapsed*proc_num,' line / second ,',word_sum/elapsed*proc_num,'words/second')
\ No newline at end of file
diff --git a/benchmark/RNN/tensorflow_text_classfication.py b/benchmark/RNN/tensorflow_text_classfication.py
new file mode 100644
index 0000000..c690085
--- /dev/null
+++ b/benchmark/RNN/tensorflow_text_classfication.py
@@ -0,0 +1,149 @@
+
+# coding: utf-8
+
+# In[1]:
+
+
+import tensorflow as tf
+import numpy as np
+import time
+import timeit
+
+# In[2]:
+
+def language_run(data_set):
+    voc_size=566227
+    hidden_size=128
+    hidden_size_after_lstm=96
+    hidden_size_after_fc=2
+    batch_size=1
+    tf.device('/cpu:0')
+
+
+    # In[3]:
+
+
+    x_input = tf.placeholder(
+        tf.int32, [1,None], name="x_input")
+
+
+    # In[4]:
+
+
+    embedding_table = tf.get_variable('emb', [voc_size, hidden_size], dtype=tf.float32)
+    embedding_out=tf.nn.embedding_lookup(embedding_table, x_input)
+
+
+    # In[5]:
+
+
+    lstm_cell = tf.contrib.rnn.LSTMCell(hidden_size)
+    # lstm_init_state=lstm_cell.zero_state(batch_size, dtype=tf.float32)
+    # lstm_out,_=tf.nn.dynamic_rnn(lstm_cell,embedding_out,initial_state=lstm_init_state)
+    (output_fw, output_bw), _=tf.nn.bidirectional_dynamic_rnn(lstm_cell,
+                                                              lstm_cell, embedding_out,
+                                                              dtype=tf.float32)
+
+    bi_lstm_out = tf.concat([output_fw, output_bw], axis=-1)
+
+    # In[6]:
+
+
+    fc_weights = tf.get_variable(
+        'fc_weights', [ hidden_size*2,hidden_size_after_lstm],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.01, dtype=tf.float32),
+        dtype=tf.float32)
+    fc_bias = tf.get_variable(
+        'fc_bias', [hidden_size_after_lstm],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.0, dtype=tf.float32),
+        dtype=tf.float32)
+    bi_lstm_out=tf.squeeze(bi_lstm_out,[0])
+    fc1_out=tf.tanh(tf.matmul(bi_lstm_out,fc_weights) + fc_bias)
+
+    # In[7]:
+    fc2_weights = tf.get_variable(
+        'fc2_weights', [ hidden_size_after_lstm,hidden_size_after_fc],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.01, dtype=tf.float32),
+        dtype=tf.float32)
+    fc2_bias = tf.get_variable(
+        'fc2_bias', [hidden_size_after_fc],
+        initializer=tf.truncated_normal_initializer(
+            stddev=0.0, dtype=tf.float32),
+        dtype=tf.float32)
+    fc2_out=tf.matmul(fc1_out,fc2_weights) + fc2_bias
+
+    softmax=tf.nn.softmax(fc2_out)
+
+
+    # In[8]:
+
+    init = tf.global_variables_initializer()
+    sess = tf.Session()
+    sess.run(init)
+
+    # In[9]:
+
+
+    def clock(func):
+        def clocked(*args):
+            t0 = timeit.default_timer()
+            result = func(*args)
+            elapsed = timeit.default_timer() - t0
+            name = func.__name__
+            arg_str = ', '.join(repr(arg) for arg in args)
+            print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, 'arg_str', result))
+            lines=len(args[0])
+            counter=sum(len(line) for line in args[0])
+            print('Delay = '+str(elapsed*1000/lines)+'ms')
+            return result
+        return clocked
+
+
+    # In[10]:
+
+
+    @clock
+    def benchmark(data_set):
+        for one_batch in data_set:
+            sess.run([softmax],{x_input:np.array(one_batch).reshape(1,len(one_batch))})
+
+            # tf.train.write_graph(sess.graph.as_graph_def(), 'model/text_classfi_model_tf/', 'graph.pb', as_text=False)
+            # saver=tf.train.Saver()
+            # saver.save(sess, "model/text_classfi_model_tf/model.cpkt")
+            # exit()
+
+
+    benchmark(data_set)
+if __name__=='__main__':
+    import getopt
+    import sys
+    proc_num=1
+    try:
+        opts, args = getopt.getopt(sys.argv[1:], "ho:", ["help", "process_num="])
+        for key,arg in opts:
+            if key in ('-h','--help'):
+                print('usage --process_num=k ,default=1')
+            if key in ('--process_num'):
+                proc_num=int(arg)
+        print(opts)
+    except getopt.GetoptError:
+        pass
+
+    from read_ptb_data import PTB_Data_Reader
+    data_set=PTB_Data_Reader().read()
+    word_sum=sum(len(i) for i in data_set)
+    from multiprocessing import Process
+    threads=[]
+    t0 = timeit.default_timer()
+    for i in range(proc_num):
+        t =Process(target=language_run,args=(data_set,))
+        t.start()
+        threads.append(t)
+
+    for t in threads:
+        t.join()
+    elapsed = timeit.default_timer() - t0
+    print(__file__,'process = ',proc_num,',QPS = ',len(data_set)/elapsed*proc_num,' line / second ,',word_sum/elapsed*proc_num,'words/second')
\ No newline at end of file
diff --git a/benchmark/arm_benchmark.md b/benchmark/arm_benchmark.md
new file mode 100644
index 0000000..3ab4feb
--- /dev/null
+++ b/benchmark/arm_benchmark.md
@@ -0,0 +1,57 @@
+# 测试环境和参数:
++ 测试模型Mobilenetv1, mobilenetv2, mobilenet-ssd
++ 采用android ndk交叉编译，gcc 4.9，enable neon， ABI： armveabi-v7a with neon -mfloat-abi=softfp
++ 测试平台
+   - 荣耀v9(root): 处理器:麒麟960, 4 big cores in 2.36GHz, 4 little cores in 1.8GHz
+   - nubia z17:处理器:高通835, 4 big cores in 2.36GHz, 4 little cores in 1.9GHz
+   - 360 N5:处理器:高通653, 4 big cores in 1.8GHz, 4 little cores in 1.4GHz
++ 多线程：openmp
++ 时间：warmup10次，运行10次取均值
++ ncnn版本：来源于github的master branch中commits ID：307a77f04be29875f40d337cfff6df747df09de6（msg:convert            LogisticRegressionOutput)版本
++ TFlite版本：来源于github的master branch中commits ID：65c05bc2ac19f51f7027e66350bc71652662125c（msg:Removed unneeded file copy that was causing failure in Pi builds)版本
+
+## Anakin
+
+在BenchMark中本文将使用**`ncnn`**、**`TFlite`**和**`Anakin`**进行性能对比分析
+
+## BenchMark model
+
+> 注意在性能测试之前，请先将测试model通过[External Converter](#10003)转换为Anakin model
+> 对这些model，本文在ARM上进行多线程的单batch size测试。
+
+- [Mobilenet v1](#11)  *caffe model 可以在[这儿](https://github.com/shicai/MobileNet-Caffe)下载*
+- [Mobilenet v2](#22)  *caffe model 可以在[这儿](https://github.com/shicai/MobileNet-Caffe)下载*
+- [mobilenet-ssd](#33)  *caffe model 可以在[这儿](https://github.com/chuanqi305/MobileNet-SSD)下载*
+
+### <span id = '11'> mobilenetv1 </span>
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |麒麟960|107.7ms|61.1ms|38.2ms|152.8ms|85.2ms|51.9ms|152.6ms|nan|nan|
+   |高通835|105.7ms|63.1ms|~~46.8ms~~|152.7ms|87.0ms|~~92.7ms~~|146.9ms|nan|nan|
+   |高通653|120.3ms|64.2ms|46.6ms|202.5ms|117.6ms|84.8ms|158.6ms|nan|nan| 
+
+### <span id = '22'> mobilenetv2 </span>
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |麒麟960|93.1ms|53.9ms|34.8ms|144.4ms|84.3ms|55.3ms|100.6ms|nan|nan|
+   |高通835|93.0ms|55.6ms|41.1ms|139.1ms|88.4ms|58.1ms|95.2ms|nan|nan|
+   |高通653|106.6ms|64.2ms|48.0ms|199.9ms|125.1ms|98.9ms|108.5ms|nan|nan|
+
+### <span id = '33'> mobilenet-ssd </span>
+
+   |platform | Anakin (1) | Anakin (2) | Anakin (4) | ncnn (1) | ncnn (2) | ncnn (4) | TFlite (1) | TFlite (2) | TFlite (4)| 
+   |:---: | :---: | :---: | :---:| :---:| :---:| :---:| :---:| :---:| :---:|
+   |麒麟960|213.9ms|120.5ms|74.5ms|307.9ms|166.5ms|104.2ms|nan|nan|nan|
+   |高通835|213.0ms|125.7ms|~~98.4ms~~|292.9ms|177.9ms|~~167.8ms~~|nan|nan|nan|
+   |高通653|236.0ms|129.6ms|96.0ms|377.7ms|228.9ms|165.0ms|nan|nan|nan
+
+## How to run those Benchmark models?
+
+1. 首先, 使用[External Converter](../docs/Manual/Converter_en.md)对caffe model 进行转换
+2. 然后将转换后的Anakin model和编译好的benchmark_arm 二进制文件通过'adb push'命令上传至测试机
+3. 接着在测试机含有Anakin model的目录中运行'./benchmark_arm ./ anakin_model.anakin.bin 1 10 10 1' 命令
+4. 最后，终端显示器上将会打印该模型的运行时间
+5. 其中运行命令的参数个数和含义可以通过运行'./benchmark_arm'看到
+
diff --git a/cmake/compiler_options.cmake b/cmake/compiler_options.cmake
index 26db4f5..ef5e953 100644
--- a/cmake/compiler_options.cmake
+++ b/cmake/compiler_options.cmake
@@ -1,10 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     compiler_options.cmake
-# @auther   cuichaowen
-# @date     2017-3-2
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 # ----------------------------------------------------------------------------
 # section: set the compiler and linker options 
@@ -16,7 +22,6 @@ anakin_add_compile_option(-std=c++11)
 anakin_add_compile_option(-fPIC)
 anakin_add_compile_option(-ldl)
 if(NOT USE_ARM_PLACE)
-	anakin_add_compile_option(-mavx2)
     anakin_add_compile_option(-lrt)
 endif()
 anakin_add_compile_option(-W)
@@ -74,6 +79,9 @@ if(TARGET_IOS)
 endif()
 
 if(USE_X86_PLACE)
+#	anakin_add_compile_option(-mavx2)
+#	anakin_add_compile_option(-fopenmp)
+	anakin_add_compile_option(-march=native)
     anakin_add_compile_option(-Ofast)
     anakin_add_compile_option(-ffast-math)
     anakin_add_compile_option(-Wall)
diff --git a/cmake/config/anakin_config.h.in b/cmake/config/anakin_config.h.in
index 52a2eae..fe2b8dc 100644
--- a/cmake/config/anakin_config.h.in
+++ b/cmake/config/anakin_config.h.in
@@ -1,16 +1,17 @@
-/**********************************************************
- * Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
- *   
- * @file        anakin_config.h.in
- * @brief       file ak_config.h is autogenerated from config.h.in
- * 				during the cmake configuration of anakin.
- *      
- * @auther      cuichaowen
- * @version     ANAKIN V @VERSION@
- * @date        2017-10-23
- *
- **********************************************************/
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+ */
 
 #ifndef _ANAKIN_CONFIGURATION_HEADER_GUARD_H_
 #define _ANAKIN_CONFIGURATION_HEADER_GUARD_H_
@@ -58,7 +59,7 @@
 
 #cmakedefine USE_ARM_PLACE
 
-#cmakedefine TARGET_ANDRIOD
+#cmakedefine TARGET_ANDROID
 
 #cmakedefine TARGET_IOS
 
diff --git a/cmake/cuda.cmake b/cmake/cuda.cmake
index da5540a..4b06a58 100644
--- a/cmake/cuda.cmake
+++ b/cmake/cuda.cmake
@@ -1,10 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2017 Baidu.com, Inc. All Rights Reserved
-# @file     cuda.cmake
-# @auther   cuichaowen
-# @date     2017-10-23
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # ----------------------------------------------------------------------------
 # section: Set nvcc arch info.
 # ----------------------------------------------------------------------------
diff --git a/cmake/external/mklml.cmake b/cmake/external/mklml.cmake
index de9b905..1aed995 100644
--- a/cmake/external/mklml.cmake
+++ b/cmake/external/mklml.cmake
@@ -59,5 +59,12 @@ list(APPEND ANAKIN_SABER_DEPENDENCIES mklml)
 
 list(APPEND ANAKIN_LINKER_LIBS ${MKLML_LIB};${MKLML_IOMP_LIB})
 
+set(OPENMP_FLAGS "-fopenmp")
+#set(CMAKE_C_CREATE_SHARED_LIBRARY_FORBIDDEN_FLAGS ${OPENMP_FLAGS})
+set(CMAKE_CXX_CREATE_SHARED_LIBRARY_FORBIDDEN_FLAGS ${OPENMP_FLAGS})
+set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} ${OPENMP_FLAGS}")
+set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${OPENMP_FLAGS}")
+
+
 # iomp5 must be installed
 install(FILES ${MKLML_LIB} ${MKLML_IOMP_LIB} DESTINATION lib)
diff --git a/cmake/find_modules.cmake b/cmake/find_modules.cmake
index c76440e..611da6a 100644
--- a/cmake/find_modules.cmake
+++ b/cmake/find_modules.cmake
@@ -1,9 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2017 Baidu.com, Inc. All Rights Reserved
-# @file     find_modules.cmake
-# @auther   cuichaowen
-# @date     2016-11-9
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 #anakin cmake module
 set(CMAKE_MODULE_PATH "${ANAKIN_ROOT}/cmake")
@@ -11,13 +18,14 @@ set(CMAKE_MODULE_PATH "${ANAKIN_ROOT}/cmake")
 set(ANAKIN_LINKER_LIBS "")
 
 if(UNIX)
-	if(NOT USE_ARM_PLACE) 
-    	find_library(RTLIB rt)
-    	if(RTLIB)
-        	list(APPEND ANAKIN_LINKER_LIBS ${RTLIB})
-    	else()
-        	message(SEND_ERROR "Could not found -lrt !")
-    	endif()
+	if(USE_ARM_PLACE)
+	else()
+		find_library(RTLIB rt)
+		if(RTLIB)
+			list(APPEND ANAKIN_LINKER_LIBS ${RTLIB})
+		else()
+			message(SEND_ERROR "Could not found -lrt !")
+		endif()
 	endif()
 
     find_library(DLLIB dl)
@@ -30,30 +38,38 @@ endif()
 
 #find opencv version >= 2.4.3
 macro(anakin_find_opencv)
-    if(BUILD_SHARED OR TRUE) # temporary not support static link opencv.
-	    #set(CMAKE_FIND_ROOT_PATH ${ANAKIN_ROOT}/third-party/opencv243/lib)
-        find_package(OpenCV QUIET COMPONENTS core highgui imgproc imgcodecs)
-        if(NOT OpenCV_FOUND)
-            find_package(OpenCV QUIET COMPONENTS core highgui imgproc)
-        endif()
-	    if(OpenCV_FOUND)
-	    	message(STATUS "Found opencv: ${OpenCV_INCLUDE_DIRS}")
-	    	include_directories(SYSTEM ${OpenCV_INCLUDE_DIRS})
-	    	list(APPEND ANAKIN_LINKER_LIBS ${OpenCV_LIBS})	
-	    else()
-	    	message(SEND_ERROR "Could not found opencv !")
-	    endif()	
-    else() # BUILD_STATIC
-        list(APPEND OPENCV_STATIC_LIBS libopencv_core.a
-                                       libopencv_highgui.a
-                                       libopencv_imgproc.a
-                                       libopencv_contrib.a)
-        foreach(CV_LIB ${OPENCV_STATIC_LIBS})
-            set(__CV_LIB_FULL_PATH "${ANAKIN_ROOT}/third-party/opencv243/lib/${CV_LIB}")    
-            #message(STATUS ${__CV_LIB_FULL_PATH})
-            list(APPEND ANAKIN_LINKER_LIBS ${__CV_LIB_FULL_PATH})
-        endforeach()
-        unset(__CV_LIB_FULL_PATH)
+
+	if(USE_ARM_PLACE AND TARGET_ANDROID)
+		include_directories(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/jni/include/)
+		LINK_DIRECTORIES(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/libs/armeabi-v7a/)
+
+	else()
+
+		if(BUILD_SHARED) # temporary not support static link opencv.
+			find_package(OpenCV QUIET COMPONENTS core highgui imgproc imgcodecs)
+			if(NOT OpenCV_FOUND)
+				find_package(OpenCV QUIET COMPONENTS core highgui imgproc)
+			endif()
+			if(OpenCV_FOUND)
+				message(STATUS "Found opencv: ${OpenCV_INCLUDE_DIRS}")
+				include_directories(SYSTEM ${OpenCV_INCLUDE_DIRS})
+				list(APPEND ANAKIN_LINKER_LIBS ${OpenCV_LIBS})
+
+			else()
+				message(SEND_ERROR "Could not found opencv !")
+			endif()
+		else() # BUILD_STATIC
+			set(OPENCV_LIB_PATH "" CACHE "Path to oopen cv library")
+			list(APPEND OPENCV_STATIC_LIBS ${OPENCV_LIB_PATH}/libopencv_core.a
+					${OPENCV_LIB_PATH}libopencv_highgui.a
+					${OPENCV_LIB_PATH}libopencv_imgproc.a
+					${OPENCV_LIB_PATH}libopencv_contrib.a)
+			foreach(CV_LIB ${OPENCV_STATIC_LIBS})
+				list(APPEND ANAKIN_LINKER_LIBS ${CV_LIB})
+			endforeach()
+			unset(__CV_LIB_FULL_PATH)
+		endif()
+
     endif()
 endmacro()
 
@@ -267,22 +283,28 @@ macro(anakin_find_mklml)
 endmacro()
 
 macro(anakin_find_protobuf)
-	if(USE_ARM_PLACE) 
-		set(ARM_PROTOBUF_ROOT "" CACHE PATH "arm use protobuf root dir.") 
-		find_path(PROTO_INCLUDE_DIR stubs/common.h PATHS ${ARM_PROTOBUF_ROOT}/include/google/protobuf 
-														 ${ANAKIN_ROOT}/third-party/protobuf/include/google/protobuf 
-														 NO_DEFAULT_PATH)
-		if(BUILD_SHARED) 
-			list(APPEND ANAKIN_LINKER_LIBS ${ARM_RPOTO_ROOT}/lib/libprotobuf.so) 
-		else() 
-			list(APPEND ANAKIN_LINKER_LIBS ${ARM_RPOTO_ROOT}/lib/libprotobuf.a) 
-		endif()
+	if(USE_ARM_PLACE)
+		set(ARM_RPOTO_ROOT "${CMAKE_SOURCE_DIR}/third-party/arm-android/protobuf")
+		include_directories(${ARM_RPOTO_ROOT}/include)
+		set(PROTOBUF_LIBRARIES "")
+		#if(BUILD_SHARED)
+		#	list(APPEND ANAKIN_LINKER_LIBS ${ARM_RPOTO_ROOT}/lib/libprotobuf.so)
+		#else()
+			list(APPEND ANAKIN_LINKER_LIBS ${ARM_RPOTO_ROOT}/lib/libprotobuf.a)
+		#endif()
+		find_library( # Sets the name of the path variable.
+				log-lib
+
+				# Specifies the name of the NDK library that
+				# you want CMake to locate.
+				log )
+		list(APPEND ANAKIN_LINKER_LIBS ${log-lib})
 	else()
-		find_package(Protobuf REQUIRED) 
-		if(PROTOBUF_FOUND) 
-			message(STATUS "Found protobuf in ${PROTOBUF_INCLUDE_DIR}") 
-			include_directories(${PROTOBUF_INCLUDE_DIR}) 
-			list(APPEND ANAKIN_LINKER_LIBS ${PROTOBUF_LIBRARIES}) 
+		find_package(Protobuf REQUIRED)
+		if(PROTOBUF_FOUND)
+			message(STATUS "Found protobuf in ${PROTOBUF_INCLUDE_DIR}")
+			include_directories(${PROTOBUF_INCLUDE_DIR})
+			list(APPEND ANAKIN_LINKER_LIBS ${PROTOBUF_LIBRARIES})
 		endif()
 	endif()
 endmacro()
@@ -291,12 +313,12 @@ endmacro()
 macro(anakin_find_openmp)
 	find_package(OpenMP REQUIRED)
 	if(OPENMP_FOUND OR OpenMP_CXX_FOUND)
+		set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} ${OpenMP_C_FLAGS}")
+		set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}")
 		message(STATUS "Found openmp in ${OPENMP_INCLUDE_DIR}")
-		message(STATUS " |-- openmp c flags:  ${OpenMP_C_FLAGS}")
-	    	message(STATUS " |-- openmp cxx flags:  ${OpenMP_CXX_FLAGS}")
-	    	message(STATUS " `-- openmp link flags:  ${OpenMP_EXE_LINKER_FLAGS}")
-		include_directories(${OPENMP_INCLUDE_DIR})
-		list(APPEND ANAKIN_LINKER_LIBS ${OPENMP_LIBRARIES})
+		message(STATUS " |--openmp cflags: ${OpenMP_C_FLAGS}")
+		message(STATUS " |--openmp cxxflags: ${OpenMP_CXX_FLAGS}")
+		message(STATUS " |--openmp cflags: ${OpenMP_EXE_LINKER_FLAGS}")
 	else()
 		message(FATAL_ERROR "Could not found openmp !")
 	endif()
diff --git a/cmake/gather.cmake b/cmake/gather.cmake
index 635fa54..0f701f8 100644
--- a/cmake/gather.cmake
+++ b/cmake/gather.cmake
@@ -1,10 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2017 Baidu.com, Inc. All Rights Reserved
-# @file     gather_libs.cmake
-# @auther   cuichaowen
-# @date     2017-10-24
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # find cudnn default cudnn 5
 if(USE_CUDNN)
     anakin_find_cudnn()
@@ -67,7 +73,7 @@ if(DISABLE_ALL_WARNINGS)
 endif()
 
 if(USE_ARM_PLACE)
-	if(TARGET_ANDROID)
+    if(TARGET_ANDROID)
 		if(USE_OPENMP)
         	anakin_find_openmp()
 		endif()
diff --git a/cmake/msg_color.cmake b/cmake/msg_color.cmake
index 3bf6da6..18fc4cf 100644
--- a/cmake/msg_color.cmake
+++ b/cmake/msg_color.cmake
@@ -1,9 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     msg_color.cmake
-# @auther   cuichaowen
-# @date     2016-11-8
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 # ----------------------------------------------------------------------------
 # section: help to get colorful cmake message.
diff --git a/cmake/statistic.cmake b/cmake/statistic.cmake
index 65a9f79..8613812 100644
--- a/cmake/statistic.cmake
+++ b/cmake/statistic.cmake
@@ -1,10 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     statistic.cmake
-# @auther   cuichaowen
-# @date     2017-4-20
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 # ----------------------------------------------------------------------------
 # section: prints the statistic of configuration of anakin.
@@ -113,7 +119,7 @@ function(anakin_print_statistic)
 	elseif(USE_ARM_PLACE)
   	message(STATUS "  USE_ARM_PLACE             : ${USE_ARM_PLACE}")
     if(TARGET_ANDROID)
-    message(STATUS "    `--Target Andriod       : ${TARGET_ANDROID}")
+    message(STATUS "    `--Target Android       : ${TARGET_ANDROID}")
     else()
     message(STATUS "    `--Target IOS           : ${TARGET_IOS}")
     endif()
diff --git a/cmake/utils.cmake b/cmake/utils.cmake
index 28b101b..1c28184 100644
--- a/cmake/utils.cmake
+++ b/cmake/utils.cmake
@@ -1,9 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     utils.cmake
-# @auther   cuichaowen
-# @date     2016-11-8
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 # ----------------------------------------------------------------------------
 # section: help to search src and include files
@@ -51,6 +58,14 @@ function(anakin_fetch_include_recursively root_dir)
     endforeach()
 endfunction()
 
+# judge fetch files
+function(anakin_judge_avx   outputs)
+	exec_program(cat /proc/cpuinfo|greps flag|uniq
+			OUTPUT_VARIABLE OUTPUT
+			RETURN_VALUE VALUE)
+	message("it is anakin_judge_avx " OUTPUT)
+	set(${outputs} ${${outputs}} PARENT_SCOPE)
+endfunction()
 # ----------------------------------------------------------------------------
 # section: help to detect the compiler options
 # ----------------------------------------------------------------------------
diff --git a/docker/README_cn.md b/docker/README_cn.md
new file mode 100644
index 0000000..6d5ed99
--- /dev/null
+++ b/docker/README_cn.md
@@ -0,0 +1,46 @@
+# Anakin 2.0 And Docker
+---
+
+## 依赖软件
+
++ 你的操作系统上应该已经安装了docker.
++ 如果你要在docker中使用`NVIDIA GPU` 还需要安装[nvidia-docker2](https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0))
+
+## 使用方法
+
+推荐使用 `anakin_docker_build_and_run.sh` 脚本来构建和运行docker镜像，脚本的使用方法如下
+
+```bash
+Usage: anakin_docker_build_and_run.sh -p <place> -o <os> -m <Optional>
+
+选项:
+
+   -p     硬件的运行环境 [ NVIDIA-GPU / AMD_GPU / X86-ONLY / ARM ]
+   -o     主机的操作系统类型 [ Centos / Ubuntu ]
+   -m     脚本的执行模式[ Build / Run / All] 默认模式是 build and run
+```
+
+### GPU Docker
+#### 构建镜像
+```bash
+/usr/bash anakin_docker_build_and_run.sh  -p NVIDIA-GPU -o Centos -m Build
+或者
+chmod +x ./anakin_docker_build_and_run.sh
+./anakin_docker_build_and_run.sh  -p NVIDIA-GPU -o Centos -m Build
+```
+
+#### 运行 docker容器
+```bash
+/usr/bash anakin_docker_build_and_run.sh  -p NVIDIA-GPU -o Centos -m Run
+或者
+chmod +x ./anakin_docker_build_and_run.sh
+./anakin_docker_build_and_run.sh  -p NVIDIA-GPU -o Centos -m Run
+```
+
+### X86 Docker
+
+> Not support yet
+
+### ARM Docer
+
+> Not support yet
diff --git a/docs/Manual/C++APIs_ch.md b/docs/Manual/C++APIs_ch.md
new file mode 100644
index 0000000..e0dc81d
--- /dev/null
+++ b/docs/Manual/C++APIs_ch.md
@@ -0,0 +1,624 @@
+# C++ APIs ##
+
+本教程将会介绍Anakin的一些基本的API及如何调用这些API。
+
+主要内容如下：
+
+- [Anakin APIs](#api)
+- [示例代码](#example)
+
+## <span id ='api'>Anakin APIs </span> ###
+### Tensor ####
+
+`Tensor`提供基础的数据操作和管理，为ops提供统一的数据接口。`Tensor`包含以下几个属性：   
+
+- Buffer  
+   数据存储区
+- Shape  
+   数据的维度信息
+- Event  
+   用于异步计算的同步
+
+ `Tensor` 类包含三个`Shape`对象， 分别是`_shape`, `_valid_shape`和 `offset`。 `_shape`为`tensor`真正空间信息，`_valid_shape`表示当前`tensor`使用的空间信息， `_offset`表示当前`tensor`数据指针相对于真正数据空间的信息。 `Tensor`不同维度与分别与数学中的向量、矩阵等相对应如下表所示。
+
+
+Dimentions | Math entity |
+ :----: | :----:
+1 | vector
+2 | matrix
+3 | 3-tensor
+n | n-tensor
+
+#### 声明tensor对象
+
+`Tensor`接受三个模板参数:
+
+
+```c++
+ template<typename TargetType, DataType datatype, typename LayOutType = NCHW>
+ class Tensor .../* Inherit other class */{
+  //some implements
+  ...
+ };
+```
+
+TargetType是平台类型，如X86，GPU等等，在Anakin内部有相应的标识与之对应；datatype是普通的数据类型，在Anakin内部也有相应的标志与之对应；[LayOutType](#layout)是数据分布类型，如batch x channel x height x width [NxCxHxW], 在Anakin内部用一个struct来标识。 Anakin中数据类型与基本数据类型的对应如下:
+
+1. <span id='target'>TargetType</sapn>
+
+ Anakin TargetType | platform
+  :----: | :----:|
+  NV | NVIDIA GPU
+  ARM | ARM
+  AMD | AMD GPU
+  X86 | X86
+  NVHX86 | NVIDIA GPU with Pinned Memory
+
+2. <sapn id='datatype'>DataType</span>
+
+Anakin DataType | C++ | Description 
+:---: | :---: | :---: |
+AK_HALF | short | fp16
+AK_FLOAT | float | fp32
+AK_DOUBLE | double | fp64
+AK_INT8 | char | int8
+AK_INT16 | short | int16
+AK_INT32 | int | int32
+AK_INT64 | long | int64
+AK_UINT8 | unsigned char | uint8
+AK_UINT16 | unsigned short | uint8
+AK_UINT32 | unsigned int | uint32
+AK_STRING | std::string | /
+AK_BOOL | bool | /
+AK_SHAPE | / | Anakin Shape 
+AK_TENSOR | / | Anakin Tensor 
+
+
+3. <span id = 'layout'>LayOutType </span>
+
+Anakin LayOutType ( Tensor LayOut ) | Tensor Dimention | Tensor Support | Op Support
+:---: | :---: | :---: | :---: |
+W | 1-D | YES | NO
+HW | 2-D | YES | NO
+WH | 2-D | YES | NO
+NW | 2-D | YES | YES
+NHW | 3-D | YES |YES
+NCHW ( default ) | 4-D | YES | YES
+NHWC | 4-D | YES | NO
+NCHW_C4 | 5-D | YES | YES
+
+
+理论上，Anakin支持申明1维以上的tensor，但是对于Anakin中的Op来说，只支持NW、NHW、NCHW、NCHW_C4这四种LayOut，其中NCHW是默认的LayOutType，NCHW_C4是专门针对于int8这种数据类型的。
+
+
+例子
+
+> 下面的代码将展示如何使用tensor， 我们建议先看看这些示例。
+
+> 要想获得更多关于tensor的信息， 请参考 *soure_path/core/tensor.h*
+
+> 1. 使用shape对象初始化tensor
+``` c++  
+  //create a null tensor. A null tensor holds for nothing.
+  //tensor's buffer  is resident at CPU and its datatype is AK_FLOAT.
+  //tensor's Layout is NCHW(default)
+   Tensor<X86, AK_FLOAT> mytensor;
+
+   //1. using shape object to create a tensor.
+   Shape shape1(NUM); //1-D shape. NUM is the number of dimention.
+   Tensor<X86, AK_FLOAT, W> mytensor1(shape1); //1-D tensor.
+
+  // A 4-D shape
+   Shape shape2(N, C, H, W); // batch x channel x height x width
+```
+
+>`注意：Shape的维度必须和tensor的`[LayoutType](#layout)`相同，比如Shape(N,C,H,W), 那么Tensor的 LayoutType必须是NCHW，否则会出错。如下列代码所示`  
+
+
+```c++
+   // A 4-D tensor.
+   Tensor<X86, AK_FLOAT> mytensor2(shape2);  //right
+
+   //A 4-D tensor which is resident at GPU and its datatype is AK_INT8
+   Tensor<NV, AK_INT8> mytensor3(shape2);   //right
+   
+   Tensor<X86, AK_FLOAT, NHW> mytensor4(shape2); //wrong!! shape's dimetion must be equal to tensor's Layout.
+   Tensor<NV, AK_FLOAT, NCHW_C4> mytensor5(shape2); //wrong!!!!
+
+```
+
+> 2. 使用现有的数据和shape初始化tensor
+
+```c++
+
+   /**
+   *  A construtor of Tensor.
+   *  data_ptr is a pointer to any data type of data
+   *  TargetType is type of a platform [Anakin TargetType]
+   *  id : device id
+   *  shape: a Anakin shape
+   */
+   Tensor(Dtype* data_ptr, TargetType_t target, int id, Shape shape);
+
+   //using existing data feed to a tensor
+   Tensor<X86, AK_FLOAT> mytensor(data_ptr, TargetType, device_id, shape); //shape must has dimention (N, C, H, W).
+
+```
+
+> 3. 使用tensor初始化tensor
+
+```c++
+   Tensor<NV, AK_FLOAT> tensor(exist_tensor);
+```
+
+
+> 提示： 你可以用` typedef Tensor<X86, AK_FLOAT> Tensor4d_X86 `方便定义tensor
+
+
+#### 填充tensor数据区
+
+
+填充数据区得看你申明tensor的方式， 下面展示了如何填充tensor的数据区。
+
+```c++
+首先来看看tensor的四种声明方式：
+
+1. Tensor<X86, AK_FLOAT> mytensor;
+2. Tensor<X86, AK_FLOAT, W> mytensor1(shape1);
+3. Tensor<X86, AK_FLOAT> mytensor(data_ptr, TargetType, device_id, shape);
+4. Tensor<NV, AK_FLOAT> tensor(exist_tensor);
+
+
+相关的声明方式的数据填充方法如下：
+
+1：声明一个空的tensor，此时没有为其分配内存，所以，我们需要手动的为其分配内存。
+            
+            //parama shape
+            mytensor.re_alloc(Shape shape); 
+
+            //Get writable pointer to mytensor.
+            //parama index (int): where you start to write.
+            //Dtype is your data type such int, float or double.
+            Dtype *p = mytensor.mutable_data(index/*=0*/);
+            //write data to mytensor
+            for(int i = 0; i < mytensor.size(); i++){
+              p[i] = 1.0f;
+            }
+            //do something ...
+
+2: 这种声明方式会自动分配内存 
+
+          //Get writable pointer to mytensor.
+          //parama index (int): where you start to write.
+          //Dtype is your data type such int, float or double.
+          Dtype *p = mytensor1.mutable_data(index/*=0*/);
+          //write data to mytensor
+          for(int i = 0; i < mytensor.size(); i++){
+            p[i] = 1.0f;
+          }
+          //do something ...
+
+ 
+3：在该种声明方式中，我们仍不需要手动为其分配内存。但在构造函数内部是否为其分配内存，得依情况而定。如果data_ptr和申明的
+tensor都在都一个目标平台上，那么该tensor就会与data_ptr共享内存空间，相反，如果他们不在同一个平台上（如data_ptr在X86上，而
+tensor在GPU上），那么此时tensor就会开辟一个新的内存空间，并将data_ptr所指向的数据拷贝到tensor的buffer中。
+
+          //Get writable pointer to mytensor.
+          //parama index (int): where you start to write.
+          //Dtype is your data type such int, float or double.
+          Dtype *p = mytensor.mutable_data(index/*=0*/);
+          //write data to mytensor
+          for(int i = 0; i < mytensor.size(); i++){
+            p[i] = 1.0f;
+          }
+          //do something ...
+
+4：该种方式仍不需要手动分配内存
+
+          //Get writable pointer to mytensor.
+          //parama index (int): where you start to write.
+          //Dtype is your data type such int, float or double.
+          Dtype *p = mytensor.mutable_data(index/*=0*/);
+          //write data to mytensor
+          for(int i = 0; i < mytensor.size(); i++){
+            p[i] = 1.0f;
+          }
+          //do something ...
+
+
+另外，你还可以获取一个tensor的可读指针，示例如下：
+        //Get read-only pointer to mytensor.
+        //parama index (int): where you start to read.
+        //Dtype is your data type such int, float or double.
+         Dtype *p = mytensor.data(index/*=0*/);
+        //do something ...
+```
+
+如果想更详细的了解tensor，请查阅*soure_path/saber/core/tensor.h*
+
+#### 获取tensor的shape
+
+```c++
+//some declarations
+// ...
+Shape shape = mytensor.shape();
+
+//Get a first dimetion size of tesor, if it has.
+int d1 = shape[0];
+
+//Get a second dimention size of tensor, if it has.
+int d2 = shape[1];
+
+...
+
+//Get a n-th dimention size of tensor, if it has.
+int dn = shape[n-1];
+
+
+//Get a tensor's dimention
+int dims = mytensor.dims();
+
+//Get the size of tensor.
+//size = d1 x d2 x ... x dn.
+int size = mytensor.size();
+
+//Get the size of tensor at interval [Di, Dj)
+// form i-th dimention to j-th dimention, but not including the j-th dimention.
+// which means di x (di+1) x ... x (dj -1)
+int size = mytensor.count(start, end);
+```
+
+#### 设置tensor的shape
+
+我们可以用tensor的成员函数set_shape来设置tensor的shape。 下面是set_shape的定义
+
+
+```c++
+/**
+ * \brief set a tensor's shape
+ * \param valid_shape [a Shape object]
+ * \param shape [a Shape object]
+ * \param offset [a Shape object]
+ * \return the status of this operation, that means whether it success * or not.
+ */
+SaberStatus set_shape(Shape valid_shape, Shape shape = Shape::zero(TensorAPI::layout_dims::value), Shape offset = Shape::minusone(TensorAPI::layout_dims::value)); 
+```
+
+这个成员函数只设置tensor的shape。这些shape对象(valid_shape, shape, offset)的[LayOutType](#layout)必须和当前的tensor的相应三个shape对象的LayOutType相同，如果不同就会出错，返回SaberInvalidValue。 如果相同，那么将成功设置tensor的shape。
+
+```c++
+
+// some declarations
+// ...
+//valid_shape, shape , offset are Shape object;
+//All these Shape object's LayOutType must be equal to mytensor's.
+mytensor.set_shape(valid_shape, shape, offset);
+
+```
+
+#### 重置 tensor的shape
+
+```c++
+//some declarations
+Shape shape, valid_shape, offset;
+
+//do some initializations
+... 
+mytensor.reshape(valid_shape, shape, offset);
+```
+
+注意： Reshape操作仍然需要shape的[LayOutType](#layout) 与tensor的相同
+
+
+### Graph ###
+
+`Graph`类负责加载Anakin模型生成计算图、对图进行优化、存储模型等操作。
+
+#### 图的声明
+
+与`Tensor`一样，graph也接受三个模板参数。
+
+```c++
+
+template<typename TargetType, DataType Dtype, Precision Ptype>
+class Graph ... /* inherit other class*/{
+  
+  //some implements
+  ...
+
+};
+```
+
+前面已经介绍过[TargetType](#target)和[DataType](#datatype)是Anakin内部自定义数据类型。[TargetType](#target)表示平台类型 (如NV、X86), [DataType](#datatype)是Anakin基本数据类型与C++/C中的基本数据类型相对应。 [Precision](#precision)为op所支持的精度类型, 稍后我们在介绍它。
+
+
+```c++
+
+//Create a empty graph object.
+Graph graph = Graph<NV, AK_FLOAT, Precision::FP32> tmp();
+
+//Create a pointer to a empty graph.
+Graph *graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+
+//Create a pointer to a empty graph.
+auto graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+
+```
+
+#### 加载 Anakin 模型
+
+```c++
+//some declarations
+...
+auto graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+std::string model_path = "the/path/to/where/your/models/are";
+const char *model_path1 = "the/path/to/where/your/models/are";
+
+//Loading Anakin model to generate a compute graph.
+auto status = graph->load(model_path);
+
+//Or this way.
+auto status = graph->load(model_path1);
+//Check whether load operation success.
+if(!status){
+  std::cout << "error" << endl;
+  //do something...
+}
+
+```
+
+#### 优化计算图
+
+```c++
+//some declarations
+...
+//Load graph.
+...
+//According to the ops of loaded graph, optimize compute graph.
+graph->Optimize();
+
+```
+
+> 注意： 第一次加载原始图，必须要优化。
+
+#### 保存模型
+
+你可以在任何时候保存模型， 特别的， 你可以保存一个优化的模型，这样，下次再加载模型时，就不必进行优化操作。
+
+
+```c++
+//some declarations
+...
+//Load graph.
+...
+// save a model
+//save_model_path: the path to where your model is.
+auto status = graph->save(save_model_path);
+
+//Checking
+if(!status){
+  cout << "error" << endl;
+  //do somethin...
+}
+```
+
+#### 重新设置计算图里的tensor的shape
+
+```c++
+//some declarations
+...
+//Load graph.
+...
+vector<int> shape{10, 256, 256, 10};
+//input_name : std::string.
+//Reshape a tensor named input_name.
+graph->Reshape(input_name, shape);//Note: shape is a vector, not a Shape object.
+```
+
+#### 设置 batch size
+
+`Graph` 支持重新设置batch size的大小。
+
+```c++
+//some declarations
+...
+//Load graph.
+...
+//input_name : std::string.
+//Reset a tensor named input_name.
+int new_batch_size = 4;
+graph->ResetBatchSize(input_name, new_batch_size);
+```
+
+###  Net ###
+
+
+`Net` 是计算图的执行器。你可以通过Net对象获得输入和输出
+#### Creating a graph executor
+
+`Net`接受四个模板参数。  
+
+
+```c++
+template<typename TargetType, DataType Dtype, Precision PType OpRunType RunType = OpRunType::ASYNC>
+class Net{
+  //some implements
+  ...
+
+};
+```
+由于有些Op可能支持多种精度，我们可以通过Precision来指定。OpRunType表示同步或异步类型，异步是默认类型。OpRunType::SYNC表示同步，在GPU上只有单个流；OpRunType::ASYNC表示异步，在GPU上有多个流并以异步方式执行。实际上，Precision和OpRunType都是enum class, 详细设计请参考*source_root/framework/core/types.h*.
+
+
+1. <span id = 'precision'> Precision </span>
+
+Precision | Op support
+:---: | :---:
+Precision::INT4 | NO
+Precision::INT8 | NO
+Precision::FP16 | NO
+Precision::FP32 | YES
+Precision::FP64 | NO
+
+现在Op的精度只支持FP32， 但在将来我们会支持剩下的Precision.
+
+
+
+2. OpRunType
+
+OpRunType | Sync/Aync |Description
+:---: | :---: | :---:
+OpRunType::SYNC | Synchronization | single-stream on GPU
+OpRunType::ASYNC | Asynchronization | multi-stream on GPU
+
+用graph对象创建一个执行器。
+```c++
+//some declarations
+...
+//Create a pointer to a graph.
+auto graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+//do something...
+...
+
+//create a executor
+Net<NV, AK_FLOAT, Precision::FP32> executor(*graph);
+
+```
+
+#### 获取输入输出tensor
+
+
+获取输入输出tensor，并填充输入tensor的buffer。如果想要获取输入和输出tensor，那么必须指定输入的名字，如"input_0", "input_1", "input_2", ..., 必须传入如上字符串才能够获得输入tensor。另外，如果想知道input_i对应哪个输入，你需要去dash board查看，如何使用dash board请看[Anakin Parser](Converter_ch.md)。请看如下示例代码
+
+```c++
+//some declaratinos
+...
+
+//create a executor
+//TargetType is NV [NVIDIA GPU]
+Net<NV, AK_FLOAT, Precision::FP32> executor(*graph);
+
+//Get the first input tensor.
+//The following tensors(tensor_in0, tensor_in2 ...) are resident at GPU.
+//Note: Member function get_in returns an pointer to tensor.
+Tensor<NV, AK_FLOAT>* tensor_in0 = executor.get_in("input_0");
+
+//If you have multiple input tensors
+//You just type this code below.
+Tensor<NV, AK_FLOAT>* tensor_in1 = executor.get_in("input_1");
+...
+auto tensor_inn = executor.get_in("input_n");
+```
+
+当得到输入tensor之后，就可以填充它的数据区了。
+
+```c++
+//This tensor is resident at GPU.
+auto tensor_d_in = executor.get_in("input_0");
+
+//If we want to feed above tensor, we must feed the tensor which is resident at host. And then copy the host tensor to the device's one.
+
+//using Tensor4d = Tensor<Ttype, Dtype>;
+Tensor4d<X86, AK_FLOAT> tensor_h_in; //host tensor;
+//Tensor<X86, AK_FLOAT> tensor_h_in; 
+
+//Allocate memory for host tensor.
+tensor_h_in.re_alloc(tensor_d_in->valid_shape());
+//Get a writable pointer to tensor.
+float *h_data = tensor_h_in.mutable_data();
+
+//Feed your tensor.
+/** example
+for(int i = 0; i < tensor_h_in.size(); i++){
+  h_data[i] = 1.0f;
+}
+*/
+//Copy host tensor's data to device tensor.
+tensor_d_in->copy_from(tensor_h_in);
+
+// And then
+```
+
+
+类似的，我们可以利用成员函数get_out来获得输出tensor。但与获得输入tensor不同的是， 我们需要指定输入tensor结点的名字，这个可以从dash board中看到，请从[Anakin Parser](Converter_ch.md)中查看dash board的使用方法。假如有个输出结点叫pred_out, 那么我们可以通过如下代码获得相应的输出tensor：
+```c++
+//Note: this tensor are resident at GPU.
+Tensor<NV, AK_FLOAT>* tensor_out_d = executor.get_out("pred_out");
+
+```
+
+
+#### Executing graph
+
+
+当一切准备就绪后，我们就可以执行真正的计算了！
+```c++
+executor.prediction();
+```
+ 
+## <span id='example'> 示例代码 </span> ##
+
+下面的例子展示了如何调用Anakin。
+
+在这儿之前， 请确保你已经有了Anakin模型。如果还没有，那么请使用[Anakin Parser](Converter_ch.md)转换你的模型。
+
+### Single-thread
+
+单线程例子在 *`source_root/test/framework/net/net_exec_test.cpp`*
+
+```c++
+
+std::string model_path = "your_Anakin_models/xxxxx.anakin.bin";
+// Create an empty graph object.
+auto graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+// Load Anakin model.
+auto status = graph->load(model_path);
+if(!status ) {
+    LOG(FATAL) << " [ERROR] " << status.info();
+}
+// Reshape
+graph->Reshape("input_0", {10, 384, 960, 10});
+// You must optimize graph for the first time.
+graph->Optimize();
+// Create a executer.
+Net<NV, AK_FLOAT, Precision::FP32> net_executer(*graph);
+
+//Get your input tensors through some specific string such as "input_0", "input_1", and 
+//so on. 
+//And then, feed the input tensor.
+//If you don't know Which input do these specific string ("input_0", "input_1") correspond with, you can launch dash board to find out.
+auto d_tensor_in_p = net_executer.get_in("input_0");
+Tensor4d<X86, AK_FLOAT> h_tensor_in;
+auto valid_shape_in = d_tensor_in_p->valid_shape();
+for (int i=0; i<valid_shape_in.size(); i++) {
+    LOG(INFO) << "detect input dims[" << i << "]" << valid_shape_in[i]; //see tensor's dimentions
+}
+h_tensor_in.re_alloc(valid_shape_in);
+float* h_data = h_tensor_in.mutable_data();
+for (int i=0; i<h_tensor_in.size(); i++) {
+    h_data[i] = 1.0f;
+}
+d_tensor_in_p->copy_from(h_tensor_in);
+
+//Do inference.
+net_executer.prediction();
+
+//Get result tensor through the name of output node.
+//And also, you need to see the dash board again to find out how many output nodes are and remember their name.
+
+//For example, you've got a output node named obj_pre_out
+//Then, you can get an output tensor.
+auto d_tensor_out_0_p = net_executer.get_out("obj_pred_out"); //get_out returns a pointer to output tensor.
+auto d_tensor_out_1_p = net_executer.get_out("lc_pred_out"); //get_out returns a pointer to output tensor.
+//......
+// do something else ...
+//...
+//save model.
+//You might not optimize the graph when you load the saved model again.
+std::string save_model_path = model_path + std::string(".saved");
+auto status = graph->save(save_model_path);
+if (!status ) {
+    LOG(FATAL) << " [ERROR] " << status.info();
+}
+
+```
diff --git a/docs/Manual/Contribution_ch.md b/docs/Manual/Contribution_ch.md
new file mode 100644
index 0000000..f669587
--- /dev/null
+++ b/docs/Manual/Contribution_ch.md
@@ -0,0 +1,128 @@
+# 如何贡献代码
+
+我们真诚地感谢您的贡献，欢迎通过 GitHub 的 fork 和 pull request 流程来提交代码。
+
+## 代码要求
+
+- 代码注释请遵守[Doxygen](http://www.stack.nl/~dimitri/doxygen/)的样式
+- 所有代码必须具有单元测试
+- 通过所有单元测试
+- 请遵守提交代码的一些约定
+
+以下教程将指导您提交代码
+
+## Fork
+首先跳转到[Anakin](https://github.com/PaddlePaddle/Anakin)的github首页，然后点击`Fork`, 生成自己目录下的仓库
+
+## 克隆（clone）
+
+将远程仓库clone到本地：
+
+```bash
+git clone YOUR_REPOSITORY_URL
+cd Anakin
+```
+
+## 创建本地分支
+Anakin目前使用[Git流分支模型](https://nvie.com/posts/a-successful-git-branching-model/)进行开发, 测试和维护。  
+所有的feature和bug fix的开发工作都应该在一个新的分支上完成，根据需要从现有分支上创建新分支。  
+使用`git checkout -b`创建并切换到新分支
+```bash
+git checkout -b YOUR_NEW_BRANCH
+```
+
+## 开始开发
+
+编写代码
+
+
+## 构建和测试
+
+详细请参考[Docker installation guide](docker/README.md) 和 [build from source guide](docs/Manual/INSTALL_en.md)。
+
+
+## 提交（commit）
+
+提交代码时，请认真写好提交说明，这样其他人就可以清楚的知道这次提交做了哪些改变：
+```bash
+git commit -m 'description'
+```
+
+## 保持本地仓库最新
+
+在发起Pull Request之前，需要与原始仓库同步。
+
+如果还没添加原仓库，请先添加源，可通过`git remote -v`查看是否添加源：
+```bash
+git remote -v
+origin .... (fetch)
+origin .... (push)
+```
+如果只出现origin，说明还未添加源，可通过如下命令添加源：
+```bash
+git remote add upstream ORIGIN_REPOSITORY_URL
+```
+获取 upstream 的最新代码并更新当前分支
+```bash
+git fetch upstream
+git pull upstream BRANCH_NAME
+```
+## Push到远程仓库
+
+将本地的修改push到远程仓库上
+```bash
+git push origin BRANCH_NAME
+```
+
+## 提交Pull Request
+
+切换到所建分支，然后点击`New pull request`。  
+![](./contri1.JPG)
+
+选择目标分支：  
+![](./contri2.JPG)
+
+接下来等待review。
+
+## 删除远程分支
+在PR被merge进主仓库后，可以在PR的界面删除远程仓库的分支。  
+也可以通过以下命令删除远程分支：
+```bash
+git push origin :YOUR_NEW_BRANCH
+```
+
+## 删除本地分支
+
+最后，删除本地分支。
+```bash
+#切换到其他分支
+git checkout OTHER_BRANCH
+
+#删除YOUR_NEW_BRANCH分支
+git branch -D YOUR_NEW_BRANCH
+```
+
+至此，我们就完成了一次代码贡献的过程。
+
+## 提交代码的一些约定
+
+为了使评审人在评审代码时更好地专注于代码本身，请您每次提交代码时，遵守以下约定：
+
+1. 提交Pull Request前：  
+- 注意commit的数量
+
+  - 原因：如果仅仅修改一个文件但提交了十几个commit，每个commit只做了少量的修改，这会给评审人带来很大困扰。评审人需要逐一查看每个commit才能知道做了哪些修改，且不排除commit之间的修改存在相互覆盖的情况。
+
+  - 建议：每次提交时，保持尽量少的commit，可以通过`git commit --amend`补充上次的commit。对已经Push到远程仓库的多个commit，可以参考[squash commits after push](https://stackoverflow.com/questions/5667884/how-to-squash-commits-in-git-after-they-have-been-pushed)
+  
+- 注意每个commit的名称：应能反映当前commit的内容，不能太随意。
+
+2. 如果解决了某个Issue的问题，请在该Pull Request的第一个评论框中加上：`fix #issue_number`，这样当该Pull Request被合并后，会自动关闭对应的Issue。关键词包括：close, closes, closed, fix, fixes, fixed, resolve, resolves, resolved，请选择合适的词汇。详细可参考[Closing issues via commit messages](https://help.github.com/articles/closing-issues-via-commit-messages)。
+
+在回复评审人意见时，请您遵守以下约定：  
+1. 评审人的每个意见都必须回复
+   - 对评审意见同意且按其修改完的，给个简单的Done即可
+   - 对评审意见不同意的，请给出您自己的反驳理由。
+2. 如果评审意见比较多
+   - 请给出总体的修改情况。
+   - 请采用[start a review](https://help.github.com/articles/reviewing-proposed-changes-in-a-pull-request/)进行回复，而非直接回复的方式。
\ No newline at end of file
diff --git a/docs/Manual/Converter_ch.md b/docs/Manual/Converter_ch.md
index d137ba2..56ca582 100644
--- a/docs/Manual/Converter_ch.md
+++ b/docs/Manual/Converter_ch.md
@@ -1,77 +1,73 @@
-# External Converter
+# 模型转换指南
 
-This guide will show you how to convert your models to Anakin models.
+Anakin 支持不同框架的模型预测。但由于格式的差别，Anakin 需要您预先转换模型。本文档介绍如何转换模型。
 
-## Introduction
+## 简介
 
-Before using Anakin, you must convert your models to Anakin ones. If you don't, Anakin won't work properly.
+Anakin 模型转换器输入支持 Caffe 和 Fluid 两种格式的预测模型，模型包含网络结构（model 或 prototxt）和权重参数（param 或 caffemodel）。   
 
-## Requirements
+模型转换的输出是一个 bin 文件，它作为 Anakin 框架的 graph 参数导入。   
+
+您还可以使用模型转换器的 launch board 功能生成网络结构的 HTML 预览。   
+
+
+## 系统要求
 
 - python 2.7+
 - pyyaml
 - flask
+- protobuf 3.5+
 
-## Downloading Converter Source
 
-```bash
-git clone https://xxxxxxxxx
-``` 
+## 用法
+
+### 1、环境
+转换器所需的依赖标注于 *系统要求* 一节。
 
-## Usage
+### 2、配置
+您需要对 *config.yaml* 文件进行修改以告知您的需求。工程中给出了 *config.yaml* 示例，下面作进一步说明。
 
-### 1. Configuration
-Configure your *config.yaml* file. Find example *config.yaml* file in the `converter source` directory. The example below explains how to configure your config.yaml file.
-#### Caffe Case
+#### config.yaml
 ```bash
 OPTIONS:
-    Framework: CAFFE # select a target dl-framework you want parsing
-    SavePath: ./output
-    ResultName: googlenet # the name you want when saving the parsed model
+    Framework: CAFFE       # 依框架类型填写 CAFFE 或 FLUID
+    SavePath: ./output     # 转换结束后模型的保存位置
+    ResultName: googlenet  # 输出模型的名字
     Config:
-        LaunchBoard: ON  # should be on if you want to launch graph board
+        LaunchBoard: ON    # 是否生成网络结构预览页面
         Server:
             ip: 0.0.0.0
-            port: 8888
-        OptimizedGraph:  # only enable(set enable(ON) and path) when you have optimized graph model.
-            enable: ON
+            port: 8888     # 从一个可用端口访问预览页面
+        OptimizedGraph:    # 当您使用了 Anakin 框架的 Optimized 功能时，才应该打开此项
+            enable: OFF
             path: /path/to/anakin_optimized_anakin_model/googlenet.anakin.bin.saved
     LOGGER:
-        LogToPath: ./log/ # the path where log
-        WithColor: ON  # colorful log message
+        LogToPath: ./log/  # 生成日志的路径
+        WithColor: ON
 
 TARGET:
     CAFFE:
-        # path to proto files
+        # 当 Framework 为 CAFFE 时需填写
         ProtoPaths:
             - /path/to/caffe/src/caffe/proto/caffe.proto
         PrototxtPath: /path/to/your/googlenet.prototxt
         ModelPath: /path/to/your/googlenet.caffemodel
-   
-	# not support yet 
-    PADDLE:
-        # path to proto files   
-        ProtoPath:
-            - /path/to/proto_0
-            - /path/to/proto_1
-            - /path/to/proto_n
-        PrototxtPath: /path/to/prototxt
-        ModelPath: /path/to/model
-	# ... 
-```
-
-### 2. Converting 
-After finishing configuration , you just need to call python script ```python converter.py```  to complete transfromation.
-
-### 3. Launching dash board
-Anakin external converter will be launched on site http://0.0.0.0:8888 (configurable).
-Then open you browser and search http://0.0.0.0:8888, amazing things will happen!
-
-> if you set ip to 0.0.0.0 in remote server, you need to open local browser and search the server real ip:port, not the 0.0.0.0.
 
+    FLUID:
+        # 当 Framework 为 FLUID 时需填写
+        Debug: NULL
+        ProtoPaths:
+            - /
+        PrototxtPath: /path/to/fluid/inference_model
+        ModelPath: /path/to/fluid/inference_model
+	# ...
+```
 
-### 4. Note
+### 3、转换
+在完成配置文件的修改后，您只需执行 ```python converter.py``` 就可以进行模型转换了。
 
-> 1.We support caffe so far
 
+### 4、预览
+最后一步，就是在浏览器中查看令人振奋的转换结果！网址是在 *config.yaml* 中配置的，例如 http://0.0.0.0:8888 。
 
+> 注意：若您使用了默认的 IP 地址 0.0.0.0，请在预览时使用真实的服务器地址 real_ip:port 替代它。
diff --git a/docs/Manual/Converter_en.md b/docs/Manual/Converter_en.md
index d137ba2..4262726 100644
--- a/docs/Manual/Converter_en.md
+++ b/docs/Manual/Converter_en.md
@@ -16,7 +16,7 @@ Before using Anakin, you must convert your models to Anakin ones. If you don't,
 
 ```bash
 git clone https://xxxxxxxxx
-``` 
+```
 
 ## Usage
 
@@ -47,9 +47,8 @@ TARGET:
             - /path/to/caffe/src/caffe/proto/caffe.proto
         PrototxtPath: /path/to/your/googlenet.prototxt
         ModelPath: /path/to/your/googlenet.caffemodel
-   
-	# not support yet 
-    PADDLE:
+
+    FLUID:
         # path to proto files   
         ProtoPath:
             - /path/to/proto_0
@@ -57,10 +56,10 @@ TARGET:
             - /path/to/proto_n
         PrototxtPath: /path/to/prototxt
         ModelPath: /path/to/model
-	# ... 
+	# ...
 ```
 
-### 2. Converting 
+### 2. Converting
 After finishing configuration , you just need to call python script ```python converter.py```  to complete transfromation.
 
 ### 3. Launching dash board
@@ -73,5 +72,3 @@ Then open you browser and search http://0.0.0.0:8888, amazing things will happen
 ### 4. Note
 
 > 1.We support caffe so far
-
-
diff --git a/docs/Manual/INSTALL_ch.md b/docs/Manual/INSTALL_ch.md
index 8339769..bc628db 100644
--- a/docs/Manual/INSTALL_ch.md
+++ b/docs/Manual/INSTALL_ch.md
@@ -6,7 +6,7 @@
 
 * [在CentOS上安装 Anakin]()
 * [在Ubuntu上安装 Anakin]()
-* [在ARM上安装 Anakin]()
+* [在ARM上安装 Anakin](run_on_arm_ch.md)
 * [验证安装]()
 
 
diff --git a/docs/Manual/INSTALL_en.md b/docs/Manual/INSTALL_en.md
index 506e80b..852b184 100644
--- a/docs/Manual/INSTALL_en.md
+++ b/docs/Manual/INSTALL_en.md
@@ -6,7 +6,7 @@ We've built and tested Anakin on CentOS 7.3. The other operating systems install
 
 * [Installing on CentOS](#0001)
 * [Installing on Ubuntu](#0002)
-* [Installing on ARM](#0003)
+* [Installing on ARM](run_on_arm_en.md)
 * [Verifying installation](#0004)
 
 
diff --git a/docs/Manual/addCustomDevice.md b/docs/Manual/addCustomDevice.md
new file mode 100644
index 0000000..0c8c7fd
--- /dev/null
+++ b/docs/Manual/addCustomDevice.md
@@ -0,0 +1,459 @@
+# 如何支持一个新的设备
+
+## 概览
+
+添加一个新的设备需要以下3个步骤：
+
+* [在`CMakeList`中添加设备的支持](#0001)
+* [在`saber`中添加设备的实现](#0002)
+* [在`framework`中添加设备的具体化或实例化](#0003)
+
+假设新设备的名称为`TNEW`, 以下将以这个设备名称进行演示。
+
+## <span id = '0001'> 在`CMakeList`中添加设备的支持 </span> ##
+
+* 修改根目录`CMakeList.txt`
+```cmake
+#select the plantform to build
+anakin_option(USE_GPU_PLACE "Select the build mode for GPU place." NO)
+anakin_option(USE_X86_PLACE "Select the build mode for X86 place." NO)
+anakin_option(USE_ARM_PLACE "Select the build mode for ARM place." NO)
+anakin_option(USE_TNEW_PLACE "Select the build mode for ARM place." YES)
+```
+
+* 修改`saber/CMakeList.txt`
+
+根据新增设备的目录完善`saber`目录下的`CMakeList.txt`。
+```cmake
+if(USE_TNEW_PLACE)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core/impl/tnew "cpp" ANAKIN_SABER_BASE_SRC)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/tnew "cpp" ANAKIN_SABER_BASE_SRC)
+endif()
+```
+
+* 修改`test/CMakeList.txt`
+
+新增设备的单测文件放在`test/saber/tnew`目录下，修改`test`目录下的`CMakeList.txt`。
+```cmake
+if(USE_TNEW_PLACE)
+    anakin_fetch_files_with_suffix(${ANAKIN_UNIT_TEST}/saber/tnew "cpp" ANAKIN_TEST_CASE_SRC)
+endif()
+```
+
+* 修改`cmake/anakin_config.h.in`
+```c++
+// plantform to use
+#cmakedefine USE_GPU_PLACE
+
+#cmakedefine USE_X86_PLACE
+
+#cmakedefine USE_ARM_PLACE
+
+#cmakedefine USE_TNEW_PLACE
+```
+
+* 其他依赖和编译选项    
+修改`cmake`目录下的`compiler_options.cmake`和`find_modules.cmake`
+
+
+## <span id = '0002'> 在`saber`中添加设备的实现 </span> ##
+`saber`是`Anakin`的基础计算库，对外提供设备无关的统一的API，设备相关的实现都会封装到`TargetWrapper`中。
+
+### 在`saber/saber_types.h`中添加设备
+
+```c++
+enum TargetTypeEnum {
+    eINVALID = -1,
+    eNV = 1,
+    eAMD = 2,
+    eARM = 3,
+    eX86 = 4,
+    eNVHX86 = 5,
+    eTNEW = 6
+};
+
+typedef TargetType<eNV> NV;
+typedef TargetType<eARM> ARM;
+typedef TargetType<eAMD> AMD;
+typedef TargetType<eX86> X86;
+typedef TargetType<eTNEW> TNEW;
+
+```
+
+### 在`saber/core`中添加设备的实现
+
+1. 在`target_traits.h`中添加新设备
+
+* 增加设备类型
+```c++
+struct __cuda_device{};
+struct __arm_device{};
+struct __amd_device{};
+struct __x86_device{};
+struct __tnew_device{};
+```
+
+* `TargetTypeTraits`模板具体化
+```c++
+template <>
+struct TargetTypeTraits<TNEW> {
+    typedef __xxx_target target_category;//根据实际设备是host端还是device端进行选择
+    typedef __tnew_device target_type;
+};
+```
+
+2. 在`data_traits.h`中特化`DataTrait`模板类
+
+如果设备需要特殊的数据类型，则特化出设备的`DataTrait`类的实现，例如opencl数据类型的实现如下：
+```c++
+#ifdef USE_OPENCL
+struct ClMem{
+    ClMem(){
+        dmem = nullptr;
+        offset = 0;
+    }
+
+    ClMem(cl_mem* mem_in, int offset_in = 0) {
+        dmem = mem_in;
+        offset = offset_in;
+    }
+
+    ClMem(ClMem& right) {
+        dmem = right.dmem;
+        offset = right.offset;
+    }
+
+    ClMem& operator=(ClMem& right) {
+        this->dmem = right.dmem;
+        this->offset = right.offset;
+        return *this;
+    }
+
+    ClMem& operator+(int offset_in) {
+        this->offset += offset_in;
+        return *this;
+    }
+
+    int offset{0};
+    cl_mem* dmem;
+};
+
+template <>
+struct DataTrait<AMD, AK_FLOAT> {
+    typedef ClMem Dtype;
+    typedef float dtype;
+};
+
+template <>
+struct DataTrait<AMD, AK_DOUBLE> {
+    typedef ClMem Dtype;
+    typedef double dtype;
+};
+
+template <>
+struct DataTrait<AMD, AK_INT8> {
+    typedef ClMem Dtype;
+    typedef char dtype;
+};
+#endif //use_opencl
+```
+
+3. 在`target_wrapper.h`中特化`TargetWrapper`模板类
+
+特化`TargetWrapper`模板类，在`target_wrapper.h`中声明函数，具体如下：
+```c++
+template <>
+struct TargetWrapper<TNEW, __xxx_target> { //根据TNEW的具体类型修改__xxx_target，__host_target或者__device_target
+
+    typedef xxx_event event_t;          //根据设备实现xxx_event
+    typedef xxx_stream stream_t;        //根据设备实现xxx_stream
+
+    static void get_device_count(int& count);
+
+    static void set_device(int id);
+
+    //We should add strategy to avoid malloc directly
+    static void mem_alloc(void** ptr, size_t n);
+
+    static void mem_free(void* ptr);
+
+    static void mem_set(void* ptr, int value, size_t n);
+
+    static void create_event(event_t& event, bool flag = false);
+
+    static void create_stream(stream_t& stream);
+
+    static void create_stream_with_flag(stream_t& stream, unsigned int flag);
+
+    static void create_stream_with_priority(stream_t& stream, unsigned int flag, int priority);
+
+    static void destroy_stream(stream_t& stream);
+
+    static void destroy_event(event_t& event);
+
+    static void record_event(event_t& event, stream_t stream);
+
+    static void query_event(event_t& event);
+
+    static void sync_event(event_t& event);
+
+    static void sync_stream(event_t& event, stream_t& stream);
+
+    static void sync_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                            size_t count, __DtoD);
+
+    static void async_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                             size_t count, stream_t& stream, __DtoD);
+
+    static void sync_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                            size_t count, __HtoD);
+
+    static void async_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                             size_t count, stream_t& stream, __HtoD);
+
+    static void sync_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                            size_t count, __DtoH);
+
+    static void async_memcpy(void* dst, int dst_id, const void* src, int src_id, \
+                             size_t count, stream_t& stream, __DtoH);
+
+    static void sync_memcpy_p2p(void* dst, int dst_dev, const void* src, \
+                                int src_dev, size_t count);
+
+    static void async_memcpy_p2p(void* dst, int dst_dev, const void* src, \
+                                 int src_dev, size_t count, stream_t& stream);
+
+    static int get_device_id();
+};
+
+```
+
+4. 在`impl/`目录下添加设备目录和实现
+
+在`saber/core/impl`目录下添加设备目录`tnew`。
+* 实现`TargetWrapper<TNEW, __xxx_target>`结构体中各函数的定义。    
+如果`TargetWrapper<TNEW, __xxx_target>`的实现与默认的模板类一致，则不用特化出该类。
+
+```c++
+typedef TargetWrapper<TNEW, __xxx_target> TNEW_API;
+void TNEW_API::get_device_count(int &count) {
+    // add implementation
+}
+
+void TNEW_API::set_device(int id){
+    // add implementation
+}
+        
+void TNEW_API::mem_alloc(void** ptr, size_t n){
+    // add implementation
+}
+        
+void TNEW_API::mem_free(void* ptr){
+    if(ptr != nullptr){
+        // add implementation
+    }
+}
+...
+
+```
+
+* 特化实现`device.h`中的`Device<TNEW>`
+
+```c++
+template <>
+void Device<TNEW>::create_stream() {
+    // add implementation
+}
+
+template <>
+void Device<TNEW>::get_info() {
+
+    // add implementation
+}
+
+```
+
+### 在`saber/funcs`中实现设备相关的op
+
+参考[如何增加新的Operator](addCustomOp.md)
+
+
+## <span id = '0003'> 在`framework`中添加设备的具体化或实例化 </span> ##
+
+### `framework/core`
+
+* `net.cpp`中添加实例化
+
+```c++
+#ifdef USE_TNEW_PLACE
+template class Net<TNEW, AK_FLOAT, Precision::FP32, OpRunType::ASYNC>;
+template class Net<TNEW, AK_FLOAT, Precision::FP32, OpRunType::SYNC>;
+#endif
+```
+
+* `operator_func.cpp`中添加实例化
+
+```c++
+#ifdef USE_TNEW_PLACE
+template class OperatorFunc<TNEW, AK_FLOAT, Precision::FP32>;
+#endif
+```
+
+* `worker.cpp`中添加实例化
+
+```c++
+#ifdef USE_TNEW_PLACE
+template class Worker<TNEW, AK_FLOAT, Precision::FP32, OpRunType::ASYNC>;
+template class Worker<TNEW, AK_FLOAT, Precision::FP32, OpRunType::SYNC>;
+#endif
+```
+
+* `operator_attr.cpp`中添加实例化
+
+```c++
+template
+OpAttrWarpper& OpAttrWarpper::__alias__<TNEW, AK_FLOAT, Precision::FP32>(const std::string& op_name);
+template
+OpAttrWarpper& OpAttrWarpper::__alias__<TNEW, AK_FLOAT, Precision::FP16>(const std::string& op_name);
+template
+OpAttrWarpper& OpAttrWarpper::__alias__<TNEW, AK_FLOAT, Precision::INT8>(const std::string& op_name);
+```
+
+* `parameter.h`中添加设备的实现
+
+```c++
+#ifdef USE_TNEW_PLACE
+template<typename Dtype>
+class PBlock<Dtype, TNEW> {
+public:
+	typedef Tensor4d<TNEW, DataTypeRecover<Dtype>::type> type;
+
+	PBlock() {
+		_inner_tensor = std::make_shared<type>(); 
+	}
+	...
+}
+#endif //TNEW
+```
+
+* `type_traits_extend.h`中添加设备的实现
+
+```c++
+template<>
+struct target_host<saber::TNEW> {
+    typedef saber::X86 type; //根据TNEW选择正确的host type
+};
+```
+
+### `framework/graph`
+
+* `graph.cpp`中添加实例化
+  
+```c++
+  #ifdef USE_TNEW_PLACE
+  template class Graph<TNEW, AK_FLOAT, Precision::FP32>;
+  template class Graph<TNEW, AK_FLOAT, Precision::FP16>;
+  template class Graph<TNEW, AK_FLOAT, Precision::INT8>;
+  #endif
+```
+
+### `framework/model_parser`
+
+* `parser.cpp`中添加实例化
+  
+```c++
+  #ifdef USE_TNEW_PLACE
+  template
+  Status load<TNEW, AK_FLOAT, Precision::FP32>(graph::Graph<TNEW, AK_FLOAT, Precision::FP32>* graph,
+          const char* model_path);
+  template
+  Status load<TNEW, AK_FLOAT, Precision::FP16>(graph::Graph<TNEW, AK_FLOAT, Precision::FP16>* graph,
+          const char* model_path);
+  template
+  Status load<TNEW, AK_FLOAT, Precision::INT8>(graph::Graph<TNEW, AK_FLOAT, Precision::INT8>* graph,
+          const char* model_path);
+  
+  template
+  Status save<TNEW, AK_FLOAT, Precision::FP32>(graph::Graph<TNEW, AK_FLOAT, Precision::FP32>* graph,
+          std::string& model_path);
+  template
+  Status save<TNEW, AK_FLOAT, Precision::FP16>(graph::Graph<TNEW, AK_FLOAT, Precision::FP16>* graph,
+          std::string& model_path);
+  template
+  Status save<TNEW, AK_FLOAT, Precision::INT8>(graph::Graph<TNEW, AK_FLOAT, Precision::INT8>* graph,
+          std::string& model_path);
+  
+  template
+  Status load<TNEW, AK_FLOAT, Precision::FP32>(graph::Graph<TNEW, AK_FLOAT, Precision::FP32>* graph,
+          std::string& model_path);
+  template
+  Status load<TNEW, AK_FLOAT, Precision::FP16>(graph::Graph<TNEW, AK_FLOAT, Precision::FP16>* graph,
+          std::string& model_path);
+  template
+  Status load<TNEW, AK_FLOAT, Precision::INT8>(graph::Graph<TNEW, AK_FLOAT, Precision::INT8>* graph,
+          std::string& model_path);
+  
+  template
+  Status save<TNEW, AK_FLOAT, Precision::FP32>(graph::Graph<TNEW, AK_FLOAT, Precision::FP32>* graph,
+          const char* model_path);
+  template
+  Status save<TNEW, AK_FLOAT, Precision::FP16>(graph::Graph<TNEW, AK_FLOAT, Precision::FP16>* graph,
+          const char* model_path);
+  template
+  Status save<TNEW, AK_FLOAT, Precision::INT8>(graph::Graph<TNEW, AK_FLOAT, Precision::INT8>* graph,
+          const char* model_path);
+  #endif
+```
+
+* `model_io.cpp`中添加实例化
+
+```c++
+#ifdef USE_TNEW_PLACE
+template class NodeIO<TNEW, AK_FLOAT, Precision::FP32>;
+template class NodeIO<TNEW, AK_FLOAT, Precision::FP16>;
+template class NodeIO<TNEW, AK_FLOAT, Precision::INT8>;
+#endif
+```
+
+### `framework/operators`
+
+为`framework/operators`目录下所有op添加实例化或具体化
+以`activation.cpp`为例，实例化如下：
+
+```c++
+#ifdef USE_TNEW_PLACE
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::FP32);
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::FP16);
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::INT8);
+template class ActivationHelper<TNEW, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Activation, ActivationHelper, TNEW, AK_FLOAT, Precision::FP32);
+#endif
+```
+
+如果TNEW设备函数的实现与现有模板实现不一致，可以特化实现如下（以init()为例）：
+```c++
+#ifdef USE_TNEW_PLACE
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::FP32);
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::FP16);
+INSTANCE_ACTIVATION(TNEW, AK_FLOAT, Precision::INT8);
+template <>
+Status ActivationHelper<TNEW, AK_FLOAT, Precision::FP32>::Init(OpContext<TNEW> &ctx,\
+        const std::vector<Tensor4dPtr<TNEW, AK_FLOAT> >& ins, \
+                std::vector<Tensor4dPtr<TNEW, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_activation.init(ins, outs, _param_activation, SPECIFY, SABER_IMPL, ctx)); //在这里选择实现方式
+    return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(Activation, ActivationHelper, TNEW, AK_FLOAT, Precision::FP32);
+#endif
+```
+
+在`ANAKIN_REGISTER_OP(Activation)`中添加TNEW的注册
+
+```c++
+#ifdef USE_TNEW_PLACE
+.__alias__<TNEW, AK_FLOAT, Precision::FP32>("activation")
+#endif
+```
+
+## 注意事项
+不要修改`Tensor`/`Buffer`/`Env`/`Context`这些类函数的接口和实现
\ No newline at end of file
diff --git a/docs/Manual/addCustomOp.md b/docs/Manual/addCustomOp.md
new file mode 100644
index 0000000..f2783eb
--- /dev/null
+++ b/docs/Manual/addCustomOp.md
@@ -0,0 +1,405 @@
+# 如何增加新的Operator
+
+## 基本概念
+
+简单介绍下几个同Operator相关的基本概念，详情请参考设计文档。
+
+```framework```: 上层的逻辑代码，负责从parser中获取参数及weights，添加op时主要修改framework/operator目录下的内容。
+
+```saber```: 底层的实现代码，Anakin通过saber封装了不同的backends，不同的实现(impl)分别特化出自己的实现，外层framework通过不同的template进入各自的impl完成调用。各个op的parameter放在saber/saber_funcs_param.h文件中，增加op主要修改saber/funcs下的内容。
+
+saber的文件结构：
+* saber/funcs下的是各个funcs的外部接口，这一层的op与具体的设备实现无关，只与各op完成的功能有关。由于跟实现(impl)无关，本层文件明均不带impl。
+* saber/funcs/impl下是各个op的impl声明，特定设备需要完成该层声明的特化版本，如saber/funcs/impl/x86实现了上一层impl声明的x86特化版本，saber/funcs/impl/cuda实现了上一层impl声明的NV特化版本。当增加新的backends时需要特化出新的实现。本层代码同实现相关，均带有```impl_```前缀。
+* saber/funcs/impl/cuda/base/cuda_c内有cuda```.cu```扩展名的文件，添加cuda的kernel需要在该文件目录下添加。
+* saber/funcs/impl/cuda/base/sass 内有不同架构的汇编代码编译的静态库。
+
+### 涉及到的基类及各个类之前的关系
+
+简单介绍相关的基类
+
+* ```anakin::Operator```: framework的operator基类，位于framework/core/operator/operator.h
+
+* ```anakin::saber::BaseFunc```: saber对外的op接口基类，提供统一的对外接口，位于saber/funcs/base.h。BaseFunc的```compute_output_shape```接口只根据input的shape和param的参数计算输出的shape，并通过```tensor```的```set_shape```接口(只设置shape，不分配空间)设置到output中。```operator()```接口为各个op的计算接口。
+
+* ```ankain::saber::ImplBase```: saber设备实现的op的接口，所有设备相关实现的基类。位于saber/funcs/impl/impl_base.h。实现版本中这里分为两类，一类以```vender_```为前缀，带有```vender_```代码意为使用第三方库来实现该op，如cudnn的conv，或mkl的conv等等，这类op的性能我们难以调优，因此单独列为一类。另一类是带有源码的saber实现，这些实现都带有```saber_```为前缀，此类实现带有源码，能够通过后续优化不断提升性能，实现起名时需要注意这一点。
+
+## 添加operator
+
+添加一个新的op需要以下几步：
+
+1. 添加saber的param
+2. 定义saber的Operator类
+3. 定义新的impl声明
+3. 完成新的impl实现
+4. 增加framework的实现或特化
+
+接下来就针对这几步，以一个简单例子为例介绍实现。
+
+例如我们要添加新的Mul op。给出计算公式如下：$$Out = alpha \dot X * Y$$
+
+### 为operator增加param
+
+涉及到的文件：```saber/saber_funcs_param.h```。如果之前已经存在需要添加的op的param，这一步可以跳过。
+这里```XXXParam```是一个```struct```。包含一个无参数的构造函数，含参数的构造函数，复制构造函数，```operator=()```及```operator==()```。
+```
+template <typename opTensor> // 能够获得target, datatype, layout
+struct MulParam{
+  MulParam()
+    : alpha(0)
+  {}
+  MulParam(float alpha_in)
+    : alpha(alpha_in)
+  {}
+  MulParam(const MulParam& right)
+    : alpha(right.alpha)
+  {}
+  MulParam &operator=(const MulParam &right) {
+    alpha = right.alpha;
+  }
+  bool operator==(const MulParam &right) {
+    return alpha == right.alpha;
+  }
+  float alpha;
+};
+```
+
+### 定义Operator类
+涉及到的文件:```saber/funcs/mul.h```。如果之前定义过该op的类，这里需要修改输入的impl定义头文件。
+下面给出一个相对完整的定义结构供参考。
+```
+//不同的设备需要包含对应的operator实现.[详见](#impl)
+#ifdef NVIDIA_GPU
+#include "saber/funcs/impl/cuda/saber_mul.h"
+#include "saber/funcs/impl/cuda/vender_mul.h"
+#endif
+//如果一个设备现在还没有对应的operator实现，需要包含声明。[详见](#declare)
+#ifdef USE_X86_PLACE
+#include "saber/funcs/impl/impl_mul.h"
+#endif
+namespace anakin {
+namespace saber {
+template<typename TargetType,
+        DataType OpDtype,
+        DataType inDtype = AK_FLOAT,
+        DataType outDtype = AK_FLOAT,
+        typename LayOutType_op = NCHW,
+        typename LayOutType_in = NCHW,
+        typename LayOutType_out = NCHW>
+class Mul : public BaseFunc<
+        Tensor<TargetType, inDtype, LayOutType_in>,
+        Tensor<TargetType, outDtype, LayOutType_out>,
+        Tensor<TargetType, OpDtype, LayOutType_op>,
+        ImplBase, MulParam> {
+public:
+    using BaseFunc<
+            Tensor<TargetType, inDtype, LayOutType_in>,
+            Tensor<TargetType, outDtype, LayOutType_out>,
+            Tensor<TargetType, OpDtype, LayOutType_op>,
+            ImplBase, MulParam>::BaseFunc;
+    Mul() = default;
+    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
+    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
+    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
+    typedef MulParam<OpTensor> Param_t;
+    typedef std::vector<InDataTensor *> Input_v;
+    typedef std::vector<OutDataTensor *> Output_v;
+    typedef std::vector<Shape> Shape_v;
+
+    virtual SaberStatus compute_output_shape(const Input_v &input,
+                                             Output_v &output, Param_t &param) override {
+        //计算输出的shape，
+        Shape output_shape = (input[0]->valid_shape());
+        /* code */
+        return output[0]->set_shape(output_shape);
+    }
+    virtual SaberStatus init_impl(ImplEnum implenum) override {
+      // 不同设备均使用此init_impl, 此接口创建对应impl的实现。
+      switch (implenum) {
+            case VENDER_IMPL:
+                this->_impl.push_back(new VenderMul <TargetType,
+                OpDtype, inDtype, outDtype,
+                LayOutType_op, LayOutType_in, LayOutType_out>);
+                return SaberSuccess;
+            case SABER_IMPL:
+                this->_impl.push_back(new SaberMul <TargetType,
+                OpDtype, inDtype, outDtype,
+                LayOutType_op, LayOutType_in, LayOutType_out>);
+                return SaberSuccess;
+            default:
+                return SaberUnImplError;
+        }
+    }
+private:
+    virtual void pick_best_static() override {
+        if (true) // some condition?
+            this->_best_impl = this->_impl[0];
+    }
+    virtual void pick_best_specify(ImplEnum implenum) override {
+        this->_best_impl = this->_impl[0];
+    }
+};
+} // namespace saber
+} // namespace anakin
+```
+
+### 为operator增加新的impl<span id="declare">声明</span>
+
+涉及的文件:```saber/funcs/impl/impl_mul.h```。不同的设备都特化同一个声明，特化版本放在对应的文件夹下，这里的声明就是给出所有设备的统一声明。下面给出一个参考。
+```
+#include "saber/funcs/impl/impl_macro.h"
+namespace anakin{
+namespace saber{
+DEFINE_OP_CLASS(Mul, MulParam); // 第一个参数是op的名字，第二个是对应param的名字
+}
+}
+```
+
+### 完成新的operator特定后端<span id="impl">实现</span>
+
+涉及的文件:```saber/funcs/impl/xxx/vender_mul.h```或```saber/funcs/impl/xxx/saber_mul.h```
+这里```xxx```指代特定的一种设备。```vender```是指的使用第三方库实现的op，```saber```指的源码实现的op。这里以cuda的vender实现为例，简单介绍一下特化出的函数的几个基本接口。
+
+```
+// include 对应的声明
+#include "saber/funcs/impl/impl_mul.h"
+
+namespace anakin{
+namespace saber{
+template <DataType OpDtype,
+    DataType inDtype,
+    DataType outDtype,
+    typename LayOutType_op,
+    typename LayOutType_in,
+    typename LayOutType_out>
+class VenderMul<NV, //偏特化出需要的后端。
+    OpDtype, inDtype, outDtype,
+    LayOutType_op, LayOutType_in, LayOutType_out> :
+    public ImplBase<
+        Tensor<NV, inDtype, LayOutType_in>,
+        Tensor<NV, outDtype, LayOutType_out>,
+        Tensor<NV, OpDtype, LayOutType_op>,
+        MulParam<Tensor<NV, OpDtype, LayOutType_op> > >
+{
+public:
+    typedef Tensor<NV, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<NV, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<NV, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype InDataType;
+    typedef typename DataTensor_out::Dtype OutDataType;
+    typedef typename OpTensor::Dtype OpDataType;
+    VenderMul(){}
+    ~VenderMul() {}
+
+    virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
+                            std::vector<DataTensor_out *>& outputs,
+                            MulParam<OpTensor>& param, Context<NV>& ctx) {
+        this->_ctx = ctx;
+        create(inputs, outputs, param, ctx);
+    }
+
+    virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
+                            std::vector<DataTensor_out *>& outputs,
+                            MulParam<OpTensor>& param, Context<NV>& ctx) {
+        // set内部参数
+    }
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                          std::vector<DataTensor_out*>& outputs,
+                        MulParam<OpTensor>& param) {
+        // dispatch kernel.
+    }
+
+private:
+};
+}
+}
+```
+```init```和```create```的区别：```init```接口是第一次初始化op的时候进入的接口，此函数只在第一次初始化op时调用，这个接口一般放一些只需要执行一次的代码，如malloc或者create之类的函数。```create```函数除了第一次init执行外，在输入发生变化或者param发生变化时会再次触发，create一般放置set函数，设置内部变量，当input发生变化时这里执行一些同input或weights直接相关的代码。但create因为触发位置在网络内，如果```create```函数执行了一些严重耗时的操作，这里会拖慢整个op的执行时间，需要慎重选择操作放置的位置。
+### 添加framework的特化
+
+涉及的文件:```framework/operators/mul.h```和```framework/operators/mul.cpp```。
+这里简单介绍下如果添加或修改framework内的operator
+
+```
+#include "framework/core/base.h"
+#include "framework/core/data_types.h"
+#include "framework/core/operator/operator.h"
+#include "utils/logger/logger.h"
+#include "saber/funcs/mul.h" // 需要包对应的saber头文件
+namespace anakin {
+namespace ops {
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class MulHelper;
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class Mul : public Operator<Ttype, Dtype, Ptype> {
+public:
+    Mul() {}
+    /// forward impl
+    virtual void operator() (OpContext<Ttype> &ctx,
+                             const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                             std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+        LOG(ERROR) << "Not Impl Yet Operator power<TargetType:"<<"unknown"<<","
+                   <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+    }
+    friend class MulHelper<Ttype, Dtype, Ptype>;
+};
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class MulHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
+public:
+    MulHelper() = default;
+    ~MulHelper();
+    Status InitParam() override;
+
+    Status Init(OpContext<Ttype> &ctx,
+                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+    Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+public:
+    saber::MulParam<Tensor4d<Ttype, Dtype>> _param_mul;
+    saber::Mul<Ttype, Dtype> _funcs_mul;
+};
+}
+} /* namespace anakin */
+```
+对应的```.cpp```文件如下：
+```
+#include "framework/operators/mul.h"
+
+namespace anakin {
+namespace ops {
+
+#ifdef USE_CUDA
+template<>
+void Mul<NV, AK_FLOAT, Precision::FP32>::operator()(
+    OpContext<NV>& ctx,
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    auto* impl =
+        static_cast<MulHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param =
+        static_cast<MulHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_mul;
+    impl->_funcs_mul(ins, outs, param, ctx);
+}
+#endif
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status MulHelper<Ttype, Dtype, Ptype>::InitParam() {
+    auto alpha = GET_PARAMETER(float, alpha);
+    MulParam<Tensor4d<Ttype, Dtype>> param_mul(alpha);
+    _param_mul = param_mul;
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status MulHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+
+    SABER_CHECK(_funcs_mul.init(ins, outs, _param_mul, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status MulHelper<Ttype, Dtype, Ptype>::InferShape(const
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs_mul.compute_output_shape(ins, outs, _param_mul));
+    return Status::OK();
+}
+
+#ifdef USE_CUDA
+template class MulHelper<NV, AK_FLOAT, Precision::FP32>;
+#endif
+#ifdef USE_ARM_PLACE
+template class MulHelper<ARM, AK_FLOAT, Precision::FP32>;
+#endif
+// register helper
+#ifdef USE_CUDA
+ANAKIN_REGISTER_OP_HELPER(Mul, MulHelper, NV, AK_FLOAT, Precision::FP32);
+#endif
+#ifdef USE_ARM_PLACE
+ANAKIN_REGISTER_OP_HELPER(Mul, MulHelper, ARM, AK_FLOAT, Precision::FP32);
+#endif
+//! register op
+ANAKIN_REGISTER_OP(Mul)
+.Doc("Mul operator")
+#ifdef USE_CUDA
+.__alias__<NV, AK_FLOAT, Precision::FP32>("mul")
+#endif
+#ifdef USE_ARM_PLACE
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("mul")
+#endif
+.num_in(1)
+.num_out(1)
+.Args<float>("alpha", " alpha of Mul "); //注册
+
+} /* namespace ops */
+
+} /* namespace anakin */
+```
+
+## 实现单元测试
+涉及的文件:```test/saber/xxx/test_saber_funcs_mul_xxx.cpp```
+在对应的test下需要添加新的单元测试
+
+```
+TEST(TestSaberFuncNV, test_depthwise_conv) {
+
+    // init tensors and some param.
+
+    // start Reshape & doInfer
+    Context<NV> ctx1(0, 1, 1);
+
+    // create param
+    MulParam<Tensor<NV, AK_FLOAT, NCHW> > param(alpha);
+
+    std::vector<Tensor<NV, AK_FLOAT, NCHW>*> input;
+    std::vector<Tensor<NV, AK_FLOAT, NCHW>*> output;
+
+    // create saber op
+    Mul<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW> mul;
+
+    // compute output shape
+    mul.compute_output_shape(input, output, param);
+
+    // re_alloc output tensors memory based on output shape
+    output[0]->re_alloc(output[0]->shape());
+
+    // init saber op(calling init and create)
+    mul.init(input, output, param, SPECIFY, VENDER_IMPL, ctx1);
+
+    // call operator()
+    mul(input, output, param, ctx1);
+
+    // cuda specified, record events
+    cudaStream_t cuda_stream = ctx1.get_compute_stream();
+    output[0]->record_event(cuda_stream);
+    output_dev.sync();
+    
+    // param changed 
+    param.alpha = 2.0;
+    // auto calling saber op(create and dispatch)
+    mul(input, output, param, ctx1);
+
+    cudaDeviceSynchronize();
+    CUDA_CHECK(cudaPeekAtLastError());
+}
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<NV>::env_init();
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
+```
+## 调试及注意事项
+
+一个op需要有对外的op接口和内部实现，由于存在saber/funcs/impl的非特化版本声明，当有op在某种设备下没有对应实现时，也能够编译，但此时是没有任何实现的空实现，
diff --git a/docs/Manual/pics/contri1.JPG b/docs/Manual/pics/contri1.JPG
new file mode 100755
index 0000000..753f7c4
Binary files /dev/null and b/docs/Manual/pics/contri1.JPG differ
diff --git a/docs/Manual/pics/contri2.JPG b/docs/Manual/pics/contri2.JPG
new file mode 100755
index 0000000..e788058
Binary files /dev/null and b/docs/Manual/pics/contri2.JPG differ
diff --git a/docs/Manual/run_on_arm_ch.md b/docs/Manual/run_on_arm_ch.md
new file mode 100644
index 0000000..ebeb38f
--- /dev/null
+++ b/docs/Manual/run_on_arm_ch.md
@@ -0,0 +1,151 @@
+## 源码编译 Anakin ##
+
+目前Anakin支持ARM Android平台，采用Android NDK交叉编译工具链，已在mac os和centos上编译和测试通过。
+
+### 安装概览 ###
+
+* [系统需求](#0001)
+* [安装第三方依赖](#0002)
+* [Anakin源码编译](#0003)
+* [验证安装](#0004)
+
+
+### <span id = '0001'> 1. 系统需求 </span> ###
+
+*  宿主机: linux, mac    
+*  cmake 3.8.2+    
+*  Android NDK r14, Linux 版本[从这里下载](https://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip)
+
+### <span id = '0002'> 2. 安装第三方依赖 </span> ###
+
+- 2.1 protobuf3.4.0     
+   源码从这里[下载](https://github.com/google/protobuf/releases/tag/v3.4.0)    
+ - 2.1.1 为宿主机编译protobuf     
+ ```bash
+   $ tar -xzf protobuf-3.4.0.tar.gz  
+   $ cd protobuf-3.4.0   
+   $ ./autogen.sh  
+   $ ./configure    
+   $ make  
+   $ make check   
+   $ make install
+   ```
+   上述 $make install 执行后，可在 /usr/local/include/google 找到 libprotobuf 所需的头文件,将整个google文件夹拷贝至Anakin/third-party/arm-android/protobuf/下，
+   如有问题，请点[这里](https://github.com/google/protobuf/blob/v3.4.0/src/README.md)。
+   然后将已经生成文件清除。
+ ```bash
+   $ make distclean
+   ```
+ - 2.1.1 交叉编译Android`armeabi-v7a`的protobuf，注意设置ANDROID_NDK的路径，以及ARCH_ABI、HOSTOSN的值，   
+ ```bash
+
+   $ export ANDROID_NDK=your_ndk_path 
+   $ ARCH_ABI="arm-linux-androideabi-4.9"
+   $ HOSTOSN="darwin-x86_64"
+   $ export SYSROOT=$ANDROID_NDK/platforms/android-9/arch-arm  
+   $ export PREBUILT=$ANDROID_NDK/toolchains/$ARCH_ABI
+   $ export LDFLAGS="--sysroot=$SYSROOT"
+   $ export LD="$ANDROID_NDK/toolchains/$ARCH_ABI/prebuilt/$HOSTOSN/arm-linux-androideabi/bin/ld $LDFLAGS"
+   $ export LIBS="-llog $ANDROID_NDK/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/libgnustl_static.a"
+   $ export CPPFLAGS=""
+   $ export INCLUDES="-I$ANDROID_NDK/sources/cxx-stl/gnu-libstdc++/4.9/include/ -I$ANDROID_NDK/platforms/android-9/arch-arm/usr/include/ -I$ANDROID_NDK/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include/"
+   $ export CXXFLAGS="-march=armv7-a -mfloat-abi=softfp -DGOOGLE_PROTOBUF_NO_RTTI --sysroot=$SYSROOT"
+   $ export CCFLAGS="$CXXFLAGS"
+   $ export CXX="$PREBUILT/prebuilt/$HOSTOSN/bin/arm-linux-androideabi-g++ $CXXFLAGS"
+   $ export CC="$CXX"
+   $ export RANLIB="$ANDROID_NDK/toolchains/$ARCH_ABI/prebuilt/$HOSTOSN/bin/arm-linux-androideabi-ranlib"  
+   $ ./autogen.sh  
+   $ ./configure --host=arm-linux-androideabi --with-sysroot=$SYSROOT --enable-cross-compile --with-protoc=protoc --disable-shared CXX="$CXX" CC="$CC" LD="$LD"  
+   $ make
+  ```
+  
+  编译生成 *.a 静态库，若希望编译*.so 动态链接库 ，请在./configure参数中改--disable-shared为--disable-static --enable-shared。  
+  生成文件在src/.libs/下，将生成的文件拷贝至Anakin/third-party/arm-android/protobuf/lib下。  
+  在[cmake](../../cmake/find_modules.cmake)中更新`ARM_RPOTO_ROOT`的路径。        
+  ```cmake
+  set(ARM_RPOTO_ROOT "${CMAKE_SOURCE_DIR}/third-party/arm-android/protobuf")
+  ```
+  
+- 2.2 opencv 2.4.3+(optional)    
+    Anakin只在examples示例中使用opencv   
+    Android系统的opencv从[这里下载](https://opencv.org/releases.html)    
+    解压后将 `3rdparty/libs/armeabi-v7a`中的库文件拷贝到`libs/armeabi-v7a`    
+    在[cmake](../../cmake/find_modules.cmake)中搜索`anakin_find_opencv`, 
+    并设置 `include_directories` 和 `LINK_DIRECTORIES`为自己安装的库的路径。   
+    ```cmake
+    include_directories(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/jni/include/)
+    LINK_DIRECTORIES(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/libs/armeabi-v7a/)
+    ```
+### <span id = '0003'> 3. Anakin源码编译 </span> ###
+
+#### 编译Android版本
+
+   克隆[源码](https://github.com/PaddlePaddle/Anakin/tree/arm)
+```bash
+    cd your_dir
+    git clone https://github.com/PaddlePaddle/Anakin.git
+    cd Anakin
+    git fetch origin arm
+    git checkout arm
+  ```
+  修改`android_build.sh`    
+- 修改NDK路径    
+  ```bash
+    #modify "your_ndk_path" to your NDK path
+    export ANDROID_NDK=your_ndk_path
+  ```
+- 修改ARM 处理器架构     
+  对于32位ARM处理器, 将ANDROID_ABI 设置为 `armeabi-v7a with NEON`， 
+  对于64位ARM处理器, 可以将ANDROID_ABI 设置为 `armeabi-v7a with NEON`或者`arm64-v8a`。        
+  目前我们只支持 `armeabi-v7a with NEON`；`arm64-v8a` 还在开发中。      
+  ```bash
+      -DANDROID_ABI="armeabi-v7a with NEON"
+  ```
+- 设置Android API    
+  根据Android系统的版本设置API level， 例如API Level 21 -> Android 5.0.1    
+  ```bash
+      -DANDROID_NATIVE_API_LEVEL=21
+  ```
+
+- 选择编译静态库或动态库    
+  设置`BUILD_SHARED=NO`编译静态库    
+  设置`BUILD_SHARED=YES`编译动态库    
+  ```bash
+      -DBUILD_SHARED=NO
+  ```
+- OpenMP多线程支持    
+  设置`USE_OPENMP=YES`开启OpenMP多线程    
+  ```bash
+      -DUSE_OPENMP=YES
+  ```
+  
+- 编译单测文件    
+  设置`BUILD_WITH_UNIT_TEST=YES`将会编译单测文件    
+    ```bash
+        -DBUILD_WITH_UNIT_TEST=YES
+    ```
+
+- 编译示例文件    
+  设置`BUILD_EXAMPLES=YES`将会编译示例文件    
+    ```bash
+        -DBUILD_EXAMPLES=YES
+    ```
+  
+- 开启opencv    
+  如果使用opencv，设置`USE_OPENCV=YES`    
+    ```bash
+        -DUSE_OPENCV=YES
+    ```
+    
+- 开始编译    
+  运行脚本 `android_build.sh` 将自动编译Anakin     
+  ```bash
+      ./android_build.sh
+  ```
+
+### <span id = '0004'> 4. 验证安装 </span> ###    
+  编译好的库会放在目录`${Anakin_root}/output`下；    
+  编译好的单测文件会放在`${Anakin_root}/output/unit_test`目录下；    
+  编译好的示例文件会放在`${Anakin_root}/output/examples`目录下。
+  
+  对于Android系统，打开设备的调试模式，通过ADB可以访问的目录是`data/local/tmp`，通过ADB push将测试文件、模型和数据发送到设备目录， 运行测试文件。
diff --git a/docs/Manual/run_on_arm_en.md b/docs/Manual/run_on_arm_en.md
new file mode 100644
index 0000000..a726b7d
--- /dev/null
+++ b/docs/Manual/run_on_arm_en.md
@@ -0,0 +1,127 @@
+## Build Anakin for ARM from source ##
+
+Now, we have successfully build on mac os and centos, using Android NDK
+
+### Installation overview ###
+
+* [system requirements](#0001)
+* [dependencies](#0002)
+* [build from source](#0003)
+* [verification](#0004)
+
+
+### <span id = '0001'> 1. system requirements </span> ###
+
+*  Host machine: linux, mac    
+*  cmake 3.8.2+    
+*  Android NDK r14, download linux version from [here](https://dl.google.com/android/repository/android-ndk-r14b-linux-x86_64.zip)
+
+### <span id = '0002'> 2. dependencies </span> ###
+
+- 2.1 protobuf3.4.0     
+   Download source from https://github.com/google/protobuf/releases/tag/v3.4.0    
+ - 2.1.1 Build protobuf for host     
+ ```bash
+   $ tar -xzf protobuf-3.4.0.tar.gz  
+   $ cd protobuf-3.4.0   
+   $ ./autogen.sh  
+   $ ./configure    
+   $ make  
+   $ make check   
+   $ make install
+   ```
+   for details, please refer [here](https://github.com/google/protobuf/blob/v3.4.0/src/README.md)
+    
+ - 2.1.2 Build protobuf for ARM `armeabi-v7a`    
+ ```bash
+ 
+  ```
+  Set your protobuf path [here](../../cmake/find_modules.cmake), search `anakin_find_protobuf`, and set `ARM_RPOTO_ROOT` to your path.    
+  ```cmake
+  set(ARM_RPOTO_ROOT "${CMAKE_SOURCE_DIR}/third-party/arm-android/protobuf")
+  ```
+  
+- 2.2 opencv 2.4.3+(optional)    
+    We only use opencv in examples   
+    For Android, visit opencv [release page](https://opencv.org/releases.html), choose Android pack and download, 
+    copy libs in `3rdparty/libs/armeabi-v7a` to `libs/armeabi-v7a`.   
+    Set your opencv path [here](../../cmake/find_modules.cmake),  Search `anakin_find_opencv`, 
+    and set `include_directories` and `LINK_DIRECTORIES` according to your path.   
+    ```cmake
+    include_directories(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/jni/include/)
+    LINK_DIRECTORIES(${CMAKE_SOURCE_DIR}/third-party/arm-android/opencv/sdk/native/libs/armeabi-v7a/)
+    ```
+### <span id = '0003'> 3. build from source </span> ###
+
+#### build for Android
+
+   clone the [source code](https://github.com/PaddlePaddle/Anakin/tree/arm)
+```bash
+    cd your_dir
+    git clone https://github.com/PaddlePaddle/Anakin.git
+    cd Anakin
+    git fetch origin arm
+    git checkout arm
+  ```
+  change the `android_build.sh`    
+- Set NDK path to yours    
+  ```bash
+    #modify "your_ndk_path" to your NDK path
+    export ANDROID_NDK=your_ndk_path
+  ```
+- Set your ARM target platform    
+
+  For 32bits ARM CPU with NEON, Set ANDROID_ABI to `armeabi-v7a with NEON`， 
+  for 64bits ARM CPU, either `arm64-v8a` or `armeabi-v7a with NEON` can work.    
+  Now, we only support `armeabi-v7a with NEON`，`arm64-v8a` is under developing    
+  ```bash
+      -DANDROID_ABI="armeabi-v7a with NEON"
+  ```
+- Set Android API level    
+  Choose your API LEVEL according to your android system version    
+  API Level 21 -> Android 5.0.1    
+  ```bash
+      -DANDROID_NATIVE_API_LEVEL=21
+  ```
+
+- build static or shared lib    
+  if building static lib, set `BUILD_SHARED=NO`    
+  if building shared lib, set `BUILD_SHARED=YES`    
+  ```bash
+      -DBUILD_SHARED=NO
+  ```
+- OpenMP for multi-threads    
+  set `USE_OPENMP=YES` to use OpenMP multi-threads    
+  ```bash
+      -DUSE_OPENMP=YES
+  ```
+  
+- build unit test    
+  set `BUILD_WITH_UNIT_TEST=YES` to build unit tests    
+    ```bash
+        -DBUILD_WITH_UNIT_TEST=YES
+    ```
+
+- build examples    
+  set `BUILD_EXAMPLES=YES` to build detection and classification examples    
+    ```bash
+        -DBUILD_EXAMPLES=YES
+    ```
+  
+- use opencv in examples    
+  set `USE_OPENCV=YES` to use opencv in examples    
+    ```bash
+        -DUSE_OPENCV=YES
+    ```
+    
+- build    
+  run `android_build.sh` to build the Anakin     
+  ```bash
+      ./android_build.sh
+  ```
+
+### <span id = '0004'> 4. Verification </span> ###    
+  The libs is in `${Anakin_root}/output`, the unit test and benchmark file is in `${Anakin_root}/output/unit_test` 
+  and the examples is in `${Anakin_root}/output/examples`   
+  Open `USB debug mode` in your Android device, Use ADB to push the test files and model files to `data/local/tmp/your_dir`    
+  run the test
\ No newline at end of file
diff --git a/examples/CMakeLists.txt b/examples/CMakeLists.txt
new file mode 100644
index 0000000..3ba3ccb
--- /dev/null
+++ b/examples/CMakeLists.txt
@@ -0,0 +1,54 @@
+# used for temporary
+anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK})
+anakin_fetch_include_recursively(${ANAKIN_MODEL_PARSER})
+anakin_fetch_include_recursively(${ANAKIN_SABER})
+
+if(NVIDIA_GPU)
+anakin_fetch_files_with_suffix(${ANAKIN_EXAMPLES}/cuda "cpp" ANAKIN_TEST_CASE_SRC)
+endif()
+
+if(USE_X86_PLACE)
+anakin_fetch_files_with_suffix(${ANAKIN_EXAMPLES}/x86 "cpp" ANAKIN_TEST_CASE_SRC)
+endif()
+
+if(USE_ARM_PLACE) #build unit test for arm devices
+	anakin_fetch_files_with_suffix(${ANAKIN_EXAMPLES}/arm "cpp" ANAKIN_TEST_CASE_SRC)
+	if(USE_OPENMP)
+		set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fopenmp")
+	endif()
+	if (USE_PROTOBUF)
+		find_library(log-lib log)
+	endif()
+endif()
+
+file(REMOVE ${PROJECT_SOURCE_DIR}/output/examples/*)
+
+# build test cases
+foreach(SRC_NAME ${ANAKIN_TEST_CASE_SRC})
+	#unpack the dir "/"
+	string(REPLACE "/" ";" SEXY_LIST ${SRC_NAME})
+	list(GET SEXY_LIST -1 TEST_CASE_NAME)
+	#get the file name without suffix
+	string(REPLACE "." ";" SEXY_LIST ${TEST_CASE_NAME})
+	list(GET SEXY_LIST 0 TEST_CASE_NAME)
+	add_executable(${TEST_CASE_NAME}  ${SRC_NAME})
+	if(BUILD_SHARED)
+		target_link_libraries(${TEST_CASE_NAME} ${anakin_lib_so} ${ANAKIN_LINKER_LIBS})
+	else()
+		target_link_libraries(${TEST_CASE_NAME} -Wl,--whole-archive ${anakin_lib_static} -Wl,--no-whole-archive ${ANAKIN_LINKER_LIBS})
+	endif()
+	if(USE_ARM_PLACE)
+		target_link_libraries(${TEST_CASE_NAME} ${log-lib})
+	endif()
+    if(USE_OPENCV)
+        if (USE_ARM_PLACE)
+            target_link_libraries(${TEST_CASE_NAME} -lopencv_core -lopencv_highgui -lopencv_imgproc
+					-ltbb -llibtiff -llibpng -llibjpeg -llibjasper -lIlmImf -lc -lz -llog -ldl)
+        else()
+            target_link_libraries(${TEST_CASE_NAME} -lopencv_core -lopencv_highgui -lopencv_imgproc)
+        endif()
+    endif()
+	set_target_properties(${TEST_CASE_NAME} PROPERTIES
+						RUNTIME_OUTPUT_DIRECTORY 
+						${PROJECT_SOURCE_DIR}/output/examples)
+endforeach()
diff --git a/examples/README.md b/examples/README.md
new file mode 100644
index 0000000..160231d
--- /dev/null
+++ b/examples/README.md
@@ -0,0 +1,20 @@
+# hands on examples
+
+## dependecies
+
+- opencv2.4.3+ for image reading
+
+## NV GPU
+
+
+
+## ARM
+- refer [run on arm](../docs/Manual/run_on_arm_en.md) to set your opencv path
+- Enable `USE_OPENCV` in [CMakeList.txt](../CMakeLists.txt)
+- Enable building examples in [CMakeList.txt](../CMakeLists.txt)
+
+### mobilenet_ssd detection
+
+
+### mobilenetv1 classification
+
diff --git a/examples/arm/classification.cpp b/examples/arm/classification.cpp
new file mode 100644
index 0000000..27c3ce4
--- /dev/null
+++ b/examples/arm/classification.cpp
@@ -0,0 +1,234 @@
+#include "graph_base.h"
+#include "graph.h"
+#include "scheduler.h"
+#include "net.h"
+#include "worker.h"
+#include "tensor_op.h"
+#include "timer.h"
+
+using namespace anakin::saber;
+using namespace anakin::graph;
+using namespace anakin;
+typedef Tensor<ARM, AK_FLOAT, NCHW> Tensor4hf;
+
+
+void load_labels(std::string path, std::vector<std::string>& labels) {
+
+    FILE* fp = fopen(path.c_str(), "r");
+    if (fp == nullptr) {
+        LOG(FATAL) << "load label file failed";
+    }
+    while (!feof(fp)) {
+        char str[1024];
+        fgets(str, 1024, fp);
+        std::string str_s(str);
+
+        if (str_s.length() > 0) {
+            for (int i = 0; i < str_s.length(); i++) {
+                if (str_s[i] == ' ') {
+                    std::string strr = str_s.substr(i, str_s.length() - i - 1);
+                    labels.push_back(strr);
+                    i = str_s.length();
+                }
+            }
+        }
+    }
+    fclose(fp);
+}
+
+void print_topk(const float* scores, const int size, const int topk, \
+    const std::vector<std::string>& labels) {
+
+    std::vector< std::pair<float, int> > vec;
+    vec.resize(size);
+    for (int i = 0; i < size; i++) {
+        vec[i] = std::make_pair(scores[i], i);
+    }
+
+    std::partial_sort(vec.begin(), vec.begin() + topk, vec.end(),
+                      std::greater< std::pair<float, int> >());
+
+    // print topk and score
+    for (int i = 0; i < topk; i++) {
+        float score = vec[i].first;
+        int index = vec[i].second;
+        LOG(INFO) << i <<": " << index << "  " << labels[index] << "  " << score;
+    }
+}
+
+#ifdef USE_OPENCV
+#include "opencv2/opencv.hpp"
+
+using namespace cv;
+
+void fill_tensor_with_cvmat(const Mat& img_in, Tensor4hf& tout, const int num, \
+    const int width, const int height, const float* mean, const float* scale) {
+    cv::Mat im;
+    cv::resize(img_in, im, cv::Size(width, height), 0.f, 0.f);
+    float* ptr_data_in = tout.mutable_data();
+    int stride = width * height;
+    for (int i = 0; i < num; i++) {
+        float* ptr_in = ptr_data_in + i * tout.channel() * tout.height() * tout.width();
+        for (int r = 0; r < height; r++) {
+            for (int c = 0; c < width; c++) {
+                ptr_in[r * width + c] = (im.at<cv::Vec3b>(r, c)[0] - mean[0]) * scale[0];
+                ptr_in[stride + r * width + c] = (im.at<cv::Vec3b>(r, c)[1] - mean[1]) * scale[1];
+                ptr_in[2 * stride + r * width + c] = (im.at<cv::Vec3b>(r, c)[2] - mean[2]) * scale[2];
+            }
+        }
+    }
+}
+#endif
+
+void test_net(const std::string model_file_name, const std::string image_file_name, \
+    const std::vector<std::string>& labels, const int topk, const int threads, \
+    const int test_iter) {
+
+    int batch_size = 1;
+
+    //! create runtime context
+    LOG(INFO) << "create runtime context";
+    std::shared_ptr<Context<ARM>> ctx1 = std::make_shared<Context<ARM>>();
+    ctx1->set_run_mode(SABER_POWER_HIGH, threads);
+    LOG(INFO) << omp_get_num_threads() << " threads is activated";
+
+    //! load model
+    LOG(WARNING) << "load anakin model file from " << model_file_name << " ...";
+    Graph<ARM, AK_FLOAT, Precision::FP32> graph;
+    auto status = graph.load(model_file_name);
+    if (!status) {
+         LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    //! set batch size
+    graph.ResetBatchSize("input_0", batch_size);
+
+    //! optimize the graph
+    LOG(INFO) << "optimize the graph";
+    graph.Optimize();
+
+    //! get output name
+    std::vector<std::string>& vout_name = graph.get_outs();
+    LOG(INFO) << "output size: " << vout_name.size();
+
+    //! constructs the executer net
+    LOG(INFO) << "create net to execute";
+    Net<ARM, AK_FLOAT, Precision::FP32, OpRunType::SYNC> net_executer(graph, ctx1, true);
+
+    //! get in
+    LOG(INFO) << "get input";
+    auto d_tensor_in_p = net_executer.get_in("input_0");
+    auto valid_shape_in = d_tensor_in_p->valid_shape();
+    for (int i = 0; i < valid_shape_in.size(); i++) {
+        LOG(INFO) << "detect input dims[" << i << "]" << valid_shape_in[i];
+    }
+    Tensor4hf thin(valid_shape_in);
+
+    //! feed input image to input tensor
+#ifdef USE_OPENCV
+    LOG(INFO) << "loading image " << image_file_name << " ...";
+    Mat img = imread(image_file_name, CV_LOAD_IMAGE_COLOR);
+    if (img.empty()) {
+        LOG(FATAL) << "opencv read image " << image_file_name << " failed";
+    }
+    //! set your mean value and scale value here
+    float mean_mb[3] = {103.94f, 116.78f, 123.68f};
+    float scale_mb[3] = {0.017f, 0.017f, 0.017f};
+    fill_tensor_with_cvmat(img, thin, batch_size, thin.width(), thin.height(), mean_mb, scale_mb);
+
+#else
+    fill_tensor_host_const(thin, 1.f);
+#endif
+
+    //! do inference
+    Context<ARM> ctx(0, 0, 0);
+    anakin::saber::SaberTimer<ARM> my_time;
+    LOG(INFO) << "run prediction ";
+
+    double to = 0;
+    double tmin = 1000000;
+    double tmax = 0;
+    my_time.start(ctx);
+    saber::SaberTimer<ARM> t1;
+    for (int i = 0; i < test_iter; i++) {
+        d_tensor_in_p->copy_from(thin);
+        t1.clear();
+        t1.start(ctx);
+        net_executer.prediction();
+        t1.end(ctx);
+        double tdiff = t1.get_average_ms();
+        if (tdiff > tmax) {
+            tmax = tdiff;
+        }
+        if (tdiff < tmin) {
+            tmin = tdiff;
+        }
+        to += tdiff;
+    }
+    my_time.end(ctx);
+
+
+    LOG(INFO) << model_file_name << " batch_size " << batch_size << \
+        " average time " << to / test_iter << \
+        ", min time: " << tmin << "ms, max time: " << tmax << " ms";
+
+    //! get output
+    //! fixme get output
+    //std::vector<Tensor4hf*> vout = net_executer.get_out_list();
+    std::vector<Tensor4hf*> vout;
+    for (auto& it : vout_name) {
+        vout.push_back(net_executer.get_out(it));
+    }
+    Tensor4hf* tensor_out = vout[0];
+    LOG(INFO) << "output size: " << vout.size();
+
+#if 0 //print output tensor data
+    LOG(INFO) << "extract data: size: " << tensor_out->valid_size() << \
+        ", width=" << tensor_out->width() << ", height=" << tensor_out->height();
+    const float* ptr_out = tensor_out->data();
+    for (int i = 0; i < tensor_out->valid_size(); i++) {
+        printf("%0.4f  ", ptr_out[i]);
+        if ((i + 1) % 7 == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+#endif
+    print_topk(tensor_out->data(), tensor_out->valid_size(), topk, labels);
+}
+
+int main(int argc, char** argv){
+
+    LOG(INFO) << "initialized the device";
+    Env<ARM>::env_init();
+
+    if (argc < 4) {
+        LOG(ERROR) << "usage: " << argv[0] << ": model_file label_file image_name [topk] [test_iter] [threads]";
+        return -1;
+    }
+    char* model_file = argv[1];
+    char* label_file = argv[2];
+    char* image_path = argv[3];
+
+    std::vector<std::string> labels;
+    load_labels(label_file, labels);
+
+    int topk = 5;
+    if (argc > 4) {
+        topk = atoi(argv[4]);
+    }
+
+    int test_iter = 10;
+    if (argc > 5) {
+        test_iter = atoi(argv[5]);
+    }
+
+    int threads = 1;
+    if (argc > 6) {
+        threads = atoi(argv[6]);
+    }
+
+	test_net(model_file, image_path, labels, topk, threads, test_iter);
+    return 0;
+}
+
diff --git a/examples/arm/ssd_detection.cpp b/examples/arm/ssd_detection.cpp
new file mode 100644
index 0000000..50b02b3
--- /dev/null
+++ b/examples/arm/ssd_detection.cpp
@@ -0,0 +1,233 @@
+#include "graph_base.h"
+#include "graph.h"
+#include "scheduler.h"
+#include "net.h"
+#include "worker.h"
+#include "tensor_op.h"
+#include "timer.h"
+
+using namespace anakin::saber;
+using namespace anakin::graph;
+using namespace anakin;
+typedef Tensor<ARM, AK_FLOAT, NCHW> Tensor4hf;
+
+#ifdef USE_OPENCV
+#include "opencv2/opencv.hpp"
+
+using namespace cv;
+
+struct Object{
+    int batch_id;
+    cv::Rect rec;
+    int class_id;
+    float prob;
+};
+
+const char* class_names[] = {"background",
+                             "aeroplane", "bicycle", "bird", "boat",
+                             "bottle", "bus", "car", "cat", "chair",
+                             "cow", "diningtable", "dog", "horse",
+                             "motorbike", "person", "pottedplant",
+                             "sheep", "sofa", "train", "tvmonitor"};
+
+void fill_tensor_with_cvmat(const Mat& img_in, Tensor4hf& tout, const int num, \
+    const int width, const int height, const float* mean, const float* scale) {
+    cv::Mat im;
+    cv::resize(img_in, im, cv::Size(width, height), 0.f, 0.f);
+    float* ptr_data_in = tout.mutable_data();
+    int stride = width * height;
+    for (int i = 0; i < num; i++) {
+        float* ptr_in = ptr_data_in + i * tout.channel() * tout.height() * tout.width();
+        for (int r = 0; r < height; r++) {
+            for (int c = 0; c < width; c++) {
+                ptr_in[r * width + c] = (im.at<cv::Vec3b>(r, c)[0] - mean[0]) * scale[0];
+                ptr_in[stride + r * width + c] = (im.at<cv::Vec3b>(r, c)[1] - mean[1]) * scale[1];
+                ptr_in[2 * stride + r * width + c] = (im.at<cv::Vec3b>(r, c)[2] - mean[2]) * scale[2];
+            }
+        }
+    }
+}
+
+void detect_object(Tensor4hf& tout, const float thresh, Mat& image) {
+    std::vector<Object> objects;
+    const float* dout = tout.data();
+    for (int iw = 0; iw < tout.height(); iw++) {
+        Object object;
+        const float *values = dout + iw * tout.width();
+        int batch_id = static_cast<int>(values[0]);
+        int oriw = image.cols;
+        int orih = image.rows;
+        object.batch_id = batch_id;
+        object.class_id = (int)values[1];
+        object.prob = values[2];
+        object.rec.x = (int)(values[3] * oriw);
+        object.rec.y = (int)(values[4] * orih);
+        object.rec.width = (int)(values[5] * oriw - object.rec.x);
+        object.rec.height = (int)(values[6] * orih - object.rec.y);
+        objects.push_back(object);
+    }
+
+    for (int i = 0; i< objects.size(); ++i) {
+        Object object = objects.at(i);
+        if (object.prob > thresh) {
+            cv::rectangle(image, object.rec, cv::Scalar(255, 0, 0));
+            std::ostringstream pro_str;
+            pro_str << object.prob;
+            std::string label = std::string(class_names[object.class_id]) + ": " + pro_str.str();
+            cv::putText(image, label, cv::Point(object.rec.x, object.rec.y), \
+                cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
+            LOG(INFO) << "detection in batch: " << object.batch_id << ", image size: " << image.cols << ", " << image.rows << \
+                    ", detect object: " << class_names[object.class_id] << ", location: x=" << object.rec.x << ", y=" << object.rec.y << \
+                      ", width=" << object.rec.width << ", height=" << object.rec.height;
+            cv::imwrite("detection_output.jpg", image);
+        }
+    }
+}
+#endif
+
+void test_net(const std::string model_file_name, const std::string image_file_name, float thresh, \
+    int threads, int test_iter) {
+
+    int batch_size = 1;
+
+    //! create runtime context
+    LOG(INFO) << "create runtime context";
+    std::shared_ptr<Context<ARM>> ctx1 = std::make_shared<Context<ARM>>();
+    ctx1->set_run_mode(SABER_POWER_HIGH, threads);
+    LOG(INFO) << omp_get_num_threads() << " threads is activated";
+
+    //! load model
+    LOG(WARNING) << "load anakin model file from " << model_file_name << " ...";
+    Graph<ARM, AK_FLOAT, Precision::FP32> graph;
+    auto status = graph.load(model_file_name);
+    if (!status) {
+         LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    //! set batch size
+    graph.ResetBatchSize("input_0", batch_size);
+
+    //! optimize the graph
+    LOG(INFO) << "optimize the graph";
+    graph.Optimize();
+
+    //! get output name
+    std::vector<std::string>& vout_name = graph.get_outs();
+    LOG(INFO) << "output size: " << vout_name.size();
+
+    //! constructs the executer net
+    LOG(INFO) << "create net to execute";
+    Net<ARM, AK_FLOAT, Precision::FP32, OpRunType::SYNC> net_executer(graph, ctx1, true);
+
+    //! get in
+    LOG(INFO) << "get input";
+    auto d_tensor_in_p = net_executer.get_in("input_0");
+    auto valid_shape_in = d_tensor_in_p->valid_shape();
+    for (int i = 0; i < valid_shape_in.size(); i++) {
+        LOG(INFO) << "detect input dims[" << i << "]" << valid_shape_in[i];
+    }
+    Tensor4hf thin(valid_shape_in);
+
+    //! feed input image to input tensor
+#ifdef USE_OPENCV
+    LOG(INFO) << "loading image " << image_file_name << " ...";
+    Mat img = imread(image_file_name, CV_LOAD_IMAGE_COLOR);
+    if (img.empty()) {
+        LOG(FATAL) << "opencv read image " << image_file_name << " failed";
+    }
+    float mean_mb[3] = {127.5f, 127.5f, 127.5f};
+    float scale_mb[3] = {1 / 127.5f, 1 / 127.5f, 1 / 127.5f};
+    fill_tensor_with_cvmat(img, thin, batch_size, thin.width(), thin.height(), mean_mb, scale_mb);
+#else
+    fill_tensor_host_const(thin, 1.f);
+#endif
+
+    //! do inference
+    Context<ARM> ctx(0, 0, 0);
+    anakin::saber::SaberTimer<ARM> my_time;
+    LOG(INFO) << "run prediction ";
+
+    double to = 0;
+    double tmin = 1000000;
+    double tmax = 0;
+    my_time.start(ctx);
+    saber::SaberTimer<ARM> t1;
+    for (int i = 0; i < test_iter; i++) {
+        d_tensor_in_p->copy_from(thin);
+        t1.clear();
+        t1.start(ctx);
+        net_executer.prediction();
+        t1.end(ctx);
+        double tdiff = t1.get_average_ms();
+        if (tdiff > tmax) {
+            tmax = tdiff;
+        }
+        if (tdiff < tmin) {
+            tmin = tdiff;
+        }
+        to += tdiff;
+    }
+    my_time.end(ctx);
+
+
+    LOG(INFO) << model_file_name << " batch_size " << batch_size << \
+        " average time " << to / test_iter << \
+        ", min time: " << tmin << "ms, max time: " << tmax << " ms";
+
+    //! fixme get output
+    //std::vector<Tensor4hf*> vout = net_executer.get_out_list();
+    std::vector<Tensor4hf*> vout;
+    for (auto& it : vout_name) {
+        vout.push_back(net_executer.get_out(it));
+    }
+    Tensor4hf* tensor_out = vout[0];
+    LOG(INFO) << "output size: " << vout.size();
+#if 0 //print output data
+    LOG(INFO) << "extract data: size: " << tensor_out->valid_size() << \
+        ", width=" << tensor_out->width() << ", height=" << tensor_out->height();
+    const float* ptr_out = tensor_out->data();
+    for (int i = 0; i < tensor_out->valid_size(); i++) {
+        printf("%0.4f  ", ptr_out[i]);
+        if ((i + 1) % 7 == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+#endif
+#ifdef USE_OPENCV
+    detect_object(*tensor_out, thresh, img);
+#endif
+}
+
+int main(int argc, char** argv){
+
+    LOG(INFO) << "initialized the device";
+    Env<ARM>::env_init();
+
+    if (argc < 2) {
+        LOG(ERROR) << "usage: " << argv[0] << ": model_file image_name [detect_thresh] [test_iter] [threads]";
+        return -1;
+    }
+    char* model_file = argv[1];
+
+    char* image_path = argv[2];
+
+    float thresh = 0.6;
+    if(argc > 3) {
+        thresh = (float)atof(argv[3]);
+    }
+
+    int test_iter = 10;
+    if (argc > 4) {
+        test_iter = atoi(argv[4]);
+    }
+
+    int threads = 1;
+    if (argc > 5) {
+        threads = atoi(argv[5]);
+    }
+
+	test_net(model_file, image_path, thresh, threads, test_iter);
+    return 0;
+}
+
diff --git a/examples/cat1.jpg b/examples/cat1.jpg
new file mode 100755
index 0000000..343aec4
Binary files /dev/null and b/examples/cat1.jpg differ
diff --git a/examples/cuda/example_nv_cnn_net.cpp b/examples/cuda/example_nv_cnn_net.cpp
new file mode 100644
index 0000000..be7ec64
--- /dev/null
+++ b/examples/cuda/example_nv_cnn_net.cpp
@@ -0,0 +1,66 @@
+
+#include "utils/logger/logger.h"
+#include "graph.h"
+#include "net.h"
+
+#ifdef USE_CUDA
+/*util to fill tensor*/
+#include "saber/core/tensor_op.h"
+using namespace anakin;
+using namespace anakin::graph;
+using namespace anakin::saber;
+
+int main(int argc, const char** argv) {
+    /*init graph object, graph is the skeleton of model*/
+    Graph<NV, AK_FLOAT, Precision::FP32> graph;
+
+    /*load model from file to init the graph*/
+    auto status = graph.load("Resnet50.anakin.bin");
+    if (!status) {
+        LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    /*set net input shape and use this shape to optimize the graph(fusion and init operator),shape is n,c,h,w*/
+    graph.Reshape("input_0", {1, 3, 224, 224});
+    graph.Optimize();
+
+    /*net_executer is the executor object of model. use graph to init Net*/
+    Net<NV, AK_FLOAT, Precision::FP32> net_executer(graph, true);
+
+    /*use input string to get the input tensor of net. for we use NV as target, the tensor of net_executer is on GPU memory*/
+    auto d_tensor_in_p = net_executer.get_in("input_0");
+    auto valid_shape_in = d_tensor_in_p->valid_shape();
+
+    /*create tensor located in host*/
+    Tensor4d<X86, AK_FLOAT> h_tensor_in;
+
+    /*alloc for host tensor*/
+    h_tensor_in.re_alloc(valid_shape_in);
+
+    /*init host tensor by random*/
+    fill_tensor_host_rand(h_tensor_in, -1.0f, 1.0f);
+
+    /*use host tensor to int device tensor which is net input*/
+    d_tensor_in_p->copy_from(h_tensor_in);
+
+    /*run infer*/
+    net_executer.prediction();
+
+    LOG(INFO)<<"infer finash";
+
+    /*get the out put of net, which is a device tensor*/
+    auto d_out=net_executer.get_out("prob_out");
+
+    /*create another host tensor, and copy the content of device tensor to host*/
+    Tensor4d<X86, AK_FLOAT> h_tensor_out;
+    h_tensor_out.re_alloc(d_out->valid_shape());
+    h_tensor_out.copy_from(*d_out);
+
+    /*show output content*/
+    for(int i=0;i<h_tensor_out.valid_size();i++){
+        LOG(INFO)<<"out ["<<i<<"] = "<<h_tensor_out.data()[i];
+    }
+}
+#else
+int main(){}
+#endif
\ No newline at end of file
diff --git a/examples/cuda/example_nv_cnn_net_multi_thread.cpp b/examples/cuda/example_nv_cnn_net_multi_thread.cpp
new file mode 100644
index 0000000..689774b
--- /dev/null
+++ b/examples/cuda/example_nv_cnn_net_multi_thread.cpp
@@ -0,0 +1,50 @@
+
+#include "utils/logger/logger.h"
+#include "graph.h"
+#include "net.h"
+
+/*worker is anakin thread pool*/
+#include "worker.h"
+
+/*util to fill tensor*/
+#include "saber/core/tensor_op.h"
+#ifdef USE_CUDA
+using namespace anakin;
+using namespace anakin::graph;
+using namespace anakin::saber;
+
+int main(int argc, const char** argv) {
+
+    /*init works object by model path and thread pool size*/
+    Worker<NV, AK_FLOAT, Precision::FP32>  workers("Resnet50.anakin.bin", 10);
+    workers.register_inputs({"input_0"});
+    workers.register_outputs({"prob_out"});
+    /*set input shape*/
+    workers.Reshape("input_0", {1, 3, 224, 224});
+    /*start workers*/
+    workers.launch();
+
+    /*fill input*/
+    std::vector<Tensor4dPtr<target_host<NV>::type, AK_FLOAT> > host_tensor_p_in_list;
+    saber::Shape valid_shape_in({1, 3, 224, 224});
+    Tensor4dPtr<target_host<NV>::type, AK_FLOAT> h_tensor_in = new Tensor4d<target_host<NV>::type, AK_FLOAT>(valid_shape_in);
+    float* h_data = h_tensor_in->mutable_data();
+    for (int i=0; i<h_tensor_in->size(); i++) {
+        h_data[i] = 1.0f;
+    }
+    host_tensor_p_in_list.push_back(h_tensor_in);
+
+
+    /*run infer，send input to worker queue*/
+    int epoch = 1000;
+    for(int i=0; i<epoch; i++) {
+        auto  d_tensor_p_out_list = workers.sync_prediction(host_tensor_p_in_list);
+        auto d_tensor_p = d_tensor_p_out_list[0];
+    }
+    LOG(INFO)<<"info finish";
+
+}
+#else
+#include "stdio.h"
+int main(){printf("nothing happened -_-!!\n");}
+#endif
\ No newline at end of file
diff --git a/examples/example_introduction_cn.md b/examples/example_introduction_cn.md
new file mode 100644
index 0000000..8737f0b
--- /dev/null
+++ b/examples/example_introduction_cn.md
@@ -0,0 +1,85 @@
+# Example
+Anakin目前只支持NCHW的格式
+示例文件在test/framework/net下
+
+## 在NV的GPU上运行CNN模型
+整体流程如下：
+- 将模型的的path设置为anakin模型的路径，初始化NV平台的图对象。 anakin模型可以通过转换器转化caffe或fluid的模型得到
+```cpp
+Graph<NV, AK_FLOAT, Precision::FP32> graph;
+auto status = graph.load("Resnet50.anakin.bin");
+```
+
+- 根据模型设置网络图的输入尺寸，进行图优化
+```cpp
+graph.Reshape("input_0", {1, 3, 224, 224});
+graph.Optimize();
+```
+
+- 根据优化后的网络图初始化网络执行器
+```cpp
+Net<NV, AK_FLOAT, Precision::FP32> net_executer(graph, true);
+```
+
+- 取出网络的输入tensor，将数据拷贝到输入tensor，其中copy_from将数据从内存拷贝到显存
+```cpp
+auto d_tensor_in_p = net_executer.get_in("input_0");
+Tensor4d<X86, AK_FLOAT> h_tensor_in;
+h_tensor_in.re_alloc(valid_shape_in);
+fill_tensor_host_rand(h_tensor_in, -1.0f, 1.0f);
+d_tensor_in_p->copy_from(h_tensor_in);
+```
+
+- 运行推导
+```cpp
+net_executer.prediction();
+```
+
+- 取出网络的输出tensor,其中copy_from将数据从显存拷贝到内存
+```cpp
+auto d_out=net_executer.get_out("prob_out");
+Tensor4d<X86, AK_FLOAT> h_tensor_out;
+h_tensor_out.re_alloc(d_out->valid_shape());
+h_tensor_out.copy_from(*d_out);
+```
+
+示例文件为[example_nv_cnn_net.cpp](cuda/example_nv_cnn_net.cpp)  
+以NV平台为例演示Anakin框架的使用方法，注意编译时需要打开GPU编译开关和example编译开关，也可以将文件复制到`test/framework/net`下直接编译
+- - -
+## 在X86上运行RNN模型
+
+整体流程与在NV的GPU上运行CNN模型相似，不同之处如下：
+- 使用X86标识初始化图对象和网络执行器对象
+```cpp
+Graph<X86, AK_FLOAT, Precision::FP32> graph;
+Net<X86, AK_FLOAT, Precision::FP32> net_executer(graph, true);
+```
+
+- rnn模型的输入尺寸是可变的，初始化图时的输入维度是维度的最大值，输入维度N代表总的词的个数。还需要设置输入tensor的seq_offset来标示这些词是如何划分为句子的，如{0,10,15,30}表示共有12个词，其中第0到第9个词是第一句话，第10到第14个词是第二句话，第15到第29个词是第三句话  
+```cpp
+h_tensor_in_p->set_seq_offset({0,10,15,30});
+```
+
+示例文件为[example_x86_rnn_net.cpp](x86/example_x86_rnn_net.cpp)  
+以X86平台为例演示Anakin框架的使用方法，注意编译时需要打开X86编译开关和example编译开关，也可以将文件复制到`test/framework/net`下直接编译
+- - -
+## 在NV的GPU上使用Anakin的线程池运行CNN模型
+
+整体流程与在NV的GPU上运行CNN模型相似，不同之处如下：
+- 用模型地址和线程池大小初始化worker对象，注册输入输出，启动线程池  
+```cpp
+Worker<NV, AK_FLOAT, Precision::FP32>  workers("Resnet50.anakin.bin", 10);
+workers.register_inputs({"input_0"});
+workers.register_outputs({"prob_out"});
+workers.Reshape("input_0", {1, 3, 224, 224});
+workers.launch();
+```
+- 将输入tensor注入任务队列,获得输出tensor  
+```cpp
+auto d_tensor_p_out_list = workers.sync_prediction(host_tensor_p_in_list);
+auto d_tensor_p = d_tensor_p_out_list[0];
+```
+
+示例文件为[example_nv_cnn_net_multi_thread.cpp](cuda/example_nv_cnn_net_multi_thread.cpp) 示例使用worker的同步预测接口  
+
+以NV平台为例演示Anakin框架的使用方法，注意编译时需要打开GPU编译开关和example编译开关，也可以将文件复制到`test/framework/net`下直接编译
diff --git a/examples/labels.txt b/examples/labels.txt
new file mode 100755
index 0000000..a9e8c7f
--- /dev/null
+++ b/examples/labels.txt
@@ -0,0 +1,1000 @@
+n01440764 tench, Tinca tinca
+n01443537 goldfish, Carassius auratus
+n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias
+n01491361 tiger shark, Galeocerdo cuvieri
+n01494475 hammerhead, hammerhead shark
+n01496331 electric ray, crampfish, numbfish, torpedo
+n01498041 stingray
+n01514668 cock
+n01514859 hen
+n01518878 ostrich, Struthio camelus
+n01530575 brambling, Fringilla montifringilla
+n01531178 goldfinch, Carduelis carduelis
+n01532829 house finch, linnet, Carpodacus mexicanus
+n01534433 junco, snowbird
+n01537544 indigo bunting, indigo finch, indigo bird, Passerina cyanea
+n01558993 robin, American robin, Turdus migratorius
+n01560419 bulbul
+n01580077 jay
+n01582220 magpie
+n01592084 chickadee
+n01601694 water ouzel, dipper
+n01608432 kite
+n01614925 bald eagle, American eagle, Haliaeetus leucocephalus
+n01616318 vulture
+n01622779 great grey owl, great gray owl, Strix nebulosa
+n01629819 European fire salamander, Salamandra salamandra
+n01630670 common newt, Triturus vulgaris
+n01631663 eft
+n01632458 spotted salamander, Ambystoma maculatum
+n01632777 axolotl, mud puppy, Ambystoma mexicanum
+n01641577 bullfrog, Rana catesbeiana
+n01644373 tree frog, tree-frog
+n01644900 tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui
+n01664065 loggerhead, loggerhead turtle, Caretta caretta
+n01665541 leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea
+n01667114 mud turtle
+n01667778 terrapin
+n01669191 box turtle, box tortoise
+n01675722 banded gecko
+n01677366 common iguana, iguana, Iguana iguana
+n01682714 American chameleon, anole, Anolis carolinensis
+n01685808 whiptail, whiptail lizard
+n01687978 agama
+n01688243 frilled lizard, Chlamydosaurus kingi
+n01689811 alligator lizard
+n01692333 Gila monster, Heloderma suspectum
+n01693334 green lizard, Lacerta viridis
+n01694178 African chameleon, Chamaeleo chamaeleon
+n01695060 Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis
+n01697457 African crocodile, Nile crocodile, Crocodylus niloticus
+n01698640 American alligator, Alligator mississipiensis
+n01704323 triceratops
+n01728572 thunder snake, worm snake, Carphophis amoenus
+n01728920 ringneck snake, ring-necked snake, ring snake
+n01729322 hognose snake, puff adder, sand viper
+n01729977 green snake, grass snake
+n01734418 king snake, kingsnake
+n01735189 garter snake, grass snake
+n01737021 water snake
+n01739381 vine snake
+n01740131 night snake, Hypsiglena torquata
+n01742172 boa constrictor, Constrictor constrictor
+n01744401 rock python, rock snake, Python sebae
+n01748264 Indian cobra, Naja naja
+n01749939 green mamba
+n01751748 sea snake
+n01753488 horned viper, cerastes, sand viper, horned asp, Cerastes cornutus
+n01755581 diamondback, diamondback rattlesnake, Crotalus adamanteus
+n01756291 sidewinder, horned rattlesnake, Crotalus cerastes
+n01768244 trilobite
+n01770081 harvestman, daddy longlegs, Phalangium opilio
+n01770393 scorpion
+n01773157 black and gold garden spider, Argiope aurantia
+n01773549 barn spider, Araneus cavaticus
+n01773797 garden spider, Aranea diademata
+n01774384 black widow, Latrodectus mactans
+n01774750 tarantula
+n01775062 wolf spider, hunting spider
+n01776313 tick
+n01784675 centipede
+n01795545 black grouse
+n01796340 ptarmigan
+n01797886 ruffed grouse, partridge, Bonasa umbellus
+n01798484 prairie chicken, prairie grouse, prairie fowl
+n01806143 peacock
+n01806567 quail
+n01807496 partridge
+n01817953 African grey, African gray, Psittacus erithacus
+n01818515 macaw
+n01819313 sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita
+n01820546 lorikeet
+n01824575 coucal
+n01828970 bee eater
+n01829413 hornbill
+n01833805 hummingbird
+n01843065 jacamar
+n01843383 toucan
+n01847000 drake
+n01855032 red-breasted merganser, Mergus serrator
+n01855672 goose
+n01860187 black swan, Cygnus atratus
+n01871265 tusker
+n01872401 echidna, spiny anteater, anteater
+n01873310 platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus
+n01877812 wallaby, brush kangaroo
+n01882714 koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus
+n01883070 wombat
+n01910747 jellyfish
+n01914609 sea anemone, anemone
+n01917289 brain coral
+n01924916 flatworm, platyhelminth
+n01930112 nematode, nematode worm, roundworm
+n01943899 conch
+n01944390 snail
+n01945685 slug
+n01950731 sea slug, nudibranch
+n01955084 chiton, coat-of-mail shell, sea cradle, polyplacophore
+n01968897 chambered nautilus, pearly nautilus, nautilus
+n01978287 Dungeness crab, Cancer magister
+n01978455 rock crab, Cancer irroratus
+n01980166 fiddler crab
+n01981276 king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica
+n01983481 American lobster, Northern lobster, Maine lobster, Homarus americanus
+n01984695 spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish
+n01985128 crayfish, crawfish, crawdad, crawdaddy
+n01986214 hermit crab
+n01990800 isopod
+n02002556 white stork, Ciconia ciconia
+n02002724 black stork, Ciconia nigra
+n02006656 spoonbill
+n02007558 flamingo
+n02009229 little blue heron, Egretta caerulea
+n02009912 American egret, great white heron, Egretta albus
+n02011460 bittern
+n02012849 crane
+n02013706 limpkin, Aramus pictus
+n02017213 European gallinule, Porphyrio porphyrio
+n02018207 American coot, marsh hen, mud hen, water hen, Fulica americana
+n02018795 bustard
+n02025239 ruddy turnstone, Arenaria interpres
+n02027492 red-backed sandpiper, dunlin, Erolia alpina
+n02028035 redshank, Tringa totanus
+n02033041 dowitcher
+n02037110 oystercatcher, oyster catcher
+n02051845 pelican
+n02056570 king penguin, Aptenodytes patagonica
+n02058221 albatross, mollymawk
+n02066245 grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus
+n02071294 killer whale, killer, orca, grampus, sea wolf, Orcinus orca
+n02074367 dugong, Dugong dugon
+n02077923 sea lion
+n02085620 Chihuahua
+n02085782 Japanese spaniel
+n02085936 Maltese dog, Maltese terrier, Maltese
+n02086079 Pekinese, Pekingese, Peke
+n02086240 Shih-Tzu
+n02086646 Blenheim spaniel
+n02086910 papillon
+n02087046 toy terrier
+n02087394 Rhodesian ridgeback
+n02088094 Afghan hound, Afghan
+n02088238 basset, basset hound
+n02088364 beagle
+n02088466 bloodhound, sleuthhound
+n02088632 bluetick
+n02089078 black-and-tan coonhound
+n02089867 Walker hound, Walker foxhound
+n02089973 English foxhound
+n02090379 redbone
+n02090622 borzoi, Russian wolfhound
+n02090721 Irish wolfhound
+n02091032 Italian greyhound
+n02091134 whippet
+n02091244 Ibizan hound, Ibizan Podenco
+n02091467 Norwegian elkhound, elkhound
+n02091635 otterhound, otter hound
+n02091831 Saluki, gazelle hound
+n02092002 Scottish deerhound, deerhound
+n02092339 Weimaraner
+n02093256 Staffordshire bullterrier, Staffordshire bull terrier
+n02093428 American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier
+n02093647 Bedlington terrier
+n02093754 Border terrier
+n02093859 Kerry blue terrier
+n02093991 Irish terrier
+n02094114 Norfolk terrier
+n02094258 Norwich terrier
+n02094433 Yorkshire terrier
+n02095314 wire-haired fox terrier
+n02095570 Lakeland terrier
+n02095889 Sealyham terrier, Sealyham
+n02096051 Airedale, Airedale terrier
+n02096177 cairn, cairn terrier
+n02096294 Australian terrier
+n02096437 Dandie Dinmont, Dandie Dinmont terrier
+n02096585 Boston bull, Boston terrier
+n02097047 miniature schnauzer
+n02097130 giant schnauzer
+n02097209 standard schnauzer
+n02097298 Scotch terrier, Scottish terrier, Scottie
+n02097474 Tibetan terrier, chrysanthemum dog
+n02097658 silky terrier, Sydney silky
+n02098105 soft-coated wheaten terrier
+n02098286 West Highland white terrier
+n02098413 Lhasa, Lhasa apso
+n02099267 flat-coated retriever
+n02099429 curly-coated retriever
+n02099601 golden retriever
+n02099712 Labrador retriever
+n02099849 Chesapeake Bay retriever
+n02100236 German short-haired pointer
+n02100583 vizsla, Hungarian pointer
+n02100735 English setter
+n02100877 Irish setter, red setter
+n02101006 Gordon setter
+n02101388 Brittany spaniel
+n02101556 clumber, clumber spaniel
+n02102040 English springer, English springer spaniel
+n02102177 Welsh springer spaniel
+n02102318 cocker spaniel, English cocker spaniel, cocker
+n02102480 Sussex spaniel
+n02102973 Irish water spaniel
+n02104029 kuvasz
+n02104365 schipperke
+n02105056 groenendael
+n02105162 malinois
+n02105251 briard
+n02105412 kelpie
+n02105505 komondor
+n02105641 Old English sheepdog, bobtail
+n02105855 Shetland sheepdog, Shetland sheep dog, Shetland
+n02106030 collie
+n02106166 Border collie
+n02106382 Bouvier des Flandres, Bouviers des Flandres
+n02106550 Rottweiler
+n02106662 German shepherd, German shepherd dog, German police dog, alsatian
+n02107142 Doberman, Doberman pinscher
+n02107312 miniature pinscher
+n02107574 Greater Swiss Mountain dog
+n02107683 Bernese mountain dog
+n02107908 Appenzeller
+n02108000 EntleBucher
+n02108089 boxer
+n02108422 bull mastiff
+n02108551 Tibetan mastiff
+n02108915 French bulldog
+n02109047 Great Dane
+n02109525 Saint Bernard, St Bernard
+n02109961 Eskimo dog, husky
+n02110063 malamute, malemute, Alaskan malamute
+n02110185 Siberian husky
+n02110341 dalmatian, coach dog, carriage dog
+n02110627 affenpinscher, monkey pinscher, monkey dog
+n02110806 basenji
+n02110958 pug, pug-dog
+n02111129 Leonberg
+n02111277 Newfoundland, Newfoundland dog
+n02111500 Great Pyrenees
+n02111889 Samoyed, Samoyede
+n02112018 Pomeranian
+n02112137 chow, chow chow
+n02112350 keeshond
+n02112706 Brabancon griffon
+n02113023 Pembroke, Pembroke Welsh corgi
+n02113186 Cardigan, Cardigan Welsh corgi
+n02113624 toy poodle
+n02113712 miniature poodle
+n02113799 standard poodle
+n02113978 Mexican hairless
+n02114367 timber wolf, grey wolf, gray wolf, Canis lupus
+n02114548 white wolf, Arctic wolf, Canis lupus tundrarum
+n02114712 red wolf, maned wolf, Canis rufus, Canis niger
+n02114855 coyote, prairie wolf, brush wolf, Canis latrans
+n02115641 dingo, warrigal, warragal, Canis dingo
+n02115913 dhole, Cuon alpinus
+n02116738 African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus
+n02117135 hyena, hyaena
+n02119022 red fox, Vulpes vulpes
+n02119789 kit fox, Vulpes macrotis
+n02120079 Arctic fox, white fox, Alopex lagopus
+n02120505 grey fox, gray fox, Urocyon cinereoargenteus
+n02123045 tabby, tabby cat
+n02123159 tiger cat
+n02123394 Persian cat
+n02123597 Siamese cat, Siamese
+n02124075 Egyptian cat
+n02125311 cougar, puma, catamount, mountain lion, painter, panther, Felis concolor
+n02127052 lynx, catamount
+n02128385 leopard, Panthera pardus
+n02128757 snow leopard, ounce, Panthera uncia
+n02128925 jaguar, panther, Panthera onca, Felis onca
+n02129165 lion, king of beasts, Panthera leo
+n02129604 tiger, Panthera tigris
+n02130308 cheetah, chetah, Acinonyx jubatus
+n02132136 brown bear, bruin, Ursus arctos
+n02133161 American black bear, black bear, Ursus americanus, Euarctos americanus
+n02134084 ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus
+n02134418 sloth bear, Melursus ursinus, Ursus ursinus
+n02137549 mongoose
+n02138441 meerkat, mierkat
+n02165105 tiger beetle
+n02165456 ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle
+n02167151 ground beetle, carabid beetle
+n02168699 long-horned beetle, longicorn, longicorn beetle
+n02169497 leaf beetle, chrysomelid
+n02172182 dung beetle
+n02174001 rhinoceros beetle
+n02177972 weevil
+n02190166 fly
+n02206856 bee
+n02219486 ant, emmet, pismire
+n02226429 grasshopper, hopper
+n02229544 cricket
+n02231487 walking stick, walkingstick, stick insect
+n02233338 cockroach, roach
+n02236044 mantis, mantid
+n02256656 cicada, cicala
+n02259212 leafhopper
+n02264363 lacewing, lacewing fly
+n02268443 dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk
+n02268853 damselfly
+n02276258 admiral
+n02277742 ringlet, ringlet butterfly
+n02279972 monarch, monarch butterfly, milkweed butterfly, Danaus plexippus
+n02280649 cabbage butterfly
+n02281406 sulphur butterfly, sulfur butterfly
+n02281787 lycaenid, lycaenid butterfly
+n02317335 starfish, sea star
+n02319095 sea urchin
+n02321529 sea cucumber, holothurian
+n02325366 wood rabbit, cottontail, cottontail rabbit
+n02326432 hare
+n02328150 Angora, Angora rabbit
+n02342885 hamster
+n02346627 porcupine, hedgehog
+n02356798 fox squirrel, eastern fox squirrel, Sciurus niger
+n02361337 marmot
+n02363005 beaver
+n02364673 guinea pig, Cavia cobaya
+n02389026 sorrel
+n02391049 zebra
+n02395406 hog, pig, grunter, squealer, Sus scrofa
+n02396427 wild boar, boar, Sus scrofa
+n02397096 warthog
+n02398521 hippopotamus, hippo, river horse, Hippopotamus amphibius
+n02403003 ox
+n02408429 water buffalo, water ox, Asiatic buffalo, Bubalus bubalis
+n02410509 bison
+n02412080 ram, tup
+n02415577 bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis
+n02417914 ibex, Capra ibex
+n02422106 hartebeest
+n02422699 impala, Aepyceros melampus
+n02423022 gazelle
+n02437312 Arabian camel, dromedary, Camelus dromedarius
+n02437616 llama
+n02441942 weasel
+n02442845 mink
+n02443114 polecat, fitch, foulmart, foumart, Mustela putorius
+n02443484 black-footed ferret, ferret, Mustela nigripes
+n02444819 otter
+n02445715 skunk, polecat, wood pussy
+n02447366 badger
+n02454379 armadillo
+n02457408 three-toed sloth, ai, Bradypus tridactylus
+n02480495 orangutan, orang, orangutang, Pongo pygmaeus
+n02480855 gorilla, Gorilla gorilla
+n02481823 chimpanzee, chimp, Pan troglodytes
+n02483362 gibbon, Hylobates lar
+n02483708 siamang, Hylobates syndactylus, Symphalangus syndactylus
+n02484975 guenon, guenon monkey
+n02486261 patas, hussar monkey, Erythrocebus patas
+n02486410 baboon
+n02487347 macaque
+n02488291 langur
+n02488702 colobus, colobus monkey
+n02489166 proboscis monkey, Nasalis larvatus
+n02490219 marmoset
+n02492035 capuchin, ringtail, Cebus capucinus
+n02492660 howler monkey, howler
+n02493509 titi, titi monkey
+n02493793 spider monkey, Ateles geoffroyi
+n02494079 squirrel monkey, Saimiri sciureus
+n02497673 Madagascar cat, ring-tailed lemur, Lemur catta
+n02500267 indri, indris, Indri indri, Indri brevicaudatus
+n02504013 Indian elephant, Elephas maximus
+n02504458 African elephant, Loxodonta africana
+n02509815 lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens
+n02510455 giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca
+n02514041 barracouta, snoek
+n02526121 eel
+n02536864 coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch
+n02606052 rock beauty, Holocanthus tricolor
+n02607072 anemone fish
+n02640242 sturgeon
+n02641379 gar, garfish, garpike, billfish, Lepisosteus osseus
+n02643566 lionfish
+n02655020 puffer, pufferfish, blowfish, globefish
+n02666196 abacus
+n02667093 abaya
+n02669723 academic gown, academic robe, judge's robe
+n02672831 accordion, piano accordion, squeeze box
+n02676566 acoustic guitar
+n02687172 aircraft carrier, carrier, flattop, attack aircraft carrier
+n02690373 airliner
+n02692877 airship, dirigible
+n02699494 altar
+n02701002 ambulance
+n02704792 amphibian, amphibious vehicle
+n02708093 analog clock
+n02727426 apiary, bee house
+n02730930 apron
+n02747177 ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin
+n02749479 assault rifle, assault gun
+n02769748 backpack, back pack, knapsack, packsack, rucksack, haversack
+n02776631 bakery, bakeshop, bakehouse
+n02777292 balance beam, beam
+n02782093 balloon
+n02783161 ballpoint, ballpoint pen, ballpen, Biro
+n02786058 Band Aid
+n02787622 banjo
+n02788148 bannister, banister, balustrade, balusters, handrail
+n02790996 barbell
+n02791124 barber chair
+n02791270 barbershop
+n02793495 barn
+n02794156 barometer
+n02795169 barrel, cask
+n02797295 barrow, garden cart, lawn cart, wheelbarrow
+n02799071 baseball
+n02802426 basketball
+n02804414 bassinet
+n02804610 bassoon
+n02807133 bathing cap, swimming cap
+n02808304 bath towel
+n02808440 bathtub, bathing tub, bath, tub
+n02814533 beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon
+n02814860 beacon, lighthouse, beacon light, pharos
+n02815834 beaker
+n02817516 bearskin, busby, shako
+n02823428 beer bottle
+n02823750 beer glass
+n02825657 bell cote, bell cot
+n02834397 bib
+n02835271 bicycle-built-for-two, tandem bicycle, tandem
+n02837789 bikini, two-piece
+n02840245 binder, ring-binder
+n02841315 binoculars, field glasses, opera glasses
+n02843684 birdhouse
+n02859443 boathouse
+n02860847 bobsled, bobsleigh, bob
+n02865351 bolo tie, bolo, bola tie, bola
+n02869837 bonnet, poke bonnet
+n02870880 bookcase
+n02871525 bookshop, bookstore, bookstall
+n02877765 bottlecap
+n02879718 bow
+n02883205 bow tie, bow-tie, bowtie
+n02892201 brass, memorial tablet, plaque
+n02892767 brassiere, bra, bandeau
+n02894605 breakwater, groin, groyne, mole, bulwark, seawall, jetty
+n02895154 breastplate, aegis, egis
+n02906734 broom
+n02909870 bucket, pail
+n02910353 buckle
+n02916936 bulletproof vest
+n02917067 bullet train, bullet
+n02927161 butcher shop, meat market
+n02930766 cab, hack, taxi, taxicab
+n02939185 caldron, cauldron
+n02948072 candle, taper, wax light
+n02950826 cannon
+n02951358 canoe
+n02951585 can opener, tin opener
+n02963159 cardigan
+n02965783 car mirror
+n02966193 carousel, carrousel, merry-go-round, roundabout, whirligig
+n02966687 carpenter's kit, tool kit
+n02971356 carton
+n02974003 car wheel
+n02977058 cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM
+n02978881 cassette
+n02979186 cassette player
+n02980441 castle
+n02981792 catamaran
+n02988304 CD player
+n02992211 cello, violoncello
+n02992529 cellular telephone, cellular phone, cellphone, cell, mobile phone
+n02999410 chain
+n03000134 chainlink fence
+n03000247 chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour
+n03000684 chain saw, chainsaw
+n03014705 chest
+n03016953 chiffonier, commode
+n03017168 chime, bell, gong
+n03018349 china cabinet, china closet
+n03026506 Christmas stocking
+n03028079 church, church building
+n03032252 cinema, movie theater, movie theatre, movie house, picture palace
+n03041632 cleaver, meat cleaver, chopper
+n03042490 cliff dwelling
+n03045698 cloak
+n03047690 clog, geta, patten, sabot
+n03062245 cocktail shaker
+n03063599 coffee mug
+n03063689 coffeepot
+n03065424 coil, spiral, volute, whorl, helix
+n03075370 combination lock
+n03085013 computer keyboard, keypad
+n03089624 confectionery, confectionary, candy store
+n03095699 container ship, containership, container vessel
+n03100240 convertible
+n03109150 corkscrew, bottle screw
+n03110669 cornet, horn, trumpet, trump
+n03124043 cowboy boot
+n03124170 cowboy hat, ten-gallon hat
+n03125729 cradle
+n03126707 crane
+n03127747 crash helmet
+n03127925 crate
+n03131574 crib, cot
+n03133878 Crock Pot
+n03134739 croquet ball
+n03141823 crutch
+n03146219 cuirass
+n03160309 dam, dike, dyke
+n03179701 desk
+n03180011 desktop computer
+n03187595 dial telephone, dial phone
+n03188531 diaper, nappy, napkin
+n03196217 digital clock
+n03197337 digital watch
+n03201208 dining table, board
+n03207743 dishrag, dishcloth
+n03207941 dishwasher, dish washer, dishwashing machine
+n03208938 disk brake, disc brake
+n03216828 dock, dockage, docking facility
+n03218198 dogsled, dog sled, dog sleigh
+n03220513 dome
+n03223299 doormat, welcome mat
+n03240683 drilling platform, offshore rig
+n03249569 drum, membranophone, tympan
+n03250847 drumstick
+n03255030 dumbbell
+n03259280 Dutch oven
+n03271574 electric fan, blower
+n03272010 electric guitar
+n03272562 electric locomotive
+n03290653 entertainment center
+n03291819 envelope
+n03297495 espresso maker
+n03314780 face powder
+n03325584 feather boa, boa
+n03337140 file, file cabinet, filing cabinet
+n03344393 fireboat
+n03345487 fire engine, fire truck
+n03347037 fire screen, fireguard
+n03355925 flagpole, flagstaff
+n03372029 flute, transverse flute
+n03376595 folding chair
+n03379051 football helmet
+n03384352 forklift
+n03388043 fountain
+n03388183 fountain pen
+n03388549 four-poster
+n03393912 freight car
+n03394916 French horn, horn
+n03400231 frying pan, frypan, skillet
+n03404251 fur coat
+n03417042 garbage truck, dustcart
+n03424325 gasmask, respirator, gas helmet
+n03425413 gas pump, gasoline pump, petrol pump, island dispenser
+n03443371 goblet
+n03444034 go-kart
+n03445777 golf ball
+n03445924 golfcart, golf cart
+n03447447 gondola
+n03447721 gong, tam-tam
+n03450230 gown
+n03452741 grand piano, grand
+n03457902 greenhouse, nursery, glasshouse
+n03459775 grille, radiator grille
+n03461385 grocery store, grocery, food market, market
+n03467068 guillotine
+n03476684 hair slide
+n03476991 hair spray
+n03478589 half track
+n03481172 hammer
+n03482405 hamper
+n03483316 hand blower, blow dryer, blow drier, hair dryer, hair drier
+n03485407 hand-held computer, hand-held microcomputer
+n03485794 handkerchief, hankie, hanky, hankey
+n03492542 hard disc, hard disk, fixed disk
+n03494278 harmonica, mouth organ, harp, mouth harp
+n03495258 harp
+n03496892 harvester, reaper
+n03498962 hatchet
+n03527444 holster
+n03529860 home theater, home theatre
+n03530642 honeycomb
+n03532672 hook, claw
+n03534580 hoopskirt, crinoline
+n03535780 horizontal bar, high bar
+n03538406 horse cart, horse-cart
+n03544143 hourglass
+n03584254 iPod
+n03584829 iron, smoothing iron
+n03590841 jack-o'-lantern
+n03594734 jean, blue jean, denim
+n03594945 jeep, landrover
+n03595614 jersey, T-shirt, tee shirt
+n03598930 jigsaw puzzle
+n03599486 jinrikisha, ricksha, rickshaw
+n03602883 joystick
+n03617480 kimono
+n03623198 knee pad
+n03627232 knot
+n03630383 lab coat, laboratory coat
+n03633091 ladle
+n03637318 lampshade, lamp shade
+n03642806 laptop, laptop computer
+n03649909 lawn mower, mower
+n03657121 lens cap, lens cover
+n03658185 letter opener, paper knife, paperknife
+n03661043 library
+n03662601 lifeboat
+n03666591 lighter, light, igniter, ignitor
+n03670208 limousine, limo
+n03673027 liner, ocean liner
+n03676483 lipstick, lip rouge
+n03680355 Loafer
+n03690938 lotion
+n03691459 loudspeaker, speaker, speaker unit, loudspeaker system, speaker system
+n03692522 loupe, jeweler's loupe
+n03697007 lumbermill, sawmill
+n03706229 magnetic compass
+n03709823 mailbag, postbag
+n03710193 mailbox, letter box
+n03710637 maillot
+n03710721 maillot, tank suit
+n03717622 manhole cover
+n03720891 maraca
+n03721384 marimba, xylophone
+n03724870 mask
+n03729826 matchstick
+n03733131 maypole
+n03733281 maze, labyrinth
+n03733805 measuring cup
+n03742115 medicine chest, medicine cabinet
+n03743016 megalith, megalithic structure
+n03759954 microphone, mike
+n03761084 microwave, microwave oven
+n03763968 military uniform
+n03764736 milk can
+n03769881 minibus
+n03770439 miniskirt, mini
+n03770679 minivan
+n03773504 missile
+n03775071 mitten
+n03775546 mixing bowl
+n03776460 mobile home, manufactured home
+n03777568 Model T
+n03777754 modem
+n03781244 monastery
+n03782006 monitor
+n03785016 moped
+n03786901 mortar
+n03787032 mortarboard
+n03788195 mosque
+n03788365 mosquito net
+n03791053 motor scooter, scooter
+n03792782 mountain bike, all-terrain bike, off-roader
+n03792972 mountain tent
+n03793489 mouse, computer mouse
+n03794056 mousetrap
+n03796401 moving van
+n03803284 muzzle
+n03804744 nail
+n03814639 neck brace
+n03814906 necklace
+n03825788 nipple
+n03832673 notebook, notebook computer
+n03837869 obelisk
+n03838899 oboe, hautboy, hautbois
+n03840681 ocarina, sweet potato
+n03841143 odometer, hodometer, mileometer, milometer
+n03843555 oil filter
+n03854065 organ, pipe organ
+n03857828 oscilloscope, scope, cathode-ray oscilloscope, CRO
+n03866082 overskirt
+n03868242 oxcart
+n03868863 oxygen mask
+n03871628 packet
+n03873416 paddle, boat paddle
+n03874293 paddlewheel, paddle wheel
+n03874599 padlock
+n03876231 paintbrush
+n03877472 pajama, pyjama, pj's, jammies
+n03877845 palace
+n03884397 panpipe, pandean pipe, syrinx
+n03887697 paper towel
+n03888257 parachute, chute
+n03888605 parallel bars, bars
+n03891251 park bench
+n03891332 parking meter
+n03895866 passenger car, coach, carriage
+n03899768 patio, terrace
+n03902125 pay-phone, pay-station
+n03903868 pedestal, plinth, footstall
+n03908618 pencil box, pencil case
+n03908714 pencil sharpener
+n03916031 perfume, essence
+n03920288 Petri dish
+n03924679 photocopier
+n03929660 pick, plectrum, plectron
+n03929855 pickelhaube
+n03930313 picket fence, paling
+n03930630 pickup, pickup truck
+n03933933 pier
+n03935335 piggy bank, penny bank
+n03937543 pill bottle
+n03938244 pillow
+n03942813 ping-pong ball
+n03944341 pinwheel
+n03947888 pirate, pirate ship
+n03950228 pitcher, ewer
+n03954731 plane, carpenter's plane, woodworking plane
+n03956157 planetarium
+n03958227 plastic bag
+n03961711 plate rack
+n03967562 plow, plough
+n03970156 plunger, plumber's helper
+n03976467 Polaroid camera, Polaroid Land camera
+n03976657 pole
+n03977966 police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria
+n03980874 poncho
+n03982430 pool table, billiard table, snooker table
+n03983396 pop bottle, soda bottle
+n03991062 pot, flowerpot
+n03992509 potter's wheel
+n03995372 power drill
+n03998194 prayer rug, prayer mat
+n04004767 printer
+n04005630 prison, prison house
+n04008634 projectile, missile
+n04009552 projector
+n04019541 puck, hockey puck
+n04023962 punching bag, punch bag, punching ball, punchball
+n04026417 purse
+n04033901 quill, quill pen
+n04033995 quilt, comforter, comfort, puff
+n04037443 racer, race car, racing car
+n04039381 racket, racquet
+n04040759 radiator
+n04041544 radio, wireless
+n04044716 radio telescope, radio reflector
+n04049303 rain barrel
+n04065272 recreational vehicle, RV, R.V.
+n04067472 reel
+n04069434 reflex camera
+n04070727 refrigerator, icebox
+n04074963 remote control, remote
+n04081281 restaurant, eating house, eating place, eatery
+n04086273 revolver, six-gun, six-shooter
+n04090263 rifle
+n04099969 rocking chair, rocker
+n04111531 rotisserie
+n04116512 rubber eraser, rubber, pencil eraser
+n04118538 rugby ball
+n04118776 rule, ruler
+n04120489 running shoe
+n04125021 safe
+n04127249 safety pin
+n04131690 saltshaker, salt shaker
+n04133789 sandal
+n04136333 sarong
+n04141076 sax, saxophone
+n04141327 scabbard
+n04141975 scale, weighing machine
+n04146614 school bus
+n04147183 schooner
+n04149813 scoreboard
+n04152593 screen, CRT screen
+n04153751 screw
+n04154565 screwdriver
+n04162706 seat belt, seatbelt
+n04179913 sewing machine
+n04192698 shield, buckler
+n04200800 shoe shop, shoe-shop, shoe store
+n04201297 shoji
+n04204238 shopping basket
+n04204347 shopping cart
+n04208210 shovel
+n04209133 shower cap
+n04209239 shower curtain
+n04228054 ski
+n04229816 ski mask
+n04235860 sleeping bag
+n04238763 slide rule, slipstick
+n04239074 sliding door
+n04243546 slot, one-armed bandit
+n04251144 snorkel
+n04252077 snowmobile
+n04252225 snowplow, snowplough
+n04254120 soap dispenser
+n04254680 soccer ball
+n04254777 sock
+n04258138 solar dish, solar collector, solar furnace
+n04259630 sombrero
+n04263257 soup bowl
+n04264628 space bar
+n04265275 space heater
+n04266014 space shuttle
+n04270147 spatula
+n04273569 speedboat
+n04275548 spider web, spider's web
+n04277352 spindle
+n04285008 sports car, sport car
+n04286575 spotlight, spot
+n04296562 stage
+n04310018 steam locomotive
+n04311004 steel arch bridge
+n04311174 steel drum
+n04317175 stethoscope
+n04325704 stole
+n04326547 stone wall
+n04328186 stopwatch, stop watch
+n04330267 stove
+n04332243 strainer
+n04335435 streetcar, tram, tramcar, trolley, trolley car
+n04336792 stretcher
+n04344873 studio couch, day bed
+n04346328 stupa, tope
+n04347754 submarine, pigboat, sub, U-boat
+n04350905 suit, suit of clothes
+n04355338 sundial
+n04355933 sunglass
+n04356056 sunglasses, dark glasses, shades
+n04357314 sunscreen, sunblock, sun blocker
+n04366367 suspension bridge
+n04367480 swab, swob, mop
+n04370456 sweatshirt
+n04371430 swimming trunks, bathing trunks
+n04371774 swing
+n04372370 switch, electric switch, electrical switch
+n04376876 syringe
+n04380533 table lamp
+n04389033 tank, army tank, armored combat vehicle, armoured combat vehicle
+n04392985 tape player
+n04398044 teapot
+n04399382 teddy, teddy bear
+n04404412 television, television system
+n04409515 tennis ball
+n04417672 thatch, thatched roof
+n04418357 theater curtain, theatre curtain
+n04423845 thimble
+n04428191 thresher, thrasher, threshing machine
+n04429376 throne
+n04435653 tile roof
+n04442312 toaster
+n04443257 tobacco shop, tobacconist shop, tobacconist
+n04447861 toilet seat
+n04456115 torch
+n04458633 totem pole
+n04461696 tow truck, tow car, wrecker
+n04462240 toyshop
+n04465501 tractor
+n04467665 trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi
+n04476259 tray
+n04479046 trench coat
+n04482393 tricycle, trike, velocipede
+n04483307 trimaran
+n04485082 tripod
+n04486054 triumphal arch
+n04487081 trolleybus, trolley coach, trackless trolley
+n04487394 trombone
+n04493381 tub, vat
+n04501370 turnstile
+n04505470 typewriter keyboard
+n04507155 umbrella
+n04509417 unicycle, monocycle
+n04515003 upright, upright piano
+n04517823 vacuum, vacuum cleaner
+n04522168 vase
+n04523525 vault
+n04525038 velvet
+n04525305 vending machine
+n04532106 vestment
+n04532670 viaduct
+n04536866 violin, fiddle
+n04540053 volleyball
+n04542943 waffle iron
+n04548280 wall clock
+n04548362 wallet, billfold, notecase, pocketbook
+n04550184 wardrobe, closet, press
+n04552348 warplane, military plane
+n04553703 washbasin, handbasin, washbowl, lavabo, wash-hand basin
+n04554684 washer, automatic washer, washing machine
+n04557648 water bottle
+n04560804 water jug
+n04562935 water tower
+n04579145 whiskey jug
+n04579432 whistle
+n04584207 wig
+n04589890 window screen
+n04590129 window shade
+n04591157 Windsor tie
+n04591713 wine bottle
+n04592741 wing
+n04596742 wok
+n04597913 wooden spoon
+n04599235 wool, woolen, woollen
+n04604644 worm fence, snake fence, snake-rail fence, Virginia fence
+n04606251 wreck
+n04612504 yawl
+n04613696 yurt
+n06359193 web site, website, internet site, site
+n06596364 comic book
+n06785654 crossword puzzle, crossword
+n06794110 street sign
+n06874185 traffic light, traffic signal, stoplight
+n07248320 book jacket, dust cover, dust jacket, dust wrapper
+n07565083 menu
+n07579787 plate
+n07583066 guacamole
+n07584110 consomme
+n07590611 hot pot, hotpot
+n07613480 trifle
+n07614500 ice cream, icecream
+n07615774 ice lolly, lolly, lollipop, popsicle
+n07684084 French loaf
+n07693725 bagel, beigel
+n07695742 pretzel
+n07697313 cheeseburger
+n07697537 hotdog, hot dog, red hot
+n07711569 mashed potato
+n07714571 head cabbage
+n07714990 broccoli
+n07715103 cauliflower
+n07716358 zucchini, courgette
+n07716906 spaghetti squash
+n07717410 acorn squash
+n07717556 butternut squash
+n07718472 cucumber, cuke
+n07718747 artichoke, globe artichoke
+n07720875 bell pepper
+n07730033 cardoon
+n07734744 mushroom
+n07742313 Granny Smith
+n07745940 strawberry
+n07747607 orange
+n07749582 lemon
+n07753113 fig
+n07753275 pineapple, ananas
+n07753592 banana
+n07754684 jackfruit, jak, jack
+n07760859 custard apple
+n07768694 pomegranate
+n07802026 hay
+n07831146 carbonara
+n07836838 chocolate sauce, chocolate syrup
+n07860988 dough
+n07871810 meat loaf, meatloaf
+n07873807 pizza, pizza pie
+n07875152 potpie
+n07880968 burrito
+n07892512 red wine
+n07920052 espresso
+n07930864 cup
+n07932039 eggnog
+n09193705 alp
+n09229709 bubble
+n09246464 cliff, drop, drop-off
+n09256479 coral reef
+n09288635 geyser
+n09332890 lakeside, lakeshore
+n09399592 promontory, headland, head, foreland
+n09421951 sandbar, sand bar
+n09428293 seashore, coast, seacoast, sea-coast
+n09468604 valley, vale
+n09472597 volcano
+n09835506 ballplayer, baseball player
+n10148035 groom, bridegroom
+n10565667 scuba diver
+n11879895 rapeseed
+n11939491 daisy
+n12057211 yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum
+n12144580 corn
+n12267677 acorn
+n12620546 hip, rose hip, rosehip
+n12768682 buckeye, horse chestnut, conker
+n12985857 coral fungus
+n12998815 agaric
+n13037406 gyromitra
+n13040303 stinkhorn, carrion fungus
+n13044778 earthstar
+n13052670 hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa
+n13054560 bolete
+n13133613 ear, spike, capitulum
+n15075141 toilet tissue, toilet paper, bathroom tissue
diff --git a/examples/x86/example_x86_rnn_net.cpp b/examples/x86/example_x86_rnn_net.cpp
new file mode 100644
index 0000000..3ba2d61
--- /dev/null
+++ b/examples/x86/example_x86_rnn_net.cpp
@@ -0,0 +1,56 @@
+
+#include "utils/logger/logger.h"
+#include "graph.h"
+#include "net.h"
+
+#ifdef USE_X86_PLACE
+/*util to fill tensor*/
+#include "saber/core/tensor_op.h"
+using namespace anakin;
+using namespace anakin::graph;
+using namespace anakin::saber;
+
+int main(int argc, const char** argv) {
+    /*init graph object, graph is the skeleton of model*/
+    Graph<X86, AK_FLOAT, Precision::FP32> graph;
+
+    /*load model from file to init the graph*/
+    auto status = graph.load("language_model.anakin2.bin");
+    if (!status) {
+        LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    /*set net input shape and use this shape to optimize the graph(fusion and init operator), shape is n,c,h,w. n=sum of words*/
+    graph.Reshape("input_0", {30, 1, 1, 1});
+    graph.Optimize();
+
+    /*net_executer is the executor object of model. use graph to init Net*/
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(graph, true);
+
+    /*use input string to get the input tensor of net. for we use X86 as target, the tensor of net_executer is on host memory*/
+    auto h_tensor_in_p = net_executer.get_in("input_0");
+
+    /*init host tensor by continue int*/
+    fill_tensor_host_seq(*h_tensor_in_p);
+
+    /*seq offset of tensor means offset of sentence, 0,10,15,30 means sentence0 = 0-9, sentence 1 =  10-14, sentence2 = 15-29*/
+    h_tensor_in_p->set_seq_offset({0,10,15,30});
+
+
+    /*run infer*/
+    net_executer.prediction();
+
+    LOG(INFO)<<"infer finash";
+
+    /*get the out put of net, which is a host tensor*/
+    auto h_out=net_executer.get_out("fc_1.tmp_2_out");
+
+
+    /*show some output content*/
+    for(int i=0;i<10;i++){
+        LOG(INFO)<<"out ["<<i<<"] = "<<h_out->data()[i];
+    }
+}
+#else
+int main(){}
+#endif
\ No newline at end of file
diff --git a/framework/CMakeLists.txt b/framework/CMakeLists.txt
index 429c819..47cf6ed 100644
--- a/framework/CMakeLists.txt
+++ b/framework/CMakeLists.txt
@@ -1,16 +1,24 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     CMakeLists files in the framework directory of project
-# @auther   cuichaowen
-# @date     2017-10-24
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+anakin_fetch_include_recursively(${ANAKIN_SABER})
+anakin_fetch_include_recursively(${ANAKIN_MODEL_PARSER})
+anakin_fetch_include_recursively(${ANAKIN_UTILS})
 anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK}/core)
 anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK}/graph)
 anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK}/model_parser)
 anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK}/operators)
-anakin_fetch_include_recursively(${ANAKIN_SABER})
-anakin_fetch_include_recursively(${ANAKIN_MODEL_PARSER})
-anakin_fetch_include_recursively(${ANAKIN_UTILS})
+
 
 set(ANAKIN_BASE_SRC "")
 
@@ -51,8 +59,8 @@ if(UNIX OR APPLE)
 	endif()
 	if(BUILD_STATIC)
 		add_library(${anakin_lib_static} STATIC ${ANAKIN_SRC})
-		add_dependencies(${anakin_lib_static} ${ANAKIN_SABER_LIB_TARGET})
-		set_target_properties(${anakin_lib_static} PROPERTIES VERSION ${VERSION})
+		add_dependencies(${anakin_lib_static} ${ANAKIN_SABER_LIB_TARGET})# ${anakin_framework_static})
+		#set_target_properties(${anakin_lib_static} PROPERTIES VERSION ${VERSION})
 		target_link_libraries(${anakin_lib_static} ${ANAKIN_SABER_LIB_TARGET} ${ANAKIN_LINKER_LIBS})
         set_target_properties(${anakin_lib_static} PROPERTIES LINK_FLAGS "")
 		set_target_properties(${anakin_lib_static} PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${PROJECT_SOURCE_DIR}/output/)
diff --git a/framework/core/any.h b/framework/core/any.h
index 80fc038..bef1270 100644
--- a/framework/core/any.h
+++ b/framework/core/any.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/base.h b/framework/core/base.h
index dd59a11..6cf5d9f 100644
--- a/framework/core/base.h
+++ b/framework/core/base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/common_macros.h b/framework/core/common_macros.h
index d7f3c81..0c8b443 100644
--- a/framework/core/common_macros.h
+++ b/framework/core/common_macros.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/data_types.h b/framework/core/data_types.h
index f06db5b..496f1b6 100644
--- a/framework/core/data_types.h
+++ b/framework/core/data_types.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/factory.h b/framework/core/factory.h
index f91684f..81771b1 100644
--- a/framework/core/factory.h
+++ b/framework/core/factory.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -36,6 +36,9 @@ public:
         if (_container.count(type_id) == 0) {
             LOG(FATAL) << type_id << " has not been registered! ";
         }
+        //LOG(INFO) << "create " << type_id << " fuction " << &_container.at(type_id);
+        //auto ptr = _container.at(type_id)();
+        //return ptr;
         return (_container.at(type_id))();
     }
     void __ALIAS__(const TypeIdentifier& ori_type_id, const TypeIdentifier& type_id) {
@@ -51,9 +54,11 @@ public:
     bool Register(TypeIdentifier type_id, PolicyCreator creator) 
                                          EXCLUSIVE_LOCKS_REQUIRED(container_mutex_) {
         std::lock_guard<std::mutex> guard(container_mutex_);
-        CHECK_EQ(_container.count(type_id), 0) << type_id << " has not been registered! ";
-        _type_id_list.push_back(type_id);
-        _container[type_id] = creator;
+        //LOG(ERROR) << "register " << type_id;
+        if (_container.count(type_id) == 0) {
+            _type_id_list.push_back(type_id);
+            _container[type_id] = creator;
+        }
         return true;
     }
     void UnRegister(const TypeIdentifier& type_id) 
@@ -103,9 +108,8 @@ public:
     PolicyType* Get(const TypeIdentifier& type_id) {
         if (_container.count(type_id) == 0) {
             LOG(FATAL) << type_id << " has not been registered! ";
-        } else {
-            return _container.at(type_id);
         }
+        return _container.at(type_id);
     }
     void __ALIAS__(const TypeIdentifier& ori_type_id, const TypeIdentifier& type_id) {
         if (_container.count(ori_type_id) == 0) {
@@ -119,11 +123,17 @@ public:
     }
     PolicyType& Register(TypeIdentifier type_id) EXCLUSIVE_LOCKS_REQUIRED(_container_mutex) { 
         std::lock_guard<std::mutex> guard(_container_mutex); 
-        CHECK_EQ(_container.count(type_id), 0) << type_id << " has been registered! ";
-        PolicyType* object= new PolicyType();
-        _container[type_id] = object; 
-        _type_id_list.push_back(type_id);
-        return *object;
+        //CHECK_EQ(_container.count(type_id), 0) << type_id << " has been registered! ";
+        if (_container.count(type_id) == 0) {
+            PolicyType* object= new PolicyType();
+            _container[type_id] = object;
+            _type_id_list.push_back(type_id);
+            return *object;
+        } else {
+            PolicyType* object = _container[type_id];
+            return *object;
+        }
+
     }
     void UnRegister(const TypeIdentifier& type_id) EXCLUSIVE_LOCKS_REQUIRED(_container_mutex) {
         std::lock_guard<std::mutex> guard(_container_mutex);
diff --git a/framework/core/functor.h b/framework/core/functor.h
index 0e4232e..7aacdd9 100644
--- a/framework/core/functor.h
+++ b/framework/core/functor.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/mem_info.h b/framework/core/mem_info.h
new file mode 100644
index 0000000..6055621
--- /dev/null
+++ b/framework/core/mem_info.h
@@ -0,0 +1,63 @@
+/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_MEM_INFO_H
+#define ANAKIN_MEM_INFO_H 
+
+#include "framework/core/parameter.h"
+#include "framework/core/singleton.h"
+
+namespace anakin {
+
+/** 
+ *  \brief memory management
+ */
+template<typename Ttype>
+class MemInfo {
+public:
+	MemInfo() {}
+	~MemInfo() {}
+
+	/// get used mem in MB
+	double get_used_mem_in_mb() { 
+		return mem_used;
+	}
+
+private:
+	double mem_used{0.f}; ///< mem in mb
+	double mem_total{0.f}; //< mem in mb
+};
+
+#ifdef USE_CUDA
+template<>
+double MemInfo<NV>::get_used_mem_in_mb() {
+	size_t free_bytes;
+	size_t total_bytes;
+	auto cuda_status = cudaMemGetInfo(&free_bytes, &total_bytes);	
+	if(cudaSuccess != cuda_status) {
+		LOG(FATAL) <<" cudaMemGetInfo fails: %s" << cudaGetErrorString(cuda_status);
+	}
+	this->mem_used = (double)(total_bytes - free_bytes)/1e6;
+	this->mem_total = (double)total_bytes/1e6;
+	return this->mem_used;
+};
+#endif
+
+template<typename Ttype>
+using MemoryInfo= Singleton<MemInfo<Ttype>>;
+
+} /* namespace anakin */
+
+#endif
diff --git a/framework/core/net/net.cpp b/framework/core/net/net.cpp
index 66d1614..4baa15c 100644
--- a/framework/core/net/net.cpp
+++ b/framework/core/net/net.cpp
@@ -1,6 +1,8 @@
 #include "framework/core/net/net.h"
 #include "saber/funcs/timer.h"
 #include "saber/funcs/debug.h"
+#include "framework/core/mem_info.h"
+
 namespace anakin {
 
 template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
@@ -14,15 +16,15 @@ Net<Ttype, Dtype, Ptype, RunType>::~Net() {
 template<typename Ttype, DataType Dtype>
 double tensor_average(Tensor4dPtr<Ttype, Dtype>& out_tensor_p) {
     double sum = 0.0f;
-#ifdef USE_CUDA
-    float* h_data = new float[out_tensor_p->valid_size()];
-    const float* d_data = out_tensor_p->data();
-    CUDA_CHECK(cudaMemcpy(h_data, d_data, out_tensor_p->valid_size()*sizeof(float), cudaMemcpyDeviceToHost));
-#else
-	float* h_data = out_tensor_p->data();
-#endif
+    typedef typename DataTrait<Ttype, Dtype>::dtype dtype;
+    const dtype* hptr = nullptr;
+
+    Shape shin = out_tensor_p->valid_shape();
+    PBlock<dtype, Ttype> tensorptr(shin);
+    tensorptr.h_tensor().copy_from(*out_tensor_p);
+    hptr = tensorptr.h_tensor().data();
     for (int i=0; i<out_tensor_p->valid_size(); i++) {
-		sum+=h_data[i];
+		sum += hptr[i];
     }
     return sum/out_tensor_p->valid_size();
 }
@@ -37,20 +39,108 @@ template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
 Net<Ttype, Dtype, Ptype, RunType>::Net(graph::Graph<Ttype, Dtype, Ptype>& graph, bool need_summary) {
     _graph_p = new graph::Graph<Ttype, Dtype, Ptype>();
     _need_summary = need_summary;
-    init_env(graph);
+    //init_env(graph);
     init(graph);
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
+Net<Ttype, Dtype, Ptype, RunType>::Net(\
+    graph::Graph<Ttype, Dtype, Ptype>& graph, OpContextPtr<Ttype> ctx, bool need_summary) {
+    _graph_p = new graph::Graph<Ttype, Dtype, Ptype>();
+    _need_summary = need_summary;
+    //init_env(graph);
+    init(graph, ctx);
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
+void Net<Ttype, Dtype, Ptype, RunType>::init(graph::Graph<Ttype, Dtype, Ptype>& graph, \
+    OpContextPtr<Ttype> ctx) {
+
+    init_env(graph);
+    // shallow copy
+    _graph_p->CopyFrom(graph);
+    auto node_names_in_exec_order = graph.get_nodes_in_order();
+    // infer basic shape and parsing parameter from graph
+    for (auto& node_name : node_names_in_exec_order) {
+        auto node_ptr = (*_graph_p)[node_name];
+        //LOG(ERROR) << "get node " << node_name << ", op type " << node_ptr->get_op_name();
+        if (node_ptr->get_op_name() == "Output") {
+            continue;
+        }
+
+        // create operations
+        auto* op_pointer = OpFactory<Ttype, Dtype, Ptype>::Global()[node_ptr->get_op_name()];
+        if (op_pointer == nullptr) {
+            LOG(FATAL) << node_name << ", type " << node_ptr->get_op_name() << " is null";
+        }
+        node_ptr->set_op(op_pointer);
+        //LOG(ERROR) << "set op";
+        op_pointer = nullptr;
+
+        static_cast<Operator<Ttype, Dtype, Ptype>*>(node_ptr->Op())->_helper->BindParam(node_ptr);
+        //LOG(ERROR) << "bind param";
+        // parsing parameter
+        static_cast<Operator<Ttype, Dtype, Ptype>*>(node_ptr->Op())->_helper->InitParam();
+        //LOG(ERROR) << "init param";
+    }
+
+    // remove null op node
+    for (auto it = node_names_in_exec_order.begin(); it != node_names_in_exec_order.end(); ){
+        if (!(*_graph_p)[*it]->Op()) {
+            it = node_names_in_exec_order.erase(it);
+        } else {
+            ++it;
+        }
+    }
+    _exec_funcs.resize(node_names_in_exec_order.size());
+    for(int i = 0; i < node_names_in_exec_order.size(); i++) {
+        auto& node_name = node_names_in_exec_order[i];
+        auto& op_func = _exec_funcs[i];
+        op_func.name = node_name;
+        auto& edge_in_its = _graph_p->get_in_arc_its(node_name);
+        DLOG(ERROR) << " node : " << op_func.name << " (" << (*_graph_p)[node_name]->get_op_name() << ") ";
+        for(auto& edge_it : edge_in_its) {
+            DLOG(INFO) << "  => find in arc : " << edge_it->bottom() << "  -->  " << edge_it->top();
+            op_func.ins.push_back(edge_it->weight().get());
+            op_func.in_lanes.push_back(edge_it->lane());
+        }
+        auto& edge_out_its = _graph_p->get_out_arc_its(node_name);
+        for(auto& edge_it : edge_out_its) {
+            DLOG(INFO) << "  <= find out arc : " << edge_it->bottom() << "  -->  " << edge_it->top();
+            op_func.outs.push_back(edge_it->weight().get());
+            op_func.out_lanes.push_back(edge_it->lane());
+        }
+        op_func.current_lane = (*_graph_p)[node_name]->lane();
+        op_func.need_sync = (*_graph_p)[node_name]->need_wait();
+        op_func.op = static_cast<Operator<Ttype, Dtype, Ptype>* >((*_graph_p)[node_name]->Op());
+        op_func.op_name = (*_graph_p)[node_name]->get_op_name();
+        op_func.ctx_p = ctx;
+        // call init of operator
+        CHECK_NOTNULL(op_func.op) << "Node(node_name) doesn't have op pointer! ";
+
+        op_func.op->_helper->InferShape(op_func.ins, op_func.outs);
+        op_func.op->_helper->Init(*(op_func.ctx_p), op_func.ins, op_func.outs);
+    }
+    //LOG(ERROR) << "finish create op";
+
+    // init memory of _graph_p
+    init_memory();
+}
+
+
+template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
 void Net<Ttype, Dtype, Ptype, RunType>::init(graph::Graph<Ttype, Dtype, Ptype>& graph) {
     init_env(graph);
     // shallow copy
     _graph_p->CopyFrom(graph);
-     
+	
+	double curr_mem_in_mb_start = MemoryInfo<Ttype>::Global().get_used_mem_in_mb(); 
+
     auto node_names_in_exec_order = graph.get_nodes_in_order();
     // infer basic shape and parsing parameter from graph
     for (auto& node_name : node_names_in_exec_order) {
         auto node_ptr = (*_graph_p)[node_name];
+        //LOG(ERROR) << "get node " << node_name << ", op type " << node_ptr->get_op_name();
         if (node_ptr->get_op_name() == "Output") {
             continue;
         }
@@ -91,24 +181,33 @@ void Net<Ttype, Dtype, Ptype, RunType>::init(graph::Graph<Ttype, Dtype, Ptype>&
 
         // create operations
 #if defined(USE_CUDA)
-       	if (node_ptr->get_op_name() == "ConvBatchnormScaleRelu" || node_ptr->get_op_name() == "ConvRelu" || node_ptr->get_op_name() == "Convolution") {
-        std::string group = "group";
-        auto group_val =  node_ptr->template get_attr<int>(group);
-        if (group_val == 1) {
-            node_ptr->set_op(OpFactory<Ttype, Dtype, Ptype>::Global()["Sass"+node_ptr->get_op_name()]);
-            node_ptr->get_op_name() = "Sass" + node_ptr->get_op_name();
-        } else {
-            LOG(ERROR) << "node_ptr->get_op_name()  sass not support yet.";
-            auto* op_pointer = OpFactory<Ttype, Dtype, Ptype>::Global()[node_ptr->get_op_name()];
-            node_ptr->set_op(op_pointer);
-        }
+       	if (node_ptr->get_op_name() == "ConvBatchnormScale" || node_ptr->get_op_name() == "ConvBatchnormScaleRelu" || node_ptr->get_op_name() == "ConvRelu" || node_ptr->get_op_name() == "Convolution") {
+        	std::string group = "group";
+        	auto group_val =  node_ptr->template get_attr<int>(group);
+			using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+			std::string weight_name = "weight_1";
+			auto weights = node_ptr->template get_attr<pblock_type>(weight_name);
+			//int c = weights.d_tensor().channel();
+			
+        	if ((group_val == 1)) {
+            	node_ptr->set_op(OpFactory<Ttype, Dtype, Ptype>::Global()["Sass"+node_ptr->get_op_name()]);
+            	node_ptr->get_op_name() = "Sass" + node_ptr->get_op_name();
+        	} else {
+            	LOG(ERROR) << "node_ptr->get_op_name()  sass not support yet.";
+            	auto* op_pointer = OpFactory<Ttype, Dtype, Ptype>::Global()[node_ptr->get_op_name()];
+            	node_ptr->set_op(op_pointer);
+        	}
         } else {
             auto* op_pointer = OpFactory<Ttype, Dtype, Ptype>::Global()[node_ptr->get_op_name()];
             node_ptr->set_op(op_pointer);
         }
 #else
         auto* op_pointer = OpFactory<Ttype, Dtype, Ptype>::Global()[node_ptr->get_op_name()];
+        if (op_pointer == nullptr) {
+            LOG(FATAL) << node_name << ", type " << node_ptr->get_op_name() << " is null";
+        }
         node_ptr->set_op(op_pointer);
+        //LOG(ERROR) << "set op";
 		op_pointer = nullptr;
 #endif
         // bind parameter structure
@@ -161,19 +260,33 @@ void Net<Ttype, Dtype, Ptype, RunType>::init(graph::Graph<Ttype, Dtype, Ptype>&
                           << " " << in->valid_shape()[1] 
                           << " " << in->valid_shape()[2] 
                           << " " << in->valid_shape()[3];
+                LOG(INFO) <<"in offset size = "<<in->get_seq_offset().size();
         }
         for(auto& out : op_func.outs) {
                 LOG(INFO) << "  <= [shape]: " << out->valid_shape()[0] 
                           << " " << out->valid_shape()[1] 
                           << " " << out->valid_shape()[2] 
                           << " " << out->valid_shape()[3];
+                LOG(INFO) <<"out offset size = "<<out->get_seq_offset().size();
         }
+
 #endif
         op_func.op->_helper->Init(*(op_func.ctx_p), op_func.ins, op_func.outs);
+#ifdef ENABLE_DEBUG
+        DLOG(INFO)<<"op init success "<<op_func.name;
+#endif
     }
     
+	double curr_mem_in_mb_end = MemoryInfo<Ttype>::Global().get_used_mem_in_mb(); 
+	this->_graph_p->statistics.template set_info<graph::SYSTEM_MEM>(curr_mem_in_mb_end - curr_mem_in_mb_start);
     // init memory of _graph_p
     init_memory();
+	
+	graph.statistics = _graph_p->statistics; // copy statistic back
+	LOG(INFO) << "Temp mem used:        " << this->_graph_p->statistics.template get_info<graph::TEMP_MEM>() << " MB"; 
+	LOG(INFO) << "Original mem used:    " << this->_graph_p->statistics.template get_info<graph::ORI_TEMP_MEM>() << " MB";
+	LOG(INFO) << "Model mem used:       " << this->_graph_p->statistics.template get_info<graph::MODEL_MEM>() << " MB";
+	LOG(INFO) << "System mem used:      " << this->_graph_p->statistics.template get_info<graph::SYSTEM_MEM>() << " MB";
 #ifdef ENABLE_OP_TIMER
     _op_time = std::vector<float>(_exec_funcs.size(), 0.0f);
 #endif
@@ -207,6 +320,8 @@ void Net<Ttype, Dtype, Ptype, RunType>::prediction() {
 #ifdef ENABLE_OP_TIMER
     int op_id = 0;
 #endif
+
+    int i = 0;
     for(auto& executer : _exec_funcs) {
         if (RunType == OpRunType::SYNC || executer.need_sync) {
             for(int i = 0; i < executer.ins.size(); i++) {
@@ -227,7 +342,7 @@ void Net<Ttype, Dtype, Ptype, RunType>::prediction() {
                 << " offset_size "<<in->get_seq_offset().size();
         }
 #endif
-#ifdef ENABLE_OP_TIMER   
+#ifdef ENABLE_OP_TIMER
 	Context<Ttype> ctx(0, 0, 0);
 	saber::SaberTimer<Ttype> my_time;
 	my_time.start(ctx);
@@ -250,32 +365,92 @@ void Net<Ttype, Dtype, Ptype, RunType>::prediction() {
     _op_time[op_id++] += my_time.get_average_ms();
 #endif
 	//LOG(INFO)<< "op: " << executer.name<<"(" << executer.op_name <<")  ===  infer+launch time "<<my_time.get_average_ms() << " ms";
-#ifdef ENABLE_DEBUG	
+#ifdef ENABLE_DEBUG
 #ifdef USE_CUDA
-	cudaDeviceSynchronize();
-    CUDA_CHECK(cudaPeekAtLastError());
+        CUDA_CHECK(cudaDeviceSynchronize());
+        CUDA_CHECK(cudaPeekAtLastError());
+#endif
 	for (auto out : executer.outs) {
+	    std::vector<int> offset=out->get_seq_offset();
+	    LOG(INFO)<<"print offset of "<<executer.name <<",size = "<<offset.size();
+	    for(int i=0;i<offset.size();++i){
+	        LOG(INFO)<<offset[i]<<",";
+	    }
+	    LOG(INFO)<<"  end print offset of "<<executer.name;
         LOG(INFO) <<executer.name <<" d_tensor_out_p :" <<out->data();
-        record_dev_tensorfile(out->data(), out->valid_size(),
-                              ("net_record_" + executer.name + ".txt").data());
-	    LOG(ERROR) << "    |---out avg " << tensor_average(out);
-	}
-	cudaDeviceSynchronize();
-    CUDA_CHECK(cudaPeekAtLastError());
-#endif
 #ifdef USE_X86_PLACE
-    for (auto out : executer.outs) {
-        LOG(INFO) <<executer.name <<" d_tensor_out_p :" <<out->data();
-        const float* out_data = out->data();
-        std::cout << "seq_offset size: " << out->get_seq_offset().size()<<" ";
         for (int i = 0; i < 10; ++i) {
-            std::cout << out_data[i] << " ";
+            std::cout << out->data()[i]<<" ";
+        }
+#endif
+	    LOG(ERROR) << "    |---out avg " << tensor_average(out);
+	}
+
+#ifdef USE_ARM_PLACE
+        int idx = 0;
+        for (auto out : executer.outs) {
+            int size = out->valid_size();
+            const float* ptr_data = out->data();
+            int num = out->num();
+            int c = out->channel();
+            int w = out->width();
+            int h = out->height();
+            double sum = 0;
+            for (int j = 0; j < num * c; ++j) {
+                double sum_c = 0;
+                for (int k = 0; k < w * h; ++k) {
+                    sum_c += *ptr_data;
+                    sum += *ptr_data;
+                    ptr_data++;
+                }
+                //LOG(INFO) << "channel: " << j << ", mean value :" << sum_c / (w * h);
+            }
+
+            LOG(INFO) << executer.name << ", tensor idx: " << idx << ", mean value :" << sum / size << ", num: " << out->num() << \
+                 ", channel: " << out->channel() << ", height: " << out->height() << ", width: " << out->width();
+            idx++;
         }
-        std::cout << std::endl;
 
-    }
+
+        i++;
+        if (0/*executer.name == "prob"*/) {
+            for (auto out : executer.outs) {
+                printf("output size: dims=%d, ", out->dims());
+                for (int i = 0; i < out->dims(); i++){
+                    printf("%d ", out->valid_shape()[i]);
+                }
+                printf("\n");
+
+                printf("extract data: size: %d, num: %d, channel: %d, height=%d, width=%d\n", \
+                     out->valid_size(), out->num(), out->channel(), out->height(), out->width());
+
+                int ch_get = 0;
+                int size_channel = out->width() * out->height();
+                int start = ch_get * size_channel;
+                int end = start + 1000;//size_channel;
+                end = (end > out->valid_size())? (out->valid_size() - start) : end;
+                const float* ptr_in = out->data(start);
+#if 1
+                //FILE* fp = fopen("conv0_relu_anakin.txt", "w+");
+
+                for (int i = 0; i < end - start; i++)
+                {
+                    //fprintf(fp, "%f ", ptr_in[i]);
+                    printf("%0.4f  ", ptr_in[i]);
+                    if ((i + 1) % 10 == 0) {
+                        //fprintf(fp, "\n");
+                        printf("\n");
+                    }
+                }
+                printf("\n");
+                //fflush(fp);
+                //fclose(fp);
 #endif
+            }
+            LOG(FATAL) << "exit";
+        }
 #endif
+#endif //debug
     }
 }
 
@@ -456,8 +631,9 @@ Status Net<Ttype, Dtype, Ptype, RunType>::init_memory() {
             ori_temp_mem_in_mbytes += (tensor_p->valid_shape().count() * 4);
         };
         this->_graph_p->Scanner->BFS_Edge(analysis_used_of_temp_mem);
-        LOG(ERROR) << " temp !!!!!! " << temp_mem_in_mbytes / 1e6 << "  mb ";
-        LOG(ERROR) << " origin temp !!!!!! " << ori_temp_mem_in_mbytes / 1e6 << "  mb ";
+
+		this->_graph_p->statistics.template set_info<graph::TEMP_MEM>(temp_mem_in_mbytes / 1e6);
+		this->_graph_p->statistics.template set_info<graph::ORI_TEMP_MEM>(ori_temp_mem_in_mbytes / 1e6);
     }
     return Status::OK();
 }
@@ -465,7 +641,7 @@ Status Net<Ttype, Dtype, Ptype, RunType>::init_memory() {
 template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
 Status Net<Ttype, Dtype, Ptype, RunType>::init_env(graph::Graph<Ttype, Dtype, Ptype>& graph) {
     LOG(WARNING) << "Detect and initial " << graph.get_ins().size() << " lanes.";
-    Env<Ttype>::env_init(graph.get_ins().size()); 
+    Env<Ttype>::env_init(graph.get_ins().size());
     LOG(WARNING) << "Current used device id : " << TargetWrapper<Ttype>::get_device_id();
     return Status::OK();
 }
@@ -492,14 +668,22 @@ template class Net<X86, AK_FLOAT, Precision::INT8, OpRunType::SYNC>;
 #endif
 
 #ifdef USE_ARM_PLACE
+#ifdef ANAKIN_TYPE_FP32
 template class Net<ARM, AK_FLOAT, Precision::FP32, OpRunType::ASYNC>;
-template class Net<ARM, AK_FLOAT, Precision::FP16, OpRunType::ASYNC>;
-template class Net<ARM, AK_FLOAT, Precision::INT8, OpRunType::ASYNC>;
-
 template class Net<ARM, AK_FLOAT, Precision::FP32, OpRunType::SYNC>;
+#endif
+
+#ifdef ANAKIN_TYPE_FP16
+template class Net<ARM, AK_FLOAT, Precision::FP16, OpRunType::ASYNC>;
 template class Net<ARM, AK_FLOAT, Precision::FP16, OpRunType::SYNC>;
-template class Net<ARM, AK_FLOAT, Precision::INT8, OpRunType::SYNC>;
 #endif
 
+#ifdef ANAKIN_TYPE_INT8
+template class Net<ARM, AK_FLOAT, Precision::INT8, OpRunType::ASYNC>;
+template class Net<ARM, AK_FLOAT, Precision::INT8, OpRunType::SYNC>;
+#endif //int8
+
+#endif //arm
+
 } /* namespace anakin */
 
diff --git a/framework/core/net/net.h b/framework/core/net/net.h
index 3930e75..ceae98f 100644
--- a/framework/core/net/net.h
+++ b/framework/core/net/net.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -34,14 +34,25 @@ public:
      *  \brief Construct a net by graph. 
      *  This construction should be use in thread call and make sure thread safety.
      */
-    explicit Net(graph::Graph<Ttype, Dtype, Ptype>&, bool need_summary = false); 
+    explicit Net(graph::Graph<Ttype, Dtype, Ptype>&, bool need_summary = false);
+
+    /**
+     *  \brief Construct a net by graph, init with specified context.
+     *  This construction should be use in thread call and make sure thread safety.
+     */
+    explicit Net(graph::Graph<Ttype, Dtype, Ptype>&, OpContextPtr<Ttype> ctx, bool need_summary = false);
 
     ~Net();
 
 public:
-    
-    /** 
-     * \brief init execute net from graph.   
+    /**
+     * \brief init execute net from graph, init with specified context.
+     *  you can use Net(Graph&) instead.
+     */
+    void init(graph::Graph<Ttype, Dtype, Ptype>& graph, OpContextPtr<Ttype> ctx);
+
+    /**
+     * \brief init execute net from graph.
      *  you can use Net(Graph&) instead.
      */
     void init(graph::Graph<Ttype, Dtype, Ptype>&);
diff --git a/framework/core/net/operator_func.cpp b/framework/core/net/operator_func.cpp
index 7bc7f44..1a98bd8 100644
--- a/framework/core/net/operator_func.cpp
+++ b/framework/core/net/operator_func.cpp
@@ -25,10 +25,19 @@ template class OperatorFunc<X86, AK_FLOAT, Precision::INT8>;
 #endif
 
 #ifdef USE_ARM_PLACE
+#ifdef ANAKIN_TYPE_FP32
 template class OperatorFunc<ARM, AK_FLOAT, Precision::FP32>;
+#endif
+
+#ifdef ANAKIN_TYPE_FP16
 template class OperatorFunc<ARM, AK_FLOAT, Precision::FP16>;
+#endif
+
+#ifdef ANAKIN_TYPE_INT8
 template class OperatorFunc<ARM, AK_FLOAT, Precision::INT8>;
 #endif
 
+#endif
+
 } /* namespace */
 
diff --git a/framework/core/net/operator_func.h b/framework/core/net/operator_func.h
index 822bfc3..541062c 100644
--- a/framework/core/net/operator_func.h
+++ b/framework/core/net/operator_func.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/net/worker.cpp b/framework/core/net/worker.cpp
index be981af..d5c0376 100644
--- a/framework/core/net/worker.cpp
+++ b/framework/core/net/worker.cpp
@@ -41,6 +41,7 @@ struct NetGraphWrapper {
             return _thread_to_net[id];
         }
         LOG(FATAL) << " target key(thread_id) not found in NetGraphWrapper";
+        return _thread_to_net[id];
     }
     
 private:
@@ -92,10 +93,13 @@ template<typename Ttype, DataType Dtype, Precision Ptype, OpRunType RunType>
 std::vector<Tensor4dPtr<Ttype, Dtype> > Worker<Ttype, Dtype, Ptype, RunType>::sync_prediction(std::vector<Tensor4dPtr<typename target_host<Ttype>::type, Dtype> >& net_ins_list) {
     auto task = [&](std::vector<Tensor4dPtr<typename target_host<Ttype>::type, Dtype> >& ins) -> std::vector<Tensor4dPtr<Ttype, Dtype> > {
         auto& net = MultiThreadModel<Ttype, Dtype, Ptype, RunType>::Global().get_net(std::this_thread::get_id()); 
-        //fill the graph inputs 
+        //fill the graph inputs
+
         for(int i = 0; i < _inputs_in_order.size(); i++) { 
-            auto d_tensor_in_p = net.get_in(_inputs_in_order[i]); 
-            d_tensor_in_p->copy_from(*ins[i]); 
+            auto d_tensor_in_p = net.get_in(_inputs_in_order[i]);
+            d_tensor_in_p->reshape(ins[i]->valid_shape());
+            d_tensor_in_p->copy_from(*ins[i]);
+            d_tensor_in_p->set_seq_offset(ins[i]->get_seq_offset());
         } 
 #ifdef ENABLE_OP_TIMER
         Context<NV> ctx(0, 0, 0); 
@@ -119,7 +123,7 @@ std::vector<Tensor4dPtr<Ttype, Dtype> > Worker<Ttype, Dtype, Ptype, RunType>::sy
         }
 
         return ret; 
-    }; 
+    };
     return this->RunSync(task, net_ins_list);
 }
 
@@ -153,7 +157,9 @@ void Worker<Ttype, Dtype, Ptype, RunType>::async_prediction(std::vector<Tensor4d
             //fill the graph inputs
             for(int i = 0; i < _inputs_in_order.size(); i++) {
                 auto d_tensor_in_p = net.get_in(_inputs_in_order[i]);
+                d_tensor_in_p->reshape(ins[i]->valid_shape());
                 d_tensor_in_p->copy_from(*ins[i]);
+                d_tensor_in_p->set_seq_offset(ins[i]->get_seq_offset());
             }
 
             net.prediction();
@@ -211,14 +217,23 @@ template class Worker<X86, AK_FLOAT, Precision::INT8, OpRunType::SYNC>;
 #endif
 
 #ifdef USE_ARM_PLACE
-template class Worker<ARM, AK_FLOAT, Precision::FP32, OpRunType::ASYNC>;
-template class Worker<ARM, AK_FLOAT, Precision::FP16, OpRunType::ASYNC>;
-template class Worker<ARM, AK_FLOAT, Precision::INT8, OpRunType::ASYNC>;
 
+#ifdef ANAKIN_TYPE_FP32
+template class Worker<ARM, AK_FLOAT, Precision::FP32, OpRunType::ASYNC>;
 template class Worker<ARM, AK_FLOAT, Precision::FP32, OpRunType::SYNC>;
+#endif
+
+#ifdef ANAKIN_TYPE_FP16
+template class Worker<ARM, AK_FLOAT, Precision::FP16, OpRunType::ASYNC>;
 template class Worker<ARM, AK_FLOAT, Precision::FP16, OpRunType::SYNC>;
+#endif
+
+#ifdef ANAKIN_TYPE_INT8
+template class Worker<ARM, AK_FLOAT, Precision::INT8, OpRunType::ASYNC>;
 template class Worker<ARM, AK_FLOAT, Precision::INT8, OpRunType::SYNC>;
 #endif
 
+#endif
+
 } /* namespace */
 
diff --git a/framework/core/net/worker.h b/framework/core/net/worker.h
index 9ecf238..b1ed97d 100644
--- a/framework/core/net/worker.h
+++ b/framework/core/net/worker.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/operator/operator.h b/framework/core/operator/operator.h
index 30319fa..d49562a 100644
--- a/framework/core/operator/operator.h
+++ b/framework/core/operator/operator.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -83,6 +83,7 @@ public:
      */
     virtual Status InitParam() {
         DLOG(ERROR) << " Target ParserParam not overriden.";
+        return Status::FAIL();
     }
 
     /** 
@@ -92,6 +93,7 @@ public:
                         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
                         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs){
         DLOG(ERROR) << " Target init not overriden.";
+        return Status::FAIL();
     }
 
     /** 
@@ -100,6 +102,7 @@ public:
     virtual Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
                               std::vector<Tensor4dPtr<Ttype, Dtype> >& outs){
         DLOG(ERROR) << " Target infershape not overriden.";
+        return Status::FAIL();
     }
 
     /** 
@@ -116,6 +119,13 @@ public:
     template<typename T>
     T get_attr(std::string attr_name) { return _node_p->get_attr<T>(attr_name); }
 
+	/**
+	 *  \brief Judge if op access target attr
+	 */
+	inline bool check_attr(const std::string& attr_name) {
+		return _node_p->inspect_attr(attr_name);
+	}
+
 private:
     ///< Pointer to graph node.
     graph::NodePtr<Ttype, Dtype, Ptype> _node_p;
@@ -149,7 +159,7 @@ public:
      *  \brief Create Operator object by op_name.
      */
     virtual Operator<Ttype, Dtype, Ptype>* operator[](const std::string op_name) {
-        Factory<Operator<Ttype, Dtype, Ptype>, OperatorCreator<Ttype, Dtype, Ptype>>::operator[](op_name);
+        return Factory<Operator<Ttype, Dtype, Ptype>, OperatorCreator<Ttype, Dtype, Ptype>>::operator[](op_name);
     }
 
     /** 
diff --git a/framework/core/operator/operator_attr.cpp b/framework/core/operator/operator_attr.cpp
index 1837730..0745b62 100644
--- a/framework/core/operator/operator_attr.cpp
+++ b/framework/core/operator/operator_attr.cpp
@@ -15,27 +15,41 @@ OpAttrWarpper& OpAttrWarpper::__alias__(const std::string& op_name) {
     OpFactory<Ttype, Dtype, Ptype>::Global().add_alias(this->opAttr_.name, op_name);
     return *this;
 }
-
+//#ifdef USE_CUDA
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<NV, AK_FLOAT, Precision::FP32>(const std::string& op_name);
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<NV, AK_FLOAT, Precision::FP16>(const std::string& op_name);
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<NV, AK_FLOAT, Precision::INT8>(const std::string& op_name);
+//#endif
 
+//#ifdef USE_X86_PLACE
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<X86, AK_FLOAT, Precision::FP32>(const std::string& op_name);
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<X86, AK_FLOAT, Precision::FP16>(const std::string& op_name);
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<X86, AK_FLOAT, Precision::INT8>(const std::string& op_name);
+//#endif
 
+//#ifdef USE_ARM_PLACE
+//#ifdef ANAKIN_TYPE_FP32
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<ARM, AK_FLOAT, Precision::FP32>(const std::string& op_name);
+//#endif
+
+//#ifdef ANAKIN_TYPE_FP16
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<ARM, AK_FLOAT, Precision::FP16>(const std::string& op_name);
+//#endif
+
+//#ifdef ANAKIN_TYPE_INT8
 template
 OpAttrWarpper& OpAttrWarpper::__alias__<ARM, AK_FLOAT, Precision::INT8>(const std::string& op_name);
+//#endif
+
+//#endif
 
 OpAttrWarpper& OpAttrWarpper::Doc(const std::string& doc) {
     opAttr_.doc = doc;
diff --git a/framework/core/operator/operator_attr.h b/framework/core/operator/operator_attr.h
index 4665782..ca81ee6 100644
--- a/framework/core/operator/operator_attr.h
+++ b/framework/core/operator/operator_attr.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/operator/request.h b/framework/core/operator/request.h
index ba6b0e8..d7a1732 100644
--- a/framework/core/operator/request.h
+++ b/framework/core/operator/request.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/parameter.h b/framework/core/parameter.h
index 2be808b..8ef2449 100644
--- a/framework/core/parameter.h
+++ b/framework/core/parameter.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -165,7 +165,7 @@ private:
 template<typename T>
 struct DataTypeRecover; /// declare for PBlock
 
-/** 
+/**
  *  \brief a simple wrapper of tensor use in weights parameter.
  *   default layout [ NCHW ]
  */
@@ -223,6 +223,12 @@ public:
         return ret;
     }
 
+	// reallocate the storage
+	void re_alloc(Shape4d shape) {
+		_d_inner_tensor->re_alloc(shape);
+		_h_inner_tensor->re_alloc(shape);
+	}
+
     /// Get shape.
     Shape4d shape() const { 
         CHECK(_d_inner_tensor->valid_shape() == _h_inner_tensor->valid_shape()) 
@@ -237,8 +243,8 @@ public:
 
     ~PBlock() {}
 
-private: 
-	std::shared_ptr<d_type> _d_inner_tensor; 
+private:
+	std::shared_ptr<d_type> _d_inner_tensor;
 	std::shared_ptr<h_type> _h_inner_tensor;
 };
 
@@ -285,20 +291,25 @@ public:
         return ret;
     }
 
+	// reallocate storage	
+	void re_alloc(Shape4d shape) {
+		_inner_tensor->re_alloc(shape);
+	}
+
     /// Get shape.
-    Shape4d shape() { 
-        return _inner_tensor->valid_shape(); 
+    Shape4d shape() {
+        return _inner_tensor->valid_shape();
     }
 
     /// Get size.
-    size_t count() { 
+    size_t count() {
         return this->shape().count();
     }
 
     ~PBlock() {}
 
-private: 
-	std::shared_ptr<type> _inner_tensor; 
+private:
+	std::shared_ptr<type> _inner_tensor;
 };
 
 template<typename Dtype>
@@ -323,11 +334,13 @@ public:
 
     /// assign
     PBlock<Dtype, ARM>& operator=(const PBlock<Dtype, ARM>& p_block) {
-        _inner_tensor = p_block._inner_tensor;
+        this->_inner_tensor = p_block._inner_tensor;
+        return *this;
     }
 
     PBlock<Dtype, ARM>& operator=(PBlock<Dtype, ARM>& p_block) {
-        _inner_tensor = p_block._inner_tensor;
+        this->_inner_tensor = p_block._inner_tensor;
+        return *this;
     }
 
     /// Get tensor.
@@ -344,23 +357,28 @@ public:
         return ret;
     }
 
+	// reallocate the storage
+	void re_alloc(Shape4d shape) {
+		_inner_tensor->re_alloc(shape);
+	}
+
     /// Get shape.
-    Shape4d shape() { 
-        return _inner_tensor->valid_shape(); 
+    Shape4d shape() {
+        return _inner_tensor->valid_shape();
     }
 
     /// Get size.
-    size_t count() { 
+    size_t count() {
         return this->shape().count();
     }
 
     ~PBlock() {}
 
-private: 
-	std::shared_ptr<type> _inner_tensor; 
+private:
+	std::shared_ptr<type> _inner_tensor;
 };
 
-/** 
+/**
  *  \brief Enum type.
  */
 struct Enum {
diff --git a/framework/core/singleton.h b/framework/core/singleton.h
index f0f8b5d..b79b940 100644
--- a/framework/core/singleton.h
+++ b/framework/core/singleton.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/thread_pool.h b/framework/core/thread_pool.h
index f4687bf..aea288a 100644
--- a/framework/core/thread_pool.h
+++ b/framework/core/thread_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -32,32 +32,88 @@ namespace anakin {
 class ThreadPool {
 public:
     ThreadPool(int num_thread):_num_thread(num_thread) {}
-    virtual ~ThreadPool();
-
-    void launch();
+    virtual ~ThreadPool(){
+        stop();
+        this->_cv.notify_all();
+        for(auto & worker: _workers){
+            worker.join();
+        }
+    }
+
+    void launch() {
+        for(size_t i = 0; i<_num_thread; ++i) {
+            _workers.emplace_back(
+                    [i ,this]() {
+                        // initial
+                        this->init();
+                        for(;;) {
+                            std::function<void(void)> task;
+                            {
+                                std::unique_lock<std::mutex> lock(this->_mut);
+                                while(!this->_stop && this->_tasks.empty()) {
+                                    this->_cv.wait(lock);
+                                }
+                                if(this->_stop) {
+                                    return ;
+                                }
+                                task = std::move(this->_tasks.front());
+                                this->_tasks.pop();
+                            }
+                                    DLOG(INFO) << " Thread (" << i <<") processing";
+                            auxiliary_funcs();
+                            task();
+                        }
+                    }
+            );
+        }
+    }
 
     /** 
      *  \brief Lanuch the normal function task in sync.
      */
     template<typename functor, typename ...ParamTypes>
-    typename function_traits<functor>::return_type RunSync(functor function, ParamTypes ...args);
+    typename function_traits<functor>::return_type RunSync(functor function, ParamTypes ...args) {
+        auto task = std::make_shared<std::packaged_task<typename function_traits<functor>::return_type(void)> >( \
+            std::bind(function, std::forward<ParamTypes>(args)...)
+        );
+        std::future<typename function_traits<functor>::return_type> result = task->get_future();
+        {
+            std::unique_lock<std::mutex> lock(this->_mut);
+            this->_tasks.emplace( [&]() { (*task)(); } );
+        }
+        this->_cv.notify_one();
+        return result.get();
+    }
 
     /**
      *  \brief Lanuch the normal function task in async.
      */
     template<typename functor, typename ...ParamTypes>
-    typename std::future<typename function_traits<functor>::return_type> RunAsync(functor function, ParamTypes ...args);
-
+    typename std::future<typename function_traits<functor>::return_type> RunAsync(functor function, ParamTypes ...args) {
+        auto task = std::make_shared<std::packaged_task<typename function_traits<functor>::return_type(void)> >( \
+            std::bind(function, std::forward<ParamTypes>(args)...)
+        );
+        std::future<typename function_traits<functor>::return_type> result = task->get_future();
+        {
+            std::unique_lock<std::mutex> lock(this->_mut);
+            this->_tasks.emplace( [=]() { (*task)(); } );
+        }
+        this->_cv.notify_one();
+        return result;
+    }
     
     /// Stop the pool.
-    void stop();
+    void stop() {
+        std::unique_lock<std::mutex> lock(this->_mut);
+        _stop = true;
+    }
 
 private:
     /// The initial function should be overrided by user who derive the ThreadPool class.
-    virtual void init();
+    virtual void init(){}
 
     /// Auxiliary function should be overrided when you want to do other things in the derived class.
-    virtual void auxiliary_funcs();
+    virtual void auxiliary_funcs(){}
 
 private:
     int _num_thread;
@@ -70,6 +126,6 @@ private:
 
 } /* namespace anakin */
 
-#include "thread_pool.inl"
+//#include "thread_pool.inl"
 
 #endif
diff --git a/framework/core/thread_safe_macros.h b/framework/core/thread_safe_macros.h
index 6f08cdd..e8d9b6f 100644
--- a/framework/core/thread_safe_macros.h
+++ b/framework/core/thread_safe_macros.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/tls.h b/framework/core/tls.h
index df38fa2..888fce8 100644
--- a/framework/core/tls.h
+++ b/framework/core/tls.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/type_traits_extend.h b/framework/core/type_traits_extend.h
index 2c22bca..0129377 100644
--- a/framework/core/type_traits_extend.h
+++ b/framework/core/type_traits_extend.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/core/types.h b/framework/core/types.h
index 3d872ce..81abfb5 100644
--- a/framework/core/types.h
+++ b/framework/core/types.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/algorithm.h b/framework/graph/algorithm.h
index 39adca9..4523acf 100644
--- a/framework/graph/algorithm.h
+++ b/framework/graph/algorithm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/arc.h b/framework/graph/arc.h
index c42293e..3d86edd 100644
--- a/framework/graph/arc.h
+++ b/framework/graph/arc.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -34,7 +34,7 @@ public:
     Arc(VertexNameType vertex_1, VertexNameType vertex_2);
     Arc(VertexNameType vertex_1, VertexNameType vertex_2, WeightType weight);
     Arc(const Arc& otherArc);
-    virtual ~Arc() {};
+    virtual ~Arc() {}
 	
     /// judge if one arc equal to another
     bool operator==(const Arc<VertexNameType, WeightType>& otherArc) const {
diff --git a/framework/graph/graph.cpp b/framework/graph/graph.cpp
index 8e79cc2..b623863 100644
--- a/framework/graph/graph.cpp
+++ b/framework/graph/graph.cpp
@@ -1,6 +1,7 @@
 #include "framework/graph/graph.h"
 #include "framework/model_parser/parser/parser.h"
 #include "framework/graph/llvm/scheduler.h"
+#include "framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.h"
 #include "framework/graph/llvm/optimizer/parall_scheduler.h"
 #include "framework/graph/llvm/optimizer/memory_scheduler.h"
 #include "framework/graph/llvm/fusion/graph_pattern.h"
@@ -106,7 +107,7 @@ Status Graph<Ttype, Dtype, Ptype>::Optimize() EXCLUSIVE_LOCKS_REQUIRED(_mut) {
         //! decide wheter the vgraph is optimized
         auto is_optimized = statistics.get_info<IS_OPTIMIZED>();
 
-        if (is_optimized && _registed_outs.size() == 0) {
+        if (is_optimized && (_registed_outs.size() == 0)) {
             // schedule for exec order
             Scheduler scheduler;
             scheduler.RegIOResource(_vgraph);
@@ -129,10 +130,21 @@ Status Graph<Ttype, Dtype, Ptype>::Optimize() EXCLUSIVE_LOCKS_REQUIRED(_mut) {
             scheduler.RegIOResource(_vgraph);
             scheduler.Run();
 
+			_nodes_exec_order = scheduler.get_exec_node_in_order();
+
+
+#if 0
             // get node exec in order
             _nodes_exec_order = scheduler.get_exec_node_in_order();
-
+#else		// enable conv+eltwise fusion
             // optimization
+			ConvElsFusionScheduler conv_eltwise_fusion_scheduler;
+			conv_eltwise_fusion_scheduler.RegIOResource(_vgraph);
+			conv_eltwise_fusion_scheduler.Run();
+			// get node exec in order
+			//_nodes_exec_order = conv_eltwise_fusion_scheduler.get_exec_node_in_order();
+#endif
+			// optimization again
             MemoryScheduler mem_scheduler;
             mem_scheduler.RegIOResource(_vgraph);
             mem_scheduler.Run();
@@ -140,8 +152,6 @@ Status Graph<Ttype, Dtype, Ptype>::Optimize() EXCLUSIVE_LOCKS_REQUIRED(_mut) {
             para_scheduler.RegIOResource(_vgraph);
             para_scheduler.Run();
 
-            LOG(INFO) << "input_0 name: " << (*_vgraph)["input_0"].name << " input_0 lane: " <<  (*_vgraph)["input_0"].lane << " wait: " << (*_vgraph)["input_0"].need_wait;
-
             // set info for graph
             statistics.set_info<IS_OPTIMIZED>(true);
             DLOG(INFO) << " model size : " << graph::GraphGlobalMem<Ttype>::Global().get_sum_mbyte() << " mb ";
@@ -288,6 +298,11 @@ Status Graph<Ttype, Dtype, Ptype>::restore_from_vgraph(VGraph* vgraph) {
                     this->_pattern_name_merges[target_node.name].push_back(target_node.mergeNodeNames[i]);
                 }
             }
+			if(target_node.idx_keep_in_merge_nodes.size()) {
+				for(auto& idx : target_node.idx_keep_in_merge_nodes) {
+					this->_node_merges_keep[target_node.name].push_back(idx);
+				}
+			}
 
             auto& need_wait = node_p->need_wait();
             need_wait = target_node.need_wait;
@@ -315,7 +330,14 @@ Status Graph<Ttype, Dtype, Ptype>::restore_from_vgraph(VGraph* vgraph) {
                 auto& tmp_node_p = this->operator[](this->_node_merges[target_node_name][i]);
                 (*node_p).Merge(*tmp_node_p,
                                 this->_pattern_name_merges[target_node_name][i]); // add the merge node's attr
-                this->remove(this->_node_merges[target_node_name][i]); // remove merge node which is useless
+
+				// detect if the i-th node in _node_merges should be saved in Graph
+				auto ret = std::find(this->_node_merges_keep[target_node_name].begin(), 
+									 this->_node_merges_keep[target_node_name].end(), 
+									 i);
+				if(ret == this->_node_merges_keep[target_node_name].end()) {
+                	this->remove(this->_node_merges[target_node_name][i]); // remove merge node which is useless
+				}
             }
         }
 
@@ -356,8 +378,11 @@ Status Graph<Ttype, Dtype, Ptype>::CopyFrom(Graph<Ttype, Dtype, Ptype>& graph) {
     graph.Scanner->BFS(shallow_copy_edge);
     // get node execution order
     _nodes_exec_order = graph.get_nodes_in_order();
-	_ins = graph._ins;
-	_outs = graph._outs;
+	// get graph inputs and outputs
+	 _ins = graph._ins;	
+	 _outs = graph._outs;
+	// get statistic
+	statistics = graph.statistics;
     return Status::OK();
 }
 
@@ -387,10 +412,16 @@ template class Graph<X86, AK_FLOAT, Precision::INT8>;
 #endif
 
 #ifdef USE_ARM_PLACE
+#ifdef ANAKIN_TYPE_FP32
 template class Graph<ARM, AK_FLOAT, Precision::FP32>;
+#endif
+#ifdef ANAKIN_TYPE_FP16
 template class Graph<ARM, AK_FLOAT, Precision::FP16>;
+#endif
+#ifdef ANAKIN_TYPE_INT8
 template class Graph<ARM, AK_FLOAT, Precision::INT8>;
 #endif
+#endif
 
 } /* namespace graph */
 
diff --git a/framework/graph/graph.h b/framework/graph/graph.h
index 9aa5491..5822c11 100644
--- a/framework/graph/graph.h
+++ b/framework/graph/graph.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -54,6 +54,7 @@ public:
     }
 
     /// get graph name
+    void set_name(std::string name){_name = name;}
     std::string& name() { return _name; }
 
     /// add i/o
@@ -126,7 +127,7 @@ private:
     ///< _vgraph stand for graph. default nullptr
     VGraph* _vgraph{nullptr};
     ///< _name stand for message
-    std::string _name;
+    std::string _name{"default"};
     ///< graph input node name
     std::vector<std::string> _ins; 
     ///< graph output node name     
@@ -135,6 +136,8 @@ private:
     std::vector<std::string> _nodes_exec_order;
     ///< node_merges map: target node map to all its fusion node
     std::unordered_map<std::string, std::vector<std::string> > _node_merges;
+	///< _node_merges_keep map: target node map to all its fusion node that shouldn't be removed
+	std::unordered_map<std::string, std::vector<int> > _node_merges_keep;
 
     ///< _pattern_name_merges map: target node map to all its fusion pattern node
     std::unordered_map<std::string, std::vector<std::string> > _pattern_name_merges;
diff --git a/framework/graph/graph_base.h b/framework/graph/graph_base.h
index 5903f82..d30db00 100644
--- a/framework/graph/graph_base.h
+++ b/framework/graph/graph_base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/graph_base.inl b/framework/graph/graph_base.inl
index 6f68fcb..4cb4896 100644
--- a/framework/graph/graph_base.inl
+++ b/framework/graph/graph_base.inl
@@ -216,9 +216,10 @@ ArcType& GraphBase<VertexNameType, VertexType, WeightType, ArcType>::get_arc(Ver
     }
     Arc_iterator<VertexNameType, WeightType, ArcType> it_end = _arcs.end(); 
     Arc_iterator<VertexNameType, WeightType, ArcType> it = find(vertex_name_from, vertex_name_to); 
-    if(it != it_end) { 
-        return *it; 
-    } 
+//    if(it != it_end) {
+//        return *it;
+//    }
+    return *it;
 }
 
 template<typename VertexNameType, typename VertexType, typename WeightType, typename ArcType>
diff --git a/framework/graph/graph_global_mem.h b/framework/graph/graph_global_mem.h
index 5796bc5..5ecfe99 100644
--- a/framework/graph/graph_global_mem.h
+++ b/framework/graph/graph_global_mem.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/llvm/base.h b/framework/graph/llvm/base.h
index 8b4e8f6..f96d69d 100644
--- a/framework/graph/llvm/base.h
+++ b/framework/graph/llvm/base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/llvm/fusion/fusion_op_register.cpp b/framework/graph/llvm/fusion/fusion_op_register.cpp
index 106c88d..1b0c4e4 100644
--- a/framework/graph/llvm/fusion/fusion_op_register.cpp
+++ b/framework/graph/llvm/fusion/fusion_op_register.cpp
@@ -4,6 +4,8 @@ namespace anakin {
 
 namespace graph {
 
+/// in straight order
+
 REGISTER_GRAPH_FUSION_PATTERN(DeconvRelu)
 .Type(IN_ORDER)
 .AddOpNode("conv_0",  "Deconvolution")
@@ -74,13 +76,6 @@ REGISTER_GRAPH_FUSION_PATTERN(EltwiseRelu)
 .AddConnect("eltwise_0", "relu_0")
 .CreatePattern([](VGraph* graph) {});
 
-
-/*REGISTER_GRAPH_FUSION_PATTERN(Dense)
-    .Type(IN_PARELLEL)
-    .CreatePattern([](VGraph* graph){
-    })*/
-
-
 } /* namespace graph */
 
 } /* namespace anakin */
diff --git a/framework/graph/llvm/fusion/graph_pattern.cpp b/framework/graph/llvm/fusion/graph_pattern.cpp
index d49c100..9ff2b87 100644
--- a/framework/graph/llvm/fusion/graph_pattern.cpp
+++ b/framework/graph/llvm/fusion/graph_pattern.cpp
@@ -4,8 +4,7 @@ namespace anakin {
 
 namespace graph {
 
-const std::unordered_map<Fusion, std::function<int(VGraph*, Pattern*)>, FusionHash> FusionSniffer
-= {
+const std::unordered_map<Fusion, std::function<int(VGraph*, Pattern*)>, FusionHash> FusionSniffer = {
     {
         IN_ORDER,
         [](VGraph * vgraph, Pattern * pattern) -> int {
@@ -92,19 +91,22 @@ const std::unordered_map<Fusion, std::function<int(VGraph*, Pattern*)>, FusionHa
                 }
             };
             vgraph->Scanner->BFS(search_vgraph, pattern);
+            return 0;
         }
     },
     {
         IN_PARELLEL,
         [](VGraph * vgraph, Pattern * pattern) ->int {
+            return 0;
         }
     },
     {
         GRAPH,
         [](VGraph * vgraph, Pattern * pattern) ->int {
+            return 0;
         }
     },
-    { None, [](VGraph*, Pattern*) ->int {} }
+    { None, [](VGraph*, Pattern*) ->int { return 0;} }
 };
 
 Pattern& Pattern::name(std::string fusion_op_name) {
diff --git a/framework/graph/llvm/fusion/graph_pattern.h b/framework/graph/llvm/fusion/graph_pattern.h
index 1513c21..2363578 100644
--- a/framework/graph/llvm/fusion/graph_pattern.h
+++ b/framework/graph/llvm/fusion/graph_pattern.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.cpp b/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.cpp
new file mode 100644
index 0000000..8e05a61
--- /dev/null
+++ b/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.cpp
@@ -0,0 +1,89 @@
+#include "framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.h"
+
+namespace anakin {
+
+namespace graph {
+
+bool ConvElsFusionScheduler::callable(node& node_arg) {
+	if(_helper.has_node(node_arg)) {
+		auto& node_arc_out_its = _vgraph->get_out_arc_its(node_arg.name);	
+		auto& node_arc_in_its = _vgraph->get_in_arc_its(node_arg.name);
+		CHECK_EQ(node_arc_out_its.size(), 1)<<"Conv+eltwise analysis: Convolution like op should have only one output.";
+		auto& node_next = (*_vgraph)[node_arc_out_its[0]->top()];
+		if(node_next.opName == "EltwiseRelu" || node_next.opName == "Eltwise") {
+			auto& elt_node_in_its = _vgraph->get_in_arc_its(node_next.name);
+			for(auto& it : elt_node_in_its) {
+				if(it->bottom() != node_arg.name) {
+					if(!_helper.need_wait(it->bottom())) {
+						_helper.push_wait(node_arg.name);
+						if(!this->have_launched((*_vgraph)[it->bottom()])) {
+							/*std::vector<io> io_in; 
+							for (auto& arc_it : node_arc_in_its) { 
+								io_in.push_back(arc_it->weight()); 
+							}
+							_helper.set_holder(io_in, _vgraph);*/
+							//_helper.register_pair(node_arg.name, node_next.name);
+							if ((*_vgraph)[it->bottom()].opName == "Split") { 
+								_helper.register_pair(node_arg.name, node_next.name); } 
+							else { 
+								_helper.register_pair(it->bottom(), node_next.name); 
+							}
+
+							//_helper.register_pair(it->bottom(), node_next.name);
+							return false;
+						} else {
+							_helper.release(node_arg.name);
+						}
+						break;
+					}
+				}
+			}
+		}
+	}
+
+	// original code
+    auto& node_arc_in_its = _vgraph->get_in_arc_its(node_arg.name);
+    std::vector<io> io_in;
+
+    for (auto& arc_it : node_arc_in_its) {
+        io_in.push_back(arc_it->weight());
+    }
+
+    return this->check_access(io_in);
+}
+
+void ConvElsFusionScheduler::Run() {
+	while (!(this->_wait_que.empty())) {
+        // lanuch the acessible op and remove it from wait que.
+        for (auto op_it = this->_wait_que.begin(); op_it != this->_wait_que.end();) {
+            if (callable(*op_it)) {
+                launch(*op_it);
+                op_it = this->_wait_que.erase(op_it);
+            } else {
+                ++op_it;
+            }
+        }
+    }
+
+	// complete fusion replacement for conv+eltwise
+	auto& pairs = _helper.get_replace_pairs();
+	for(auto& tmp_pair : pairs) {
+		auto& node_conv = (*_vgraph)[tmp_pair.conv_name];
+		auto& node_eltwise = (*_vgraph)[tmp_pair.eltwise_name];
+		node_conv += node_eltwise; // merge node parameter
+		node_conv.register_keep(node_conv.mergeNodes.size()-1); // keep eltwise node in reconstruction
+		node_conv.mergeNodeNames.push_back("merge"); // eltwise op's pattern name is equal to its original attr's name
+
+		node_eltwise.opName = "Gather"; // change eltwise op to Gather op
+	}
+	// set exec order for vgraph
+	auto exec_node_order = this->get_exec_node_in_order();
+	_vgraph->set_exec_order(exec_node_order);
+}
+
+
+} /* namespace graph */
+
+} /* namespace anakin */
+
+
diff --git a/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.h b/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.h
new file mode 100644
index 0000000..a3ca2bb
--- /dev/null
+++ b/framework/graph/llvm/optimizer/conv_elewise_fusion_scheduler.h
@@ -0,0 +1,142 @@
+/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_LLVM_SCHEDULER_CONV_ELEWISE_FUSION_H
+#define ANAKIN_LLVM_SCHEDULER_CONV_ELEWISE_FUSION_H
+
+#include "utils/logger/logger.h"
+#include "framework/graph/llvm/schedule_base.h"
+#include "framework/graph/llvm/virtual_graph.h"
+#include "framework/graph/llvm/scheduler.h"
+
+namespace anakin {
+
+namespace graph {
+
+/**
+ *  \brief ConvElsFusionScheduler helper class
+ */
+struct ConvElsFusionHelper {
+private:
+	std::vector<std::string> ops {
+		"ConvBatchnormScale",
+	};
+	struct conv_eltwise_pair {
+		std::string conv_name;
+		std::string eltwise_name;
+		inline bool operator==(const conv_eltwise_pair& pair_other) {
+			return (conv_name == pair_other.conv_name) && (eltwise_name == pair_other.eltwise_name);
+		}
+	};
+	std::vector<conv_eltwise_pair> _pairs;
+
+	std::vector<std::string> _node_need_to_wait;
+
+public:
+	/**
+	 * \brief judge if meet target op
+	 */
+	inline bool has_node(node& node_arg) {
+		for(auto& op : ops) {
+			if(op == node_arg.opName) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	bool need_wait(std::string& node_name) {
+		auto ret = std::find(_node_need_to_wait.begin(), _node_need_to_wait.end(), node_name);
+		if(ret != _node_need_to_wait.end()) {
+			return true;
+		}
+		return false;
+	}
+
+	void push_wait(std::string& node_name) {
+		if(!need_wait(node_name)) {
+			_node_need_to_wait.push_back(node_name);
+		}
+	}
+
+	void release(std::string& node_name) {
+		int index = -1;
+		for(int i=0; i<_node_need_to_wait.size();i++) {
+			if(_node_need_to_wait[i] == node_name) {
+				index = i;
+			}
+		}
+		if(index != -1) {
+			_node_need_to_wait.erase(_node_need_to_wait.begin()+index);
+		}
+	}
+
+	/*void set_holder(std::vector<io>& io_vec, VGraph* graph) {
+		for(auto io : io_vec) {
+			io.holder = true;
+		}
+		for (auto& io_res : io_vec) { 
+			auto replace_arc = [&](Arc<std::string, io>& arc) { 
+				if (arc.weight() == io_res) { 
+					auto& io_tmp = arc.weight(); 
+					io_tmp = io_res; 
+					return Status::EXIT(" Find the matched target arc io. "); 
+				} 
+				return Status::OK(); 
+			}; 
+			graph->Scanner->BFS_Edge(replace_arc); 
+		}
+	}*/
+
+	void register_pair(std::string& conv_name, std::string& eltwise_name) {
+		conv_eltwise_pair tmp_pair;
+		tmp_pair.conv_name = conv_name;
+		tmp_pair.eltwise_name = eltwise_name;
+		auto ret = std::find(_pairs.begin(), _pairs.end(), tmp_pair);
+		if(ret == _pairs.end()) {
+			_pairs.push_back(tmp_pair);
+		}
+	}
+
+	std::vector<conv_eltwise_pair>& get_replace_pairs() {
+		return _pairs;
+	}
+};
+
+/**
+ *  \brief Dependency scheduler for analysing the possibility of conv+eltwise fusion in graph
+ */
+class ConvElsFusionScheduler : public Scheduler {
+public:
+    ConvElsFusionScheduler() {}
+    virtual ~ConvElsFusionScheduler() {}
+
+	/// decide if the target node's op is callable
+    virtual bool callable(node&);
+
+	/// run scheduler
+    virtual void Run();
+
+
+private:
+	ConvElsFusionHelper _helper;
+};
+
+
+} /* namespace graph */
+
+} /* namespace anakin */
+
+#endif 
diff --git a/framework/graph/llvm/optimizer/memory_scheduler.cpp b/framework/graph/llvm/optimizer/memory_scheduler.cpp
index 239ae53..cc1a88e 100644
--- a/framework/graph/llvm/optimizer/memory_scheduler.cpp
+++ b/framework/graph/llvm/optimizer/memory_scheduler.cpp
@@ -29,7 +29,6 @@ void IOBlockResource::rm_self_lock_tree(io& io_in) {
     }
 }
 
-
 void IOBlockResource::free_self(std::vector<io>& self_shared_edges, VGraph* vgraph_p) {
     for (auto& io : self_shared_edges) {
         rm_self_lock_tree(io);
@@ -113,7 +112,6 @@ void IOBlockResource::free(std::vector<io>& io_vec, VGraph* vgraph_p) {
             tmp_io.name = io_res.name;
 
             if ((*it) == tmp_io) {
-                //_free.push(*it);
                 push_free(*it, vgraph_p);
                 it = _lock.erase(it);
             } else {
@@ -144,6 +142,16 @@ void IOBlockResource::lock(std::vector<io>& io_vec) {
     }
 }
 
+bool IOBlockResource::is_locked(io& io_in) {
+	for(auto it = _lock.begin(); it != _lock.end();) {
+		if((*it) == io_in) {
+			return true;
+		} else {
+			++it;
+		}
+	}
+}
+
 void IOBlockResource::map_ios_to_vgraph(std::vector<io>& io_vec, VGraph* vgraph_p) {
     for (auto& io_res : io_vec) {
         auto replace_arc = [&](Arc<std::string, io>& arc) {
@@ -174,26 +182,84 @@ void MemoryScheduler::launch(node& node_arg) {
     set_fix_io(io_out);
 
     if (_need_self_shared(node_arg)) {
-        auto& node_arc_in_its = _vgraph->get_in_arc_its(node_arg.name);
-        CHECK_EQ(node_arc_in_its.size(),
-                 1) << "Self shared node(" << node_arg.name << ")'s input size should be 1";
-
-        for (auto& arc_it : node_arc_in_its) {
-            _io_block_res.push_self_lock(arc_it->weight());
-        }
-
-        for (auto& io_tmp : io_out) {
-            io_tmp.shared = true;
-
-            if (node_arc_in_its[0]->weight().shared) {
-                io_tmp.share_from = node_arc_in_its[0]->weight().share_from;
-            } else {
-                io_tmp.share_from = node_arc_in_its[0]->weight().name;
-            }
-        }
-
-        _io_block_res.reg_self_lock_tree(node_arc_in_its[0]->weight(), io_out);
-        _io_block_res.map_ios_to_vgraph(io_out, _vgraph); // map changes to _vgraph
+		auto& node_arc_in_its = _vgraph->get_in_arc_its(node_arg.name);
+		if(node_arc_in_its.size() > 1) {
+			int selected = 0;
+			std::vector<int> io_locked_idx;
+			for(int i=0; i < node_arc_in_its.size(); i++) {
+				//if(_io_block_res.is_locked(node_arc_in_its[i]->weight())) {
+					io_locked_idx.push_back(i);
+				//}
+			}
+			// collect all locked io bottom node's inputs io
+			std::vector<io> all_collected;
+			for(auto idx : io_locked_idx) {
+				auto& arc_select = node_arc_in_its[idx];
+				auto& temp_arc_in_its = _vgraph->get_in_arc_its(arc_select->bottom());
+				for(auto& it : temp_arc_in_its) {
+					all_collected.push_back(it->weight());
+				}
+			}
+			for(auto idx : io_locked_idx) {
+				bool dismiss = false;
+				for(auto& io : all_collected) {
+					if(node_arc_in_its[idx]->weight().shared) {
+						auto& node_btm = (*_vgraph)[node_arc_in_its[idx]->bottom()]; 
+						if(_need_self_shared(node_btm)) { 
+							dismiss = false; 
+							break; 
+						}
+						if((io.share_from == node_arc_in_its[idx]->weight().share_from) || \
+								(io.name == node_arc_in_its[idx]->weight().share_from)) {
+							dismiss = true;
+							break;
+						}
+					} else {
+						dismiss = false;
+						break;
+					}
+				}
+				if(!dismiss) {
+					selected = idx;
+					break;
+				}
+			}
+			_io_block_res.push_self_lock(node_arc_in_its[selected]->weight());
+			for(int i=0; i<node_arc_in_its.size(); i++) {
+				if(i != selected) {
+					io_out.push_back(node_arc_in_its[i]->weight());
+				}
+			}
+			for(auto& io_tmp : io_out) {
+				io_tmp.shared = true;
+				if (node_arc_in_its[selected]->weight().shared) {
+                	io_tmp.share_from = node_arc_in_its[selected]->weight().share_from;
+            	} else {
+                	io_tmp.share_from = node_arc_in_its[selected]->weight().name;
+            	}
+			}
+			_io_block_res.reg_self_lock_tree(node_arc_in_its[selected]->weight(), io_out); 
+			_io_block_res.map_ios_to_vgraph(io_out, _vgraph); // map changes to _vgraph
+		} else {
+			// original impl
+			auto& node_arc_in_its = _vgraph->get_in_arc_its(node_arg.name);
+        	CHECK_EQ(node_arc_in_its.size(),
+        	         1) << "Self shared node(" << node_arg.name << ")'s input size should be 1";
+
+        	for (auto& arc_it : node_arc_in_its) {
+        	    _io_block_res.push_self_lock(arc_it->weight());
+        	}
+        	for (auto& io_tmp : io_out) {
+        	    io_tmp.shared = true;
+        	    if (node_arc_in_its[0]->weight().shared) {
+        	        io_tmp.share_from = node_arc_in_its[0]->weight().share_from;
+        	    } else {
+        	        io_tmp.share_from = node_arc_in_its[0]->weight().name;
+        	    }
+        	}
+			_io_block_res.reg_self_lock_tree(node_arc_in_its[0]->weight(), io_out); 
+			_io_block_res.map_ios_to_vgraph(io_out, _vgraph); // map changes to _vgraph
+		}
     } else {
         _io_block_res.lock(io_out); // lock out
         _io_block_res.map_ios_to_vgraph(io_out, _vgraph); // map changes to _vgraph
@@ -208,9 +274,6 @@ void MemoryScheduler::launch(node& node_arg) {
             _io_block_res.free(io_in, _vgraph);
         }
 
-        /*if (!_need_self_shared.last_op_is_self_shared(_vgraph, node_arg)) {
-            _io_block_res.free_self();
-        }*/
         std::vector<io> self_shared_edges;
 
         if (_need_self_shared.last_op_is_self_shared(_vgraph, node_arg, self_shared_edges)) {
diff --git a/framework/graph/llvm/optimizer/memory_scheduler.h b/framework/graph/llvm/optimizer/memory_scheduler.h
index b3a3352..e4a0e75 100644
--- a/framework/graph/llvm/optimizer/memory_scheduler.h
+++ b/framework/graph/llvm/optimizer/memory_scheduler.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -24,22 +24,24 @@
 namespace anakin {
 
 namespace graph {
+
 /**
-* \brief check_self_shared struct
-*  used to check arcs in graph whether is shared
-*/
+ * \brief check_self_shared struct
+ *  used to check arcs in graph whether is shared
+ */
 struct check_self_shared {
     /// ops : Split and Reshape  
     std::vector<std::string> ops{
         "Split",
         "Reshape",
+		"Gather",
 		"Flatten"
     };
     /**
-    * \brief whether node_arg's op is in ops
-    * \param node_arg stand for certain node
-    * \return bool the value of ops == node_arg.opName
-    */
+     * \brief whether node_arg's op is in ops
+     * \param node_arg stand for certain node
+     * \return bool the value of ops == node_arg.opName
+     */
     inline bool operator()(node& node_arg) {
         for (auto& op_type : ops) {
             if (op_type == node_arg.opName) {
@@ -50,12 +52,12 @@ struct check_self_shared {
     }
 
     /**
-    * \brief whether bottom_node's op is in ops
-    * \param graph stand for current graph
-    * \param node_tmp stand for certain node
-    * \param self_shared_ios stand for shared ios queue
-    * \return bool the value of ret
-    */
+     * \brief whether bottom_node's op is in ops
+     * \param graph stand for current graph
+     * \param node_tmp stand for certain node
+     * \param self_shared_ios stand for shared ios queue
+     * \return bool the value of ret
+     */
     inline bool last_op_is_self_shared(VGraph* graph, node& node_tmp, std::vector<io>& self_shared_ios) {
 	bool ret = false;
         auto node_arc_in_its = graph->get_in_arc_its(node_tmp.name);
@@ -63,7 +65,7 @@ struct check_self_shared {
             auto& node_ref = (*graph)[arc_in_it->bottom()];
             for (auto& op_type : ops) {
                 if (op_type == node_ref.opName) {
-		    self_shared_ios.push_back(arc_in_it->weight());
+		    		self_shared_ios.push_back(arc_in_it->weight());
                     ret = true;
                 }
             }
@@ -73,8 +75,8 @@ struct check_self_shared {
 };
 
 /**
-* \brief io block resource class used for scheduler of VGraph memory usage
-*/
+ * \brief io block resource class used for scheduler of VGraph memory usage
+ */
 class IOBlockResource {
 public:
     IOBlockResource() {}
@@ -85,9 +87,11 @@ public:
     bool is_same_target(io&, io&, VGraph*);
     void push_free(io&, VGraph*);
     void lock(std::vector<io>&);
+	bool is_locked(io&);
     inline void push_self_lock(io& io_tmp) { _self_lock.push_back(io_tmp);}
     void reg_self_lock_tree(io&, std::vector<io>&);
     void rm_self_lock_tree(io&);
+	bool is_in_self_tree(io&);
     void free_self(std::vector<io>&, VGraph*);
     void map_ios_to_vgraph(std::vector<io>&, VGraph*);
 
diff --git a/framework/graph/llvm/optimizer/parall_scheduler.h b/framework/graph/llvm/optimizer/parall_scheduler.h
index c1ec3f7..9460da6 100644
--- a/framework/graph/llvm/optimizer/parall_scheduler.h
+++ b/framework/graph/llvm/optimizer/parall_scheduler.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/llvm/schedule_base.h b/framework/graph/llvm/schedule_base.h
index c9990f2..9a7d8ec 100644
--- a/framework/graph/llvm/schedule_base.h
+++ b/framework/graph/llvm/schedule_base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -201,6 +201,7 @@ public:
     inline void exe_push(OpType& op) {
         _exec_que.push(op);
     }
+	
     /**
     *  \brief operations of op queue
     *  push_back operation
@@ -218,6 +219,23 @@ public:
     */
     virtual void launch(OpType&) = 0;
 
+	/**
+     *  \brief judge if target op have been launched
+	 *
+     *  \param op stand for operation type
+     *  \return bool
+     */
+	inline bool have_launched(OpType& op) {
+		for(auto it = _wait_que.begin(); it != _wait_que.end();) {
+			if(*it == op) {
+				return false;
+			}
+			++it;
+		}
+		return true;
+	}
+
+
     /**
     *  \brief get exec queue.
     *  queue operation such as push,push_back,pop
diff --git a/framework/graph/llvm/scheduler.cpp b/framework/graph/llvm/scheduler.cpp
index 33c37ec..970f512 100644
--- a/framework/graph/llvm/scheduler.cpp
+++ b/framework/graph/llvm/scheduler.cpp
@@ -14,12 +14,19 @@ void Scheduler::RegIOResource(VGraph* vgraph) {
     // register io resources.
     vgraph->Scanner->BFS_Edge(register_io_f);
 
-    auto push_wait_que_f = [this](node & node_arg) {
-        this->wait_push(node_arg);
-        return 0;
-    };
-    // push all node op to wait que and disable the out resources.
-    vgraph->Scanner->BFS(push_wait_que_f);
+	/*if(vgraph->has_exec_order()) {
+		auto node_exec_order = vgraph->get_exec_order();
+		for(auto& node_name : node_exec_order) {
+			this->wait_push((*vgraph)[node_name]);
+		}
+	} else {*/
+    	auto push_wait_que_f = [this](node & node_arg) {
+        	this->wait_push(node_arg);
+        	return 0;
+    	};
+    	// push all node op to wait que and disable the out resources.
+    	vgraph->Scanner->BFS(push_wait_que_f);
+	//}
 
     // scheduler add fix arc io
     auto& regist_outs = vgraph->get_registed_outs();
diff --git a/framework/graph/llvm/scheduler.h b/framework/graph/llvm/scheduler.h
index f6d4548..8ffeb6e 100644
--- a/framework/graph/llvm/scheduler.h
+++ b/framework/graph/llvm/scheduler.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/graph/llvm/virtual_graph.h b/framework/graph/llvm/virtual_graph.h
index 73daf01..5a5f26e 100644
--- a/framework/graph/llvm/virtual_graph.h
+++ b/framework/graph/llvm/virtual_graph.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -80,10 +80,12 @@ struct node {
 
     ///< mergeNodes stand for sub merged nodes
     std::vector<node> mergeNodes;
+	///< save node's index in mergeNodes which shouldn't be removed in reconstructing Graph
+	std::vector<int> idx_keep_in_merge_nodes;
 
     ///<mergeNodeNames stand for sub merged node names from pattern
     std::vector<std::string> mergeNodeNames;
-    
+
     ///< lane stand for the stream of lane the node operator occurs. default 0
     int lane{0};
     ///<need_wait stand forwhether it needs wait .default false
@@ -134,6 +136,11 @@ struct node {
         this->mergeNodes.push_back(rhs);
         return *this;
     }
+
+	// register node index should keep
+	inline void register_keep(int idx) {
+		idx_keep_in_merge_nodes.push_back(idx);
+	}
 };
 
 /**
@@ -161,9 +168,17 @@ public:
 
     std::vector<std::pair<std::string, std::string>>& get_registed_outs() { return _registed_outs; }
 
+	bool has_exec_order() { return _nodes_exec_order.size() == 0 ? false : true; }
+
+	void set_exec_order(std::vector<std::string>& exe_order) { _nodes_exec_order = exe_order; }
+
+	std::vector<std::string>& get_exec_order() { return _nodes_exec_order; }
+
 private:
     ///< _registed_outs :outs that needs to be exported
     std::vector<std::pair<std::string, std::string>> _registed_outs;
+	///< node execute order
+	std::vector<std::string> _nodes_exec_order;
 };
 
 
diff --git a/framework/graph/node.h b/framework/graph/node.h
index be5a17f..7a78144 100644
--- a/framework/graph/node.h
+++ b/framework/graph/node.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -155,6 +155,17 @@ public:
     /// Access to attributes.
     AttrInfo& attr() { return _attr; } 
 
+	/// inspect if node attr have target attr name
+	inline bool inspect_attr(const std::string& attr_name) {
+		auto& attrs = this->attr();
+		auto it_end = attrs.parameter.end();
+		auto it_find = attrs.parameter.find(attr_name);
+		if(it_find != it_end) {
+			return true;
+		}
+		return false;
+	}
+
     /**
     * \brief Get target attr by name
     * \param attr_name stand for target_attr name
@@ -163,7 +174,7 @@ public:
     template<typename T>
     T get_attr(std::string& attr_name) {
         auto& attrs = this->attr();
-        const auto& it_end = attrs.parameter.end();
+        auto it_end = attrs.parameter.end();
         auto it_find = attrs.parameter.find(attr_name);
         if(it_find == it_end) {
             LOG(FATAL) << "Target attr name(" << attr_name << ") not found.";
@@ -180,7 +191,7 @@ public:
     template<typename T>
     Status set_attr(const std::string& attr_name, const T val) {
         auto& attrs = this->attr();    
-        const auto& it_end = attrs.parameter.end();
+        auto it_end = attrs.parameter.end();
         auto it_find = attrs.parameter.find(attr_name);
         if(it_find != it_end) {
             return Status::FAIL();
@@ -196,7 +207,7 @@ public:
     */
     Status remove_attr(const std::string& attr_name) {
         auto& attrs = this->attr();
-        const auto& it_end = attrs.parameter.end();
+        auto it_end = attrs.parameter.end();
         auto it_find = attrs.parameter.find(attr_name);
         if(it_find != it_end) {
             attrs.parameter.erase(attr_name);
@@ -248,6 +259,7 @@ public:
         _need_wait = operand._need_wait;
         _in_degree = operand._in_degree;
         _out_degree = operand._out_degree;
+        return *this;
     }
     
     /// print message
diff --git a/framework/lite/code_gen_cpp.cpp b/framework/lite/code_gen_cpp.cpp
index 41740f5..ffe92ec 100644
--- a/framework/lite/code_gen_cpp.cpp
+++ b/framework/lite/code_gen_cpp.cpp
@@ -18,8 +18,8 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_header_start() {
 	_code<<"#include <stdio.h>\n";
 	_code<<"#include <stdlib.h>\n";
 	_code<<"#include <string.h>\n\n";
+	_code<<"#include <saber/lite/core/common_lite.h>\n";
     _code<<"#include <saber/lite/funcs/detection_lite.h>\n";
-    _code<<"#include <saber/lite/funcs/op_base.h>\n";
     _code<<"#include <saber/lite/funcs/saber_activation.h>\n";
     _code<<"#include <saber/lite/funcs/saber_concat.h>\n";
     _code<<"#include <saber/lite/funcs/saber_detection_output.h>\n";
@@ -29,14 +29,14 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_header_start() {
     _code<<"#include <saber/lite/funcs/saber_priorbox.h>\n";
     _code<<"#include <saber/lite/funcs/saber_slice.h>\n";
     _code<<"#include <saber/lite/funcs/timer_lite.h>\n";
-    _code<<"#include <saber/lite/funcs/utils_arm.h>\n";
     _code<<"#include <saber/lite/funcs/saber_conv.h>\n";
     _code<<"#include <saber/lite/funcs/saber_conv_act.h>\n";
-    _code<<"#include <saber/lite/funcs/saber_conv_batchnorm_scale.h>\n";
-    _code<<"#include <saber/lite/funcs/saber_conv_batchnorm_scale_relu.h>\n";
     _code<<"#include <saber/lite/funcs/saber_fc.h>\n";
     _code<<"#include <saber/lite/funcs/saber_pooling.h>\n";
-    _code<<"#include <saber/lite/funcs/saber_softmax.h>\n";
+    _code<<"#include <saber/lite/funcs/saber_softmax.h>\n\n";
+	_code<<"using namespace anakin;\n";
+	_code<<"using namespace anakin::saber;\n";
+	_code<<"using namespace anakin::saber::lite;\n\n";
     _code<<"namespace anakin { \n\n";
 }	
 
@@ -61,53 +61,86 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_source_end() {
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 void GenCPP<Ttype, Dtype, Ptype>::gen_tensors() {
-	_code<<"\n// generating and setting tensors \n";
+	_code<<"\n// generating tensors \n";
 	for(auto it = this->_tensor_map.begin(); it != this->_tensor_map.end(); ++it) {
 		auto& edge_name = it->first;
 		auto& edge_info = it->second;
 		if(! edge_info.is_shared) {
-			_code.feed("tensor %s;\n", edge_name.c_str());
-			_code.feed("%s.set_valid_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.valid_shape[0],
-																				edge_info.valid_shape[1],
-																				edge_info.valid_shape[2],
-																				edge_info.valid_shape[3]);
-			_code.feed("%s.set_real_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.real_shape[0],
-																			   edge_info.real_shape[1],
-																			   edge_info.real_shape[2],
-																			   edge_info.real_shape[3]);
+			_code.feed("Tensor<CPU, AK_FLOAT> %s;\n", edge_name.c_str());
+			_code.feed("Shape %s_real_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.real_shape[0],
+																			edge_info.real_shape[1],
+																			edge_info.real_shape[2],
+																			edge_info.real_shape[3]);
+			_code.feed("Shape %s_valid_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.valid_shape[0],
+																				  edge_info.valid_shape[1],
+																				  edge_info.valid_shape[2],
+																				  edge_info.valid_shape[3]); 
 		}
 	}
 	for(auto it = this->_tensor_map.begin(); it != this->_tensor_map.end(); ++it) {
 		auto& edge_name = it->first;
 		auto& edge_info = it->second;
 		if(edge_info.is_shared) {
-			_code.feed("tensor %s;\n", edge_name.c_str());
-			_code.feed("%s.set_valid_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.valid_shape[0],
-																	   edge_info.valid_shape[1],
-																	   edge_info.valid_shape[2],
-																	   edge_info.valid_shape[3]);
-			_code.feed("%s.share_from(%s);\n", edge_name.c_str(), edge_info.share_from.c_str());
+			_code.feed("Tensor<CPU, AK_FLOAT> %s;\n", edge_name.c_str());
+			_code.feed("Shape %s_valid_shape(%d,%d,%d,%d);\n", edge_name.c_str(), edge_info.valid_shape[0],
+																				  edge_info.valid_shape[1],
+																				  edge_info.valid_shape[2],
+																				  edge_info.valid_shape[3]); 
 		}
 	}
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
+void GenCPP<Ttype, Dtype, Ptype>::tensors_init() {
+	_code<<"\n// initialize tensors \n";
+	_code.feed("void %s_tensors_init() {\n", _code_name.c_str());
+	for(auto it = this->_tensor_map.begin(); it != this->_tensor_map.end(); ++it) {
+		auto& edge_name = it->first;
+		auto& edge_info = it->second;
+		if(! edge_info.is_shared) {
+			_code.feed("    %s.re_alloc(%s_real_shape);\n", edge_name.c_str(), edge_name.c_str());
+			_code.feed("    %s.set_shape(%s_valid_shape);\n", edge_name.c_str(), edge_name.c_str());
+		}
+	}
+	for(auto it = this->_tensor_map.begin(); it != this->_tensor_map.end(); ++it) {
+		auto& edge_name = it->first;
+		auto& edge_info = it->second;
+		if(edge_info.is_shared) {
+			_code.feed("    %s.set_shape(%s_valid_shape);\n", edge_name.c_str(), edge_name.c_str());
+			_code.feed("    %s.share_from(%s);\n", edge_name.c_str(), edge_info.share_from.c_str());
+		}
+	}
+	_code<<"}\n";
+
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
 void GenCPP<Ttype, Dtype, Ptype>::gen_model_ios() {
 	_code<<"\n// generating model's I/O \n";
 	for(auto & node_name : this->_exec_node_order) {
 		auto& node_info = this->_graph_node_map[node_name];
-		_code.feed("std::vector<tensor*> %s_ins;\n", node_name.c_str());
-		for(auto &edge_in : node_info.ins) {
-			_code.feed("%s_ins.push_back(&%s);\n", node_name.c_str(), edge_in.c_str());
-		}
-		_code.feed("std::vector<tensor*> %s_outs;\n", node_name.c_str());
-		for(auto &edge_out : node_info.outs) {
-			_code.feed("%s_outs.push_back(&%s);\n", node_name.c_str(), edge_out.c_str());
-		}
+		_code.feed("std::vector<Tensor<CPU, AK_FLOAT>*> %s_ins;\n", node_name.c_str());
+		_code.feed("std::vector<Tensor<CPU, AK_FLOAT>*> %s_outs;\n", node_name.c_str());
 	}
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
+void GenCPP<Ttype, Dtype, Ptype>::model_ios_init() {
+	_code<<"\n// initialize model's I/O \n";
+    _code.feed("void %s_model_ios_init() {\n", _code_name.c_str());
+    for(auto & node_name : this->_exec_node_order) {
+        auto& node_info = this->_graph_node_map[node_name];
+        for(auto &edge_in : node_info.ins) {
+            _code.feed("    %s_ins.push_back(&%s);\n", node_name.c_str(), edge_in.c_str());
+        }
+        for(auto &edge_out : node_info.outs) {
+            _code.feed("    %s_outs.push_back(&%s);\n", node_name.c_str(), edge_out.c_str());
+        }
+    }	
+	_code<<"}\n";
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
 void GenCPP<Ttype, Dtype, Ptype>::gen_ops() {
 	_code<<"\n// generating model's operations\n";
 	for(auto & node_name : this->_exec_node_order) {
@@ -124,7 +157,7 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_ops() {
 template<typename Ttype, DataType Dtype, Precision Ptype>
 void GenCPP<Ttype, Dtype, Ptype>::gen_init_impl() {
 	_code<<"// initial function for model.\n"; 
-	_code.feed("void %s_init(const Context& ctx) {\n", _code_name.c_str());
+	_code.feed("void %s_init(Context& ctx) {\n", _code_name.c_str());
 	for(auto & node_name : this->_exec_node_order) {
 		if(this->_graph_node_map[node_name].op_name == "Input" || this->_graph_node_map[node_name].op_name == "Output") {
 			continue;
@@ -183,7 +216,7 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_head_api() {
 	}
 
 	// gen api for getting graph input tensor
-	_code << "tensor* get_in(const char* in_name);\n\n";
+	_code << "LITE_EXPORT Tensor<CPU, AK_FLOAT>* get_in(const char* in_name);\n\n";
 
 	// gen gloss for graph outs
 	_code << "/// Model " << _code_name << " have  " << this->_outs.size() << " outputs.\n";
@@ -201,22 +234,22 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_head_api() {
 		}
 	}
 	// gen api for getting graph output tensor
-	_code << "tensor* get_out(const char* out_name);\n\n";
+	_code << "LITE_EXPORT Tensor<CPU, AK_FLOAT>* get_out(const char* out_name);\n\n";
 
 	// gen weights loading function
-	_code.feed("bool %s_load_param(const char* param_path);\n\n", _code_name.c_str());
+	_code.feed("LITE_EXPORT bool %s_load_param(const char* param_path);\n\n", _code_name.c_str());
 
 	// gen api for model init
 	_code.feed("/// %s_init should only be invoked once when input shape changes.\n", _code_name.c_str());
-	_code.feed("void %s_init(const context& ctx);\n\n", _code_name.c_str());
+	_code.feed("LITE_EXPORT void %s_init(Context& ctx);\n\n", _code_name.c_str());
 
 	// gen api for model prediction
 	_code.feed("/// Running prediction for model %s.\n", _code_name.c_str());
-	_code.feed("void %s_prediction();\n\n", _code_name.c_str());
+	_code.feed("LITE_EXPORT void %s_prediction();\n\n", _code_name.c_str());
 
 	// gen free function
 	_code.feed("/// Release all resource used by model %s.\n", _code_name.c_str());
-	_code.feed("void %s_release_resource();\n\n", _code_name.c_str());
+	_code.feed("LITE_EXPORT void %s_release_resource();\n\n", _code_name.c_str());
 
 }
 
@@ -224,7 +257,7 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 void GenCPP<Ttype, Dtype, Ptype>::gen_head_api_impl() {
 	// gen api for getting graph input tensor
 	_code << "\n// gen api for getting graph input tensor \n";
-	_code << "tensor* get_in(const char* in_name) {\n";
+	_code << "Tensor<CPU, AK_FLOAT>* get_in(const char* in_name) {\n";
 	_code.feed("    if(strcmp(in_name, \"%s\") == 0) {\n", this->_ins[0].c_str());
 	auto node_info = this->_graph_node_map[this->_ins[0]]; 
 	auto edge_info = this->_tensor_map[node_info.outs[0]];
@@ -240,7 +273,7 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_head_api_impl() {
 
 	// gen api for getting graph output tensor
 	_code << "\n// gen api for getting graph output tensor \n";
-	_code << "tensor& get_out(const char* out_name) {\n";
+	_code << "Tensor<CPU, AK_FLOAT>* get_out(const char* out_name) {\n";
 	_code.feed("    if(strcmp(out_name, \"%s\") == 0) {\n", this->_outs[0].c_str());
 	node_info = this->_graph_node_map[this->_outs[0]]; 
 	edge_info = this->_tensor_map[node_info.ins[0]];
@@ -257,7 +290,7 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_head_api_impl() {
 	// gen weights loading function
 	_code.feed("float *%s = nullptr; // global weights start pointer \n", _g_weights_ptr_name.c_str());
 	_code.feed("bool %s_load_param(const char* param_path) {\n", _code_name.c_str());
-	_code << "    FILE *f = fopen(param_path.c_str(), \"rb\"); \n";
+	_code << "    FILE *f = fopen(param_path, \"rb\"); \n";
 	_code << "    if(!f) {\n";
 	_code << "        return false;\n    }\n";
 	_code << "    fseek(f, 0, SEEK_END);\n";
@@ -266,6 +299,8 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_head_api_impl() {
 	_code.feed("    %s = new float[fsize + 1];\n", _g_weights_ptr_name.c_str());
 	_code.feed("    fread(%s, fsize, sizeof(float), f);\n", _g_weights_ptr_name.c_str());
 	_code << "    fclose(f);\n";
+	_code.feed("    %s_tensors_init();\n", _code_name.c_str()); // invoke (model_name)_tensors_init()
+	_code.feed("    %s_model_ios_init();\n", _code_name.c_str()); // invoke (model_name)_model_ios_init()
 	for(auto & node_name : this->_exec_node_order) {
 		if(this->_graph_node_map[node_name].op_name == "Input" || this->_graph_node_map[node_name].op_name == "Output") {
 			continue;
@@ -314,8 +349,12 @@ void GenCPP<Ttype, Dtype, Ptype>::gen_source() {
 	gen_source_start(); 
 	// generate tensors 
 	gen_tensors();
+	// tensors init
+	tensors_init();
 	// generate i/o
 	gen_model_ios();
+	// initial model i/o
+	model_ios_init();
 	// generate ops
 	gen_ops();
 	// gen head api implement
diff --git a/framework/lite/code_gen_cpp.h b/framework/lite/code_gen_cpp.h
index bba400c..88cdf97 100644
--- a/framework/lite/code_gen_cpp.h
+++ b/framework/lite/code_gen_cpp.h
@@ -57,6 +57,11 @@ private:
 	 * \brief generate tensors for edges
 	 */
 	void gen_tensors();
+	
+	/**
+	 * \brief initialize tensors for edges
+	 */
+	void tensors_init();
 
 	/**
 	 * \brief generate model's inputs and outputs
@@ -64,6 +69,11 @@ private:
 	void gen_model_ios();
 
 	/**
+	 * \brief initialize model's inputs and outputs
+	 */
+	void model_ios_init();
+
+	/**
 	 * \brief generate operations for model
 	 */
 	virtual void gen_ops();
diff --git a/framework/lite/op_map_cpp.cpp b/framework/lite/op_map_cpp.cpp
index 379d61c..3be8f06 100644
--- a/framework/lite/op_map_cpp.cpp
+++ b/framework/lite/op_map_cpp.cpp
@@ -1,4 +1,5 @@
 #include "framework/lite/op_map.h"
+#include "framework/lite/utils.h"
 
 namespace anakin {
 
@@ -135,51 +136,62 @@ std::string ParserConvBatchnormScale(graph::AttrInfo& attr,
     int weights_size = weights_shape[2]*weights_shape[3];
     int num_output = weights_shape[0]*weights_shape[1];
 
-	writter.register_weights(node_name, weights);
-	if(bias_term) {
-		auto bias = get_attr<PBlock<float, NV>>("weight_2", attr);
-		writter.register_weights(node_name, bias);
-	}
-
-    auto gen_vec_code = [](std::vector<float> pvec) -> std::string {
-		CodeWritter dims_vec_code;
-		dims_vec_code<<"{";
-		for(int i=0; i<pvec.size()-1; i++) {
-			dims_vec_code<<pvec[i]<<",";
-		}
-		if(pvec.size() > 0) {
-			dims_vec_code<<pvec[pvec.size()-1] << "}";
-		} else {
-			dims_vec_code<< "}";
-		}
-		return dims_vec_code.get_code_string();
-	};
-
-
     // get batchnorm param
     auto epsilon = get_attr<float>("batchnorm_0_epsilon", attr);
     auto momentum = get_attr<float>("batchnorm_0_momentum", attr);
     auto batch_norm_weight_1 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_1", attr);
-    auto batch_norm_weight_1_vector = gen_vec_code(batch_norm_weight_1.vector());
+    auto batch_norm_weight_1_vector = batch_norm_weight_1.vector();
     auto batch_norm_weight_2 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_2", attr);
-    auto batch_norm_weight_2_vector = gen_vec_code(batch_norm_weight_2.vector());
+    auto batch_norm_weight_2_vector = batch_norm_weight_2.vector();
     auto batch_norm_weight_3 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_3", attr);
-    auto batch_norm_weight_3_vector = gen_vec_code(batch_norm_weight_3.vector()); // ???? not impl bias
+    auto batch_norm_weight_3_vector = batch_norm_weight_3.vector();
 
     // get scale param
     auto scale_num_axes = get_attr<int>("scale_0_num_axes", attr);
     auto scale_bias_term = get_attr<bool>("scale_0_bias_term", attr);
     auto scale_axis = get_attr<int>("scale_0_axis", attr);
     auto scale_weight_1 = get_attr<PBlock<float, NV>>("scale_0_weight_1", attr);
-    auto scale_weight_1_vector = gen_vec_code(scale_weight_1.vector());
+    auto scale_weight_1_vector = scale_weight_1.vector();
     auto scale_weight_2 = get_attr<PBlock<float, NV>>("scale_0_weight_2", attr);
-    auto scale_weight_2_vector = gen_vec_code(scale_weight_2.vector());
+    auto scale_weight_2_vector = scale_weight_2.vector();
+
+
+	if(bias_term) {
+		auto bias = get_attr<PBlock<float, NV>>("weight_2", attr);
+		update_weights(weights, bias,
+					   weights_shape[0], weights_shape[1], weights_shape[2], weights_shape[3],
+					   bias_term, 
+					   batch_norm_weight_3_vector[0], epsilon, 
+					   batch_norm_weight_1_vector, 
+					   batch_norm_weight_2_vector,
+					   scale_weight_1_vector,
+					   scale_weight_2_vector,
+					   scale_bias_term);
+	
+		
+		writter.register_weights(node_name, weights);
+		writter.register_weights(node_name, bias);
+	} else {
+		auto bias = PBlock<float, NV>();
+		update_weights(weights, bias,
+					   weights_shape[0], weights_shape[1], weights_shape[2], weights_shape[3],
+					   false, 
+					   batch_norm_weight_3_vector[0], epsilon, 
+					   batch_norm_weight_1_vector, 
+					   batch_norm_weight_2_vector,
+					   scale_weight_1_vector,
+					   scale_weight_2_vector,
+					   scale_bias_term);
+
+		writter.register_weights(node_name, weights);
+		writter.register_weights(node_name, bias);
+	}
 
     auto offset_info = writter.get_weights_by_name(node_name);
 
 	// gen cpp code
 	CodeWritter code_w;
-    code_w.feed("%s.load_param(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%s,%f,%f,%s,%s,%s,%s,%s,%s+%d,%s+%d);\n", node_name.c_str(),
+    code_w.feed("%s.load_param(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%s,%s+%d,%s+%d);\n", node_name.c_str(),
                                            weights_size,
                                            num_output,
                                            group,
@@ -191,14 +203,7 @@ std::string ParserConvBatchnormScale(graph::AttrInfo& attr,
                                            padding[0],
                                            dilation_rate[1],
                                            dilation_rate[0],
-                                           bias_term ? "true":"false",
-                                           epsilon,
-                                           momentum,
-                                           batch_norm_weight_1_vector.c_str(),
-                                           batch_norm_weight_2_vector.c_str(),
-                                           scale_weight_1_vector.c_str(),
-                                           scale_weight_2_vector.c_str(),
-                                           scale_bias_term ? "true" : "false",
+                                           "true",
                                            weights_ptr_name.c_str(),
                                            offset_info.weights[0].offset,
                                            weights_ptr_name.c_str(),
@@ -227,51 +232,61 @@ std::string ParserConvBatchnormScaleRelu(graph::AttrInfo& attr,
     int weights_size = weights_shape[2]*weights_shape[3];
     int num_output = weights_shape[0]*weights_shape[1];
 
-	writter.register_weights(node_name, weights);
-	if(bias_term) {
-		auto bias = get_attr<PBlock<float, NV>>("weight_2", attr);
-		writter.register_weights(node_name, bias);
-	}
-
-    auto gen_vec_code = [](std::vector<float> pvec) -> std::string {
-		CodeWritter dims_vec_code;
-		dims_vec_code<<"{";
-		for(int i=0; i<pvec.size()-1; i++) {
-			dims_vec_code<<pvec[i]<<",";
-		}
-		if(pvec.size() > 0) {
-			dims_vec_code<<pvec[pvec.size()-1] << "}";
-		} else {
-			dims_vec_code<< "}";
-		}
-		return dims_vec_code.get_code_string();
-	};
-
-
     // get batchnorm param
     auto epsilon = get_attr<float>("batchnorm_0_epsilon", attr);
     auto momentum = get_attr<float>("batchnorm_0_momentum", attr);
     auto batch_norm_weight_1 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_1", attr);
-    auto batch_norm_weight_1_vector = gen_vec_code(batch_norm_weight_1.vector());
+    auto batch_norm_weight_1_vector = batch_norm_weight_1.vector();
     auto batch_norm_weight_2 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_2", attr);
-    auto batch_norm_weight_2_vector = gen_vec_code(batch_norm_weight_2.vector());
+    auto batch_norm_weight_2_vector = batch_norm_weight_2.vector();
     auto batch_norm_weight_3 = get_attr<PBlock<float, NV>>("batchnorm_0_weight_3", attr);
-    auto batch_norm_weight_3_vector = gen_vec_code(batch_norm_weight_3.vector()); // ???? not impl bias
+    auto batch_norm_weight_3_vector = batch_norm_weight_3.vector(); 
 
     // get scale param
     auto scale_num_axes = get_attr<int>("scale_0_num_axes", attr);
     auto scale_bias_term = get_attr<bool>("scale_0_bias_term", attr);
     auto scale_axis = get_attr<int>("scale_0_axis", attr);
     auto scale_weight_1 = get_attr<PBlock<float, NV>>("scale_0_weight_1", attr);
-    auto scale_weight_1_vector = gen_vec_code(scale_weight_1.vector());
+    auto scale_weight_1_vector = scale_weight_1.vector();
     auto scale_weight_2 = get_attr<PBlock<float, NV>>("scale_0_weight_2", attr);
-    auto scale_weight_2_vector = gen_vec_code(scale_weight_2.vector());
+    auto scale_weight_2_vector = scale_weight_2.vector();
+
+	if(bias_term) {
+		auto bias = get_attr<PBlock<float, NV>>("weight_2", attr);
+		update_weights(weights, bias,
+					   weights_shape[0], weights_shape[1], weights_shape[2], weights_shape[3],
+					   bias_term, 
+					   batch_norm_weight_3_vector[0], epsilon, 
+					   batch_norm_weight_1_vector, 
+					   batch_norm_weight_2_vector,
+					   scale_weight_1_vector,
+					   scale_weight_2_vector,
+					   scale_bias_term);
+	
+		
+		writter.register_weights(node_name, weights);
+		writter.register_weights(node_name, bias);
+	} else {
+		auto bias = PBlock<float, NV>();
+		update_weights(weights, bias,
+					   weights_shape[0], weights_shape[1], weights_shape[2], weights_shape[3],
+					   false, 
+					   batch_norm_weight_3_vector[0], epsilon, 
+					   batch_norm_weight_1_vector, 
+					   batch_norm_weight_2_vector,
+					   scale_weight_1_vector,
+					   scale_weight_2_vector,
+					   scale_bias_term);
+
+		writter.register_weights(node_name, weights);
+		writter.register_weights(node_name, bias);
+	}
 
     auto offset_info = writter.get_weights_by_name(node_name);
 
 	// gen cpp code
 	CodeWritter code_w;
-    code_w.feed("%s.load_param(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%s,%f,%f,%s,%s,%s,%s,%s,Active_relu,%s+%d,%s+%d);\n", node_name.c_str(),
+    code_w.feed("%s.load_param(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%s,Active_relu,%s+%d,%s+%d);\n", node_name.c_str(),
                                            weights_size,
                                            num_output,
                                            group,
@@ -283,14 +298,7 @@ std::string ParserConvBatchnormScaleRelu(graph::AttrInfo& attr,
                                            padding[0],
                                            dilation_rate[1],
                                            dilation_rate[0],
-                                           bias_term ? "true":"false",
-                                           epsilon,
-                                           momentum,
-                                           batch_norm_weight_1_vector.c_str(),
-                                           batch_norm_weight_2_vector.c_str(),
-                                           scale_weight_1_vector.c_str(),
-                                           scale_weight_2_vector.c_str(),
-                                           scale_bias_term ? "true" : "false",
+                                           "true",
                                            weights_ptr_name.c_str(),
                                            offset_info.weights[0].offset,
                                            weights_ptr_name.c_str(),
@@ -356,6 +364,16 @@ std::string ParserEltwise(graph::AttrInfo& attr,
     auto type = get_attr<std::string>("type", attr); 
     auto coeff = get_attr<PTuple<float>>("coeff", attr);
 
+	std::string eltwise_type_str("Eltwise_unknow");
+
+	if (type == "Add") {
+        eltwise_type_str = "Eltwise_sum";
+    } else if (type == "Max") {
+        eltwise_type_str = "Eltwise_max";
+    } else {
+        eltwise_type_str = "Eltwise_prod";
+    }
+
 	CodeWritter coeff_vec_code;
 	coeff_vec_code<<"{";
 	for(int i=0; i<coeff.size()-1; i++) {
@@ -369,7 +387,8 @@ std::string ParserEltwise(graph::AttrInfo& attr,
 
 	// gen cpp code
 	CodeWritter code_w; 
-	code_w.feed("%s.load_param(%s, %s);\n", node_name.c_str(), type.c_str(), coeff_vec_code.get_code_string().c_str());
+	code_w.feed("%s.load_param(%s, %s);\n", node_name.c_str(), eltwise_type_str.c_str(), 
+											coeff_vec_code.get_code_string().c_str());
 	return code_w.get_code_string();
 }
 
@@ -619,8 +638,8 @@ std::unordered_map<std::string, OpParser> OPERATION_MAP({
 	{"Activation", {"SaberActivation", ParserActivation} }, // done
     {"ReLU", {"SaberActivation",ParserRelu}}, // done
 	{"ConvRelu", {"SaberConvAct2D", ParserConvolutionRelu} },  // done
-	{"ConvBatchnormScaleRelu", {"SaberConvBatchnormScaleRelu", ParserConvBatchnormScaleRelu}}, // done have question ??
-	{"ConvBatchnormScale", {"SaberConvBatchnormScale", ParserConvBatchnormScale}}, //done
+	{"ConvBatchnormScaleRelu", {"SaberConvAct2D", ParserConvBatchnormScaleRelu}}, // done have question ??
+	{"ConvBatchnormScale", {"SaberConv2D", ParserConvBatchnormScale}}, //done
 	{"Concat", {"SaberConcat", ParserConcat} },  // done
 	{"DetectionOutput", {"SaberDectionOutput", ParserDectionOutput} }, // done 
 	{"Eltwise", {"SaberEltwise", ParserEltwise} }, //done
diff --git a/framework/lite/utils.h b/framework/lite/utils.h
new file mode 100644
index 0000000..e6ec8da
--- /dev/null
+++ b/framework/lite/utils.h
@@ -0,0 +1,76 @@
+/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_FRAMEWORK_LITE_UTILS_H
+#define ANAKIN_FRAMEWORK_LITE_UTILS_H
+
+#include <string>
+#include <unordered_map>
+
+namespace anakin {
+
+namespace lite {
+
+/**
+ * \brief  update conv weights with batchnorm and scale parameters.
+ */
+template<typename D, typename T>
+void update_weights(PBlock<D, T> weights, PBlock<D, T> bias,
+					int n, int c, int h, int w, bool conv_bias_term, 
+					float batchnorm_scale, float batchnorm_eps, 
+					std::vector<float> batchnorm_mean, 
+					std::vector<float> batchnorm_variance, 
+					std::vector<float> scale_w, 
+					std::vector<float> scale_b, 
+					bool scale_bias_term) {
+	D* weights_p = weights.h_tensor().mutable_data();
+	if(!conv_bias_term) {
+		bias.re_alloc({1,batchnorm_mean.size(),1,1});
+		void* new_bias_data = bias.h_tensor().mutable_data();
+		memset(new_bias_data, 0, sizeof(D) * bias.h_tensor().size());
+	}
+	D* bias_p = bias.h_tensor().mutable_data();
+
+	batchnorm_scale = (batchnorm_scale == 0) ? 1.f : batchnorm_scale;
+	int chw = c*h*w;
+	for(int i=0; i <n; i++ ) {
+		D alpha = 0.f;
+		D beta = 0.f;
+		// insert batchnorm parameters
+		alpha = batchnorm_variance[i] * batchnorm_scale + batchnorm_eps;
+		alpha = 1.f / sqrtf(alpha);
+		beta = -1.f * (batchnorm_mean[i] * batchnorm_scale);
+		beta = beta * alpha;
+
+		// insert scale parameters
+		alpha = scale_w[i] * alpha;
+		if(scale_bias_term) {
+			beta = beta * scale_w[i] + scale_b[i];
+		} else {
+			beta = beta * scale_w[i];
+		}
+		for(int j=0; j < chw; j++) {
+			weights_p[i * chw + j] *= alpha;
+		}
+		bias_p[i] *= alpha;
+		bias_p[i] += beta;
+	}
+}
+
+} /* namespace lite */
+
+} /* namespace anakin */
+
+#endif
diff --git a/framework/model_parser/CMakeLists.txt b/framework/model_parser/CMakeLists.txt
index dd0e1a9..c6bc3e7 100644
--- a/framework/model_parser/CMakeLists.txt
+++ b/framework/model_parser/CMakeLists.txt
@@ -1,10 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     CMakeLists files in the model parser directory of project
-# @auther   cuichaowen
-# @date     2017-10-24
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 set(ANAKIN_BASE_SRC "")
 
 # add ak_base_source files
diff --git a/framework/model_parser/parser/model_io.cpp b/framework/model_parser/parser/model_io.cpp
index 795f531..52b67bc 100644
--- a/framework/model_parser/parser/model_io.cpp
+++ b/framework/model_parser/parser/model_io.cpp
@@ -13,7 +13,7 @@ NodeIO<Ttype, Dtype, Ptype>& NodeIO<Ttype, Dtype, Ptype>::operator>>(const NodeP
     node_p->need_wait() = node_proto.need_wait();
     node_p->lane() = node_proto.lane();
     auto it = node_proto.attr().begin();
-
+    DLOG(INFO)<<"read :"<<node_p->name();
     for (; it != node_proto.attr().end(); ++it) {
         auto& key = it->first;
         auto& value = it->second;
@@ -344,11 +344,20 @@ template class NodeIO<X86, AK_FLOAT, Precision::INT8>;
 #endif
 
 #ifdef USE_ARM_PLACE
+#ifdef ANAKIN_TYPE_FP32
 template class NodeIO<ARM, AK_FLOAT, Precision::FP32>;
+#endif
+
+#ifdef ANAKIN_TYPE_FP16
 template class NodeIO<ARM, AK_FLOAT, Precision::FP16>;
+#endif
+
+#ifdef ANAKIN_TYPE_INT8
 template class NodeIO<ARM, AK_FLOAT, Precision::INT8>;
 #endif
 
+#endif
+
 } /* parser */
 
 } /* anakin */
diff --git a/framework/model_parser/parser/model_io.h b/framework/model_parser/parser/model_io.h
index 7ba9ba7..b32f5b8 100644
--- a/framework/model_parser/parser/model_io.h
+++ b/framework/model_parser/parser/model_io.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/model_parser/parser/parser.cpp b/framework/model_parser/parser/parser.cpp
index f70ee27..1f1fa96 100644
--- a/framework/model_parser/parser/parser.cpp
+++ b/framework/model_parser/parser/parser.cpp
@@ -22,42 +22,6 @@ Status load(graph::Graph<Ttype, Dtype, Ptype>* graph, std::string& model_path) {
     return load(graph, model_path.c_str());
 }
 
-#ifdef USE_CUDA
-template
-Status load<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status load<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status load<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
-#ifdef USE_X86_PLACE
-template
-Status load<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status load<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status load<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
-#ifdef USE_ARM_PLACE
-template
-Status load<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status load<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status load<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status load(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
 #if 0
@@ -86,13 +50,16 @@ Status load(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
 
     google::protobuf::io::ZeroCopyInputStream* raw_input = new google::protobuf::io::FileInputStream(
         file_descriptor);
+
     google::protobuf::io::CodedInputStream* coded_input = new google::protobuf::io::CodedInputStream(
         raw_input);
+
     coded_input->SetTotalBytesLimit(ProtoReadBytesLimit, 536870912);
+
     bool success = graph_proto.ParseFromCodedStream(coded_input);
 
     if (!success) {
-        LOG(FATAL) << " Parsing GraphProto " << model_path;
+        LOG(FATAL) << " Parsing GraphProto " << model_path << " ERROR";
     }
 
     delete coded_input;
@@ -100,8 +67,8 @@ Status load(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
     close(file_descriptor);
 #endif
     // fill the graph with name
-    LOG(INFO) << " graph name: " << graph_proto.name();
-    graph->name() = graph_proto.name();
+    LOG(INFO) << "graph name: " << graph_proto.name();
+    graph->set_name(graph_proto.name());
 
     // fill the graph with ins/outs
     for (int i = 0; i < graph_proto.ins().size(); i++) {
@@ -190,83 +157,11 @@ Status load(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
     return Status::OK();
 }
 
-#ifdef USE_CUDA
-template
-Status load<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
-        const char* model_path);
-template
-Status load<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
-        const char* model_path);
-template
-Status load<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
-        const char* model_path);
-#endif
-
-#ifdef USE_X86_PLACE
-template
-Status load<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
-        const char* model_path);
-template
-Status load<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
-        const char* model_path);
-template
-Status load<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
-        const char* model_path);
-#endif
-
-#ifdef USE_ARM_PLACE
-template
-Status load<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
-        const char* model_path);
-template
-Status load<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
-        const char* model_path);
-template
-Status load<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
-        const char* model_path);
-#endif
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status save(graph::Graph<Ttype, Dtype, Ptype>* graph, std::string& model_path) {
     return save(graph, model_path.c_str());
 }
 
-#ifdef USE_CUDA
-template
-Status save<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status save<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status save<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
-#ifdef USE_X86_PLACE
-template
-Status save<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status save<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status save<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
-#ifdef USE_ARM_PLACE
-template
-Status save<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
-        std::string& model_path);
-template
-Status save<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
-        std::string& model_path);
-template
-Status save<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
-        std::string& model_path);
-#endif
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status save(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
     std::fstream output(model_path, std::ios::out | std::ios::trunc | std::ios::binary);
@@ -352,8 +247,38 @@ Status save(graph::Graph<Ttype, Dtype, Ptype>* graph, const char* model_path) {
     return Status::OK();
 }
 
+
 #ifdef USE_CUDA
 template
+Status load<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
+        const char* model_path);
+template
+Status load<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
+        const char* model_path);
+template
+Status load<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
+        const char* model_path);
+        template
+Status save<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
+        std::string& model_path);
+template
+Status save<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
+        std::string& model_path);
+template
+Status save<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
+        std::string& model_path);
+
+template
+Status load<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
+        std::string& model_path);
+template
+Status load<NV, AK_FLOAT, Precision::FP16>(graph::Graph<NV, AK_FLOAT, Precision::FP16>* graph,
+        std::string& model_path);
+template
+Status load<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision::INT8>* graph,
+        std::string& model_path);
+
+template
 Status save<NV, AK_FLOAT, Precision::FP32>(graph::Graph<NV, AK_FLOAT, Precision::FP32>* graph,
         const char* model_path);
 template
@@ -366,6 +291,36 @@ Status save<NV, AK_FLOAT, Precision::INT8>(graph::Graph<NV, AK_FLOAT, Precision:
 
 #ifdef USE_X86_PLACE
 template
+Status load<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
+        const char* model_path);
+template
+Status load<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
+        const char* model_path);
+template
+Status load<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
+        const char* model_path);
+
+template
+Status save<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
+        std::string& model_path);
+template
+Status save<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
+        std::string& model_path);
+template
+Status save<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
+        std::string& model_path);
+
+template
+Status load<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
+        std::string& model_path);
+template
+Status load<X86, AK_FLOAT, Precision::FP16>(graph::Graph<X86, AK_FLOAT, Precision::FP16>* graph,
+        std::string& model_path);
+template
+Status load<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precision::INT8>* graph,
+        std::string& model_path);
+
+template
 Status save<X86, AK_FLOAT, Precision::FP32>(graph::Graph<X86, AK_FLOAT, Precision::FP32>* graph,
         const char* model_path);
 template
@@ -377,17 +332,56 @@ Status save<X86, AK_FLOAT, Precision::INT8>(graph::Graph<X86, AK_FLOAT, Precisio
 #endif
 
 #ifdef USE_ARM_PLACE
+#ifdef ANAKIN_TYPE_FP32
+template
+Status load<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
+                                                    const char* model_path);
 template
 Status save<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
-        const char* model_path);
+                                                    std::string& model_path);
+template
+Status load<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
+                                                    std::string& model_path);
+template
+Status save<ARM, AK_FLOAT, Precision::FP32>(graph::Graph<ARM, AK_FLOAT, Precision::FP32>* graph,
+                                                    const char* model_path);
+#endif
+
+#ifdef ANAKIN_TYPE_FP16
+template
+Status load<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
+                                                    const char* model_path);
 template
 Status save<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
-        const char* model_path);
+                                                    std::string& model_path);
+template
+Status load<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
+                                                    std::string& model_path);
+template
+Status save<ARM, AK_FLOAT, Precision::FP16>(graph::Graph<ARM, AK_FLOAT, Precision::FP16>* graph,
+                                                    const char* model_path);
+#endif
+
+#ifdef ANAKIN_TYPE_INT8
+template
+Status load<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
+                                                    const char* model_path);
 template
 Status save<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
-        const char* model_path);
+                                                    std::string& model_path);
+template
+Status load<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
+                                                    std::string& model_path);
+template
+Status save<ARM, AK_FLOAT, Precision::INT8>(graph::Graph<ARM, AK_FLOAT, Precision::INT8>* graph,
+                                                    const char* model_path);
+#endif
+
 #endif
 
+
+
+
 } /* parser */
 
 } /* anakin */
diff --git a/framework/model_parser/parser/parser.h b/framework/model_parser/parser/parser.h
index 59d0917..45baa38 100644
--- a/framework/model_parser/parser/parser.h
+++ b/framework/model_parser/parser/parser.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/activation.cpp b/framework/operators/activation.cpp
index 8df3e6b..55e67a3 100644
--- a/framework/operators/activation.cpp
+++ b/framework/operators/activation.cpp
@@ -4,23 +4,20 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Activation<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ActivationHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param =
-        static_cast<ActivationHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_activation;
-    impl->_funcs_activation(ins, outs, param, ctx);
+#define INSTANCE_ACTIVATION(Ttype, Dtype, Ptype) \
+template<> \
+void Activation<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<ActivationHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = \
+        static_cast<ActivationHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_activation; \
+    impl->_funcs_activation(ins, outs, param, ctx); \
 }
-#endif
 
 /// TODO ... specialization other type of operator
 
-
 /// set helper
 template<typename Ttype, DataType Dtype, Precision Ptype>
 ActivationHelper<Ttype, Dtype, Ptype>::~ActivationHelper() {
@@ -30,13 +27,33 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ActivationHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Activation op parameter.";
     auto type = GET_PARAMETER(std::string, type);
-
     if (type == "TanH") {
         ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_tanh);
         _param_activation = param_activation;
     } else if (type == "Sigmoid") {
         ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_sigmoid);
         _param_activation = param_activation;
+    } else if (type == "PReLU") {
+        auto channel_shared = GET_PARAMETER(bool, channel_shared);
+        using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+        auto weights = GET_PARAMETER(pblock_type, weight_1);
+
+        PreluParam<Tensor4d<Ttype, Dtype>> prelu_param(channel_shared, &(weights.d_tensor()));
+        
+        ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_prelu, 0, 0, prelu_param);
+        _param_activation = param_activation;
+    } else if (type == "Stanh") {
+        ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_stanh);
+        _param_activation = param_activation;
+    } else if (type == "Relu") {
+         ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_relu);
+         _param_activation = param_activation;
+    } else if (type == "ClippedRelu") {
+         ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_clipped_relu);
+         _param_activation = param_activation;
+    } else if (type == "Elu") {
+         ActivationParam<Tensor4d<Ttype, Dtype>> param_activation(Active_elu);
+         _param_activation = param_activation;
     } else {
         LOG(FATAL) << "Other Activation type" << type << " should be replace by other ops.";
     }
@@ -48,35 +65,44 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ActivationHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_activation.init(ins, outs, _param_activation, SPECIFY, VENDER_IMPL, ctx));
+    SABER_CHECK(_funcs_activation.init(ins, outs, _param_activation, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ActivationHelper<Ttype, Dtype, Ptype>::InferShape(const
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+                                                         std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                                                         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
     SABER_CHECK(_funcs_activation.compute_output_shape(ins, outs, _param_activation));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
-template class ActivationHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ActivationHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ActivationHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class ActivationHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ActivationHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ActivationHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
+INSTANCE_ACTIVATION(NV, AK_FLOAT, Precision::FP32);
+template<>
+Status ActivationHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV>& ctx,
+        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_activation.init(ins, outs, _param_activation, STATIC, VENDER_IMPL, ctx));
+    return Status::OK();
+}
 ANAKIN_REGISTER_OP_HELPER(Activation, ActivationHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_ACTIVATION(X86, AK_FLOAT, Precision::FP32);
+INSTANCE_ACTIVATION(X86, AK_FLOAT, Precision::FP16);
+INSTANCE_ACTIVATION(X86, AK_FLOAT, Precision::INT8);
+template class ActivationHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Activation, ActivationHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_ACTIVATION(ARM, AK_FLOAT, Precision::FP32);
+template class ActivationHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Activation, ActivationHelper, ARM, AK_FLOAT, Precision::FP32);
-#endif
+#endif//arm
+
 //! register op
 ANAKIN_REGISTER_OP(Activation)
 .Doc("Activation operator")
@@ -86,12 +112,15 @@ ANAKIN_REGISTER_OP(Activation)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("activation")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("activation")
+#endif
 .num_in(1)
 .num_out(1)
-.Args<std::string>("type", " type of Activation ");
+.Args<std::string>("type", " type of Activation ")
+.Args<bool>("channel_shared", "prelu channel is shared or not ");
 
 } /* namespace ops */
 
 } /* namespace anakin */
 
-
diff --git a/framework/operators/activation.h b/framework/operators/activation.h
index 42bdac0..d40261d 100644
--- a/framework/operators/activation.h
+++ b/framework/operators/activation.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/arg_max.cpp b/framework/operators/arg_max.cpp
index b852517..9904e68 100644
--- a/framework/operators/arg_max.cpp
+++ b/framework/operators/arg_max.cpp
@@ -4,21 +4,30 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Argmax<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ArgmaxHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = impl->_param_argmax;
-    impl->_funcs_argmax(ins, outs, param, ctx);
-}
-#endif
+//#ifdef USE_CUDA
+//template<>
+//void Argmax<NV, AK_FLOAT, Precision::FP32>::operator()(
+//    OpContext<NV>& ctx,
+//    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+//    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+//    auto* impl =
+//        static_cast<ArgmaxHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+//    auto& param = impl->_param_argmax;
+//    impl->_funcs_argmax(ins, outs, param, ctx);
+//}
+//#endif
 
 /// TODO ... specialization other type of operator
-
+#define INSTANCE_ARGMAX(Ttype, Dtype, Ptype) \
+template<> \
+void Argmax<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<ArgmaxHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = impl->_param_argmax; \
+    impl->_funcs_argmax(ins, outs, param, ctx); \
+}
 
 /// set helper
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -30,9 +39,17 @@ Status ArgmaxHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Argmax op parameter.";
     auto out_max_val = GET_PARAMETER(bool, out_max_val);
     auto top_k = GET_PARAMETER(int, top_k);
-    auto axis = GET_PARAMETER(int, axis);
-    saber::ArgmaxParam<Tensor4d<Ttype, Dtype>> argmax_param(out_max_val, top_k, axis);
-    _param_argmax = argmax_param;
+    auto axis_term = GET_PARAMETER(bool, axis_term);
+
+    if (axis_term == true) {
+        auto axis = GET_PARAMETER(int, axis);
+        saber::ArgmaxParam <Tensor4d<Ttype, Dtype>> argmax_param(out_max_val, top_k, axis);
+        _param_argmax = argmax_param;
+    } else {
+        saber::ArgmaxParam <Tensor4d<Ttype, Dtype>> argmax_param(out_max_val, top_k);
+        _param_argmax = argmax_param;
+    }
+
     return Status::OK();
 }
 
@@ -53,24 +70,38 @@ Status ArgmaxHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dP
 }
 
 #ifdef USE_CUDA
+INSTANCE_ARGMAX(NV, AK_FLOAT, Precision::FP32);
 template class ArgmaxHelper<NV, AK_FLOAT, Precision::FP32>;
 template class ArgmaxHelper<NV, AK_FLOAT, Precision::FP16>;
 template class ArgmaxHelper<NV, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Argmax, ArgmaxHelper, NV, AK_FLOAT, Precision::FP32);
+#endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_ARGMAX(X86, AK_FLOAT, Precision::FP32);
+template class ArgmaxHelper<X86, AK_FLOAT, Precision::FP32>;
+template class ArgmaxHelper<X86, AK_FLOAT, Precision::FP16>;
+template class ArgmaxHelper<X86, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Argmax, ArgmaxHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+
+#ifdef ANAKIN_TYPE_FP32
+INSTANCE_ARGMAX(ARM, AK_FLOAT, Precision::FP32);
 template class ArgmaxHelper<ARM, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Argmax, ArgmaxHelper, ARM, AK_FLOAT, Precision::FP32);
+#endif //fp32
+
+#ifdef ANAKIN_TYPE_FP16
 template class ArgmaxHelper<ARM, AK_FLOAT, Precision::FP16>;
+#endif //fp16
+
+#ifdef ANAKIN_TYPE_INT8
 template class ArgmaxHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
+#endif //int8
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Argmax, ArgmaxHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
-#ifdef USE_ARM_PLACE
-ANAKIN_REGISTER_OP_HELPER(Argmax, ArgmaxHelper, ARM, AK_FLOAT, Precision::FP32);
-#endif
+#endif //arm
 
 //! register op
 ANAKIN_REGISTER_OP(Argmax)
@@ -81,6 +112,10 @@ ANAKIN_REGISTER_OP(Argmax)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("Argmax")
 #endif
+
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("Argmax")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<bool>("out_max_val", " out_max_val for argmax ")
diff --git a/framework/operators/arg_max.h b/framework/operators/arg_max.h
index 05ef7ca..3e76669 100644
--- a/framework/operators/arg_max.h
+++ b/framework/operators/arg_max.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/axpy.cpp b/framework/operators/axpy.cpp
index 56d7a9e..f347a7c 100644
--- a/framework/operators/axpy.cpp
+++ b/framework/operators/axpy.cpp
@@ -4,21 +4,30 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Axpy<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<AxpyHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = impl->_param_axpy;
-    impl->_funcs_axpy(ins, outs, param, ctx);
-}
-#endif
+//#ifdef USE_CUDA
+//template<>
+//void Axpy<NV, AK_FLOAT, Precision::FP32>::operator()(
+//    OpContext<NV>& ctx,
+//    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+//    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+//    auto* impl =
+//        static_cast<AxpyHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+//    auto& param = impl->_param_axpy;
+//    impl->_funcs_axpy(ins, outs, param, ctx);
+//}
+//#endif
 
 /// TODO ... specialization other type of operator
-
+#define INSTANCE_AXPY(Ttype, Dtype, Ptype) \
+template<> \
+void Axpy<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<AxpyHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = impl->_param_axpy; \
+    impl->_funcs_axpy(ins, outs, param, ctx); \
+}
 
 /// set helper
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -51,25 +60,39 @@ Status AxpyHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr
 }
 
 #ifdef USE_CUDA
+INSTANCE_AXPY(NV, AK_FLOAT, Precision::FP32);
 template class AxpyHelper<NV, AK_FLOAT, Precision::FP32>;
 template class AxpyHelper<NV, AK_FLOAT, Precision::FP16>;
 template class AxpyHelper<NV, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Axpy, AxpyHelper, NV, AK_FLOAT, Precision::FP32);
+#endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_AXPY(X86, AK_FLOAT, Precision::FP32);
+template class AxpyHelper<X86, AK_FLOAT, Precision::FP32>;
+template class AxpyHelper<X86, AK_FLOAT, Precision::FP16>;
+template class AxpyHelper<X86, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Axpy, AxpyHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+
+#ifdef ANAKIN_TYPE_FP32
+INSTANCE_AXPY(ARM, AK_FLOAT, Precision::FP32);
 template class AxpyHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class AxpyHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class AxpyHelper<ARM, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Axpy, AxpyHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Axpy, AxpyHelper, NV, AK_FLOAT, Precision::FP32);
+#ifdef ANAKIN_TYPE_FP16
+template class AxpyHelper<ARM, AK_FLOAT, Precision::FP16>;
 #endif
-#ifdef USE_ARM_PLACE
-ANAKIN_REGISTER_OP_HELPER(Axpy, AxpyHelper, ARM, AK_FLOAT, Precision::FP32);
+
+#ifdef ANAKIN_TYPE_INT8
+template class AxpyHelper<ARM, AK_FLOAT, Precision::INT8>;
 #endif
 
+#endif//arm
+
 //! register op
 ANAKIN_REGISTER_OP(Axpy)
 .Doc("Axpy operator")
@@ -79,6 +102,9 @@ ANAKIN_REGISTER_OP(Axpy)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("axpy")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("axpy")
+#endif
 .num_in(3)
 .num_out(1);
 
diff --git a/framework/operators/axpy.h b/framework/operators/axpy.h
index 6a77dc7..38b0874 100644
--- a/framework/operators/axpy.h
+++ b/framework/operators/axpy.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/batch_norm.cpp b/framework/operators/batch_norm.cpp
index d590449..27df745 100644
--- a/framework/operators/batch_norm.cpp
+++ b/framework/operators/batch_norm.cpp
@@ -4,29 +4,52 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
+#define INSTANCE_BATCHNORM(Ttype, Dtype, Ptype) \
+template<> \
+void BatchNorm<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+        auto* impl = static_cast<BatchNormHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+        auto& param = static_cast<BatchNormHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_scale; \
+        impl->_funcs_scale(ins, outs, param, ctx); \
+}
+
+#if 0//def USE_CUDA
 template<>
 void BatchNorm<NV, AK_FLOAT, Precision::FP32>::operator()(
     OpContext<NV>& ctx,
     const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
     std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    /*auto* impl = static_cast<BatchNorm<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<BatchNorm<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_permute;
-    impl->_funcs_permute(ins, outs, param, ctx);*/
+    auto* impl = static_cast<BatchNormHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param = static_cast<BatchNormHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_scale;
+    impl->_funcs_scale(ins, outs, param, ctx);
 }
 #endif
 
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-BatchNormHelper<Ttype, Dtype, Ptype>::~BatchNormHelper() {
-    LOG(INFO) << "Decons permute_cpu_float";
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status BatchNormHelper<Ttype, Dtype, Ptype>::InitParam() {
+    DLOG(WARNING) << "Parsing Scale op parameter.";
+    using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+
+    auto eps = GET_PARAMETER(float, epsilon);
+    auto mean = GET_PARAMETER(pblock_type, weight_1);
+    auto var = GET_PARAMETER(pblock_type, weight_2);
+    auto scale_factor = GET_PARAMETER(pblock_type, weight_3);
+    auto mean_vec = mean.vector();
+    auto var_vec = var.vector();
+    auto scale_factor_vec = scale_factor.vector();
+    std::vector<typename DataTypeWarpper<Dtype>::type> scale;
+    std::vector<typename DataTypeWarpper<Dtype>::type> bias;
+    scale.resize(mean.count());
+    bias.resize(mean.count());
+    auto scale_val = scale_factor_vec[0] == 0 ? 0 : 1 / scale_factor_vec[0];
+    for (int i = 0; i < mean.count(); i++) {
+        scale[i] = 1.0f / std::sqrt(var_vec[i] * scale_val + eps);
+        bias[i] = - mean_vec[i] * scale_val / std::sqrt(var_vec[i] * scale_val + eps); 
+    }
+
+    saber::ScaleParam <Tensor4d<Ttype, Dtype>> param_scale(scale, bias, true, 1, 1);
+    _param_scale = param_scale;
     return Status::OK();
 }
 
@@ -34,7 +57,7 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status BatchNormHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    //_funcs_permute.init(ins, outs, _param_permute, SPECIFY, VENDER_IMPL, ctx);
+    SABER_CHECK(_funcs_scale.init(ins, outs, _param_scale, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -42,50 +65,40 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status BatchNormHelper<Ttype, Dtype, Ptype>::InferShape(const
         std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    std::vector<Shape4d> shape;
-
-    //_funcs_permute.compute_output_shape(shape, ins, _param_permute);
-    //CHECK_EQ(shape.size(), outs.size()) << " size of (out) should be equal to that of vector (shape).";
-    for (int i = 0; i <  outs.size(); i++) {
-        // set tensor shape tensor->set_shape(shape[i]);
-        outs[i]->set_shape(ins[i]->shape());
-    }
-
+    SABER_CHECK(_funcs_scale.compute_output_shape(ins, outs, _param_scale));
     return Status::OK();
 }
-#ifdef USE_CUDA
-template class BatchNormHelper<NV, AK_FLOAT, Precision::FP32>;
-template class BatchNormHelper<NV, AK_FLOAT, Precision::FP16>;
-template class BatchNormHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class BatchNormHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class BatchNormHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class BatchNormHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
 
 // register helper
 #ifdef USE_CUDA
+INSTANCE_BATCHNORM(NV, AK_FLOAT, Precision::FP32);
+template class BatchNormHelper<NV, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(BatchNorm, BatchNormHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
+#ifdef USE_X86_PLACE
+INSTANCE_BATCHNORM(X86, AK_FLOAT, Precision::FP32);
+template class BatchNormHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(BatchNorm, BatchNormHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_BATCHNORM(ARM, AK_FLOAT, Precision::FP32);
+template class BatchNormHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(BatchNorm, BatchNormHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
 //! register op
 ANAKIN_REGISTER_OP(BatchNorm)
-	.Doc("BatchNorm operator")
+.Doc("BatchNorm operator")
 #ifdef USE_CUDA
-	.__alias__<NV, AK_FLOAT, Precision::FP32>("power")
+.__alias__<NV, AK_FLOAT, Precision::FP32>("eps")
 #endif
 #ifdef USE_ARM_PLACE
-	.__alias__<ARM, AK_FLOAT, Precision::FP32>("power")
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("eps")
 #endif
-	.num_in(1)
-	.num_out(1)
-	.Args<PTuple<int>>("dims", " dims for permuting the order of input ");
+.num_in(1)
+.num_out(1);
 
 } /* namespace ops */
 
diff --git a/framework/operators/batch_norm.h b/framework/operators/batch_norm.h
index b578af5..655d9c5 100644
--- a/framework/operators/batch_norm.h
+++ b/framework/operators/batch_norm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -20,7 +20,7 @@
 #include "framework/core/data_types.h"
 #include "framework/core/operator/operator.h"
 #include "utils/logger/logger.h"
-//#include "saber/funcs/permute.h"
+#include "saber/funcs/scale.h"
 
 namespace anakin {
 
@@ -60,7 +60,7 @@ class BatchNormHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     BatchNormHelper()=default;
 
-    ~BatchNormHelper();
+    ~BatchNormHelper() {}
 
     Status InitParam() override;
 
@@ -83,18 +83,13 @@ public:
     */
     Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                       std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
-
 public:
-    //PermuteParam<void> _param_permute;
-    //saber::Permute<Ttype, Dtype> _funcs_permute;
+    saber::ScaleParam<Tensor4d<Ttype, Dtype>> _param_scale;
+    ///< _funcs_scale stand for scale function
+    saber::Scale<Ttype, Dtype> _funcs_scale;
 
-private:
-    ///< _dims stand for batchNorm size 
-    PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/concat.cpp b/framework/operators/concat.cpp
index 1af835f..8d74722 100644
--- a/framework/operators/concat.cpp
+++ b/framework/operators/concat.cpp
@@ -4,38 +4,6 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Concat<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConcatHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConcatHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_concat;
-    impl->_funcs_concat(ins, outs, param, ctx);
-}
-#endif
-#ifdef USE_X86_PLACE
-template<>
-void Concat<X86, AK_FLOAT, Precision::FP32>::operator()(
-        OpContext<X86>& ctx,
-        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConcatHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConcatHelper<X86, AK_FLOAT, Precision::FP32>*>
-    (this->_helper)->_param_concat;
-    impl->_funcs_concat(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ConcatHelper<Ttype, Dtype, Ptype>::~ConcatHelper() {
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConcatHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Concat op parameter.";
@@ -46,44 +14,47 @@ Status ConcatHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ConcatHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status ConcatHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx,
+                                  const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                                    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs){
     SABER_CHECK(_funcs_concat.init(ins, outs, _param_concat, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ConcatHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status ConcatHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_concat.compute_output_shape(ins, outs, _param_concat));
     return Status::OK();
 }
 
+
+#define INSTANCE_CONCAT(Ttype, Dtype, Ptype) \
+template<> \
+void Concat<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<ConcatHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = \
+        static_cast<ConcatHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_concat; \
+    impl->_funcs_concat(ins, outs, param, ctx); \
+}
+
 #ifdef USE_CUDA
+INSTANCE_CONCAT(NV, AK_FLOAT, Precision::FP32);
 template class ConcatHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConcatHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConcatHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class ConcatHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConcatHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConcatHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_X86_PLACE
-template class ConcatHelper<X86, AK_FLOAT, Precision::FP32>;
-template class ConcatHelper<X86, AK_FLOAT, Precision::FP16>;
-template class ConcatHelper<X86, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Concat, ConcatHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_CONCAT(ARM, AK_FLOAT, Precision::FP32);
+template class ConcatHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Concat, ConcatHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_X86_PLACE
+INSTANCE_CONCAT(X86, AK_FLOAT, Precision::FP32);
+template class ConcatHelper<X86, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Concat, ConcatHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
diff --git a/framework/operators/concat.h b/framework/operators/concat.h
index e191bd3..ea98eb5 100644
--- a/framework/operators/concat.h
+++ b/framework/operators/concat.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ConcatHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ConcatHelper()=default;
 
-    ~ConcatHelper();
+    ~ConcatHelper() {}
 
     Status InitParam() override;
 
@@ -96,7 +96,6 @@ private:
 };
 
 
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/conv_3x3.cpp b/framework/operators/conv_3x3.cpp
index dd5da9b..2b1b5c4 100644
--- a/framework/operators/conv_3x3.cpp
+++ b/framework/operators/conv_3x3.cpp
@@ -80,11 +80,11 @@ template class SassConvolutionHelper<NV, AK_FLOAT, Precision::FP16>;
 template class SassConvolutionHelper<NV, AK_FLOAT, Precision::INT8>;
 #endif
 
-#ifdef USE_ARM_PLACE
-template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
+//#ifdef USE_ARM_PLACE
+//template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
+//template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::FP16>;
+//template class SassConvolutionHelper<ARM, AK_FLOAT, Precision::INT8>;
+//#endif
 
 // register helper
 #ifdef USE_CUDA
@@ -92,7 +92,7 @@ ANAKIN_REGISTER_OP_HELPER(SassConvolution, SassConvolutionHelper, NV, AK_FLOAT,
 #endif
 
 #ifdef USE_ARM_PLACE
-ANAKIN_REGISTER_OP_HELPER(SassConvolution, SassConvolutionHelper, ARM, AK_FLOAT, Precision::FP32);
+//ANAKIN_REGISTER_OP_HELPER(SassConvolution, SassConvolutionHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
 //! register op
@@ -101,9 +101,9 @@ ANAKIN_REGISTER_OP(SassConvolution)
 #ifdef USE_CUDA
 .__alias__<NV, AK_FLOAT, Precision::FP32>("convolution")
 #endif
-#ifdef USE_ARM_PLACE
-.__alias__<ARM, AK_FLOAT, Precision::FP32>("convolution")
-#endif
+//#ifdef USE_ARM_PLACE
+//.__alias__<ARM, AK_FLOAT, Precision::FP32>("convolution")
+//#endif
 .num_in(1)
 .num_out(1)
 .Args<int>("group", " group of conv ")
diff --git a/framework/operators/conv_3x3.h b/framework/operators/conv_3x3.h
index 251dc53..be01162 100644
--- a/framework/operators/conv_3x3.h
+++ b/framework/operators/conv_3x3.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/convolution.cpp b/framework/operators/convolution.cpp
index 487e812..9966057 100644
--- a/framework/operators/convolution.cpp
+++ b/framework/operators/convolution.cpp
@@ -4,25 +4,15 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Convolution<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConvolutionHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConvolutionHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_conv;
-    impl->_funcs_conv(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ConvolutionHelper<Ttype, Dtype, Ptype>::~ConvolutionHelper() {
+#define INSTANCE_CONVOLUTION(Ttype, Dtype, Ptype) \
+template<> \
+void Convolution<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<ConvolutionHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<ConvolutionHelper<Ttype, Dtype, Ptype>*> \
+                  (this->_helper)->_param_conv; \
+    impl->_funcs_conv(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -72,7 +62,7 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvolutionHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_conv.init(ins, outs, _param_conv, SPECIFY, VENDER_IMPL, ctx));
+    SABER_CHECK(_funcs_conv.init(ins, outs, _param_conv, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -85,23 +75,29 @@ Status ConvolutionHelper<Ttype, Dtype, Ptype>::InferShape(const
 }
 
 #ifdef USE_CUDA
+INSTANCE_CONVOLUTION(NV, AK_FLOAT, Precision::FP32);
+template <>
+Status ConvolutionHelper<NV, AK_FLOAT, Precision ::FP32>::Init(OpContext<NV> &ctx, \
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+                    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_conv.init(ins, outs, _param_conv, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
 template class ConvolutionHelper<NV, AK_FLOAT, Precision::FP32>;
 template class ConvolutionHelper<NV, AK_FLOAT, Precision::FP16>;
 template class ConvolutionHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class ConvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvolutionHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvolutionHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Convolution, ConvolutionHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
+//#ifdef USE_X86_PLACE
+//INSTANCE_CONVOLUTION(X86, AK_FLOAT, Precision::FP32);
+//template class ConvolutionHelper<X86, AK_FLOAT, Precision::FP32>;
+//ANAKIN_REGISTER_OP_HELPER(Convolution, ConvolutionHelper, X86, AK_FLOAT, Precision::FP32);
+//#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVOLUTION(ARM, AK_FLOAT, Precision::FP32);
+template class ConvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Convolution, ConvolutionHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -119,11 +115,11 @@ ANAKIN_REGISTER_OP(Convolution)
 .Args<int>("group", " group of conv ")
 .Args<bool>("bias_term", " whether conv weights have bias")
 .Args<PTuple<int>>("padding", "padding of conv (x, y)")
-                .Args<PTuple<int>>("strides", "strides of conv (x)")
-                .Args<PTuple<int>>("dilation_rate", "dilation rate of conv (x)")
-                .Args<int>("filter_num", "filter(kernel) number of weights")
-                .Args<PTuple<int>>("kernel_size", "kernel size of kernel (x, y)")
-                .Args<int>("axis", "axis of conv");
+.Args<PTuple<int>>("strides", "strides of conv (x)")
+.Args<PTuple<int>>("dilation_rate", "dilation rate of conv (x)")
+.Args<int>("filter_num", "filter(kernel) number of weights")
+.Args<PTuple<int>>("kernel_size", "kernel size of kernel (x, y)")
+.Args<int>("axis", "axis of conv");
 
 } /* namespace ops */
 
diff --git a/framework/operators/convolution.h b/framework/operators/convolution.h
index e929c0e..4ad3330 100644
--- a/framework/operators/convolution.h
+++ b/framework/operators/convolution.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -45,6 +45,10 @@ public:
                              std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
         LOG(ERROR) << "Not Impl Yet Operator convolution<TargetType:"<<"unknown"<<","
                    <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+        //auto* impl = static_cast<ConvolutionHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+        auto& param = static_cast<ConvolutionHelper<Ttype, Dtype, Ptype>*> \
+                  (this->_helper)->_param_conv; \
+        impl->_funcs_conv(ins, outs, param, ctx);
     }
 
     friend class ConvolutionHelper<Ttype, Dtype, Ptype>;
@@ -60,7 +64,7 @@ class ConvolutionHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ConvolutionHelper()=default;
 
-    ~ConvolutionHelper();
+    ~ConvolutionHelper(){}
 
     Status InitParam() override;
 
@@ -95,8 +99,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/crf_decoding.h b/framework/operators/crf_decoding.h
index 2bf966c..4fa63e6 100644
--- a/framework/operators/crf_decoding.h
+++ b/framework/operators/crf_decoding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/ctc_align.h b/framework/operators/ctc_align.h
index 9f47b28..9725db8 100644
--- a/framework/operators/ctc_align.h
+++ b/framework/operators/ctc_align.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/deconvolution.cpp b/framework/operators/deconvolution.cpp
index e219824..8bd7d98 100644
--- a/framework/operators/deconvolution.cpp
+++ b/framework/operators/deconvolution.cpp
@@ -4,25 +4,14 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Deconvolution<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<DeconvolutionHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<DeconvolutionHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_deconv;
-    impl->_funcs_deconv(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-DeconvolutionHelper<Ttype, Dtype, Ptype>::~DeconvolutionHelper() {
+#define INSTANCE_DECONV(Ttype, Dtype, Ptype) \
+template<> \
+void Deconvolution<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<DeconvolutionHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<DeconvolutionHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_deconv; \
+    impl->_funcs_deconv(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -63,6 +52,24 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status DeconvolutionHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs_deconv.init(ins, outs, _param_deconv, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status DeconvolutionHelper<Ttype, Dtype, Ptype>::InferShape(const
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs_deconv.compute_output_shape(ins, outs, _param_deconv));
+    return Status::OK();
+}
+
+#ifdef USE_CUDA
+INSTANCE_DECONV(NV, AK_FLOAT, Precision::FP32);
+template<>
+Status DeconvolutionHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV>& ctx,
+        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
     bool p = true;
     p = p && (_param_deconv.weight()->width() == 4);
     p = p && (_param_deconv.weight()->height() == 4);
@@ -86,33 +93,15 @@ Status DeconvolutionHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
 
     return Status::OK();
 }
-
-template<typename Ttype, DataType Dtype, Precision Ptype>
-Status DeconvolutionHelper<Ttype, Dtype, Ptype>::InferShape(const
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_deconv.compute_output_shape(ins, outs, _param_deconv));
-    return Status::OK();
-}
-
-#ifdef USE_CUDA
 template class DeconvolutionHelper<NV, AK_FLOAT, Precision::FP32>;
 template class DeconvolutionHelper<NV, AK_FLOAT, Precision::FP16>;
 template class DeconvolutionHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class DeconvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class DeconvolutionHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class DeconvolutionHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Deconvolution, DeconvolutionHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_DECONV(ARM, AK_FLOAT, Precision::FP32);
+template class DeconvolutionHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Deconvolution, DeconvolutionHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -130,11 +119,11 @@ ANAKIN_REGISTER_OP(Deconvolution)
 .Args<int>("group", " group of conv ")
 .Args<bool>("bias_term", " whether conv weights have bias")
 .Args<PTuple<int>>("padding", "padding of conv (x, y)")
-                .Args<PTuple<int>>("strides", "strides of conv (x)")
-                .Args<PTuple<int>>("dilation_rate", "dilation rate of conv (x)")
-                .Args<int>("filter_num", "filter(kernel) number of weights")
-                .Args<PTuple<int>>("kernel_size", "kernel size of kernel (x, y)")
-                .Args<int>("axis", "axis of conv");
+.Args<PTuple<int>>("strides", "strides of conv (x)")
+.Args<PTuple<int>>("dilation_rate", "dilation rate of conv (x)")
+.Args<int>("filter_num", "filter(kernel) number of weights")
+.Args<PTuple<int>>("kernel_size", "kernel size of kernel (x, y)")
+.Args<int>("axis", "axis of conv");
 
 } /* namespace ops */
 
diff --git a/framework/operators/deconvolution.h b/framework/operators/deconvolution.h
index 5c8b46b..4bae085 100644
--- a/framework/operators/deconvolution.h
+++ b/framework/operators/deconvolution.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class DeconvolutionHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     DeconvolutionHelper()=default;
 
-    ~DeconvolutionHelper();
+    ~DeconvolutionHelper(){}
 
     Status InitParam() override;
 
@@ -96,8 +96,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/deformconvolution.h b/framework/operators/deformconvolution.h
index 967d3a1..b174649 100644
--- a/framework/operators/deformconvolution.h
+++ b/framework/operators/deformconvolution.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/dense.cpp b/framework/operators/dense.cpp
index 8fc7242..bf4eb0c 100644
--- a/framework/operators/dense.cpp
+++ b/framework/operators/dense.cpp
@@ -4,36 +4,14 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Dense<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<DenseHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<DenseHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_dense;
-    impl->_funcs_dense(ins, outs, param, ctx);
-}
-#endif
-
-#ifdef USE_X86_PLACE
-template<>
-void Dense<X86, AK_FLOAT, Precision::FP32>::operator()(
-        OpContext<X86>& ctx,
-        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<DenseHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<DenseHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_dense;
-    impl->_funcs_dense(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-DenseHelper<Ttype, Dtype, Ptype>::~DenseHelper() {
+#define INSTANCE_DENSE(Ttype, Dtype, Ptype) \
+template<> \
+void Dense<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<DenseHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<DenseHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_dense; \
+    impl->_funcs_dense(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -67,6 +45,30 @@ Status DenseHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
     return Status::OK();
 }
 
+template<>
+Status DenseHelper<X86, AK_FLOAT, Precision::FP32>::Init(OpContext<X86>& ctx,
+          const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+          std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_dense.init(ins, outs, _param_dense, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<>
+Status DenseHelper<X86, AK_FLOAT, Precision::FP16>::Init(OpContext<X86>& ctx,
+                                                         const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+                                                         std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_dense.init(ins, outs, _param_dense, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<>
+Status DenseHelper<X86, AK_FLOAT, Precision::INT8>::Init(OpContext<X86>& ctx,
+                                                         const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+                                                         std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_dense.init(ins, outs, _param_dense, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
+
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status DenseHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
         ins,
@@ -76,33 +78,28 @@ Status DenseHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPt
 }
 
 #ifdef USE_CUDA
+INSTANCE_DENSE(NV, AK_FLOAT, Precision::FP32);
 template class DenseHelper<NV, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Dense, DenseHelper, NV, AK_FLOAT, Precision::FP32);
 template class DenseHelper<NV, AK_FLOAT, Precision::FP16>;
 template class DenseHelper<NV, AK_FLOAT, Precision::INT8>;
 #endif
 
 #ifdef USE_ARM_PLACE
-template class DenseHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class DenseHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class DenseHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_X86_PLACE
-template class DenseHelper<X86, AK_FLOAT, Precision::FP32>;
-template class DenseHelper<X86, AK_FLOAT, Precision::FP16>;
-template class DenseHelper<X86, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Dense, DenseHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
-
-#ifdef USE_ARM_PLACE
+INSTANCE_DENSE(ARM, AK_FLOAT, Precision::FP32);
+template<>
+Status DenseHelper<ARM, AK_FLOAT, Precision::FP32>::Init(OpContext<ARM> &ctx,\
+        const std::vector<Tensor4dPtr<ARM, AK_FLOAT> >& ins, \
+                std::vector<Tensor4dPtr<ARM, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_dense.init(ins, outs, _param_dense, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
 ANAKIN_REGISTER_OP_HELPER(Dense, DenseHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_X86_PLACE
+INSTANCE_DENSE(X86, AK_FLOAT, Precision::FP32);
+template class DenseHelper<X86, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Dense, DenseHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
diff --git a/framework/operators/dense.h b/framework/operators/dense.h
index 9d551b1..27e241e 100644
--- a/framework/operators/dense.h
+++ b/framework/operators/dense.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class DenseHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     DenseHelper()=default;
 
-    ~DenseHelper();
+    ~DenseHelper() {}
 
     Status InitParam() override;
 
@@ -95,8 +95,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/detection_output.cpp b/framework/operators/detection_output.cpp
index 10e3ec3..5cb2902 100644
--- a/framework/operators/detection_output.cpp
+++ b/framework/operators/detection_output.cpp
@@ -4,24 +4,14 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void DetectionOutput<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx,
-        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<DetectionOutputHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<DetectionOutputHelper<NV, AK_FLOAT, \
-                  Precision::FP32>*>(this->_helper)->_param_detection_output;
-    impl->_funcs_detection_output(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-DetectionOutputHelper<Ttype, Dtype, Ptype>::~DetectionOutputHelper() {
+#define INSTANCE_DETECTIONOUTPUT(Ttype, Dtype, Ptype) \
+template<> \
+void DetectionOutput<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<DetectionOutputHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<DetectionOutputHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_detection_output; \
+    impl->_funcs_detection_output(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -47,7 +37,7 @@ Status DetectionOutputHelper<Ttype, Dtype, Ptype>::InitParam() {
     } else if (code_type_ == "CORNER_SIZE") {
         code_type = CORNER_SIZE;
     } else {
-        LOG(FATAL) << "unsupport type: " << code_type_;
+                LOG(FATAL) << "unsupport type: " << code_type_;
     }
 
     DetectionOutputParam<Tensor4d<Ttype, Dtype>> param_det(classes_num, background_id_, \
@@ -58,38 +48,37 @@ Status DetectionOutputHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status DetectionOutputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status DetectionOutputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                   std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_detection_output.init(ins, outs, _param_detection_output, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status DetectionOutputHelper<Ttype, Dtype, Ptype>::InferShape(\
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status DetectionOutputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                         std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_detection_output.compute_output_shape(ins, outs, _param_detection_output));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
+INSTANCE_DETECTIONOUTPUT(NV, AK_FLOAT, Precision::FP32);
 template class DetectionOutputHelper<NV, AK_FLOAT, Precision::FP32>;
-template class DetectionOutputHelper<NV, AK_FLOAT, Precision::FP16>;
-template class DetectionOutputHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class DetectionOutputHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class DetectionOutputHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class DetectionOutputHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(DetectionOutput, DetectionOutputHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_DETECTIONOUTPUT(X86, AK_FLOAT, Precision::FP32);
+template class DetectionOutputHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(DetectionOutput, DetectionOutputHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_DETECTIONOUTPUT(ARM, AK_FLOAT, Precision::FP32);
+template class DetectionOutputHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(DetectionOutput, DetectionOutputHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
 //! register op
 ANAKIN_REGISTER_OP(DetectionOutput)
 .Doc("DetectionOutput operator")
@@ -99,6 +88,9 @@ ANAKIN_REGISTER_OP(DetectionOutput)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("detectionoutput")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("detectionoutput")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<bool>("share_location", " flag whether all classes share location ")
diff --git a/framework/operators/detection_output.h b/framework/operators/detection_output.h
index 633fae9..f485f24 100644
--- a/framework/operators/detection_output.h
+++ b/framework/operators/detection_output.h
@@ -50,7 +50,7 @@ class DetectionOutputHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     DetectionOutputHelper()=default;
 
-    ~DetectionOutputHelper();
+    ~DetectionOutputHelper(){}
 
     Status InitParam() override;
 
@@ -68,8 +68,6 @@ public:
     saber::DetectionOutput<Ttype, Dtype> _funcs_detection_output;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/eltwise_op.cpp b/framework/operators/eltwise_op.cpp
index 5dd8953..fcd3ae3 100644
--- a/framework/operators/eltwise_op.cpp
+++ b/framework/operators/eltwise_op.cpp
@@ -4,27 +4,18 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Eltwise<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<EltwiseHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<EltwiseHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_eltwise;
-    impl->_funcs_eltwise(ins, outs, param, ctx);
+#define INSTANCE_ELTWISE(Ttype, Dtype, Ptype) \
+template<> \
+void Eltwise<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<EltwiseHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<EltwiseHelper<Ttype, Dtype, Ptype>*> \
+                  (this->_helper)->_param_eltwise; \
+    impl->_funcs_eltwise(ins, outs, param, ctx); \
 }
-#endif
-
-/// TODO ... specialization other type of operator
 
 
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-EltwiseHelper<Ttype, Dtype, Ptype>::~EltwiseHelper() {
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status EltwiseHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Eltwise op parameter.";
@@ -39,56 +30,40 @@ Status EltwiseHelper<Ttype, Dtype, Ptype>::InitParam() {
     } else {
         elt_type = Eltwise_prod;
     }
-
-    //    Shape shape_coeff(1, 1, 1, coeff.size());
-    //    Tensor<X86, Dtype> thcoeff(shape_coeff);
-    //    for (int i = 0; i < thcoeff.size(); ++i) {
-    //        thcoeff.mutable_data()[i] = coeff[i];
-    //    }
-    //    Tensor4d<Ttype, Dtype> * tdcoeff_p = new Tensor4d<Ttype, Dtype>();
-    //    tdcoeff_p->re_alloc(shape_coeff);
-    //    tdcoeff_p->copy_from(thcoeff);
-
-    //    saber::EltwiseParam<Tensor4d<Ttype, Dtype>>    eltwise_param(elt_type, tdcoeff_p);
     saber::EltwiseParam<Tensor4d<Ttype, Dtype> > eltwise_param(elt_type, coeff.vector());
     _param_eltwise = eltwise_param;
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status EltwiseHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status EltwiseHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                           std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_eltwise.init(ins, outs, _param_eltwise, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status EltwiseHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status EltwiseHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                 std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_eltwise.compute_output_shape(ins, outs, _param_eltwise));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
+INSTANCE_ELTWISE(NV, AK_FLOAT, Precision::FP32);
 template class EltwiseHelper<NV, AK_FLOAT, Precision::FP32>;
-template class EltwiseHelper<NV, AK_FLOAT, Precision::FP16>;
-template class EltwiseHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class EltwiseHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class EltwiseHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class EltwiseHelper<ARM, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Eltwise, EltwiseHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Eltwise, EltwiseHelper, NV, AK_FLOAT, Precision::FP32);
+#ifdef USE_X86_PLACE
+INSTANCE_ELTWISE(X86, AK_FLOAT, Precision::FP32);
+template class EltwiseHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Eltwise, EltwiseHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_ELTWISE(ARM, AK_FLOAT, Precision::FP32);
+template class EltwiseHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Eltwise, EltwiseHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -101,11 +76,15 @@ ANAKIN_REGISTER_OP(Eltwise)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("eltwise")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("eltwise")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<std::string>("type", " eltwise type( string )")
 .Args<PTuple<float>>("coeff", "coeff of eltwise");
 
+
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/eltwise_op.h b/framework/operators/eltwise_op.h
index c17bc9a..e3d4a09 100644
--- a/framework/operators/eltwise_op.h
+++ b/framework/operators/eltwise_op.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class EltwiseHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     EltwiseHelper()=default;
 
-    ~EltwiseHelper();
+    ~EltwiseHelper() {}
 
     Status InitParam() override;
 
@@ -95,8 +95,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/embedding.h b/framework/operators/embedding.h
index 23cebf2..d140a0f 100644
--- a/framework/operators/embedding.h
+++ b/framework/operators/embedding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/flatten.cpp b/framework/operators/flatten.cpp
index af25b19..6c7509b 100644
--- a/framework/operators/flatten.cpp
+++ b/framework/operators/flatten.cpp
@@ -4,26 +4,16 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Flatten<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<FlattenHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<FlattenHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_flatten;
-    impl->_funcs_flatten(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-FlattenHelper<Ttype, Dtype, Ptype>::~FlattenHelper() {
+#define INSTANCE_FLATTEN(Ttype, Dtype, Ptype) \
+template<> \
+void Flatten<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<FlattenHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<FlattenHelper<Ttype, Dtype, Ptype>*> \
+                  (this->_helper)->_param_flatten; \
+    impl->_funcs_flatten(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -38,39 +28,32 @@ Status FlattenHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status FlattenHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status FlattenHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                           std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_flatten.init(ins, outs, _param_flatten, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status FlattenHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status FlattenHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                 std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_flatten.compute_output_shape(ins, outs, _param_flatten));
     return Status::OK();
 }
-
 #ifdef USE_CUDA
+INSTANCE_FLATTEN(NV, AK_FLOAT, Precision::FP32);
 template class FlattenHelper<NV, AK_FLOAT, Precision::FP32>;
-template class FlattenHelper<NV, AK_FLOAT, Precision::FP16>;
-template class FlattenHelper<NV, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Flatten, FlattenHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
-#ifdef USE_ARM_PLACE
-template class FlattenHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class FlattenHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class FlattenHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Flatten, FlattenHelper, NV, AK_FLOAT, Precision::FP32);
+#ifdef USE_X86_PLACE
+INSTANCE_FLATTEN(X86, AK_FLOAT, Precision::FP32);
+template class FlattenHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Flatten, FlattenHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_FLATTEN(ARM, AK_FLOAT, Precision::FP32);
+template class FlattenHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Flatten, FlattenHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -83,6 +66,9 @@ ANAKIN_REGISTER_OP(Flatten)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("flatten")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("flatten")
+#endif
 .num_in(1)
 .num_out(1);
 
diff --git a/framework/operators/flatten.h b/framework/operators/flatten.h
index eb4e650..5b6daaf 100644
--- a/framework/operators/flatten.h
+++ b/framework/operators/flatten.h
@@ -51,7 +51,7 @@ class FlattenHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     FlattenHelper()=default;
 
-    ~FlattenHelper();
+    ~FlattenHelper() {}
 
     Status InitParam() override;
 
@@ -72,8 +72,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.cpp b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.cpp
new file mode 100644
index 0000000..d4366d0
--- /dev/null
+++ b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.cpp
@@ -0,0 +1,190 @@
+#include "framework/operators/fusion_ops/conv_3x3_batchnorm_scale.h"
+
+namespace anakin {
+
+namespace ops {
+
+#ifdef USE_CUDA
+template<>
+void SassConvBatchnormScale<NV, AK_FLOAT, Precision::FP32>::operator()(
+    OpContext<NV>& ctx,
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    auto* impl = static_cast<SassConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>*>
+                 (this->_helper);
+    auto& param = static_cast<SassConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>*>
+                  (this->_helper)->_param_conv_batchnorm_scale_relu;
+    impl->_funcs_conv_batchnorm_scale_relu(ins, outs, param, ctx);
+}
+#endif
+
+/// TODO ... specialization other type of operator
+
+
+/// set helper
+template<typename Ttype, DataType Dtype, Precision Ptype>
+SassConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::~SassConvBatchnormScaleHelper() {
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SassConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::InitParam() {
+    LOG(WARNING) << "Parsing SassConvBatchnormScale op parameter.";
+    saber::ConvParam<Tensor4d<Ttype, Dtype>> _conv_param;
+
+    // get conv param
+    auto group = GET_PARAMETER(int, group);
+    auto bias_term = GET_PARAMETER(bool, bias_term);
+    auto padding = GET_PARAMETER(PTuple<int>, padding);
+    auto strides = GET_PARAMETER(PTuple<int>, strides);
+    auto dilation_rate = GET_PARAMETER(PTuple<int>, dilation_rate);
+    auto filter_num = GET_PARAMETER(int, filter_num);
+    auto kernel_size = GET_PARAMETER(PTuple<int>, kernel_size);
+    auto axis = GET_PARAMETER(int, axis);
+
+	
+	using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+    auto weights = GET_PARAMETER(pblock_type, weight_1);
+
+    if (bias_term) {
+        auto bias = GET_PARAMETER(pblock_type, weight_2);
+        saber::ConvParam<Tensor4d<Ttype, Dtype>> conv_param(group, padding[0], padding[1],
+                                              strides[0], strides[1],
+                                              dilation_rate[0], dilation_rate[1],
+                                              &(weights.d_tensor()), &(bias.d_tensor()));
+        _conv_param = conv_param;
+    } else {
+        Tensor4d<Ttype, Dtype>* bias = new Tensor4d<Ttype, Dtype>();;
+        saber::ConvParam<Tensor4d<Ttype, Dtype>> conv_param(group, padding[0], padding[1],
+                                              strides[0], strides[1],
+                                              dilation_rate[0], dilation_rate[1],
+                                              &(weights.d_tensor()), bias);
+        _conv_param = conv_param;
+    }
+
+
+    // get batchnorm param
+    auto epsilon = GET_PARAMETER(float, batchnorm_0_epsilon);
+    auto momentum = GET_PARAMETER(float, batchnorm_0_momentum);
+    auto batch_norm_weight_1 = GET_PARAMETER(pblock_type, batchnorm_0_weight_1);
+    auto batch_norm_weight_1_vector = batch_norm_weight_1.vector();
+    auto batch_norm_weight_2 = GET_PARAMETER(pblock_type, batchnorm_0_weight_2);
+    auto batch_norm_weight_2_vector = batch_norm_weight_2.vector();
+    auto batch_norm_weight_3 = GET_PARAMETER(pblock_type, batchnorm_0_weight_3);
+    auto batch_norm_weight_3_vector = batch_norm_weight_3.vector();
+    BatchnormParam<Tensor4d<Ttype, Dtype>> batchnorm_param(batch_norm_weight_1_vector,
+                                        batch_norm_weight_2_vector,
+                                        batch_norm_weight_3_vector[0],
+                                        momentum, epsilon);
+    // get scale param
+    auto scale_num_axes = GET_PARAMETER(int, scale_0_num_axes);
+    auto scale_bias_term = GET_PARAMETER(bool, scale_0_bias_term);
+    auto scale_axis = GET_PARAMETER(int, scale_0_axis);
+    auto scale_weight_1 = GET_PARAMETER(pblock_type, scale_0_weight_1);
+    auto scale_weight_1_vector = scale_weight_1.vector();
+    auto scale_weight_2 = GET_PARAMETER(pblock_type, scale_0_weight_2);
+    auto  scale_weight_2_vector = scale_weight_2.vector();
+    saber::ScaleParam<Tensor4d<Ttype, Dtype>> scale_param(scale_weight_1_vector,  scale_weight_2_vector,
+                                           scale_bias_term, scale_axis, scale_num_axes);
+
+    // get relu param
+    //auto alpha = GET_PARAMETER(float, relu_0_alpha);
+    //ActivationParam<Tensor4d<Ttype, Dtype>> active_param(Active_relu);//, alpha); // TEMP
+
+	// check if conv has eltwise_relu op attr
+	if(check_attr("merge_type")) {
+		LOG(ERROR) << "detect eltwise relu!!!!!!!! ";
+		auto type = GET_PARAMETER(std::string, merge_type);
+    	//auto alpha = GET_PARAMETER(float, merge_relu_0_alpha);
+    	auto coeff = GET_PARAMETER(PTuple<float>, merge_coeff);
+    	ActivationParam<Tensor4d<Ttype, Dtype>> activation_param(Active_relu);
+    	EltwiseType elt_type;
+    	if (type == "Add") {
+        	elt_type = Eltwise_sum;
+    	} else if (type == "Max") {
+        	elt_type = Eltwise_max;
+    	} else {
+        	elt_type = Eltwise_prod;
+    	}
+    	saber::EltwiseParam<Tensor4d<Ttype, Dtype>>  eltwise_param(elt_type, coeff.vector());
+    	EltwiseActiveParam<Tensor4d<Ttype, Dtype>> eltwise_relu_param(eltwise_param, activation_param);
+
+		ConvActiveParam<Tensor4d<Ttype, Dtype>> conv_act_param(_conv_param, batchnorm_param, scale_param, eltwise_relu_param);
+		_param_conv_batchnorm_scale_relu = conv_act_param;
+	} else { 
+		ConvActiveParam<Tensor4d<Ttype, Dtype>> conv_act_param(_conv_param, batchnorm_param, scale_param); 
+		_param_conv_batchnorm_scale_relu = conv_act_param;
+	}
+
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SassConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    _funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY, SABER_IMPL, ctx);
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SassConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::InferShape(
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    _funcs_conv_batchnorm_scale_relu.compute_output_shape(ins, outs, _param_conv_batchnorm_scale_relu);
+    return Status::OK();
+}
+
+#ifdef USE_CUDA
+template class SassConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>;
+template class SassConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP16>;
+template class SassConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::INT8>;
+#endif
+
+#ifdef USE_ARM_PLACE
+template class SassConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::FP32>;
+template class SassConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::FP16>;
+template class SassConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::INT8>;
+#endif
+
+// register helper
+#ifdef USE_CUDA
+ANAKIN_REGISTER_OP_HELPER(SassConvBatchnormScale, SassConvBatchnormScaleHelper, NV,
+                          AK_FLOAT, Precision::FP32);
+#endif
+
+#ifdef USE_ARM_PLACE
+ANAKIN_REGISTER_OP_HELPER(SassConvBatchnormScale, SassConvBatchnormScaleHelper, ARM,
+                          AK_FLOAT, Precision::FP32);
+#endif
+
+//! register op
+ANAKIN_REGISTER_OP(SassConvBatchnormScale)
+.Doc("SassConvBatchnormScale fusion operator")
+#ifdef USE_CUDA
+.__alias__<NV, AK_FLOAT, Precision::FP32>("convolution_batchnorm_scale_relu")
+#endif
+#ifdef USE_ARM_PLACE
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("convolution_batchnorm_scale_relu")
+#endif
+.num_in(1)
+.num_out(1)
+.Args<int>("group", " group of conv ")
+.Args<bool>("bias_term", " whether conv weights have bias")
+.Args<PTuple<int>>("padding", "padding of conv (x, y)")
+                .Args<PTuple<int>>("strides", "strides of conv (x)")
+                .Args<PTuple<int>>("dilation_rate", "dilation rate of conv (x)")
+                .Args<int>("filter_num", "filter(kernel) number of weights")
+                .Args<PTuple<int>>("kernel_size", "kernel size of kernel (x, y)")
+                .Args<int>("axis", "axis of conv")
+                .Args<float>("relu_0_alpha", " alpha for relu")
+                .Args<int>("scale_0_num_axes", " num axes for scale")
+                .Args<bool>("scale_0_bias_term", "whether scale has bias")
+                .Args<int>("scale_0_axis", "axis for scale")
+                .Args<float>("batchnorm_0_epsilon", "epsilon for batchnorm")
+                .Args<float>("batchnorm_0_momentum", "momentum for batchnorm");
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+
diff --git a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.h b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.h
new file mode 100644
index 0000000..d83b18a
--- /dev/null
+++ b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale.h
@@ -0,0 +1,104 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_OPERATOR_CONV_SASS_BATCHNORM_SCALE_H
+#define ANAKIN_OPERATOR_CONV_SASS_BATCHNORM_SCALE_H
+
+#include "framework/core/base.h"
+#include "framework/core/data_types.h"
+#include "framework/core/operator/operator.h"
+#include "utils/logger/logger.h"
+#include "saber/funcs/conv_act.h"
+
+namespace anakin {
+
+namespace ops {
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SassConvBatchnormScaleHelper;
+
+/// pooling op
+/**
+ * \brief SassConvBatchnormScale implementation class
+ * public inherit Operator
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SassConvBatchnormScale : public Operator<Ttype, Dtype, Ptype> {
+public:
+    SassConvBatchnormScale() {}
+
+    /// forward impl
+    virtual void operator() (OpContext<Ttype> &ctx, 
+                             const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                             std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+        //LOG(ERROR) << "Not Impl Yet Operator convolution<TargetType:"<<"unknown"<<","
+                   //<<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+    }
+
+    friend class SassConvBatchnormScaleHelper<Ttype, Dtype, Ptype>;
+};
+
+/**
+ * \brief SassConvBatchnormScale helper class to implement it
+ * public inherit OperatorHelper
+ * including init resource and shape size in SassConvBatchnormScale context
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SassConvBatchnormScaleHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
+public:
+    SassConvBatchnormScaleHelper()=default;
+
+    ~SassConvBatchnormScaleHelper();
+
+    Status InitParam() override;
+    
+    /**
+    * \brief initial all the resource needed by pooling
+    * \param ctx stand for SassConvBatchnormScale operation context
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    *///! initial all the resource needed by pooling
+    Status Init(OpContext<Ttype> &ctx,
+                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+    /**
+    * \brief infer the shape of output and input.
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+public:
+     ///< _param_conv_batchnorm_scale_relu stand for SassConvBatchnormScale parameter
+    saber::ConvActiveParam<Tensor4d<Ttype, Dtype>>  _param_conv_batchnorm_scale_relu;
+    ///< _funcs_conv_batchnorm_scale_relu stand for SassConvBatchnormScale function 
+    saber::ConvAct<Ttype, Dtype> _funcs_conv_batchnorm_scale_relu;
+
+private:
+    ///< _dims stand for SassConvBatchnormScale size
+    PTuple<int> _dims; 
+};
+
+
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+#endif
diff --git a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.cpp b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.cpp
index b5a058e..0d6d6ee 100644
--- a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.cpp
+++ b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.cpp
@@ -41,6 +41,7 @@ Status SassConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>::InitParam() {
     auto kernel_size = GET_PARAMETER(PTuple<int>, kernel_size);
     auto axis = GET_PARAMETER(int, axis);
 
+	
 	using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
     auto weights = GET_PARAMETER(pblock_type, weight_1);
 
diff --git a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.h b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.h
index b5f29fd..6e6f38e 100644
--- a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.h
+++ b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu_pool.h b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu_pool.h
index 3030d91..bfc8207 100644
--- a/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu_pool.h
+++ b/framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/conv_3x3_relu.h b/framework/operators/fusion_ops/conv_3x3_relu.h
index e63f3f4..5f93759 100644
--- a/framework/operators/fusion_ops/conv_3x3_relu.h
+++ b/framework/operators/fusion_ops/conv_3x3_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/conv_3x3_relu_pool.cpp b/framework/operators/fusion_ops/conv_3x3_relu_pool.cpp
index c742a92..f4ca7d3 100644
--- a/framework/operators/fusion_ops/conv_3x3_relu_pool.cpp
+++ b/framework/operators/fusion_ops/conv_3x3_relu_pool.cpp
@@ -95,8 +95,7 @@ Status SassConvReluPoolHelper<Ttype, Dtype, Ptype>::InitParam() {
         LOG(FATAL) << " SassConvReluPool fusion op doesn't support : " << pool_method << " pooling.";
     }
 
-    ConvActivePoolingParam<Tensor4d<Ttype, Dtype>> conv_act_pooling_param(_conv_param,
-									  active_param,
+    ConvActivePoolingParam<Tensor4d<Ttype, Dtype>> conv_act_pooling_param(_conv_param, active_param,
                                                                           _pooling_param);
     _param_conv_relu_pooling = conv_act_pooling_param;
     return Status::OK();
diff --git a/framework/operators/fusion_ops/conv_3x3_relu_pool.h b/framework/operators/fusion_ops/conv_3x3_relu_pool.h
index 258bd35..4aae20e 100644
--- a/framework/operators/fusion_ops/conv_3x3_relu_pool.h
+++ b/framework/operators/fusion_ops/conv_3x3_relu_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale.cpp b/framework/operators/fusion_ops/conv_batchnorm_scale.cpp
index 69c64fd..cdfcd82 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale.cpp
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale.cpp
@@ -4,30 +4,21 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ConvBatchnormScale<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_conv_batchnorm_scale;
-    impl->_funcs_conv_batchnorm_scale(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::~ConvBatchnormScaleHelper() {
+#define INSTANCE_CONVBATCHNORMSCALE(Ttype, Dtype, Ptype) \
+template<> \
+void ConvBatchnormScale<Ttype, Dtype, Ptype>::operator()(\
+    OpContext<Ttype>& ctx,\
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {\
+    auto* impl = static_cast<ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>*>(this->_helper);\
+    auto& param = static_cast<ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_conv_batchnorm_scale;\
+    SABER_CHECK(impl->_funcs_conv_batchnorm_scale(ins, outs, param, ctx));\
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::InitParam() {
-    DLOG(WARNING) << "Parsing ConvBatchnormScale op parameter.";
+    LOG(WARNING) << "Parsing ConvBatchnormScale op parameter.";
     saber::ConvParam<Tensor4d<Ttype, Dtype>> _conv_param;
 
     // get conv param
@@ -88,10 +79,10 @@ Status ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::InitParam() {
     /*auto alpha = GET_PARAMETER(float, relu_0_alpha);
     ActivationParam<Tensor4d<Ttype, Dtype>> active_param(Active_relu);//, alpha); // TEMP */
 
+	ConvActiveParam<Tensor4d<Ttype, Dtype>> conv_act_param(_conv_param, batchnorm_param, scale_param); 
+	_param_conv_batchnorm_scale = conv_act_param;
 
-    ConvActiveParam<Tensor4d<Ttype, Dtype>> conv_act_param(_conv_param, batchnorm_param, scale_param);
-    _param_conv_batchnorm_scale = conv_act_param;
-
+	
     return Status::OK();
 }
 
@@ -99,7 +90,8 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    _funcs_conv_batchnorm_scale.init(ins, outs, _param_conv_batchnorm_scale, SPECIFY, VENDER_IMPL, ctx);
+    SABER_CHECK(_funcs_conv_batchnorm_scale.init(ins, outs, \
+        _param_conv_batchnorm_scale, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -107,32 +99,36 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleHelper<Ttype, Dtype, Ptype>::InferShape(const
         std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    _funcs_conv_batchnorm_scale.compute_output_shape(ins, outs, _param_conv_batchnorm_scale);
+    SABER_CHECK(_funcs_conv_batchnorm_scale.compute_output_shape(ins, outs, \
+        _param_conv_batchnorm_scale));
     return Status::OK();
 }
 
-#ifdef USE_CUDA
-template class ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVBATCHNORMSCALE(ARM, AK_FLOAT, Precision::FP32);
 template class ConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleHelper<ARM, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScale, ConvBatchnormScaleHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
-// register helper
 #ifdef USE_CUDA
+INSTANCE_CONVBATCHNORMSCALE(NV, AK_FLOAT, Precision::FP32);
+template<>
+Status ConvBatchnormScaleHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV>& ctx, \
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, \
+    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    _funcs_conv_batchnorm_scale.init(ins, outs, _param_conv_batchnorm_scale, SPECIFY, VENDER_IMPL, ctx);
+    return Status::OK();
+}
 ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScale, ConvBatchnormScaleHelper, NV, AK_FLOAT,
                           Precision::FP32);
 #endif
+//#ifdef USE_X86_PLACE
+//INSTANCE_CONVBATCHNORMSCALE(X86, AK_FLOAT, Precision::FP32);
+//template class ConvBatchnormScaleHelper<X86, AK_FLOAT, Precision::FP32>;
+//ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScale, ConvBatchnormScaleHelper, X86, AK_FLOAT,
+//                          Precision::FP32);
+//#endif
 
-#ifdef USE_ARM_PLACE
-ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScale, ConvBatchnormScaleHelper, ARM, AK_FLOAT,
-                          Precision::FP32);
-#endif
 
 //! register op
 ANAKIN_REGISTER_OP(ConvBatchnormScale)
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale.h b/framework/operators/fusion_ops/conv_batchnorm_scale.h
index 985ec79..b70cce7 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale.h
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ConvBatchnormScaleHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ConvBatchnormScaleHelper()=default;
 
-    ~ConvBatchnormScaleHelper();
+    ~ConvBatchnormScaleHelper() {}
 
     Status InitParam() override;
 
@@ -89,14 +89,8 @@ public:
     saber::ConvActiveParam<Tensor4d<Ttype, Dtype>>  _param_conv_batchnorm_scale;
     ///< _funcs_conv stand for ConvBatchnormScale function 
     saber::ConvAct<Ttype, Dtype> _funcs_conv_batchnorm_scale;
-
-private:
-    ///< _dims stand for ConvBatchnormScale size
-    PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale_relu.cpp b/framework/operators/fusion_ops/conv_batchnorm_scale_relu.cpp
index 8f847a4..e83ecad 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale_relu.cpp
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale_relu.cpp
@@ -4,26 +4,17 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ConvBatchnormScaleRelu<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::FP32>*>
-                 (this->_helper);
-    auto& param = static_cast<ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_conv_batchnorm_scale_relu;
-    impl->_funcs_conv_batchnorm_scale_relu(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>::~ConvBatchnormScaleReluHelper() {
+#define INSTANCE_CONVBATCHNORMSCALERELU(Ttype, Dtype, Ptype) \
+template<> \
+void ConvBatchnormScaleRelu<Ttype, Dtype, Ptype>::operator()(\
+    OpContext<Ttype>& ctx,\
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {\
+    auto* impl = static_cast<ConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>*>\
+                 (this->_helper);\
+    auto& param = static_cast<ConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_conv_batchnorm_scale_relu;\
+    SABER_CHECK(impl->_funcs_conv_batchnorm_scale_relu(ins, outs, param, ctx));\
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -106,16 +97,9 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    if (_param_conv_batchnorm_scale_relu.conv_param.group == ins[0]->channel() && \
-            _param_conv_batchnorm_scale_relu.conv_param.group == outs[0]->channel()) {
-        _funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY,
-                                              SABER_IMPL, ctx);
-    } else {
-        _funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY,
-                                              VENDER_IMPL, ctx);
-    }
 
-    //_funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY, VENDER_IMPL, ctx);
+    SABER_CHECK(_funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY,
+                                              SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -123,31 +107,43 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleReluHelper<Ttype, Dtype, Ptype>::InferShape(const
         std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    _funcs_conv_batchnorm_scale_relu.compute_output_shape(ins, outs, _param_conv_batchnorm_scale_relu);
+    SABER_CHECK(_funcs_conv_batchnorm_scale_relu.compute_output_shape(ins, outs, _param_conv_batchnorm_scale_relu));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
-template class ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class ConvBatchnormScaleReluHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleReluHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleReluHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
+template <>
+Status ConvBatchnormScaleReluHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV> &ctx, \
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    if (_param_conv_batchnorm_scale_relu.conv_param.group == ins[0]->channel() && \
+            _param_conv_batchnorm_scale_relu.conv_param.group == outs[0]->channel()) {
+        _funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY,
+                                              SABER_IMPL, ctx);
+    } else {
+        _funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY,
+                                              VENDER_IMPL, ctx);
+    }
 
-// register helper
-#ifdef USE_CUDA
+    //_funcs_conv_batchnorm_scale_relu.init(ins, outs, _param_conv_batchnorm_scale_relu, SPECIFY, VENDER_IMPL, ctx);
+    return Status::OK();
+}
+INSTANCE_CONVBATCHNORMSCALERELU(NV, AK_FLOAT, Precision::FP32);
 ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleRelu, ConvBatchnormScaleReluHelper, NV, AK_FLOAT,
-                          Precision::FP32);
+                                  Precision::FP32);
 #endif
 
+//#ifdef USE_X86_PLACE
+//template class ConvBatchnormScaleReluHelper<X86, AK_FLOAT, Precision::FP32>;
+//INSTANCE_CONVBATCHNORMSCALERELU(X86, AK_FLOAT, Precision::FP32);
+//ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleRelu, ConvBatchnormScaleReluHelper, X86, AK_FLOAT,
+//                                  Precision::FP32);
+//#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVBATCHNORMSCALERELU(ARM, AK_FLOAT, Precision::FP32);
+template class ConvBatchnormScaleReluHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleRelu, ConvBatchnormScaleReluHelper, ARM, AK_FLOAT,
-                          Precision::FP32);
+                                  Precision::FP32);
 #endif
 
 //! register op
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale_relu.h b/framework/operators/fusion_ops/conv_batchnorm_scale_relu.h
index 76f0144..72b626b 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale_relu.h
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ConvBatchnormScaleReluHelper : public OperatorHelper<Ttype, Dtype, Ptype>
 public:
     ConvBatchnormScaleReluHelper()=default;
 
-    ~ConvBatchnormScaleReluHelper();
+    ~ConvBatchnormScaleReluHelper() {}
 
     Status InitParam() override;
 
@@ -95,8 +95,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.cpp b/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.cpp
index b7df025..449fadb 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.cpp
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.cpp
@@ -4,19 +4,18 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ConvBatchnormScaleReluPool<NV, AK_FLOAT, Precision::FP32>::operator() (OpContext<NV> &ctx, 
-                                                                            const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, 
-                                                                            std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_conv_batchnorm_scale_relu_pooling;
-    impl->_funcs_conv_batchnorm_scale_relu_pooling(ins, outs, param, ctx);
+#define INSTANCE_CONVBATCHNORMSCALERELUPOOLING(Ttype, Dtype, Ptype) \
+template<> \
+void ConvBatchnormScaleReluPool<Ttype, Dtype, Ptype>::operator()(\
+    OpContext<Ttype>& ctx,\
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {\
+    auto* impl = static_cast<ConvBatchnormScaleReluPoolHelper<Ttype, Dtype, Ptype>*>\
+                 (this->_helper);\
+    auto& param = static_cast<ConvBatchnormScaleReluPoolHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_conv_batchnorm_scale_relu_pooling;\
+    SABER_CHECK(impl->_funcs_conv_batchnorm_scale_relu_pooling(ins, outs, param, ctx));\
 }
-#endif
-
-/// TODO ... specialization other type of operator
-
 
 /// set helper
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -122,38 +121,38 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleReluPoolHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, 
                                                                    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                                                                    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    _funcs_conv_batchnorm_scale_relu_pooling.init(ins, outs, _param_conv_batchnorm_scale_relu_pooling, SPECIFY, VENDER_IMPL, ctx);
+    SABER_CHECK(_funcs_conv_batchnorm_scale_relu_pooling.init(ins, outs, \
+        _param_conv_batchnorm_scale_relu_pooling, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvBatchnormScaleReluPoolHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                                                                          std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-   _funcs_conv_batchnorm_scale_relu_pooling.compute_output_shape(ins, outs, _param_conv_batchnorm_scale_relu_pooling);
+    SABER_CHECK(_funcs_conv_batchnorm_scale_relu_pooling.compute_output_shape(ins, outs, \
+        _param_conv_batchnorm_scale_relu_pooling));
    return Status::OK();
 }
 
 #ifdef USE_CUDA
-template class ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::INT8>;
+INSTANCE_CONVBATCHNORMSCALERELUPOOLING(NV, AK_FLOAT, Precision::FP32);
+template<>
+Status ConvBatchnormScaleReluPoolHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV> &ctx,
+                                                                   const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+                                                                   std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    _funcs_conv_batchnorm_scale_relu_pooling.init(ins, outs, _param_conv_batchnorm_scale_relu_pooling, SPECIFY, VENDER_IMPL, ctx);
+    return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleReluPool, ConvBatchnormScaleReluPoolHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVBATCHNORMSCALERELUPOOLING(ARM, AK_FLOAT, Precision::FP32);
 template class ConvBatchnormScaleReluPoolHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvBatchnormScaleReluPoolHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvBatchnormScaleReluPoolHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper 
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleReluPool, ConvBatchnormScaleReluPoolHelper, NV, AK_FLOAT, Precision::FP32);
-#endif 
-
-#ifdef USE_ARM_PLACE
 ANAKIN_REGISTER_OP_HELPER(ConvBatchnormScaleReluPool, ConvBatchnormScaleReluPoolHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
+
 //! register op
 ANAKIN_REGISTER_OP(ConvBatchnormScaleReluPool)
     .Doc("ConvBatchnormScaleReluPool fusion operator")
diff --git a/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.h b/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.h
index 85d1903..a1c3fa3 100644
--- a/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.h
+++ b/framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/conv_relu.cpp b/framework/operators/fusion_ops/conv_relu.cpp
index 95b503f..f4bdb69 100644
--- a/framework/operators/fusion_ops/conv_relu.cpp
+++ b/framework/operators/fusion_ops/conv_relu.cpp
@@ -4,25 +4,16 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ConvRelu<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ConvReluHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = impl->_param_conv_relu;
-    impl->_funcs_conv_relu(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ConvReluHelper<Ttype, Dtype, Ptype>::~ConvReluHelper() {
+#define INSTANCE_CONVRELU(Ttype, Dtype, Ptype) \
+template<> \
+void ConvRelu<Ttype, Dtype, Ptype>::operator()(\
+    OpContext<Ttype>& ctx,\
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {\
+    auto* impl =\
+        static_cast<ConvReluHelper<Ttype, Dtype, Ptype>*>(this->_helper);\
+    auto& param = impl->_param_conv_relu;\
+    impl->_funcs_conv_relu(ins, outs, param, ctx);\
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -85,25 +76,8 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvReluHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-#if 0
-
-    if (_param_conv_relu.conv_param.group == ins[0]->channel() && \
-            _param_conv_relu.conv_param.group == outs[0]->channel()) {
-        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, SABER_IMPL, ctx);
-    } else {
-        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, VENDER_IMPL, ctx);
-    }
-
-#else
-
-    if (_param_conv_relu.conv_param.group == 1) {
-        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, SABER_IMPL, ctx);
-    } else {
-        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, VENDER_IMPL, ctx);
-    }
 
-#endif
-    //_funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, VENDER_IMPL, ctx);
+    SABER_CHECK(_funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -116,25 +90,35 @@ Status ConvReluHelper<Ttype, Dtype, Ptype>::InferShape(const
 }
 
 #ifdef USE_CUDA
-template class ConvReluHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConvReluHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConvReluHelper<NV, AK_FLOAT, Precision::INT8>;
+INSTANCE_CONVRELU(NV, AK_FLOAT, Precision::FP32);
+template <>
+Status ConvReluHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV>& ctx, \
+        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, \
+        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    if (_param_conv_relu.conv_param.group == 1|| (_param_conv_relu.conv_param.group == ins[0]->channel() && \
+        _param_conv_relu.conv_param.group == outs[0]->channel())) {
+        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, SABER_IMPL, ctx);
+    } else {
+        _funcs_conv_relu.init(ins, outs, _param_conv_relu, SPECIFY, VENDER_IMPL, ctx);
+    }
+    return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(ConvRelu, ConvReluHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
-#ifdef USE_ARM_PLACE
-template class ConvReluHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvReluHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvReluHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
+//#ifdef USE_X86_PLACE
+//INSTANCE_CONVRELU(X86, AK_FLOAT, Precision::FP32);
+//template class ConvReluHelper<X86, AK_FLOAT, Precision::FP32>;
+//ANAKIN_REGISTER_OP_HELPER(ConvRelu, ConvReluHelper, X86, AK_FLOAT, Precision::FP32);
+//#endif
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(ConvRelu, ConvReluHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVRELU(ARM, AK_FLOAT, Precision::FP32);
+template class ConvReluHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(ConvRelu, ConvReluHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
+
 //! register op
 ANAKIN_REGISTER_OP(ConvRelu)
 .Doc("ConvRelu operator")
@@ -144,6 +128,9 @@ ANAKIN_REGISTER_OP(ConvRelu)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("power")
 #endif
+//#ifdef USE_X86_PLACE
+//.__alias__<X86, AK_FLOAT, Precision::FP32>("power")
+//#endif
 .num_in(1)
 .num_out(1)
 .Args<int>("group", " group of conv ")
diff --git a/framework/operators/fusion_ops/conv_relu.h b/framework/operators/fusion_ops/conv_relu.h
index f06744d..1dfe496 100644
--- a/framework/operators/fusion_ops/conv_relu.h
+++ b/framework/operators/fusion_ops/conv_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ConvReluHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ConvReluHelper()=default;
 
-    ~ConvReluHelper();
+    ~ConvReluHelper() {}
 
     Status InitParam() override;
 
@@ -89,14 +89,8 @@ public:
     saber::ConvActiveParam<Tensor4d<Ttype, Dtype>> _param_conv_relu;
     ///< _funcs_conv_relu stand for ConvRelu function 
     saber::ConvAct<Ttype, Dtype> _funcs_conv_relu;
-
-private:
-    ///< _dims stand for ConvRelu size
-    PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/fusion_ops/conv_relu_pool.cpp b/framework/operators/fusion_ops/conv_relu_pool.cpp
index 1dea031..47a7cf7 100644
--- a/framework/operators/fusion_ops/conv_relu_pool.cpp
+++ b/framework/operators/fusion_ops/conv_relu_pool.cpp
@@ -4,28 +4,16 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ConvReluPool<NV, AK_FLOAT, Precision::FP32>::operator() (
-	OpContext<NV> &ctx, 
-	const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, 
-	std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    /*LOG(ERROR) << " compute of ConvReluPool ";
-    float * h_data = new float[outs[0]->size()];//valid_size()];
-    LOG(ERROR) << " outs[0]->valid_size() : " << outs[0]->size();
-    cudaMemcpy(h_data, outs[0]->mutable_data(), outs[0]->size()*sizeof(float), cudaMemcpyDeviceToHost);
-    cudaDeviceSynchronize();
-    CUDA_CHECK(cudaPeekAtLastError()); 
-    LOG(ERROR) << "over "; */
-    auto* impl = static_cast<ConvReluPoolHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<ConvReluPoolHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_conv_relu_pooling;
-    impl->_funcs_conv_relu_pooling(ins, outs, param, ctx);
+#define INSTANCE_CONVRELUPOOLING(Ttype, Dtype, Ptype) \
+template<> \
+void ConvReluPool<Ttype, Dtype, Ptype>::operator()(\
+    OpContext<Ttype>& ctx,\
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {\
+    auto* impl = static_cast<ConvReluPoolHelper<Ttype, Dtype, Ptype>*>(this->_helper);\
+    auto& param = static_cast<ConvReluPoolHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_conv_relu_pooling;\
+    SABER_CHECK(impl->_funcs_conv_relu_pooling(ins, outs, param, ctx));\
 }
-#endif
-
-/// TODO ... specialization other type of operator
-
-
 /// set helper
 template<typename Ttype, DataType Dtype, Precision Ptype>
 ConvReluPoolHelper<Ttype, Dtype, Ptype>::~ConvReluPoolHelper() {
@@ -95,8 +83,7 @@ Status ConvReluPoolHelper<Ttype, Dtype, Ptype>::InitParam() {
         LOG(FATAL) << " ConvReluPool fusion op doesn't support : " << pool_method << " pooling.";
     }
 
-    ConvActivePoolingParam<Tensor4d<Ttype, Dtype>> conv_act_pooling_param(_conv_param,
-									  active_param,
+    ConvActivePoolingParam<Tensor4d<Ttype, Dtype>> conv_act_pooling_param(_conv_param, active_param,
                                                                           _pooling_param);
     _param_conv_relu_pooling = conv_act_pooling_param;
     return Status::OK();
@@ -106,8 +93,7 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ConvReluPoolHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, 
                                                                    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                                                                    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    LOG(INFO)<<"IN THIS!!!!!";
-    _funcs_conv_relu_pooling.init(ins, outs, _param_conv_relu_pooling, STATIC, SABER_IMPL/*VENDER_IMPL*/, ctx);
+    SABER_CHECK(_funcs_conv_relu_pooling.init(ins, outs, _param_conv_relu_pooling, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -119,26 +105,24 @@ Status ConvReluPoolHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Ten
 }
 
 #ifdef USE_CUDA
-template class ConvReluPoolHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ConvReluPoolHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ConvReluPoolHelper<NV, AK_FLOAT, Precision::INT8>;
+INSTANCE_CONVRELUPOOLING(NV, AK_FLOAT, Precision::FP32);
+template<>
+Status ConvReluPoolHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV> &ctx,
+                                                                   const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+                                                                   std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    _funcs_conv_relu_pooling.init(ins, outs, _param_conv_relu_pooling, STATIC, SABER_IMPL, ctx);
+    return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(ConvReluPool, ConvReluPoolHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_CONVRELUPOOLING(ARM, AK_FLOAT, Precision::FP32);
 template class ConvReluPoolHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ConvReluPoolHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ConvReluPoolHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register helper 
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(ConvReluPool, ConvReluPoolHelper, NV, AK_FLOAT, Precision::FP32);
-#endif 
-
-#ifdef USE_ARM_PLACE
 ANAKIN_REGISTER_OP_HELPER(ConvReluPool, ConvReluPoolHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
+
 //! register op
 ANAKIN_REGISTER_OP(ConvReluPool)
     .Doc("ConvReluPool fusion operator")
diff --git a/framework/operators/fusion_ops/conv_relu_pool.h b/framework/operators/fusion_ops/conv_relu_pool.h
index 08956df..a640dd8 100644
--- a/framework/operators/fusion_ops/conv_relu_pool.h
+++ b/framework/operators/fusion_ops/conv_relu_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/deconv_relu.h b/framework/operators/fusion_ops/deconv_relu.h
index 5767a68..85be672 100644
--- a/framework/operators/fusion_ops/deconv_relu.h
+++ b/framework/operators/fusion_ops/deconv_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/eltwise_relu.h b/framework/operators/fusion_ops/eltwise_relu.h
index e1a6717..966460e 100644
--- a/framework/operators/fusion_ops/eltwise_relu.h
+++ b/framework/operators/fusion_ops/eltwise_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/fusion_ops/permute_power.h b/framework/operators/fusion_ops/permute_power.h
index caa7ef0..a31b313 100644
--- a/framework/operators/fusion_ops/permute_power.h
+++ b/framework/operators/fusion_ops/permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/gather.cpp b/framework/operators/gather.cpp
new file mode 100644
index 0000000..5fb30ab
--- /dev/null
+++ b/framework/operators/gather.cpp
@@ -0,0 +1,105 @@
+#include "framework/operators/gather.h"
+
+namespace anakin {
+
+namespace ops {
+
+#ifdef USE_CUDA
+template<>
+void Gather<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx,
+        const std::vector<Tensor4dPtr<NV, AK_FLOAT>>& ins,
+        std::vector<Tensor4dPtr<NV, AK_FLOAT>>& outs) {
+}
+#endif
+#ifdef USE_X86_PLACE
+template<>
+void Gather<X86, AK_FLOAT, Precision::FP32>::operator()(OpContext<X86>& ctx,
+      const std::vector<Tensor4dPtr<X86, AK_FLOAT>>& ins,
+      std::vector<Tensor4dPtr<X86, AK_FLOAT>>& outs) {
+}
+#endif
+
+/// TODO ... specialization other type of operator
+
+
+/// set helper
+template<typename Ttype, DataType Dtype, Precision Ptype>
+GatherHelper<Ttype, Dtype, Ptype>::~GatherHelper() {
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status GatherHelper<Ttype, Dtype, Ptype>::InitParam() {
+    DLOG(WARNING) << "Parsing Gather op parameter.";
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status GatherHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
+        const std::vector<Tensor4dPtr<Ttype, Dtype>>& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype>>& outs) {
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status GatherHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
+        ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    outs[0]->set_shape(ins[0]->valid_shape());
+    outs[0]->set_seq_offset(ins[0]->get_seq_offset());
+    return Status::OK();
+}
+
+#ifdef USE_CUDA
+template class GatherHelper<NV, AK_FLOAT, Precision::FP32>;
+template class GatherHelper<NV, AK_FLOAT, Precision::FP16>;
+template class GatherHelper<NV, AK_FLOAT, Precision::INT8>;
+#endif
+
+#ifdef USE_ARM_PLACE
+template class GatherHelper<ARM, AK_FLOAT, Precision::FP32>;
+template class GatherHelper<ARM, AK_FLOAT, Precision::FP16>;
+template class GatherHelper<ARM, AK_FLOAT, Precision::INT8>;
+#endif
+#ifdef USE_X86_PLACE
+template class GatherHelper<X86, AK_FLOAT, Precision::FP32>;
+template class GatherHelper<X86, AK_FLOAT, Precision::FP16>;
+template class GatherHelper<X86, AK_FLOAT, Precision::INT8>;
+#endif
+
+// register help
+#ifdef USE_CUDA
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, NV, AK_FLOAT, Precision::FP32);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, NV, AK_FLOAT, Precision::FP16);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, NV, AK_FLOAT, Precision::INT8);
+#endif
+
+#ifdef USE_ARM_PLACE
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, ARM, AK_FLOAT, Precision::FP32);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, ARM, AK_FLOAT, Precision::FP16);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, ARM, AK_FLOAT, Precision::INT8);
+#endif
+
+#ifdef USE_X86_PLACE
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, X86, AK_FLOAT, Precision::FP32);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, X86, AK_FLOAT, Precision::FP16);
+ANAKIN_REGISTER_OP_HELPER(Gather, GatherHelper, X86, AK_FLOAT, Precision::INT8);
+#endif
+
+//! register op
+ANAKIN_REGISTER_OP(Gather) 
+#ifdef USE_CUDA
+    .__alias__<NV, AK_FLOAT, Precision::FP32>("gather")
+#endif
+#ifdef USE_ARM_PLACE
+    .__alias__<ARM, AK_FLOAT, Precision::FP32>("gather")
+#endif
+#ifdef USE_X86_PLACE
+    .__alias__<X86, AK_FLOAT, Precision::FP32>("gather")
+#endif
+	.Doc("Gather operator [ only a middle data holder and reshape ] ");
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+
diff --git a/framework/operators/gather.h b/framework/operators/gather.h
new file mode 100644
index 0000000..6e2010d
--- /dev/null
+++ b/framework/operators/gather.h
@@ -0,0 +1,90 @@
+/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_OPERATOR_GATHER_H
+#define ANAKIN_OPERATOR_GATHER_H
+
+#include "framework/core/base.h"
+#include "framework/core/data_types.h"
+#include "framework/core/operator/operator.h"
+#include "utils/logger/logger.h"
+
+namespace anakin {
+
+namespace ops {
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class GatherHelper;
+
+/// Gather op without any compute, this a holder for input
+/**
+ * \brief Gather implementation class
+ * public inherit Operator
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class Gather : public Operator<Ttype, Dtype, Ptype> {
+public:
+    virtual void operator() (OpContext<Ttype> &ctx, 
+                             const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                             std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+        LOG(ERROR) << "Not Impl Yet Operator Gather<TargetType:"<<"unknown"<<"," 
+                   <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info();
+    }
+
+    friend class GatherHelper<Ttype, Dtype, Ptype>;
+};
+
+/**
+ * \brief Gather helper class to implement it
+ * public inherit OperatorHelper
+ * including init resource and shape size in input context
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class GatherHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
+    typedef OperatorHelper<Ttype, Dtype, Ptype> Base; 
+public:
+    GatherHelper() {}
+
+    ~GatherHelper();
+
+    Status InitParam() override;
+
+    /**
+    * \brief initial all the resource needed by pooling
+    * \param ctx stand for Gather operation context
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status Init(OpContext<Ttype> &ctx, 
+                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+    /**
+    * \brief infer the shape of output and input.
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+};
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+#endif
diff --git a/framework/operators/gru.cpp b/framework/operators/gru.cpp
index 530c9ee..f2c4769 100644
--- a/framework/operators/gru.cpp
+++ b/framework/operators/gru.cpp
@@ -6,8 +6,8 @@ namespace ops {
 
 #ifdef USE_CUDA
 template<>
-void Gru<NV, AK_FLOAT, Precision::FP32>::operator() (OpContext<NV> &ctx, 
-                          const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, 
+void Gru<NV, AK_FLOAT, Precision::FP32>::operator() (OpContext<NV> &ctx,
+                          const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
                           std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
     auto* impl = static_cast<GruHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
     auto& param = static_cast<GruHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_gru;
@@ -77,6 +77,7 @@ Status GruHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx,
                                                 const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
                                                 std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
     SABER_CHECK(_funcs_gru.init(ins, outs, _param_gru, SPECIFY, SABER_IMPL, ctx));
+//    SABER_CHECK(_funcs_gru.init(ins, outs, _param_gru, SPECIFY, VENDER_IMPL, ctx));
     return Status::OK();
 }
 
diff --git a/framework/operators/gru.h b/framework/operators/gru.h
index 3a5ebb9..a80b9e6 100644
--- a/framework/operators/gru.h
+++ b/framework/operators/gru.h
@@ -1,6 +1,6 @@
 
 
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/im2sequence.h b/framework/operators/im2sequence.h
index df8ec97..3d12665 100644
--- a/framework/operators/im2sequence.h
+++ b/framework/operators/im2sequence.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/input.cpp b/framework/operators/input.cpp
index 3515073..2b852cc 100644
--- a/framework/operators/input.cpp
+++ b/framework/operators/input.cpp
@@ -4,34 +4,17 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Input<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx,
-        const std::vector<Tensor4dPtr<NV, AK_FLOAT>>& ins,
-        std::vector<Tensor4dPtr<NV, AK_FLOAT>>& outs) {
-}
-#endif
-#ifdef USE_X86_PLACE
-template<>
-void Input<X86, AK_FLOAT, Precision::FP32>::operator()(OpContext<X86>& ctx,
-      const std::vector<Tensor4dPtr<X86, AK_FLOAT>>& ins,
-      std::vector<Tensor4dPtr<X86, AK_FLOAT>>& outs) {
-}
-#endif
-
-/// TODO ... specialization other type of operator
+#define INSTANCE_INPUT(Ttype, Dtype, Ptype) \
+template<> \
+void Input<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+      const std::vector<Tensor4dPtr<Ttype, Dtype>>& ins, \
+      std::vector<Tensor4dPtr<Ttype, Dtype>>& outs) {}
 
 
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-InputHelper<Ttype, Dtype, Ptype>::~InputHelper() {
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status InputHelper<Ttype, Dtype, Ptype>::InitParam() {
-    DLOG(WARNING) << "Parsing Input op parameter.";
+    LOG(WARNING) << "Parsing Input op parameter.";
     input_shape = GET_PARAMETER(PTuple<int>, input_shape);
-
     for (int i = 0; i < input_shape.size(); i++) {
         LOG(INFO) << " |-- shape [" << i << "]: " << input_shape[i];
     }
@@ -40,18 +23,16 @@ Status InputHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status InputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype>>& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype>>& outs) {
+Status InputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx,
+                                              const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                              std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status InputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status InputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                               std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     saber::Shape out_shape;
-
     for (int i = 0; i < input_shape.size(); i++) {
         out_shape.push_back(input_shape[i]);
     }
@@ -64,54 +45,36 @@ Status InputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPt
 }
 
 #ifdef USE_CUDA
+INSTANCE_INPUT(NV, AK_FLOAT, Precision::FP32);
 template class InputHelper<NV, AK_FLOAT, Precision::FP32>;
-template class InputHelper<NV, AK_FLOAT, Precision::FP16>;
-template class InputHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-
-#ifdef USE_ARM_PLACE
-template class InputHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class InputHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class InputHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_X86_PLACE
-template class InputHelper<X86, AK_FLOAT, Precision::FP32>;
-template class InputHelper<X86, AK_FLOAT, Precision::FP16>;
-template class InputHelper<X86, AK_FLOAT, Precision::INT8>;
-#endif
-
-// register help
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, NV, AK_FLOAT, Precision::FP32);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, NV, AK_FLOAT, Precision::FP16);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, NV, AK_FLOAT, Precision::INT8);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_INPUT(ARM, AK_FLOAT, Precision::FP32);
+template class InputHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, ARM, AK_FLOAT, Precision::FP32);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, ARM, AK_FLOAT, Precision::FP16);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, ARM, AK_FLOAT, Precision::INT8);
-#endif
+#endif //arm
 
 #ifdef USE_X86_PLACE
+INSTANCE_INPUT(X86, AK_FLOAT, Precision::FP32);
+template class InputHelper<X86, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, X86, AK_FLOAT, Precision::FP32);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, X86, AK_FLOAT, Precision::FP16);
-ANAKIN_REGISTER_OP_HELPER(Input, InputHelper, X86, AK_FLOAT, Precision::INT8);
 #endif
 
 //! register op
-ANAKIN_REGISTER_OP(Input) 
-    .Doc("Input operator [ only a input data holder and reshape ] ")
+ANAKIN_REGISTER_OP(Input)
+.Doc("Input operator [ only a input data holder and reshape ] ")
 #ifdef USE_CUDA
-    .__alias__<NV, AK_FLOAT, Precision::FP32>("input")
+.__alias__<NV, AK_FLOAT, Precision::FP32>("input")
 #endif
 #ifdef USE_ARM_PLACE
-    .__alias__<ARM, AK_FLOAT, Precision::FP32>("input")
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("input")
 #endif
 #ifdef USE_X86_PLACE
-    .__alias__<X86, AK_FLOAT, Precision::FP32>("input")
+.__alias__<X86, AK_FLOAT, Precision::FP32>("input")
 #endif
-    .Args<PTuple<int>>("input_shape", " shape of graph input.");
+.Args<PTuple<int>>("input_shape", " shape of graph input.");
 
 } /* namespace ops */
 
diff --git a/framework/operators/input.h b/framework/operators/input.h
index 6586344..fb97f1d 100644
--- a/framework/operators/input.h
+++ b/framework/operators/input.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -57,7 +57,7 @@ class InputHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     InputHelper() {}
 
-    ~InputHelper();
+    ~InputHelper() {}
 
     Status InitParam() override;
 
@@ -81,7 +81,6 @@ public:
     Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                       std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
 
-
 private:
     ///<  input_shape :input op may hold motl-input
     PTuple<int> input_shape;
diff --git a/framework/operators/layer_norm.h b/framework/operators/layer_norm.h
index 977d406..9619d75 100644
--- a/framework/operators/layer_norm.h
+++ b/framework/operators/layer_norm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/lrn.h b/framework/operators/lrn.h
index 2a19073..881e65e 100644
--- a/framework/operators/lrn.h
+++ b/framework/operators/lrn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/lstm.cpp b/framework/operators/lstm.cpp
new file mode 100644
index 0000000..f90760f
--- /dev/null
+++ b/framework/operators/lstm.cpp
@@ -0,0 +1,153 @@
+#include "framework/operators/lstm.h"
+#include <unordered_map>
+namespace anakin {
+
+namespace ops {
+
+#ifdef USE_CUDA
+template<>
+void Lstm<NV, AK_FLOAT, Precision::FP32>::operator() (OpContext<NV> &ctx,
+                          const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, 
+                          std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    auto* impl = static_cast<LstmHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param = static_cast<LstmHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_lstm;
+    impl->_funcs_lstm(ins, outs, param, ctx);
+}
+#endif
+#ifdef USE_X86_PLACE
+template<>
+void Lstm<X86, AK_FLOAT, Precision::FP32>::operator() (OpContext<X86> &ctx,
+                                                     const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+                                                     std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    auto* impl = static_cast<LstmHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param = static_cast<LstmHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_lstm;
+    impl->_funcs_lstm(ins, outs, param, ctx);
+}
+#endif
+
+/// TODO ... specialization other type of operator
+/// set helper
+template<typename Ttype, DataType Dtype, Precision Ptype>
+LstmHelper<Ttype, Dtype, Ptype>::~LstmHelper() {
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status LstmHelper<Ttype, Dtype, Ptype>::InitParam() {
+    DLOG(WARNING) << "Parsing Lstm op parameter.";
+
+    auto num_direction = GET_PARAMETER(int, num_direction);
+    auto dropout_param = GET_PARAMETER(float, dropout_param);
+    auto num_layers = GET_PARAMETER(int, num_layers);
+    auto input_activation = GET_PARAMETER(std::string, input_activation);
+    auto gate_activation = GET_PARAMETER(std::string, gate_activation);
+    auto cell_activation = GET_PARAMETER(std::string, cell_activation);
+    auto candidate_activation = GET_PARAMETER(std::string, candidate_activation);
+    auto is_reverse = GET_PARAMETER(bool, is_reverse);
+    auto use_peepholes = GET_PARAMETER(bool, use_peepholes);
+
+    //auto weight_wu = GET_PARAMETER(PBlock<typename DataTypeWarpper<Dtype>::type>, weight_1);
+    //auto bias = GET_PARAMETER(PBlock<typename DataTypeWarpper<Dtype>::type>, weight_2);
+    using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+    auto weight_wu = GET_PARAMETER(pblock_type, weight_1);
+    auto bias = GET_PARAMETER(pblock_type, weight_2);
+
+
+    LOG(INFO)<<"lstm act = ["<<input_activation<<","<<gate_activation<<","<<cell_activation<<","<<candidate_activation<<"]";
+    LOG(INFO)<<"lstm other param = ["<<use_peepholes<<","<<is_reverse<<","<<dropout_param<<","<<num_direction<<","<<num_layers<<"]";
+//    exit(0);
+
+    std::unordered_map<std::string, ActiveType> enum_map = {
+            {"null",Active_unknow},
+            {"sigmoid_fluid", Active_sigmoid_fluid},
+            {"relu_fluid", Active_relu},
+            {"tanh_fluid", Active_tanh_fluid},
+            {"identity_fluid", Active_identity},
+            {"sigmoid", Active_sigmoid},
+            {"tanh", Active_tanh},
+    };
+    LstmParam<Tensor4d<Ttype, Dtype>> lstm_param(&(weight_wu.d_tensor()), &(bias.d_tensor()), nullptr,
+            enum_map[input_activation], enum_map[gate_activation],
+            enum_map[cell_activation], enum_map[candidate_activation],
+            use_peepholes, false, is_reverse, dropout_param,
+            num_direction, num_layers);
+    _param_lstm = lstm_param;
+
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status LstmHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx,
+                                                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                                                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    DLOG(INFO)<<"inti lstm in op.cpp";
+    SABER_CHECK(_funcs_lstm.init(ins, outs, _param_lstm, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status LstmHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                                                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs_lstm.compute_output_shape(ins, outs, _param_lstm));
+    return Status::OK();
+}
+
+#ifdef USE_CUDA
+template class LstmHelper<NV, AK_FLOAT, Precision::FP32>;
+template class LstmHelper<NV, AK_FLOAT, Precision::FP16>;
+template class LstmHelper<NV, AK_FLOAT, Precision::INT8>;
+#endif
+
+#ifdef USE_ARM_PLACE
+template class LstmHelper<ARM, AK_FLOAT, Precision::FP32>;
+template class LstmHelper<ARM, AK_FLOAT, Precision::FP16>;
+template class LstmHelper<ARM, AK_FLOAT, Precision::INT8>;
+#endif
+
+#ifdef USE_X86_PLACE
+template class LstmHelper<X86, AK_FLOAT, Precision::FP32>;
+template class LstmHelper<X86, AK_FLOAT, Precision::FP16>;
+template class LstmHelper<X86, AK_FLOAT, Precision::INT8>;
+#endif
+
+#ifdef USE_CUDA
+ANAKIN_REGISTER_OP_HELPER(Lstm, LstmHelper, NV, AK_FLOAT, Precision::FP32);
+#endif
+#ifdef USE_ARM_PLACE
+ANAKIN_REGISTER_OP_HELPER(Lstm, LstmHelper, ARM, AK_FLOAT, Precision::FP32);
+#endif
+#ifdef USE_X86_PLACE
+ANAKIN_REGISTER_OP_HELPER(Lstm, LstmHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+//! register op
+ANAKIN_REGISTER_OP(Lstm)
+    .Doc("Lstm operator")
+#ifdef USE_CUDA
+    .__alias__<NV, AK_FLOAT, Precision::FP32>("LSTM")
+    .__alias__<NV, AK_FLOAT, Precision::FP32>("Lstm")
+#endif
+#ifdef USE_ARM_PLACE
+    .__alias__<ARM, AK_FLOAT, Precision::FP32>("LSTM")
+    .__alias__<ARM, AK_FLOAT, Precision::FP32>("Lstm")
+#endif
+#ifdef USE_X86_PLACE
+    .__alias__<X86, AK_FLOAT, Precision::FP32>("LSTM")
+    .__alias__<X86, AK_FLOAT, Precision::FP32>("Lstm")
+#endif
+    .num_in(1)
+    .num_out(1)
+    .Args<bool>("is_reverse", " is_reverse for lstm.")
+    .Args<int>("num_direction", "some descp")
+    .Args<float>("dropout_param", "some descp")
+    .Args<int>("num_layers", "some descp")
+    .Args<std::string>("input_activation", "some descp")
+    .Args<std::string>("gate_activation", "some descp")
+    .Args<std::string>("cell_activation", "some descp")
+    .Args<std::string>("candidate_activation", "some descp")
+    .Args<bool>("is_reverse", "some descp")
+    .Args<bool>("use_peephole", "some descp");
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+
diff --git a/framework/operators/lstm.h b/framework/operators/lstm.h
new file mode 100644
index 0000000..bdb810b
--- /dev/null
+++ b/framework/operators/lstm.h
@@ -0,0 +1,103 @@
+
+
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef ANAKIN_OPERATOR_LSTM_H
+#define ANAKIN_OPERATOR_LSTM_H
+
+#include "framework/core/base.h"
+#include "framework/core/data_types.h"
+#include "framework/core/operator/operator.h"
+#include "utils/logger/logger.h"
+#include "saber/funcs/lstm.h"
+
+namespace anakin {
+
+namespace ops {
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class LstmHelper;
+
+
+/// lstm op
+/**
+ * \brief Lstm implementation class
+ * public inherit Operator
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class Lstm : public Operator<Ttype, Dtype, Ptype> {
+public:
+    Lstm() {}
+
+    /// forward impl
+    virtual void operator() (OpContext<Ttype> &ctx, 
+                             const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                             std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+        LOG(ERROR) << "Not Impl Yet Operator Lstm<TargetType:"<<"unknown"<<","
+                   <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+    }
+
+    friend class LstmHelper<Ttype, Dtype, Ptype>;
+};
+
+/**
+ * \brief Lstm helper class to implement Lstm
+ * public inherit OperatorHelper
+ * including init resource and shape size in Lstm context
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class LstmHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
+public:
+    LstmHelper()=default;
+
+    ~LstmHelper();
+
+    Status InitParam() override;
+
+    /**
+    * \brief initial all the resource needed by lstm
+    * \param ctx stand for Lstm operation context
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status Init(OpContext<Ttype> &ctx,
+                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+    /**
+    * \brief infer the shape of output and input.
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+public:
+    ///< _param_lstm stand for Lstm parameter
+    saber::LstmParam<Tensor4d<Ttype, Dtype>> _param_lstm;
+    ///< _funcs_lstm stand for Lstm function
+    saber::Lstm<Ttype, Dtype> _funcs_lstm;
+};
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+#endif
+
+
diff --git a/framework/operators/normalize.h b/framework/operators/normalize.h
index fc67702..275d550 100644
--- a/framework/operators/normalize.h
+++ b/framework/operators/normalize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/ops.h b/framework/operators/ops.h
index 4b4d2a0..046b80b 100644
--- a/framework/operators/ops.h
+++ b/framework/operators/ops.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -15,21 +15,144 @@
 
 #ifndef ANAKIN_OPERATORS_H
 #define ANAKIN_OPERATORS_H
-
-#include "framework/operators/pooling.h"
+#if 1
+//#include "framework/graph/llvm/fusion/graph_pattern.h"
+#include "framework/operators/activation.h"
+#include "framework/operators/arg_max.h"
+//#include "framework/operators/axpy.h"
+#include "framework/operators/batch_norm.h"
+#include "framework/operators/concat.h"
+#include "framework/operators/conv_3x3.h"
+#include "framework/operators/convolution.h"
+#include "framework/operators/crf_decoding.h"
+#include "framework/operators/crop.h"
+#include "framework/operators/ctc_align.h"
+#include "framework/operators/deconvolution.h"
+#include "framework/operators/deformconvolution.h"
+#include "framework/operators/dense.h"
+#include "framework/operators/depwise_sep_convolution.h"
+#include "framework/operators/detection_output.h"
+#include "framework/operators/dot.h"
+#include "framework/operators/dropout.h"
+#include "framework/operators/eltwise_op.h"
+#include "framework/operators/elu.h"
+#include "framework/operators/embedding.h"
+#include "framework/operators/exp.h"
+#include "framework/operators/flatten.h"
+#include "framework/operators/gru.h"
+#include "framework/operators/im2sequence.h"
 #include "framework/operators/input.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-//#include "framework/operators/pooling.h"
-
+#include "framework/operators/log.h"
+#include "framework/operators/lrn.h"
+#include "framework/operators/mvn.h"
+#include "framework/operators/normalize.h"
+#include "framework/operators/output.h"
+#include "framework/operators/permute.h"
+#include "framework/operators/pooling.h"
+#include "framework/operators/power.h"
+#include "framework/operators/prelu.h"
+#include "framework/operators/priorbox.h"
+#include "framework/operators/relu.h"
+#include "framework/operators/reshape.h"
+#include "framework/operators/scale.h"
+#include "framework/operators/sequence_pool.h"
+#include "framework/operators/slice.h"
+#include "framework/operators/softmax.h"
+#include "framework/operators/spatial_pyramid_pooling.h"
+#include "framework/operators/split.h"
+#include "framework/operators/standard_rnn.h"
 
+#include "framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu.h"
+#include "framework/operators/fusion_ops/conv_3x3_batchnorm_scale_relu_pool.h"
+#include "framework/operators/fusion_ops/conv_3x3_relu.h"
+#include "framework/operators/fusion_ops/conv_3x3_relu_pool.h"
+#include "framework/operators/fusion_ops/conv_batchnorm_scale.h"
+#include "framework/operators/fusion_ops/conv_batchnorm_scale_relu.h"
+#include "framework/operators/fusion_ops/conv_batchnorm_scale_relu_pool.h"
+#include "framework/operators/fusion_ops/conv_relu.h"
+#include "framework/operators/fusion_ops/conv_relu_pool.h"
+#include "framework/operators/fusion_ops/deconv_relu.h"
+#include "framework/operators/fusion_ops/eltwise_relu.h"
+#include "framework/operators/fusion_ops/permute_power.h"
+#endif //0
 namespace anakin {
 namespace ops {
 } /* namespace ops */
 } /* namespace anakin */
+#if 0
+namespace anakin{
+namespace graph{
+    REGISTER_GRAPH_FUSION_PATTERN(DeconvRelu)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Deconvolution")
+            .AddOpNode("relu_0", "ReLU")
+            .AddConnect("conv_0", "relu_0")
+            .CreatePattern([](VGraph* graph) {});
+
+    REGISTER_GRAPH_FUSION_PATTERN(ConvRelu)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Convolution")
+            .AddOpNode("relu_0", "ReLU")
+            .AddConnect("conv_0", "relu_0")
+            .CreatePattern([](VGraph* graph) {});
+
+    REGISTER_GRAPH_FUSION_PATTERN(PermutePower)
+            .Type(IN_ORDER)
+            .AddOpNode("permute_0",  "Permute")
+            .AddOpNode("power_0", "Power")
+            .AddConnect("permute_0", "power_0")
+            .CreatePattern([](VGraph* graph) {});
+/*
+    REGISTER_GRAPH_FUSION_PATTERN(ConvReluPool)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Convolution")
+            .AddOpNode("relu_0", "ReLU")
+            .AddOpNode("pooling_0", "Pooling")
+            .AddConnect("conv_0", "relu_0")
+            .AddConnect("relu_0", "pooling_0")
+            .CreatePattern([](VGraph* graph) {});
+*/
+/*
+    REGISTER_GRAPH_FUSION_PATTERN(ConvBatchnormScaleReluPool)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Convolution")
+            .AddOpNode("batchnorm_0", "BatchNorm")
+            .AddOpNode("scale_0", "Scale")
+            .AddOpNode("relu_0", "ReLU")
+            .AddOpNode("pooling_0", "Pooling")
+            .AddConnect("conv_0", "batchnorm_0")
+            .AddConnect("batchnorm_0", "scale_0")
+            .AddConnect("scale_0", "relu_0")
+            .AddConnect("relu_0", "pooling_0")
+            .CreatePattern([](VGraph* graph) {});
+*/
+    REGISTER_GRAPH_FUSION_PATTERN(ConvBatchnormScaleRelu)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Convolution")
+            .AddOpNode("batchnorm_0", "BatchNorm")
+            .AddOpNode("scale_0", "Scale")
+            .AddOpNode("relu_0", "ReLU")
+            .AddConnect("conv_0", "batchnorm_0")
+            .AddConnect("batchnorm_0", "scale_0")
+            .AddConnect("scale_0", "relu_0")
+            .CreatePattern([](VGraph* graph) {});
+
+    REGISTER_GRAPH_FUSION_PATTERN(ConvBatchnormScale)
+            .Type(IN_ORDER)
+            .AddOpNode("conv_0",  "Convolution")
+            .AddOpNode("batchnorm_0", "BatchNorm")
+            .AddOpNode("scale_0", "Scale")
+            .AddConnect("conv_0", "batchnorm_0")
+            .AddConnect("batchnorm_0", "scale_0")
+            .CreatePattern([](VGraph* graph) {});
 
+    REGISTER_GRAPH_FUSION_PATTERN(EltwiseRelu)
+            .Type(IN_ORDER)
+            .AddOpNode("eltwise_0", "Eltwise")
+            .AddOpNode("relu_0", "ReLU")
+            .AddConnect("eltwise_0", "relu_0")
+            .CreatePattern([](VGraph* graph) {});
+}
+}
+#endif //0
 #endif
diff --git a/framework/operators/output.cpp b/framework/operators/output.cpp
index 1a34513..4bbf338 100644
--- a/framework/operators/output.cpp
+++ b/framework/operators/output.cpp
@@ -4,62 +4,62 @@ namespace anakin {
 
 namespace ops {
 
-template<>
-void Output<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT>>& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT>>& outs) {
-}
-
-
-/// TODO ... specialization other type of operator
+#define INSTANCE_OUTPUT(Ttype, Dtype, Ptype) \
+template<> \
+void Output<Ttype, Dtype, Ptype>::operator()( \
+    OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype>>& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype>>& outs) {}
 
 
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-OutputHelper<Ttype, Dtype, Ptype>::~OutputHelper() {
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status OutputHelper<Ttype, Dtype, Ptype>::InitParam() {
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status OutputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype>>& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype>>& outs) {
+Status OutputHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx,
+                                               const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                               std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
+    return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status OutputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status OutputHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     return Status::OK();
 }
 
+#ifdef USE_CUDA
+INSTANCE_OUTPUT(NV, AK_FLOAT, Precision::FP32);
 template class OutputHelper<NV, AK_FLOAT, Precision::FP32>;
-template class OutputHelper<NV, AK_FLOAT, Precision::FP16>;
-template class OutputHelper<NV, AK_FLOAT, Precision::INT8>;
-
-template class OutputHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class OutputHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class OutputHelper<ARM, AK_FLOAT, Precision::INT8>;
-
-// register help
 ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, NV, AK_FLOAT, Precision::FP32);
-ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, NV, AK_FLOAT, Precision::FP16);
-ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, NV, AK_FLOAT, Precision::INT8);
+#endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_OUTPUT(X86, AK_FLOAT, Precision::FP32);
+template class OutputHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
 
+#ifdef USE_ARM_PLACE
+INSTANCE_OUTPUT(ARM, AK_FLOAT, Precision::FP32);
+template class OutputHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, ARM, AK_FLOAT, Precision::FP32);
-ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, ARM, AK_FLOAT, Precision::FP16);
-ANAKIN_REGISTER_OP_HELPER(Output, OutputHelper, ARM, AK_FLOAT, Precision::INT8);
+#endif //arm
 
 //! register op
 ANAKIN_REGISTER_OP(Output)
-.Doc("Output operator [ only a input data holder and reshape ] ")
+#ifdef USE_CUDA
 .__alias__<NV, AK_FLOAT, Precision::FP32>("output")
-.__alias__<ARM, AK_FLOAT, Precision::FP32>("output");
+#endif
+#ifdef USE_ARM_PLACE
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("output")
+#endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("output")
+#endif
+.Doc("Output operator [ only a input data holder and reshape ] ");
 
 } /* namespace ops */
 
diff --git a/framework/operators/output.h b/framework/operators/output.h
index 71bb39c..72ae88b 100644
--- a/framework/operators/output.h
+++ b/framework/operators/output.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -57,7 +57,7 @@ class OutputHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     OutputHelper() {}
 
-    ~OutputHelper();
+    ~OutputHelper(){}
 
     Status InitParam() override;
 
@@ -81,7 +81,6 @@ public:
     Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
                       std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
 
-
 };
 
 } /* namespace ops */
diff --git a/framework/operators/permute.cpp b/framework/operators/permute.cpp
index 178bdaa..bcf933f 100644
--- a/framework/operators/permute.cpp
+++ b/framework/operators/permute.cpp
@@ -4,24 +4,15 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Permute<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx,
-        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<PermuteHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<PermuteHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_permute;
-    impl->_funcs_permute(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-PermuteHelper<Ttype, Dtype, Ptype>::~PermuteHelper() {
+#define INSTANCE_PERMUTE(Ttype, Dtype, Ptype) \
+template<> \
+void Permute<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<PermuteHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<PermuteHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_permute; \
+    impl->_funcs_permute(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -55,22 +46,20 @@ Status PermuteHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4d
 }
 
 #ifdef USE_CUDA
+INSTANCE_PERMUTE(NV, AK_FLOAT, Precision::FP32);
 template class PermuteHelper<NV, AK_FLOAT, Precision::FP32>;
-template class PermuteHelper<NV, AK_FLOAT, Precision::FP16>;
-template class PermuteHelper<NV, AK_FLOAT, Precision::INT8>;
+ANAKIN_REGISTER_OP_HELPER(Permute, PermuteHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
-#ifdef USE_ARM_PLACE
-template class PermuteHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class PermuteHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class PermuteHelper<ARM, AK_FLOAT, Precision::INT8>;
+#ifdef USE_X86_PLACE
+INSTANCE_PERMUTE(X86, AK_FLOAT, Precision::FP32);
+template class PermuteHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Permute, PermuteHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Permute, PermuteHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
 #ifdef USE_ARM_PLACE
+INSTANCE_PERMUTE(ARM, AK_FLOAT, Precision::FP32);
+template class PermuteHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Permute, PermuteHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -83,6 +72,9 @@ ANAKIN_REGISTER_OP(Permute)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("permute")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("permute")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<PTuple<int>>("dims", " dims for permuting the order of input ");
diff --git a/framework/operators/permute.h b/framework/operators/permute.h
index b8e45e7..be50685 100644
--- a/framework/operators/permute.h
+++ b/framework/operators/permute.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class PermuteHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     PermuteHelper()=default;
 
-    ~PermuteHelper();
+    ~PermuteHelper() {}
 
     Status InitParam() override;
 
@@ -90,9 +90,7 @@ public:
     ///< _funcs_permute stand for permute function
     saber::Permute<Ttype, Dtype> _funcs_permute;
 };
-
-
-
+        
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/pooling.cpp b/framework/operators/pooling.cpp
index ccc2c97..84f418f 100644
--- a/framework/operators/pooling.cpp
+++ b/framework/operators/pooling.cpp
@@ -4,26 +4,18 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Pooling<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx,
-        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<PoolingHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<PoolingHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_pooling;
-    impl->_funcs_pooling(ins, outs, param, ctx);
+#define INSTANCE_POOLING(Ttype, Dtype, Ptype) \
+template<> \
+void Pooling<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<PoolingHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<PoolingHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_pooling; \
+    impl->_funcs_pooling(ins, outs, param, ctx); \
 }
-#endif
-
-/// TODO ... specialization other type of operator
 
 
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-PoolingHelper<Ttype, Dtype, Ptype>::~PoolingHelper() {
-}
-
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status PoolingHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Pooling op parameter.";
@@ -36,60 +28,59 @@ Status PoolingHelper<Ttype, Dtype, Ptype>::InitParam() {
 
     if (pool_method == "MAX") {
         PoolingParam<Tensor4d<Ttype, Dtype>> pooling_param(pool_size[0], pool_size[1],
-                                          pool_padding[0], pool_padding[1],
-                                          pool_strides[0], pool_strides[1],
-                                          Pooling_max, global_pooling, cmp_out_shape_floor_as_conv);
+                                                           pool_padding[0], pool_padding[1],
+                                                           pool_strides[0], pool_strides[1],
+                                                           Pooling_max, global_pooling, cmp_out_shape_floor_as_conv);
         _param_pooling = pooling_param;
     } else if (pool_method == "AVG") {
         PoolingParam<Tensor4d<Ttype, Dtype>> pooling_param(pool_size[0], pool_size[1],
-                                          pool_padding[0], pool_padding[1],
-                                          pool_strides[0], pool_strides[1],
-                                          Pooling_average_include_padding, global_pooling, cmp_out_shape_floor_as_conv);
+                                                           pool_padding[0], pool_padding[1],
+                                                           pool_strides[0], pool_strides[1],
+                                                           Pooling_average_include_padding, global_pooling, cmp_out_shape_floor_as_conv);
         _param_pooling = pooling_param;
     } else {
-        LOG(FATAL) << " Pooling op doesn't support : " << pool_method << " pooling.";
+                LOG(FATAL) << " Pooling op doesn't support : " << pool_method << " pooling.";
     }
 
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status PoolingHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_pooling.init(ins, outs, _param_pooling, SPECIFY, VENDER_IMPL, ctx));
+Status PoolingHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                           std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
+    SABER_CHECK(_funcs_pooling.init(ins, outs, _param_pooling, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status PoolingHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status PoolingHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                 std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_pooling.compute_output_shape(ins, outs, _param_pooling));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
-template class PoolingHelper<NV, AK_FLOAT, Precision::FP32>;
-template class PoolingHelper<NV, AK_FLOAT, Precision::FP16>;
-template class PoolingHelper<NV, AK_FLOAT, Precision::INT8>;
+INSTANCE_POOLING(NV, AK_FLOAT, Precision::FP32);
+template <>
+Status PoolingHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV> &ctx, \
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, \
+    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_pooling.init(ins, outs, _param_pooling, SPECIFY, VENDER_IMPL, ctx));
+    return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(Pooling, PoolingHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
 #ifdef USE_ARM_PLACE
+INSTANCE_POOLING(ARM, AK_FLOAT, Precision::FP32);
 template class PoolingHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class PoolingHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class PoolingHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-
-//template class PoolingHelper<ARM, AK_FLOAT, Precision::FP32>;
-//template class PoolingHelper<ARM, AK_FLOAT, Precision::FP16>;
-//template class PoolingHelper<ARM, AK_FLOAT, Precision::INT8>;
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Pooling, PoolingHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
-#ifdef USE_ARM_PLACE
 ANAKIN_REGISTER_OP_HELPER(Pooling, PoolingHelper, ARM, AK_FLOAT, Precision::FP32);
+#endif  //arm
+
+#ifdef USE_X86_PLACE
+INSTANCE_POOLING(X86, AK_FLOAT, Precision::FP32);
+template class PoolingHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Pooling, PoolingHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
 //! register op
@@ -103,15 +94,18 @@ ANAKIN_REGISTER_OP(Pooling)
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("pooling")
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("pool")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("pooling")
+.__alias__<X86, AK_FLOAT, Precision::FP32>("pool")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<std::string>("method", "Pooling type to be applied (MAX, SUM, AVG).")
-.Args<bool>("cmp_out_shape_floor_as_conv",
-            "cmp_out_shape_floor_as_conv of pooling for adu novel approach")
+.Args<bool>("cmp_out_shape_floor_as_conv cmp_out_shape_floor_as_conv of pooling for adu novel approach")
 .Args<bool>("global_pooling", "whether execute global pooling on input")
 .Args<PTuple<int>>("pool_size", " kernel size for pooling (x, y) or (x, y, z).")
-                .Args<PTuple<int>>("strides",  "stride for pooling (x, y)  or  (x, y, z).")
-                .Args<PTuple<int>>("padding", "pad for pooling: (x, y) or (x, y, z).");
+.Args<PTuple<int>>("strides",  "stride for pooling (x, y)  or  (x, y, z).")
+.Args<PTuple<int>>("padding", "pad for pooling: (x, y) or (x, y, z).");
 
 } /* namespace ops */
 
diff --git a/framework/operators/pooling.h b/framework/operators/pooling.h
index b4f8ed4..68f31e4 100644
--- a/framework/operators/pooling.h
+++ b/framework/operators/pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -70,7 +70,7 @@ class PoolingHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     PoolingHelper()=default;
 
-    ~PoolingHelper();
+    ~PoolingHelper() {}
 
     Status InitParam() override;
 
@@ -101,6 +101,7 @@ public:
     saber::Pooling<Ttype, Dtype> _funcs_pooling;
 };
 
+
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/power.h b/framework/operators/power.h
index 0492249..062f49f 100644
--- a/framework/operators/power.h
+++ b/framework/operators/power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/priorbox.cpp b/framework/operators/priorbox.cpp
index 2e6a769..87f3ffe 100644
--- a/framework/operators/priorbox.cpp
+++ b/framework/operators/priorbox.cpp
@@ -4,24 +4,14 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void PriorBox<NV, AK_FLOAT, Precision::FP32>::operator()(OpContext<NV>& ctx, \
-        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins, \
-        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<PriorBoxHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<PriorBoxHelper<NV, AK_FLOAT, \
-                  Precision::FP32>*>(this->_helper)->_param_priorbox;
-    impl->_funcs_priorbox(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-PriorBoxHelper<Ttype, Dtype, Ptype>::~PriorBoxHelper() {
+#define INSTANCE_PRIORBOX(Ttype, Dtype, Ptype) \
+template<> \
+void PriorBox<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<PriorBoxHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<PriorBoxHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_priorbox; \
+    impl->_funcs_priorbox(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -38,10 +28,22 @@ Status PriorBoxHelper<Ttype, Dtype, Ptype>::InitParam() {
     auto step_h_   = GET_PARAMETER(float, step_h);
     auto step_w_   = GET_PARAMETER(float, step_w);
     auto offset_   = GET_PARAMETER(float, offset);
+    auto order     = GET_PARAMETER(PTuple<std::string>, order);
+    std::vector<PriorType> order_;
+
+    for (int i = 0; i < order.size(); i++) {
+        if (order[i] == "MIN") {
+            order_.push_back(PRIOR_MIN);
+        } else if (order[i] == "MAX") {
+            order_.push_back(PRIOR_MAX);
+        } else if (order[i] == "COM") {
+            order_.push_back(PRIOR_COM);
+        }
+    }
 
     saber::PriorBoxParam<Tensor4d<Ttype, Dtype>> param_priorbox(min_size_.vector(), max_size_.vector(), \
                                        as_ratio.vector(), var.vector(), flip_flag, clip_flag, \
-                                       image_w, image_h, step_w_, step_h_, offset_);
+                                       image_w, image_h, step_w_, step_h_, offset_, order_);
     _param_priorbox = param_priorbox;
     return Status::OK();
 }
@@ -63,22 +65,23 @@ Status PriorBoxHelper<Ttype, Dtype, Ptype>::InferShape(const
 }
 
 #ifdef USE_CUDA
+INSTANCE_PRIORBOX(NV, AK_FLOAT, Precision::FP32);
 template class PriorBoxHelper<NV, AK_FLOAT, Precision::FP32>;
-template class PriorBoxHelper<NV, AK_FLOAT, Precision::FP16>;
-template class PriorBoxHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class PriorBoxHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class PriorBoxHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class PriorBoxHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(PriorBox, PriorBoxHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_PRIORBOX(ARM, AK_FLOAT, Precision::FP32);
+template class PriorBoxHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(PriorBox, PriorBoxHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_PRIORBOX(X86, AK_FLOAT, Precision::FP32);
+template class PriorBoxHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(PriorBox, PriorBoxHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 //! register op
 ANAKIN_REGISTER_OP(PriorBox)
 .Doc("PriorBox operator")
@@ -88,6 +91,9 @@ ANAKIN_REGISTER_OP(PriorBox)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("priorbox")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("priorbox")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<PTuple<float>>("min_size", " min_size of bbox ")
diff --git a/framework/operators/priorbox.h b/framework/operators/priorbox.h
index adb56a5..9ac22ed 100644
--- a/framework/operators/priorbox.h
+++ b/framework/operators/priorbox.h
@@ -47,7 +47,7 @@ class PriorBoxHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     PriorBoxHelper()=default;
 
-    ~PriorBoxHelper();
+    ~PriorBoxHelper() {}
 
     Status InitParam() override;
 
@@ -65,8 +65,6 @@ public:
     saber::PriorBox<Ttype, Dtype> _funcs_priorbox;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/relu.cpp b/framework/operators/relu.cpp
index 6164e84..a5bdd09 100644
--- a/framework/operators/relu.cpp
+++ b/framework/operators/relu.cpp
@@ -4,26 +4,17 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void ReLU<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ReLUHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = impl->_param_relu;
-    impl->_funcs_relu(ins, outs, param, ctx);
+#define INSTANCE_RELU(Ttype, Dtype, Ptype) \
+template<> \
+void ReLU<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,\
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<ReLUHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = impl->_param_relu; \
+    impl->_funcs_relu(ins, outs, param, ctx); \
 }
-#endif
-
-/// TODO ... specialization other type of operator
-
 
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ReLUHelper<Ttype, Dtype, Ptype>::~ReLUHelper() {
-}
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ReLUHelper<Ttype, Dtype, Ptype>::InitParam() {
@@ -37,40 +28,42 @@ Status ReLUHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ReLUHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_relu.init(ins, outs, _param_relu, SPECIFY, VENDER_IMPL, ctx));
+Status ReLUHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                        std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
+    SABER_CHECK(_funcs_relu.init(ins, outs, _param_relu, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ReLUHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status ReLUHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                              std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_relu.compute_output_shape(ins, outs, _param_relu));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
-template class ReLUHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ReLUHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ReLUHelper<NV, AK_FLOAT, Precision::INT8>;
+INSTANCE_RELU(NV, AK_FLOAT, Precision::FP32);
+template <>
+Status ReLUHelper<NV, AK_FLOAT, Precision::FP32>::Init(OpContext<NV> &ctx,
+                                                        const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+                                                        std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+     SABER_CHECK(_funcs_relu.init(ins, outs, _param_relu, SPECIFY, VENDER_IMPL, ctx));
+     return Status::OK();
+}
+ANAKIN_REGISTER_OP_HELPER(ReLU, ReLUHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
 
-#ifdef USE_ARM_PLACE
-template class ReLUHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ReLUHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ReLUHelper<ARM, AK_FLOAT, Precision::INT8>;
+#ifdef USE_X86_PLACE
+INSTANCE_RELU(X86, AK_FLOAT, Precision::FP32);
+template class ReLUHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(ReLU, ReLUHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(ReLU, ReLUHelper, NV, AK_FLOAT, Precision::FP32);
-#endif
 #ifdef USE_ARM_PLACE
+INSTANCE_RELU(ARM, AK_FLOAT, Precision::FP32);
+template class ReLUHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(ReLU, ReLUHelper, ARM, AK_FLOAT, Precision::FP32);
-#endif
+#endif//arm
 
 //! register op
 ANAKIN_REGISTER_OP(ReLU)
@@ -81,6 +74,9 @@ ANAKIN_REGISTER_OP(ReLU)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("Relu")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("Relu")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<float>("alpha", " alpha for relu");
diff --git a/framework/operators/relu.h b/framework/operators/relu.h
index c3220bb..70089b5 100644
--- a/framework/operators/relu.h
+++ b/framework/operators/relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ReLUHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ReLUHelper()=default;
 
-    ~ReLUHelper();
+    ~ReLUHelper() {}
 
     Status InitParam() override;
 
@@ -95,8 +95,6 @@ private:
     PTuple<int> _dims; 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/reshape.cpp b/framework/operators/reshape.cpp
index f575d14..0872a27 100644
--- a/framework/operators/reshape.cpp
+++ b/framework/operators/reshape.cpp
@@ -4,26 +4,16 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Reshape<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ReshapeHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param =
-        static_cast<ReshapeHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_reshape;
-    impl->_funcs_reshape(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ReshapeHelper<Ttype, Dtype, Ptype>::~ReshapeHelper() {
+#define INSTANCE_RESHAPE(Ttype, Dtype, Ptype) \
+template<> \
+void Reshape<Ttype, Dtype, Ptype>::operator()(OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<ReshapeHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = \
+        static_cast<ReshapeHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_reshape; \
+    impl->_funcs_reshape(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -36,40 +26,42 @@ Status ReshapeHelper<Ttype, Dtype, Ptype>::InitParam() {
     return Status::OK();
 }
 
+
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ReshapeHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status ReshapeHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                           std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_reshape.init(ins, outs, _param_reshape, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
+
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status ReshapeHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status ReshapeHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                 std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_reshape.compute_output_shape(ins, outs, _param_reshape));
     outs[0]->set_seq_offset(ins[0]->get_seq_offset());
     return Status::OK();
 }
 
+
 #ifdef USE_CUDA
+INSTANCE_RESHAPE(NV, AK_FLOAT, Precision::FP32);
 template class ReshapeHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ReshapeHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ReshapeHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class ReshapeHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ReshapeHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ReshapeHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Reshape, ReshapeHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_RESHAPE(X86, AK_FLOAT, Precision::FP32);
+template class ReshapeHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Reshape, ReshapeHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_RESHAPE(ARM, AK_FLOAT, Precision::FP32);
+template class ReshapeHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Reshape, ReshapeHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
 //! register op
 ANAKIN_REGISTER_OP(Reshape)
 .Doc("Reshape operator")
@@ -79,6 +71,9 @@ ANAKIN_REGISTER_OP(Reshape)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("reshape")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("reshape")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<PTuple<int>>("dims", " dims of redhape target");
diff --git a/framework/operators/reshape.h b/framework/operators/reshape.h
index b8dbe07..7a3821b 100644
--- a/framework/operators/reshape.h
+++ b/framework/operators/reshape.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -50,6 +50,7 @@ public:
     friend class ReshapeHelper<Ttype, Dtype, Ptype>;
 };
 
+
 /**
  * \brief Reshape helper class to implement reshape
  * public inherit OperatorHelper
@@ -60,7 +61,7 @@ class ReshapeHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ReshapeHelper()=default;
 
-    ~ReshapeHelper();
+    ~ReshapeHelper() {}
 
     Status InitParam() override;
 
@@ -91,8 +92,6 @@ public:
     saber::Reshape<Ttype, Dtype> _funcs_reshape;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/scale.cpp b/framework/operators/scale.cpp
index 8803f09..23d471f 100644
--- a/framework/operators/scale.cpp
+++ b/framework/operators/scale.cpp
@@ -4,38 +4,37 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Scale<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<ScaleHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param =
-        static_cast<ScaleHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_scale;
-    impl->_funcs_scale(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-ScaleHelper<Ttype, Dtype, Ptype>::~ScaleHelper() {
+#define INSTANCE_SCALE(Ttype, Dtype, Ptype) \
+template<> \
+void Scale<Ttype, Dtype, Ptype>::operator()( \
+    OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<ScaleHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = \
+        static_cast<ScaleHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_scale; \
+    impl->_funcs_scale(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ScaleHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing Scale op parameter.";
+    using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+
     auto axis = GET_PARAMETER(int, axis);
     auto num_axes = GET_PARAMETER(int, num_axes);
     auto bias_term = GET_PARAMETER(bool, bias_term);
-    auto weights = GET_PARAMETER(PTuple<typename DataTypeWarpper<Dtype>::type>, weight_1);
-    auto bias = GET_PARAMETER(PTuple<typename DataTypeWarpper<Dtype>::type>, weight_2);
-    ScaleParam<Tensor4d<Ttype, Dtype>> param_scale(weights.vector(), bias.vector(), bias_term, axis, num_axes);
-    _param_scale = param_scale;
+    auto weights = GET_PARAMETER(pblock_type, weight_1);
+
+    if (bias_term) {
+        auto bias = GET_PARAMETER(pblock_type, weight_2);
+        ScaleParam <Tensor4d<Ttype, Dtype>> param_scale(weights.vector(), bias.vector(), bias_term, axis, num_axes);
+        _param_scale = param_scale;
+    } else {
+        ScaleParam <Tensor4d<Ttype, Dtype>> param_scale(weights.vector(), bias_term, axis, num_axes);
+        _param_scale = param_scale;
+    }
     return Status::OK();
 }
 
@@ -43,7 +42,7 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status ScaleHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
         const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
         std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-    SABER_CHECK(_funcs_scale.init(ins, outs, _param_scale, SPECIFY, VENDER_IMPL, ctx));
+    SABER_CHECK(_funcs_scale.init(ins, outs, _param_scale, SPECIFY, SABER_IMPL, ctx));
     return Status::OK();
 }
 
@@ -56,22 +55,23 @@ Status ScaleHelper<Ttype, Dtype, Ptype>::InferShape(const
 }
 
 #ifdef USE_CUDA
+INSTANCE_SCALE(NV, AK_FLOAT, Precision::FP32);
 template class ScaleHelper<NV, AK_FLOAT, Precision::FP32>;
-template class ScaleHelper<NV, AK_FLOAT, Precision::FP16>;
-template class ScaleHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class ScaleHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class ScaleHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class ScaleHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Scale, ScaleHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_SCALE(X86, AK_FLOAT, Precision::FP32);
+template class ScaleHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Scale, ScaleHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_SCALE(ARM, AK_FLOAT, Precision::FP32);
+template class ScaleHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Scale, ScaleHelper, ARM, AK_FLOAT, Precision::FP32);
-#endif
+#endif//arm
+
 //! register op
 ANAKIN_REGISTER_OP(Scale)
 .Doc("Scale operator")
@@ -81,6 +81,9 @@ ANAKIN_REGISTER_OP(Scale)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("Scale")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("Scale")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<std::string>("type", " type of Scale ");
diff --git a/framework/operators/scale.h b/framework/operators/scale.h
index d6518bc..d05dd39 100644
--- a/framework/operators/scale.h
+++ b/framework/operators/scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class ScaleHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     ScaleHelper()=default;
 
-    ~ScaleHelper();
+    ~ScaleHelper(){}
 
     Status InitParam() override;
 
@@ -91,8 +91,6 @@ public:
     saber::Scale<Ttype, Dtype> _funcs_scale;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/sequence_conv.cpp b/framework/operators/sequence_conv.cpp
new file mode 100644
index 0000000..7392d3b
--- /dev/null
+++ b/framework/operators/sequence_conv.cpp
@@ -0,0 +1,157 @@
+#include "framework/operators/sequence_conv.h"
+
+namespace anakin {
+
+namespace ops {
+
+#ifdef USE_CUDA
+template<>
+void SequenceConv<NV, AK_FLOAT, Precision::FP32>::operator()(
+    OpContext<NV>& ctx,
+    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
+    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
+    auto* impl = static_cast<SequenceConvHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param = static_cast<SequenceConvHelper<NV, AK_FLOAT, Precision::FP32>*>
+                  (this->_helper)->_param;
+    impl->_funcs(ins, outs, param, ctx);
+}
+#endif
+
+#ifdef USE_X86_PLACE
+template<>
+void SequenceConv<X86, AK_FLOAT, Precision::FP32>::operator()(
+    OpContext<X86>& ctx,
+    const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+    std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    auto* impl = static_cast<SequenceConvHelper<X86, AK_FLOAT, Precision::FP32>*>(this->_helper);
+    auto& param = static_cast<SequenceConvHelper<X86, AK_FLOAT, Precision::FP32>*>
+                  (this->_helper)->_param;
+    impl->_funcs(ins, outs, param, ctx);
+}
+#endif
+
+/// TODO ... specialization other type of operator
+
+
+/// set helper
+template<typename Ttype, DataType Dtype, Precision Ptype>
+SequenceConvHelper<Ttype, Dtype, Ptype>::~SequenceConvHelper() {
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SequenceConvHelper<Ttype, Dtype, Ptype>::InitParam() {
+    DLOG(WARNING) << "Parsing SequenceConv op parameter.";
+
+    auto context_length=GET_PARAMETER(int, context_length);
+    auto context_start=GET_PARAMETER(int, context_start);
+    auto context_stride=GET_PARAMETER(int, context_stride);
+    auto padding_trainable=GET_PARAMETER(bool, padding_trainable);
+    //auto filter_tensor=GET_PARAMETER(PBlock<typename DataTypeWarpper<Dtype>::type> , filter_tensor);
+    //auto padding_tensor=GET_PARAMETER(PBlock<typename DataTypeWarpper<Dtype>::type> , padding_tensor);
+    using pblock_type = PBlock<typename DataTypeWarpper<Dtype>::type, Ttype>;
+    auto filter_tensor = GET_PARAMETER(pblock_type, filter_tensor);
+    auto padding_tensor = GET_PARAMETER(pblock_type, padding_tensor);
+
+
+    if(padding_tensor.d_tensor().valid_size()>0) {
+        SequenceConvParam<Tensor4d<Ttype, Dtype>> param(&(filter_tensor.d_tensor()), context_length, context_start,
+                                                        context_stride, padding_trainable, &(padding_tensor.d_tensor()));
+        _param = param;
+    }else{
+        SequenceConvParam<Tensor4d<Ttype, Dtype>> param(&(filter_tensor.d_tensor()), context_length, context_start,
+                                                        context_stride, padding_trainable);
+        _param = param;
+    }
+
+    return Status::OK();
+}
+
+template<>
+Status SequenceConvHelper<X86, AK_FLOAT, Precision::FP32>::Init(OpContext<X86>& ctx,
+        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    LOG(INFO) << "are you ok";
+    SABER_CHECK(_funcs.init(ins, outs, _param, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+template<>
+Status SequenceConvHelper<X86, AK_FLOAT, Precision::FP16>::Init(OpContext<X86>& ctx,
+        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    LOG(INFO) << "are you ok";
+    SABER_CHECK(_funcs.init(ins, outs, _param, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<>
+Status SequenceConvHelper<X86, AK_FLOAT, Precision::INT8>::Init(OpContext<X86>& ctx,
+        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    LOG(INFO) << "are you ok";
+    SABER_CHECK(_funcs.init(ins, outs, _param, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SequenceConvHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs.init(ins, outs, _param, STATIC, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+Status SequenceConvHelper<Ttype, Dtype, Ptype>::InferShape(const
+        std::vector<Tensor4dPtr<Ttype, Dtype> >&
+        ins,
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+    SABER_CHECK(_funcs.compute_output_shape(ins, outs, _param));
+    return Status::OK();
+}
+#ifdef USE_X86_PLACE
+template class SequenceConvHelper<X86, AK_FLOAT, Precision::FP32>;
+template class SequenceConvHelper<X86, AK_FLOAT, Precision::FP16>;
+template class SequenceConvHelper<X86, AK_FLOAT, Precision::INT8>;
+#endif
+#ifdef USE_CUDA
+template class SequenceConvHelper<NV, AK_FLOAT, Precision::FP32>;
+template class SequenceConvHelper<NV, AK_FLOAT, Precision::FP16>;
+template class SequenceConvHelper<NV, AK_FLOAT, Precision::INT8>;
+#endif
+#ifdef USE_ARM_PLACE
+template class SequenceConvHelper<ARM, AK_FLOAT, Precision::FP32>;
+template class SequenceConvHelper<ARM, AK_FLOAT, Precision::FP16>;
+template class SequenceConvHelper<ARM, AK_FLOAT, Precision::INT8>;
+#endif
+// register helper
+#ifdef USE_X86_PLACE
+ANAKIN_REGISTER_OP_HELPER(SequenceConv, SequenceConvHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
+#ifdef USE_CUDA
+ANAKIN_REGISTER_OP_HELPER(SequenceConv, SequenceConvHelper, NV, AK_FLOAT, Precision::FP32);
+#endif
+#ifdef USE_ARM_PLACE
+ANAKIN_REGISTER_OP_HELPER(SequenceConv, SequenceConvHelper, ARM, AK_FLOAT, Precision::FP32);
+#endif
+//! register op
+ANAKIN_REGISTER_OP(SequenceConv)
+.Doc("SequenceConv operator")
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("SequenceConv")
+#endif
+#ifdef USE_CUDA
+.__alias__<NV, AK_FLOAT, Precision::FP32>("SequenceConv")
+#endif
+#ifdef USE_ARM_PLACE
+.__alias__<ARM, AK_FLOAT, Precision::FP32>("SequenceConv")
+#endif
+.num_in(1)
+.num_out(1)
+.Args<int>("axis", " axis ");
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+
diff --git a/framework/operators/sequence_conv.h b/framework/operators/sequence_conv.h
new file mode 100644
index 0000000..4608e08
--- /dev/null
+++ b/framework/operators/sequence_conv.h
@@ -0,0 +1,100 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_OPERATOR_SEQUENCE_CONV_H
+#define ANAKIN_OPERATOR_SEQUENCE_CONV_H
+
+#include "framework/core/base.h"
+#include "framework/core/data_types.h"
+#include "framework/core/operator/operator.h"
+#include "utils/logger/logger.h"
+#include "saber/funcs/sequence_conv.h"
+
+namespace anakin {
+
+namespace ops {
+
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SequenceConvHelper;
+
+/// pooling op
+/**
+ * \brief SequenceConv implementation class
+ * public inherit Operator
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SequenceConv : public Operator<Ttype, Dtype, Ptype> {
+public:
+    SequenceConv() {}
+
+    /// forward impl
+    virtual void operator()(OpContext<Ttype>& ctx,
+                            const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                            std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+        //LOG(ERROR) << "Not Impl Yet Operator power<TargetType:"<<"unknown"<<","
+        //          <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+    }
+
+    friend class SequenceConvHelper<Ttype, Dtype, Ptype>;
+};
+
+/**
+ * \brief SequenceConv helper class to implement SequenceConv
+ * public inherit OperatorHelper
+ * including init resource and shape size in SequenceConv context
+ */
+template<typename Ttype, DataType Dtype, Precision Ptype>
+class SequenceConvHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
+public:
+    SequenceConvHelper() = default;
+
+    ~SequenceConvHelper();
+
+    Status InitParam() override;
+
+    /**
+    * \brief initial all the resource needed by pooling
+    * \param ctx stand for SequenceConv operation context
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status Init(OpContext<Ttype>& ctx,
+                const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+    /**
+    * \brief infer the shape of output and input.
+    * \param ins stand for input tensor vector
+    * \param outs stand for output tensor vector
+    * \return status
+    */
+    Status InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
+                      std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) override;
+
+public:
+    ///< _param_softmax stand for softmax parameter
+    saber::SequenceConvParam<Tensor4d<Ttype, Dtype>> _param;
+    ///< _funcs_SequenceConv stand for softmax function
+    saber::SequenceConv<Ttype, Dtype> _funcs;
+};
+
+
+
+} /* namespace ops */
+
+} /* namespace anakin */
+
+#endif
diff --git a/framework/operators/sequence_pool.cpp b/framework/operators/sequence_pool.cpp
index 9842c45..1cf0ccc 100644
--- a/framework/operators/sequence_pool.cpp
+++ b/framework/operators/sequence_pool.cpp
@@ -4,7 +4,7 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_X86
+#ifdef USE_X86_PLACE
 template<>
 void SequencePool<X86, AK_FLOAT, Precision::FP32>::operator()(
     OpContext<X86>& ctx,
@@ -28,8 +28,15 @@ template<typename Ttype, DataType Dtype, Precision Ptype>
 Status SequencePoolHelper<Ttype, Dtype, Ptype>::InitParam() {
     DLOG(WARNING) << "Parsing SequencePool op parameter.";
     auto pooltype = GET_PARAMETER(std::string, pooltype);
-
-    saber::SequencePoolParam<Tensor4d<Ttype, Dtype>> sequence_pool_param;
+    std::unordered_map<std::string, SequencePoolType> type_map;
+    type_map.insert(std::make_pair("null", anakin::saber::Sequence_pool_unknow));
+    type_map.insert(std::make_pair("AVERAGE", anakin::saber::Sequence_pool_average));
+    type_map.insert(std::make_pair("SUM", anakin::saber::Sequence_pool_sum));
+    type_map.insert(std::make_pair("SQRT", anakin::saber::Sequence_pool_sqrt));
+    type_map.insert(std::make_pair("LAST", anakin::saber::Sequence_pool_last));
+    type_map.insert(std::make_pair("FIRST", anakin::saber::Sequence_pool_first));
+    type_map.insert(std::make_pair("MAX", anakin::saber::Sequence_pool_max));
+    saber::SequencePoolParam<Tensor4d<Ttype, Dtype>> sequence_pool_param(type_map[pooltype]);
     _param_sequence_pool = sequence_pool_param;
     return Status::OK();
 }
diff --git a/framework/operators/sequence_pool.h b/framework/operators/sequence_pool.h
index c085620..8840acf 100644
--- a/framework/operators/sequence_pool.h
+++ b/framework/operators/sequence_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/framework/operators/slice.cpp b/framework/operators/slice.cpp
index e352507..bf8780f 100644
--- a/framework/operators/slice.cpp
+++ b/framework/operators/slice.cpp
@@ -4,26 +4,17 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Slice<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl =
-        static_cast<SliceHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param =
-        static_cast<SliceHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper)->_param_slice;
-    impl->_funcs_slice(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-SliceHelper<Ttype, Dtype, Ptype>::~SliceHelper() {
+#define INSTANCE_SLICE(Ttype, Dtype, Ptype) \
+template<> \
+void Slice<Ttype, Dtype, Ptype>::operator()( \
+    OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = \
+        static_cast<SliceHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = \
+        static_cast<SliceHelper<Ttype, Dtype, Ptype>*>(this->_helper)->_param_slice; \
+    impl->_funcs_slice(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -74,22 +65,25 @@ Status SliceHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPt
 }
 
 #ifdef USE_CUDA
+INSTANCE_SLICE(NV, AK_FLOAT, Precision::FP32);
 template class SliceHelper<NV, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Slice, SliceHelper, NV, AK_FLOAT, Precision::FP32);
 template class SliceHelper<NV, AK_FLOAT, Precision::FP16>;
 template class SliceHelper<NV, AK_FLOAT, Precision::INT8>;
 #endif
-#ifdef USE_ARM_PLACE
-template class SliceHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class SliceHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class SliceHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
-ANAKIN_REGISTER_OP_HELPER(Slice, SliceHelper, NV, AK_FLOAT, Precision::FP32);
+
+#ifdef USE_X86_PLACE
+INSTANCE_SLICE(X86, AK_FLOAT, Precision::FP32);
+template class SliceHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Slice, SliceHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_SLICE(ARM, AK_FLOAT, Precision::FP32);
+template class SliceHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Slice, SliceHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
 //! register op
 ANAKIN_REGISTER_OP(Slice)
 .Doc("Slice operator")
@@ -103,7 +97,7 @@ ANAKIN_REGISTER_OP(Slice)
 .num_out(1)
 .Args<int>("slice_dim", " slice dim at input ")
 .Args<PTuple<int>>("slice_point", " slice point of op")
-                .Args<int>("axis", " axis of input to slice");
+.Args<int>("axis", " axis of input to slice");
 
 } /* namespace ops */
 
diff --git a/framework/operators/slice.h b/framework/operators/slice.h
index 75b00aa..f261fd0 100644
--- a/framework/operators/slice.h
+++ b/framework/operators/slice.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -60,7 +60,7 @@ class SliceHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     SliceHelper()=default;
 
-    ~SliceHelper();
+    ~SliceHelper() {}
 
     Status InitParam() override;
 
@@ -97,8 +97,6 @@ private:
     int _axis;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/softmax.cpp b/framework/operators/softmax.cpp
index 509a844..500af7f 100644
--- a/framework/operators/softmax.cpp
+++ b/framework/operators/softmax.cpp
@@ -4,25 +4,16 @@ namespace anakin {
 
 namespace ops {
 
-#ifdef USE_CUDA
-template<>
-void Softmax<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-    auto* impl = static_cast<SoftmaxHelper<NV, AK_FLOAT, Precision::FP32>*>(this->_helper);
-    auto& param = static_cast<SoftmaxHelper<NV, AK_FLOAT, Precision::FP32>*>
-                  (this->_helper)->_param_softmax;
-    impl->_funcs_softmax(ins, outs, param, ctx);
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-SoftmaxHelper<Ttype, Dtype, Ptype>::~SoftmaxHelper() {
+#define INSTANCE_SOFTMAX(Ttype, Dtype, Ptype) \
+template<> \
+void Softmax<Ttype, Dtype, Ptype>::operator()( \
+    OpContext<Ttype>& ctx, \
+    const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+    std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) { \
+    auto* impl = static_cast<SoftmaxHelper<Ttype, Dtype, Ptype>*>(this->_helper); \
+    auto& param = static_cast<SoftmaxHelper<Ttype, Dtype, Ptype>*>\
+                  (this->_helper)->_param_softmax; \
+    impl->_funcs_softmax(ins, outs, param, ctx); \
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
@@ -35,37 +26,66 @@ Status SoftmaxHelper<Ttype, Dtype, Ptype>::InitParam() {
     return Status::OK();
 }
 
+template<>
+Status SoftmaxHelper<X86, AK_FLOAT, Precision::FP32>::Init(OpContext<X86>& ctx,
+        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_softmax.init(ins, outs, _param_softmax, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+template<>
+Status SoftmaxHelper<X86, AK_FLOAT, Precision::FP16>::Init(OpContext<X86>& ctx,
+                                                           const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+                                                           std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_softmax.init(ins, outs, _param_softmax, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
+template<>
+Status SoftmaxHelper<X86, AK_FLOAT, Precision::INT8>::Init(OpContext<X86>& ctx,
+                                                           const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
+                                                           std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_softmax.init(ins, outs, _param_softmax, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
+
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status SoftmaxHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status SoftmaxHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                           std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_softmax.init(ins, outs, _param_softmax, STATIC, SABER_IMPL, ctx));
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status SoftmaxHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status SoftmaxHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                                 std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     SABER_CHECK(_funcs_softmax.compute_output_shape(ins, outs, _param_softmax));
     return Status::OK();
 }
 
 #ifdef USE_CUDA
+INSTANCE_SOFTMAX(NV, AK_FLOAT, Precision::FP32);
 template class SoftmaxHelper<NV, AK_FLOAT, Precision::FP32>;
 template class SoftmaxHelper<NV, AK_FLOAT, Precision::FP16>;
 template class SoftmaxHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class SoftmaxHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class SoftmaxHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class SoftmaxHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-// register helper
-#ifdef USE_CUDA
 ANAKIN_REGISTER_OP_HELPER(Softmax, SoftmaxHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
+#ifdef USE_X86_PLACE
+INSTANCE_SOFTMAX(X86, AK_FLOAT, Precision::FP32);
+template class SoftmaxHelper<X86, AK_FLOAT, Precision::FP32>;
+ANAKIN_REGISTER_OP_HELPER(Softmax, SoftmaxHelper, X86, AK_FLOAT, Precision::FP32);
+#endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_SOFTMAX(ARM, AK_FLOAT, Precision::FP32);
+template <>
+Status SoftmaxHelper<ARM, AK_FLOAT, Precision::FP32>::Init(OpContext<ARM> &ctx, \
+    const std::vector<Tensor4dPtr<ARM, AK_FLOAT> >& ins, \
+    std::vector<Tensor4dPtr<ARM, AK_FLOAT> >& outs) {
+    SABER_CHECK(_funcs_softmax.init(ins, outs, _param_softmax, SPECIFY, SABER_IMPL, ctx));
+    return Status::OK();
+}
 ANAKIN_REGISTER_OP_HELPER(Softmax, SoftmaxHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
 //! register op
@@ -77,6 +97,9 @@ ANAKIN_REGISTER_OP(Softmax)
 #ifdef USE_ARM_PLACE
 .__alias__<ARM, AK_FLOAT, Precision::FP32>("softmax")
 #endif
+#ifdef USE_X86_PLACE
+.__alias__<X86, AK_FLOAT, Precision::FP32>("softmax")
+#endif
 .num_in(1)
 .num_out(1)
 .Args<int>("axis", " axis ");
diff --git a/framework/operators/softmax.h b/framework/operators/softmax.h
index aa8b8ef..32af733 100644
--- a/framework/operators/softmax.h
+++ b/framework/operators/softmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -43,13 +43,15 @@ public:
     virtual void operator() (OpContext<Ttype> &ctx, 
                              const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, 
                              std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
-        //LOG(ERROR) << "Not Impl Yet Operator power<TargetType:"<<"unknown"<<","
-         //          <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
+        LOG(ERROR) << "Not Impl Yet Operator power<TargetType:"<<"unknown"<<","
+                   <<type_id<typename DataTypeWarpper<Dtype>::type>().type_info()<<">";
     }
 
     friend class SoftmaxHelper<Ttype, Dtype, Ptype>;
 };
 
+
+
 /**
  * \brief softmax helper class to implement softmax
  * public inherit OperatorHelper
@@ -60,7 +62,7 @@ class SoftmaxHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     SoftmaxHelper()=default;
 
-    ~SoftmaxHelper();
+    ~SoftmaxHelper() {}
 
     Status InitParam() override;
 
@@ -91,8 +93,6 @@ public:
     saber::Softmax<Ttype, Dtype> _funcs_softmax;
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/split.cpp b/framework/operators/split.cpp
index 09de18e..a889670 100644
--- a/framework/operators/split.cpp
+++ b/framework/operators/split.cpp
@@ -3,32 +3,13 @@
 namespace anakin {
 
 namespace ops {
+#define INSTANCE_SPLIT(Ttype, Dtype, Ptype) \
+template<> \
+void Split<Ttype, Dtype, Ptype>::operator()( \
+        OpContext<Ttype>& ctx, \
+        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins, \
+        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {}
 
-#ifdef USE_CUDA
-template<>
-void Split<NV, AK_FLOAT, Precision::FP32>::operator()(
-    OpContext<NV>& ctx,
-    const std::vector<Tensor4dPtr<NV, AK_FLOAT> >& ins,
-    std::vector<Tensor4dPtr<NV, AK_FLOAT> >& outs) {
-}
-#endif
-
-#ifdef USE_X86_PLACE
-template<>
-void Split<X86, AK_FLOAT, Precision::FP32>::operator()(
-        OpContext<X86>& ctx,
-        const std::vector<Tensor4dPtr<X86, AK_FLOAT> >& ins,
-        std::vector<Tensor4dPtr<X86, AK_FLOAT> >& outs) {
-}
-#endif
-
-/// TODO ... specialization other type of operator
-
-
-/// set helper
-template<typename Ttype, DataType Dtype, Precision Ptype>
-SplitHelper<Ttype, Dtype, Ptype>::~SplitHelper() {
-}
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
 Status SplitHelper<Ttype, Dtype, Ptype>::InitParam() {
@@ -38,48 +19,37 @@ Status SplitHelper<Ttype, Dtype, Ptype>::InitParam() {
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status SplitHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype>& ctx,
-        const std::vector<Tensor4dPtr<Ttype, Dtype> >& ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status SplitHelper<Ttype, Dtype, Ptype>::Init(OpContext<Ttype> &ctx, const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                         std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     return Status::OK();
 }
 
 template<typename Ttype, DataType Dtype, Precision Ptype>
-Status SplitHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype> >&
-        ins,
-        std::vector<Tensor4dPtr<Ttype, Dtype> >& outs) {
+Status SplitHelper<Ttype, Dtype, Ptype>::InferShape(const std::vector<Tensor4dPtr<Ttype, Dtype>> &ins,
+                               std::vector<Tensor4dPtr<Ttype, Dtype>> &outs) {
     for (int i = 0; i < split_num; i++) {
         outs[i]->set_shape(ins[0]->valid_shape());
         outs[i]->set_seq_offset(ins[0]->get_seq_offset());
     }
-
     return Status::OK();
 }
 
-#ifdef USE_CUDA
-template class SplitHelper<NV, AK_FLOAT, Precision::FP32>;
-template class SplitHelper<NV, AK_FLOAT, Precision::FP16>;
-template class SplitHelper<NV, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_ARM_PLACE
-template class SplitHelper<ARM, AK_FLOAT, Precision::FP32>;
-template class SplitHelper<ARM, AK_FLOAT, Precision::FP16>;
-template class SplitHelper<ARM, AK_FLOAT, Precision::INT8>;
-#endif
-#ifdef USE_X86_PLACE
-template class SplitHelper<X86, AK_FLOAT, Precision::FP32>;
-template class SplitHelper<X86, AK_FLOAT, Precision::FP16>;
-template class SplitHelper<X86, AK_FLOAT, Precision::INT8>;
-#endif
 
-// register helper
 #ifdef USE_CUDA
+INSTANCE_SPLIT(NV, AK_FLOAT, Precision::FP32);
+template class SplitHelper<NV, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Split, SplitHelper, NV, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_ARM_PLACE
+INSTANCE_SPLIT(ARM, AK_FLOAT, Precision::FP32);
+template class SplitHelper<ARM, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Split, SplitHelper, ARM, AK_FLOAT, Precision::FP32);
 #endif
+
 #ifdef USE_X86_PLACE
+INSTANCE_SPLIT(X86, AK_FLOAT, Precision::FP32);
+template class SplitHelper<X86, AK_FLOAT, Precision::FP32>;
 ANAKIN_REGISTER_OP_HELPER(Split, SplitHelper, X86, AK_FLOAT, Precision::FP32);
 #endif
 
@@ -99,6 +69,7 @@ ANAKIN_REGISTER_OP(Split)
 .num_out(1)
 .Args<int>("split_num", " split output number. ");
 
+
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/framework/operators/split.h b/framework/operators/split.h
index 09b5dd1..c97a4e4 100644
--- a/framework/operators/split.h
+++ b/framework/operators/split.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -59,7 +59,7 @@ class SplitHelper : public OperatorHelper<Ttype, Dtype, Ptype> {
 public:
     SplitHelper()=default;
 
-    ~SplitHelper();
+    ~SplitHelper(){}
 
     Status InitParam() override;
 
@@ -89,8 +89,6 @@ public:
 
 };
 
-
-
 } /* namespace ops */
 
 } /* namespace anakin */
diff --git a/saber/CMakeLists.txt b/saber/CMakeLists.txt
index 4661082..fd24ed1 100644
--- a/saber/CMakeLists.txt
+++ b/saber/CMakeLists.txt
@@ -1,14 +1,21 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     CMakeLists files in the saber directory of project
-# @auther   cuichaowen
-# @date     2017-10-24
-# ----------------------------------------------------------------------------
-
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 set(ANAKIN_SABER_STATIC_RELAY "" )
 
 set(ANAKIN_SABER_BASE_SRC "")
 anakin_fetch_include_recursively(${ANAKIN_SABER})
+anakin_fetch_include_recursively(${ANAKIN_UTILS})
 
 # add ak_base_source files
 anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core "cpp" ANAKIN_SABER_BASE_SRC)
@@ -16,9 +23,9 @@ anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/ "cpp" ANAKIN_SABER_BA
 anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs "cpp" ANAKIN_SABER_BASE_SRC)
 
 if(USE_ARM_PLACE)
-    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core/impl/arm "cpp" ANAKIN_SABER_BASE_SRC) 
-	anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/arm "cpp" ANAKIN_SABER_BASE_SRC) 
-	anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/arm/impl "cpp" ANAKIN_SABER_BASE_SRC)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core/impl/arm "cpp" ANAKIN_SABER_BASE_SRC)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/arm "cpp" ANAKIN_SABER_BASE_SRC)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/arm/impl "cpp" ANAKIN_SABER_BASE_SRC)
 endif()
 
 if(USE_GPU_PLACE)
@@ -32,7 +39,7 @@ endif()
 
 
 if(USE_X86_PLACE)
-	anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core/impl/x86 "cpp" ANAKIN_SABER_BASE_SRC)
+    anakin_fetch_files_with_suffix(${ANAKIN_SABER}/core/impl/x86 "cpp" ANAKIN_SABER_BASE_SRC)
     anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/x86 "cpp" ANAKIN_SABER_BASE_SRC)
     anakin_fetch_files_with_suffix(${ANAKIN_SABER}/funcs/impl/x86/kernel "cpp" ANAKIN_SABER_BASE_SRC)
 endif()
@@ -74,21 +81,31 @@ if(USE_CUDA)
 				      ${WHOLE_ARCHIVE_END})	
 endif()
 
-# add saber library to share
-if(UNIX OR APPLE) 
-    ADD_LIBRARY(${ANAKIN_SABER_TEMP_COMMMON_LIB} SHARED ${ANAKIN_SABER_CUDA_C_SRC_OBJS} ${ANAKIN_SABER_BASE_SRC})
-							#$<TARGET_OBJECTS:ANAKIN_SABER_BASE_OBJS>) 
-    if(USE_X86_PLACE)
-		message(STATUS ${ANAKIN_SABER_DEPENDENCIES})
-        add_dependencies(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_SABER_DEPENDENCIES})
+# add saber library to static
+if(UNIX OR APPLE)
+    if (USE_ARM_PLACE)
+        ADD_LIBRARY(${ANAKIN_SABER_TEMP_COMMMON_LIB} STATIC ${ANAKIN_SABER_CUDA_C_SRC_OBJS} ${ANAKIN_SABER_BASE_SRC})
+        set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+                ${ANAKIN_ROOT}/output/)
+    else()
+        if (BUILD_SHARED)
+            ADD_LIBRARY(${ANAKIN_SABER_TEMP_COMMMON_LIB} SHARED ${ANAKIN_SABER_CUDA_C_SRC_OBJS} ${ANAKIN_SABER_BASE_SRC})
+            #$<TARGET_OBJECTS:ANAKIN_SABER_BASE_OBJS>)
+            if(USE_X86_PLACE)
+                message(STATUS ${ANAKIN_SABER_DEPENDENCIES})
+                add_dependencies(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_SABER_DEPENDENCIES})
+            endif()
+            set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES VERSION ${VERSION})
+            target_link_libraries(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_LINKER_LIBS})
+            target_link_libraries(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_SABER_STATIC_RELAY})
+            set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LINK_FLAGS "")
+            set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+                    ${ANAKIN_ROOT}/output/)
+        else()
+            ADD_LIBRARY(${ANAKIN_SABER_TEMP_COMMMON_LIB} STATIC ${ANAKIN_SABER_CUDA_C_SRC_OBJS} ${ANAKIN_SABER_BASE_SRC})
+            set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+                    ${ANAKIN_ROOT}/output/)
+        endif ()
     endif()
-    set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES VERSION ${VERSION}) 
-    target_link_libraries(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_LINKER_LIBS}) 
-    target_link_libraries(${ANAKIN_SABER_TEMP_COMMMON_LIB} ${ANAKIN_SABER_STATIC_RELAY})
-    set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LINK_FLAGS "") 
-    set_target_properties(${ANAKIN_SABER_TEMP_COMMMON_LIB} PROPERTIES LIBRARY_OUTPUT_DIRECTORY
-							   ${ANAKIN_ROOT}/output/) 
 endif()
-
-
 set(ANAKIN_SABER_LIB_TARGET ${ANAKIN_SABER_TEMP_COMMMON_LIB} PARENT_SCOPE)
diff --git a/saber/core/buffer.h b/saber/core/buffer.h
index 13903b6..d9c83a4 100644
--- a/saber/core/buffer.h
+++ b/saber/core/buffer.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_BUFFER_H
 #define ANAKIN_SABER_CORE_BUFFER_H
diff --git a/saber/core/common.h b/saber/core/common.h
index 9e1bdd8..ffc3c6a 100644
--- a/saber/core/common.h
+++ b/saber/core/common.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -54,8 +54,11 @@ inline const char* saber_get_error_string(SaberStatus error_code){
             return "ANAKIN_SABER_STATUS_OUT_OF_MEMORY";
         case SaberUnImplError:
             return "ANAKIN_SABER_STATUS_UNIMPL_ERROR";
+        case SaberWrongDevice:
+            return "ANAKIN_SABER_STATUS_WRONG_DEVICE";
+        default:
+            return "ANAKIN SABER UNKOWN ERRORS";
     }
-    return "ANAKIN SABER UNKOWN ERRORS";
 }
 
 template <bool If, typename ThenType, typename ElseType>
@@ -141,8 +144,11 @@ const char* cudnn_get_errorstring(cudnnStatus_t status);
 
 
 #ifdef USE_ARM_PLACE
-
-#endif
+#ifdef USE_OPENMP
+#include <omp.h>
+#include <arm_neon.h>
+#endif //openmp
+#endif //ARM
 
 #endif //ANAKIN_SABER_CORE_COMMON_H
 
diff --git a/saber/core/context.h b/saber/core/context.h
index 847f91e..b8a9165 100644
--- a/saber/core/context.h
+++ b/saber/core/context.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_CONTEXT_H
 #define ANAKIN_SABER_CORE_CONTEXT_H
@@ -62,6 +63,10 @@ public:
         _compute_stream_id = ctx._compute_stream_id;
         _stream_compute = ctx._stream_compute;
         _stream_data = ctx._stream_data;
+#ifdef USE_ARM_PLACE
+        _act_ids = ctx._act_ids;
+        _mode = ctx._mode;
+#endif
     }
 
     Context& operator=(const Context& ctx){
@@ -70,6 +75,10 @@ public:
         this->_compute_stream_id = ctx._compute_stream_id;
         this->_stream_data = ctx._stream_data;
         this->_stream_compute = ctx._stream_compute;
+#ifdef USE_ARM_PLACE
+        this->_act_ids = ctx._act_ids;
+        this->_mode = ctx._mode;
+#endif
         return *this;
     }
 
@@ -106,11 +115,14 @@ public:
     }
 
 #ifdef USE_ARM_PLACE
-    void set_power_mode(PowerMode mode);
-    void set_act_cores(std::vector<int> ids);
+    //void set_act_cores(std::vector<int> ids);
+    //void set_power_mode(PowerMode mode);
+    void set_run_mode(PowerMode mode, int threads);
+    //void set_cache(size_t l1size, size_t l2size, size_t l3size);
     void bind_dev();
-    PowerMode get_mode();
-    std::vector<int> get_act_ids();
+    PowerMode get_mode(int& threads);
+    //PowerMode get_mode();
+    //std::vector<int> get_act_ids();
 #endif
 
 
@@ -123,8 +135,8 @@ private:
     int _data_stream_id;
     int _compute_stream_id;
 #ifdef USE_ARM_PLACE
-    PowerMode _mode;
-    std::vector<int> _act_ids;
+    PowerMode _mode{SABER_POWER_HIGH};
+    std::vector<int> _act_ids{0};
 #endif
 };
 
diff --git a/saber/core/data_traits.h b/saber/core/data_traits.h
index 0bb732a..06d7ba1 100644
--- a/saber/core/data_traits.h
+++ b/saber/core/data_traits.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_DATA_TRAITS_H
 #define ANAKIN_SABER_CORE_DATA_TRAITS_H
@@ -21,61 +22,124 @@ namespace anakin{
 
 namespace saber{
 
-template <DataType type>
+template <typename Ttype, DataType datatype>
 struct DataTrait{
+    typedef __invalid_type Dtype;
     typedef __invalid_type dtype;
 };
 
-template <>
-struct DataTrait<AK_HALF> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_HALF> {
+    typedef short Dtype;
     typedef short dtype;
 };
 
-template <>
-struct DataTrait<AK_FLOAT> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_FLOAT> {
+    typedef float Dtype;
     typedef float dtype;
 };
 
-template <>
-struct DataTrait<AK_DOUBLE> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_DOUBLE> {
+    typedef double Dtype;
     typedef double dtype;
 };
 
-template <>
-struct DataTrait<AK_INT8> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_INT8> {
+    typedef char Dtype;
     typedef char dtype;
 };
 
-template <>
-struct DataTrait<AK_INT16> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_INT16> {
+    typedef short Dtype;
     typedef short dtype;
 };
 
-template <>
-struct DataTrait<AK_INT32> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_INT32> {
+    typedef int Dtype;
     typedef int dtype;
 };
 
-template <>
-struct DataTrait<AK_INT64> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_INT64> {
+    typedef long Dtype;
     typedef long dtype;
 };
 
-template <>
-struct DataTrait<AK_UINT8> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_UINT8> {
+    typedef unsigned char Dtype;
     typedef unsigned char dtype;
 };
 
-template <>
-struct DataTrait<AK_UINT16> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_UINT16> {
+    typedef unsigned short Dtype;
     typedef unsigned short dtype;
 };
 
-template <>
-struct DataTrait<AK_UINT32> {
+template <typename Ttype>
+struct DataTrait<Ttype, AK_UINT32> {
+    typedef unsigned int Dtype;
     typedef unsigned int dtype;
 };
 
+#ifdef USE_OPENCL
+struct ClMem{
+    ClMem(){
+        dmem = nullptr;
+        offset = 0;
+    }
+
+    ClMem(cl_mem* mem_in, int offset_in = 0) {
+        dmem = mem_in;
+        offset = offset_in;
+    }
+
+    ClMem(ClMem& right) {
+        dmem = right.dmem;
+        offset = right.offset;
+    }
+
+    ClMem& operator=(ClMem& right) {
+        this->dmem = right.dmem;
+        this->offset = right.offset;
+        return *this;
+    }
+
+    ClMem& operator+(int offset_in) {
+        this->offset += offset_in;
+        return *this;
+    }
+
+    int offset{0};
+    cl_mem* dmem{nullptr};
+};
+
+template <>
+struct DataTrait<AMD, AK_FLOAT> {
+    typedef ClMem Dtype;
+    typedef float dtype;
+};
+
+template <>
+struct DataTrait<AMD, AK_DOUBLE> {
+    typedef ClMem Dtype;
+    typedef double dtype;
+};
+
+template <>
+struct DataTrait<AMD, AK_INT8> {
+    typedef ClMem Dtype;
+    typedef char dtype;
+};
+
+#endif
+
 } //namespace saber
 
 } //namespace anakin
diff --git a/saber/core/device.h b/saber/core/device.h
index 12e929e..88e6190 100644
--- a/saber/core/device.h
+++ b/saber/core/device.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_DEVICE_H
 #define ANAKIN_SABER_CORE_DEVICE_H
diff --git a/saber/core/env.h b/saber/core/env.h
index 3ae4216..d654758 100644
--- a/saber/core/env.h
+++ b/saber/core/env.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_ENV_H
 #define ANAKIN_SABER_CORE_ENV_H
diff --git a/saber/core/events.h b/saber/core/events.h
index dd6094b..1d20f2f 100644
--- a/saber/core/events.h
+++ b/saber/core/events.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_EVENTS_H
 #define ANAKIN_SABER_CORE_EVENTS_H
diff --git a/saber/core/impl/arm/arm_device.cpp b/saber/core/impl/arm/arm_device.cpp
index f214dfa..fd50a58 100644
--- a/saber/core/impl/arm/arm_device.cpp
+++ b/saber/core/impl/arm/arm_device.cpp
@@ -53,15 +53,102 @@ void Device<ARM>::get_info() {
     }
 }
 
-template void Device<ARM>::get_info();
-template void Device<ARM>::create_stream();
-
 template <>
 void Context<ARM>::bind_dev() {
     set_cpu_affinity(_act_ids);
 }
 
 template <>
+void Context<ARM>::set_run_mode(PowerMode mode, int threads) {
+    std::vector<int> big_cores;
+    std::vector<int> small_cores;
+    for (int i = 0; i < devs[0]._info._cluster_ids.size(); ++i) {
+        if (devs[0]._info._cluster_ids[i] == 0) {
+            big_cores.push_back(devs[0]._info._core_ids[i]);
+        } else {
+            small_cores.push_back(devs[0]._info._core_ids[i]);
+        }
+    }
+    int big_core_size = big_cores.size();
+    int small_core_size = small_cores.size();
+    if (threads > big_core_size + small_core_size) {
+        threads = big_core_size + small_core_size;
+    }
+    switch (mode) {
+        case SABER_POWER_FULL:
+            _mode = mode;
+            _act_ids.clear();
+            for (int i = 0; i < threads; ++i) {
+                if (i < big_core_size) {
+                    _act_ids.push_back(big_cores[i]);
+                } else {
+                    _act_ids.push_back(small_cores[i - big_core_size]);
+                }
+            }
+            break;
+        case SABER_POWER_HIGH:
+            _act_ids.clear();
+            if (big_core_size > 0) {
+                _mode = SABER_POWER_HIGH;
+                if (threads > big_core_size) {
+                    printf("threads: %d, exceed the big cores size: %d\n", threads, big_core_size);
+                    _act_ids = big_cores;
+                } else {
+                    for (int i = 0; i < threads; ++i) {
+                        _act_ids.push_back(big_cores[i]);
+                    }
+                }
+            } else {
+                _mode = SABER_POWER_LOW;
+                printf("HIGH POWER MODE is not support, switch to small cores\n");
+                if(threads > small_core_size) {
+                    _act_ids = small_cores;
+                } else {
+                    for (int i = 0; i < threads; ++i) {
+                        _act_ids.push_back(small_cores[i]);
+                    }
+                }
+
+            }
+            break;
+        case SABER_POWER_LOW:
+            _act_ids.clear();
+            if (small_core_size > 0) {
+                _mode = SABER_POWER_LOW;
+                if (threads > small_core_size) {
+                    printf("threads: %d, exceed the small cores size: %d\n", threads, small_core_size);
+                    _act_ids = small_cores;
+                } else {
+                    for (int i = 0; i < threads; ++i) {
+                        _act_ids.push_back(small_cores[i]);
+                    }
+                }
+            } else {
+                _mode = SABER_POWER_HIGH;
+                printf("LOW POWER MODE is not support, switch to big cores\n");
+                if(threads > big_core_size) {
+                    _act_ids = big_cores;
+                } else {
+                    for (int i = 0; i < threads; ++i) {
+                        _act_ids.push_back(small_cores[i]);
+                    }
+                }
+
+            }
+            break;
+    }
+
+    bind_dev();
+}
+
+template <>
+PowerMode Context<ARM>::get_mode(int& threads) {
+    threads = _act_ids.size();
+    return _mode;
+}
+
+#if 0
+template <>
 void Context<ARM>::set_power_mode(PowerMode mode) {
     _mode = mode;
     Device<ARM> dev = devs[_device_id];
@@ -97,6 +184,18 @@ void Context<ARM>::set_power_mode(PowerMode mode) {
 
 template <>
 void Context<ARM>::set_act_cores(std::vector<int> ids) {
+
+#ifdef USE_OPENMP
+    int dynamic_current = 0;
+    int num_threads_current = 1;
+    dynamic_current = omp_get_dynamic();
+    num_threads_current = omp_get_num_threads();
+    omp_set_dynamic(0);
+    omp_set_num_threads(ids.size());
+    _act_ids = ids;
+#endif
+
+#if 0
     Device<ARM> dev = devs[_device_id];
     if (ids.size() == 0){
         _act_ids.resize(1);
@@ -110,6 +209,7 @@ void Context<ARM>::set_act_cores(std::vector<int> ids) {
         }
     }
     bind_dev();
+#endif
 }
 
 template <>
@@ -121,6 +221,8 @@ template <>
 std::vector<int> Context<ARM>::get_act_ids() {
     return _act_ids;
 }
+#endif
+
 
 } //namespace saber
 
diff --git a/saber/core/impl/arm/arm_device.h b/saber/core/impl/arm/arm_device.h
index c92cc96..b42829f 100644
--- a/saber/core/impl/arm/arm_device.h
+++ b/saber/core/impl/arm/arm_device.h
@@ -297,6 +297,7 @@ static int set_cpu_affinity(const std::vector<int>& cpuids){
             return -1;
         }
 #endif
+    return 0;
 }
 
 #endif //PLATFORN_ANDROID
diff --git a/saber/core/impl/arm/arm_impl.cpp b/saber/core/impl/arm/arm_impl.cpp
index a51b48d..a7c9a41 100644
--- a/saber/core/impl/arm/arm_impl.cpp
+++ b/saber/core/impl/arm/arm_impl.cpp
@@ -13,18 +13,23 @@ template struct TargetWrapper<ARM, __host_target>;
 template class Buffer<ARM>;
 
 //! ARM Tensor
+#ifdef ANAKIN_TYPE_FP32
 template class Tensor<ARM, AK_FLOAT, NCHW>;
-template class Tensor<ARM, AK_FLOAT, NHWC>;
-template class Tensor<ARM, AK_FLOAT, HW>;
+//template class Tensor<ARM, AK_FLOAT, NHWC>;
+//template class Tensor<ARM, AK_FLOAT, HW>;
+#endif
 
+#ifdef ANAKIN_TYPE_INT8
 template class Tensor<ARM, AK_INT8, NCHW>;
 template class Tensor<ARM, AK_INT8, NHWC>;
 template class Tensor<ARM, AK_INT8, HW>;
+#endif
 
+#ifdef ANAKIN_TYPE_FP16
 template class Tensor<ARM, AK_HALF, NCHW>;
 template class Tensor<ARM, AK_HALF, NHWC>;
 template class Tensor<ARM, AK_HALF, HW>;
-
+#endif
 template class Env<ARM>;
 
 #endif //USE_ARM_PLACE
diff --git a/saber/core/impl/x86/x86_impl.cpp b/saber/core/impl/x86/x86_impl.cpp
index a867a3e..398fc0c 100644
--- a/saber/core/impl/x86/x86_impl.cpp
+++ b/saber/core/impl/x86/x86_impl.cpp
@@ -4,7 +4,7 @@
 namespace anakin{
 
 namespace saber{
-using namespace anakin::saber;
+
 //! target wrapper
 template struct TargetWrapper<X86, __host_target>;
 
diff --git a/saber/core/shape.h b/saber/core/shape.h
index 658aeb6..b8f9c76 100644
--- a/saber/core/shape.h
+++ b/saber/core/shape.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_SHAPE_H
 #define ANAKIN_SABER_CORE_SHAPE_H
diff --git a/saber/core/target_traits.h b/saber/core/target_traits.h
index 9c1d06d..52d1cc6 100644
--- a/saber/core/target_traits.h
+++ b/saber/core/target_traits.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_TARGET_TRAITS_H
 #define ANAKIN_SABER_CORE_TARGET_TRAITS_H
diff --git a/saber/core/target_wrapper.h b/saber/core/target_wrapper.h
index 7784915..8616962 100644
--- a/saber/core/target_wrapper.h
+++ b/saber/core/target_wrapper.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_TARGET_WRAPPER_H
 #define ANAKIN_SABER_CORE_TARGET_WRAPPER_H
diff --git a/saber/core/tensor.h b/saber/core/tensor.h
index 33e6557..3ec7c87 100644
--- a/saber/core/tensor.h
+++ b/saber/core/tensor.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -61,7 +61,8 @@ template<typename TargetType, DataType datatype, typename LayOutType = NCHW>
 class Tensor : public TensorBase {
 public:
     typedef TargetType targetType_t;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<TargetType, datatype>::Dtype Dtype;
+    typedef typename DataTrait<TargetType, datatype>::dtype dtype;
     typedef typename TargetTypeTraits<TargetType>::target_category target_category;
     typedef typename TargetTypeTraits<TargetType>::target_type target_type;
     typedef TargetWrapper<TargetType> API;
@@ -228,7 +229,7 @@ public:
         return SaberSuccess;
     }
 
-    void try_expand_size(Shape& shape) {
+    void try_expand_size(Shape shape) {
         //        LOG(INFO)<<"in try expand "<<shape.count()<<","<<valid_size();
         if (shape.count() > (valid_size())) {
             re_alloc(shape);
@@ -502,7 +503,7 @@ public:
     /**
      *  \brief Return tensor data pointer, with data type of current tensor (Dtype*).
      */
-    const Dtype * data(int index = 0) const {
+    const Dtype* data(int index = 0) const {
         // synchronize the events tree
         //sync();
         CHECK_EQ(device_id(), API::get_device_id()) << \
@@ -899,7 +900,7 @@ public:
 
 private:
     ///< Length of datatype.
-    size_t _type_len{sizeof(Dtype)};
+    size_t _type_len{sizeof(dtype)};
     ///< Represent the raw mem shape.
     Shape _shape;
     ///< Represent the mem you have right to access shape.
diff --git a/saber/core/tensor_op.cpp b/saber/core/tensor_op.cpp
index 2e64dcd..215d575 100644
--- a/saber/core/tensor_op.cpp
+++ b/saber/core/tensor_op.cpp
@@ -92,12 +92,12 @@ void tensor_cmp_host(const Dtype* src1, const Dtype* src2, \
 
 #define FILL_TENSOR_HOST(target, type, layout) \
     template void fill_tensor_host_const<Tensor<target, type, layout>>\
-        (Tensor<target, type, layout>& tensor, DataTrait<type>::dtype value); \
+        (Tensor<target, type, layout>& tensor, DataTrait<target, type>::dtype value); \
     template void fill_tensor_host_rand<Tensor<target, type, layout>>\
         (Tensor<target, type, layout>& tensor); \
     template void fill_tensor_host_rand<Tensor<target, type, layout>>\
-        (Tensor<target, type, layout>& tensor, DataTrait<type>::dtype vstart, \
-        DataTrait<type>::dtype vend); \
+        (Tensor<target, type, layout>& tensor, DataTrait<target, type>::dtype vstart, \
+        DataTrait<target, type>::dtype vend); \
     template void print_tensor_host<Tensor<target, type, layout>>\
         (Tensor<target, type, layout>& tensor);\
     template void fill_tensor_host_seq<Tensor<target, type, layout>>\
@@ -135,7 +135,7 @@ template <>
 void print_tensor_host<Tensor<X86, AK_INT8, NCHW_C4>>(Tensor<X86, AK_INT8, NCHW_C4>& tensor) {
     typedef typename Tensor<X86, AK_INT8, NCHW_C4>::Dtype Dtype;
     LOG(INFO) << "host tensor data:" << tensor.size();
-    const Dtype* data_ptr = tensor.get_buf()->get_data();
+    const Dtype* data_ptr = (const Dtype*)tensor.get_buf()->get_data();
     int size = tensor.size();
 
     for (int i = 0; i < size; ++i) {
diff --git a/saber/core/tensor_op.h b/saber/core/tensor_op.h
index 166d8f3..e92acb1 100644
--- a/saber/core/tensor_op.h
+++ b/saber/core/tensor_op.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/core/tensor_traits.h b/saber/core/tensor_traits.h
index 33aaf52..e2266e8 100644
--- a/saber/core/tensor_traits.h
+++ b/saber/core/tensor_traits.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_TENSOR_TRAITS_H
 #define ANAKIN_SABER_CORE_TENSOR_TRAITS_H
@@ -39,7 +40,7 @@ struct TensorTraits<Tensor<TargetType, datatype, NCHW_C16>>
 {
     typedef typename Tensor<TargetType, datatype, NCHW_C16>::target_category  target_category;
     typedef typename Tensor<TargetType, datatype, NCHW_C16>::target_type target_type;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<target_type, datatype>::dtype Dtype;
     typedef _5D layout_category;
     typedef NCHW_C16 layout_type;
     using layout_dims = std::integral_constant<int, 5>;
@@ -71,7 +72,7 @@ struct TensorTraits<Tensor<TargetType, datatype, NCHW_C8>>
 {
     typedef typename Tensor<TargetType, datatype, NCHW_C8>::target_category  target_category;
     typedef typename Tensor<TargetType, datatype, NCHW_C8>::target_type target_type;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<target_type, datatype>::dtype Dtype;
     typedef _5D layout_category;
     typedef NCHW_C8 layout_type;
     using layout_dims = std::integral_constant<int, 5>;
@@ -103,7 +104,7 @@ struct TensorTraits<Tensor<TargetType, datatype, NCHW_C4>>
 {
     typedef typename Tensor<TargetType, datatype, NCHW_C4>::target_category  target_category;
     typedef typename Tensor<TargetType, datatype, NCHW_C4>::target_type target_type;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<target_type, datatype>::dtype Dtype;
     typedef _5D layout_category;
     typedef NCHW_C4 layout_type;
     using layout_dims = std::integral_constant<int, 5>;
@@ -134,7 +135,7 @@ struct TensorTraits<Tensor<TargetType, datatype, NCHW>>
 {
     typedef typename Tensor<TargetType, datatype, NCHW>::target_category  target_category;
     typedef typename Tensor<TargetType, datatype, NCHW>::target_type target_type;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<target_type, datatype>::dtype Dtype;
     typedef _4D layout_category;
     typedef NCHW layout_type;
     using layout_dims = std::integral_constant<int, 4>;
diff --git a/saber/funcs/CMakeLists.txt b/saber/funcs/CMakeLists.txt
index deaf76e..74c1d4a 100644
--- a/saber/funcs/CMakeLists.txt
+++ b/saber/funcs/CMakeLists.txt
@@ -1,3 +1,17 @@
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 aux_source_directory(. DIR_BASE_SRCS)
 aux_source_directory(impl DIR_BASE_SRCS_IMPL)
 if(USE_ARM)
diff --git a/saber/funcs/activation.h b/saber/funcs/activation.h
index f39747a..1978713 100644
--- a/saber/funcs/activation.h
+++ b/saber/funcs/activation.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -29,6 +29,10 @@
 #include "saber/funcs/impl/x86/saber_activation.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_activation.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
@@ -69,6 +73,7 @@ public:
                                              Output_v &output, Param_t &param) override {
 
         Shape output_shape = (input[0]->valid_shape());
+        output[0]->set_seq_offset(input[0]->get_seq_offset());
         return output[0]->set_shape(output_shape);
     }
 
@@ -95,8 +100,11 @@ public:
 private:
 
     virtual void pick_best_static() override {
-        if (true) // some condition?
+        if (this->_param.active == Active_prelu) {
+            this->_best_impl = this->_impl[1];
+        } else {
             this->_best_impl = this->_impl[0];
+        }
     }
 
     virtual void pick_best_specify(ImplEnum implenum) override {
@@ -110,4 +118,4 @@ private:
 } // namespace saber
 } // namespace anakin
 
-#endif
\ No newline at end of file
+#endif
diff --git a/saber/funcs/argmax.h b/saber/funcs/argmax.h
index b258011..42d26be 100644
--- a/saber/funcs/argmax.h
+++ b/saber/funcs/argmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,6 +26,11 @@
 #include "saber/funcs/impl/impl_argmax.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_argmax.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/axpy.h b/saber/funcs/axpy.h
index 610b8b8..47c5e4f 100644
--- a/saber/funcs/axpy.h
+++ b/saber/funcs/axpy.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,6 +25,11 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_axpy.h"
 #endif
+
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_axpy.h"
+#endif
    
 namespace anakin {
 namespace saber {
diff --git a/saber/funcs/base.h b/saber/funcs/base.h
index 144de4b..54394aa 100644
--- a/saber/funcs/base.h
+++ b/saber/funcs/base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/box_coder.h b/saber/funcs/box_coder.h
deleted file mode 100644
index c96e0a4..0000000
--- a/saber/funcs/box_coder.h
+++ /dev/null
@@ -1,114 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
-*/
-#ifndef ANAKIN_SABER_FUNCS_BOX_CODER_H
-#define ANAKIN_SABER_FUNCS_BOX_CODER_H
-
-#include "saber/funcs/base.h"
-#include "saber/funcs/impl/impl_base.h"
-
-#ifdef NVIDIA_GPU
-#include "saber/funcs/impl/cuda/saber_box_coder.h"
-#endif
-
-#ifdef USE_X86_PLACE
-#include "saber/funcs/impl/impl_box_coder.h"
-#endif
-
-namespace anakin {
-namespace saber {
-
-template<typename TargetType,
-        DataType OpDtype,
-        DataType inDtype = AK_FLOAT,
-        DataType outDtype = AK_FLOAT,
-        typename LayOutType_op = NCHW,
-        typename LayOutType_in = NCHW,
-        typename LayOutType_out = NCHW
->
-class BoxCoder : public BaseFunc<
-        Tensor<TargetType, inDtype, LayOutType_in>,
-        Tensor<TargetType, outDtype, LayOutType_out>,
-        Tensor<TargetType, OpDtype, LayOutType_op>,
-        ImplBase,
-        BoxCoderParam
-> {
-public:
-    using BaseFunc<
-            Tensor<TargetType, inDtype, LayOutType_in>,
-            Tensor<TargetType, outDtype, LayOutType_out>,
-            Tensor<TargetType, OpDtype, LayOutType_op>,
-            ImplBase,
-            BoxCoderParam>::BaseFunc;
-
-    BoxCoder() = default;
-
-    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
-    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
-    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
-    typedef BoxCoderParam<OpTensor> Param_t;
-    typedef std::vector<InDataTensor *> Input_v;
-    typedef std::vector<OutDataTensor *> Output_v;
-    typedef std::vector<Shape> Shape_v;
-
-    virtual SaberStatus compute_output_shape(const Input_v &input,
-                                             Output_v &output, Param_t &param) override {
-
-        Shape shape_out = output[0]->valid_shape();
-        CHECK_EQ(shape_out.dims(), 2) << "only support 3d (NHW) output layout";
-        shape_out[0] = 2;
-
-        int win1 = input[0]->width();
-        int hin1 = input[0]->height();
-
-        return output[0]->set_shape(shape_out);
-    }
-
-    virtual SaberStatus init_impl(ImplEnum implenum) override {
-        switch (implenum) {
-            case VENDER_IMPL:
-                this->_impl.push_back(new VenderBoxCoder <TargetType,
-                        OpDtype, inDtype, outDtype,
-                        LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            case SABER_IMPL:
-                this->_impl.push_back(new SaberBoxCoder <TargetType,
-                        OpDtype, inDtype, outDtype,
-                        LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            default:
-                return SaberUnImplError;
-        }
-    }
-
-private:
-
-    virtual void pick_best_static() override {
-        if (true) // some condition?
-            this->_best_impl = this->_impl[0];
-    }
-
-    virtual void pick_best_specify(ImplEnum implenum) override {
-        this->_best_impl = this->_impl[0];
-    }
-
-};
-
-} // namespace saber
-} // namespace anakin
-
-
-#endif
\ No newline at end of file
diff --git a/saber/funcs/cast.h b/saber/funcs/cast.h
index 7d8f48c..0049cef 100644
--- a/saber/funcs/cast.h
+++ b/saber/funcs/cast.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,6 +26,11 @@
 #include "saber/funcs/impl/impl_cast.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_cast.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/concat.h b/saber/funcs/concat.h
index 3a630f7..700e626 100644
--- a/saber/funcs/concat.h
+++ b/saber/funcs/concat.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,6 +26,10 @@
 #include "saber/funcs/impl/x86/saber_concat.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_concat.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/conv.h b/saber/funcs/conv.h
index 4e5ca76..7ca38fd 100644
--- a/saber/funcs/conv.h
+++ b/saber/funcs/conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -27,6 +27,9 @@
 #include "saber/funcs/impl/impl_conv.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_conv.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/conv_act.h b/saber/funcs/conv_act.h
index 441dd99..bc0e02b 100644
--- a/saber/funcs/conv_act.h
+++ b/saber/funcs/conv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,7 +26,11 @@
 
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_conv_act.h"
-#endif   
+#endif
+
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_conv_act.h"
+#endif
 
 namespace anakin {
 namespace saber {
diff --git a/saber/funcs/conv_act_pooling.h b/saber/funcs/conv_act_pooling.h
index fb95a75..836f343 100644
--- a/saber/funcs/conv_act_pooling.h
+++ b/saber/funcs/conv_act_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -27,6 +27,11 @@
 #include "saber/funcs/impl/x86/saber_conv_act_pooling.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/arm/saber_conv_act_pooling.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
@@ -201,10 +206,14 @@ private:
         _use_saber_conv_pooling &= !(this->_param).pooling_param.global_pooling;
         _use_saber_conv_pooling &= (this->_param).pooling_param.pooling_type == Pooling_max;
 
-        if (!_use_saber_conv_pooling) {
-            this->_best_impl = this->_impl[0];
-        } else {
+        if (_use_saber_conv_pooling) {
             this->_best_impl = this->_impl[1];
+            delete this->_impl[0];
+            this->_impl[0] = NULL;
+        } else {
+            this->_best_impl = this->_impl[0];
+            delete this->_impl[1];
+            this->_impl[1] = NULL;
         }
     }
 
@@ -220,4 +229,4 @@ private:
 } // namespace anakin
 
 
-#endif
\ No newline at end of file
+#endif
diff --git a/saber/funcs/crf_decoding.h b/saber/funcs/crf_decoding.h
index 14e6b53..0fd17de 100644
--- a/saber/funcs/crf_decoding.h
+++ b/saber/funcs/crf_decoding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -29,6 +29,11 @@
 #include "saber/funcs/impl/x86/saber_crf_decoding.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_crf_decoding.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/crop.h b/saber/funcs/crop.h
index a847945..e7d8449 100644
--- a/saber/funcs/crop.h
+++ b/saber/funcs/crop.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,6 +25,11 @@
 #include "saber/funcs/impl/impl_crop.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_crop.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/ctc_align.h b/saber/funcs/ctc_align.h
index 772aa3e..0d5a685 100644
--- a/saber/funcs/ctc_align.h
+++ b/saber/funcs/ctc_align.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,6 +25,11 @@
 #include "saber/funcs/impl/impl_ctc_align.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_ctc_align.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/debug.h b/saber/funcs/debug.h
index 82eff70..df180b4 100644
--- a/saber/funcs/debug.h
+++ b/saber/funcs/debug.h
@@ -1,6 +1,17 @@
-//
-// Created by Liu,Junjie(SYS) on 2018/5/28.
-//
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_DEBUG_H
 #define ANAKIN_SABER_FUNCS_DEBUG_H
@@ -32,9 +43,12 @@ static void write_tensorfile(Tensor <X86, AK_FLOAT, NCHW> tensor, const char* lo
     LOG(INFO) << "!!! write success: " << locate;
 }
 #endif
+template <typename TargetType>
+static void record_dev_tensorfile(const float* dev_tensor, int size, const char* locate){};
 
 #ifdef USE_CUDA
-static void record_dev_tensorfile(const float* dev_tensor, int size, const char* locate) {
+template <>
+void record_dev_tensorfile<NV>(const float* dev_tensor, int size, const char* locate) {
     Tensor <X86, AK_FLOAT, NCHW> host_temp;
     host_temp.re_alloc(Shape(1, 1, 1, size));
     CUDA_CHECK(cudaMemcpy(host_temp.mutable_data(), dev_tensor, sizeof(float) * size,
@@ -55,6 +69,66 @@ static void record_dev_tensorfile(const float* dev_tensor, int size, const char*
 
     LOG(INFO) << "!!! write success: " << locate;
 }
+static void record_dev_tensorfile(Tensor <NV, AK_FLOAT, NCHW>* dev_tensor, const char* locate) {
+    Tensor <X86, AK_FLOAT, NCHW> host_temp;
+    int size=dev_tensor->valid_size();
+    host_temp.re_alloc(Shape(1, 1, 1, size));
+    CUDA_CHECK(cudaMemcpy(host_temp.mutable_data(), dev_tensor->data(), sizeof(float) * size,
+                          cudaMemcpyDeviceToHost));
+    cudaDeviceSynchronize();
+    FILE* fp = fopen(locate, "w+");
+
+    if (fp == 0) {
+                LOG(ERROR) << "file open failed " << locate;
+
+    } else {
+        for (int i = 0; i < size; ++i) {
+            fprintf(fp, "[%d] %g \n", i, (host_temp.data()[i]));
+        }
+
+        fclose(fp);
+    }
+
+            LOG(INFO) << "!!! write success: " << locate;
+}
+#endif
+
+#ifdef USE_X86_PLACE
+template<>
+void record_dev_tensorfile<X86>(const float* dev_tensor, int size, const char* locate) {
+    FILE* fp = fopen(locate, "w+");
+
+    if (fp == 0) {
+        LOG(ERROR) << "file open failed " << locate;
+
+    } else {
+        for (int i = 0; i < size; ++i) {
+            fprintf(fp, "[%d] %g \n", i, (dev_tensor[i]));
+        }
+
+        fclose(fp);
+    }
+
+    LOG(INFO) << "!!! write success: " << locate;
+}
+static void record_dev_tensorfile(Tensor <X86, AK_FLOAT, NCHW>* dev_tensor, const char* locate) {
+    int size=dev_tensor->valid_size();
+    FILE* fp = fopen(locate, "w+");
+
+    if (fp == 0) {
+        LOG(ERROR) << "file open failed " << locate;
+
+    } else {
+
+        for (int i = 0; i < size; ++i) {
+            fprintf(fp, "[%d] %g \n", i, (dev_tensor->data()[i]));
+        }
+
+        fclose(fp);
+    }
+
+        LOG(INFO) << "!!! write success: " << locate;
+}
 #endif
 
 #if defined(USE_X86_PLACE) || defined(USE_CUDA)
diff --git a/saber/funcs/deconv.h b/saber/funcs/deconv.h
index de0a1d7..7848080 100644
--- a/saber/funcs/deconv.h
+++ b/saber/funcs/deconv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_deconv.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/arm/saber_deconv.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/deconv_act.h b/saber/funcs/deconv_act.h
index 1790ec2..58a5b5a 100644
--- a/saber/funcs/deconv_act.h
+++ b/saber/funcs/deconv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_deconv_act.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_deconv_act.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/deformable_conv.h b/saber/funcs/deformable_conv.h
index 68169e9..da9e0dc 100644
--- a/saber/funcs/deformable_conv.h
+++ b/saber/funcs/deformable_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -24,7 +24,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_deformable_conv.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_deformable_conv.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/detection_output.h b/saber/funcs/detection_output.h
index 866b71a..db2fc4b 100644
--- a/saber/funcs/detection_output.h
+++ b/saber/funcs/detection_output.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,6 +25,10 @@
 #include "saber/funcs/impl/impl_detection_output.h"
 #endif
 
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_detection_output.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/eltwise.h b/saber/funcs/eltwise.h
index 7d3a486..6ec2d26 100644
--- a/saber/funcs/eltwise.h
+++ b/saber/funcs/eltwise.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_eltwise.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_eltwise.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/eltwise_act.h b/saber/funcs/eltwise_act.h
index d53c267..97ab92c 100644
--- a/saber/funcs/eltwise_act.h
+++ b/saber/funcs/eltwise_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,11 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_eltwise_act.h"
 #endif
-   
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/arm/saber_eltwise_active.h"
+#endif
+
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/embedding.h b/saber/funcs/embedding.h
index 3ad5fdd..99a6507 100644
--- a/saber/funcs/embedding.h
+++ b/saber/funcs/embedding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -28,7 +28,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_embedding.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_embedding.h"
+#endif
 namespace anakin {
 namespace saber {
 
@@ -69,6 +72,7 @@ public:
                                              Output_v &output, Param_t &param) override {
 
         Shape output_shape = {input[0]->valid_size(), param.emb_dim, 1, 1};
+        output[0]->set_seq_offset(input[0]->get_seq_offset());
         return output[0]->set_shape(output_shape);
     }
 
diff --git a/saber/funcs/fc.h b/saber/funcs/fc.h
index 06dc869..02c2663 100644
--- a/saber/funcs/fc.h
+++ b/saber/funcs/fc.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,6 +26,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/vender_fc.h"
 #endif
+
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_fc.h"
+#endif
    
 namespace anakin{
 
@@ -91,6 +95,7 @@ public:
             shape_out[widht_idx] = 1;
         }
         shape_out[channel_idx] = n;
+        output[0]->set_seq_offset(input[0]->get_seq_offset());
         return output[0]->set_shape(shape_out);
     }
 
diff --git a/saber/funcs/flatten.h b/saber/funcs/flatten.h
index 32ecd77..f9199fc 100644
--- a/saber/funcs/flatten.h
+++ b/saber/funcs/flatten.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -78,7 +78,7 @@ public:
     //flatten ops do nothing
     virtual SaberStatus operator()(const Input_v& input, Output_v& output, Param_t& param, \
         Context<TargetType> &ctx) {
-
+        return SaberSuccess;
     }
 
 private:
diff --git a/saber/funcs/funcs_utils.h b/saber/funcs/funcs_utils.h
index 0538ec7..978f6d8 100644
--- a/saber/funcs/funcs_utils.h
+++ b/saber/funcs/funcs_utils.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -217,8 +217,13 @@ void transpose_filter_KCRS_2_CRSK(const Dtype *input, Dtype *output, \
 template < typename Tensor_t, template <typename T> class Param >
 void update_conv_weights(Param<Tensor_t>& param)
 {
+#ifdef USE_ARM_PLACE
+    Tensor<ARM, AK_FLOAT, NCHW> new_weight;
+    Tensor<ARM, AK_FLOAT, NCHW> new_bias;
+#else
     Tensor<X86, AK_FLOAT, NCHW> new_weight;
     Tensor<X86, AK_FLOAT, NCHW> new_bias;
+#endif //USE_ARM_PLACE
     typedef typename Tensor_t::Dtype dtype;
 
     Shape weight_shape = param.conv_param.weight()->shape();
diff --git a/saber/funcs/gru.h b/saber/funcs/gru.h
index 280dc7e..5f0a80d 100644
--- a/saber/funcs/gru.h
+++ b/saber/funcs/gru.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_GRU_H
 #define ANAKIN_SABER_FUNCS_GRU_H
@@ -24,8 +25,12 @@
 
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_gru.h"
+#include "saber/funcs/impl/x86/vender_gru.h"
+#endif
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_gru.h"
 #endif
-
 namespace anakin {
 namespace saber {
 
@@ -90,8 +95,11 @@ public:
 //            } else {
             int seq_sum = input[0]->num();
 //            CHECK_LE(seq_sum, max_seq_sum) << "seq_sum should le than the init shape";
+
             Shape output_shape = Shape(seq_sum, hiddenSize * param.num_direction, 1, 1);
-            return output[0]->set_shape(output_shape);
+            output[0]->set_shape(output_shape);
+            output[0]->set_seq_offset(input[0]->get_seq_offset());
+            return SaberSuccess;
 //            }
 //        }
 //        else {
@@ -112,6 +120,7 @@ public:
         case VENDER_IMPL:
             this->_impl.push_back(new VenderGru <TargetType, OpDtype, inDtype, outDtype,
                                   LayOutType_op, LayOutType_in, LayOutType_out>);
+            LOG(INFO)<<"VENDER_IMPL !!";
             return SaberSuccess;
 
         case SABER_IMPL:
diff --git a/saber/funcs/im2sequence.h b/saber/funcs/im2sequence.h
index b5c94a6..140c8ee 100644
--- a/saber/funcs/im2sequence.h
+++ b/saber/funcs/im2sequence.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_im2sequence.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_im2sequence.h"
+#endif
 namespace anakin {
 namespace saber {
 
@@ -89,7 +92,12 @@ public:
         output_shape[width_idx] = 1;
         output[0]->set_shape(output_shape);
 
-
+        int n=input[0]->num();
+        std::vector<int> offset(n+1);
+        for(int i=0;i<=n;i++){
+            offset.push_back(i*output_height * output_width);
+        }
+        output[0]->set_seq_offset(offset);
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/arm/impl/conv3x3s1_direct.cpp b/saber/funcs/impl/arm/impl/conv3x3s1_direct.cpp
new file mode 100644
index 0000000..a751b52
--- /dev/null
+++ b/saber/funcs/impl/arm/impl/conv3x3s1_direct.cpp
@@ -0,0 +1,2902 @@
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+#ifdef USE_ARM_PLACE
+
+namespace anakin{
+
+namespace saber{
+
+/*
+void conv_3x3s1_direct1(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, \
+    const float* weights, const float* bias, \
+    int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
+    int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space) {
+    //! 3x3s1 convolution, implemented by direct algorithm
+    //! pad is done implicit
+    const float zero[6] = {0.f, 0.f, 0.f, 0.f, 0.f, 0.f};
+    //! for 4x6 convolution window
+    const int right_pad_idx[4] = {3, 2, 1, 0};
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+
+    const float* din = tensor_in.data();
+    float* dout = tensor_out.mutable_data();
+
+    int size_in_channel = w_in * h_in;
+    int size_out_channel = w_out * h_out;
+    int w_stride = ch_in * 9;
+
+    int tile_w = (w_in + 3) >> 2;
+    int tile_h = (h_in + 1) >> 1;
+    int w_in_twice = w_in << 1;
+    int cnt_col = tile_w - 2;
+
+    int size_pad_right = 1 + (tile_w << 2) - w_in;
+    int size_pad_bottom = 1 + (tile_h << 1) - h_in;
+
+    int cremain = ch_out - ((ch_out >> 1) << 1);
+
+    uint32x4_t vmask_rp = vcgeq_s32(vld1q_s32(right_pad_idx), vdupq_n_s32(size_pad_right));
+    unsigned int pmask_rp[4];
+    vst1q_u32(pmask_rp, vmask_rp);
+    int right_pad_sub = (size_pad_right - 1) * sizeof(float);
+
+    for (int n = 0; n < num; ++n) {
+        const float *din_batch = din + n * ch_in * size_in_channel;
+        float *dout_batch = dout + n * ch_in * size_out_channel;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out - 1; c += 2) {
+
+            float* dout_c0 = dout_batch + c * size_out_channel;
+            float* dout_c1 = dout_c0 + size_out_channel;
+
+            if (flag_bias) {
+                fill_bias(dout_c0, &bias[c], 1, size_out_channel);
+                fill_bias(dout_c1, &bias[c + 1], 1, size_out_channel);
+            } else {
+                fill_bias(dout_c0, zero, 1, size_out_channel);
+                fill_bias(dout_c1, zero, 1, size_out_channel);
+            }
+
+            //float* dout_c2 = dout_c1 + size_out_channel;
+            //float* dout_c3 = dout_c2 + size_out_channel;
+
+            const float* wc0 = weights + c * w_stride;
+            const float* wc1 = wc0 + w_stride;
+
+            //const float* wc2 = wc0 + w_stride;
+            //const float* wc3 = wc0 + w_stride;
+
+            for (int i = 0; i < ch_in; ++i) {
+
+                int relu = 0;
+                if ((i == ch_in - 1) && flag_relu) {
+                    relu = 1;
+                }
+
+                const float *din_channel = din_batch + i * size_in_channel;
+
+                const float* wcin0 = wc0 + i * 9;
+                const float* wcin1 = wc1 + i * 9;
+                float32x4_t wr00 = vld1q_f32(wcin0);
+                float32x4_t wr01 = vld1q_f32(wcin0 + 3);
+                float32x4_t wr02 = vld1q_f32(wcin0 + 6);
+
+                float32x4_t wr10 = vld1q_f32(wcin1);
+                float32x4_t wr11 = vld1q_f32(wcin1 + 3);
+                float32x4_t wr12 = vld1q_f32(wcin1 + 6);
+
+                float *doutc0r0 = dout_c0;
+                float *doutc0r1 = doutc0r0 + w_out;
+
+                float *doutc1r0 = dout_c1;
+                float *doutc1r1 = doutc1r0 + w_out;
+
+                const float *dr0 = din_channel;
+                const float *dr1 = dr0 + w_in;
+                const float *dr2 = dr1 + w_in;
+                const float *dr3 = dr2 + w_in;
+
+                const float *din0_ptr = dr0;
+                const float *din1_ptr = dr1;
+                const float *din2_ptr = dr2;
+                const float *din3_ptr = dr3;
+
+                float* ptr_zero = const_cast<float*>(zero);
+
+                //! deal with top pad
+                int h = 0;
+                {
+                    //! process
+                    if (1) {
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+
+                        float tmp1[4];
+                        float* ptr1 = tmp1;
+                        float tmp2[4];
+                        float* ptr2 = tmp2;
+
+                        asm volatile(
+                        //! process left pad
+                        "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tl                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_tl:                              @ store top left result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  start_top_right                   @ jump to main loop start point\n"
+                                "start_top_mid:                         @ main loop start point\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]      @ load din r1\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tm                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_tm:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    start_top_mid                   @ jump to main loop start point\n"
+
+                                //! process right pad
+                                "start_top_right:                       @ right pad entry\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tr                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_tr:                              @ store top mid result\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                "vmvn.32  q12, q15                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q14, q11, q15                     @ bit select\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout1r1\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+
+                                "vbif q8, q10, q15                      @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+
+                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \
+                            [relu] "r"(relu)
+                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                    //! after process, increase pointer
+                    doutc0r0 += w_out;
+                    doutc0r1 = doutc0r0 + w_out;
+                    doutc1r0 += w_out;
+                    doutc1r1 = doutc1r0 + w_out;
+
+                    dr0 = dr1;
+                    dr1 = dr2;
+                    dr2 = dr1 + w_in;
+                    dr3 = dr2 + w_in;
+                } //! end of process top row
+
+
+                //! process mid row
+                for (h = 1; h < tile_h - 1; h++) {
+                    din0_ptr = dr0;
+                    din1_ptr = dr1;
+                    din2_ptr = dr2;
+                    din3_ptr = dr3;
+
+                    {
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                        "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "pld [%[din3_ptr], #192]                @ preload data\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r2\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                //! 4rd row
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!     @ load din r3\n"
+                                "pld [%[din3_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_ml                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_ml:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din3_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  start_mid_right                   @ jump to main loop start point\n"
+                                "start_mid_mid:                         @ main loop start point\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r2\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                //! 4rd row
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!     @ load din r3\n"
+                                "pld [%[din3_ptr], #192]                @ preload data\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_mm                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_mm:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din3_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    start_mid_mid                   @ jump to main loop start point\n"
+
+                                //! process right pad
+                                "start_mid_right:                       @ right pad entry\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!      @ load din r1\n"
+                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]          @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1              @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]          @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]           @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]           @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2              @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]          @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]           @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]           @ mul weight1 02, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r2\n"
+                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]          @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]          @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1              @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]          @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]          @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]           @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]           @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2              @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]          @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]          @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]           @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]           @ mul weight1 12, out1r1\n"
+
+                                //! 4rd row
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]          @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1              @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]          @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]           @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2              @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]          @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]           @ mul weight1 22, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_mr                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_mr:                              @ store top mid result\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                "vmvn.32  q12, q15                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q14, q11, q15                     @ bit select\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout1r1\n"
+
+                                "vbif q8, q10, q15                      @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+
+                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [din3_ptr] "+r"(din3_ptr), \
+                            [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \
+                            [relu] "r"(relu)
+                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                    doutc0r0 += w_out;
+                    doutc0r1 = doutc0r0 + w_out;
+                    doutc1r0 += w_out;
+                    doutc1r1 = doutc1r0 + w_out;
+
+                    dr0 = dr2;
+                    dr1 = dr3;
+                    dr2 = dr1 + w_in;
+                    dr3 = dr2 + w_in;
+                } //! end of processing mid rows
+
+                //! deal with bottom pad
+                if (1) {
+
+                    din0_ptr = dr0;
+                    din1_ptr = dr1;
+                    if (size_pad_bottom == 2) {
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                        "pld [%[doutc0r0]]                              @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+
+                                "vmla.f32 q6, q8, %e[wr00][1]           @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][1]           @ mul weight1 01, out1r0\n"
+
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q8, #3              @ shift right r1\n"
+                                "vmla.f32 q6, q12, %e[wr00][0]          @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                "vmla.f32 q6, q10, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q6, q12, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bl_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_bl_1:                            @ store top mid result\n"
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
+
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  conv3x3_bot_right                 @ jump to main loop start point\n"
+                                "conv3x3_bot_mid:                       @ main loop start point\n"
+
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+
+                                "vmla.f32 q6, q8, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %e[wr00][1]          @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q8, q9, #2               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vmla.f32 q6, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bm_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_bm_1:                            @ store top mid result\n"
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    conv3x3_bot_mid                 @ jump to main loop start point\n"
+
+                                //! process right pad
+                                "conv3x3_bot_right:                     @ right pad entry\n"
+
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+
+                                "vbif d17, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d18, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+
+                                "vmla.f32 q6, q8, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %e[wr00][1]          @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q8, q9, #2               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q6, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_br_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_br_1:                            @ store top mid result\n"
+
+                                "vld1.32  {d16-d17}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r0]]      @ load dout0r0\n"
+
+                                "vmvn.32  q12, q15                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q6, q8, q15                       @ bit select\n"
+                                "vbif q7, q9, q15                       @ bit select\n"
+
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]      @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]      @ store result, add pointer\n"
+                        :[doutc0r0] "+r"(doutc0r0), [doutc1r0] "+r" (doutc1r0),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), \
+                            [vmask_rp] "w" (vmask_rp), [relu] "r"(relu)
+                        :"q6", "q7", "q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+
+                    } else { // write 2 rows
+                        din2_ptr = dr2;
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                        "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bl_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_bl_2:                            @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "add %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+
+                                //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  conv3x3_bot_right_2               @ jump to main loop start point\n"
+                                "conv3x3_bot_mid_2:                     @ main loop start point\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                "pld [%[din0_ptr], #192]                @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                "pld [%[din1_ptr], #192]                @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bm_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_bm_2:                            @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0], #192]                @ preload data\n"
+                                "pld [%[doutc1r0], #192]                @ preload data\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r1], #192]                @ preload data\n"
+                                "pld [%[doutc1r1], #192]                @ preload data\n"
+                                "add %[din2_ptr], #16                   @ point to 4 data ahead\n"
+                                "pld [%[din2_ptr], #192]                @ preload data\n"
+
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    conv3x3_bot_mid_2               @ jump to main loop start point\n"
+
+                                //! process right pad
+                                "conv3x3_bot_right_2:                   @ right pad entry\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                //! 3rd row
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_br_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_br_2:                            @ store top mid result\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r0]]      @ load dout0r1\n"
+
+                                "vmvn.32  q12, q15                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q8, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]      @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]      @ store result, add pointer\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r1]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout0r1\n"
+
+                                "vbif q14, q10, q15                     @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]      @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]      @ store result, add pointer\n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [relu] "r" (relu)
+                        :"q8", "q9", "q10", \
+                            "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                } // end of processing bottom pad
+            } // end of processing channels
+        } //end of processing output channel
+        if (cremain > 0) {
+            for (int c = 0; c < cremain; ++c) {
+
+                int cidx = ch_out - cremain + c;
+                float* dout_c = dout_batch + cidx * size_out_channel;
+
+                if (flag_bias) {
+                    fill_bias(dout_c, &bias[cidx], 1, size_out_channel);
+                } else {
+                    fill_bias(dout_c, zero, 1, size_out_channel);
+                }
+
+                const float* wc0 = weights + cidx * w_stride;
+
+                for (int i = 0; i < ch_in; ++i) {
+
+                    bool relu = (i == ch_in - 1) && flag_relu;
+
+                    const float* din_channel = din_batch + i * size_in_channel;
+                    for (int h = 0; h < h_out; ++h) {
+
+                        int hstart = h - pad_h;
+                        int hend = hstart + 3;
+                        hstart = std::max(hstart, 0);
+                        hend = std::min(hend, h_in);
+
+                        int khstart = hend < kernel_h? kernel_h - hend : 0;
+
+                        float* dout_row = dout_c + h * w_out;
+
+                        for (int w = 0; w < w_out; ++w) {
+                            int wstart = w - pad_w;
+                            int wend = wstart + 3;
+                            wstart = std::max(wstart, 0);
+                            wend = std::min(wend, w_in);
+                            int kwstart = wend < kernel_w? kernel_w - wend : 0;
+
+                            for (int kh = hstart; kh < hend; ++kh) {
+                                for (int kw = wstart; kw < wend; ++kw) {
+                                    dout_row[w] += din_channel[kh * w_in + kw] * \
+                                        wc0[(khstart + kh - hstart) * 3 + kwstart + kw - wstart];
+                                }
+                            }
+                            if (relu) {
+                                dout_row[w] = dout_row[w] > 0.f? dout_row[w] : 0.f;
+                            }
+                        }
+                    }
+                    wc0 += 9;
+                }
+            }
+        } // end of remain out channel
+
+    } // end of processing batchs
+}
+*/
+void conv_3x3s1_direct(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, \
+    const float* weights, const float* bias, \
+    int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
+    int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space) {
+    //! 3x3s1 convolution, implemented by direct algorithm
+    //! pad is done implicit
+    const float zero[6] = {0.f, 0.f, 0.f, 0.f, 0.f, 0.f};
+    //! for 4x6 convolution window
+    const int right_pad_idx[4] = {3, 2, 1, 0};
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+
+    const float* din = tensor_in.data();
+    float* dout = tensor_out.mutable_data();
+
+    int size_in_channel = w_in * h_in;
+    int size_out_channel = w_out * h_out;
+    int w_stride = ch_in * 9;
+
+    int tile_w = (w_in + 3) >> 2;
+    int tile_h = (h_in + 1) >> 1;
+    int w_in_twice = w_in << 1;
+    int cnt_col = tile_w - 2;
+
+    int size_pad_right = 1 + (tile_w << 2) - w_in;
+    int size_pad_bottom = 1 + (tile_h << 1) - h_in;
+
+    int cremain = ch_out - ((ch_out >> 1) << 1);
+
+    uint32x4_t vmask_rp = vcgeq_s32(vld1q_s32(right_pad_idx), vdupq_n_s32(size_pad_right));
+    unsigned int pmask_rp[4];
+    vst1q_u32(pmask_rp, vmask_rp);
+    int right_pad_sub = (size_pad_right - 1) * sizeof(float);
+
+    for (int n = 0; n < num; ++n) {
+        const float *din_batch = din + n * ch_in * size_in_channel;
+        float *dout_batch = dout + n * ch_in * size_out_channel;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out - 1; c += 2) {
+
+            float* dout_c0 = dout_batch + c * size_out_channel;
+            float* dout_c1 = dout_c0 + size_out_channel;
+
+            if (flag_bias) {
+                fill_bias(dout_c0, &bias[c], 1, size_out_channel);
+                fill_bias(dout_c1, &bias[c + 1], 1, size_out_channel);
+            } else {
+                fill_bias(dout_c0, zero, 1, size_out_channel);
+                fill_bias(dout_c1, zero, 1, size_out_channel);
+            }
+
+            //float* dout_c2 = dout_c1 + size_out_channel;
+            //float* dout_c3 = dout_c2 + size_out_channel;
+
+            const float* wc0 = weights + c * w_stride;
+            const float* wc1 = wc0 + w_stride;
+
+            //const float* wc2 = wc0 + w_stride;
+            //const float* wc3 = wc0 + w_stride;
+
+            for (int i = 0; i < ch_in; ++i) {
+
+                const float *din_channel = din_batch + i * size_in_channel;
+
+                const float* wcin0 = wc0 + i * 9;
+                const float* wcin1 = wc1 + i * 9;
+                float32x4_t wr00 = vld1q_f32(wcin0);
+                float32x4_t wr01 = vld1q_f32(wcin0 + 3);
+                float32x4_t wr02 = vld1q_f32(wcin0 + 6);
+
+                float32x4_t wr10 = vld1q_f32(wcin1);
+                float32x4_t wr11 = vld1q_f32(wcin1 + 3);
+                float32x4_t wr12 = vld1q_f32(wcin1 + 6);
+
+                float *doutc0r0 = dout_c0;
+                float *doutc0r1 = doutc0r0 + w_out;
+
+                float *doutc1r0 = dout_c1;
+                float *doutc1r1 = doutc1r0 + w_out;
+
+                const float *dr0 = din_channel;
+                const float *dr1 = dr0 + w_in;
+                const float *dr2 = dr1 + w_in;
+                const float *dr3 = dr2 + w_in;
+
+                const float *din0_ptr = dr0;
+                const float *din1_ptr = dr1;
+                const float *din2_ptr = dr2;
+                const float *din3_ptr = dr3;
+
+                float* ptr_zero = const_cast<float*>(zero);
+                float32x4_t vzero = vdupq_n_f32(0.f);
+
+                //! deal with top pad
+                int h = 0;
+                {
+                    //! process
+                    if (1) {
+#ifdef __aarch64__
+                        // todo
+                        int cnt = cnt_col;
+
+                        //float tmp1[4];
+                        //float* ptr1 = tmp1;
+                        //float tmp2[4];
+                        //float* ptr2 = tmp2;
+
+                        asm volatile(
+                        //! process left pad
+                                "prfm     pldl1keep, [%[doutc0r0]]          @ preload data\n"
+                                "prfm     pldl1keep, [%[din0_ptr]]          @ preload data\n"
+                                "prfm     pldl1keep, [%[doutc0r1]]          @ preload data\n"
+                                "prfm     pldl1keep, [%[doutc1r0]]          @ preload data\n"
+                                "prfm     pldl1keep, [%[doutc1r1]]          @ preload data\n"
+                                "ld1      {v13.4s}, [%[doutc0r0]]           @ load dout0r0\n"
+
+                                //! 1st row
+                                "ld1 {v10.4s, v11.2s}, [%[din0_ptr]]!   @ load dout0r0\n"
+                                "ld1 {v14.4s}, [%[doutc0r1]]            @ load dout0r0\n"
+                                "ld1 {v8.4s}, [%[doutc1r0]]             @ load dout0r0\n"
+                                "ld1 {v9.4s}, [%[doutc1r1]]             @ load dout0r0\n"
+
+                                "prfm     pldl1keep, [%[din1_ptr]]      @ preload data\n"
+                                "prfm     pldl1keep, [%[din2_ptr]]      @ preload data\n"
+
+                               // "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "ext v12.16b, v10.16b, v11.16b, #4      @ shift left r1\n"
+                              //  "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "fmla v13.4s, v10.4s, %v[wr01].s[1]     @ mul weight0 11, out0r0\n"
+                                "fmla v14.4s, v10.4s, %v[wr00].s[1]     @ mul weight0 01, out0r1\n"
+                                "fmla v8.4s, v10.4s, %v[wr11].s[1]     @ mul weight1 11, out1r0\n"
+                                "fmla v9.4s, v10.4s, %v[wr10].s[1]     @ mul weight1 01, out1r1\n"
+
+                                //"vmov.u32 q15, #0                       @ dump zero\n"
+                               // "vext.32  q15, %q[vzero], q10, #3         @ shift right r1\n"
+                                "ext v15.16b, %v[vzero].16b, v10.16b, #12      @ shift right r1\n"
+                                "fmla v13.4s, v12.4s, %v[wr01].s[0]     @ mul weight0 12, out0r0\n"
+                                "fmla v14.4s, v12.4s, %v[wr00].s[0]     @ mul weight0 02, out0r1\n"
+                                "fmla v8.4s, v12.4s, %v[wr11].s[0]     @ mul weight1 12, out1r0\n"
+                                "fmla v9.4s, v12.4s, %v[wr10].s[0]     @ mul weight1 02, out1r1\n"
+
+                               // "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+                                "ld1 {v10.4s, v11.2s}, [%[din1_ptr]]!   @ load din r2\n"
+
+                                "vmla.f32 q13, q15, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr10][0]          @ mul weight1 00, out1r1\n" 
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+
+                                //! 2nd row
+                                //"pld [%[din1_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+
+                                "vmla.f32 q13, q15, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                //! 3rd row
+                               // "pld [%[din2_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r3\n"
+                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+                                
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "pld [%[din2_ptr]]                      @ preload data\n"
+                                "vmla.f32 q14, q15, %e[wr02][0]            @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q15, %e[wr12][0]            @ mul weight1 20, out1r1\n"
+
+                                //"sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                               // "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                //"sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                            //stroe result
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n" 
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                
+                                "pld [%[doutc0r0]]                     @ preload data\n"
+                                "pld [%[doutc0r1]]                     @ preload data\n"
+                                "pld [%[doutc1r0]]                     @ preload data\n"
+                                "pld [%[doutc1r1]]                     @ preload data\n"
+                            
+                            //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  start_top_right                   @ jump to main loop start point\n"
+                                "start_top_mid:                         @ main loop start point\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                //! 1st row
+                               // "pld [%[din0_ptr]]                       @ preload data\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                               // "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                               //  "pld [%[din0_ptr]]                     @ preload data\n"
+                                 "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                               // "pld [%[din1_ptr]]                       @ preload data\n"
+                                "sub %[din2_ptr], #8                      @ 2 float data overlap with previous data\n"
+
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                               
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+                                "pld [%[din0_ptr]]                       @ preload data\n"
+                                "pld [%[din1_ptr]]                       @ preload data\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+
+                                "pld [%[din2_ptr]]                       @ preload data\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "pld [%[doutc0r0]]                @ preload data\n"
+                                "pld [%[doutc0r1]]                @ preload data\n"
+
+                                "pld [%[doutc1r0]]                @ preload data\n"
+                                "pld [%[doutc1r1]]                @ preload data\n"
+
+                              // "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                               // "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                               // "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    start_top_mid                   @ jump to main loop start point\n"
+
+                            //! process right pad
+                                "start_top_right:                       @ right pad entry\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                //! 1st row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                               
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
+
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+
+                                "vmvn.32  q12, %q[vzero]                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                      @ bit select\n"
+                                "vbif q14, q11, q15                      @ bit select\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+
+                                "vbif q8, q10, q15                      @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                
+                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \ 
+                            [vzero] "w" (vzero)
+                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+                       
+#else
+                        int cnt = cnt_col;
+
+                        //float tmp1[4];
+                        //float* ptr1 = tmp1;
+                        //float tmp2[4];
+                        //float* ptr2 = tmp2;
+
+                        asm volatile(
+                        //! process left pad
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[doutc0r1]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+                                "pld [%[doutc1r1]]                      @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "pld [%[din2_ptr]]                      @ preload data\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10,  %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10,  %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                //"vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q15, %q[vzero], q10, #3         @ shift right r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+
+                                "vmla.f32 q13, q15, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr10][0]          @ mul weight1 00, out1r1\n" 
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+
+                                //! 2nd row
+                                //"pld [%[din1_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+
+                                "vmla.f32 q13, q15, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                //! 3rd row
+                               // "pld [%[din2_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r3\n"
+                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
+                                
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "pld [%[din2_ptr]]                      @ preload data\n"
+                                "vmla.f32 q14, q15, %e[wr02][0]            @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q15, %e[wr12][0]            @ mul weight1 20, out1r1\n"
+
+                                //"sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                               // "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                //"sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                            //stroe result
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n" 
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                
+                                "pld [%[doutc0r0]]                     @ preload data\n"
+                                "pld [%[doutc0r1]]                     @ preload data\n"
+                                "pld [%[doutc1r0]]                     @ preload data\n"
+                                "pld [%[doutc1r1]]                     @ preload data\n"
+                            
+                            //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  start_top_right                   @ jump to main loop start point\n"
+                                "start_top_mid:                         @ main loop start point\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                //! 1st row
+                               // "pld [%[din0_ptr]]                       @ preload data\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                               // "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                               //  "pld [%[din0_ptr]]                     @ preload data\n"
+                                 "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                               // "pld [%[din1_ptr]]                       @ preload data\n"
+                                "sub %[din2_ptr], #8                      @ 2 float data overlap with previous data\n"
+
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                               
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+                                "pld [%[din0_ptr]]                       @ preload data\n"
+                                "pld [%[din1_ptr]]                       @ preload data\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+
+                                "pld [%[din2_ptr]]                       @ preload data\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "pld [%[doutc0r0]]                @ preload data\n"
+                                "pld [%[doutc0r1]]                @ preload data\n"
+
+                                "pld [%[doutc1r0]]                @ preload data\n"
+                                "pld [%[doutc1r1]]                @ preload data\n"
+
+                              // "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                               // "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                               // "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    start_top_mid                   @ jump to main loop start point\n"
+
+                            //! process right pad
+                                "start_top_right:                       @ right pad entry\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                //! 1st row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                //! 2nd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+                                //! 3rd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                               
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
+
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+
+                                "vmvn.32  q12, %q[vzero]                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                      @ bit select\n"
+                                "vbif q14, q11, q15                      @ bit select\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+
+                                "vbif q8, q10, q15                      @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
+
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                
+                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \ 
+                            [vzero] "w" (vzero)
+                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                    //! after process, increase pointer
+                    doutc0r0 += w_out;
+                    doutc0r1 = doutc0r0 + w_out;
+                    doutc1r0 += w_out;
+                    doutc1r1 = doutc1r0 + w_out;
+
+                    dr0 = dr1;
+                    dr1 = dr2;
+                    dr2 = dr1 + w_in;
+                    dr3 = dr2 + w_in;
+                } //! end of process top row
+
+
+                //! process mid row
+                for (h = 1; h < tile_h - 1; h++) {
+                    din0_ptr = dr0;
+                    din1_ptr = dr1;
+                    din2_ptr = dr2;
+                    din3_ptr = dr3;
+
+                    {
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[doutc0r1]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+                                "pld [%[doutc1r1]]                      @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "pld [%[din2_ptr]]                      @ preload data\n"
+
+                                //! 1st row
+                               // "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r1\n"
+                                "vmla.f32 q13, q10, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+
+
+                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
+
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                "vmla.f32 q13, q15, %e[wr00][0]            @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q15, %e[wr10][0]            @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                //"pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3          @ shift right r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q13, q15, %e[wr01][0]            @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr00][0]            @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr11][0]            @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr10][0]            @ mul weight1 00, out1r1\n"
+
+                                //! 3rd row
+                                //"pld [%[din2_ptr], #192]                @ preload data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q13, q15, %e[wr02][0]            @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q15, %e[wr01][0]            @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q15, %e[wr12][0]            @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q15, %e[wr11][0]            @ mul weight1 10, out1r1\n"
+
+                                //! 4rd row
+                                //"pld [%[din3_ptr], #192]                @ preload data\n"
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]           @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]           @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3       @ shift right r3\n"
+                                "pld [%[din2_ptr]]                      @ preload data\n"
+                                "sub %[din3_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                
+                                "pld [%[din3_ptr]]                      @ preload data\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                
+
+                                "vmla.f32 q14, q15, %e[wr02][0]            @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q15, %e[wr12][0]            @ mul weight1 20, out1r1\n"
+
+                                
+                                "pld [%[doutc0r0]]                     @ preload data\n"
+                                "pld [%[doutc1r0]]                     @ preload data\n"
+                                
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "pld [%[doutc0r1]]                     @ preload data\n"
+                                "pld [%[doutc1r1]]                     @ preload data\n"
+
+                            //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  start_mid_right                   @ jump to main loop start point\n"
+                                "start_mid_mid:                         @ main loop start point\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                //! 1st row
+                               // "pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                
+                                "vext.32  q15, q10, q11, #2               @ shift left r0\n"
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+ 
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vmla.f32 q13, q15, %f[wr00][0]            @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "pld [%[din1_ptr]]                        @ preload data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+
+                                //! 3rd row
+                                "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift right r2\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+
+                                //! 4rd row
+                                "pld [%[din2_ptr]]                        @ preload data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+
+                                "sub %[din3_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+                                 
+                                "pld [%[din3_ptr]]                        @ preload data\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+
+                                
+                                "pld [%[doutc0r0]]                @ preload data\n"
+                                "pld [%[doutc1r0]]                @ preload data\n"
+                                
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "pld [%[doutc0r1]]                @ preload data\n"
+                                "pld [%[doutc1r1]]                @ preload data\n"
+
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    start_mid_mid                   @ jump to main loop start point\n"
+
+                            //! process right pad
+                                "start_mid_right:                       @ right pad entry\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                //! 1st row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vmla.f32 q13, q15, %f[wr00][0]            @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+
+                                //! 3rd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift right r2\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+
+                                //! 4rd row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r0]]       @ load dout1r0\n"
+                                
+                                "vmla.f32 q14, q15, %f[wr02][0]            @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                
+
+                                "vmvn.32  q12, %q[vzero]                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                      @ bit select\n"
+                                "vbif q8, q11, q15                      @ bit select\n"
+                                
+                                "vld1.32  {d20-d21}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
+                                "vbif q14, q10, q15                      @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
+
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+              
+                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
+                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [din3_ptr] "+r"(din3_ptr), \
+                            [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \ 
+                            [vzero] "w" (vzero)
+                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                    doutc0r0 += w_out;
+                    doutc0r1 = doutc0r0 + w_out;
+                    doutc1r0 += w_out;
+                    doutc1r1 = doutc1r0 + w_out;
+
+                    dr0 = dr2;
+                    dr1 = dr3;
+                    dr2 = dr1 + w_in;
+                    dr3 = dr2 + w_in;
+                } //! end of processing mid rows
+
+                //! deal with bottom pad
+                if (1) {
+
+                    din0_ptr = dr0;
+                    din1_ptr = dr1;
+                    if (size_pad_bottom == 2) {
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+
+                                //! 1st row
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+                                "vmla.f32 q6, q8, %e[wr00][1]           @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][1]           @ mul weight1 01, out1r0\n"
+
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                //"pld [%[din0_ptr]]                      @ preload data\n"
+                                "vext.32  q15, %q[vzero], q8, #3              @ shift right r1\n"
+
+                                "vmla.f32 q6, q12, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+                                
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "vmla.f32 q6, q15, %e[wr00][0]          @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q15, %e[wr10][0]          @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q10, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3             @ shift right r1\n"
+                                "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "vmla.f32 q6, q15, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q15, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+
+                            //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  conv3x3_bot_right                 @ jump to main loop start point\n"
+                                "conv3x3_bot_mid:                       @ main loop start point\n"
+                                     
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                //"sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                //! 1st row
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+                                "vmla.f32 q6, q8, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q15, q8, q9, #2               @ shift left r0\n"
+                                "pld [%[din0_ptr]]                      @ preload data\n"
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                "vmla.f32 q6, q12, %e[wr00][1]          @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "pld [%[din1_ptr]]                      @ preload data\n"
+                                "vmla.f32 q6, q15, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q15, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "vmla.f32 q6, q15, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q15, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    conv3x3_bot_mid                 @ jump to main loop start point\n"
+
+                            //! process right pad
+                                "conv3x3_bot_right:                     @ right pad entry\n"
+
+                                "vld1.32  {d16-d18}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vld1.32  {d12-d13}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d14-d15}, [%[doutc1r0]]      @ load dout1r0\n"
+
+                                //! 1st row
+                                "vbif d17, %e[vzero], %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d18, %e[vzero], %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vext.32  q12, q8, q9, #1               @ shift left r0\n"
+
+                                "vmla.f32 q6, q8, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q7, q8, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q15, q8, q9, #2               @ shift left r0\n"
+                                "vmla.f32 q6, q12, %e[wr00][1]          @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
+
+                                "vbif d21, %e[vzero], %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q6, q15, %f[wr00][0]          @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q7, q15, %f[wr10][0]          @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q6, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q7, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q6, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q7, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+
+                                "vld1.32  {d16-d17}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r0]]      @ load dout0r0\n"
+                                "vmla.f32 q6, q15, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q7, q15, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+
+                                "vmvn.32  q12, %q[vzero]                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q6, q8, q15                       @ bit select\n"
+                                "vbif q7, q9, q15                       @ bit select\n"
+
+                                "vst1.32  {d12-d13}, [%[doutc0r0]]      @ store result, add pointer\n"
+                                "vst1.32  {d14-d15}, [%[doutc1r0]]      @ store result, add pointer\n"
+                        :[doutc0r0] "+r"(doutc0r0), [doutc1r0] "+r" (doutc1r0),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), \
+                            [vmask_rp] "w" (vmask_rp), [vzero] "w" (vzero)
+                        :"q6", "q7", "q8", "q9", "q10", "q11", "q12", "q13", "q15"
+                        );
+#endif //__aarch64__
+
+                    } else { // write 2 rows
+                        din2_ptr = dr2;
+#ifdef __aarch64__
+                        // todo
+#else
+                        int cnt = cnt_col;
+                        asm volatile (
+                        //! process left pad
+                                "pld [%[doutc0r0]]                     @ preload data\n"
+                                "pld [%[din0_ptr]]                       @ preload data\n"
+                                "pld [%[doutc1r0]]                     @ preload data\n"
+                                "pld [%[doutc0r1]]                     @ preload data\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "pld [%[doutc1r1]]                      @ preload data\n"
+                                "pld [%[din1_ptr]]                       @ preload data\n"
+                                "pld [%[din2_ptr]]                       @ preload data\n"
+
+                                //! 1st row
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][1]           @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][1]           @ mul weight1 01, out1r0\n"
+
+                                //"pld [%[din0_ptr], #192]                @ preload data\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r1\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
+
+                              //  "vmov.u32 q15, #0                         @ dump zero\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "pld [%[din0_ptr]]                        @ preload data\n"
+                                "vmla.f32 q13, q15, %e[wr00][0]            @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q15, %e[wr10][0]            @ mul weight1 00, out1r0\n"
+
+                                //! 2nd row
+                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
+
+                               // "pld [%[din1_ptr], #192]                @ preload data\n"
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r1\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
+                                "vmla.f32 q14, q15, %e[wr00][0]            @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q9, q15, %e[wr10][0]            @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q15, %e[wr01][0]            @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q8, q15, %e[wr11][0]            @ mul weight1 10, out1r0\n"
+
+                                //! 3rd row
+                                "add %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
+
+                                "vext.32  q15, %q[vzero], q10, #3               @ shift right r2\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+
+                                "pld [%[din1_ptr]]                         @ preload data\n"
+                                "vmla.f32 q14, q15, %e[wr01][0]            @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q9, q15, %e[wr11][0]            @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q15, %e[wr02][0]            @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q8, q15, %e[wr12][0]            @ mul weight1 20, out1r0\n"
+                                "pld [%[din2_ptr]]                         @ preload data\n"
+
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "pld [%[doutc0r1]]                      @ preload data\n"
+                                "pld [%[doutc1r1]]                      @ preload data\n"
+                                "pld [%[doutc0r0]]                      @ preload data\n"
+                                "pld [%[doutc1r0]]                      @ preload data\n"
+
+                                //"sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                //"sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
+                                //"add %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
+
+                            //! process mid cols
+                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
+                                "blt  conv3x3_bot_right_2                   @ jump to main loop start point\n"
+                                "conv3x3_bot_mid_2:                         @ main loop start point\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                //! 1st row
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "pld [%[din0_ptr]]                        @ preload data\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vmla.f32 q13, q15, %f[wr00][0]            @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+
+                               // "pld [%[din1_ptr], #192]                @ preload data\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+
+                                //! 3rd row
+                                "add %[din2_ptr], #16                    @ 2 float data overlap with previous data\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "pld [%[din1_ptr]]                        @ preload data\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "pld [%[din2_ptr]]                        @ preload data\n"
+   
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+
+                                "pld [%[doutc0r1]]                      @ preload data\n"
+                                "pld [%[doutc1r1]]                     @ preload data\n"
+                                "pld [%[doutc0r0]]                     @ preload data\n"
+                                "pld [%[doutc1r0]]                     @ preload data\n"
+
+                               // "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                               // "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
+
+                                //"add %[din2_ptr], #16                   @ point to 4 data ahead\n"
+
+                                "subs %[cnt], #1                        @ loop count minus 1\n"
+                                "bne    conv3x3_bot_mid_2                   @ jump to main loop start point\n"
+
+                            //! process right pad
+                                "conv3x3_bot_right_2:                       @ right pad entry\n"
+
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
+
+                                //! 1st row
+                                "vbif d21, %e[vzero], %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, %e[vzero], %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r0\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+
+                                "vmla.f32 q13, q15, %f[wr00][0]            @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q15, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+
+                                //! 2nd row
+                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
+                                "vmla.f32 q13, q15, %f[wr01][0]            @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr00][0]            @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr11][0]            @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+
+                                //! 3rd row
+                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
+                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q15, q10, q11, #2               @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r0]]       @ load dout0r1\n"
+                                "vmla.f32 q13, q15, %f[wr02][0]            @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q15, %f[wr01][0]            @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q15, %f[wr12][0]            @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q15, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+
+
+                                "vmvn.32  q12, %q[vzero]                      @ \n"
+                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q8, q11, q15                      @ bit select\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r1]]       @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout0r1\n"
+
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]      @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]      @ store result, add pointer\n"
+
+                                "vbif q14, q10, q15                     @ bit select\n"
+                                "vbif q9, q11, q15                      @ bit select\n"
+
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]      @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]      @ store result, add pointer\n"
+
+                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
+                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
+                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
+                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
+                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
+                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
+                            [vmask_rp] "w" (vmask_rp), [vzero] "w" (vzero)
+                        :"q8", "q9", "q10", \
+                            "q11", "q12", "q13", "q14", "q15"
+                        );
+#endif //__aarch64__
+                    }
+                } // end of processing bottom pad
+            } // end of processing channels
+        } //end of processing output channel
+        if (cremain > 0) {
+            for (int c = 0; c < cremain; ++c) {
+
+                int cidx = ch_out - cremain + c;
+                float* dout_c = dout_batch + cidx * size_out_channel;
+
+                if (flag_bias) {
+                    fill_bias(dout_c, &bias[cidx], 1, size_out_channel);
+                } else {
+                    fill_bias(dout_c, zero, 1, size_out_channel);
+                }
+
+                const float* wc0 = weights + cidx * w_stride;
+
+                for (int i = 0; i < ch_in; ++i) {
+                    const float* din_channel = din_batch + i * size_in_channel;
+                    for (int h = 0; h < h_out; ++h) {
+
+                        int hstart = h - pad_h;
+                        int hend = hstart + 3;
+                        hstart = std::max(hstart, 0);
+                        hend = std::min(hend, h_in);
+
+                        int khstart = hend < kernel_h? kernel_h - hend : 0;
+
+                        float* dout_row = dout_c + h * w_out;
+
+                        for (int w = 0; w < w_out; ++w) {
+                            int wstart = w - pad_w;
+                            int wend = wstart + 3;
+                            wstart = std::max(wstart, 0);
+                            wend = std::min(wend, w_in);
+                            int kwstart = wend < kernel_w? kernel_w - wend : 0;
+
+                            for (int kh = hstart; kh < hend; ++kh) {
+                                for (int kw = wstart; kw < wend; ++kw) {
+                                    dout_row[w] += din_channel[kh * w_in + kw] * \
+                                        wc0[(khstart + kh - hstart) * 3 + kwstart + kw - wstart];
+                                }
+                            }
+                        }
+                    }
+                    wc0 += 9;
+                }
+            }
+        } // end of remain out channel
+
+    } // end of processing batchs
+}
+
+} //namespace saber
+
+} //namespace anakin
+
+#endif
\ No newline at end of file
diff --git a/saber/funcs/impl/arm/impl/conv_arm_7x7s1.cpp b/saber/funcs/impl/arm/impl/conv_arm_7x7s1.cpp
new file mode 100644
index 0000000..9e33b7c
--- /dev/null
+++ b/saber/funcs/impl/arm/impl/conv_arm_7x7s1.cpp
@@ -0,0 +1,3311 @@
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+#ifdef USE_ARM_PLACE
+#include "saber/core/tensor_op.h"
+#if __ARM_NEON
+#include <arm_neon.h>
+#endif // __ARM_NEON
+
+namespace anakin{
+
+namespace saber{
+
+void conv7x7_mid_top2(const float* din, float* dout, int w_out, int width, int height, const float* weight_ch_in){
+    float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+    float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+    vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+
+    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+
+    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+
+    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+
+    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+
+    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+    for (int i = 0; i < height; i++){
+        const float* inptr_ch0 = din + i * width;
+        const float* inptr_ch1 = inptr_ch0 + width;
+        const float* inptr_ch2 = inptr_ch1 + width;
+        const float* inptr_ch3 = inptr_ch2 + width;
+        const float* inptr_ch4 = inptr_ch3 + width;
+        const float* inptr_ch5 = inptr_ch4 + width;
+        const float* wei_ptr = weight_ch_in + 7;//1
+        float* outptr = dout + 3;
+        int cnt = (width - 6) / 4;
+        int remain = (width - 6) - cnt * 4;
+        //printf("din: %x, inptr_ch0: %x, inptr_ch1: %x, weight_ch_in: %x \n", din, inptr_ch0, inptr_ch1, weight_ch_in);
+#ifdef __arrch64__
+        for(; cnt > 0; cnt --){
+            //0
+            float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+            float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+            float32x4_t vdin02 = vld1q_f32(inptr_ch0 + 8);
+            float32x4_t vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            float32x4_t vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            float32x4_t vdin03456 = vextq_f32(vdin00, vdin01, 3);
+            //printf("vdin00: %.2f, vdin01234: %.2f\n", vgetq_lane_f32(vdin00, 0), vgetq_lane_f32(vdin01234, 0));
+
+            float32x4_t vsum0 = vmulq_f32(vdin00, vweights10);
+            float32x4_t vsum1 = vmulq_f32(vdin01234, vweights10);
+            float32x4_t vsum2 = vmulq_f32(vdin02345, vweights10);
+            float32x4_t vsum3 = vmulq_f32(vdin03456, vweights10);
+
+            float32x4_t vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            float32x4_t vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            float32x4_t vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights11);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights11);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights11);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights11);
+
+            //1
+            vdin00 = vld1q_f32(inptr_ch1);
+            vdin01 = vld1q_f32(inptr_ch1 + 4);
+            vdin02 = vld1q_f32(inptr_ch1 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights20);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights20);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights20);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights20);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights21);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights21);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights21);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights21);
+
+            //2
+            vdin00 = vld1q_f32(inptr_ch2);
+            vdin01 = vld1q_f32(inptr_ch2 + 4);
+            vdin02 = vld1q_f32(inptr_ch2 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights30);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights30);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights30);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights30);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights31);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights31);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights31);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights31);
+
+            //3
+            vdin00 = vld1q_f32(inptr_ch3);
+            vdin01 = vld1q_f32(inptr_ch3 + 4);
+            vdin02 = vld1q_f32(inptr_ch3 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights40);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights40);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights40);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights40);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights41);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights41);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights41);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights41);
+
+            //4
+            vdin00 = vld1q_f32(inptr_ch4);
+            vdin01 = vld1q_f32(inptr_ch4 + 4);
+            vdin02 = vld1q_f32(inptr_ch4 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights50);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights50);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights50);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights50);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights51);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights51);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights51);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights51);
+
+            //5
+            vdin00 = vld1q_f32(inptr_ch5);
+            vdin01 = vld1q_f32(inptr_ch5 + 4);
+            vdin02 = vld1q_f32(inptr_ch5 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights60);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights60);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights60);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights60);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights61);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights61);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights61);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights61);
+
+            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum0), vget_high_f32(vsum0));
+            vtotal = vpadd_f32(vtotal, vtotal);
+            float32x2_t vtotal1 = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));
+            vtotal1 = vpadd_f32(vtotal1, vtotal1);
+            float32x2_t vtotal2 = vpadd_f32(vget_low_f32(vsum2), vget_high_f32(vsum2));
+            vtotal2 = vpadd_f32(vtotal2, vtotal2);
+            float32x2_t vtotal3 = vpadd_f32(vget_low_f32(vsum3), vget_high_f32(vsum3));
+            vtotal3 = vpadd_f32(vtotal3, vtotal3);
+
+            float32x4_t vsum = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal1, 0), vsum, 1);
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal2, 0), vsum, 2);
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal3, 0), vsum, 3);
+            float32x4_t vdataout = vld1q_f32(outptr);
+            vdataout = vaddq_f32(vdataout, vsum);
+            vst1q_f32(outptr, vdataout);
+            outptr += 4;
+            inptr_ch0 += 4;
+            inptr_ch1 += 4;
+            inptr_ch2 += 4;
+            inptr_ch3 += 4;
+            inptr_ch4 += 4;
+            inptr_ch5 += 4;
+            inptr_ch6 += 4;
+        }
+#else
+        asm volatile(
+            "cmp      %[cnt], #0                                    @ cnt > 0 \n"
+            "ble       exit_top2                                    @ exit \n"
+            "loop_top2:                                             @ loop \n"
+            //0.0
+            "vld1.f32 {d0-d1}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch0]]!                    @ load data \n"
+            "vld1.f32 {d14-d15}, [%[outptr]]                        @ load out \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmul.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmul.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmul.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //0.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch0], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch1]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch1]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            
+            //1.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch1]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //1.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch1], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch2]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch2]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //2.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch2]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //2.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch2], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch3]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch3]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //3.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch3]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //3.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch3], #32                              @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch4]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch4]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //4.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch4]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //4.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch4], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch5]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch5]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //5.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch5]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //5.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch5], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            "sub      %[wei_ptr], #172                              @ sub wei_ptr - 4 \n"
+            "vadd.f32 q5, q10, q7                                  @ add \n"
+            "vadd.f32 q6, q9, q8                                  @ add \n"
+            "subs     %[cnt], #1                                   @ subs \n"
+            "vadd.f32 q4, q5, q6                                  @ add \n"
+            "vst1.f32 {d8-d9}, [%[outptr]]!                       @ stroe \n"
+            "bne loop_top2                                        @ loop \n"
+            "exit_top2:                                           @ exit \n"
+            :[cnt] "+r" (cnt), [wei_ptr] "+r" (wei_ptr), [outptr] "+r" (outptr), \
+            [inptr_ch0] "+r" (inptr_ch0), [inptr_ch1] "+r" (inptr_ch1), \
+            [inptr_ch2] "+r" (inptr_ch2), [inptr_ch3] "+r" (inptr_ch3), \
+            [inptr_ch4] "+r" (inptr_ch4), [inptr_ch5] "+r" (inptr_ch5)
+            :
+            :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9", "q10"
+        );
+      // printf("inptr_ch0: %x, inptr_ch1: %x, weight_ch_in: %x, cnt: %d \n", inptr_ch0, inptr_ch1, wei_ptr, cnt);
+#endif
+        for (; remain > 0; remain--){
+            float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+            float32x4_t vdin10 = vld1q_f32(inptr_ch1);
+            float32x4_t vdin20 = vld1q_f32(inptr_ch2);
+            float32x4_t vdin30 = vld1q_f32(inptr_ch3);
+            float32x4_t vdin40 = vld1q_f32(inptr_ch4);
+            float32x4_t vdin50 = vld1q_f32(inptr_ch5);
+            float32x4_t vsum = vmulq_f32(vdin00, vweights10);
+            vsum = vmlaq_f32(vsum, vdin10, vweights20);
+            vsum = vmlaq_f32(vsum, vdin20, vweights30);
+            vsum = vmlaq_f32(vsum, vdin30, vweights40);
+            vsum = vmlaq_f32(vsum, vdin40, vweights50);
+            vsum = vmlaq_f32(vsum, vdin50, vweights60);
+            float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+            float32x4_t vdin11 = vld1q_f32(inptr_ch1 + 4);
+            float32x4_t vdin21 = vld1q_f32(inptr_ch2 + 4);
+            float32x4_t vdin31 = vld1q_f32(inptr_ch3 + 4);
+            float32x4_t vdin41 = vld1q_f32(inptr_ch4 + 4);
+            float32x4_t vdin51 = vld1q_f32(inptr_ch5 + 4);
+            vsum = vmlaq_f32(vsum, vdin01, vweights11);
+            vsum = vmlaq_f32(vsum, vdin11, vweights21);
+            vsum = vmlaq_f32(vsum, vdin21, vweights31);
+            vsum = vmlaq_f32(vsum, vdin31, vweights41);
+            vsum = vmlaq_f32(vsum, vdin41, vweights51);
+            vsum = vmlaq_f32(vsum, vdin51, vweights61);
+            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+            vtotal = vpadd_f32(vtotal, vtotal);
+            float32x2_t vdataout = vld1_f32(outptr);
+            vtotal = vset_lane_f32(0.f, vtotal, 1);
+            vdataout = vadd_f32(vdataout, vtotal);
+            vst1_f32(outptr, vdataout);
+            outptr++;
+            inptr_ch0++;
+            inptr_ch1++;
+            inptr_ch2++;
+            inptr_ch3++;
+            inptr_ch4++;
+            inptr_ch5++;
+        }
+    }
+}
+
+void conv7x7_mid_top1(const float* din, float* dout, int w_out, int width, int height, const float* weight_ch_in){
+    
+    const float* inptr_ch0 = din;
+    const float* inptr_ch1 = inptr_ch0 + width;
+    const float* inptr_ch2 = inptr_ch1 + width;
+    const float* inptr_ch3 = inptr_ch2 + width;
+    const float* inptr_ch4 = inptr_ch3 + width;
+    const float* wei_ptr = weight_ch_in + 14;//2
+    float* outptr = dout + 3;
+    int cnt = (width - 6) / 4;
+    int remain = (width - 6) - cnt * 4;
+    asm volatile(
+            "cmp      %[cnt], #0                                    @ cnt > 0 \n"
+            "ble       exit_top1                                    @ exit \n"
+            "loop_top1:                                             @ loop \n"
+            //0.0
+            "vld1.f32 {d0-d1}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch0]]!                    @ load data \n"
+            "vld1.f32 {d14-d15}, [%[outptr]]                        @ load out \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmul.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmul.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmul.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //0.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch0], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch1]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch1]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            
+            //1.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch1]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //1.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch1], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch2]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch2]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //2.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch2]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //2.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch2], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch3]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch3]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //3.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch3]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //3.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch3], #32                              @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch4]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch4]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //4.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch4]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //4.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch4], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            "sub      %[wei_ptr], #144                              @ sub wei_ptr - 4 \n"
+            "vadd.f32 q5, q10, q7                                  @ add \n"
+            "vadd.f32 q6, q9, q8                                  @ add \n"
+            "subs     %[cnt], #1                                   @ subs \n"
+            "vadd.f32 q4, q5, q6                                  @ add \n"
+            "vst1.f32 {d8-d9}, [%[outptr]]!                       @ stroe \n"
+            "bne loop_top1                                        @ loop \n"
+            "exit_top1:                                           @ exit \n"
+            :[cnt] "+r" (cnt), [wei_ptr] "+r" (wei_ptr), [outptr] "+r" (outptr), \
+            [inptr_ch0] "+r" (inptr_ch0), [inptr_ch1] "+r" (inptr_ch1), \
+            [inptr_ch2] "+r" (inptr_ch2), [inptr_ch3] "+r" (inptr_ch3), \
+            [inptr_ch4] "+r" (inptr_ch4)
+            :
+            :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9", "q10"
+    );
+
+    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+
+    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+
+    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+
+    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+
+    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+    for (; remain > 0; remain--){
+        float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+        float32x4_t vdin10 = vld1q_f32(inptr_ch1);
+        float32x4_t vdin20 = vld1q_f32(inptr_ch2);
+        float32x4_t vdin30 = vld1q_f32(inptr_ch3);
+        float32x4_t vdin40 = vld1q_f32(inptr_ch4);
+        float32x4_t vsum = vmulq_f32(vdin00, vweights20);
+        vsum = vmlaq_f32(vsum, vdin10, vweights30);
+        vsum = vmlaq_f32(vsum, vdin20, vweights40);
+        vsum = vmlaq_f32(vsum, vdin30, vweights50);
+        vsum = vmlaq_f32(vsum, vdin40, vweights60);
+        float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+        float32x4_t vdin11 = vld1q_f32(inptr_ch1 + 4);
+        float32x4_t vdin21 = vld1q_f32(inptr_ch2 + 4);
+        float32x4_t vdin31 = vld1q_f32(inptr_ch3 + 4);
+        float32x4_t vdin41 = vld1q_f32(inptr_ch4 + 4);
+        vsum = vmlaq_f32(vsum, vdin01, vweights21);
+        vsum = vmlaq_f32(vsum, vdin11, vweights31);
+        vsum = vmlaq_f32(vsum, vdin21, vweights41);
+        vsum = vmlaq_f32(vsum, vdin31, vweights51);
+        vsum = vmlaq_f32(vsum, vdin41, vweights61);
+        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+        vtotal = vpadd_f32(vtotal, vtotal);
+        float32x2_t vdataout = vld1_f32(outptr);
+        vtotal = vset_lane_f32(0.f, vtotal, 1);
+        vdataout = vadd_f32(vdataout, vtotal);
+        vst1_f32(outptr, vdataout);
+        outptr++;
+        inptr_ch0++;
+        inptr_ch1++;
+        inptr_ch2++;
+        inptr_ch3++;
+        inptr_ch4++;
+    }
+}
+
+void conv7x7_mid_top0(const float* din, float* dout, int w_out, int width, int height, const float* weight_ch_in){
+    
+    const float* inptr_ch0 = din;
+    const float* inptr_ch1 = inptr_ch0 + width;
+    const float* inptr_ch2 = inptr_ch1 + width;
+    const float* inptr_ch3 = inptr_ch2 + width;
+    const float* wei_ptr = weight_ch_in + 21;//3
+    float* outptr = dout + 3;
+    int cnt = (width - 6) / 4;
+    int remain = (width - 6) - cnt * 4;
+    asm volatile(
+            "cmp      %[cnt], #0                                    @ cnt > 0 \n"
+            "ble       exit_top0                                    @ exit \n"
+            "loop_top0:                                             @ loop \n"
+            //0.0
+            "vld1.f32 {d0-d1}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch0]]!                    @ load data \n"
+            "vld1.f32 {d14-d15}, [%[outptr]]                        @ load out \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmul.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmul.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmul.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //0.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch0], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch1]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch1]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            
+            //1.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch1]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //1.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch1], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch2]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch2]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //2.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch2]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //2.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch2], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch3]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch3]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //3.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch3]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //3.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch3], #32                              @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            "sub      %[wei_ptr], #116                              @ sub wei_ptr - 4 \n"
+            "vadd.f32 q5, q10, q7                                  @ add \n"
+            "vadd.f32 q6, q9, q8                                  @ add \n"
+            "subs     %[cnt], #1                                   @ subs \n"
+            "vadd.f32 q4, q5, q6                                  @ add \n"
+            "vst1.f32 {d8-d9}, [%[outptr]]!                       @ stroe \n"
+            "bne loop_top0                                        @ loop \n"
+            "exit_top0:                                           @ exit \n"
+            :[cnt] "+r" (cnt), [wei_ptr] "+r" (wei_ptr), [outptr] "+r" (outptr), \
+            [inptr_ch0] "+r" (inptr_ch0), [inptr_ch1] "+r" (inptr_ch1), \
+            [inptr_ch2] "+r" (inptr_ch2), [inptr_ch3] "+r" (inptr_ch3)
+            :
+            :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9", "q10"
+    );
+
+    
+    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+
+    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+
+    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+
+    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+    for (; remain > 0; remain--){
+        float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+        float32x4_t vdin10 = vld1q_f32(inptr_ch1);
+        float32x4_t vdin20 = vld1q_f32(inptr_ch2);
+        float32x4_t vdin30 = vld1q_f32(inptr_ch3);
+        float32x4_t vsum = vmulq_f32(vdin00, vweights30);
+        vsum = vmlaq_f32(vsum, vdin10, vweights40);
+        vsum = vmlaq_f32(vsum, vdin20, vweights50);
+        vsum = vmlaq_f32(vsum, vdin30, vweights60);
+        float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+        float32x4_t vdin11 = vld1q_f32(inptr_ch1 + 4);
+        float32x4_t vdin21 = vld1q_f32(inptr_ch2 + 4);
+        float32x4_t vdin31 = vld1q_f32(inptr_ch3 + 4);
+        vsum = vmlaq_f32(vsum, vdin01, vweights31);
+        vsum = vmlaq_f32(vsum, vdin11, vweights41);
+        vsum = vmlaq_f32(vsum, vdin21, vweights51);
+        vsum = vmlaq_f32(vsum, vdin31, vweights61);
+        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+        vtotal = vpadd_f32(vtotal, vtotal);
+        float32x2_t vdataout = vld1_f32(outptr);
+        vtotal = vset_lane_f32(0.f, vtotal, 1);
+        vdataout = vadd_f32(vdataout, vtotal);
+        vst1_f32(outptr, vdataout);
+        outptr++;
+        inptr_ch0++;
+        inptr_ch1++;
+        inptr_ch2++;
+        inptr_ch3++;
+    }
+}
+
+
+void conv7x7_mid_mid(const float* din, float* dout, int w_out, int width, int height, const float* weight_ch_in){
+    float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+    float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+    vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+
+    float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+    float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+    vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+
+    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+
+    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+
+    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+
+    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+
+    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+    height -= 3;
+    for (int i = 0; i < height; i++){
+        const float* inptr_ch0 = din + i * width;
+        const float* inptr_ch1 = inptr_ch0 + width;
+        const float* inptr_ch2 = inptr_ch1 + width;
+        const float* inptr_ch3 = inptr_ch2 + width;
+        const float* inptr_ch4 = inptr_ch3 + width;
+        const float* inptr_ch5 = inptr_ch4 + width;
+        const float* inptr_ch6 = inptr_ch5 + width;
+        const float* wei_ptr = weight_ch_in;
+        float* outptr = dout + i * w_out + 3;
+        int cnt = (width - 6) / 4;
+        int remain = (width - 6) - cnt * 4;
+        //printf("din: %x, inptr_ch0: %x, inptr_ch1: %x, weight_ch_in: %x \n", din, inptr_ch0, inptr_ch1, weight_ch_in);
+#ifdef __arrch64__
+        for(; cnt > 0; cnt --){
+            //0
+            float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+            float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+            float32x4_t vdin02 = vld1q_f32(inptr_ch0 + 8);
+            float32x4_t vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            float32x4_t vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            float32x4_t vdin03456 = vextq_f32(vdin00, vdin01, 3);
+            //printf("vdin00: %.2f, vdin01234: %.2f\n", vgetq_lane_f32(vdin00, 0), vgetq_lane_f32(vdin01234, 0));
+
+            float32x4_t vsum0 = vmulq_f32(vdin00, vweights00);
+            float32x4_t vsum1 = vmulq_f32(vdin01234, vweights00);
+            float32x4_t vsum2 = vmulq_f32(vdin02345, vweights00);
+            float32x4_t vsum3 = vmulq_f32(vdin03456, vweights00);
+
+            float32x4_t vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            float32x4_t vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            float32x4_t vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights01);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights01);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights01);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights01);
+
+            //1
+            vdin00 = vld1q_f32(inptr_ch1);
+            vdin01 = vld1q_f32(inptr_ch1 + 4);
+            vdin02 = vld1q_f32(inptr_ch1 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights10);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights10);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights10);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights10);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights11);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights11);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights11);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights11);
+
+            //2
+            vdin00 = vld1q_f32(inptr_ch2);
+            vdin01 = vld1q_f32(inptr_ch2 + 4);
+            vdin02 = vld1q_f32(inptr_ch2 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights20);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights20);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights20);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights20);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights21);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights21);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights21);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights21);
+
+            //3
+            vdin00 = vld1q_f32(inptr_ch3);
+            vdin01 = vld1q_f32(inptr_ch3 + 4);
+            vdin02 = vld1q_f32(inptr_ch3 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights30);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights30);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights30);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights30);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights31);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights31);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights31);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights31);
+
+            //4
+            vdin00 = vld1q_f32(inptr_ch4);
+            vdin01 = vld1q_f32(inptr_ch4 + 4);
+            vdin02 = vld1q_f32(inptr_ch4 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights40);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights40);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights40);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights40);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights41);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights41);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights41);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights41);
+
+            //5
+            vdin00 = vld1q_f32(inptr_ch5);
+            vdin01 = vld1q_f32(inptr_ch5 + 4);
+            vdin02 = vld1q_f32(inptr_ch5 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights50);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights50);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights50);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights50);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights51);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights51);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights51);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights51);
+
+            //6
+            vdin00 = vld1q_f32(inptr_ch6);
+            vdin01 = vld1q_f32(inptr_ch6 + 4);
+            vdin02 = vld1q_f32(inptr_ch6 + 8);
+            vdin01234 = vextq_f32(vdin00, vdin01, 1);
+            vdin02345 = vextq_f32(vdin00, vdin01, 2);
+            vdin03456 = vextq_f32(vdin00, vdin01, 3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin00, vweights60);
+            vsum1 = vmlaq_f32(vsum1, vdin01234, vweights60);
+            vsum2 = vmlaq_f32(vsum2, vdin02345, vweights60);
+            vsum3 = vmlaq_f32(vsum3, vdin03456, vweights60);
+
+            vdin05678 = vextq_f32(vdin01, vdin02, 1);
+            vdin06789 = vextq_f32(vdin01, vdin02, 2);
+            vdin078910 = vextq_f32(vdin01, vdin02,3);
+
+            vsum0 = vmlaq_f32(vsum0, vdin01, vweights61);
+            vsum1 = vmlaq_f32(vsum1, vdin05678, vweights61);
+            vsum2 = vmlaq_f32(vsum2, vdin06789, vweights61);
+            vsum3 = vmlaq_f32(vsum3, vdin078910, vweights61);
+
+            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum0), vget_high_f32(vsum0));
+            vtotal = vpadd_f32(vtotal, vtotal);
+            float32x2_t vtotal1 = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));
+            vtotal1 = vpadd_f32(vtotal1, vtotal1);
+            float32x2_t vtotal2 = vpadd_f32(vget_low_f32(vsum2), vget_high_f32(vsum2));
+            vtotal2 = vpadd_f32(vtotal2, vtotal2);
+            float32x2_t vtotal3 = vpadd_f32(vget_low_f32(vsum3), vget_high_f32(vsum3));
+            vtotal3 = vpadd_f32(vtotal3, vtotal3);
+
+            float32x4_t vsum = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal1, 0), vsum, 1);
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal2, 0), vsum, 2);
+            vsum = vsetq_lane_f32(vget_lane_f32(vtotal3, 0), vsum, 3);
+            float32x4_t vdataout = vld1q_f32(outptr);
+
+           // printf("vdin05678: %.2f, vdin00: %.2f \n", vgetq_lane_f32(vdin05678, 0), vgetq_lane_f32(vdin00, 0));
+            //printf("outptr: %x, vdataout: %.2f \n", outptr, vgetq_lane_f32(vdataout, 0));
+            vdataout = vaddq_f32(vdataout, vsum);
+            //printf("outptr: %x, vdataout: %.2f \n", outptr, vgetq_lane_f32(vdataout, 0));
+            vst1q_f32(outptr, vdataout);
+            outptr += 4;
+            inptr_ch0 += 4;
+            inptr_ch1 += 4;
+            inptr_ch2 += 4;
+            inptr_ch3 += 4;
+            inptr_ch4 += 4;
+            inptr_ch5 += 4;
+            inptr_ch6 += 4;
+        }
+#else
+        asm volatile(
+            "cmp      %[cnt], #0                                    @ cnt > 0 \n"
+            "ble       exit1                                        @ exit \n"
+            "loop1:                                                 @ loop \n"
+            //0.0
+            "vld1.f32 {d0-d1}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch0]]!                      @ load data \n"
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch0]]!                    @ load data \n"
+            "vld1.f32 {d14-d15}, [%[outptr]]                        @ load out \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmul.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmul.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmul.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //0.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch0], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch1]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch1]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            
+            //1.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch1]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //1.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch1], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch2]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch2]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //2.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch2]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //2.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch2], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch3]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch3]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //3.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch3]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //3.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch3], #32                              @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch4]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch4]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //4.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch4]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //4.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch4], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch5]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch5]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+             //5.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch5]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //5.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch5], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "sub      %[wei_ptr], #4                                 @ sub wei_ptr - 4 \n"
+            "vld1.f32 {d0-d1}, [%[inptr_ch6]]!                      @ load data \n"
+            "vld1.f32 {d2-d3}, [%[inptr_ch6]]!                      @ load data \n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+
+            //6.0
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                      @ load weights00 \n"
+            "vld1.f32 {d12-d13}, [%[inptr_ch6]]!                    @ load data \n"
+            "vext.f32 q2, q0, q1, #1                                @ extq 1234 \n"
+            "vext.f32 q3, q0, q1, #2                                @ extq 2345 \n"
+            "vext.f32 q4, q0, q1, #3                                @ extq 3456 \n"
+            "vmla.f32 q7, q0, d10[0]                                @ mla vdin0 * wei00[0]\n"
+            "vmla.f32 q8, q2, d10[1]                                @ mla 1234 * wei00[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 2345 * wei00[2]\n"
+            "vmla.f32 q10, q4, d11[1]                               @ mla 3456 * wei00[3]\n"
+            //6.1
+            "vld1.f32 {d10-d11}, [%[wei_ptr]]!                       @ load weights01 \n"
+            "vext.f32 q2, q1, q6, #1                               @ extq 5678 \n"
+            "vext.f32 q3, q1, q6, #2                                @ extq 6789 \n"
+            "sub      %[inptr_ch6], #32                             @ sub inptr_ch0 - 32 \n"
+            "vmla.f32 q7, q1, d10[0]                                @ mla 4567 * wei01[0]\n"
+            "vmla.f32 q8, q2, d10[1]                               @ mla 5678 * wei01[1]\n"
+            "vmla.f32 q9, q3, d11[0]                                @ mla 6789 * wei01[2]\n"
+            "sub      %[wei_ptr], #200                             @ sub wei_ptr - 4 \n"
+            "vadd.f32 q5, q10, q7                                  @ add \n"
+            "vadd.f32 q6, q9, q8                                  @ add \n"
+            "subs     %[cnt], #1                                   @ subs \n"
+            "vadd.f32 q4, q5, q6                                  @ add \n"
+            "vst1.f32 {d8-d9}, [%[outptr]]!                       @ stroe \n"
+            "bne loop1                                            @ loop \n"
+            "exit1:                                               @ exit \n"
+            :[cnt] "+r" (cnt), [wei_ptr] "+r" (wei_ptr), [outptr] "+r" (outptr), \
+            [inptr_ch0] "+r" (inptr_ch0), [inptr_ch1] "+r" (inptr_ch1), \
+            [inptr_ch2] "+r" (inptr_ch2), [inptr_ch3] "+r" (inptr_ch3), \
+            [inptr_ch4] "+r" (inptr_ch4), [inptr_ch5] "+r" (inptr_ch5), \
+            [inptr_ch6] "+r" (inptr_ch6)
+            :
+            :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9", "q10"
+        );
+      // printf("inptr_ch0: %x, inptr_ch1: %x, weight_ch_in: %x, cnt: %d \n", inptr_ch0, inptr_ch1, wei_ptr, cnt);
+#endif
+        for (; remain > 0; remain--){
+            float32x4_t vdin00 = vld1q_f32(inptr_ch0);
+            float32x4_t vdin10 = vld1q_f32(inptr_ch1);
+            float32x4_t vdin20 = vld1q_f32(inptr_ch2);
+            float32x4_t vdin30 = vld1q_f32(inptr_ch3);
+            float32x4_t vdin40 = vld1q_f32(inptr_ch4);
+            float32x4_t vdin50 = vld1q_f32(inptr_ch5);
+            float32x4_t vdin60 = vld1q_f32(inptr_ch6);
+            float32x4_t vsum = vmulq_f32(vdin00, vweights00);
+            vsum = vmlaq_f32(vsum, vdin10, vweights10);
+            vsum = vmlaq_f32(vsum, vdin20, vweights20);
+            vsum = vmlaq_f32(vsum, vdin30, vweights30);
+            vsum = vmlaq_f32(vsum, vdin40, vweights40);
+            vsum = vmlaq_f32(vsum, vdin50, vweights50);
+            vsum = vmlaq_f32(vsum, vdin60, vweights60);
+            float32x4_t vdin01 = vld1q_f32(inptr_ch0 + 4);
+            float32x4_t vdin11 = vld1q_f32(inptr_ch1 + 4);
+            float32x4_t vdin21 = vld1q_f32(inptr_ch2 + 4);
+            float32x4_t vdin31 = vld1q_f32(inptr_ch3 + 4);
+            float32x4_t vdin41 = vld1q_f32(inptr_ch4 + 4);
+            float32x4_t vdin51 = vld1q_f32(inptr_ch5 + 4);
+            float32x4_t vdin61 = vld1q_f32(inptr_ch6 + 4);
+            vsum = vmlaq_f32(vsum, vdin01, vweights01);
+            vsum = vmlaq_f32(vsum, vdin11, vweights11);
+            vsum = vmlaq_f32(vsum, vdin21, vweights21);
+            vsum = vmlaq_f32(vsum, vdin31, vweights31);
+            vsum = vmlaq_f32(vsum, vdin41, vweights41);
+            vsum = vmlaq_f32(vsum, vdin51, vweights51);
+            vsum = vmlaq_f32(vsum, vdin61, vweights61);
+            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+            vtotal = vpadd_f32(vtotal, vtotal);
+            float32x2_t vdataout = vld1_f32(outptr);
+            vtotal = vset_lane_f32(0.f, vtotal, 1);
+            vdataout = vadd_f32(vdataout, vtotal);
+            vst1_f32(outptr, vdataout);
+            outptr++;
+            inptr_ch0++;
+            inptr_ch1++;
+            inptr_ch2++;
+            inptr_ch3++;
+            inptr_ch4++;
+            inptr_ch5++;
+            inptr_ch6++;
+        }
+    }
+}
+
+void conv_arm_7x7s1(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, \
+    const float* weights, const float* bias, \
+    int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
+    int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space) {
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num_in = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+
+    const int size_kernel = kernel_h * kernel_w;
+
+    const int ch_out_g = ch_out / group;
+    const int ch_in_g = ch_in / group;
+    const int size_in_channel = w_in * h_in;
+    const int size_in_batch = size_in_channel * ch_in;
+    const int size_out_channel = w_out * h_out;
+    const int size_out_batch = size_out_channel * ch_out;
+
+    //printf("extend kernel size: %d, %d\n", kernel_ext_w, kernel_ext_h);
+    const float *data_in = tensor_in.data();
+    float *outptr = tensor_out.mutable_data();
+
+    int kernel_w_even = kernel_w >> 1;
+    int kernel_h_even = kernel_h >> 1;
+
+    for (int b = 0; b < num_in; ++b) {
+        float *outptr_batch = outptr + b * size_out_batch;
+        const float* data_in_batch = data_in + b * size_in_batch;
+//#pragma omp parallel for collapse(2)
+        for (int g = 0; g < group; ++g) {
+#pragma omp parallel for
+            for (int c = 0; c < ch_out_g; ++c) {
+                const float *inptr_group = data_in_batch + g * ch_in_g * size_in_channel;
+                float *outptr_ch = outptr_batch + (g * ch_out_g + c) * size_out_channel;
+                const float *weight_ch = weights + (g * ch_out_g + c) * ch_in_g * size_kernel;
+
+                float bias_value = flag_bias? bias[g * ch_out_g + c] : 0.f;
+                fill_bias(outptr_ch, &bias_value, 1, w_out * h_out);
+                for(int cin = 0; cin < ch_in_g; cin++){
+                    const float *inptr_ch = inptr_group + cin * size_in_channel;
+                    const float *weight_ch_in = weight_ch + cin * size_kernel;
+                    float32x4_t vzero = vdupq_n_f32(0.f);
+                    const float *inptr_ch0 = inptr_ch;
+                    const float *inptr_ch1 = inptr_ch0 + w_in;
+                    const float *inptr_ch2 = inptr_ch1 + w_in;
+                    const float *inptr_ch3 = inptr_ch2 + w_in;
+                    const float *inptr_ch4 = inptr_ch3 + w_in;
+                    const float *inptr_ch5 = inptr_ch4 + w_in;
+                    const float *inptr_ch6 = inptr_ch5 + w_in;
+
+                    //mid
+                    float* outptr_imd = outptr_ch ;
+                    const float* inptr_imd = inptr_ch0;
+                    const float* wei_ptr = weight_ch_in;
+                    conv7x7_mid_top0(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    outptr_imd = outptr_ch + 1 * w_out;
+                    inptr_imd = inptr_ch0;
+                    wei_ptr = weight_ch_in;
+                    conv7x7_mid_top1(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    outptr_imd = outptr_ch + 2 * w_out;
+                    inptr_imd = inptr_ch0;
+                    wei_ptr = weight_ch_in;
+                    conv7x7_mid_top2(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    outptr_imd = outptr_ch + 3 * w_out;
+                    inptr_imd = inptr_ch0;
+                    wei_ptr = weight_ch_in;
+                    conv7x7_mid_mid(inptr_imd, outptr_imd, w_out, w_in, h_out - kernel_h_even, wei_ptr);
+
+                    outptr_imd = outptr_ch + (h_out - 3) * w_out;
+                    inptr_imd = inptr_ch + (h_out - kernel_h + 1) * w_in;//1
+                    wei_ptr = weight_ch_in - 7;
+                    conv7x7_mid_top2(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    outptr_imd = outptr_ch + (h_out - 2) * w_out;
+                    inptr_imd = inptr_ch + (h_out - kernel_h + 2) * w_in;//1
+                    wei_ptr = weight_ch_in - 14;
+                    conv7x7_mid_top1(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    outptr_imd = outptr_ch + (h_out - 1) * w_out;
+                    inptr_imd = inptr_ch + (h_out - kernel_h + 3) * w_in;//1
+                    wei_ptr = weight_ch_in - 21;
+                    conv7x7_mid_top0(inptr_imd, outptr_imd, w_out, w_in, 1, wei_ptr);
+
+                    int h = 0;
+                    //border
+                    for(; h < h_out; h++){ // 0-3
+                        float *outptr_ch_wh = outptr_ch + h * w_out;
+                        if (h > kernel_h_even && h < h_out - kernel_h_even){
+                            inptr_ch0 = inptr_ch + (h - kernel_h_even) * w_in;
+                            inptr_ch1 = inptr_ch0 + w_in;
+                            inptr_ch2 = inptr_ch1 + w_in;
+                            inptr_ch3 = inptr_ch2 + w_in;
+                            inptr_ch4 = inptr_ch3 + w_in;
+                            inptr_ch5 = inptr_ch4 + w_in;
+                            inptr_ch6 = inptr_ch5 + w_in;
+                        }else{
+                            if(h <= kernel_h_even)
+                                inptr_ch0 = inptr_ch;
+                            else
+                                inptr_ch0 = inptr_ch + (h_out - kernel_h) * w_in;
+                            inptr_ch1 = inptr_ch0 + w_in;
+                            inptr_ch2 = inptr_ch1 + w_in;
+                            inptr_ch3 = inptr_ch2 + w_in;
+                            inptr_ch4 = inptr_ch3 + w_in;
+                            inptr_ch5 = inptr_ch4 + w_in;
+                            inptr_ch6 = inptr_ch5 + w_in;
+                        }
+                        if (h < h_out - kernel_h_even){
+                            int w = 0;
+                            for(w = 0; w < 3; w++){
+                                if (h == 0){//0
+                                    //load weights 7x7
+                                    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+                                    if (w == 0){//3456
+                                        float32x4_t vw0_3456 = vextq_f32(vweights30, vweights31, 3);
+                                        float32x4_t vw1_3456 = vextq_f32(vweights40, vweights41, 3);
+                                        float32x4_t vw2_3456 = vextq_f32(vweights50, vweights51, 3);
+                                        float32x4_t vw3_3456 = vextq_f32(vweights60, vweights61, 3);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_3456);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    } else if (w == 1){//23456
+                                        float32x4_t vw0_2345 = vextq_f32(vweights30, vweights31, 2);
+                                        float32x4_t vw1_2345 = vextq_f32(vweights40, vweights41, 2);
+                                        float32x4_t vw2_2345 = vextq_f32(vweights50, vweights51, 2);
+                                        float32x4_t vw3_2345 = vextq_f32(vweights60, vweights61, 2);
+                                        float32x4_t vw0_6700 = vextq_f32(vweights31, vzero, 2);
+                                        float32x4_t vw1_6700 = vextq_f32(vweights41, vzero, 2);
+                                        float32x4_t vw2_6700 = vextq_f32(vweights51, vzero, 2);
+                                        float32x4_t vw3_6700 = vextq_f32(vweights61, vzero, 2);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_2345);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_6700);//6
+                                        vtotal = vget_low_f32(vsum1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                       // vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    } else if (w == 2){//123456
+                                        float32x4_t vw0_1234 = vextq_f32(vweights30, vweights31, 1);
+                                        float32x4_t vw1_1234 = vextq_f32(vweights40, vweights41, 1);
+                                        float32x4_t vw2_1234 = vextq_f32(vweights50, vweights51, 1);
+                                        float32x4_t vw3_1234 = vextq_f32(vweights60, vweights61, 1);
+                                        float32x4_t vw0_5670 = vextq_f32(vweights31, vzero, 1);
+                                        float32x4_t vw1_5670 = vextq_f32(vweights41, vzero, 1);
+                                        float32x4_t vw2_5670 = vextq_f32(vweights51, vzero, 1);
+                                        float32x4_t vw3_5670 = vextq_f32(vweights61, vzero, 1);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_1234);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_5670);//6
+                                        vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    } 
+                                } else if (h == 1){//1
+                                    //load weights 7x7
+                                    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+                                    if (w == 0){//3456
+                                        float32x4_t vw0_3456 = vextq_f32(vweights20, vweights21, 3);
+                                        float32x4_t vw1_3456 = vextq_f32(vweights30, vweights31, 3);
+                                        float32x4_t vw2_3456 = vextq_f32(vweights40, vweights41, 3);
+                                        float32x4_t vw3_3456 = vextq_f32(vweights50, vweights51, 3);
+                                        float32x4_t vw4_3456 = vextq_f32(vweights60, vweights61, 3);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_3456);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 1){//23456
+                                        float32x4_t vw0_2345 = vextq_f32(vweights20, vweights21, 2);
+                                        float32x4_t vw1_2345 = vextq_f32(vweights30, vweights31, 2);
+                                        float32x4_t vw2_2345 = vextq_f32(vweights40, vweights41, 2);
+                                        float32x4_t vw3_2345 = vextq_f32(vweights50, vweights51, 2);
+                                        float32x4_t vw4_2345 = vextq_f32(vweights60, vweights61, 2);
+                                        float32x4_t vw0_6700 = vextq_f32(vweights21, vzero, 2);
+                                        float32x4_t vw1_6700 = vextq_f32(vweights31, vzero, 2);
+                                        float32x4_t vw2_6700 = vextq_f32(vweights41, vzero, 2);
+                                        float32x4_t vw3_6700 = vextq_f32(vweights51, vzero, 2);
+                                        float32x4_t vw4_6700 = vextq_f32(vweights61, vzero, 2);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_2345);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_6700);//6
+                                        vtotal = vget_low_f32(vsum1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 2){//123456
+                                        float32x4_t vw0_1234 = vextq_f32(vweights20, vweights21, 1);
+                                        float32x4_t vw1_1234 = vextq_f32(vweights30, vweights31, 1);
+                                        float32x4_t vw2_1234 = vextq_f32(vweights40, vweights41, 1);
+                                        float32x4_t vw3_1234 = vextq_f32(vweights50, vweights51, 1);
+                                        float32x4_t vw4_1234 = vextq_f32(vweights60, vweights61, 1);
+
+                                        float32x4_t vw0_5670 = vextq_f32(vweights21, vzero, 1);
+                                        float32x4_t vw1_5670 = vextq_f32(vweights31, vzero, 1);
+                                        float32x4_t vw2_5670 = vextq_f32(vweights41, vzero, 1);
+                                        float32x4_t vw3_5670 = vextq_f32(vweights51, vzero, 1);
+                                        float32x4_t vw4_5670 = vextq_f32(vweights61, vzero, 1);
+
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_1234);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_5670);//6
+                                        vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }
+                                } else if (h == 2){//2 
+                                    //load weights 7x7
+                                    float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                    float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                    vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+                                    
+                                    if (w == 0){//3456
+                                        float32x4_t vw0_3456 = vextq_f32(vweights10, vweights11, 3);
+                                        float32x4_t vw1_3456 = vextq_f32(vweights20, vweights21, 3);
+                                        float32x4_t vw2_3456 = vextq_f32(vweights30, vweights31, 3);
+                                        float32x4_t vw3_3456 = vextq_f32(vweights40, vweights41, 3);
+                                        float32x4_t vw4_3456 = vextq_f32(vweights50, vweights51, 3);
+                                        float32x4_t vw5_3456 = vextq_f32(vweights60, vweights61, 3);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_3456);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 1){//23456
+                                        float32x4_t vw0_2345 = vextq_f32(vweights10, vweights11, 2);
+                                        float32x4_t vw1_2345 = vextq_f32(vweights20, vweights21, 2);
+                                        float32x4_t vw2_2345 = vextq_f32(vweights30, vweights31, 2);
+                                        float32x4_t vw3_2345 = vextq_f32(vweights40, vweights41, 2);
+                                        float32x4_t vw4_2345 = vextq_f32(vweights50, vweights51, 2);
+                                        float32x4_t vw5_2345 = vextq_f32(vweights60, vweights61, 2);
+                                        float32x4_t vw0_6700 = vextq_f32(vweights11, vzero, 2);
+                                        float32x4_t vw1_6700 = vextq_f32(vweights21, vzero, 2);
+                                        float32x4_t vw2_6700 = vextq_f32(vweights31, vzero, 2);
+                                        float32x4_t vw3_6700 = vextq_f32(vweights41, vzero, 2);
+                                        float32x4_t vw4_6700 = vextq_f32(vweights51, vzero, 2);
+                                        float32x4_t vw5_6700 = vextq_f32(vweights61, vzero, 2);
+
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_2345);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                        
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_6700);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain51, vw5_6700);//6
+                                        vtotal = vget_low_f32(vsum1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 2){//123456
+                                       
+                                        float32x4_t vw0_1234 = vextq_f32(vweights10, vweights11, 1);
+                                        float32x4_t vw1_1234 = vextq_f32(vweights20, vweights21, 1);
+                                        float32x4_t vw2_1234 = vextq_f32(vweights30, vweights31, 1);
+                                        float32x4_t vw3_1234 = vextq_f32(vweights40, vweights41, 1);
+                                        float32x4_t vw4_1234 = vextq_f32(vweights50, vweights51, 1);
+                                        float32x4_t vw5_1234 = vextq_f32(vweights60, vweights61, 1);
+                                        float32x4_t vw0_5670 = vextq_f32(vweights11, vzero, 1);
+                                        float32x4_t vw1_5670 = vextq_f32(vweights21, vzero, 1);
+                                        float32x4_t vw2_5670 = vextq_f32(vweights31, vzero, 1);
+                                        float32x4_t vw3_5670 = vextq_f32(vweights41, vzero, 1);
+                                        float32x4_t vw4_5670 = vextq_f32(vweights51, vzero, 1);
+                                        float32x4_t vw5_5670 = vextq_f32(vweights61, vzero, 1);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_1234);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain51, vw5_5670);//6
+                                        vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }
+                                }else{//mid
+                                    //load weights 7x7
+                                    float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                                    float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                                    vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                                    float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                    float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                    vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                    float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                    float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                    vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                    float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                    float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                    vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                    float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                    float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                    vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                    float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                    float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                    vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                    float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                    float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                    vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+                                   if (w == 0){//3456
+                                        float32x4_t vw0_3456 = vextq_f32(vweights00, vweights01, 3);
+                                        float32x4_t vw1_3456 = vextq_f32(vweights10, vweights11, 3);
+                                        float32x4_t vw2_3456 = vextq_f32(vweights20, vweights21, 3);
+                                        float32x4_t vw3_3456 = vextq_f32(vweights30, vweights31, 3);
+                                        float32x4_t vw4_3456 = vextq_f32(vweights40, vweights41, 3);
+                                        float32x4_t vw5_3456 = vextq_f32(vweights50, vweights51, 3);
+                                        float32x4_t vw6_3456 = vextq_f32(vweights60, vweights61, 3);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                        float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_3456);
+                                        vsum = vmlaq_f32(vsum, vdatain60, vw6_3456);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 1){//23456
+                                        float32x4_t vw0_2345 = vextq_f32(vweights00, vweights01, 2);
+                                        float32x4_t vw1_2345 = vextq_f32(vweights10, vweights11, 2);
+                                        float32x4_t vw2_2345 = vextq_f32(vweights20, vweights21, 2);
+                                        float32x4_t vw3_2345 = vextq_f32(vweights30, vweights31, 2);
+                                        float32x4_t vw4_2345 = vextq_f32(vweights40, vweights41, 2);
+                                        float32x4_t vw5_2345 = vextq_f32(vweights50, vweights51, 2);
+                                        float32x4_t vw6_2345 = vextq_f32(vweights60, vweights61, 2);
+
+                                        float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 2);
+                                        float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 2);
+                                        float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 2);
+                                        float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 2);
+                                        float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 2);
+                                        float32x4_t vw5_5670 = vextq_f32(vweights51, vzero, 2);
+                                        float32x4_t vw6_5670 = vextq_f32(vweights61, vzero, 2);
+
+                                        float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_2345);
+                                        vsum = vmlaq_f32(vsum, vdatain60, vw6_2345);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                        float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain51, vw5_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain61, vw6_5670);//6
+                                        vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vtotal, vdataout);
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }else if (w == 2){//123456
+                                        float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 1);
+                                        float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 1);
+                                        float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 1);
+                                        float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 1);
+                                        float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 1);
+                                        float32x4_t vw5_5670 = vextq_f32(vweights51, vzero, 1);
+                                        float32x4_t vw6_5670 = vextq_f32(vweights61, vzero, 1); 
+                                        
+                                        float32x4_t vw0_1234 = vextq_f32(vweights00, vweights01, 1);
+                                        float32x4_t vw1_1234 = vextq_f32(vweights10, vweights11, 1);
+                                        float32x4_t vw2_1234 = vextq_f32(vweights20, vweights21, 1);
+                                        float32x4_t vw3_1234 = vextq_f32(vweights30, vweights31, 1);
+                                        float32x4_t vw4_1234 = vextq_f32(vweights40, vweights41, 1);
+                                        float32x4_t vw5_1234 = vextq_f32(vweights50, vweights51, 1);
+                                        float32x4_t vw6_1234 = vextq_f32(vweights60, vweights61, 1);
+                                       // printf("vw0_1234_0: %.2f, vw0_1234_1: %.2f, vw0_1234_2: %.2f, vw0_1234_3: %.2f\n", \ 
+                                        //    vgetq_lane_f32(vw0_1234,0), vgetq_lane_f32(vw0_1234,1), vgetq_lane_f32(vw0_1234,2), vgetq_lane_f32(vw0_1234,3));
+
+                                        float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                        float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                        float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                        float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                        float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                        float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                        float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                        float32x4_t vsum = vmulq_f32(vdatain00, vw0_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain10, vw1_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain20, vw2_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain30, vw3_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain40, vw4_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain50, vw5_1234);
+                                        vsum = vmlaq_f32(vsum, vdatain60, vw6_1234);
+                                        float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                        vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                        float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                        vsum1 = vextq_f32(vsum1, vzero, 3);
+                                       
+                                        
+                                        float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                        float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                        float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                        float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                        float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                        float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                        float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                       // printf("vw0_5670_0: %.2f, vw0_5670_1: %.2f, vw0_5670_2: %.2f, vw0_5670_3: %.2f\n", \ 
+                                         //   vgetq_lane_f32(vw0_5670,0), vgetq_lane_f32(vw0_5670,1), vgetq_lane_f32(vw0_5670,2), vgetq_lane_f32(vw0_5670,3));
+                                        
+                                        vsum1 = vmlaq_f32(vsum1, vdatain01, vw0_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain11, vw1_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain21, vw2_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain31, vw3_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain41, vw4_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain51, vw5_5670);//6
+                                        vsum1 = vmlaq_f32(vsum1, vdatain61, vw6_5670);//6
+                                        vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                        //printf("vtotal_0: %.2f, vatotal_1: %.2f, vdataout_0: %.2f, vdataout_1: %.2f\n", \ 
+                                        //    vget_lane_f32(vtotal,0), vget_lane_f32(vtotal,1), vget_lane_f32(vdataout,0), vget_lane_f32(vdataout,1));
+                                        float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                        vdataout = vadd_f32(vdataout, vtotal);
+                                       // printf("vtotal_0: %.2f, vatotal_1: %.2f, vdataout_0: %.2f, vdataout_1: %.2f\n", \ 
+                                         //   vget_lane_f32(vtotal,0), vget_lane_f32(vtotal,1), vget_lane_f32(vdataout,0), vget_lane_f32(vdataout,1));
+                                        
+                                        vst1_f32(outptr_ch_wh, vdataout);
+                                        if(flag_relu)
+                                            outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+
+                                        outptr_ch_wh++;
+                                        continue;
+                                    }
+                                } 
+                            }
+                            //right
+                            inptr_ch0 += w_in - 7;
+                            inptr_ch1 += w_in - 7;
+                            inptr_ch2 += w_in - 7;
+                            inptr_ch3 += w_in - 7;
+                            inptr_ch4 += w_in - 7;
+                            inptr_ch5 += w_in - 7;
+                            inptr_ch6 += w_in - 7;
+                            outptr_ch_wh +=w_out - 6;
+                           
+                            if (h == 0){
+                                
+                                float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                //3 123456-012345
+                                float32x4_t vdin0_1234 = vextq_f32(vdatain00, vdatain01, 1);
+                                float32x4_t vdin1_1234 = vextq_f32(vdatain10, vdatain11, 1);
+                                float32x4_t vdin2_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                                float32x4_t vdin3_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                                float32x4_t vdin0_5670 = vextq_f32(vdatain01, vzero, 1);
+                                float32x4_t vdin1_5670 = vextq_f32(vdatain11, vzero, 1);
+                                float32x4_t vdin2_5670 = vextq_f32(vdatain21, vzero, 1);
+                                float32x4_t vdin3_5670 = vextq_f32(vdatain31, vzero, 1);
+
+                                float32x4_t vdin0_2345 = vextq_f32(vdatain00, vdatain01, 2);
+                                float32x4_t vdin1_2345 = vextq_f32(vdatain10, vdatain11, 2);
+                                float32x4_t vdin2_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                                float32x4_t vdin3_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                                float32x4_t vdin0_6700 = vextq_f32(vdatain01, vzero, 2);
+                                float32x4_t vdin1_6700 = vextq_f32(vdatain11, vzero, 2);
+                                float32x4_t vdin2_6700 = vextq_f32(vdatain21, vzero, 2);
+                                float32x4_t vdin3_6700 = vextq_f32(vdatain31, vzero, 2);
+
+                                float32x4_t vdin0_3456 = vextq_f32(vdatain00, vdatain01, 3);
+                                float32x4_t vdin1_3456 = vextq_f32(vdatain10, vdatain11, 3);
+                                float32x4_t vdin2_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                                float32x4_t vdin3_3456 = vextq_f32(vdatain30, vdatain31, 3);
+
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                float32x4_t vsum = vmulq_f32(vdin0_1234, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin1_1234, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin2_1234, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin3_1234, vweights60);
+                                
+                                //out
+                                float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+
+
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+                                float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                                float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                                float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights51, 2);
+                                float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights61, 2);
+                                vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                                vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                                vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                                vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                                float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+
+                                //2 23456-01234
+                                
+                                vsum = vmulq_f32(vdin0_2345, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin1_2345, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin2_2345, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin3_2345, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                                //out
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                                vsum1 = vextq_f32(vsum1, vzero, 3);
+                                
+                                vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights31);
+                                vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights41);
+                                vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights51);
+                                vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights61);
+                                
+                                vtotal = vget_low_f32(vsum1);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+
+                                //1 3456 - 0123
+                                vsum = vmulq_f32(vdin0_3456, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin1_3456, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin2_3456, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin3_3456, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++; 
+                            } else if (h == 1){
+                                //3
+                                float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+                                //1 123456-012345
+                                float32x4_t vdin0_1234 = vextq_f32(vdatain00, vdatain01, 1);
+                                float32x4_t vdin1_1234 = vextq_f32(vdatain10, vdatain11, 1);
+                                float32x4_t vdin2_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                                float32x4_t vdin3_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                                float32x4_t vdin4_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                                float32x4_t vdin0_5670 = vextq_f32(vdatain01, vzero, 1);
+                                float32x4_t vdin1_5670 = vextq_f32(vdatain11, vzero, 1);
+                                float32x4_t vdin2_5670 = vextq_f32(vdatain21, vzero, 1);
+                                float32x4_t vdin3_5670 = vextq_f32(vdatain31, vzero, 1);
+                                float32x4_t vdin4_5670 = vextq_f32(vdatain41, vzero, 1);
+
+                                float32x4_t vdin0_2345 = vextq_f32(vdatain00, vdatain01, 2);
+                                float32x4_t vdin1_2345 = vextq_f32(vdatain10, vdatain11, 2);
+                                float32x4_t vdin2_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                                float32x4_t vdin3_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                                float32x4_t vdin4_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                                float32x4_t vdin0_6700 = vextq_f32(vdatain01, vzero, 2);
+                                float32x4_t vdin1_6700 = vextq_f32(vdatain11, vzero, 2);
+                                float32x4_t vdin2_6700 = vextq_f32(vdatain21, vzero, 2);
+                                float32x4_t vdin3_6700 = vextq_f32(vdatain31, vzero, 2);
+                                float32x4_t vdin4_6700 = vextq_f32(vdatain41, vzero, 2);
+
+                                float32x4_t vdin0_3456 = vextq_f32(vdatain00, vdatain01, 3);
+                                float32x4_t vdin1_3456 = vextq_f32(vdatain10, vdatain11, 3);
+                                float32x4_t vdin2_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                                float32x4_t vdin3_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                                float32x4_t vdin4_3456 = vextq_f32(vdatain40, vdatain41, 3);
+
+                                float32x4_t vsum = vmulq_f32(vdin0_1234, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin1_1234, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin2_1234, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin3_1234, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin4_1234, vweights60);
+                                
+                                //out
+                                float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+
+                                float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                                float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                                float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                                float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights51, 2);
+                                float32x4_t vw4_4500 = vsetq_lane_f32(0.f, vweights61, 2);
+                                
+                                vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                                vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                                vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                                vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                                vsum = vmlaq_f32(vsum, vdin4_5670, vw4_4500);
+                                float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+
+                                //2 23456-01234
+                                
+                                vsum = vmulq_f32(vdin0_2345, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin1_2345, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin2_2345, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin3_2345, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin4_2345, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                                //out
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                                vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                
+                                vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights21);
+                                vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights31);
+                                vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights41);
+                                vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights51);
+                                vsum1 = vmlaq_f32(vsum1, vdin4_6700, vweights61);
+                                
+                                vtotal = vget_low_f32(vsum1);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+                                
+                                //1 3456 - 0123
+                                
+                                vsum = vmulq_f32(vdin0_3456, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin1_3456, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin2_3456, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin3_3456, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin4_3456, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++; 
+                            }else if (h == 2){
+                                
+                                float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                
+                                //1 123456-012345
+                                float32x4_t vdin0_1234 = vextq_f32(vdatain00, vdatain01, 1);
+                                float32x4_t vdin1_1234 = vextq_f32(vdatain10, vdatain11, 1);
+                                float32x4_t vdin2_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                                float32x4_t vdin3_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                                float32x4_t vdin4_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                                float32x4_t vdin5_1234 = vextq_f32(vdatain50, vdatain51, 1);
+                                float32x4_t vdin0_5670 = vextq_f32(vdatain01, vzero, 1);
+                                float32x4_t vdin1_5670 = vextq_f32(vdatain11, vzero, 1);
+                                float32x4_t vdin2_5670 = vextq_f32(vdatain21, vzero, 1);
+                                float32x4_t vdin3_5670 = vextq_f32(vdatain31, vzero, 1);
+                                float32x4_t vdin4_5670 = vextq_f32(vdatain41, vzero, 1);
+                                float32x4_t vdin5_5670 = vextq_f32(vdatain51, vzero, 1);
+
+                                float32x4_t vdin0_2345 = vextq_f32(vdatain00, vdatain01, 2);
+                                float32x4_t vdin1_2345 = vextq_f32(vdatain10, vdatain11, 2);
+                                float32x4_t vdin2_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                                float32x4_t vdin3_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                                float32x4_t vdin4_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                                float32x4_t vdin5_2345 = vextq_f32(vdatain50, vdatain51, 2);
+                                float32x4_t vdin0_6700 = vextq_f32(vdatain01, vzero, 2);
+                                float32x4_t vdin1_6700 = vextq_f32(vdatain11, vzero, 2);
+                                float32x4_t vdin2_6700 = vextq_f32(vdatain21, vzero, 2);
+                                float32x4_t vdin3_6700 = vextq_f32(vdatain31, vzero, 2);
+                                float32x4_t vdin4_6700 = vextq_f32(vdatain41, vzero, 2);
+                                float32x4_t vdin5_6700 = vextq_f32(vdatain51, vzero, 2);
+                                float32x4_t vdin0_3456 = vextq_f32(vdatain00, vdatain01, 3);
+                                float32x4_t vdin1_3456 = vextq_f32(vdatain10, vdatain11, 3);
+                                float32x4_t vdin2_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                                float32x4_t vdin3_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                                float32x4_t vdin4_3456 = vextq_f32(vdatain40, vdatain41, 3);
+                                float32x4_t vdin5_3456 = vextq_f32(vdatain50, vdatain51, 3);
+
+                                float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+
+                                float32x4_t vsum = vmulq_f32(vdin0_1234, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin1_1234, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin2_1234, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin3_1234, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin4_1234, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin5_1234, vweights60);
+                                
+                                //out
+                                float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                
+                                float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+
+                                float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights11, 2);
+                                float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                                float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                                float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                                float32x4_t vw4_4500 = vsetq_lane_f32(0.f, vweights51, 2);
+                                float32x4_t vw5_4500 = vsetq_lane_f32(0.f, vweights61, 2);
+                                
+                                vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                                vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                                vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                                vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                                vsum = vmlaq_f32(vsum, vdin4_5670, vw4_4500);
+                                vsum = vmlaq_f32(vsum, vdin5_5670, vw5_4500);
+                                float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+
+                                //2 23456-01234
+                                
+                                vsum = vmulq_f32(vdin0_2345, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin1_2345, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin2_2345, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin3_2345, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin4_2345, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin5_2345, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                                //out
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                                vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                
+                                vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights11);
+                                vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights21);
+                                vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights31);
+                                vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights41);
+                                vsum1 = vmlaq_f32(vsum1, vdin4_6700, vweights51);
+                                vsum1 = vmlaq_f32(vsum1, vdin5_6700, vweights61);
+                                
+                                vtotal = vget_low_f32(vsum1);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+                                
+                                //1 3456 - 0123
+                                
+                                vsum = vmulq_f32(vdin0_3456, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin1_3456, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin2_3456, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin3_3456, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin4_3456, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin5_3456, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++; 
+                            } else {//mid
+                                
+                                float32x4_t vdatain00 = vld1q_f32(inptr_ch0);
+                                float32x4_t vdatain01 = vld1q_f32(inptr_ch0 + 4);
+                                float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                //1 123456-012345
+                                float32x4_t vdin0_1234 = vextq_f32(vdatain00, vdatain01, 1);
+                                float32x4_t vdin1_1234 = vextq_f32(vdatain10, vdatain11, 1);
+                                float32x4_t vdin2_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                                float32x4_t vdin3_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                                float32x4_t vdin4_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                                float32x4_t vdin5_1234 = vextq_f32(vdatain50, vdatain51, 1);
+                                float32x4_t vdin6_1234 = vextq_f32(vdatain60, vdatain61, 1);
+                                float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                                float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights60 = vld1q_f32(weight_ch_in + 42);
+
+                                float32x4_t vsum = vmulq_f32(vdin0_1234, vweights00);
+                                vsum = vmlaq_f32(vsum, vdin1_1234, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin2_1234, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin3_1234, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin4_1234, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin5_1234, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin6_1234, vweights60);
+                                
+                                //out
+                                float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+
+                                float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                                vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                                float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                float32x4_t vweights61 = vld1q_f32(weight_ch_in + 46);
+                                vweights61 = vsetq_lane_f32(0.f, vweights61, 3);
+
+                                float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights01, 2);
+                                float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights11, 2);
+                                float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                                float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                                float32x4_t vw4_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                                float32x4_t vw5_4500 = vsetq_lane_f32(0.f, vweights51, 2);
+                                float32x4_t vw6_4500 = vsetq_lane_f32(0.f, vweights61, 2);
+                                float32x4_t vdin0_5670 = vextq_f32(vdatain01, vzero, 1);
+                                float32x4_t vdin1_5670 = vextq_f32(vdatain11, vzero, 1);
+                                float32x4_t vdin2_5670 = vextq_f32(vdatain21, vzero, 1);
+                                float32x4_t vdin3_5670 = vextq_f32(vdatain31, vzero, 1);
+                                float32x4_t vdin4_5670 = vextq_f32(vdatain41, vzero, 1);
+                                float32x4_t vdin5_5670 = vextq_f32(vdatain51, vzero, 1);
+                                float32x4_t vdin6_5670 = vextq_f32(vdatain61, vzero, 1);
+                                vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                                vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                                vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                                vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                                vsum = vmlaq_f32(vsum, vdin4_5670, vw4_4500);
+                                vsum = vmlaq_f32(vsum, vdin5_5670, vw5_4500);
+                                vsum = vmlaq_f32(vsum, vdin6_5670, vw6_4500);
+                                float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+
+                                //2 23456-01234
+                                float32x4_t vdin0_2345 = vextq_f32(vdatain00, vdatain01, 2);
+                                float32x4_t vdin1_2345 = vextq_f32(vdatain10, vdatain11, 2);
+                                float32x4_t vdin2_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                                float32x4_t vdin3_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                                float32x4_t vdin4_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                                float32x4_t vdin5_2345 = vextq_f32(vdatain50, vdatain51, 2);
+                                float32x4_t vdin6_2345 = vextq_f32(vdatain60, vdatain61, 2);
+                                vsum = vmulq_f32(vdin0_2345, vweights00);
+                                vsum = vmlaq_f32(vsum, vdin1_2345, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin2_2345, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin3_2345, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin4_2345, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin5_2345, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin6_2345, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                                //out
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                                vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                float32x4_t vdin0_6700 = vextq_f32(vdatain01, vzero, 2);
+                                float32x4_t vdin1_6700 = vextq_f32(vdatain11, vzero, 2);
+                                float32x4_t vdin2_6700 = vextq_f32(vdatain21, vzero, 2);
+                                float32x4_t vdin3_6700 = vextq_f32(vdatain31, vzero, 2);
+                                float32x4_t vdin4_6700 = vextq_f32(vdatain41, vzero, 2);
+                                float32x4_t vdin5_6700 = vextq_f32(vdatain51, vzero, 2);
+                                float32x4_t vdin6_6700 = vextq_f32(vdatain61, vzero, 2);
+                                vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights01);
+                                vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights11);
+                                vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights21);
+                                vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights31);
+                                vsum1 = vmlaq_f32(vsum1, vdin4_6700, vweights41);
+                                vsum1 = vmlaq_f32(vsum1, vdin5_6700, vweights51);
+                                vsum1 = vmlaq_f32(vsum1, vdin6_6700, vweights61);
+                                
+                                vtotal = vget_low_f32(vsum1);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++;
+                                
+                                //1 3456 - 0123
+                                float32x4_t vdin0_3456 = vextq_f32(vdatain00, vdatain01, 3);
+                                float32x4_t vdin1_3456 = vextq_f32(vdatain10, vdatain11, 3);
+                                float32x4_t vdin2_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                                float32x4_t vdin3_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                                float32x4_t vdin4_3456 = vextq_f32(vdatain40, vdatain41, 3);
+                                float32x4_t vdin5_3456 = vextq_f32(vdatain50, vdatain51, 3);
+                                float32x4_t vdin6_3456 = vextq_f32(vdatain60, vdatain61, 3);
+                                vsum = vmulq_f32(vdin0_3456, vweights00);
+                                vsum = vmlaq_f32(vsum, vdin1_3456, vweights10);
+                                vsum = vmlaq_f32(vsum, vdin2_3456, vweights20);
+                                vsum = vmlaq_f32(vsum, vdin3_3456, vweights30);
+                                vsum = vmlaq_f32(vsum, vdin4_3456, vweights40);
+                                vsum = vmlaq_f32(vsum, vdin5_3456, vweights50);
+                                vsum = vmlaq_f32(vsum, vdin6_3456, vweights60);
+                                vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                vtotal = vpadd_f32(vtotal, vtotal);
+                                vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                vdataout = vld1_f32(outptr_ch_wh);
+                                vdataout = vadd_f32(vdataout, vtotal);
+                                vst1_f32(outptr_ch_wh, vdataout);
+                                if(flag_relu)
+                                    outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                outptr_ch_wh++; 
+                            }
+                        } else if (h == h_out - kernel_h_even){//3 123456
+                            int w = 0;
+                            for (w = 0; w < 3; w++){
+                                float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                                float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                                vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                                float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                 
+                                if (w == 0){//3456
+                                    float32x4_t vw0_3456 = vextq_f32(vweights00, vweights01, 3);
+                                    float32x4_t vw1_3456 = vextq_f32(vweights10, vweights11, 3);
+                                    float32x4_t vw2_3456 = vextq_f32(vweights20, vweights21, 3);
+                                    float32x4_t vw3_3456 = vextq_f32(vweights30, vweights31, 3);
+                                    float32x4_t vw4_3456 = vextq_f32(vweights40, vweights41, 3);
+                                    float32x4_t vw5_3456 = vextq_f32(vweights50, vweights51, 3);
+                                    //load data
+                                    float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    
+                                    float32x4_t vsum = vmulq_f32(vdatain10, vw0_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain20, vw1_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw2_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw3_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw4_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw5_3456);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                        outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 1){//23456
+                                    float32x4_t vw0_2345 = vextq_f32(vweights00, vweights01, 2);
+                                    float32x4_t vw1_2345 = vextq_f32(vweights10, vweights11, 2);
+                                    float32x4_t vw2_2345 = vextq_f32(vweights20, vweights21, 2);
+                                    float32x4_t vw3_2345 = vextq_f32(vweights30, vweights31, 2);
+                                    float32x4_t vw4_2345 = vextq_f32(vweights40, vweights41, 2);
+                                    float32x4_t vw5_2345 = vextq_f32(vweights50, vweights51, 2);
+                                    //load data
+                                    float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    float32x4_t vsum = vmulq_f32(vdatain10, vw0_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain20, vw1_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw2_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw3_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw4_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw5_2345);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 2);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 2);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 2);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 2);
+                                    float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 2);
+                                    float32x4_t vw5_5670 = vextq_f32(vweights51, vzero, 2);
+
+                                    float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                    float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+
+                                    vsum1 = vmlaq_f32(vsum1, vdatain11, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain21, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw3_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw4_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw5_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 2){//123456
+                                    float32x4_t vw0_1234 = vextq_f32(vweights00, vweights01, 1);
+                                    float32x4_t vw1_1234 = vextq_f32(vweights10, vweights11, 1);
+                                    float32x4_t vw2_1234 = vextq_f32(vweights20, vweights21, 1);
+                                    float32x4_t vw3_1234 = vextq_f32(vweights30, vweights31, 1);
+                                    float32x4_t vw4_1234 = vextq_f32(vweights40, vweights41, 1);
+                                    float32x4_t vw5_1234 = vextq_f32(vweights50, vweights51, 1);
+                                    //load data
+                                    float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    float32x4_t vsum = vmulq_f32(vdatain10, vw0_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain20, vw1_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw2_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw3_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw4_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw5_1234);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 1);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 1);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 1);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 1);
+                                    float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 1);
+                                    float32x4_t vw5_5670 = vextq_f32(vweights51, vzero, 1);
+                                    float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                                    float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+
+                                    vsum1 = vmlaq_f32(vsum1, vdatain11, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain21, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw3_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw4_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw5_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vdataout, vtotal);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                        outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }
+                            } 
+                            //right
+                           //right
+                            inptr_ch1 += w_in - 7;
+                            inptr_ch2 += w_in - 7;
+                            inptr_ch3 += w_in - 7;
+                            inptr_ch4 += w_in - 7;
+                            inptr_ch5 += w_in - 7;
+                            inptr_ch6 += w_in - 7;
+                            outptr_ch_wh +=w_out - 6;
+                           // printf("inptr_ch1: %x, inptr_ch2: %x, inptr_ch3: %x, inptr_ch4: %x, inptr_ch5: %x, inptr_ch6: %x \n", \
+                                     inptr_ch1, inptr_ch2, inptr_ch3, inptr_ch4, inptr_ch5, inptr_ch6);
+                            float32x4_t vdatain10 = vld1q_f32(inptr_ch1);
+                            float32x4_t vdatain11 = vld1q_f32(inptr_ch1 + 4);
+                            float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                            float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                            float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                            float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                            float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                            float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                            float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                            float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                            float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                            float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+
+                            //1 123456-012345
+                            float32x4_t vdin0_1234 = vextq_f32(vdatain10, vdatain11, 1);
+                            float32x4_t vdin1_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                            float32x4_t vdin2_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                            float32x4_t vdin3_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                            float32x4_t vdin4_1234 = vextq_f32(vdatain50, vdatain51, 1);
+                            float32x4_t vdin5_1234 = vextq_f32(vdatain60, vdatain61, 1);
+                            float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                            float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                            float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                            float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                            float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                            float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+
+                            float32x4_t vsum = vmulq_f32(vdin0_1234, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_1234, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_1234, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_1234, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_1234, vweights40);
+                            vsum = vmlaq_f32(vsum, vdin5_1234, vweights50);
+                                
+                            //out
+                            float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                            
+                            float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                            vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                            float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                            vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                            float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                            vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                            float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                            vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                            float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                            vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                            float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                            vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                            float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights01, 2);
+                            float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights11, 2);
+                            float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                            float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                            float32x4_t vw4_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                            float32x4_t vw5_4500 = vsetq_lane_f32(0.f, vweights51, 2);
+                            float32x4_t vdin0_5670 = vextq_f32(vdatain11, vzero, 1);
+                            float32x4_t vdin1_5670 = vextq_f32(vdatain21, vzero, 1);
+                            float32x4_t vdin2_5670 = vextq_f32(vdatain31, vzero, 1);
+                            float32x4_t vdin3_5670 = vextq_f32(vdatain41, vzero, 1);
+                            float32x4_t vdin4_5670 = vextq_f32(vdatain51, vzero, 1);
+                            float32x4_t vdin5_5670 = vextq_f32(vdatain61, vzero, 1);
+                            vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                            vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                            vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                            vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                            vsum = vmlaq_f32(vsum, vdin4_5670, vw4_4500);
+                            vsum = vmlaq_f32(vsum, vdin5_5670, vw5_4500);
+                            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+
+                            //2 23456-01234;
+                            float32x4_t vdin0_2345 = vextq_f32(vdatain10, vdatain11, 2);
+                            float32x4_t vdin1_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                            float32x4_t vdin2_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                            float32x4_t vdin3_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                            float32x4_t vdin4_2345 = vextq_f32(vdatain50, vdatain51, 2);
+                            float32x4_t vdin5_2345 = vextq_f32(vdatain60, vdatain61, 2);
+                            vsum = vmulq_f32(vdin0_2345, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_2345, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_2345, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_2345, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_2345, vweights40);
+                            vsum = vmlaq_f32(vsum, vdin5_2345, vweights50);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                            //out
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                            vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                            float32x4_t vdin0_6700 = vextq_f32(vdatain11, vzero, 2);
+                            float32x4_t vdin1_6700 = vextq_f32(vdatain21, vzero, 2);
+                            float32x4_t vdin2_6700 = vextq_f32(vdatain31, vzero, 2);
+                            float32x4_t vdin3_6700 = vextq_f32(vdatain41, vzero, 2);
+                            float32x4_t vdin4_6700 = vextq_f32(vdatain51, vzero, 2);
+                            float32x4_t vdin5_6700 = vextq_f32(vdatain61, vzero, 2);
+                            vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights01);
+                            vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights11);
+                            vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights21);
+                            vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights31);
+                            vsum1 = vmlaq_f32(vsum1, vdin4_6700, vweights41);
+                            vsum1 = vmlaq_f32(vsum1, vdin5_6700, vweights51);
+                                
+                            vtotal = vget_low_f32(vsum1);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+                                
+                            //1 3456 - 0123
+                            float32x4_t vdin0_3456 = vextq_f32(vdatain10, vdatain11, 3);
+                            float32x4_t vdin1_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                            float32x4_t vdin2_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                            float32x4_t vdin3_3456 = vextq_f32(vdatain40, vdatain41, 3);
+                            float32x4_t vdin4_3456 = vextq_f32(vdatain50, vdatain51, 3);
+                            float32x4_t vdin5_3456 = vextq_f32(vdatain60, vdatain61, 3);
+                            vsum = vmulq_f32(vdin0_3456, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_3456, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_3456, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_3456, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_3456, vweights40);
+                            vsum = vmlaq_f32(vsum, vdin5_3456, vweights50);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++; 
+                                    
+                        }else if (h == h_out - kernel_h_even + 1){//1
+                            int w = 0;
+                            for (w = 0; w < w_out - kernel_w_even; w++){
+                                float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                                float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                                vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                                float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+                                float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                                vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+                                float32x4_t vweights50 = vld1q_f32(weight_ch_in + 35);
+                                float32x4_t vweights51 = vld1q_f32(weight_ch_in + 39);
+                                vweights51 = vsetq_lane_f32(0.f, vweights51, 3);
+                                
+                                if (w == 0){//3456
+                                    float32x4_t vw0_3456 = vextq_f32(vweights00, vweights01, 3);
+                                    float32x4_t vw1_3456 = vextq_f32(vweights10, vweights11, 3);
+                                    float32x4_t vw2_3456 = vextq_f32(vweights20, vweights21, 3);
+                                    float32x4_t vw3_3456 = vextq_f32(vweights30, vweights31, 3);
+                                    float32x4_t vw4_3456 = vextq_f32(vweights40, vweights41, 3);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+
+                                    float32x4_t vsum = vmulq_f32(vdatain20, vw0_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw1_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw2_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw3_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw4_3456);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 1){//23456
+                                    float32x4_t vw0_2345 = vextq_f32(vweights00, vweights01, 2);
+                                    float32x4_t vw1_2345 = vextq_f32(vweights10, vweights11, 2);
+                                    float32x4_t vw2_2345 = vextq_f32(vweights20, vweights21, 2);
+                                    float32x4_t vw3_2345 = vextq_f32(vweights30, vweights31, 2);
+                                    float32x4_t vw4_2345 = vextq_f32(vweights40, vweights41, 2);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    float32x4_t vsum = vmulq_f32(vdatain20, vw0_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw1_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw2_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw3_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw4_2345);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                    float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 2);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 2);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 2);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 2);
+                                    float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 2);
+                                    vsum1 = vmlaq_f32(vsum1, vdatain21, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw3_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw4_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vtotal = vget_low_f32(vsum1);
+                                    vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 2){//123456
+                                    float32x4_t vw0_1234 = vextq_f32(vweights00, vweights01, 1);
+                                    float32x4_t vw1_1234 = vextq_f32(vweights10, vweights11, 1);
+                                    float32x4_t vw2_1234 = vextq_f32(vweights20, vweights21, 1);
+                                    float32x4_t vw3_1234 = vextq_f32(vweights30, vweights31, 1);
+                                    float32x4_t vw4_1234 = vextq_f32(vweights40, vweights41, 1);
+                                    float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    float32x4_t vsum = vmulq_f32(vdatain20, vw0_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain30, vw1_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw2_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw3_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw4_1234);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 1);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 1);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 1);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 1);
+                                    float32x4_t vw4_5670 = vextq_f32(vweights41, vzero, 1);
+                                    float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+
+                                    vsum1 = vmlaq_f32(vsum1, vdatain21, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw3_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw4_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vdataout, vtotal);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }
+                            } 
+                            //right
+                            inptr_ch2 += w_in - 7;
+                            inptr_ch3 += w_in - 7;
+                            inptr_ch4 += w_in - 7;
+                            inptr_ch5 += w_in - 7;
+                            inptr_ch6 += w_in - 7;
+                            outptr_ch_wh +=w_out - 6;
+                            float32x4_t vdatain20 = vld1q_f32(inptr_ch2);
+                            float32x4_t vdatain21 = vld1q_f32(inptr_ch2 + 4);
+                            float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                            float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                            float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                            float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                            float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                            float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                            float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                            float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+
+                            //1 123456-012345
+                            float32x4_t vdin0_1234 = vextq_f32(vdatain20, vdatain21, 1);
+                            float32x4_t vdin1_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                            float32x4_t vdin2_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                            float32x4_t vdin3_1234 = vextq_f32(vdatain50, vdatain51, 1);
+                            float32x4_t vdin4_1234 = vextq_f32(vdatain60, vdatain61, 1);
+                            float32x4_t vweights00 = vld1q_f32(weight_ch_in );
+                            float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                            float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                            float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                            float32x4_t vweights40 = vld1q_f32(weight_ch_in + 28);
+
+                            float32x4_t vsum = vmulq_f32(vdin0_1234, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_1234, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_1234, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_1234, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_1234, vweights40);
+                                
+                            //out
+                            float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                            float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                            vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                            float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                            vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                            float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                            vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                            float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                            vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                            float32x4_t vweights41 = vld1q_f32(weight_ch_in + 32);
+                            vweights41 = vsetq_lane_f32(0.f, vweights41, 3);
+
+                            float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights01, 2);
+                            float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights11, 2);
+                            float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                            float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                            float32x4_t vw4_4500 = vsetq_lane_f32(0.f, vweights41, 2);
+                            float32x4_t vdin0_5670 = vextq_f32(vdatain21, vzero, 1);
+                            float32x4_t vdin1_5670 = vextq_f32(vdatain31, vzero, 1);
+                            float32x4_t vdin2_5670 = vextq_f32(vdatain41, vzero, 1);
+                            float32x4_t vdin3_5670 = vextq_f32(vdatain51, vzero, 1);
+                            float32x4_t vdin4_5670 = vextq_f32(vdatain61, vzero, 1);
+                            vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                            vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                            vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                            vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                            vsum = vmlaq_f32(vsum, vdin4_5670, vw4_4500);
+                            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                               outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+
+                            //2 23456-01234;
+                            float32x4_t vdin0_2345 = vextq_f32(vdatain20, vdatain21, 2);
+                            float32x4_t vdin1_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                            float32x4_t vdin2_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                            float32x4_t vdin3_2345 = vextq_f32(vdatain50, vdatain51, 2);
+                            float32x4_t vdin4_2345 = vextq_f32(vdatain60, vdatain61, 2);
+                            vsum = vmulq_f32(vdin0_2345, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_2345, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_2345, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_2345, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_2345, vweights40);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                            //out
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                            vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                            float32x4_t vdin0_6700 = vextq_f32(vdatain21, vzero, 2);
+                            float32x4_t vdin1_6700 = vextq_f32(vdatain31, vzero, 2);
+                            float32x4_t vdin2_6700 = vextq_f32(vdatain41, vzero, 2);
+                            float32x4_t vdin3_6700 = vextq_f32(vdatain51, vzero, 2);
+                            float32x4_t vdin4_6700 = vextq_f32(vdatain61, vzero, 2);
+                            vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights01);
+                            vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights11);
+                            vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights21);
+                            vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights31);
+                            vsum1 = vmlaq_f32(vsum1, vdin4_6700, vweights41);
+                                
+                            vtotal = vget_low_f32(vsum1);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+                                
+                            //1 3456 - 0123
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            float32x4_t vdin0_3456 = vextq_f32(vdatain20, vdatain21, 3);
+                            float32x4_t vdin1_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                            float32x4_t vdin2_3456 = vextq_f32(vdatain40, vdatain41, 3);
+                            float32x4_t vdin3_3456 = vextq_f32(vdatain50, vdatain51, 3);
+                            float32x4_t vdin4_3456 = vextq_f32(vdatain60, vdatain61, 3);
+                            vsum = vmulq_f32(vdin0_3456, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_3456, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_3456, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_3456, vweights30);
+                            vsum = vmlaq_f32(vsum, vdin4_3456, vweights40);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                               outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++; 
+                        }else if (h == h_out - kernel_h_even + 2){//2
+                            for (int w = 0; w < w_out - kernel_w_even; w++){
+                                float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                                float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                                vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                                float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                                float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                                vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                                float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                                float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                                vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                                float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+                                float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                                vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+                                if (w == 0){//3456
+                                    float32x4_t vw0_3456 = vextq_f32(vweights00, vweights01, 3);
+                                    float32x4_t vw1_3456 = vextq_f32(vweights10, vweights11, 3);
+                                    float32x4_t vw2_3456 = vextq_f32(vweights20, vweights21, 3);
+                                    float32x4_t vw3_3456 = vextq_f32(vweights30, vweights31, 3);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    
+
+                                    float32x4_t vsum = vmulq_f32(vdatain30, vw0_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw1_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw2_3456);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw3_3456);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    vtotal = vset_lane_f32(0.f, vtotal, 1);
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 1){//23456
+                                    float32x4_t vw0_2345 = vextq_f32(vweights00, vweights01, 2);
+                                    float32x4_t vw1_2345 = vextq_f32(vweights10, vweights11, 2);
+                                    float32x4_t vw2_2345 = vextq_f32(vweights20, vweights21, 2);
+                                    float32x4_t vw3_2345 = vextq_f32(vweights30, vweights31, 2);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+
+                                    float32x4_t vsum = vmulq_f32(vdatain30, vw0_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw1_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw2_2345);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw3_2345);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+                                    
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 2);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 2);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 2);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 2);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw3_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vtotal, vdataout);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }else if (w == 2){//123456
+                                    float32x4_t vw0_1234 = vextq_f32(vweights00, vweights01, 1);
+                                    float32x4_t vw1_1234 = vextq_f32(vweights10, vweights11, 1);
+                                    float32x4_t vw2_1234 = vextq_f32(vweights20, vweights21, 1);
+                                    float32x4_t vw3_1234 = vextq_f32(vweights30, vweights31, 1);
+                                    float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                                    float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                                    float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                                    float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                                    float32x4_t vsum = vmulq_f32(vdatain30, vw0_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain40, vw1_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain50, vw2_1234);
+                                    vsum = vmlaq_f32(vsum, vdatain60, vw3_1234);
+                                    float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                                    vtotal = vpadd_f32(vtotal, vtotal);//0+1+2+3
+                                    float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal, 0));
+                                    vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                                    float32x4_t vw0_5670 = vextq_f32(vweights01, vzero, 1);
+                                    float32x4_t vw1_5670 = vextq_f32(vweights11, vzero, 1);
+                                    float32x4_t vw2_5670 = vextq_f32(vweights21, vzero, 1);
+                                    float32x4_t vw3_5670 = vextq_f32(vweights31, vzero, 1);
+                                    float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                                    float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                                    float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                                    float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                                    vsum1 = vmlaq_f32(vsum1, vdatain31, vw0_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain41, vw1_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain51, vw2_5670);//6
+                                    vsum1 = vmlaq_f32(vsum1, vdatain61, vw3_5670);//6
+                                    vtotal = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));//x, 0
+                                    float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                                    vdataout = vadd_f32(vdataout, vtotal);
+                                    vst1_f32(outptr_ch_wh, vdataout);
+                                    if(flag_relu)
+                                       outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                                    outptr_ch_wh++;
+                                    continue;
+                                }
+                            } 
+                            //right
+                            inptr_ch3 += w_in - 7;
+                            inptr_ch4 += w_in - 7;
+                            inptr_ch5 += w_in - 7;
+                            inptr_ch6 += w_in - 7;
+                            outptr_ch_wh +=w_out - 6;
+                            float32x4_t vdatain30 = vld1q_f32(inptr_ch3);
+                            float32x4_t vdatain31 = vld1q_f32(inptr_ch3 + 4);
+                            float32x4_t vdatain40 = vld1q_f32(inptr_ch4);
+                            float32x4_t vdatain41 = vld1q_f32(inptr_ch4 + 4);
+                            float32x4_t vdatain50 = vld1q_f32(inptr_ch5);
+                            float32x4_t vdatain51 = vld1q_f32(inptr_ch5 + 4);
+                            float32x4_t vdatain60 = vld1q_f32(inptr_ch6);
+                            float32x4_t vdatain61 = vld1q_f32(inptr_ch6 + 4);
+                            float32x4_t vweights00 = vld1q_f32(weight_ch_in);
+                            float32x4_t vweights10 = vld1q_f32(weight_ch_in + 7);
+                            float32x4_t vweights20 = vld1q_f32(weight_ch_in + 14);
+                            float32x4_t vweights30 = vld1q_f32(weight_ch_in + 21);
+
+                            //1 123456-012345
+                            float32x4_t vdin0_1234 = vextq_f32(vdatain30, vdatain31, 1);
+                            float32x4_t vdin1_1234 = vextq_f32(vdatain40, vdatain41, 1);
+                            float32x4_t vdin2_1234 = vextq_f32(vdatain50, vdatain51, 1);
+                            float32x4_t vdin3_1234 = vextq_f32(vdatain60, vdatain61, 1);
+
+                            float32x4_t vsum = vmulq_f32(vdin0_1234, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_1234, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_1234, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_1234, vweights30);
+                                
+                            //out
+                            float32x2_t vdataout = vld1_f32(outptr_ch_wh);
+                            
+                            float32x4_t vweights01 = vld1q_f32(weight_ch_in + 4);
+                            vweights01 = vsetq_lane_f32(0.f, vweights01, 3);
+                            float32x4_t vweights11 = vld1q_f32(weight_ch_in + 11);
+                            vweights11 = vsetq_lane_f32(0.f, vweights11, 3);
+                            float32x4_t vweights21 = vld1q_f32(weight_ch_in + 18);
+                            vweights21 = vsetq_lane_f32(0.f, vweights21, 3);
+                            float32x4_t vweights31 = vld1q_f32(weight_ch_in + 25);
+                            vweights31 = vsetq_lane_f32(0.f, vweights31, 3);
+
+                            float32x4_t vw0_4500 = vsetq_lane_f32(0.f, vweights01, 2);
+                            float32x4_t vw1_4500 = vsetq_lane_f32(0.f, vweights11, 2);
+                            float32x4_t vw2_4500 = vsetq_lane_f32(0.f, vweights21, 2);
+                            float32x4_t vw3_4500 = vsetq_lane_f32(0.f, vweights31, 2);
+                            float32x4_t vdin0_5670 = vextq_f32(vdatain31, vzero, 1);
+                            float32x4_t vdin1_5670 = vextq_f32(vdatain41, vzero, 1);
+                            float32x4_t vdin2_5670 = vextq_f32(vdatain51, vzero, 1);
+                            float32x4_t vdin3_5670 = vextq_f32(vdatain61, vzero, 1);
+                            vsum = vmlaq_f32(vsum, vdin0_5670, vw0_4500);
+                            vsum = vmlaq_f32(vsum, vdin1_5670, vw1_4500);
+                            vsum = vmlaq_f32(vsum, vdin2_5670, vw2_4500);
+                            vsum = vmlaq_f32(vsum, vdin3_5670, vw3_4500);
+                            float32x2_t vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+
+                            //2 23456-01234;
+                            float32x4_t vdin0_2345 = vextq_f32(vdatain30, vdatain31, 2);
+                            float32x4_t vdin1_2345 = vextq_f32(vdatain40, vdatain41, 2);
+                            float32x4_t vdin2_2345 = vextq_f32(vdatain50, vdatain51, 2);
+                            float32x4_t vdin3_2345 = vextq_f32(vdatain60, vdatain61, 2);
+                            vsum = vmulq_f32(vdin0_2345, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_2345, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_2345, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_2345, vweights30);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                                
+                            //out
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            float32x4_t vsum1 = vdupq_n_f32(vget_lane_f32(vtotal,0));
+                            vsum1 = vextq_f32(vsum1, vzero, 3);
+
+                            float32x4_t vdin0_6700 = vextq_f32(vdatain31, vzero, 2);
+                            float32x4_t vdin1_6700 = vextq_f32(vdatain41, vzero, 2);
+                            float32x4_t vdin2_6700 = vextq_f32(vdatain51, vzero, 2);
+                            float32x4_t vdin3_6700 = vextq_f32(vdatain61, vzero, 2);
+                            vsum1 = vmlaq_f32(vsum1, vdin0_6700, vweights01);
+                            vsum1 = vmlaq_f32(vsum1, vdin1_6700, vweights11);
+                            vsum1 = vmlaq_f32(vsum1, vdin2_6700, vweights21);
+                            vsum1 = vmlaq_f32(vsum1, vdin3_6700, vweights31);
+                                
+                            vtotal = vget_low_f32(vsum1);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++;
+                                
+                            //1 3456 - 0123
+                            float32x4_t vdin0_3456 = vextq_f32(vdatain30, vdatain31, 3);
+                            float32x4_t vdin1_3456 = vextq_f32(vdatain40, vdatain41, 3);
+                            float32x4_t vdin2_3456 = vextq_f32(vdatain50, vdatain51, 3);
+                            float32x4_t vdin3_3456 = vextq_f32(vdatain60, vdatain61, 3);
+                            vsum = vmulq_f32(vdin0_3456, vweights00);
+                            vsum = vmlaq_f32(vsum, vdin1_3456, vweights10);
+                            vsum = vmlaq_f32(vsum, vdin2_3456, vweights20);
+                            vsum = vmlaq_f32(vsum, vdin3_3456, vweights30);
+                            vtotal = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));
+                            vtotal = vpadd_f32(vtotal, vtotal);
+                            vtotal = vset_lane_f32(0.f, vtotal, 1);
+                            vdataout = vld1_f32(outptr_ch_wh);
+                            vdataout = vadd_f32(vdataout, vtotal);
+                            vst1_f32(outptr_ch_wh, vdataout);
+                            if(flag_relu)
+                                outptr_ch_wh[0] = outptr_ch_wh[0] > 0 ? outptr_ch_wh[0]: 0.f;
+                            outptr_ch_wh++; 
+                        }
+                    }
+                    
+                }
+                
+            }
+        }
+    }
+}
+}//anakin
+}//saber
+#endif //USE_ARM_PLACE
\ No newline at end of file
diff --git a/saber/funcs/impl/arm/impl/conv_arm_depthwise.cpp b/saber/funcs/impl/arm/impl/conv_arm_depthwise.cpp
index 57390da..ee9ecab 100644
--- a/saber/funcs/impl/arm/impl/conv_arm_depthwise.cpp
+++ b/saber/funcs/impl/arm/impl/conv_arm_depthwise.cpp
@@ -1133,6 +1133,8 @@ void conv_depthwise_3x3s2p1_bias(float* dout, const float* din, \
 
             // process bottom pad if needed
             if (size_pad_bottom) {
+                din0_ptr = dr0;
+                din1_ptr = dr1;
 #ifdef __aarch64__
                 // todo
 #else
@@ -2017,6 +2019,8 @@ void conv_depthwise_3x3s2p1_bias_relu(float* dout, const float* din, \
     int size_right_remain = (((w_out + 1) >> 1) << 1) - w_out;
     int cnt_col = ((w_out + 1) >> 1) - 2;
 
+    const float zero[6] = {0.f, 0.f, 0.f, 0.f, 0.f, 0.f};
+
     if (size_right_remain == 0 || size_pad_right == 0) {
         right_pad_idx[0] = 1;
     }
@@ -2339,8 +2343,10 @@ void conv_depthwise_3x3s2p1_bias_relu(float* dout, const float* din, \
                 dr2 = dr1 + w_in;
             } // end of process mid rows
 
-            // process bottom pad if needed
+            //! process bottom pad if needed
             if (size_pad_bottom) {
+                din0_ptr = dr0;
+                din1_ptr = dr1;
 #ifdef __aarch64__
                 // todo
 #else
@@ -2348,100 +2354,101 @@ void conv_depthwise_3x3s2p1_bias_relu(float* dout, const float* din, \
                 asm volatile(
                 // process left pad
                 "pld [%[din0_ptr], #128]               @ preload data\n"
-                        "pld [%[din1_ptr], #128]               @ preload data\n"
+                        "pld [%[din1_ptr], #128]                @ preload data\n"
 
                         "vmov.u32 q11, #0 @ for left pad\n"
-                        "vld1.32  {d20-d21}, [%[din0_ptr]]!    @ load din r0\n"
-                        "vext.32 q7, q11, q10, #3 @ shift right 1 data\n"
-                        "vmul.f32 q8, q7, %q[wr0]  @mul weight 00, outr0\n"
-                        "vext.32  q7, q10, q11, #1   @ shift left r0\n"
-                        "vmul.f32 q9, q7, %q[wr0]    @mul weight 00, outr1\n"
+                        "vld1.32  {d20-d21}, [%[din0_ptr]]!     @ load din r0\n"
+                        "vld1.32  {d24-d25}, [%[din1_ptr]]!     @ load din r1\n"
 
-                        "vld1.32  {d24-d25}, [%[din1_ptr]]!    @ load din r1\n"
-                        "vext.32 q7, q11, q12, #3 @ shift right 1 data\n"
-                        "vmla.f32 q8, q7, %q[wr1]   @mul weight 10, outr0\n"
-                        "vext.32  q7, q12, q11, #1   @ shift left r1\n"
-                        "vmla.f32 q9, q7,  %q[wr1]   @mul weight 10, outr1\n"
+                        "vext.32 q7, q11, q10, #3               @ shift right 1 data\n"
+                        "vmul.f32 q8, q7, %q[wr0]               @ mul weight 00, outr0\n"
+                        "vext.32  q7, q10, q11, #1              @ shift left r0\n"
+                        "vmul.f32 q9, q7, %q[wr0]               @ mul weight 00, outr1\n"
 
-                        "vpadd.f32 d22, d16, d17  @ pair add of out0 \n"
-                        "vpadd.f32 d23, d18, d19  @ pair add of out1 \n"
-                        "vpadd.f32 d16, d22, d23  @ get finnal out0,1\n"
+                        "vext.32 q7, q11, q12, #3               @ shift right 1 data\n"
+                        "vmla.f32 q8, q7, %q[wr1]               @ mul weight 10, outr0\n"
+                        "vext.32  q7, q12, q11, #1              @ shift left r1\n"
+                        "vmla.f32 q9, q7,  %q[wr1]              @ mul weight 10, outr1\n"
 
-                        "vadd.f32  d17, d16, %e[bias]  @ add bias \n"
+                        "vpadd.f32 d22, d16, d17                @ pair add of out0 \n"
+                        "vpadd.f32 d23, d18, d19                @ pair add of out1 \n"
+                        "vpadd.f32 d16, d22, d23                @ get finnal out0,1\n"
+
+                        "vadd.f32  d17, d16, %e[bias]           @ add bias \n"
                         "vmax.f32  d17, d17, %e[vzero]          @ relu\n"
 
-                        "vst1.32  {d17},   [%[dout_ptr1]]!  @ store result, add pointer\n"
+                        "vst1.32  {d17},   [%[dout_ptr1]]!      @ store result, add pointer\n"
 
-                        "sub %[din0_ptr], #4 @ 1pad + 2 float data overlap\n"
-                        "sub %[din1_ptr], #4 @ 1pad + 2 float data overlap\n"
+                        "sub %[din0_ptr], #4                    @ 1pad + 2 float data overlap\n"
+                        "sub %[din1_ptr], #4                    @ 1pad + 2 float data overlap\n"
 
                         // process mid cols
-                        "cmp %[cnt], #1                             @ check whether has mid loop\n"
+                        "cmp %[cnt], #1                         @ check whether has mid loop\n"
                         "blt  s2_bot_right_relu                 @ jump to rightpad\n"
                         "s2_bot_mid_relu:                       @ main loop start point\n"
-                        "pld [%[din0_ptr], #192]               @ preload data\n"
-                        "pld [%[din1_ptr], #192]               @ preload data\n"
-                        "vld1.32  {d20-d22}, [%[din0_ptr]]!    @ load din r0\n"
-                        "vmul.f32 q8, q10, %q[wr0]      @mul weight 00, outr0\n"
-                        "vext.32  q7, q10, q11, #2      @ shift left r1\n"
-                        "vmul.f32 q9, q7, %q[wr0]  @mul weight 00, outr1\n"
+                        "pld [%[din0_ptr], #192]                @ preload data\n"
+                        "pld [%[din1_ptr], #192]                @ preload data\n"
+                        "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                        "vmul.f32 q8, q10, %q[wr0]              @ mul weight 00, outr0\n"
+                        "vext.32  q7, q10, q11, #2              @ shift left r1\n"
+                        "vmul.f32 q9, q7, %q[wr0]               @ mul weight 00, outr1\n"
 
-                        "vld1.32  {d24-d26}, [%[din1_ptr]]!    @ load din r1\n"
-                        "vmla.f32 q8, q12, %q[wr1]  @mul weight 10, outr0\n"
-                        "vext.32  q7, q12, q13, #2      @ shift left r2\n"
-                        "vmla.f32 q9, q7, %q[wr1]  @mul weight 10, outr1\n"
+                        "vld1.32  {d24-d26}, [%[din1_ptr]]!     @ load din r1\n"
+                        "vmla.f32 q8, q12, %q[wr1]              @ mul weight 10, outr0\n"
+                        "vext.32  q7, q12, q13, #2              @ shift left r2\n"
+                        "vmla.f32 q9, q7, %q[wr1]               @ mul weight 10, outr1\n"
 
-                        "vpadd.f32 d22, d16, d17  @ pair add of out0 \n"
-                        "vpadd.f32 d23, d18, d19 @ pair add of out1 \n"
-                        "vpadd.f32 d16, d22, d23 @ get finnal out0,1\n"
+                        "vpadd.f32 d22, d16, d17                @ pair add of out0 \n"
+                        "vpadd.f32 d23, d18, d19                @ pair add of out1 \n"
+                        "vpadd.f32 d16, d22, d23                @ get finnal out0,1\n"
 
-                        "vadd.f32  d17, d16, %e[bias]  @ add bias \n"
+                        "vadd.f32  d17, d16, %e[bias]           @ add bias \n"
                         "vmax.f32  d17, d17, %e[vzero]          @ relu\n"
 
-                        "vst1.32  {d17},   [%[dout_ptr1]]!  @ store result, add pointer\n"
+                        "vst1.32  {d17},   [%[dout_ptr1]]!      @ store result, add pointer\n"
 
-                        "sub %[din0_ptr], #8 @ 2 float data overlap with previous data\n"
-                        "sub %[din1_ptr], #8 @ 2 float data overlap with previous data\n"
+                        "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
+                        "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
 
-                        "subs %[cnt], #1 @ loop count minus 1\n"
-                        "bne    s2_bot_mid_relu @ jump to main loop start point\n"
+                        "subs %[cnt], #1                        @ loop count minus 1\n"
+                        "bne    s2_bot_mid_relu                 @ jump to main loop start point\n"
 
                         // process right pad
-                        "s2_bot_right_relu:    @ right pad entry\n"
-                        "vmov.u32  d31, #0 @ zero buf\n"
-                        "pld [%[din0_ptr], #192]               @ preload data\n"
-                        "pld [%[din1_ptr], #192]               @ preload data\n"
-                        "vld1.32  {d20-d22}, [%[din0_ptr]]!    @ load din r1\n"
-                        "vbif d21, d31, %e[mask_din] @ bit select, deal with right pad\n"
-                        "vmul.f32 q8, q10, %q[wr0]  @mul weight 00, outr0\n"
-                        "vbif d22, d31, %f[mask_din] @ bit select, deal with right pad\n"
-                        "vext.32  q7, q10, q11, #2      @ shift left r0\n"
-                        "vmul.f32 q9, q7, %q[wr0]  @mul weight 00, outr1\n"
+                        "s2_bot_right_relu:                     @ right pad entry\n"
+                        "vmov.u32  d31, #0                      @ zero buf\n"
+                        "pld [%[din0_ptr], #192]                @ preload data\n"
+                        "pld [%[din1_ptr], #192]                @ preload data\n"
+                        "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                        "vbif d21, d31, %e[mask_din]            @ bit select, deal with right pad\n"
+                        "vmul.f32 q8, q10, %q[wr0]              @ mul weight 00, outr0\n"
+                        "vbif d22, d31, %f[mask_din]            @ bit select, deal with right pad\n"
+                        "vext.32  q7, q10, q11, #2              @ shift left r0\n"
+                        "vmul.f32 q9, q7, %q[wr0]               @ mul weight 00, outr1\n"
 
-                        "vld1.32  {d24-d26}, [%[din1_ptr]]!    @ load din r1\n"
-                        "vbif d25, d31, %e[mask_din] @ bit select, deal with right pad\n"
+                        "vld1.32  {d24-d26}, [%[din1_ptr]]!     @ load din r1\n"
+                        "vbif d25, d31, %e[mask_din]            @ bit select, deal with right pad\n"
 
-                        "pld [%[dout_ptr1], #64]         @ preload data\n"
+                        "pld [%[dout_ptr1], #64]                @ preload data\n"
 
-                        "vmla.f32 q8, q12, %q[wr1]  @mul weight 10, outr0\n"
-                        "vbif d26, d31, %f[mask_din] @ bit select, deal with right pad\n"
-                        "vext.32  q7, q12, q13, #2      @ shift left r1\n"
-                        "vmla.f32 q9, q7, %q[wr1]  @mul weight 10, outr1\n"
+                        "vmla.f32 q8, q12, %q[wr1]              @ mul weight 10, outr0\n"
+                        "vbif d26, d31, %f[mask_din]            @ bit select, deal with right pad\n"
+                        "vext.32  q7, q12, q13, #2              @ shift left r1\n"
+                        "vmla.f32 q9, q7, %q[wr1]               @ mul weight 10, outr1\n"
 
-                        "vld1.32  {d20}, [%[dout_ptr1]]    @ load dout\n"
+                        "vld1.32  {d20}, [%[dout_ptr1]]         @ load dout\n"
 
-                        "vpadd.f32 d22, d16, d17  @ pair add of out0 \n"
-                        "vpadd.f32 d23, d18, d19 @ pair add of out1 \n"
-                        "vpadd.f32 d16, d22, d23 @ get finnal out0,1\n"
+                        "vpadd.f32 d22, d16, d17                @ pair add of out0 \n"
+                        "vpadd.f32 d23, d18, d19                @ pair add of out1 \n"
+                        "vpadd.f32 d16, d22, d23                @ get finnal out0,1\n"
 
-                        "vadd.f32  d17, d16, %e[bias]  @ add bias \n"
+                        "vadd.f32  d17, d16, %e[bias]           @ add bias \n"
                         "vmax.f32  d17, d17, %e[vzero]          @ relu\n"
 
-                        "vbif d17, d20, %e[mask_w] @ bit select\n"
+                        "vbif d17, d20, %e[mask_w]              @ bit select\n"
 
-                        "vst1.32  {d17}, [%[dout_ptr1]]!  @ store result, add pointer\n"
+                        "vst1.32  {d17}, [%[dout_ptr1]]!        @ store result, add pointer\n"
 
-                        "sub %[dout_ptr1], %[dout_ptr1], %[pad_right] @ sub \n"
+                        //"sub %[dout_ptr1], %[dout_ptr1], %[pad_right] @ sub \n"
 
                 :[dout_ptr1] "+r"(doutr0), [din0_ptr] "+r"(din0_ptr), \
                     [din1_ptr] "+r"(din1_ptr), [cnt] "+r"(cnt)
@@ -2452,7 +2459,7 @@ void conv_depthwise_3x3s2p1_bias_relu(float* dout, const float* din, \
                 :"q7", "q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
                 );
 #endif //__aarch64__
-            } // end of process bottom pad
+            } //! end of process bottom pad
         }
     }
 }
@@ -2461,4 +2468,4 @@ void conv_depthwise_3x3s2p1_bias_relu(float* dout, const float* din, \
 
 } //namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/impl/conv_arm_impl.cpp b/saber/funcs/impl/arm/impl/conv_arm_impl.cpp
index a931dde..9555c6e 100644
--- a/saber/funcs/impl/arm/impl/conv_arm_impl.cpp
+++ b/saber/funcs/impl/arm/impl/conv_arm_impl.cpp
@@ -141,25 +141,26 @@ inline bool is_a_ge_zero_and_a_lt_b(int a, int b) {
  * @param stride
  * @param data_col
  */
-template <typename dtype>
-void im2col(const dtype *data_im, const int channels, const int height, \
-                   const int width, const int kernel_h, const int kernel_w, \
-                   const int pad_h, const int pad_w, const int stride_h, const int stride_w, \
-                   dtype *data_col) {
-    const int output_h = (height + 2 * pad_h - kernel_h) / stride_h + 1;
-    const int output_w = (width + 2 * pad_w - kernel_w) / stride_w + 1;
+template <typename Dtype>
+void im2col(const Dtype* data_im, const int channels, const int height, const int width, \
+    const int kernel_h, const int kernel_w, const int pad_h, const int pad_w, \
+    const int stride_h, const int stride_w, const int dilation_h, const int dilation_w, \
+    Dtype* data_col) {
+
+    const int output_h = (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;
+    const int output_w = (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;
     const int channel_size = height * width;
     for (int channel = channels; channel--; data_im += channel_size) {
         for (int kernel_row = 0; kernel_row < kernel_h; kernel_row++) {
             for (int kernel_col = 0; kernel_col < kernel_w; kernel_col++) {
-                int input_row = -pad_h + kernel_row;
+                int input_row = -pad_h + kernel_row * dilation_h;
                 for (int output_rows = output_h; output_rows; output_rows--) {
                     if (!is_a_ge_zero_and_a_lt_b(input_row, height)) {
                         for (int output_cols = output_w; output_cols; output_cols--) {
                             *(data_col++) = 0;
                         }
                     } else {
-                        int input_col = -pad_w + kernel_col;
+                        int input_col = -pad_w + kernel_col * dilation_w;
                         for (int output_col = output_w; output_col; output_col--) {
                             if (is_a_ge_zero_and_a_lt_b(input_col, width)) {
                                 *(data_col++) = data_im[input_row * width + input_col];
@@ -231,27 +232,33 @@ void conv1x1s1_gemm(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOA
     int channel_size_out = w_out * h_out;
     int channel_size_in = w_in * h_in;
 
-    const int m = ch_out;
+    const int m = ch_out / group;
     const int n = h_out * w_out;
-    const int k = ch_in;
+    const int k = ch_in / group;
 
-    //! use gemv when the output channel size = 1
+    int weights_size_per_group = ch_out * ch_in / (group * group);
+
+        //! use gemv when the output channel size = 1
     if (n == 1) {
         for (int b = 0; b < num; ++b) {
-            float *data_out_batch = tensor_out.mutable_data() + b * ch_out * channel_size_out;
-            const float* dB = tensor_in.data() + b * ch_in * channel_size_in;
-            if (flag_bias){
-                if (flag_relu) {
-                    sgemv_bias_relu(false, m, k, weights, dB, data_out_batch, bias);
-                } else {
-                    sgemv_bias(false, m, k, weights, dB, data_out_batch, bias);
-                }
+            for (int g = 0; g < group; ++g) {
+                float* dout_group = tensor_out.mutable_data() + (b * ch_out + g * m) * channel_size_out;
+                const float* din_group = tensor_in.data() + (b * ch_in + g * k)* channel_size_in;
+                const float* weights_group = weights + g * weights_size_per_group;
+                const float* bias_group = bias + g * m;
+                if (flag_bias){
+                    if (flag_relu) {
+                        sgemv_bias_relu(false, m, k, weights_group, din_group, dout_group, bias_group);
+                    } else {
+                        sgemv_bias(false, m, k, weights_group, din_group, dout_group, bias_group);
+                    }
 
-            } else {
-                if (flag_relu) {
-                    sgemv_relu(false, m, k, weights, dB, data_out_batch);
                 } else {
-                    sgemv(false, m, k, weights, dB, data_out_batch);
+                    if (flag_relu) {
+                        sgemv_relu(false, m, k, weights_group, din_group, dout_group);
+                    } else {
+                        sgemv(false, m, k, weights_group, din_group, dout_group);
+                    }
                 }
             }
         }
@@ -259,14 +266,19 @@ void conv1x1s1_gemm(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOA
     } else {
         for (int b = 0; b < num; ++b) {
             // dC
-            float *data_out_batch = tensor_out.mutable_data(b * ch_out * channel_size_out);
-            const float* dB = tensor_in.data(b * ch_in * channel_size_in);
-            float beta = 0.f;
-            if (flag_bias){
-                fill_bias(data_out_batch, bias, ch_out, w_out * h_out);
-                beta = 1.f;
+            for (int g = 0; g < group; ++g) {
+                float* dout_group = tensor_out.mutable_data() + (b * ch_out + g * m) * channel_size_out;
+                const float* din_group = tensor_in.data() + (b * ch_in + g * k) * channel_size_in;
+                const float* weights_group = weights + g * weights_size_per_group;
+                const float* bias_group = bias + g * m;
+                float beta = 0.f;
+                if (flag_bias) {
+                    fill_bias(dout_group, bias_group, m, w_out * h_out);
+                    beta = 1.f;
+                }
+                gemmer(weights_group, k, din_group, n, dout_group, n, 1.f, beta, flag_relu);
             }
-            gemmer(weights, k, dB, n, data_out_batch, n, 1.f, beta, flag_relu);
+
         }
     }
 }
@@ -287,1108 +299,44 @@ void conv_im2col_gemm(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FL
     int h_out = tensor_out.height();
     int ch_out = tensor_out.channel();
 
-    const int m = ch_out;
+    const int m = ch_out / group;
     const int n = h_out * w_out;
-    const int k = ch_in * kernel_h * kernel_w;
+    const int k = ch_in * kernel_h * kernel_w / group;
+
+    const int chin_per_group = ch_in / group;
 
     int channel_size_out = w_out * h_out;
     int channel_size_in = w_in * h_in;
-    for (int b = 0; b < num; ++b) {
-        // dC
-        float *data_out_batch = tensor_out.mutable_data(b * ch_out * channel_size_out);
-        float *data_in_batch = tensor_in.mutable_data(b * ch_in * channel_size_in);
 
-        float* dB = (float*)work_space;
-        if (kernel_w == 1 && pad_w == 0) {
-            im2col1x1s2(data_in_batch, ch_in, h_in, w_in, dB);
-        } else {
-            im2col(data_in_batch, ch_in, h_in, w_in, kernel_h, kernel_w, \
-            pad_h, pad_w, stride_h, stride_w, dB);
-        }
-
-        float beta = 0.f;
-        if (flag_bias) {
-            fill_bias(data_out_batch, bias, ch_out, w_out * h_out);
-            beta = 1.f;
-        }
-
-        gemmer(weights, k, dB, n, data_out_batch, n, 1.f, beta, flag_relu);
-    }
-}
-
-void conv_3x3s1_direct(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, \
-    const float* weights, const float* bias, \
-    int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
-    int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space) {
-    //! 3x3s1 convolution, implemented by direct algorithm
-    //! pad is done implicit
-    const float zero[6] = {0.f, 0.f, 0.f, 0.f, 0.f, 0.f};
-    //! for 4x6 convolution window
-    const int right_pad_idx[4] = {3, 2, 1, 0};
-
-    int w_in = tensor_in.width();
-    int h_in = tensor_in.height();
-    int ch_in = tensor_in.channel();
-    int num = tensor_in.num();
+    int weights_size_per_group = ch_out * ch_in * kernel_w * kernel_h / (group * group);
 
-    int w_out = tensor_out.width();
-    int h_out = tensor_out.height();
-    int ch_out = tensor_out.channel();
-
-    const float* din = tensor_in.data();
-    float* dout = tensor_out.mutable_data();
-
-    int size_in_channel = w_in * h_in;
-    int size_out_channel = w_out * h_out;
-    int w_stride = ch_in * 9;
-
-    int tile_w = (w_in + 3) >> 2;
-    int tile_h = (h_in + 1) >> 1;
-    int w_in_twice = w_in << 1;
-    int cnt_col = tile_w - 2;
-
-    int size_pad_right = 1 + (tile_w << 2) - w_in;
-    int size_pad_bottom = 1 + (tile_h << 1) - h_in;
-
-    int cremain = ch_out - (ch_out >> 1) << 1;
-
-    uint32x4_t vmask_rp = vcgeq_s32(vld1q_s32(right_pad_idx), vdupq_n_s32(size_pad_right));
-    unsigned int pmask_rp[4];
-    vst1q_u32(pmask_rp, vmask_rp);
-    int right_pad_sub = (size_pad_right - 1) * sizeof(float);
-
-    for (int n = 0; n < num; ++n) {
-        const float *din_batch = din + n * ch_in * size_in_channel;
-        float *dout_batch = dout + n * ch_in * size_out_channel;
-#pragma omp parallel for
-        for (int c = 0; c < ch_out - 1; c += 2) {
-
-            float* dout_c0 = dout_batch + c * size_out_channel;
-            float* dout_c1 = dout_c0 + size_out_channel;
-
-            if (flag_bias) {
-                fill_bias(dout_c0, &bias[c], 1, size_out_channel);
-                fill_bias(dout_c1, &bias[c + 1], 1, size_out_channel);
+    for (int b = 0; b < num; ++b) {
+        // dC
+        for (int g = 0; g < group; ++g) {
+            float* dout_group = tensor_out.mutable_data() + (b * ch_out + g * m) * channel_size_out;
+            const float* din_group = tensor_in.data() + (b * ch_in + g * chin_per_group) * channel_size_in;
+            const float* weights_group = weights + g * weights_size_per_group;
+            const float* bias_group = bias + g * m;
+            float* dB = (float*)work_space;
+            if (kernel_w == 1 && pad_w == 0) {
+                im2col1x1s2(din_group, chin_per_group, h_in, w_in, dB);
             } else {
-                fill_bias(dout_c0, zero, 1, size_out_channel);
-                fill_bias(dout_c1, zero, 1, size_out_channel);
+                im2col(din_group, chin_per_group, h_in, w_in, kernel_h, kernel_w, \
+                    pad_h, pad_w, stride_h, stride_w, dila_h, dila_w, dB);
             }
-
-            //float* dout_c2 = dout_c1 + size_out_channel;
-            //float* dout_c3 = dout_c2 + size_out_channel;
-
-            const float* wc0 = weights + c * w_stride;
-            const float* wc1 = wc0 + w_stride;
-
-            //const float* wc2 = wc0 + w_stride;
-            //const float* wc3 = wc0 + w_stride;
-
-            for (int i = 0; i < ch_in; ++i) {
-
-                const float *din_channel = din_batch + i * size_in_channel;
-
-                const float* wcin0 = wc0 + i * 9;
-                const float* wcin1 = wc1 + i * 9;
-                float32x4_t wr00 = vld1q_f32(wcin0);
-                float32x4_t wr01 = vld1q_f32(wcin0 + 3);
-                float32x4_t wr02 = vld1q_f32(wcin0 + 6);
-
-                float32x4_t wr10 = vld1q_f32(wcin1);
-                float32x4_t wr11 = vld1q_f32(wcin1 + 3);
-                float32x4_t wr12 = vld1q_f32(wcin1 + 6);
-
-                float *doutc0r0 = dout_c0;
-                float *doutc0r1 = doutc0r0 + w_out;
-
-                float *doutc1r0 = dout_c1;
-                float *doutc1r1 = doutc1r0 + w_out;
-
-                const float *dr0 = din_channel;
-                const float *dr1 = dr0 + w_in;
-                const float *dr2 = dr1 + w_in;
-                const float *dr3 = dr2 + w_in;
-
-                const float *din0_ptr = dr0;
-                const float *din1_ptr = dr1;
-                const float *din2_ptr = dr2;
-                const float *din3_ptr = dr3;
-
-                float* ptr_zero = const_cast<float*>(zero);
-
-                //! deal with top pad
-                int h = 0;
-                {
-                    //! process
-                    if (1) {
-#ifdef __aarch64__
-                        // todo
-#else
-                        int cnt = cnt_col;
-
-                        float tmp1[4];
-                        float* ptr1 = tmp1;
-                        float tmp2[4];
-                        float* ptr2 = tmp2;
-
-                        asm volatile(
-                        //! process left pad
-                        "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
-
-                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
-
-                                "vmov.u32 q15, #0                       @ dump zero\n"
-                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][0]            @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][0]            @ mul weight1 20, out1r1\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
-
-                                //! process mid cols
-                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
-                                "blt  start_top_right                   @ jump to main loop start point\n"
-                                "start_top_mid:                         @ main loop start point\n"
-
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "subs %[cnt], #1                        @ loop count minus 1\n"
-                                "bne    start_top_mid                   @ jump to main loop start point\n"
-
-                                //! process right pad
-                                "start_top_right:                       @ right pad entry\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                "vmvn.32  q12, q15                      @ \n"
-                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
-                                "vbif q13, q10, q15                      @ bit select\n"
-                                "vbif q14, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
-
-                                "vbif q8, q10, q15                      @ bit select\n"
-                                "vbif q9, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-
-                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
-
-                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
-                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
-                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
-                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
-                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
-                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub)
-                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
-                        );
-#endif //__aarch64__
-                    }
-                    //! after process, increase pointer
-                    doutc0r0 += w_out;
-                    doutc0r1 = doutc0r0 + w_out;
-                    doutc1r0 += w_out;
-                    doutc1r1 = doutc1r0 + w_out;
-
-                    dr0 = dr1;
-                    dr1 = dr2;
-                    dr2 = dr1 + w_in;
-                    dr3 = dr2 + w_in;
-                } //! end of process top row
-
-
-                //! process mid row
-                for (h = 1; h < tile_h - 1; h++) {
-                    din0_ptr = dr0;
-                    din1_ptr = dr1;
-                    din2_ptr = dr2;
-                    din3_ptr = dr3;
-
-                    {
-#ifdef __aarch64__
-                        // todo
-#else
-                        int cnt = cnt_col;
-                        asm volatile (
-                        //! process left pad
-                        "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "pld [%[din3_ptr], #192]                @ preload data\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr00][1]         @ mul weight0 01, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
-
-                                "vmov.u32 q15, #0                         @ dump zero\n"
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr00][0]            @ mul weight0 00, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][0]            @ mul weight1 00, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][0]            @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][0]            @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][0]            @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][0]            @ mul weight1 00, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][0]            @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][0]            @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][0]            @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][0]            @ mul weight1 10, out1r1\n"
-
-                                //! 4rd row
-                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
-                                "pld [%[din3_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][1]           @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][1]           @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][0]            @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][0]            @ mul weight1 20, out1r1\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din3_ptr], #12                   @ 1pad + 2 float data overlap\n"
-
-                                //! process mid cols
-                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
-                                "blt  start_mid_right                   @ jump to main loop start point\n"
-                                "start_mid_mid:                         @ main loop start point\n"
-
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                //! 4rd row
-                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
-                                "pld [%[din3_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din2_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din3_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "subs %[cnt], #1                        @ loop count minus 1\n"
-                                "bne    start_mid_mid                   @ jump to main loop start point\n"
-
-                                //! process right pad
-                                "start_mid_right:                       @ right pad entry\n"
-
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                //! 4rd row
-                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                "vmvn.32  q12, q15                      @ \n"
-                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
-                                "vbif q13, q10, q15                      @ bit select\n"
-                                "vbif q14, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
-
-                                "vbif q8, q10, q15                      @ bit select\n"
-                                "vbif q9, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-
-                                "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc1r0], %[doutc1r0], %[right_pad_sub] @ sub \n"
-                                "sub %[doutc1r1], %[doutc1r1], %[right_pad_sub] @ sub \n"
-
-                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
-                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
-                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
-                            [din2_ptr] "+r"(din2_ptr), [din3_ptr] "+r"(din3_ptr), \
-                            [cnt] "+r"(cnt)
-                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
-                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub)
-                        :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
-                        );
-#endif //__aarch64__
-                    }
-                    doutc0r0 += w_out;
-                    doutc0r1 = doutc0r0 + w_out;
-                    doutc1r0 += w_out;
-                    doutc1r1 = doutc1r0 + w_out;
-
-                    dr0 = dr2;
-                    dr1 = dr3;
-                    dr2 = dr1 + w_in;
-                    dr3 = dr2 + w_in;
-                } //! end of processing mid rows
-
-                //! deal with bottom pad
-                if (1) {
-
-                    din0_ptr = dr0;
-                    din1_ptr = dr1;
-                    if (size_pad_bottom == 2){
-                        din2_ptr = ptr_zero;
-                    } else {
-                        din2_ptr = dr2;
-                    }
-                    // process
-                    {
-#ifdef __aarch64__
-                        // todo
-#else
-                        int cnt = cnt_col;
-                        asm volatile (
-                        //! process left pad
-                        "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vmla.f32 q13, q10, %e[wr00][1]           @ mul weight0 01, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][1]           @ mul weight1 01, out1r0\n"
-
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
-
-                                "vmov.u32 q15, #0                         @ dump zero\n"
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr00][0]            @ mul weight0 00, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][0]            @ mul weight1 00, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
-
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][0]            @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][0]            @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][0]            @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][0]            @ mul weight1 00, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][0]            @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][0]            @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][0]            @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][0]            @ mul weight1 10, out1r1\n"
-
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
-
-                                "cmp %[bot_pad],  #2  @ check if bottom pad is 2\n"
-                                "beq    conv3x3_bot_mid @ jump to next block\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
-                                "add %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-
-                                //! process mid cols
-                                "cmp %[cnt], #1                         @ check whether has mid cols\n"
-                                "blt  conv3x3_bot_right                   @ jump to main loop start point\n"
-                                "conv3x3_bot_mid:                         @ main loop start point\n"
-
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
-
-                                "pld [%[din0_ptr], #192]                @ preload data\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "pld [%[din1_ptr], #192]                @ preload data\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "pld [%[doutc1r0], #192]                @ preload data\n"
-
-                                "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
-                                "sub %[din1_ptr], #8                    @ 2 float data overlap with previous data\n"
-
-                                "cmp %[bot_pad],  #2                    @ check if bottom pad is 2\n"
-                                "beq    end_bot_mid                     @ jump to check point\n"
-
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
-                                "pld [%[doutc0r1], #192]                @ preload data\n"
-                                "pld [%[doutc1r1], #192]                @ preload data\n"
-                                "add %[din2_ptr], #16                   @ point to 4 data ahead\n"
-                                "pld [%[din2_ptr], #192]                @ preload data\n"
-
-                                "end_bot_mid:  @ check point\n"
-                                "subs %[cnt], #1                        @ loop count minus 1\n"
-                                "bne    conv3x3_bot_mid                   @ jump to main loop start point\n"
-
-                                //! process right pad
-                                "conv3x3_bot_right:                       @ right pad entry\n"
-
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
-
-                                //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
-
-                                //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r0]]       @ load dout0r1\n"
-
-                                "vmvn.32  q12, q15                      @ \n"
-                                "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
-                                "vbif q13, q10, q15                     @ bit select\n"
-                                "vbif q8, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]      @ store result, add pointer\n"
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]      @ store result, add pointer\n"
-
-                                "cmp %[bot_pad],  #2  @ check if bottom pad is 2\n"
-                                "beq    end_conv3x3s1 @ jump to end point\n"
-
-                                "vld1.32  {d20-d21}, [%[doutc0r1]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout0r1\n"
-
-                                "vbif q14, q10, q15                     @ bit select\n"
-                                "vbif q9, q11, q15                      @ bit select\n"
-
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]      @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]      @ store result, add pointer\n"
-                                "end_conv3x3s1:  @ end\n"
-                        :[doutc0r0] "+r"(doutc0r0), [doutc0r1] "+r"(doutc0r1), \
-                            [doutc1r0] "+r" (doutc1r0), [doutc1r1] "+r" (doutc1r1),\
-                            [din0_ptr] "+r"(din0_ptr), [din1_ptr] "+r"(din1_ptr), \
-                            [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
-                        :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
-                            [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp), [bot_pad] "r"(size_pad_bottom)
-                        :"q8", "q9", "q10", \
-                            "q11", "q12", "q13", "q14", "q15"
-                        );
-#endif //__aarch64__
-                    }
-                } // end of processing bottom pad
-            } // end of processing channels
-        } //end of processing output channel
-        if (cremain > 0) {
-            for (int c = 0; c < cremain; ++c) {
-
-                int cidx = ch_out - cremain + c;
-                float* dout_c = dout_batch + cidx * size_out_channel;
-
-                if (flag_bias) {
-                    fill_bias(dout_c, &bias[cidx], 1, size_out_channel);
-                } else {
-                    fill_bias(dout_c, zero, 1, size_out_channel);
-                }
-
-                const float* wc0 = weights + cidx * w_stride;
-
-                for (int i = 0; i < ch_in; ++i) {
-                    const float* din_channel = din_batch + i * size_in_channel;
-                    for (int h = 0; h < h_out; ++h) {
-
-                        int hstart = h - pad_h;
-                        int hend = hstart + 3;
-                        hstart = std::max(hstart, 0);
-                        hend = std::min(hend, h_in);
-
-                        int khstart = hend < kernel_h? kernel_h - hend : 0;
-
-                        float* dout_row = dout_c + h * w_out;
-
-                        for (int w = 0; w < w_out; ++w) {
-                            int wstart = w - pad_w;
-                            int wend = wstart + 3;
-                            wstart = std::max(wstart, 0);
-                            wend = std::min(wend, w_in);
-                            int kwstart = wend < kernel_w? kernel_w - wend : 0;
-
-                            for (int kh = hstart; kh < hend; ++kh) {
-                                for (int kw = wstart; kw < wend; ++kw) {
-                                    dout_row[w] += din_channel[kh * w_in + kw] * \
-                                        wc0[(khstart + kh - hstart) * 3 + kwstart + kw - wstart];
-                                }
-                            }
-                        }
-                    }
-                    wc0 += 9;
-                }
+            float beta = 0.f;
+            if (flag_bias) {
+                fill_bias(dout_group, bias_group, m, w_out * h_out);
+                beta = 1.f;
             }
-        } // end of remain out channel
 
-    } // end of processing batchs
+            gemmer(weights_group, k, dB, n, dout_group, n, 1.f, beta, flag_relu);
+        }
+    }
 }
 
 } //namespace saber
 
 } //namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/impl/conv_arm_impl.h b/saber/funcs/impl/arm/impl/conv_arm_impl.h
index e5e8c99..61da0d5 100644
--- a/saber/funcs/impl/arm/impl/conv_arm_impl.h
+++ b/saber/funcs/impl/arm/impl/conv_arm_impl.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
+
 #ifndef ANAKIN_SABER_FUNCS_ARM_IMPL_CONV_ARM_IMPL_H
 #define ANAKIN_SABER_FUNCS_ARM_IMPL_CONV_ARM_IMPL_H
 
@@ -56,8 +57,19 @@ void conv_arm_winograd3x3(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, A
     int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
     int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space);
 
+/**
+* \brief conv7x7, stride 1, pad 3, with bias and group
+*/
+void conv_arm_7x7s1(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, \
+    const float* weights, const float* bias, \
+    int group, int kernel_w, int kernel_h, int stride_w, int stride_h, int dila_w, int dila_h, \
+    int pad_w, int pad_h, bool flag_bias, bool flag_relu, Sgemm& gemmer, void* work_space);
+
 void winograd_transform_weights(float* dout, const float* din, int ch_out, \
     int ch_in, void* work_space);
+
+void fill_bias(float* tensor, const float* bias, int channel, int channel_size);
+
 #if 0
 class ConvWinogradF63 {
 public:
diff --git a/saber/funcs/impl/arm/impl/pooling_arm_impl.cpp b/saber/funcs/impl/arm/impl/pooling_arm_impl.cpp
index a304a33..8a6ffb4 100644
--- a/saber/funcs/impl/arm/impl/pooling_arm_impl.cpp
+++ b/saber/funcs/impl/arm/impl/pooling_arm_impl.cpp
@@ -166,7 +166,7 @@ void pooling_basic(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
                                     sum += data_in_channel[h * w_in + w];
                                 }
                             }
-                            int pool_size = (hend - hstart) * (wend - wstart);
+                            int pool_size = kernel_w * kernel_h;//(hend - hstart) * (wend - wstart);
                             data_out_row[j] = sum / pool_size;
                         }
                         data_out_row += w_out;
@@ -294,71 +294,142 @@ void pooling2x2s2_max(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     int h_out = tensor_out.height();
     int ch_out = tensor_out.channel();
 
+    if (global) {
+        LOG(FATAL) << "not supported in this funcs, instead, use the basic func";
+    }
+
     int size_channel_out = w_out * h_out;
     int size_channel_in = w_in * h_in;
-
     float* data_out = tensor_out.mutable_data();
     const float* data_in = tensor_in.data();
 
-    int right_pad = w_out * 2 - w_in;
-    int bottom_pad = h_out * 2 - h_in;
-
-    uint32_t mask_buffer[8] = {0, 1, 2, 3, 4, 5, 6, 7};
-
-    int col_cnt = (w_out - right_pad) / 4;
-    int right_remian = w_out - col_cnt * 4;
-
-    int row_cnt = (h_out - bottom_pad) / 2;
-    int bottom_remian = h_out - row_cnt * 2;
-
+    int w_even = (w_in >> 1) << 1;
+    //int w_remains = w_in - w_even; // should be 0 or 1
+    int h_even = (h_in >> 1) << 1;
+    //int h_remains = h_in - h_even; // should be 0 or 1
+    int w_unroll_size = (w_even >> 3) << 3;
+    //int w_unroll_remian = w_even - w_unroll_size;
+    int w_in_2 = w_in << 1;
     float32x4_t vzero = vdupq_n_f32(0.f);
 
     for (int n = 0; n < num; ++n) {
+
         float* data_out_batch = data_out + n * ch_out * size_channel_out;
         const float* data_in_batch = data_in + n * ch_in * size_channel_in;
 #pragma omp parallel for
         for (int c = 0; c < ch_out; c++) {
-            const float* data_in_channel = data_in_batch + c * size_channel_in;
             float* data_out_channel = data_out_batch + c * size_channel_out;
+            const float* data_in_channel = data_in_batch + c * size_channel_in;
+            const float* r0 = data_in_channel;
+            const float* r1 = r0 + w_in;
             int h = 0;
-            for (; h < h_out - 1; h += 2) {
-                const float* r0 = data_in_channel + 2 * h * w_in;
-                const float* r1 = r0 + w_in;
-                const float* r2 = r1 + w_in;
-                const float* r3 = r2 + w_in;
-                float* out_r0 = data_out_channel + h * w_out;
-                float* out_r1 = out_r0 + w_out;
-                for (int w = 0; w < col_cnt; ++w) {
-#ifdef __aarch64__
-                    //todo
-#else
-                    asm volatile (
-                    "vld1.32 {d0-d3}, [%[ptr0]]!      @ load r0, 8 elements, q0=r00,r01,r02,r03;q1=r04,r05,r06,r07\n"
-                    "vld1.32 {d4-d7}, [%[ptr1]]!      @ load r1, 8 elements, q2=r10,r11,r12,r13;q1=r14,r15,r16,r17\n"
-                    "vld1.32 {d16-d19}, [%[ptr2]]!    @ load r2, 8 elements, q8=r20,r21,r22,r23;q9=r24,r25,r26,r27\n"
-                    "vld1.32 {d20-d23}, [%[ptr3]]!    @ load r3, 8 elements, q10=r30,r31,r32,r33;q11=r34,r35,r36,r37\n"
-
-                    "vmax.f32   q0, q0, q2            @ get max of r0\n"
-                    "vmax.f32   q1, q1, q3            @ get max of r0\n"
-                    "vpmax.f32   d0, d0, d1           @ get max in q0, q1\n"
-                    "vpmax.f32   d1, d2, d3           @ get max in q0, q1\n"
-                    "vst1.32    {d0-d1},[%[outptr0]]! @ write q0, 1st row\n"
-
-                    "vmax.f32   q8, q8, q10           @ get result of r2, r3\n"
-                    "vmax.f32   q9, q9, q11           @ get result of r2, r3\n"
-                    "vpmax.f32   d16, d16, d17        @ get max in q8, q9\n"
-                    "vpmax.f32   d17, d18, d19        @ get max in q8, q9\n"
-                    "vst1.32  {d16-d17},[%[outptr1]]! @ write q4, 2nd row\n"
-                    : [ptr0] "+r" (r0), [ptr1] "+r" (r1), [ptr2] "+r" (r2), \
-                        [ptr3] "+r" (r3), [outptr0] "+r" (out_r0), [outptr1] "+r" (out_r1)
-                    :
-                    : "q0", "q1", "q2", "q3", "q8", "q9", "q10", "q11"
+            for (; h < h_even; h += 2) {
+                int w = 0;
+            #ifdef  __aarch64__
+                for (; w < w_unroll_size; w += 8) {
+                    prefetch_2x(r0);
+                    prefetch_2x(r1);
+                    float32x4_t dr00 = vld1q_f32(&r0[w]);
+                    float32x4_t dr01 = vld1q_f32(&r0[w + 4]);
+                    float32x4_t dr10 = vld1q_f32(&r1[w]);
+                    float32x4_t dr11 = vld1q_f32(&r1[w + 4]);
+                    float32x4_t dmax1 = vmaxq_f32(dr00, dr10);
+                    float32x4_t dmax2 = vmaxq_f32(dr01, dr11);
+                #ifdef __aarch64__
+                    float32x4_t dmax = vpmaxq_f32(dmax1, dmax2);
+                #else
+                    float32x2_t dmaxl = vpmax_f32(vget_low_f32(dmax1), vget_high_f32(dmax1));
+                    float32x2_t dmaxh = vpmax_f32(vget_low_f32(dmax2), vget_high_f32(dmax2));
+                    float32x4_t dmax = vcombine_f32(dmaxl, dmaxh);
+                #endif
+                    vst1q_f32(&data_out_channel[w >> 1], dmax);
+
+                }
+            #else
+                w = w_unroll_size;
+                int num = w_unroll_size >> 3;
+                float* dr0 = (float *)r0;
+                float* dr1 = (float *)r1;
+                float* dr_out = data_out_channel;
+                //printf("c: %d, num: %d, dr0: %x, dr1: %x, dr_out: %x\n",c,num,dr0,dr1,dr_out);
+                if (num > 0){
+                    asm volatile(
+                    "s2_max_loop:                                     @main loop\n"  
+                    "vld1.f32   {d0-d3}, [%[dr0]]!                    @load q0, dr0\n"
+                    "vld1.f32   {d4-d7}, [%[dr1]]!                    @load q1, dr1\n"
+                    "vmax.f32   q0, q0, q2                            @max q0, q0, q2\n"
+                    "vmax.f32   q1, q1, q3                            @max q1, q1, q2\n"
+                    "vpmax.f32  d4, d0, d1                            @max d4, d0, d1\n"
+                    "vpmax.f32  d5, d2, d3                            @max d5, d2, d3\n"
+                    "vst1.f32   {d4-d5}, [%[dr_out]]!                 @vst1 q2, dr_out\n"
+                    "subs       %[num], #1                            @subs num, 1\n"
+                    "bne        s2_max_loop                           @bne num\n"
+                    :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [num] "+r" (num)
+                    :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(num)
+                    :"q0", "q1", "q2", "q3"
                     );
-#endif //__aarch64__
+                }
+            #endif //__aarch64__
+                //printf("c: %d, w: %d,num: %d\n",c,w,num);
+                for (; w < w_even; w += 2) {
+                    data_out_channel[w >> 1] = std::max(std::max(r0[w], r0[w + 1]), \
+                        std::max(r1[w], r1[w + 1]));
+                }
+                for (; w < w_in; ++w) { // run 0 or 1 time
+                    data_out_channel[w >> 1] = std::max(r0[w], r1[w]);
+                }
+                r0 += w_in_2;// << 1;
+                r1 += w_in_2;// << 1;
+                data_out_channel += w_out;
+            }
+            // process remain row (odd, last row)
+            for (; h < h_in; h++) { //run 0 or 1 time
+                int w = 0;
+            #ifdef  __aarch64__
+                for (; w < w_unroll_size; w += 8) {
+                    prefetch_2x(r0);
+                    float32x4_t dr00 = vld1q_f32(&r0[w]);
+                    float32x4_t dr01 = vld1q_f32(&r0[w + 4]);
+                #ifdef __aarch64__
+                    float32x4_t dmax = vpmaxq_f32(dr00, dr01);
+                #else
+                    float32x2_t dmaxl = vpmax_f32(vget_low_f32(dr00), vget_high_f32(dr00));
+                    float32x2_t dmaxh = vpmax_f32(vget_low_f32(dr01), vget_high_f32(dr01));
+                    float32x4_t dmax = vcombine_f32(dmaxl, dmaxh);
+                #endif
+                    float32x4_t dmax_cmp_zero = vmaxq_f32(dmax, vzero);
+                    vst1q_f32(&data_out_channel[w >> 1], dmax_cmp_zero);
 
                 }
+            #else
+                w = w_unroll_size;
+                int num = w_unroll_size >> 3;
+                float* dr0 = (float *)r0;
+                float* dr_out = data_out_channel;
+                if (num > 0){
+                    asm volatile(
+                    "s2_max_loop1:                                        @main loop\n"  
+                    "vld1.f32   {d0-d3}, [%[dr0]]!                    @load q0, dr0\n"
+                    "vpmax.f32  d4, d0, d1                            @max d4, d0, d1\n"
+                    "vpmax.f32  d5, d2, d3                            @max d5, d2, d3\n"
+                    "vst1.f32   {d4-d5}, [%[dr_out]]!                 @vst1 q2, dr_out\n"
+                    "subs       %[num], #1                            @subs num, 1\n"
+                    "bne        s2_max_loop1                          @bne num\n"
+                    :[dr0] "+r" (dr0), [dr_out] "+r" (dr_out), [num] "+r" (num)
+                    :"r" (dr0), "r" (dr_out), "r"(num)
+                    :"q0", "q1", "q2"
+                    );
+                }
+            #endif  //__aarch64__
+                for (; w < w_even; w += 2) {
+                    data_out_channel[w >> 1] = std::max(std::max(r0[w], r0[w + 1]), 0.f);
+                }
+                for (; w < w_in; ++w) { // run 0 or 1 time
+                    data_out_channel[w >> 1] = std::max(r0[w], 0.f);
+                }
             }
         }
+
     }
 }
 
@@ -512,18 +583,1667 @@ void pooling2x2s2_ave(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     }
 }
 
+void pooling3x3s1_max(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
+    Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
+    int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h) {
+
+    //no need to pad input tensor, pad_size is not used, default border is zero padded
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+    //printf("3x3s1 \n");
+
+    if (global) {
+        LOG(ERROR) << "not supported in this funcs, instead, use the basic func";
+    }
+
+    int size_channel_out = w_out * h_out;
+    int size_channel_in = w_in * h_in;
+    float* data_out = tensor_out.mutable_data();
+    const float* data_in = tensor_in.data();
+
+    int w_even = (w_in >> 1) << 1;
+    //int w_remains = w_in - w_even; // should be 0 or 1
+    int h_even = (h_in >> 1) << 1;
+    //int h_remains = h_in - h_even; // should be 0 or 1
+    //int w_unroll_size = (w_even >> 3) << 3;
+    //int w_unroll_remian = w_even - w_unroll_size;
+    int w_in_2 = w_in << 1;
+    int w_unroll_size =  (w_in - 2) >> 2;
+    int w_unroll_remian = w_in - 2 - w_unroll_size * 4;
+    float minval = std::numeric_limits<float>::lowest();
+    float32x4_t vzero = vdupq_n_f32(minval); //zero pad
+
+    for (int n = 0; n < num; ++n) {
+
+        float* data_out_batch = data_out + n * ch_out * size_channel_out;
+        const float* data_in_batch = data_in + n * ch_in * size_channel_in;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out; c++) {
+            float* data_out_channel = data_out_batch + c * size_channel_out;
+            const float* data_in_channel = data_in_batch + c * size_channel_in;
+            const float* r0 = data_in_channel;
+            const float* r1 = r0 + w_in;
+            const float* r2 = r1 + w_in;
+            int cnt_num = w_unroll_size; //w_in / 4
+            float* dr_out = data_out_channel;
+            const float* dr0 = r0;
+            const float* dr1 = r1;
+            const float* dr2 = r2;
+            int w = 0;
+            int cnt = 1;
+            //left
+            data_out_channel[0] = std::max(std::max(r0[0], r0[1]), std::max(r1[0], r1[1]));
+            // first row with zero pad
+        #ifdef __aarch64__
+            for (; w < w_in - 6; w += 4) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+
+                float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                float32x4_t vmax_3456 = vextq_f32(vmax_1234, vmax_5678,2);
+                float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                float32x2_t vmax_34_56 = vpmax_f32(vget_low_f32(vmax_3456), vget_high_f32(vmax_3456));
+                float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                float32x2_t vmax_234_456 = vmax_f32(vmax_23_45, vmax_34_56);
+                float32x4_t vmax = vdupq_n_f32(vget_lane_f32(vmax_123_345, 0));
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 0), vmax, 1);
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_123_345, 1), vmax, 2);
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 1), vmax, 3);
+                vst1_f32(&data_out_channel[cnt],vmax);
+                cnt += 4;
+            }
+            
+        #else
+            dr_out = dr_out + 1;
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+            if (cnt_num > 0){
+                asm volatile(
+                "s1_max_loop_1:                                    @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vmax.f32  q5, q0, q2                            @max r0_1234,r1_1234\n"
+                "vmax.f32  d12, d2, d6                            @max r0_5678,r1_5678\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q5, q6, #1                        @vext max_2345\n"
+                "vext.f32  q2, q5, q6, #2                        @vext max_3456\n"
+                "vpmax.f32 d2, d10, d11                          @pmax d4, max_1234, max_1234\n"
+                "vpmax.f32 d3, d0, d1                            @pmax d4, max_2345, max_2345\n"
+                "vpmax.f32 d6, d4, d5                            @pmax d6, max_3456, max_3456\n"
+                "vmax.f32  d8, d2, d3                            @max d2, vmax_12_34, vmax_23_45\n"
+                "vmax.f32  d9, d3, d6                            @max d2, vmax_23_45, vmax_34_56\n"
+                "sub       %[dr0], #8                            @sub w, 8\n"
+                "sub       %[dr1], #8                            @sub w, 8\n"
+                //swap
+                "vmov.f32  s0, s17                               @mov \n"
+                "vmov.f32  s17, s18                              @mov \n"
+                "vmov.f32  s18, s0                               @mov \n"
+                "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "bne       s1_max_loop_1                           @bne s1_max_loop\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6"
+                );
+            }
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+        #endif
+            //remian
+            w = w_unroll_size * 4;
+            for(int j = 0; j < w_unroll_remian; j++){
+                float tmp_max = std::max(r0[j + w], r1[j + w]);
+                tmp_max = std::max(tmp_max, std::max(r0[j + w + 1], r1[j + w + 1]));
+                tmp_max = std::max(tmp_max, std::max(r0[j + w + 2], r1[j + w + 2]));
+                data_out_channel[j + w + 1] = tmp_max;
+            }
+            //right
+            float tmp = std::max(r0[w_in - 2],r1[w_in - 2]);
+            tmp =std::max(tmp, std::max(r0[w_in - 1],r1[w_in - 1]));
+            data_out_channel[w_out-1]  = tmp;
+
+           // r0 = r1;
+           // r1 = r0 + w_in;
+           // r2 = r1 + w_in;
+            data_out_channel += w_out;
+            int h = 0;
+            for (; h < h_in - 2; h += 1) {
+                // deal with left pad
+                float maxr0 = std::max(r0[0], r0[1]);
+                float maxr1 = std::max(r1[0], r1[1]);
+                float maxr2 = std::max(r2[0], r2[1]);
+                data_out_channel[0] = std::max(std::max(maxr0, maxr1), maxr2);
+            #ifdef __aarch64__
+                w = 0;
+                cnt = 1;
+                for (; w < w_in - 6; w += 4) {
+                    float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                    float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                    float32x4_t vr2_1234 = vld1q_f32(&r2[w]);
+                    float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                    float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                    float32x4_t vr2_5678 = vld1q_f32(&r2[w + 4]);
+                    float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                    vmax_1234 = vamxq_f32(vmax_1234, vr2_1234);
+                    float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+                    vmax_5678 = vamxq_f32(vmax_5678, vr2_5678);
+
+                    float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                    float32x4_t vmax_3456 = vextq_f32(vmax_1234, vmax_5678,2);
+                    float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                    float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                    float32x2_t vmax_34_56 = vpmax_f32(vget_low_f32(vmax_3456), vget_high_f32(vmax_3456));
+                    float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                    float32x2_t vmax_234_456 = vmax_f32(vmax_23_45, vmax_34_56);
+                    float32x4_t vmax = vdupq_n_f32(vget_lane_f32(vmax_123_345, 0));
+                    vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 0), vmax, 1);
+                    vmax = vsetq_lane_f32(vget_lane_f32(vmax_123_345, 1), vmax, 2);
+                    vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 1), vmax, 3);
+                    vst1_f32(&data_out_channel[cnt],vmax);
+                    cnt += 4;
+                }
+            #else
+                 dr_out = data_out_channel + 1;
+                 dr0 = r0;
+                 dr1 = r1;
+                 dr2 = r2;
+                 cnt_num = w_unroll_size;
+                if (cnt_num > 0){
+                    asm volatile(
+                    "s1_max_loop_mid_1:                                    @main loop\n"
+                    "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d8-d9}, [%[dr2]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d10}, [%[dr2]]!                  @load d4-d7, dr1\n"
+                    "vmax.f32  q7, q0, q2                            @max r0_1234,r1_1234\n"
+                    "vmax.f32  d16, d2, d6                            @max r0_5678,r1_5678\n"
+                    "vmax.f32  q3, q7, q4                            @max r0_1234,r1_1234\n"
+                    "vmax.f32  d12, d16, d10                            @max r0_5678,r1_5678\n"
+                    //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                   "vext.f32  q0, q3, q6, #1                        @vext max_2345\n"
+                   "vext.f32  q2, q3, q6, #2                        @vext max_3456\n"
+                   "vpmax.f32 d2, d6, d7                            @pmax d4, max_1234, max_1234\n"
+                   "vpmax.f32 d3, d0, d1                            @pmax d4, max_2345, max_2345\n"
+                   "vpmax.f32 d6, d4, d5                            @pmax d6, max_3456, max_3456\n"
+                   "vmax.f32  d8, d2, d3                            @max d2, vmax_12_34, vmax_23_45\n"
+                   "vmax.f32  d9, d3, d6                            @max d2, vmax_23_45, vmax_34_56\n"
+                   "sub       %[dr0], #8                            @sub w, 8\n"
+                   "sub       %[dr1], #8                            @sub w, 8\n"
+                   "sub       %[dr2], #8                            @sub w, 8\n"
+                   //swap
+                   "vmov.f32  s0, s17                               @mov \n"
+                   "vmov.f32  s17, s18                              @mov \n"
+                   "vmov.f32  s18, s0                               @mov \n"
+                   "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                   "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                   "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                   "bne       s1_max_loop_mid_1                     @bne s1_max_loop\n"
+                   :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr2] "+r" (dr2), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num)
+                   :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                   :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8"
+                   );
+                }
+            #endif 
+               //remian
+               w = w_unroll_size * 4;
+               for(int j = 0; j < w_unroll_remian; j++){
+                   float tmp_max = std::max(r0[j + w], r1[j + w]);
+                   tmp_max = std::max(tmp_max, std::max(r0[j + w + 1], r1[j + w + 1]));
+                   tmp_max = std::max(tmp_max, std::max(r0[j + w + 2], r1[j + w + 2]));
+                   tmp_max = std::max(tmp_max, std::max(r2[j + w], r2[j + w + 1]));
+                   tmp_max = std::max(tmp_max, r2[j + w + 2]);
+                   data_out_channel[j + w + 1] = tmp_max;
+                }
+                //right
+                tmp = std::max(r0[w_in - 2],r1[w_in - 2]);
+                tmp =std::max(tmp, std::max(r0[w_in - 1],r1[w_in - 1]));
+                tmp =std::max(tmp, std::max(r2[w_in - 2],r2[w_in - 1]));
+                data_out_channel[w_out-1]  = tmp;
+
+                r0 = r1;
+                r1 = r2;
+                r2 = r1 + w_in;
+                data_out_channel += w_out;
+            }
+
+            //the last two line
+            float maxr0 = std::max(r0[0], r0[1]);
+            float maxr1 = std::max(r1[0], r1[1]);
+            data_out_channel[0] = std::max(maxr0, maxr1);
+            #ifdef __aarch64__
+            w = 0;
+            cnt = 1;
+            for (; w < w_in - 6; w += 4) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+
+                float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                float32x4_t vmax_3456 = vextq_f32(vmax_1234, vmax_5678,2);
+                float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                float32x2_t vmax_34_56 = vpmax_f32(vget_low_f32(vmax_3456), vget_high_f32(vmax_3456));
+                float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                float32x2_t vmax_234_456 = vmax_f32(vmax_23_45, vmax_34_56);
+                float32x4_t vmax = vdupq_n_f32(vget_lane_f32(vmax_123_345, 0));
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 0), vmax, 1);
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_123_345, 1), vmax, 2);
+                vmax = vsetq_lane_f32(vget_lane_f32(vmax_234_456, 1), vmax, 3);
+                vst1_f32(&data_out_channel[cnt],vmax);
+                cnt += 4;
+            }
+            #else
+            dr_out = data_out_channel + 1;
+            dr0 = r0;
+            dr1 = r1;
+            cnt_num = w_unroll_size;
+            if (cnt_num > 0){
+                asm volatile(
+                "s1_max_loop_bot_1:                                 @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vmax.f32  q5, q0, q2                            @max r0_1234,r1_1234\n"
+                "vmax.f32  d12, d2, d6                            @max r0_5678,r1_5678\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q5, q6, #1                        @vext max_2345\n"
+                "vext.f32  q2, q5, q6, #2                        @vext max_3456\n"
+                "vpmax.f32 d2, d10, d11                          @pmax d4, max_1234, max_1234\n"
+                "vpmax.f32 d3, d0, d1                            @pmax d4, max_2345, max_2345\n"
+                "vpmax.f32 d6, d4, d5                            @pmax d6, max_3456, max_3456\n"
+                "vmax.f32  d8, d2, d3                            @max d2, vmax_12_34, vmax_23_45\n"
+                "vmax.f32  d9, d3, d6                            @max d2, vmax_23_45, vmax_34_56\n"
+                "sub       %[dr0], #8                            @sub w, 8\n"
+                "sub       %[dr1], #8                            @sub w, 8\n"
+                //swap
+                "vmov.f32  s0, s17                               @mov \n"
+                "vmov.f32  s17, s18                              @mov \n"
+                "vmov.f32  s18, s0                               @mov \n"
+                "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "bne       s1_max_loop_bot_1                           @bne s1_max_loop\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6"
+                );
+            }
+            #endif 
+            //remian
+            w = w_unroll_size * 4;
+            for(int j = 0; j < w_unroll_remian; j++){
+                float tmp_max = std::max(r0[j + w], r1[j + w]);
+                tmp_max = std::max(tmp_max, std::max(r0[j + w + 1], r1[j + w + 1]));
+                tmp_max = std::max(tmp_max, std::max(r0[j + w + 2], r1[j + w + 2]));
+                data_out_channel[j + w + 1] = tmp_max;
+            }
+            tmp = std::max(r0[w_in - 2],r1[w_in - 2]);
+            tmp =std::max(tmp, std::max(r0[w_in - 1],r1[w_in - 1]));
+            data_out_channel[w_out-1]  = tmp;
+
+        }
+    }
+}
+
+void pooling3x3s1_ave(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
+    Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
+    int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h) {
+
+    //no need to pad input tensor, pad_size is not used, default border is zero padded
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+    //printf("3x3s1 \n");
+
+    if (global) {
+        LOG(ERROR) << "not supported in this funcs, instead, use the basic func";
+    }
+
+    int size_channel_out = w_out * h_out;
+    int size_channel_in = w_in * h_in;
+    float* data_out = tensor_out.mutable_data();
+    const float* data_in = tensor_in.data();
+
+    int w_even = (w_in >> 1) << 1;
+    int h_even = (h_in >> 1) << 1;
+    int w_in_2 = w_in << 1;
+    int w_unroll_size =  (w_in - 2) >> 2;
+    int w_unroll_remian = w_in - 2 - w_unroll_size * 4;
+    float32x4_t vzero = vdupq_n_f32(0.f); //zero pad
+    float32x4_t vcoef = vdupq_n_f32(1.f / 9.f); //zero pad
+
+    for (int n = 0; n < num; ++n) {
+
+        float* data_out_batch = data_out + n * ch_out * size_channel_out;
+        const float* data_in_batch = data_in + n * ch_in * size_channel_in;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out; c++) {
+            float* data_out_channel = data_out_batch + c * size_channel_out;
+            const float* data_in_channel = data_in_batch + c * size_channel_in;
+            const float* r0 = data_in_channel;
+            const float* r1 = r0 + w_in;
+            const float* r2 = r1 + w_in;
+            int cnt_num = w_unroll_size; //w_in / 4
+            float* dr_out = data_out_channel;
+            const float* dr0 = r0;
+            const float* dr1 = r1;
+            const float* dr2 = r2;
+            int w = 0;
+            int cnt = 1;
+            //left
+            data_out_channel[0] = (r0[0] + r0[1]+ r1[0] + r1[1]) / 9.f;
+            // first row with zero pad
+        #ifdef __aarch64__
+            for (; w < w_in - 6; w += 4) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+
+                float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                float32x4_t vsum = vaddq_f32(vsum_1234, vsum_2345);
+                vsum = vaddq_f32(vsum, vsum_3456);
+                vsum = vmulq_f32(vsum, vcoef);
+                vst1_f32(&data_out_channel[cnt],vsum);
+                cnt += 4;
+            }
+            
+        #else
+            dr_out = dr_out + 1;
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+            if (cnt_num > 0){
+                asm volatile(
+                "s1_ave_loop_1:                                    @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vadd.f32  q5, q0, q2                            @max r0_1234,r1_1234\n"
+                "vadd.f32  d12, d2, d6                            @max r0_5678,r1_5678\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q5, q6, #1                        @vext max_2345\n"
+                "vext.f32  q2, q5, q6, #2                        @vext max_3456\n"
+                "vadd.f32  q1, q5, q0                            @add 1234 + 2345\n"
+                "vadd.f32  q1, q1, q2                            @add + 3456\n"
+                "vmul.f32  q4, q1, %q[vcoef]                     @mul * 1/9.f \n"
+                "sub       %[dr0], #8                            @sub w, 8\n"
+                "sub       %[dr1], #8                            @sub w, 8\n"
+                "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "bne       s1_ave_loop_1                           @bne s1_max_loop\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), [vcoef] "+w" (vcoef)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6"
+                );
+            }
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+        #endif
+            //remian
+            w = w_unroll_size * 4;
+            for(int j = 0; j < w_unroll_remian; j++){
+                float tmp_sum = r0[j + w] + r1[j + w];
+                tmp_sum += (r0[j + w + 1] + r1[j + w + 1]);
+                tmp_sum += (r0[j + w + 2] + r1[j + w + 2]);
+                data_out_channel[j + w + 1] = tmp_sum / 9.f;
+            }
+            //right
+            float tmp = r0[w_in - 2] + r1[w_in - 2];
+            tmp +=(r0[w_in - 1] + r1[w_in - 1]);
+            data_out_channel[w_out-1]  = tmp / 9.f;
+
+           // r0 = r1;
+           // r1 = r0 + w_in;
+           // r2 = r1 + w_in;
+            data_out_channel += w_out;
+            int h = 0;
+            for (; h < h_in - 2; h += 1) {
+                // deal with left pad
+                float maxr0 = r0[0] + r0[1];
+                float maxr1 = r1[0] + r1[1];
+                float maxr2 = r2[0] + r2[1];
+                data_out_channel[0] = (maxr0 + maxr1 + maxr2) / 9.f;
+            #ifdef __aarch64__
+                w = 0;
+                cnt = 1;
+                for (; w < w_in - 6; w += 4) {
+                    float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                    float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                    float32x4_t vr2_1234 = vld1q_f32(&r2[w]);
+                    float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                    float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                    float32x4_t vr2_5678 = vld1q_f32(&r2[w + 4]);
+                    float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                    vsum_1234 = vaddq_f32(vsum_1234, vr2_1234);
+                    float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+                    vsum_5678 = vaddq_f32(vsum_5678, vr2_5678);
+
+                    float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                    float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                    float32x4_t vsum = vaddq_f32(vsum_1234, vsum_2345);
+                    vsum = vaddq_f32(vsum, vsum_3456);
+                    vsum = vmulq_f32(vsum, vcoef);
+                    vst1_f32(&data_out_channel[cnt],vsum);
+                    cnt += 4;
+                }
+            #else
+                 dr_out = data_out_channel + 1;
+                 dr0 = r0;
+                 dr1 = r1;
+                 dr2 = r2;
+                 cnt_num = w_unroll_size;
+                if (cnt_num > 0){
+                    asm volatile(
+                    "s1_ave_loop_mid_1:                                    @main loop\n"
+                    "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d8-d9}, [%[dr2]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d10}, [%[dr2]]!                  @load d4-d7, dr1\n"
+                    "vadd.f32  q7, q0, q2                            @max r0_1234,r1_1234\n"
+                    "vadd.f32  d16, d2, d6                            @max r0_5678,r1_5678\n"
+                    "vadd.f32  q3, q7, q4                            @max r0_1234,r1_1234\n"
+                    "vadd.f32  d12, d16, d10                            @max r0_5678,r1_5678\n"
+                    //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                    "vext.f32  q0, q3, q6, #1                        @vext max_2345\n"
+                    "vext.f32  q2, q3, q6, #2                        @vext max_3456\n"
+                    "vadd.f32  q1, q3, q0                            @add 1234 + 2345\n"
+                    "vadd.f32  q1, q1, q2                            @add + 3456\n"
+                    "vmul.f32  q4, q1, %q[vcoef]                     @mul * 1/9.f \n"
+                    "sub       %[dr0], #8                            @sub w, 8\n"
+                    "sub       %[dr1], #8                            @sub w, 8\n"
+                    "sub       %[dr2], #8                            @sub w, 8\n"
+                    "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                    "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "bne       s1_ave_loop_mid_1                     @bne s1_max_loop\n"
+                   :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr2] "+r" (dr2), [dr_out] "+r" (dr_out), \
+                    [cnt_num] "+r" (cnt_num), [vcoef] "+w" (vcoef)
+                   :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                   :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8"
+                   );
+                }
+            #endif 
+               //remian
+               w = w_unroll_size * 4;
+               for(int j = 0; j < w_unroll_remian; j++){
+                   float tmp_sum = r0[j + w] + r1[j + w];
+                   tmp_sum += (r0[j + w + 1] + r1[j + w + 1]);
+                   tmp_sum += (r0[j + w + 2] + r1[j + w + 2]);
+                   tmp_sum += (r2[j + w + 1] + r2[j + w + 2]);
+                   tmp_sum += r2[j + w];
+                   data_out_channel[j + w + 1] = tmp_sum / 9.f;
+                }
+                //right
+                tmp = r0[w_in - 2] + r1[w_in - 2];
+                tmp += (r0[w_in - 1] + r1[w_in - 1]);
+                tmp += (r2[w_in - 2] + r2[w_in - 1]);
+                data_out_channel[w_out-1]  = tmp / 9.f;
+
+                r0 = r1;
+                r1 = r2;
+                r2 = r1 + w_in;
+                data_out_channel += w_out;
+            }
+
+            //the last two line
+            float maxr0 = (r0[0] + r0[1]);
+            float maxr1 = (r1[0] + r1[1]);
+            data_out_channel[0] = (maxr0 + maxr1) / 9.f;
+            #ifdef __aarch64__
+            w = 0;
+            cnt = 1;
+            for (; w < w_in - 6; w += 4) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+
+                float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                float32x4_t vsum = vaddq_f32(vsum_1234, vsum_2345);
+                vsum = vaddq_f32(vsum, vsum_3456);
+                vsum = vmulq_f32(vsum, vcoef);
+                vst1_f32(&data_out_channel[cnt],vsum);
+                cnt += 4;
+            }
+            #else
+            dr_out = data_out_channel + 1;
+            dr0 = r0;
+            dr1 = r1;
+            cnt_num = w_unroll_size;
+            if (cnt_num > 0){
+                asm volatile(
+                "s1_ave_loop_bot_1:                                 @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d4-d5}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d2}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vadd.f32  q5, q0, q2                            @max r0_1234,r1_1234\n"
+                "vadd.f32  d12, d2, d6                            @max r0_5678,r1_5678\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q5, q6, #1                        @vext max_2345\n"
+                "vext.f32  q2, q5, q6, #2                        @vext max_3456\n"
+                "vadd.f32  q1, q5, q0                            @add 1234 + 2345\n"
+                "vadd.f32  q1, q1, q2                            @add + 3456\n"
+                "vmul.f32  q4, q1, %q[vcoef]                     @mul * 1/9.f \n"
+                "sub       %[dr0], #8                            @sub w, 8\n"
+                "sub       %[dr1], #8                            @sub w, 8\n"
+                "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "bne       s1_ave_loop_bot_1                           @bne s1_max_loop\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), [vcoef] "+w" (vcoef)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6"
+                );
+            }
+            #endif 
+            //remian
+            w = w_unroll_size * 4;
+            for(int j = 0; j < w_unroll_remian; j++){
+                float tmp_sum = r0[j + w] + r1[j + w];
+                tmp_sum += (r0[j + w + 1] + r1[j + w + 1]);
+                tmp_sum += (r0[j + w + 2] + r1[j + w + 2]);
+                data_out_channel[j + w + 1] = tmp_sum / 9.f;
+            }
+            //right
+            tmp = r0[w_in - 2] + r1[w_in - 2];
+            tmp +=(r0[w_in - 1] + r1[w_in - 1]);
+            data_out_channel[w_out-1]  = tmp / 9.f;
+
+        }
+    }
+}
+
 void pooling3x3s2_max(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
     int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h) {
-    //todo
+
+    //no need to pad input tensor, pad_size is not used, default border is zero padded
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+
+    if (global) {
+        LOG(ERROR) << "not supported in this funcs, instead, use the basic func";
+    }
+
+    int size_channel_out = w_out * h_out;
+    int size_channel_in = w_in * h_in;
+    float* data_out = tensor_out.mutable_data();
+    const float* data_in = tensor_in.data();
+
+    int pad_top = pad_h;
+    int pad_left = pad_w;
+    int w_needed = w_out * 2 + 1;
+    int h_needed = h_out * 2 + 1;
+    int pad_right = w_needed - w_in - pad_left;
+    int pad_bottom = h_needed - h_in - pad_top;
+    int w_even = (w_in >> 1) << 1;
+    //int w_remains = w_in - w_even; // should be 0 or 1
+    int h_even = (h_in >> 1) << 1;
+    //int h_remains = h_in - h_even; // should be 0 or 1
+    int w_unroll_size = w_in >> 3;
+    int w_unroll_remian = (w_in - w_unroll_size * 8 - 1) / 2;
+    int w_in_2 = w_in << 1;
+    float minval = std::numeric_limits<float>::lowest();
+    float32x4_t vzero = vdupq_n_f32(minval); //zero pad
+    //printf("minval: %.2f\n", minval);
+
+    for (int n = 0; n < num; ++n) {
+
+        float* data_out_batch = data_out + n * ch_out * size_channel_out;
+        const float* data_in_batch = data_in + n * ch_in * size_channel_in;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out; c++) {
+            float* data_out_channel = data_out_batch + c * size_channel_out;
+            const float* data_in_channel = data_in_batch + c * size_channel_in;
+            const float* r0 = data_in_channel;
+            const float* r1 = r0 + w_in;
+            const float* r2 = r1 + w_in;
+            int cnt_num = w_unroll_size;
+            //w = w_in - 8;
+            int cnt_num1 = w_unroll_remian;
+            float* dr_out = data_out_channel;
+            const float* dr0 = r0;
+            const float* dr1 = r1;
+            const float* dr2 = r2;
+            int w = 1;
+            int cnt = 1;
+            data_out_channel[0] = std::max(std::max(r0[0], r0[1]), std::max(r1[0], r1[1]));
+            // first row with zero pad
+        #ifdef __aarch64__
+            for (; w < w_in - 8; w += 8) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+                float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+                float32x4_t vmax_9101112 = vmaxq_f32(vr0_9101112, vr1_9101112);
+                float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                float32x4_t vmax_6789 = vextq_f32(vmax_5678, vmax_9101112,1);
+                float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                float32x2_t vmax_56_78 = vpmax_f32(vget_low_f32(vmax_5678), vget_high_f32(vmax_5678));
+                float32x2_t vmax_67_89 = vpmax_f32(vget_low_f32(vmax_6789), vget_high_f32(vmax_6789));
+                float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                float32x2_t vmax_567_789 = vmax_f32(vmax_56_78, vmax_67_89);
+                vst1_f32(&data_out_channel[cnt],vmax_123_345);
+                vst1_f32(&data_out_channel[cnt + 2],vmax_567_789);
+                cnt += 4;
+            }
+            for(; w < w_even - 1; w += 2){
+                float32x4_t vr0= vld1q_f32(&r0[w]);
+                float32x4_t vr1= vld1q_f32(&r1[w]);
+                vr0 = vsetq_lane_f32(minval, vr0, 3);
+                vr1 = vsetq_lane_f32(minval, vr1, 3);
+                float32x4_t vmax1 = vmaxq_f32(vr0, vr1);
+                float32x2_t vmax2 = vpmax_f32(vget_low_f32(vmax1), vget_high_f32(vmax1));
+                vmax2 = vpmax_f32(vmax2, vmax2);
+                data_out_channel[cnt] = vget_lane_f32(vmax2, 0);
+                cnt ++;
+            }
+        #else
+            dr0 = dr0 + 1;
+            dr1 = dr1 + 1;
+            dr_out = dr_out + 1;
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+            if (cnt_num > 0 || cnt_num1 > 0){
+                asm volatile(
+                "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                "ble       loop2                                  @ble exit\n"
+                "s3_max_loop:                                    @main loop\n"
+                "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d10}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vmax.f32  q6, q0, q3                            @max r0_1234,r1_1234\n"
+                "vmax.f32  q7, q1, q4                            @max r0_5678,r1_5678\n"
+                "vmax.f32  d16, d4, d10                            @max r0_910,r1_910\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q6, q7, #1                        @vext max_2345\n"
+                "vext.f32  q1, q7, q8, #1                        @vext max_6789\n"
+                "vpmax.f32 d4, d12, d13                          @pmax d4, vmax_1234, vmax_1234\n"
+                "vpmax.f32 d6, d14, d15                          @pmax d6, vmax_5678, vmax_5678\n"
+                "vpmax.f32 d5, d0, d1                            @pmax d5, vmax_2345, vmax_2345\n"
+                "vpmax.f32 d7, d2, d3                            @pmax d7, vmax_6789, vmax_6789\n"
+                "vmax.f32 d8, d4, d5                             @max d2, vmax_12_34, vmax_23_45\n"
+                "vmax.f32 d9, d6, d7                             @max d2, vmax_56_78, vmax_67_89\n"
+                "sub       %[dr0], #8                           @add w, 8\n"
+                "sub       %[dr1], #8                           @add w, 8\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                "bne       s3_max_loop                           @bne s3_max_loop\n"
+                "loop2:                                           @loop \n"
+                "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                "ble       exit                                  @ble exit\n"
+                "s3_max_loop_1:                                  @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                "vld1.f32  {d2-d3}, [%[dr1]]!                     @load d2-d3, dr1\n"
+                "vmov.f32  s3,s2                                 @movs3, s2\n"
+                "vmov.f32  s7,s6                                 @movs7, s6\n"
+                "vmax.f32  q0, q0, q1                            @max q0, q0, q1\n"
+                "vpmax.f32 d0, d0, d1                            @pmax d0, d0,d1\n"
+                "vpmax.f32 d0, d0, d0                            @pmax d0, d0, d0\n"
+                "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                "sub       %[dr0], #8                            @add w, 6\n"
+                "sub       %[dr1], #8                            @add w, 6\n"
+                "subs      %[cnt_num1], #1                           @subs cnt_num, #1\n"
+                "bne       s3_max_loop_1                         @bne s3_max_loop_1\n"
+                "exit:                                           @exit\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), [cnt_num1] "+r" (cnt_num1)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9"
+                );
+            }
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+        #endif
+            //int w = w_even - 1;
+            if (pad_right){
+                // deal with right pad
+                int wstart = (w_even >> 1) * stride_w - pad_w;
+                int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                float tmp = r0[wstart];//std::numeric_limits<float>::min();
+                for(int i = wstart; i < wend; i++){//only run 1 or 2 times
+                    tmp = std::max(tmp,std::max(r0[i],r1[i]));
+                }
+                data_out_channel[w_even >> 1] = tmp;
+                //cnt ++;
+            }
+
+            r0 = r1;
+            r1 = r0 + w_in;
+            r2 = r1 + w_in;
+            data_out_channel += w_out;
+            int h = 2;
+            for (; h < h_even; h += 2) {
+                // deal with left pad
+                float maxr0 = std::max(r0[0], r0[1]);
+                float maxr1 = std::max(r1[0], r1[1]);
+                float maxr2 = std::max(r2[0], r2[1]);
+                data_out_channel[0] = std::max(std::max(maxr0, maxr1), maxr2);
+            #ifdef __aarch64__
+                w = 1;
+                cnt = 1;
+                for (; w < w_in - 8; w += 8) {
+                    float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                    float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                    float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                    float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                    float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                    float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+                    float32x4_t vr2_1234 = vld1q_f32(&r2[w]);
+                    float32x4_t vr2_5678 = vld1q_f32(&r2[w + 4]);
+                    float32x4_t vr2_9101112 = vld1q_f32(&r2[w + 8]);
+                    float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                    vmax_1234 = vmaxq_f32(vmax_1234, vr2_1234);
+                    float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+                    vmax_5678 = vmaxq_f32(vmax_5678, vr2_5678);
+                    float32x4_t vmax_9101112 = vmaxq_f32(vr0_9101112, vr1_9101112);
+                    vmax_9101112 = vmaxq_f32(vmax_9101112, vr2_9101112);
+                    float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                    float32x4_t vmax_6789 = vextq_f32(vmax_5678, vmax_9101112,1);
+                    float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                    float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                    float32x2_t vmax_56_78 = vpmax_f32(vget_low_f32(vmax_5678), vget_high_f32(vmax_5678));
+                    float32x2_t vmax_67_89 = vpmax_f32(vget_low_f32(vmax_6789), vget_high_f32(vmax_6789));
+                    float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                    float32x2_t vmax_567_789 = vmax_f32(vmax_56_78, vmax_67_89);
+                    vst1_f32(&data_out_channel[cnt],vmax_123_345);
+                    vst1_f32(&data_out_channel[cnt + 2],vmax_567_789);
+                    cnt += 4;
+                }
+                for (; w < w_even - 1; w += 2) {
+                    float32x4_t vr0 = vld1q_f32(&r0[w]);
+                    float32x4_t vr1 = vld1q_f32(&r1[w]);
+                    float32x4_t vr2 = vld1q_f32(&r2[w]);
+                    vr0 = vsetq_lane_f32(minval, vr0, 3);
+                    vr1 = vsetq_lane_f32(minval, vr1, 3);
+                    vr2 = vsetq_lane_f32(minval, vr2, 3);
+                    float32x4_t vmax1 = vmaxq_f32(vr0, vr1);
+                    vmax1 = vmaxq_f32(vmax1, vr2);
+                    float32x2_t vmax2 = vpmax_f32(vget_low_f32(vmax1), vget_high_f32(vmax1));
+                    float32x2_t vmax = vpmax_f32(vmax2, vmax2);
+                    data_out_channel[cnt] = vget_lane_f32(vmax, 0);
+                    cnt ++;
+                }
+            #else
+                 dr_out = data_out_channel + 1;
+                 dr0 = (r0 + 1);
+                 dr1 = (r1 + 1);
+                 dr2 = (r2 + 1);
+                 cnt_num = w_unroll_size;
+                 cnt_num1 = w_unroll_remian;
+                if (cnt_num > 0 || cnt_num1 > 0){
+                    asm volatile(
+                    "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                    "ble       loop3                                  @ble exit\n"
+                    "s3_max_loop_mid:                                @main loop\n"
+                    "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d12-d15}, [%[dr2]]!                   @load d4-d7, dr1\n"
+                    "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d10}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d16}, [%[dr2]]!                   @load d4-d7, dr1\n"
+                    "vmax.f32  q9, q0, q3                            @max q0,q0,q2\n"
+                    "vmax.f32  q10, q1, q4                           @max q1,q1,q3\n"
+                    "vmax.f32  d22, d4, d10                           @max q1,q1,q3\n"
+                    "vmax.f32  q0, q9, q6                            @max q0,q0,q2 1234\n"
+                    "vmax.f32  q3, q10, q7                           @max q1,q1,q3 5678\n"
+                    "vmax.f32  d2, d22, d16                           @max q1,q1,q3 9101112\n"
+                    //"vmov.f32  s7,s6                               @mov s7, s6\n"
+                    "vext.f32  q4, q0, q3, #1                        @vext 2345\n"
+                    "vext.f32  q2, q3, q1, #1                        @vext 6789\n"
+                    "vpmax.f32 d10, d0, d1                           @pmax d10, vmax_1234, vmax_1234\n"
+                    "vpmax.f32 d12, d6, d7                           @pmax d12, vmax_5678, vmax_5678\n"
+                    "vpmax.f32 d11, d8, d9                           @pmax d11, vmax_2345, vmax_2345\n"
+                    "vpmax.f32 d13, d4, d5                           @pmax d13, vmax_6789, vmax_6789\n"
+                    "vmax.f32 d0, d10, d11                          @pmax d0, vmax_12_34, vmax_23_45\n"
+                    "vmax.f32 d1, d12, d13                          @pmax d1, vmax_56_78, vmax_67_89\n"
+                    "sub       %[dr0], #8                           @add w, 8\n"
+                    "sub       %[dr1], #8                           @add w, 8\n"
+                    "sub       %[dr2], #8                           @add w, 8\n"
+                    "vst1.f32  d0, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "vst1.f32  d1, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                    "bne       s3_max_loop_mid                       @bne s3_max_loop_mid\n"
+                    "loop3:                                       @loop \n"
+                    "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                    "ble       exit1                                 @ble exit1\n"
+                    "s3_max_loop_mid_1:                              @mid loop\n"
+                    "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                    "vld1.f32  {d2-d3}, [%[dr1]]!                    @load d2-d3, dr1\n"
+                    "vld1.f32  {d4-d5}, [%[dr2]]!                     @load d2-d3, dr1\n"
+                    "vmov.f32  s3,s2                                 @movs3, s2\n"
+                    "vmov.f32  s7,s6                                 @movs7, s6\n"
+                    "vmov.f32  s11,s10                               @movs11, s10\n"
+                    "vmax.f32  q0, q0, q1                            @max q0, q0, q1\n"
+                    "vmax.f32  q0, q0, q2                            @max q0, q0, q2\n"
+                    "vpmax.f32 d0, d0, d1                            @pmax d0, d0,d1\n"
+                    "vpmax.f32 d0, d0, d0                            @pmax d0, d0, d0\n"
+                    "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                    "sub       %[dr0], #8                            @add w, 6\n"
+                    "sub       %[dr1], #8                            @add w, 6\n"
+                    "sub       %[dr2], #8                            @add w, 6\n"
+                    "subs      %[cnt_num1], #1                       @subs cnt_num, #1\n"
+                    "bne       s3_max_loop_mid_1                     @bne s3_max_loop_mid_1\n"
+                    "exit1:                                           @exit\n"
+                    :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr2] "+r" (dr2), [dr_out] "+r" (dr_out), \
+                     [cnt_num] "+r" (cnt_num), [cnt_num1] "+r" (cnt_num1)
+                    :"r" (dr0), "r" (dr1), "r" (dr2), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                    :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9", "q10", "q11", "q12"
+                    );
+                }
+            #endif 
+                if (pad_right){
+                    // deal with right pad
+                     int wstart = (w_even >> 1) * stride_w - pad_w;
+                     int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                     float tmp = r0[wstart];//std::numeric_limits<float>::min();
+                    for(int i = wstart; i < wend; i++){
+                        tmp = std::max(tmp,std::max(r0[i],r1[i]));
+                        tmp = std::max(tmp,r2[i]);
+                    }
+                    data_out_channel[w_even >> 1] = tmp;
+                    //cnt ++;
+                }
+                r0 = r2;
+                r1 = r0 + w_in;
+                r2 = r1 + w_in;
+                data_out_channel += w_out;
+            }
+
+            if (pad_bottom) {
+                //deal with bottom pad
+                // first row with zero pad
+                int hstart = (h >> 1) * stride_h - pad_h;
+                int hend = std::min(std::min(hstart + kernel_h, h_in + pad_h),h_in);
+    
+                if(hstart == hend - 1){//only one lline
+                    data_out_channel[0] = std::max(r0[0], r0[1]);
+               #ifdef __aarch64__
+                    w = 1;
+                    cnt = 1;
+                    for (; w < w_in - 8; w += 8) {
+                        float32x4_t vmax_1234 = vld1q_f32(&r0[w]);
+                        float32x4_t vmax_5678 = vld1q_f32(&r0[w + 4]);
+                        float32x4_t vmax_9101112 = vld1q_f32(&r0[w + 8]);
+                        float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                        float32x4_t vmax_6789 = vextq_f32(vmax_5678, vmax_9101112,1);
+                        float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                        float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                        float32x2_t vmax_56_78 = vpmax_f32(vget_low_f32(vmax_5678), vget_high_f32(vmax_5678));
+                        float32x2_t vmax_67_89 = vpmax_f32(vget_low_f32(vmax_6789), vget_high_f32(vmax_6789));
+                        float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                        float32x2_t vmax_567_789 = vmax_f32(vmax_56_78, vmax_67_89);
+                        vst1_f32(&data_out_channel[cnt],vmax_123_345);
+                        vst1_f32(&data_out_channel[cnt + 2],vmax_567_789);
+                        cnt += 4;
+                    }
+                    for(; w < w_even - 1; w += 2){
+                        float32x4_t vr0= vld1q_f32(&r0[w]);
+                        vr0 = vsetq_lane_f32(minval, vr0, 3);
+                        float32x2_t vmax = vpmax_f32(vget_low_f32(vr0), vget_high_f32(vr0));
+                        vmax = vpmax_f32(vmax, vmax);
+                        data_out_channel[cnt] = vget_lane_f32(vmax, 0);
+                        cnt ++;
+                    }
+                #else
+                    dr_out = data_out_channel + 1;
+                    dr0 = (r0 + 1);
+                    cnt_num = w_unroll_size;
+                    cnt_num1 = w_unroll_remian;
+                    if (cnt_num > 0 || cnt_num1 > 0){
+                        asm volatile(
+                        "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                        "ble       loop4                                  @ble exit\n"
+                        "s3_max_loop_bot:                                @main loop\n"
+                        "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vext.f32  q4, q0, q1, #1                        @vext q4, q0, q1, 1 2345\n"
+                        "vext.f32  q5, q1, q2, #1                        @vext q5, q0, q1, 1 6789\n"
+                        "vpmax.f32 d12, d0, d1                           @pmax d12, vmax_1234, vmax_1234\n"
+                        "vpmax.f32 d14, d2, d3                           @pmax d14, vmax_5678, vmax_5678\n"
+                        "vpmax.f32 d13, d8, d9                           @pmax d13, vmax_2345, vmax_2345\n"
+                        "vpmax.f32 d15, d10, d11                         @pmax d15, vmax_6789, vmax_6789\n"
+                        "vmax.f32  d0, d12, d13                          @max d0, vmax_12_34,vmax_23_45\n"
+                        "vmax.f32  d1, d14, d15                          @pmax d2, vmax_56_78, vmax_67_89\n"
+                        "sub       %[dr0], #8                           @add w, 6\n"
+                        "vst1.f32  d0, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "vst1.f32  d1, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                        "bne       s3_max_loop_bot                       @bne s3_max_loop_bot\n"
+                        "loop4:                                       @loop \n"
+                        "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                        "ble       exit3                                 @ble exit\n"
+                        "s3_max_loop_bot_1:                              @bot loop\n"
+                        "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                        "vmov.f32  s3,s2                                 @movs3, s2\n"
+                        "vpmax.f32 d0, d0, d1                            @pmax d0, d0,d1\n"
+                        "vpmax.f32 d0, d0, d0                            @pmax d0, d0, d0\n"
+                        "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                        "sub       %[dr0], #8                            @add w, 2\n"
+                        "subs      %[cnt_num1], #1                           @subs cnt_num, #1\n"
+                        "bne       s3_max_loop_bot_1                     @bne s3_max_loop_bot_1\n"
+                        "exit3:                                          @exit\n"
+                        :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), [cnt_num1] "+r" (cnt_num1)
+                        :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                        :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8"
+                        );
+                    }
+                #endif
+                    if (pad_right){
+                        // deal with right pad
+                        int wstart = (w_even >> 1) * stride_w - pad_w;
+                        int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                        float tmp = r0[wstart];//std::numeric_limits<float>::min();
+                        for(int i = wstart; i < wend; i++){
+                            tmp = std::max(tmp,r0[i]);
+                        }
+                        data_out_channel[w_even >> 1] = tmp;
+                    }
+                }else{//two lines
+                    data_out_channel[0] = std::max(std::max(r0[0], r0[1]), std::max(r1[0], r1[1]));
+                #ifdef __aarch64__
+                    w = 1;
+                    cnt = 1;
+                    for (; w < w_in - 8; w += 8) {
+                        float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                        float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                        float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                        float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                        float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                        float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+                        float32x4_t vmax_1234 = vmaxq_f32(vr0_1234, vr1_1234);
+                        float32x4_t vmax_5678 = vmaxq_f32(vr0_5678, vr1_5678);
+                        float32x4_t vmax_9101112 = vmaxq_f32(vr0_9101112, vr1_9101112);
+                        float32x4_t vmax_2345 = vextq_f32(vmax_1234, vmax_5678,1);
+                        float32x4_t vmax_6789 = vextq_f32(vmax_5678, vmax_9101112,1);
+                        float32x2_t vmax_12_34 = vpmax_f32(vget_low_f32(vmax_1234), vget_high_f32(vmax_1234));
+                        float32x2_t vmax_23_45 = vpmax_f32(vget_low_f32(vmax_2345), vget_high_f32(vmax_2345));
+                        float32x2_t vmax_56_78 = vpmax_f32(vget_low_f32(vmax_5678), vget_high_f32(vmax_5678));
+                        float32x2_t vmax_67_89 = vpmax_f32(vget_low_f32(vmax_6789), vget_high_f32(vmax_6789));
+                        float32x2_t vmax_123_345 = vmax_f32(vmax_12_34, vmax_23_45);
+                        float32x2_t vmax_567_789 = vmax_f32(vmax_56_78, vmax_67_89);
+                        vst1_f32(&data_out_channel[cnt],vmax_123_345);
+                        vst1_f32(&data_out_channel[cnt + 2],vmax_567_789);
+                        cnt += 4;
+                    }
+                for(; w < w_even - 1; w += 2){
+                    float32x4_t vr0= vld1q_f32(&r0[w]);
+                    float32x4_t vr1= vld1q_f32(&r1[w]);
+                    vr0 = vsetq_lane_f32(minval, vr0, 3);
+                    vr1 = vsetq_lane_f32(minval, vr1, 3);
+                    float32x4_t vmax1 = vmaxq_f32(vr0, vr1);
+                    float32x2_t vmax2 = vpmax_f32(vget_low_f32(vmax1), vget_high_f32(vmax1));
+                    vmax2 = vpmax_f32(vmax2, vmax2);
+                    data_out_channel[cnt] = vget_lane_f32(vmax2, 0);
+                    cnt ++;
+                }
+                #else 
+                    dr_out = data_out_channel + 1;
+                    dr0 = (r0 + 1);
+                    dr1 = (r1 + 1);
+                    cnt_num = w_unroll_size;
+                    cnt_num1 = w_unroll_remian;
+                    if (cnt_num > 0 || cnt_num1 > 0){
+                        asm volatile(
+                        "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                        "ble       loop5                                  @ble exit\n"
+                        "s3_max_loop_bot1:                               @main loop\n"
+                        "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                        "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                        "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vld1.f32  {d10}, [%[dr1]]!                  @load d4-d7, dr1\n"
+                        "vmax.f32  q6, q0, q3                            @max q0,q0,q2 1234\n"
+                        "vmax.f32  q7, q1, q4                            @max q1,q1,q3 5678\n"
+                        "vmax.f32  d16, d4, d10                            @max q1,q1,q3 9101112\n"
+                        //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                        "vext.f32  q0, q6, q7, #1                        @vext q0, 2345\n"
+                        "vext.f32  q1, q7, q8, #1                        @vext q1, 6789\n"
+                        "vpmax.f32 d4, d12, d13                          @pmax d4, vmax_1234, vmax_1234\n"
+                        "vpmax.f32 d6, d14, d15                          @pmax d6, vmax_5678, vmax_5678\n"
+                        "vpmax.f32 d5, d0, d1                            @pmax d5, vmax_2345, vmax_2345\n"
+                        "vpmax.f32 d7, d2, d3                            @pmax d7, vmax_6789, vmax_6789\n"
+                        "vmax.f32 d8, d4, d5                             @max d2, vmax_12_34, vmax_23_45\n"
+                        "vmax.f32 d9, d6, d7                             @max d2, vmax_56_78, vmax_67_89\n"
+                        "sub       %[dr0], #8                           @add w, 8\n"
+                        "sub       %[dr1], #8                           @add w, 8\n"
+                        "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                        "bne       s3_max_loop_bot1                      @bne s3_max_loop_bot\n"
+                        "loop5:                                      @loop \n"
+                        "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                        "ble       exit4                                 @ble exit\n"
+                        "s3_max_loop_bot1_1:                             @bot loop\n"
+                        "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                        "vld1.f32  {d2-d3}, [%[dr1]]!                     @load d2-d3, dr1\n"
+                        "vmov.f32  s3,s2                                 @movs3, s2\n"
+                        "vmov.f32  s7,s6                                 @movs7, s6\n"
+                        "vmax.f32  q0, q0, q1                            @max q0, q0, q1\n"
+                        "vpmax.f32 d0, d0, d1                            @pmax d0, d0,d1\n"
+                        "vpmax.f32 d0, d0, d0                            @pmax d0, d0, d0\n"
+                        "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                        "sub       %[dr0], #8                            @add w, 6\n"
+                        "sub       %[dr1], #8                            @add w, 6\n"
+                        "subs      %[cnt_num1], #1                           @subs cnt_num, #1\n"
+                        "bne       s3_max_loop_bot1_1                    @bne s3_max_loop_bot_1\n"
+                        "exit4:                                          @exit\n"
+                        :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), [cnt_num1] "+r" (cnt_num1)
+                        :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                        :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9"
+                        );
+                    }
+                #endif
+                    if (pad_right){
+                     // deal with right pad
+                        int wstart = (w_even >> 1) * stride_w - pad_w;
+                        int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                        float tmp = r0[wstart];//std::numeric_limits<float>::min();
+                        for(int i = wstart; i < wend; i++){//only run 1 or 2 times
+                            tmp = std::max(tmp,std::max(r0[i],r1[i]));
+                        }
+                        data_out_channel[w_even >> 1] = tmp;
+                    }
+                }
+            }
+
+        }
+    }
 }
 
 void pooling3x3s2_ave(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
     int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h) {
-    //todo
-}
 
+    //no need to pad input tensor, pad_size is not used, default border is zero padded
+
+    int w_in = tensor_in.width();
+    int h_in = tensor_in.height();
+    int ch_in = tensor_in.channel();
+    int num = tensor_in.num();
+
+    int w_out = tensor_out.width();
+    int h_out = tensor_out.height();
+    int ch_out = tensor_out.channel();
+
+    if (global) {
+        LOG(ERROR) << "not supported in this funcs, instead, use the basic func";
+    }
+
+    int size_channel_out = w_out * h_out;
+    int size_channel_in = w_in * h_in;
+    float* data_out = tensor_out.mutable_data();
+    const float* data_in = tensor_in.data();
+
+    int pad_top = pad_h;
+    int pad_left = pad_w;
+    int w_needed = w_out * 2 + 1;
+    int h_needed = h_out * 2 + 1;
+    int pad_right = w_needed - w_in - pad_left;
+    int pad_bottom = h_needed - h_in - pad_top;
+    int w_even = (w_in >> 1) << 1;
+    //int w_remains = w_in - w_even; // should be 0 or 1
+    int h_even = (h_in >> 1) << 1;
+    //int h_remains = h_in - h_even; // should be 0 or 1
+    //int w_unroll_size = (w_even >> 3) << 3;
+    //int w_unroll_remian = w_even - w_unroll_size;
+    int w_in_2 = w_in << 1;
+    //float minval = std::numeric_limits<float>::lowest();
+    //printf("minval: %.2f\n", minval);
+    int w_unroll_size = w_in >> 3;
+    int w_unroll_remian = (w_even - w_unroll_size * 8 - 1) / 2;
+
+    for (int n = 0; n < num; ++n) {
+
+        float* data_out_batch = data_out + n * ch_out * size_channel_out;
+        const float* data_in_batch = data_in + n * ch_in * size_channel_in;
+#pragma omp parallel for
+        for (int c = 0; c < ch_out; c++) {
+            float* data_out_channel = data_out_batch + c * size_channel_out;
+            const float* data_in_channel = data_in_batch + c * size_channel_in;
+            const float* r0 = data_in_channel;
+            const float* r1 = r0 + w_in;
+            const float* r2 = r1 + w_in;
+            int cnt_num = w_unroll_size;
+            int cnt_num1 = w_unroll_remian;
+            float* dr_out = data_out_channel;
+            const float* dr0 = r0;
+            const float* dr1 = r1;
+            const float* dr2 = r2;
+            int w = 1;
+            int cnt = 1;
+            float32x4_t vcoef = vdupq_n_f32(1.f/9.f);
+            float32x4_t vzero = vdupq_n_f32(0.f); 
+            data_out_channel[0] = (r0[0] + r0[1] + r1[0] + r1[1])/9.f;
+            // first row with zero pad
+        #ifdef __aarch64__
+            for (; w < w_in - 8; w += 8) {
+                float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+                float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+                float32x4_t vsum_9101112 = vaddq_f32(vr0_9101112, vr1_9101112);
+
+                float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                float32x4_t vsum_4567 = vextq_f32(vsum_1234, vsum_5678,3);
+                float32x4_t vsum_6789 = vextq_f32(vsum_5678, vsum_9101112,1);
+                float32x4_t vsum_123_345 = vaddq_f32(vsum_1234, vsum_2345);
+                vsum_123_345 = vaddq_f32(vsum_123_345, vsum_3456);
+                float32x4_t vsum_567_789 = vaddq_f32(vsum_4567, vsum_5678);
+                vsum_567_789 = vaddq_f32(vsum_567_789, vsum_6789);
+                vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_123_345,2), vsum_123_345, 1);
+                vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,1), vsum_123_345, 2);
+                vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,3), vsum_123_345, 3);
+                float32x4_t vrst = vmulq_f32(vsum_123_345, vcoef);
+                vst1q_f32(&data_out_channel[cnt], vrst);
+                cnt += 4;
+            }
+            for(; w < w_even - 1; w += 2){
+                float32x4_t vr0= vld1q_f32(&r0[w]);
+                float32x4_t vr1= vld1q_f32(&r1[w]);
+                vr0 = vsetq_lane_f32(0.f, vr0, 3);
+                vr1 = vsetq_lane_f32(0.f, vr1, 3);
+                float32x4_t vsum1 = vaddq_f32(vr0, vr1);
+                float32x2_t vsum2 = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));
+                vsum2 = vpadd_f32(vsum2, vsum2);
+                float32x2_t vrst = vmul_f32(vsum2, vget_low_f32(vcoef));
+                data_out_channel[cnt] = vget_lane_f32(vrst, 0);
+                cnt ++;
+            }
+        #else
+            dr0 = dr0 + 1;
+            dr1 = dr1 + 1;
+            dr_out = dr_out + 1;
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+            if (cnt_num > 0 || cnt_num1 > 0){
+                asm volatile(
+                "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                "ble       loop2_ave                                  @ble exit\n"
+                "s3_ave_loop:                                    @main loop\n"
+                "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                "vld1.f32  {d10}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                "vadd.f32  q6, q0, q3                            @max r0_1234,r1_1234\n"
+                "vadd.f32  q7, q1, q4                            @max r0_5678,r1_5678\n"
+                "vadd.f32  d16, d4, d10                           @max r0_9101112,r1_9101112\n"
+                //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                "vext.f32  q0, q6, q7, #1                        @vext max_2345\n"
+                "vext.f32  q1, q6, q7, #3                        @vext max_4567\n"
+                "vext.f32  q2, q6, q7, #2                        @vext max_3456\n"
+                "vext.f32  q3, q7, q8, #1                        @vext max_6789\n"
+                "vadd.f32  q4, q6, q0                            @add 1234, 2345 \n"
+                "vadd.f32  q5, q7, q1                            @add 5678, 4567 \n"
+                "vadd.f32  q4, q4, q2                            @add 3456, sum1 \n"
+                "vadd.f32  q5, q5, q3                            @add 6789, sum2 \n"
+                "vmov.f32  s17, s18                              @mov \n"
+                "vmov.f32  s18, s21                              @mov \n"
+                "vmov.f32  s19, s23                              @mov \n"
+                "vmul.f32  q4, q4, %q[vcoef]                     @mul \n"
+                "sub       %[dr0], #8                           @add w, 8\n"
+                "sub       %[dr1], #8                           @add w, 8\n"
+                "subs      %[cnt_num], #1                        @subs cnt_num, #1\n"
+                "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                "bne       s3_ave_loop                           @bne s3_max_loop\n"
+                "loop2_ave:                                           @loop \n"
+                "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                "ble       exit_ave                                  @ble exit\n"
+                "s3_ave_loop_1:                                  @main loop\n"
+                "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                "vld1.f32  {d2-d3}, [%[dr1]]!                     @load d2-d3, dr1\n"
+                "vext.f32  q0, %q[vzero], q0, #3                 @ ext v0_0123\n"
+                "vext.f32  q1, %q[vzero], q1, #3                 @ ext v1_0123\n"
+                "vadd.f32  q0, q0, q1                            @add q0, q0, q1\n"
+                "vpadd.f32 d0, d0, d1                            @padd d0, d0,d1\n"
+                "vpadd.f32 d0, d0, d0                            @padd d0, d0, d0\n"
+                "vmul.f32  d0, d0, %e[vcoef]                     @mul \n"
+                "sub       %[dr0], #8                            @add w, 6\n"
+                "sub       %[dr1], #8                            @add w, 6\n"
+                "subs      %[cnt_num1], #1                       @subs cnt_num, #1\n"
+                "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                "bne       s3_ave_loop_1                         @bne s3_max_loop_1\n"
+                "exit_ave:                                           @exit\n"
+                :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), \
+                 [cnt_num1] "+r" (cnt_num1), [vcoef] "+w" (vcoef), [vzero] "+w" (vzero)
+                :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9"
+                );
+            }
+           // printf("cnt_num: %d, cnt_num1: %d \n",cnt_num, cnt_num1);
+        #endif
+            //int w = w_even - 1;
+            if (pad_right){
+                // deal with right pad
+                int wstart = (w_even >> 1) * stride_w - pad_w;
+                int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                float tmp = 0.f;//std::numeric_limits<float>::min();
+                for(int i = wstart; i < wend; i++){//only run 1 or 2 times
+                    tmp += (r0[i] + r1[i]);
+                }
+                data_out_channel[w_even >> 1] = tmp / 9.f;
+                //cnt ++;
+            }
+
+            r0 = r1;
+            r1 = r0 + w_in;
+            r2 = r1 + w_in;
+            data_out_channel += w_out;
+            int h = 2;
+            for (; h < h_even; h += 2) {
+                // deal with left pad
+                float sum0 = r0[0] + r0[1];
+                float sum1 = r1[0] + r1[1];
+                float sum2 = r2[0] + r2[1];
+                data_out_channel[0] = (sum0 + sum1 + sum2) / 9.f;
+            #ifdef __aarch64__
+                w = 1;
+                cnt = 1;
+                for (; w < w_in - 8; w += 8) {
+                    float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                    float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                    float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                    float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                    float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                    float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+                    float32x4_t vr2_1234 = vld1q_f32(&r2[w]);
+                    float32x4_t vr2_5678 = vld1q_f32(&r2[w + 4]);
+                    float32x4_t vr2_9101112 = vld1q_f32(&r2[w + 8]);
+                    float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                    float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+                    float32x4_t vsum_9101112 = vaddq_f32(vr0_9101112, vr1_9101112);
+                    vsum_1234 = vaddq_f32(vsum_1234, vr2_1234);
+                    vsum_5678 = vaddq_f32(vsum_5678, vr2_5678);
+                    vsum_9101112 = vaddq_f32(vsum_9101112, vr2_9101112);
+
+                    float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                    float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                    float32x4_t vsum_4567 = vextq_f32(vsum_1234, vsum_5678,3);
+                    float32x4_t vsum_6789 = vextq_f32(vsum_5678, vsum_9101112,1);
+                    float32x4_t vsum_123_345 = vaddq_f32(vsum_1234, vsum_2345);
+                    vsum_123_345 = vaddq_f32(vsum_123_345, vsum_3456);
+                    float32x4_t vsum_567_789 = vaddq_f32(vsum_4567, vsum_5678);
+                    vsum_567_789 = vaddq_f32(vsum_567_789, vsum_6789);
+                    vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_123_345,2), vsum_123_345, 1);
+                    vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,1), vsum_123_345, 2);
+                    vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,3), vsum_123_345, 3);
+                    float32x4_t vrst = vmulq_f32(vsum_123_345, vcoef);
+                    vst1q_f32(&data_out_channel[cnt],vrst);
+                    cnt += 4;
+                }
+                for (; w < w_even - 1; w += 2) {
+                    float32x4_t vr0 = vld1q_f32(&r0[w]);
+                    float32x4_t vr1 = vld1q_f32(&r1[w]);
+                    float32x4_t vr2 = vld1q_f32(&r2[w]);
+                    vr0 = vsetq_lane_f32(0.f, vr0, 3);
+                    vr1 = vsetq_lane_f32(0.f, vr1, 3);
+                    vr2 = vsetq_lane_f32(0.f, vr2, 3);
+                    float32x4_t vsum1 = vaddq_f32(vr0, vr1);
+                    vsum1 = vaddq_f32(vsum1, vr2);
+                    float32x2_t vsum2 = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));
+                    float32x2_t vsum = vpadd_f32(vsum2, vsum2);
+                    data_out_channel[cnt] = vget_lane_f32(vsum, 0) / 9.f;
+                    cnt ++;
+                }
+            #else
+                 dr_out = data_out_channel + 1;
+                 dr0 = (r0 + 1);
+                 dr1 = (r1 + 1);
+                 dr2 = (r2 + 1);
+                 cnt_num = w_unroll_size;
+                 cnt_num1 = w_unroll_remian;
+                if (cnt_num > 0 || cnt_num1 > 0){
+                    asm volatile(
+                    "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                    "ble       loop3_ave                                  @ble exit\n"
+                    "s3_ave_loop_mid:                                @main loop\n"
+                    "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d12-d15}, [%[dr2]]!                   @load d4-d7, dr1\n"
+                    "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                    "vld1.f32  {d10}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                    "vld1.f32  {d16}, [%[dr2]]!                   @load d4-d7, dr1\n"
+                    "vadd.f32  q9, q0, q3                            @max q0,q0,q2\n"
+                    "vadd.f32  q10, q1, q4                           @max q1,q1,q3\n"
+                    "vadd.f32  d22, d4, d10                           @max q1,q1,q3\n"
+                    "vadd.f32  q6, q9, q6                            @max q0,q0,q2 1234\n"
+                    "vadd.f32  q7, q10, q7                           @max q1,q1,q3 5678\n"
+                    "vadd.f32  d16, d22, d16                           @max q1,q1,q3 9101112\n"
+                    //"vmov.f32  s7,s6                               @mov s7, s6\n"
+                    "vext.f32  q0, q6, q7, #1                        @vext max_2345\n"
+                    "vext.f32  q1, q6, q7, #3                        @vext max_4567\n"
+                    "vext.f32  q2, q6, q7, #2                        @vext max_3456\n"
+                    "vext.f32  q3, q7, q8, #1                        @vext max_6789\n"
+                    "vadd.f32  q4, q6, q0                            @add 1234, 2345 \n"
+                    "vadd.f32  q5, q7, q1                            @add 5678, 4567 \n"
+                    "vadd.f32  q4, q4, q2                            @add 3456, sum1 \n"
+                    "vadd.f32  q5, q5, q3                            @add 6789, sum2 \n"
+                    "vmov.f32  s17, s18                              @mov \n"
+                    "vmov.f32  s18, s21                              @mov \n"
+                    "vmov.f32  s19, s23                              @mov \n"
+                    "vmul.f32  q4, q4, %q[vcoef]                     @mul \n"
+                    "sub       %[dr0], #8                           @add w, 8\n"
+                    "sub       %[dr1], #8                           @add w, 8\n"
+                    "sub       %[dr2], #8                           @add w, 8\n"
+                    "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                    "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                    "bne       s3_ave_loop_mid                       @bne s3_max_loop_mid\n"
+                    "loop3_ave:                                       @loop \n"
+                    "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                    "ble       exit1_ave                                 @ble exit1\n"
+                    "s3_ave_loop_mid_1:                              @mid loop\n"
+                    "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                    "vld1.f32  {d2-d3}, [%[dr1]]!                    @load d2-d3, dr1\n"
+                    "vld1.f32  {d4-d5}, [%[dr2]]!                     @load d2-d3, dr1\n"
+                    "vext.f32  q0, %q[vzero], q0, #3                 @ ext v0_0123\n"
+                    "vext.f32  q1, %q[vzero], q1, #3                 @ ext v1_0123\n"
+                    "vext.f32  q2, %q[vzero], q2, #3                 @ ext v1_0123\n"
+                    "vadd.f32  q0, q0, q1                            @add q0, q0, q1\n"
+                    "vadd.f32  q0, q0, q2                            @add q0, q0, q1\n"
+                    "vpadd.f32 d0, d0, d1                            @padd d0, d0,d1\n"
+                    "vpadd.f32 d0, d0, d0                            @padd d0, d0, d0\n"
+                    "vmul.f32  d0, d0, %e[vcoef]                     @mul \n"
+                    "sub       %[dr0], #8                            @add w, 6\n"
+                    "sub       %[dr1], #8                            @add w, 6\n"
+                    "sub       %[dr2], #8                            @add w, 6\n"
+                    "subs      %[cnt_num1], #1                       @subs cnt_num, #1\n"
+                    "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                    "bne       s3_ave_loop_mid_1                     @bne s3_max_loop_mid_1\n"
+                    "exit1_ave:                                           @exit\n"
+                    :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr2] "+r" (dr2), [dr_out] "+r" (dr_out), \
+                     [cnt_num] "+r" (cnt_num), [cnt_num1] "+r" (cnt_num1), [vcoef] "+w" (vcoef), [vzero] "+w" (vzero)
+                    :"r" (dr0), "r" (dr1), "r" (dr2), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                    :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9", "q10", "q11", "q12"
+                    );
+                }
+            #endif 
+                if (pad_right){
+                    // deal with right pad
+                     int wstart = (w_even >> 1) * stride_w - pad_w;
+                     int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                     float tmp = 0.f;
+                    for(int i = wstart; i < wend; i++){
+                        tmp += (r0[i]+r1[i]+r2[i]);
+                    }
+                    data_out_channel[w_even >> 1] = tmp / 9.f;
+                    //cnt ++;
+                }
+                r0 = r2;
+                r1 = r0 + w_in;
+                r2 = r1 + w_in;
+                data_out_channel += w_out;
+            }
+
+            if (pad_bottom) {
+                //deal with bottom pad
+                // first row with zero pad
+                int hstart = (h >> 1) * stride_h - pad_h;
+                int hend = std::min(std::min(hstart + kernel_h, h_in + pad_h),h_in);
+    
+                if(hstart == hend - 1){//only one lline
+                    data_out_channel[0] = (r0[0] + r0[1]) / 9.f;
+               #ifdef __aarch64__
+                    w = 1;
+                    cnt = 1;
+                    for (; w < w_in - 8; w += 8) {
+                        float32x4_t vsum_1234 = vld1q_f32(&r0[w]);
+                        float32x4_t vsum_5678 = vld1q_f32(&r0[w + 4]);
+                        float32x4_t vsum_9101112 = vld1q_f32(&r0[w + 8]);
+
+                        float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                        float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                        float32x4_t vsum_4567 = vextq_f32(vsum_1234, vsum_5678,3);
+                        float32x4_t vsum_6789 = vextq_f32(vsum_5678, vsum_9101112,1);
+                        float32x4_t vsum_123_345 = vaddq_f32(vsum_1234, vsum_2345);
+                        vsum_123_345 = vaddq_f32(vsum_123_345, vsum_3456);
+                        float32x4_t vsum_567_789 = vaddq_f32(vsum_4567, vsum_5678);
+                        vsum_567_789 = vaddq_f32(vsum_567_789, vsum_6789);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_123_345,2), vsum_123_345, 1);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,1), vsum_123_345, 2);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,3), vsum_123_345, 3);
+                        float32x4_t vrst = vmulq_f32(vsum_123_345, vcoef);
+                        vst1q_f32(&data_out_channel[cnt],vrst);
+                        cnt += 4;
+                    }
+                    for(; w < w_even - 1; w += 2){
+                        float32x4_t vr0= vld1q_f32(&r0[w]);
+                        vr0 = vsetq_lane_f32(0.f, vr0, 3);
+                        float32x2_t vsum = vpadd_f32(vget_low_f32(vr0), vget_high_f32(vr0));
+                        vsum = vpadd_f32(vsum, vsum);
+                        data_out_channel[cnt] = vget_lane_f32(vsum, 0) / 9.f;
+                        cnt ++;
+                    }
+                #else
+                    dr_out = data_out_channel + 1;
+                    dr0 = (r0 + 1);
+                    cnt_num = w_unroll_size;
+                    cnt_num1 = w_unroll_remian;
+                    if (cnt_num > 0 || cnt_num1 > 0){
+                        asm volatile(
+                        "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                        "ble       loop4_ave                                  @ble exit\n"
+                        "s3_ave_loop_bot:                                @main loop\n"
+                        "vld1.f32  {d12-d15}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vld1.f32  {d16}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vext.f32  q0, q6, q7, #1                        @vext max_2345\n"
+                        "vext.f32  q1, q6, q7, #3                        @vext max_4567\n"
+                        "vext.f32  q2, q6, q7, #2                        @vext max_3456\n"
+                        "vext.f32  q3, q7, q8, #1                        @vext max_6789\n"
+                        "vadd.f32  q4, q6, q0                            @add 1234, 2345 \n"
+                        "vadd.f32  q5, q7, q1                            @add 5678, 4567 \n"
+                        "vadd.f32  q4, q4, q2                            @add 3456, sum1 \n"
+                        "vadd.f32  q5, q5, q3                            @add 6789, sum2 \n"
+                        "vmov.f32  s17, s18                              @mov \n"
+                        "vmov.f32  s18, s21                              @mov \n"
+                        "vmov.f32  s19, s23                              @mov \n"
+                        "vmul.f32  q4, q4, %q[vcoef]                     @mul \n"
+                        "sub       %[dr0], #8                           @add w, 6\n"
+                        "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                        "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "bne       s3_ave_loop_bot                       @bne s3_max_loop_bot\n"
+                        "loop4_ave:                                       @loop \n"
+                        "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                        "ble       exit3_ave                                 @ble exit\n"
+                        "s3_ave_loop_bot_1:                              @bot loop\n"
+                        "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                        "vext.f32  q0, %q[vzero], q0, #3                 @ ext v0_0123\n"
+                        "vpadd.f32 d0, d0, d1                            @padd d0, d0,d1\n"
+                        "vpadd.f32 d0, d0, d0                            @padd d0, d0, d0\n"
+                        "vmul.f32  d0, d0, %e[vcoef]                     @mul \n"
+                        "sub       %[dr0], #8                            @add w, 2\n"
+                        "subs      %[cnt_num1], #1                       @subs cnt_num, #1\n"
+                        "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                        "bne       s3_ave_loop_bot_1                     @bne s3_max_loop_bot_1\n"
+                        "exit3_ave:                                          @exit\n"
+                        :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), \
+                         [cnt_num1] "+r" (cnt_num1), [vcoef] "+w" (vcoef), [vzero] "+w" (vzero)
+                        :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                        :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8"
+                        );
+                    }
+                #endif
+                    if (pad_right){
+                        // deal with right pad
+                        int wstart = (w_even >> 1) * stride_w - pad_w;
+                        int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                        float tmp = 0.f;
+                        for(int i = wstart; i < wend; i++){
+                            tmp += r0[i];
+                        }
+                        data_out_channel[w_even >> 1] = tmp / 9.f;
+                    }
+                }else{//two lines
+                    data_out_channel[0] =(r0[0] + r0[1] + r1[0] + r1[1]) / 9.f;
+                #ifdef __aarch64__
+                    w = 1;
+                    cnt = 1;
+                    for (; w < w_in - 8; w += 8) {
+                        float32x4_t vr0_1234 = vld1q_f32(&r0[w]);
+                        float32x4_t vr0_5678 = vld1q_f32(&r0[w + 4]);
+                        float32x4_t vr0_9101112 = vld1q_f32(&r0[w + 8]);
+                        float32x4_t vr1_1234 = vld1q_f32(&r1[w]);
+                        float32x4_t vr1_5678 = vld1q_f32(&r1[w + 4]);
+                        float32x4_t vr1_9101112 = vld1q_f32(&r1[w + 8]);
+
+                        float32x4_t vsum_1234 = vaddq_f32(vr0_1234, vr1_1234);
+                        float32x4_t vsum_5678 = vaddq_f32(vr0_5678, vr1_5678);
+                        float32x4_t vsum_9101112 = vaddq_f32(vr0_9101112, vr1_9101112);
+                        float32x4_t vsum_2345 = vextq_f32(vsum_1234, vsum_5678,1);
+                        float32x4_t vsum_3456 = vextq_f32(vsum_1234, vsum_5678,2);
+                        float32x4_t vsum_4567 = vextq_f32(vsum_1234, vsum_5678,3);
+                        float32x4_t vsum_6789 = vextq_f32(vsum_5678, vsum_9101112,1);
+                        float32x4_t vsum_123_345 = vaddq_f32(vsum_1234, vsum_2345);
+                        vsum_123_345 = vaddq_f32(vsum_123_345, vsum_3456);
+                        float32x4_t vsum_567_789 = vaddq_f32(vsum_4567, vsum_5678);
+                        vsum_567_789 = vaddq_f32(vsum_567_789, vsum_6789);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_123_345,2), vsum_123_345, 1);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,1), vsum_123_345, 2);
+                        vsum_123_345 = vsetq_lane_f32(vgetq_lane_f32(vsum_567_789,3), vsum_123_345, 3);
+                        float32x4_t vrst = vmulq_f32(vsum_123_345, vcoef);
+                        vst1q_f32(&data_out_channel[cnt],vrst);
+                        cnt += 4;
+                    }
+                for(; w < w_even - 1; w += 2){
+                    float32x4_t vr0= vld1q_f32(&r0[w]);
+                    float32x4_t vr1= vld1q_f32(&r1[w]);
+                    vr0 = vsetq_lane_f32(0.f, vr0, 3);
+                    vr1 = vsetq_lane_f32(0.f, vr1, 3);
+                    float32x4_t vsum1 = vaddq_f32(vr0, vr1);
+                    float32x2_t vsum2 = vpadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));
+                    vsum2 = vpadd_f32(vsum2, vsum2);
+                    float32x2_t vrst = vmul_f32(vsum2, vget_low_f32(vcoef));
+                    data_out_channel[cnt] = vget_lane_f32(vrst, 0);
+                    cnt ++;
+                }
+                #else 
+                    dr_out = data_out_channel + 1;
+                    dr0 = (r0 + 1);
+                    dr1 = (r1 + 1);
+                    cnt_num = w_unroll_size;
+                    cnt_num1 = w_unroll_remian;
+                    if (cnt_num > 0 || cnt_num1 > 0){
+                        asm volatile(
+                        "cmp       %[cnt_num], #0                        @cmp cnt_num, 0\n"
+                        "ble       loop5_ave                                  @ble exit\n"
+                        "s3_ave_loop_bot1:                               @main loop\n"
+                        "vld1.f32  {d0-d3}, [%[dr0]]!                     @load d0-d5, dr0\n"
+                        "vld1.f32  {d6-d9}, [%[dr1]]!                    @load d4-d7, dr1\n"
+                        "vld1.f32  {d4}, [%[dr0]]!                     @load d0-d3, dr0\n"
+                        "vld1.f32  {d10}, [%[dr1]]!                  @load d4-d7, dr1\n"
+                        "vmax.f32  q6, q0, q3                            @max q0,q0,q2 1234\n"
+                        "vmax.f32  q7, q1, q4                            @max q1,q1,q3 5678\n"
+                        "vmax.f32  d16, d4, d10                            @max q1,q1,q3 9101112\n"
+                        //"vmov.f32  s7,s6                                 @mov s7, s6\n"
+                        "vext.f32  q0, q6, q7, #1                        @vext max_2345\n"
+                        "vext.f32  q1, q6, q7, #3                        @vext max_4567\n"
+                        "vext.f32  q2, q6, q7, #2                        @vext max_3456\n"
+                        "vext.f32  q3, q7, q8, #1                        @vext max_6789\n"
+                        "vadd.f32  q4, q6, q0                            @add 1234, 2345 \n"
+                        "vadd.f32  q5, q7, q1                            @add 5678, 4567 \n"
+                        "vadd.f32  q4, q4, q2                            @add 3456, sum1 \n"
+                        "vadd.f32  q5, q5, q3                            @add 6789, sum2 \n"
+                        "vmov.f32  s17, s18                              @mov \n"
+                        "vmov.f32  s18, s21                              @mov \n"
+                        "vmov.f32  s19, s23                              @mov \n"
+                        "vmul.f32  q4, q4, %q[vcoef]                     @mul \n"
+                        "sub       %[dr0], #8                           @add w, 8\n"
+                        "sub       %[dr1], #8                           @add w, 8\n"
+                        "subs      %[cnt_num], #1                            @subs cnt_num, #1\n"
+                        "vst1.f32  d8, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "vst1.f32  d9, [%[dr_out]]!                      @vst1 d0, dr_out\n"
+                        "bne       s3_ave_loop_bot1                      @bne s3_max_loop_bot\n"
+                        "loop5_ave:                                      @loop \n"
+                        "cmp       %[cnt_num1], #0                           @cmp cnt_num, 0\n"
+                        "ble       exit4_ave                                 @ble exit\n"
+                        "s3_ave_loop_bot1_1:                             @bot loop\n"
+                        "vld1.f32  {d0-d1}, [%[dr0]]!                     @load d0-d1, dr0\n"
+                        "vld1.f32  {d2-d3}, [%[dr1]]!                     @load d2-d3, dr1\n"
+                        "vext.f32  q0, %q[vzero], q0, #3                 @ ext v0_0123\n"
+                        "vext.f32  q1, %q[vzero], q1, #3                 @ ext v1_0123\n"
+                        "vadd.f32  q0, q0, q1                            @add q0, q0, q1\n"
+                        "vpadd.f32 d0, d0, d1                            @padd d0, d0,d1\n"
+                        "vpadd.f32 d0, d0, d0                            @padd d0, d0, d0\n"
+                        "vmul.f32  d0, d0, %e[vcoef]                     @mul \n"
+                        "sub       %[dr0], #8                            @add w, 6\n"
+                        "sub       %[dr1], #8                            @add w, 6\n"
+                        "subs      %[cnt_num1], #1                           @subs cnt_num, #1\n"
+                        "vst1.f32  d0[0], [%[dr_out]]!                   @vst  d0[0], dr_out\n"
+                        "bne       s3_ave_loop_bot1_1                    @bne s3_max_loop_bot_1\n"
+                        "exit4_ave:                                          @exit\n"
+                        :[dr0] "+r" (dr0), [dr1] "+r" (dr1), [dr_out] "+r" (dr_out), [cnt_num] "+r" (cnt_num), \ 
+                        [cnt_num1] "+r" (cnt_num1), [vcoef] "+w" (vcoef), [vzero] "+w" (vzero)
+                        :"r" (dr0), "r" (dr1), "r" (dr_out), "r"(cnt_num), "r" (cnt_num1)
+                        :"q0", "q1", "q2", "q3", "q4", "q5", "q6","q7", "q8", "q9"
+                        );
+                    }
+                #endif
+                    if (pad_right){
+                     // deal with right pad
+                        int wstart = (w_even >> 1) * stride_w - pad_w;
+                        int wend = std::min(std::min(wstart + kernel_w, w_in + pad_w),w_in);
+                        float tmp = 0.f;
+                        for(int i = wstart; i < wend; i++){//only run 1 or 2 times
+                            tmp += (r0[i] + r1[i]);
+                        }
+                        data_out_channel[w_even >> 1] = tmp / 9.f;
+                    }
+                }
+            }
+
+        }
+    }
+}
 } //namespace saber
 
 } //namespace anakin
diff --git a/saber/funcs/impl/arm/impl/pooling_arm_impl.h b/saber/funcs/impl/arm/impl/pooling_arm_impl.h
index 28700b9..90dc01a 100644
--- a/saber/funcs/impl/arm/impl/pooling_arm_impl.h
+++ b/saber/funcs/impl/arm/impl/pooling_arm_impl.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -40,6 +39,14 @@ void pooling2x2s2_ave(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
     int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h);
 
+void pooling3x3s1_max(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
+    Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
+    int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h);
+
+void pooling3x3s1_ave(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
+    Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
+    int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h);
+
 void pooling3x3s2_max(Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \
     Tensor<ARM, AK_FLOAT, NCHW>& tensor_in, PoolingType type, bool global, \
     int kernel_w, int kernel_h, int stride_w, int stride_h, int pad_w, int pad_h);
diff --git a/saber/funcs/impl/arm/impl/sgemm_arm.cpp b/saber/funcs/impl/arm/impl/sgemm_arm.cpp
index df72b03..58c0cc0 100644
--- a/saber/funcs/impl/arm/impl/sgemm_arm.cpp
+++ b/saber/funcs/impl/arm/impl/sgemm_arm.cpp
@@ -3,6 +3,7 @@
 
 #include "saber/core/target_wrapper.h"
 namespace anakin{
+
 namespace saber{
 
 #ifdef __aarch64__
@@ -2740,4 +2741,4 @@ void merge_float_alpha1_beta1_relu(float *out, const float *in, const int ldout,
 
 } //namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/impl/sgemm_arm.h b/saber/funcs/impl/arm/impl/sgemm_arm.h
index 13208d8..f894dca 100644
--- a/saber/funcs/impl/arm/impl/sgemm_arm.h
+++ b/saber/funcs/impl/arm/impl/sgemm_arm.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -73,4 +72,4 @@ private:
 
 #endif // USE_ARM_PLACE
 
-#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMM_ARM_H
\ No newline at end of file
+#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMM_ARM_H
diff --git a/saber/funcs/impl/arm/impl/sgemv_arm.h b/saber/funcs/impl/arm/impl/sgemv_arm.h
index f7d32e5..fb8fe38 100644
--- a/saber/funcs/impl/arm/impl/sgemv_arm.h
+++ b/saber/funcs/impl/arm/impl/sgemv_arm.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -41,4 +40,4 @@ void sgemv_bias_relu(const bool transA, const int M, const int N, \
 
 #endif // USE_ARM_PLACE
 
-#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMV_ARM_H
\ No newline at end of file
+#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMV_ARM_H
diff --git a/saber/funcs/impl/arm/impl/utils_arm.h b/saber/funcs/impl/arm/impl/utils_arm.h
index a01943b..f7a2e78 100644
--- a/saber/funcs/impl/arm/impl/utils_arm.h
+++ b/saber/funcs/impl/arm/impl/utils_arm.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/funcs/impl/arm/saber_activation.h b/saber/funcs/impl/arm/saber_activation.h
index ca21305..d8b2d30 100644
--- a/saber/funcs/impl/arm/saber_activation.h
+++ b/saber/funcs/impl/arm/saber_activation.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -52,7 +51,7 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ActivationParam<OpTensor>& param, Context<ARM>& ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
@@ -73,6 +72,7 @@ public:
                 dout[i] = std::max(din[i], (OutDataType)0);
             }
         }
+        return SaberSuccess;
     }
 
 };
diff --git a/saber/funcs/impl/arm/saber_concat.h b/saber/funcs/impl/arm/saber_concat.h
index 4b703a1..e718136 100644
--- a/saber/funcs/impl/arm/saber_concat.h
+++ b/saber/funcs/impl/arm/saber_concat.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -53,7 +52,7 @@ public:
                       std::vector<DataTensor_out*>& outputs,
                       ConcatParam<OpTensor> &param, Context<ARM> &ctx){
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/arm/saber_conv.cpp b/saber/funcs/impl/arm/saber_conv.cpp
index 9ce89b6..bffd023 100755
--- a/saber/funcs/impl/arm/saber_conv.cpp
+++ b/saber/funcs/impl/arm/saber_conv.cpp
@@ -18,7 +18,10 @@ SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::SaberConv2D()
 }
 
 template <>
-SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::~SaberConv2D() {}
+SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::~SaberConv2D() {
+     //LOG(ERROR) << "release saber conv: kw=" << _kw << ", kh=" << _kh << ", num_out=" << _conv_param.weight()->num() << \
+        ", chin=" << _conv_param.weight()->channel();
+}
 
 template <>
 SaberStatus SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::create(\
@@ -26,9 +29,11 @@ SaberStatus SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::cr
     std::vector<DataTensor_out *>& outputs,\
     ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) {
 
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
+    //printf("conv init \n");
 
-    int threads = this->_ctx.get_act_ids().size();
+    int threads = 1;
+    this->_ctx->get_mode(threads);
 
     Shape shape_in = inputs[0]->valid_shape();
     Shape shape_out = outputs[0]->valid_shape();
@@ -42,9 +47,9 @@ SaberStatus SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::cr
 
     _kw = conv_param.weight()->width();
     _kh = conv_param.weight()->height();
-
-    int l1_cache = this->_ctx.devs[this->_ctx.get_device_id()]._info._L1_cache;
-    int l2_cache = this->_ctx.devs[this->_ctx.get_device_id()]._info._L2_cache;
+   // printf("kw: %d, kh: %d\n", _kw, _kh);
+    int l1_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L1_cache;
+    int l2_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L2_cache;
     //! if L1 cache size is not provided, set to 31K
     l1_cache = l1_cache > 0? l1_cache : 31000;
     //! if L2 cache size is not provided, set to 2M
@@ -56,91 +61,99 @@ SaberStatus SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::cr
         _bias_term = false;
     }
 
+    CHECK_EQ(chin % conv_param.group, 0) << "input channel or group size error";
+    CHECK_EQ(chout % conv_param.group, 0) << "output channel or group size error";
+#if 0
     //! return basic conv func
-    if (conv_param.dilation_h != 1 || conv_param.dilation_w != 1 \
-        || conv_param.stride_h != conv_param.stride_w \
-        || conv_param.stride_w > 2 || _kw != _kh || _kw > 3 \
-        || ((conv_param.group > 1) && (conv_param.group != chin || conv_param.group != chout))) {
+    if (conv_param.dilation_h != 1 || conv_param.dilation_w != 1) {
         //! basic conv
         _impl = conv_arm_basic;
-        //LOG(ERROR) << "USE BASIC";
+        LOG(ERROR) << "USE BASIC";
         return SaberSuccess;
-    } else {
-        //! depthwise conv, 3x3s1 or 3x3s2, pad must = 1
-        if (conv_param.group == chin && chin == chout && _kw == 3 && conv_param.pad_w == 1 && \
+    }
+#endif
+
+    if (conv_param.dilation_h== 1 && conv_param.dilation_w == 1 \
+        && conv_param.stride_h == conv_param.stride_w \
+        && conv_param.stride_w == 1 && _kw == _kh && _kw == 7 \
+        && conv_param.pad_w == conv_param.pad_h && conv_param.pad_w == 3) {
+        //! 7x7 conv
+        _impl = conv_arm_7x7s1;
+        LOG(ERROR) << "USE 7x7 direct";
+        return SaberSuccess;
+    }
+
+    //! depthwise conv, 3x3s1 or 3x3s2, pad must = 1
+    if (conv_param.group == chin && chin == chout && _kw == 3 && conv_param.pad_w == 1 && \
                 conv_param.pad_h == 1) {
-            _impl = conv_depthwise_3x3;
-            //LOG(ERROR) << "USE DW";
-            return SaberSuccess;
-        }
+        _impl = conv_depthwise_3x3;
+                LOG(ERROR) << "USE DW";
+        return SaberSuccess;
+    }
 
-        //! for conv3x3s2 and input channel < 10, use gemm conv
-        if (_kw < 3 || (_kw == 3 && (conv_param.stride_w == 2) || chin < 10)) {
-
-            const int m = chout;
-            const int n = hout * wout;
-            const int k = chin * _kh * _kw;
-            if (_kw == 1 && conv_param.stride_w == 1 && conv_param.pad_w == 0) {
-                //! 1x1s1p0
-                _impl = conv1x1s1_gemm;
-                _workspace_fwd_sizes = 0;
-            } else {
-                //! otherwise
-                _impl = conv_im2col_gemm;
-                _workspace_fwd_sizes = sizeof(float) * k * n;
-                _workspace_data->re_alloc(_workspace_fwd_sizes);
-            }
-
-            _gemmer.init(l1_cache, l2_cache, m, n, k, false, false, threads);
-            //LOG(ERROR) << "USE GEMM";
-            return SaberSuccess;
-        }
+    //! 3x3s1, when channel size or image size is large enough, use winograd
+    //! otherwise use direct conv
 
-        //! 3x3s1, input channel >= 10, use winograd
-        //! if chin < 10, use sgemm, faster than winograd
-        if (_kw == 3 && conv_param.stride_h == 1 && conv_param.pad_w == 1) {
-            if (chout / (wout * hout) < 1) {
-                //! use winograd
-                _weights_trans->re_alloc(sizeof(float) * 8 * 8 * chout * chin * 2);
-                //! space for computation
-                int tile_w = (wout + 5) / 6;
-                int tile_h = (hout + 5) / 6;
-                int size_tile = tile_h * tile_w;
-                int size_trans_channel = 8 * 8 * size_tile;
-                int max_ch = chin > chout? chin : chout;
+    if (_kw == 3 && _kh == 3 && conv_param.stride_h == 1 && \
+        conv_param.pad_w == 1 && conv_param.group == 1) {
 
-                //LOG(INFO) << "threads " << threads;
+        if (chout / (wout * hout) > 1 || chin < 16 || chout < 14) {
+            //! use direct
+            _impl = conv_3x3s1_direct;
+            LOG(ERROR) << "USE 3x3 direct";
+        } else {
+            //! use winograd
+            _weights_trans->re_alloc(sizeof(float) * 8 * 8 * chout * chin * 2);
+            //! space for computation
+            int tile_w = (wout + 5) / 6;
+            int tile_h = (hout + 5) / 6;
+            int size_tile = tile_h * tile_w;
+            int size_trans_channel = 8 * 8 * size_tile;
+            int max_ch = chin > chout? chin : chout;
 
-                _workspace_data->re_alloc(sizeof(float) * size_trans_channel * max_ch * 2);
+            //LOG(INFO) << "threads " << threads;
 
-                void* trans_tmp_ptr =(void*)((char*)_weights_trans->get_data_mutable() + \
+            _workspace_data->re_alloc(sizeof(float) * size_trans_channel * max_ch * 2);
+
+            void* trans_tmp_ptr =(void*)((char*)_weights_trans->get_data_mutable() + \
                     sizeof(float) * 8 * 8 * chout * chin);
-                float* weights_trans = (float*)_weights_trans->get_data_mutable();
-                winograd_transform_weights(weights_trans, \
+            float* weights_trans = (float*)_weights_trans->get_data_mutable();
+            winograd_transform_weights(weights_trans, \
                     conv_param.weight()->data(), chout, chin, trans_tmp_ptr);
 
-                //LOG(INFO) << "weighs size: " << this->_weight_data.size() << ", chout: " << chout << ", chin: " << chin;
-
-                const int m_wino = chout;
-                const int n_wino = size_tile;
-                const int k_wino = chin;
-
-                //LOG(INFO) << "threads " << threads << ", m " << m_wino << ", n " << n_wino << ", k " << k_wino;
-                _gemmer.init(l1_cache, l2_cache, m_wino, n_wino, k_wino, false, false, threads);
-                _impl = conv_arm_winograd3x3;
-                _is_trans_weights = true;
-                //LOG(ERROR) << "USE WINO";
-            } else {
-                //! use direct
-                _impl = conv_3x3s1_direct;
-                //LOG(ERROR) << "USE direct";
-            }
-            return SaberSuccess;
+            //LOG(INFO) << "weighs size: " << this->_weight_data.size() << ", chout: " << chout << ", chin: " << chin;
+
+            const int m_wino = chout;
+            const int n_wino = size_tile;
+            const int k_wino = chin;
+
+            //LOG(INFO) << "threads " << threads << ", m " << m_wino << ", n " << n_wino << ", k " << k_wino;
+            _gemmer.init(l1_cache, l2_cache, m_wino, n_wino, k_wino, false, false, threads);
+            _impl = conv_arm_winograd3x3;
+            _is_trans_weights = true;
+            LOG(ERROR) << "USE WINO";
         }
+        return SaberSuccess;
+    }
 
+    //! use im2col and gemm conv
+    const int m = chout / conv_param.group;
+    const int n = hout * wout;
+    const int k = chin * _kh * _kw / conv_param.group;
+    if (_kw == 1 && _kh == 1 && conv_param.stride_w == 1 && conv_param.stride_h == 1 && \
+            conv_param.pad_w == 0 && conv_param.pad_h == 0) {
+        //! 1x1s1p0
+        _impl = conv1x1s1_gemm;
+        _workspace_fwd_sizes = 0;
+    } else {
+        //! otherwise
+        _impl = conv_im2col_gemm;
+        _workspace_fwd_sizes = sizeof(float) * k * n;
+        _workspace_data->re_alloc(_workspace_fwd_sizes);
     }
 
-    _impl = conv_arm_basic;
+    _gemmer.init(l1_cache, l2_cache, m, n, k, false, false, threads);
+    LOG(ERROR) << "USE GEMM";
     return SaberSuccess;
 }
 
diff --git a/saber/funcs/impl/arm/saber_conv.h b/saber/funcs/impl/arm/saber_conv.h
index 46b3445..2d8c3ed 100755
--- a/saber/funcs/impl/arm/saber_conv.h
+++ b/saber/funcs/impl/arm/saber_conv.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -58,14 +57,6 @@ public:
 
     ~SaberConv2D();
 
-/**
- * [Create description] Init all resource here
- * @AuthorHTL
- * @DateTime  2018-02-01T16:13:06+0800
- * @param     inputs                    [description]
- * @param     outputs                   [description]
- * @param     conv_param                [conv parameters]
- */
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
                              std::vector<DataTensor_out*>& outputs,
                              ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) override;
diff --git a/saber/funcs/impl/arm/saber_conv_act.cpp b/saber/funcs/impl/arm/saber_conv_act.cpp
index 3f17b9d..fa3c346 100755
--- a/saber/funcs/impl/arm/saber_conv_act.cpp
+++ b/saber/funcs/impl/arm/saber_conv_act.cpp
@@ -31,6 +31,8 @@ SaberStatus SaberConv2DAct<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>:
     ConvActiveParam<OpTensor> &param, Context<ARM> &ctx) {
     if (param.has_active) {
         SABER_CHECK(_conv_op->set_activation(true));
+    } else {
+        SABER_CHECK(_conv_op->set_activation(false));
     }
     _conv_op->init(inputs, outputs, param.conv_param, ctx);
     return SaberSuccess;
diff --git a/saber/funcs/impl/arm/saber_conv_act.h b/saber/funcs/impl/arm/saber_conv_act.h
index 4c6834a..740e83a 100755
--- a/saber/funcs/impl/arm/saber_conv_act.h
+++ b/saber/funcs/impl/arm/saber_conv_act.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/funcs/impl/arm/saber_conv_act_pooling.cpp b/saber/funcs/impl/arm/saber_conv_act_pooling.cpp
new file mode 100755
index 0000000..03ef775
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_conv_act_pooling.cpp
@@ -0,0 +1,66 @@
+#include "saber/funcs/impl/arm/saber_conv_act_pooling.h"
+
+#ifdef USE_ARM_PLACE
+
+namespace anakin{
+
+namespace saber{
+
+template <>
+SaberConv2DActPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::SaberConv2DActPooling() {
+    _conv_op = new SaberConv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+    _pool_op = new SaberPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+    _vtensor_tmp.resize(1);
+}
+
+template <>
+SaberConv2DActPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::~SaberConv2DActPooling() {
+    delete _conv_op;
+    delete _pool_op;
+    _vtensor_tmp.clear();
+}
+
+template <>
+SaberStatus SaberConv2DActPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::create(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs, \
+    ConvActivePoolingParam<OpTensor> &param, Context<ARM> &ctx) {
+
+    get_conv_out_tensor(inputs, param);
+
+    SaberStatus state = _conv_op->create(inputs, _vtensor_tmp, param.conv_param, ctx);
+    return (SaberStatus)(state & _pool_op->create(_vtensor_tmp, outputs, param.pooling_param, ctx));
+}
+
+template <>
+SaberStatus SaberConv2DActPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::init(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs, \
+    ConvActivePoolingParam<OpTensor> &param, Context<ARM> &ctx) {
+
+    if (param.has_activation) {
+        SABER_CHECK(_conv_op->set_activation(true));
+    } else {
+        SABER_CHECK(_conv_op->set_activation(false));
+    }
+
+    get_conv_out_tensor(inputs, param);
+    SaberStatus state = _conv_op->init(inputs, _vtensor_tmp, param.conv_param, ctx);
+    return (SaberStatus)(state & _pool_op->init(_vtensor_tmp, outputs, param.pooling_param, ctx));
+}
+
+template <>
+SaberStatus SaberConv2DActPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs, \
+    ConvActivePoolingParam<OpTensor> &param) {
+    SaberStatus state = _conv_op->dispatch(inputs, _vtensor_tmp, param.conv_param);
+    return (SaberStatus)(state & _pool_op->dispatch(_vtensor_tmp, outputs, param.pooling_param));
+}
+
+} //namespace saber
+
+} //namespace anakin
+#endif // USE_ARM_PLACE
+
+
diff --git a/saber/funcs/impl/arm/saber_conv_act_pooling.h b/saber/funcs/impl/arm/saber_conv_act_pooling.h
new file mode 100755
index 0000000..26982a4
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_conv_act_pooling.h
@@ -0,0 +1,113 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+#ifndef ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_CONV_ACT_POOLING_H
+#define ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_CONV_ACT_POOLING_H
+
+#include "saber/funcs/impl/arm/saber_conv.h"
+#include "saber/funcs/impl/arm/saber_pooling.h"
+#include "saber/funcs/impl/impl_conv_act_pooling.h"
+
+#ifdef USE_ARM_PLACE
+
+namespace anakin{
+
+namespace saber{
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+class SaberConv2DActPooling<ARM, OpDtype, inDtype, outDtype,\
+    LayOutType_op, LayOutType_in, LayOutType_out> : \
+    public ImplBase<
+        Tensor<ARM, inDtype, LayOutType_in>,
+        Tensor<ARM, outDtype, LayOutType_out>,
+        Tensor<ARM, OpDtype, LayOutType_op>,
+        ConvActivePoolingParam<Tensor<ARM, OpDtype, LayOutType_op> > > {
+public:
+    typedef Tensor<ARM, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<ARM, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<ARM, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype InDataType;
+    typedef typename DataTensor_out::Dtype OutDataType;
+    typedef typename OpTensor::Dtype OpDataType;
+
+
+    SaberConv2DActPooling();
+
+    ~SaberConv2DActPooling();
+
+    virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
+                             std::vector<DataTensor_out *>& outputs,
+                             ConvActivePoolingParam<OpTensor> &param, Context<ARM> &ctx) override;
+
+    virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
+                               std::vector<DataTensor_out *>& outputs,
+                               ConvActivePoolingParam<OpTensor> &param, Context<ARM> &ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in *>& inputs,
+                                 std::vector<DataTensor_out *>& outputs,
+                                 ConvActivePoolingParam<OpTensor> &param) override;
+
+    void get_conv_out_tensor(const std::vector<DataTensor_in *>& inputs,
+                              ConvActivePoolingParam<OpTensor> &param) {
+
+        ConvParam<OpTensor> conv_param = param.conv_param;
+
+        Shape conv_out_shape = inputs[0]->valid_shape();
+        // append the $n and $c/$k, output: N * K * P * Q
+        int num_idx = inputs[0]->num_index();
+        int channel_idx = inputs[0]->channel_index();
+        int height_idx = inputs[0]->height_index();
+        int width_idx = inputs[0]->width_index();
+
+        conv_out_shape[num_idx] = inputs[0]->num(); // N
+        conv_out_shape[channel_idx] = conv_param.weight()->num(); // K
+
+        int input_dim = inputs[0]->height(); // P
+        int kernel_exten = conv_param.dilation_h * (conv_param.weight()->height() - 1) + 1;
+        int output_dim = (input_dim + 2 * conv_param.pad_h - kernel_exten)
+                         / conv_param.stride_h + 1;
+
+        conv_out_shape[height_idx] = output_dim;
+
+        input_dim = inputs[0]->width(); // Q
+        kernel_exten = conv_param.dilation_w * (conv_param.weight()->width() - 1) + 1;
+        output_dim = (input_dim + 2 * conv_param.pad_w - kernel_exten)
+                     / conv_param.stride_w + 1;
+
+        conv_out_shape[width_idx] = output_dim;
+
+        _tensor_tmp.reshape(conv_out_shape);
+        _vtensor_tmp[0] = &_tensor_tmp;
+    }
+
+private:
+    SaberConv2D<ARM, OpDtype, inDtype, outDtype,\
+    LayOutType_op, LayOutType_in, LayOutType_out>* _conv_op;
+    SaberPooling<ARM, OpDtype, inDtype, outDtype,\
+    LayOutType_op, LayOutType_in, LayOutType_out>* _pool_op;
+    DataTensor_in _tensor_tmp;
+    std::vector<DataTensor_in *> _vtensor_tmp;
+};
+
+} //namespace saber
+
+} //namespace anakin
+#endif // USE_ARM_PLACE
+
+#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_CONV_ACT_POOLING_H
diff --git a/saber/funcs/impl/arm/saber_deconv.cpp b/saber/funcs/impl/arm/saber_deconv.cpp
new file mode 100755
index 0000000..b751078
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_deconv.cpp
@@ -0,0 +1,190 @@
+#include "saber/funcs/impl/arm/saber_deconv.h"
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+namespace anakin{
+
+namespace saber{
+
+inline bool is_a_ge_zero_and_a_lt_b(int a, int b) {
+    return static_cast<unsigned>(a) < static_cast<unsigned>(b);
+}
+template <typename Dtype>
+void col2im(const Dtype* data_col, const int channels,
+                const int height, const int width, const int kernel_h, const int kernel_w,
+                const int pad_h, const int pad_w,
+                const int stride_h, const int stride_w,
+                const int dilation_h, const int dilation_w,
+                Dtype* data_im) {
+    memset(data_im, 0, height * width * channels * sizeof(Dtype));
+    const int output_h = (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;
+    const int output_w = (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;
+    const int channel_size = height * width;
+    for (int channel = channels; channel--; data_im += channel_size) {
+        for (int kernel_row = 0; kernel_row < kernel_h; kernel_row++) {
+            for (int kernel_col = 0; kernel_col < kernel_w; kernel_col++) {
+                int input_row = -pad_h + kernel_row * dilation_h;
+                for (int output_rows = output_h; output_rows; output_rows--) {
+                    if (!is_a_ge_zero_and_a_lt_b(input_row, height)) {
+                        data_col += output_w;
+                    } else {
+                        int input_col = -pad_w + kernel_col * dilation_w;
+                        for (int output_col = output_w; output_col; output_col--) {
+                            if (is_a_ge_zero_and_a_lt_b(input_col, width)) {
+                                data_im[input_row * width + input_col] += *data_col;
+                            }
+                            data_col++;
+                            input_col += stride_w;
+                        }
+                    }
+                    input_row += stride_h;
+                }
+            }
+        }
+    }
+}
+
+template <>
+SaberDeconv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::SaberDeconv2D() {
+    _workspace_fwd_sizes = 0;
+    _flag_relu = false;
+    _bias_term = true;
+    _workspace_data = std::make_shared<Buffer<ARM>>();
+}
+
+template <>
+SaberDeconv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::~SaberDeconv2D() {
+     //LOG(ERROR) << "release saber conv: kw=" << _kw << ", kh=" << _kh << ", num_out=" << _conv_param.weight()->num() << \
+        ", chin=" << _conv_param.weight()->channel();
+}
+
+template <>
+SaberStatus SaberDeconv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::create(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs,\
+    ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) {
+
+    this->_ctx = &ctx;
+    //printf("conv init \n");
+
+    int threads = 1;
+    this->_ctx->get_mode(threads);
+
+    Shape shape_in = inputs[0]->valid_shape();
+    Shape shape_out = outputs[0]->valid_shape();
+    int win = inputs[0]->width();
+    int hin = inputs[0]->height();
+    int chin = inputs[0]->channel();
+    int num = inputs[0]->num();
+    int wout = outputs[0]->width();
+    int hout = outputs[0]->height();
+    int chout = outputs[0]->channel();
+
+    _kw = conv_param.weight()->width();
+    _kh = conv_param.weight()->height();
+   // printf("kw: %d, kh: %d\n", _kw, _kh);
+    int l1_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L1_cache;
+    int l2_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L2_cache;
+    //! if L1 cache size is not provided, set to 31K
+    l1_cache = l1_cache > 0? l1_cache : 31000;
+    //! if L2 cache size is not provided, set to 2M
+    l2_cache = l2_cache > 0? l2_cache : 2000000;
+
+    if (conv_param.bias()->valid_size() > 0) {
+        _bias_term = true;
+    } else {
+        _bias_term = false;
+    }
+
+    CHECK_EQ(chin % conv_param.group, 0) << "input channel or group size error";
+    CHECK_EQ(chout % conv_param.group, 0) << "output channel or group size error";
+
+    //! deconv weights layout: chin * chout * kh * kw
+    _m = chout * _kw * _kh / conv_param.group;
+    _n = hin * win;
+    _k = chin / conv_param.group;
+
+    _workspace_data->re_alloc(conv_param.group * _m * _n * sizeof(float));
+
+    _gemmer.init(l1_cache, l2_cache, _m, _n, _k, true, false, threads);
+
+    LOG(ERROR) << "USE GEMM";
+    return SaberSuccess;
+}
+
+template <>
+SaberStatus SaberDeconv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::init(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs, \
+    ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) {
+    return create(inputs, outputs, conv_param, ctx);
+}
+
+template <>
+SaberStatus SaberDeconv2D<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(\
+    const std::vector<DataTensor_in *>& inputs, \
+    std::vector<DataTensor_out *>& outputs, ConvParam<OpTensor> &conv_param) {
+
+    const float* din = inputs[0]->data();
+    float* dout = outputs[0]->mutable_data();
+
+    bool flag_1x1s1p1 = (_kw == 1) && (_kh == 1) && (conv_param.stride_h == 1) && \
+        (conv_param.stride_w == 1) && (conv_param.pad_w == 1) && (conv_param.pad_h == 1) && \
+        (conv_param.dilation_w == 1) && (conv_param.dilation_h == 1);
+
+
+    const float* weights = conv_param.weight()->data();
+
+    int num = inputs[0]->num();
+    int chin = inputs[0]->channel();
+    int hin = inputs[0]->height();
+    int win = inputs[0]->width();
+
+    int chout = outputs[0]->channel();
+    int hout = outputs[0]->height();
+    int wout = outputs[0]->width();
+
+    int group = conv_param.group;
+
+    int group_size_in = win * hin * chin / group;
+    int group_size_out = wout * hout * chout / group;
+    int group_size_coldata = _m * _n;
+    int group_size_weights = chin * chout * _kw * _kh / (group * group);
+
+    for (int i = 0; i < num; ++i) {
+        const float* din_batch = din + i * chin * hin * win;
+        float* dout_batch = dout + i * chout * hout * wout;
+
+        float* col_data = (float*)_workspace_data->get_data_mutable();
+        if (flag_1x1s1p1) {
+            col_data = dout_batch;
+        }
+        for (int g = 0; g < conv_param.group; ++g) {
+            const float* din_group = din_batch + g * group_size_in;
+            const float* weights_group = weights + g * group_size_weights;
+            float* coldata_group = col_data + g * group_size_coldata;
+            _gemmer(weights_group, _m, din_group, _n, coldata_group, _n, 1.f, 0.f, _flag_relu);
+        }
+
+        if (!flag_1x1s1p1) {
+            col2im(col_data, chout, hout, wout, _kh, _kw, conv_param.pad_h, conv_param.pad_w, \
+                conv_param.stride_h, conv_param.stride_w, conv_param.dilation_h, conv_param.dilation_w, \
+                dout_batch);
+        }
+
+        //! add bias
+        if (conv_param.bias()->valid_size() > 0) {
+            fill_bias(dout_batch, conv_param.bias()->data(), chout, wout * hout);
+        }
+
+    }
+
+
+    return SaberSuccess;
+}
+
+} //namespace saber
+
+} //namespace anakin
+#endif // USE_ARM_PLACE
+
+
diff --git a/saber/funcs/impl/arm/saber_deconv.h b/saber/funcs/impl/arm/saber_deconv.h
new file mode 100755
index 0000000..6faddef
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_deconv.h
@@ -0,0 +1,91 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+#ifndef ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_DECONV_H
+#define ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_DECONV_H
+
+#include "saber/funcs/impl/impl_deconv.h"
+#include "saber/funcs/impl/arm/impl/sgemm_arm.h"
+#include "saber/core/tensor.h"
+#include "saber/saber_funcs_param.h"
+
+#ifdef USE_ARM_PLACE
+
+namespace anakin{
+
+namespace saber{
+
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+class SaberDeconv2D<ARM, OpDtype, inDtype, outDtype,\
+    LayOutType_op, LayOutType_in, LayOutType_out> : \
+    public ImplBase<
+        Tensor<ARM, inDtype, LayOutType_in>,
+        Tensor<ARM, outDtype, LayOutType_out>,
+        Tensor<ARM, OpDtype, LayOutType_op>,
+        ConvParam<Tensor<ARM, OpDtype, LayOutType_op>>> {
+public:
+    typedef Tensor<ARM, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<ARM, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<ARM, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype InDataType;
+    typedef typename DataTensor_out::Dtype OutDataType;
+    typedef typename OpTensor::Dtype OpDataType;
+
+    SaberDeconv2D();
+
+    ~SaberDeconv2D();
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) override;
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
+                               std::vector<DataTensor_out*>& outputs,
+                               ConvParam<OpTensor> &conv_param, Context<ARM> &ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                 std::vector<DataTensor_out*>& outputs,
+                                 ConvParam<OpTensor> &conv_param) override;
+
+    SaberStatus set_activation(bool flag) {
+        _flag_relu = flag;
+        return SaberSuccess;
+    }
+
+private:
+    Sgemm _gemmer;
+    bool _flag_relu{false};
+    bool _bias_term{true};
+    int _kw;
+    int _kh;
+    int _m;
+    int _n;
+    int _k;
+    size_t _workspace_fwd_sizes{0};
+    std::shared_ptr<Buffer<ARM>> _workspace_data{nullptr};
+};
+
+
+} //namespace saber
+
+} //namespace anakin
+#endif // USE_ARM_PLACE
+
+#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SABER_DECONV_H
diff --git a/saber/funcs/impl/arm/saber_detection_output.h b/saber/funcs/impl/arm/saber_detection_output.h
index 2a29a89..4c50ccd 100644
--- a/saber/funcs/impl/arm/saber_detection_output.h
+++ b/saber/funcs/impl/arm/saber_detection_output.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -53,8 +52,6 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
                       std::vector<DataTensor_out*>& outputs,
                       DetectionOutputParam<OpTensor> &param, Context<ARM> &ctx){
-        // get context
-        this->_ctx = ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -62,6 +59,8 @@ public:
                         std::vector<DataTensor_out*>& outputs,
                         DetectionOutputParam<OpTensor> &param, Context<ARM> &ctx){
 
+        this->_ctx = &ctx;
+
         //! inputs[0]: location map, dims = 4 {N, boxes * 4, 1, 1}
         //! inputs[1]: confidence map, dims = 4 {N, boxes * classes, 1, 1}
         //! inputs[2]: prior boxes, dims = 4 {1, 1, 2, boxes * 4(xmin, ymin, xmax, ymax)}
diff --git a/saber/funcs/impl/arm/saber_eltwise.cpp b/saber/funcs/impl/arm/saber_eltwise.cpp
index 3f40428..94e50ce 100644
--- a/saber/funcs/impl/arm/saber_eltwise.cpp
+++ b/saber/funcs/impl/arm/saber_eltwise.cpp
@@ -4,8 +4,7 @@
 namespace anakin{
 
 namespace saber{
-
-void eltwise_prod(const float* din_a, const float* din_b, float* dout, const int size) {
+void eltwise_prod(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
 
     float* out_ptr = dout;
     const float* a_ptr = din_a;
@@ -55,7 +54,7 @@ void eltwise_prod(const float* din_a, const float* din_b, float* dout, const int
     }
 }
 
-void eltwise_sum(const float* din_a, const float* din_b, float* dout, const int size) {
+void eltwise_sum(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
 
     float* out_ptr = dout;
     const float* a_ptr = din_a;
@@ -105,7 +104,113 @@ void eltwise_sum(const float* din_a, const float* din_b, float* dout, const int
     }
 }
 
-void eltwise_max(const float* din_a, const float* din_b, float* dout, const int size) {
+void eltwise_sub(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vsubq_f32(va0, vb0);
+        vst1q_f32(out_ptr, vout1);
+        float32x4_t vout2 = vsubq_f32(va1, vb1);
+        vst1q_f32(out_ptr + 4, vout2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "sub_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vsub.f32  q8, q0, q1                   @ q8 = q0 * q1\n"
+                "vsub.f32  q9, q2, q3                   @ q9 = q2 * q3\n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       sub_loop                     @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        *(out_ptr++) = *(a_ptr++) - (*(b_ptr++));
+    }
+}
+void eltwise_sum_coeff(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vcoef0 = vdupq_n_f32(coeff[0]);
+    float32x4_t vcoef1 = vdupq_n_f32(coeff[1]);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vmulq_f32(va0, vcoef0);
+        vout1 = vmlaq_f32(vout1, vb0, vcoef1);
+        vst1q_f32(out_ptr, vout1);
+        float32x4_t vout2 = vmulq_f32(va1, vcoef0);
+        vout2 = vmlaq_f32(vout2, vb1, vcoef1);
+        vst1q_f32(out_ptr + 4, vout2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "sum_coeff_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vmul.f32  q8, q0, %q[vcoef0]           @ q8 = q0 * coef0 \n"
+                "vmul.f32  q9, q2, %q[vcoef0]           @ q9 = q1 * coef0 \n"
+                "vmla.f32  q8, q1, %q[vcoef1]           @ q8 = q8 + q1 * coef1\n"
+                "vmla.f32  q9, q3, %q[vcoef1]           @ q9 = q9 + q1 * vcoef1 \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       sum_coeff_loop               @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), \
+            [vcoef0] "+w" (vcoef0), [vcoef1] "+w" (vcoef1)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        *(out_ptr++) = *(a_ptr++) * coeff[0] + (*(b_ptr++)) * coeff[1];
+    }
+}
+
+void eltwise_max(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
 
     float* out_ptr = dout;
     const float* a_ptr = din_a;
@@ -168,7 +273,8 @@ LayOutType_op, LayOutType_in, LayOutType_out>::create(\
         std::vector<DataTensor_out*>& outputs,\
         EltwiseParam<OpTensor> &param, \
         Context<ARM> &ctx) {
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
+    this->_coeff = param.coeff;
     Shape sh_out_saber = outputs[0]->valid_shape();
     for (int i = 0; i < inputs.size(); i ++){
         Shape sh_in_saber = inputs[i]->valid_shape();
@@ -182,7 +288,12 @@ LayOutType_op, LayOutType_in, LayOutType_out>::create(\
             _impl = eltwise_prod;
             break;
         case Eltwise_sum:
-            _impl = eltwise_sum;
+            if (param.coeff[0] == 1 && param.coeff[1] == 1)
+                _impl = eltwise_sum;
+            else if (param.coeff[0] == 1 && param.coeff[1] == -1)
+                _impl = eltwise_sub;
+            else
+                _impl = eltwise_sum_coeff;
             break;
         case Eltwise_max:
             _impl = eltwise_max;
@@ -212,10 +323,10 @@ LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(\
 
     int size = outputs[0]->valid_size();
 
-    _impl(din_a, din_b, dout, size);
+    _impl(din_a, din_b, dout, _coeff, size);
     for (int i = 2; i < inputs.size(); ++i) {
         din_a = inputs[i]->data();
-        _impl(din_a, dout, dout, size);
+        _impl(din_a, dout, dout, _coeff, size);
     }
 
     return SaberSuccess;
@@ -227,4 +338,4 @@ template class SaberEltwise<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>
 
 } // namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/saber_eltwise.h b/saber/funcs/impl/arm/saber_eltwise.h
index 3d367f3..76c9792 100644
--- a/saber/funcs/impl/arm/saber_eltwise.h
+++ b/saber/funcs/impl/arm/saber_eltwise.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -23,7 +22,7 @@ namespace anakin{
 namespace saber{
 
 typedef void (*eltwise_func)(const float* din_a, \
-    const float* din_b, float* dout, const int size);
+    const float* din_b, float* dout, std::vector<float> coeff, const int size);
 
 
 template <DataType OpDtype,
@@ -67,6 +66,7 @@ public:
 
 private:
     eltwise_func _impl{nullptr};
+    std::vector<float> _coeff;
 };
 
 } //namespace saber
diff --git a/saber/funcs/impl/arm/saber_eltwise_active.cpp b/saber/funcs/impl/arm/saber_eltwise_active.cpp
new file mode 100644
index 0000000..1210f5e
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_eltwise_active.cpp
@@ -0,0 +1,430 @@
+#include "saber/funcs/impl/arm/saber_eltwise_active.h"
+
+#ifdef USE_ARM_PLACE
+namespace anakin{
+
+namespace saber{
+void eltwise_prod_relu(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vzero = vdupq_n_f32(0.f);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vmulq_f32(va0, vb0);
+        uint32x4_t vmask1 = vcgtq_f32(vout1, vzero);//vout1 > 0
+        float32x4_t vrst1 = vbslq_f32(vmask1, vout1, vzero);
+        vst1q_f32(out_ptr, vrst1);
+        float32x4_t vout2 = vmulq_f32(va1, vb1);
+        uint32x4_t vmask2 = vcgtq_f32(vout2, vzero);//vout2 > 0
+        float32x4_t vrst2 = vbslq_f32(vmask2, vout2, vzero);
+        vst1q_f32(out_ptr + 4, vrst2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "prod_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vmul.f32  q8, q0, q1                   @ q8 = q0 * q1\n"
+                "vmul.f32  q9, q2, q3                   @ q9 = q2 * q3\n"
+                "vcgt.f32  q0, q8, %q[vzero]            @ q8 > 0 \n"
+                "vcgt.f32  q1, q9, %q[vzero]            @ q9 > 0 \n"
+                "vbif.f32  q8, %q[vzero], q0            @ bif \n"
+                "vbif.f32  q9,  %q[vzero], q1           @ bif \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!        @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!        @ store data\n"
+                "bne       prod_loop                    @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), [vzero] "+w" (vzero)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        float tmp = *(a_ptr++) * (*(b_ptr++));
+        *(out_ptr++) = tmp > 0 ? tmp : 0.f;
+    }
+}
+
+void eltwise_sum_relu(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vzero = vdupq_n_f32(0.f);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vaddq_f32(va0, vb0);
+        uint32x4_t vmask1 = vcgtq_f32(vout1, vzero);//vout1 > 0
+        float32x4_t vrst1 = vbslq_f32(vmask1, vout1, vzero);
+        vst1q_f32(out_ptr, vrst1);
+        float32x4_t vout2 = vaddq_f32(va1, vb1);
+        uint32x4_t vmask2 = vcgtq_f32(vout2, vzero);//vout1 > 0
+        float32x4_t vrst2 = vbslq_f32(vmask2, vout2, vzero);
+        vst1q_f32(out_ptr + 4, vrst2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "sum_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vadd.f32  q8, q0, q1                   @ q8 = q0 + q1\n"
+                "vadd.f32  q9, q2, q3                   @ q9 = q2 + q3\n"
+                "vcgt.f32  q0, q8, %q[vzero]            @ q8 > 0 \n"
+                "vcgt.f32  q1, q9, %q[vzero]            @ q9 > 0 \n"
+                "vbif.f32  q8, %q[vzero], q0            @ bsl \n"
+                "vbif.f32  q9,  %q[vzero], q1           @ bsl \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       sum_loop                     @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), [vzero] "+w" (vzero)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        float tmp = *(a_ptr++) + (*(b_ptr++));
+        *(out_ptr++) = tmp > 0 ? tmp : 0.f;
+    }
+}
+
+void eltwise_sub_relu(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vzero = vdupq_n_f32(0.f);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vsubq_f32(va0, vb0);
+        uint32x4_t vmask1 = vcgtq_f32(vout1, vzero);//vout1 > 0
+        float32x4_t vrst1 = vbslq_f32(vmask1, vout1, vzero);
+        vst1q_f32(out_ptr, vrst1);
+        float32x4_t vout2 = vsubq_f32(va1, vb1);
+        uint32x4_t vmask2 = vcgtq_f32(vout2, vzero);//vout1 > 0
+        float32x4_t vrst2 = vbslq_f32(vmask2, vout2, vzero);
+        vst1q_f32(out_ptr + 4, vrst2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "sub_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vsub.f32  q8, q0, q1                   @ q8 = q0 - q1\n"
+                "vsub.f32  q9, q2, q3                   @ q9 = q2  q3\n"
+                "vcgt.f32  q0, q8, %q[vzero]            @ q8 > 0 \n"
+                "vcgt.f32  q1, q9, %q[vzero]            @ q9 > 0 \n"
+                "vbif.f32  q8, %q[vzero], q0            @ bif \n"
+                "vbif.f32  q9, %q[vzero], q1            @ bif \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       sub_loop                     @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), [vzero] "+w" (vzero)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        float tmp = *(a_ptr++) - (*(b_ptr++));
+         *(out_ptr++) = tmp > 0 ? tmp : 0.f;
+    }
+}
+void eltwise_sum_coeff_relu(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vzero = vdupq_n_f32(0.f);
+    float32x4_t vcoef0 = vdupq_n_f32(coeff[0]);
+    float32x4_t vcoef1 = vdupq_n_f32(coeff[1]);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vmulq_f32(va0, vcoef0);
+        vout1 = vmlaq_f32(vout1, vb0, vcoef1);
+        uint32x4_t vmask1 = vcgtq_f32(vout1, vzero);//vout1 > 0
+        float32x4_t vrst1 = vbslq_f32(vmask1, vout1, vzero);
+        vst1q_f32(out_ptr, vrst1);
+        float32x4_t vout2 = vmulq_f32(va1, vcoef0);
+        vout2 = vmlaq_f32(vout2, vb1, vcoef1);
+        uint32x4_t vmask2 = vcgtq_f32(vout2, vzero);//vout1 > 0
+        float32x4_t vrst2 = vbslq_f32(vmask2, vout2, vzero);
+        vst1q_f32(out_ptr + 4, vrst2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "sum_coeff_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vmul.f32  q8, q0, %q[vcoef0]           @ q8 = q0 * coef0 \n"
+                "vmul.f32  q9, q2, %q[vcoef0]           @ q9 = q1 * coef0 \n"
+                "vmla.f32  q8, q1, %q[vcoef1]           @ q8 = q8 + q1 * coef1\n"
+                "vmla.f32  q9, q3, %q[vcoef1]           @ q9 = q9 + q1 * vcoef1 \n"
+                "vcgt.f32  q0, q8, %q[vzero]            @ q8 > 0 \n"
+                "vcgt.f32  q1, q9, %q[vzero]            @ q9 > 0 \n"
+                "vbif.f32  q8, %q[vzero], q0            @ bif \n"
+                "vbif.f32  q9, %q[vzero], q1            @ bif \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       sum_coeff_loop               @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), \ 
+            [vcoef0] "+w" (vcoef0), [vcoef1] "+w" (vcoef1), [vzero] "+w" (vzero)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+        float tmp = *(a_ptr++) * coeff[0] + (*(b_ptr++)) * coeff[1];
+        *(out_ptr++) = tmp > 0 ? tmp : 0.f;
+    }
+}
+
+void eltwise_max_relu(const float* din_a, const float* din_b, float* dout, std::vector<float> coeff, const int size) {
+
+    float* out_ptr = dout;
+    const float* a_ptr = din_a;
+    const float* b_ptr = din_b;
+
+    int cnt = size >> 3;
+    int remain = size & 7;
+    float32x4_t vzero = vdupq_n_f32(0.f);
+#ifdef __aarch64__
+    for (int i = 0; i < cnt; ++i) {
+        float32x4_t va0 = vld1q_f32(a_ptr);
+        float32x4_t vb0 = vld1q_f32(b_ptr);
+        float32x4_t va1 = vld1q_f32(a_ptr + 4);
+        float32x4_t vb1 = vld1q_f32(b_ptr + 4);
+        float32x4_t vout1 = vmaxq_f32(va0, vb0);
+        uint32x4_t vmask1 = vcgtq_f32(vout1, vzero);//vout1 > 0
+        float32x4_t vrst1 = vbslq_f32(vmask1, vout1, vzero);
+        vst1q_f32(out_ptr, vrst1);
+        float32x4_t vout2 = vmaxq_f32(va1, vb1);
+        uint32x4_t vmask2 = vcgtq_f32(vout2, vzero);//vout1 > 0
+        float32x4_t vrst2 = vbslq_f32(vmask2, vout2, vzero);
+        vst1q_f32(out_ptr + 4, vrst2);
+        a_ptr += 8;
+        b_ptr += 8;
+        out_ptr += 8;
+    }
+#else
+    int loop_cnt = cnt;
+    if (loop_cnt > 0) {
+        asm volatile(
+        "max_loop:                                         @ main loop start point\n"
+                "vld1.f32  {d0-d1}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d2-d3}, [%[b_ptr]]!         @ load din r1n\n"
+                "vld1.f32  {d4-d5}, [%[a_ptr]]!         @ load din r0\n"
+                "vld1.f32  {d6-d7}, [%[b_ptr]]!         @ load din r1n\n"
+                "vmax.f32  q8, q0, q1                   @ q8 = max(q0, q1)\n"
+                "vmax.f32  q9, q2, q3                   @ q9 = max(q2, q3)\n"
+                "vcgt.f32  q0, q8, %q[vzero]            @ q8 > 0 \n"
+                "vcgt.f32  q1, q9, %q[vzero]            @ q9 > 0 \n"
+                "vbif.f32  q8, %q[vzero], q0            @ bif \n"
+                "vbif.f32  q9, %q[vzero], q1            @ bif \n"
+                "subs      %[loop_cnt], #1              @ loop --\n"
+                "vst1.f32 {d16-d17}, [%[out_ptr]]!      @ store data\n"
+                "vst1.f32 {d18-d19}, [%[out_ptr]]!      @ store data\n"
+                "bne       max_loop                     @ top_loop \n"
+        :[loop_cnt] "+r" (loop_cnt), [a_ptr] "+r" (a_ptr), \
+            [b_ptr] "+r" (b_ptr), [out_ptr] "+r" (out_ptr), [vzero] "+w" (vzero)
+        :
+        :"q0", "q1", "q2", "q3", "q8", "q9"
+        );
+    }
+#endif //__aarch64__
+
+    for (; remain > 0; remain--) {
+       float tmp = std::max(*(a_ptr++), *(b_ptr++));
+       *(out_ptr++) = tmp > 0 ? tmp : 0.f;
+    }
+}
+
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberEltwiseActive<ARM, OpDtype, inDtype, outDtype, \
+LayOutType_op, LayOutType_in, LayOutType_out>::create(\
+    const std::vector<DataTensor_in*>& inputs,\
+        std::vector<DataTensor_out*>& outputs,\
+        EltwiseActiveParam<OpTensor> &param, \
+        Context<ARM> &ctx) {
+    this->_ctx = &ctx;
+    _coeff = param.eltwise_param.coeff;
+    Shape sh_out_saber = outputs[0]->valid_shape();
+    for (int i = 0; i < inputs.size(); i ++){
+        Shape sh_in_saber = inputs[i]->valid_shape();
+        if (sh_out_saber != sh_in_saber){
+                    LOG(INFO) << "input shape is not same with output shape ";
+            return SaberInvalidValue;
+        }
+    }
+    if(param.has_activation){
+        if(param.activation_param.active == 2){//Active_relu = 2
+            switch (param.eltwise_param.operation) {
+                case Eltwise_prod:
+                   _impl = eltwise_prod_relu;
+                   //printf("prod\n");
+                   break;
+                case Eltwise_sum:
+                   if (param.eltwise_param.coeff[0] == 1 && param.eltwise_param.coeff[1] == 1)
+                        _impl = eltwise_sum_relu;
+                    else if (param.eltwise_param.coeff[0] == 1 && param.eltwise_param.coeff[1] == -1)
+                        _impl = eltwise_sub_relu;
+                    else
+                        _impl = eltwise_sum_coeff_relu;
+                    break;
+                case Eltwise_max:
+                    _impl = eltwise_max_relu;
+                    break;
+                default:
+                    LOG(ERROR) << "unknown eltwise type!!";
+                    return SaberUnKownError;
+            }
+        }
+        //todo
+    }
+   /* switch (param.eltwise_param.operation) {
+        case Eltwise_prod:
+            _impl = eltwise_prod_relu;
+            break;
+        case Eltwise_sum:
+            if (param.coeff[0] == 1 && param.coeff[1] == 1)
+                _impl = eltwise_sum_relu;
+            else if (param.coeff[0] == 1 && param.coeff[1] == -1)
+                _impl = eltwise_sub_relu;
+            else
+                _impl = eltwise_sum_coeff_relu;
+            break;
+        case Eltwise_max:
+            _impl = eltwise_max_relu;
+            break;
+        default:
+            LOG(ERROR) << "unknown eltwise type!!";
+            return SaberUnKownError;
+    }
+    */
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberEltwiseActive<ARM, OpDtype, inDtype, outDtype, \
+LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(\
+    const std::vector<DataTensor_in*>& inputs, \
+    std::vector<DataTensor_out*>& outputs, \
+    EltwiseActiveParam<OpTensor> &param) {
+
+    const float* din_a = inputs[0]->data();
+    const float* din_b = inputs[1]->data();
+    float* dout = outputs[0]->mutable_data();
+
+  // printf("threads compute begin:device.id: %d \n", this->_ctx.get_device_id());
+   int threads = 1;
+    this->_ctx->get_mode(threads);
+   // printf("threads: %d\n", threads);
+    int size = outputs[0]->valid_size();
+    int num = size / threads;
+  //  printf("threads: %d, size: %d, num: %d\n", threads, size, num);
+#pragma omp parallel for 
+    for(int i = 0; i < size; i+=num){
+        const float* din0_ptr = din_a + i;
+        const float* din1_ptr = din_b + i;
+        float* dout_ptr = dout + i;
+        _impl(din0_ptr, din1_ptr, dout_ptr, _coeff, num);
+    }
+
+    //_impl(din_a, din_b, dout, _coeff, size);
+    for (int i = 2; i < inputs.size(); ++i) {
+        din_a = inputs[i]->data();
+        _impl(din_a, dout, dout, _coeff, size);
+    }
+
+    return SaberSuccess;
+}
+
+template class SaberEltwiseActive<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+
+} //namespace saber
+
+} // namespace anakin
+
+#endif //USE_ARM_PLACE
\ No newline at end of file
diff --git a/saber/funcs/impl/arm/saber_eltwise_active.h b/saber/funcs/impl/arm/saber_eltwise_active.h
new file mode 100644
index 0000000..b25b468
--- /dev/null
+++ b/saber/funcs/impl/arm/saber_eltwise_active.h
@@ -0,0 +1,79 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+#ifndef ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_ELTWISE_ACTIVE_H
+#define ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_ELTWISE_ACTIVE_H
+
+#include "saber/funcs/impl/impl_eltwise_act.h"
+
+#ifdef USE_ARM_PLACE
+namespace anakin{
+
+namespace saber{
+
+typedef void (*eltwise_active_func)(const float* din_a, \
+    const float* din_b, float* dout, std::vector<float> coeff, const int size);
+
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+class SaberEltwiseActive<ARM, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>:\
+public ImplBase<
+        Tensor<ARM, inDtype, LayOutType_in>,
+        Tensor<ARM, outDtype, LayOutType_out>,
+        Tensor<ARM, OpDtype, LayOutType_op>,
+        EltwiseActiveParam<Tensor<ARM, OpDtype, LayOutType_op>>> {
+public:
+    typedef Tensor<ARM, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<ARM, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<ARM, OpDtype, LayOutType_op> OpTensor;
+
+    typedef typename DataTensor_in::Dtype InDataType;
+    typedef typename DataTensor_out::Dtype OutDataType;
+    typedef typename OpTensor::Dtype OpDataType;
+
+    SaberEltwiseActive() {}
+    ~SaberEltwiseActive() {}
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             EltwiseActiveParam<OpTensor> &param, Context<ARM> &ctx) override {
+        return create(inputs, outputs, param, ctx);
+    }
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,\
+                               std::vector<DataTensor_out*>& outputs,\
+                               EltwiseActiveParam<OpTensor> &param, \
+                               Context<ARM> &ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs, \
+                                 std::vector<DataTensor_out*>& outputs, \
+                                 EltwiseActiveParam<OpTensor> &param) override;
+
+private:
+    eltwise_active_func _impl{nullptr};
+    std::vector<float> _coeff;
+    bool _flag_relu = true;
+};
+
+} //namespace saber
+
+} //namespace anakin
+#endif // USE_ARM_PLACE
+
+#endif //ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_ACTIVE_RELU_H
diff --git a/saber/funcs/impl/arm/saber_fc.cpp b/saber/funcs/impl/arm/saber_fc.cpp
index 38b3b6d..d5287bf 100644
--- a/saber/funcs/impl/arm/saber_fc.cpp
+++ b/saber/funcs/impl/arm/saber_fc.cpp
@@ -1,7 +1,9 @@
-#include "saber_fc.h"
+#include "saber/funcs/impl/arm/saber_fc.h"
 
 #ifdef USE_ARM_PLACE
 
+#include "saber/funcs/impl/arm/impl/sgemv_arm.h"
+
 namespace anakin{
 
 namespace saber{
@@ -41,167 +43,6 @@ void fill_bias_fc<float>(float* tensor, const float* bias, const int num, const
     }
 }
 
-template <typename Dtype>
-void fc_kernel(const Dtype* din, const Dtype* weights, const Dtype* bias, \
-    Dtype* dout, const int m, const int n, const int k, bool flag_trans_weights);
-
-template <>
-void fc_kernel<float>(const float* din, const float* weights, const float* bias, \
-    float* dout, const int m, const int n, const int k, \
-    bool flag_bias) {
-
-    float zero[4] = {0.f, 0.f, 0.f, 0.f};
-
-    float* dout_ptr = dout;
-    const float* din_ptr = din;
-    const float* weights_ptr = weights;
-
-    int cnt = k >> 3;
-    int tail = k & 7;
-    int out_cnt = n >> 2;
-
-    for (int i = 0; i < m; ++i) {
-        float* data_batch_out = dout_ptr + i * n;
-        const float* data_batch_in = din_ptr + i * k;
-
-#pragma omp parallel for
-        for (int j = 0; j < out_cnt; j++) {
-
-            float *ptr_out = data_batch_out + j * 4;
-            const float *ptr_in = data_batch_in;
-            const float *ptr_w0 = weights + (k * j * 4);
-            const float *ptr_w1 = ptr_w0 + k;
-            const float *ptr_w2 = ptr_w1 + k;
-            const float *ptr_w3 = ptr_w2 + k;
-
-            const float* ptr_bias = zero;
-            if (flag_bias) {
-                ptr_bias = bias + j * 4;
-            }
-
-            int loop_cnt = cnt;
-            asm volatile(
-            "pld [%[in], #128] @ preload cache line, input\n"
-
-                    "vmov.u32 q0, #0 @ set q0 to 0\n"
-                    "vmov.u32 q1, #0 @ set q1 to 0\n"
-                    "vmov.u32 q2, #0 @ set q2 to 0\n"
-                    "vmov.u32 q3, #0 @ set q3 to 0\n"
-
-                    "pld [%[w0], #128] @ preload cache line, weights r0\n"
-                    "pld [%[w1], #128] @ preload cache line, weights r1\n"
-                    "pld [%[w2], #128] @ preload cache line, weights r2\n"
-                    "pld [%[w3], #128] @ preload cache line, weights r3\n"
-
-                    ".full_connect_loop: @ main loop\n"
-                    // unroll 0
-                    "vld1.32 {d12-d15}, [%[in]]!    @ load input, q6, q7\n"
-                    "vld1.32 {d16-d19}, [%[w0]]!    @ load weights r0, q8,q9\n"
-                    "vld1.32 {d20-d23}, [%[w1]]!    @ load weights r1, q10,q11\n"
-                    "vld1.32 {d24-d27}, [%[w2]]!    @ load weights r2, q12,q13\n"
-                    "vld1.32 {d28-d31}, [%[w3]]!    @ load weights r3, q14, q15\n"
-                    "vmla.f32 q0, q6, q8            @ mul add\n"
-                    "pld [%[in], #128]              @ preload cache line, input\n"
-                    "pld [%[w0], #128]              @ preload cache line, weights r0\n"
-                    "vmla.f32 q1, q6, q10           @ mul add\n"
-                    "pld [%[w1], #128]              @ preload cache line, weights r1\n"
-                    "vmla.f32 q2, q8, q12           @ mul add\n"
-                    "pld [%[w2], #128]              @ preload cache line, weights r2\n"
-                    "vmla.f32 q3, q8, q14           @ mul add\n"
-                    "pld [%[w3], #128]              @ preload cache line, weights r3\n"
-
-
-                    // unrll 1
-                    "vmla.f32 q0, q7, q9            @ mul add\n"
-                    "pld [%[in], #128]              @ preload cache line, input\n"
-                    "pld [%[w0], #128]              @ preload cache line, weights r0\n"
-                    "vmla.f32 q1, q7, q11           @ mul add\n"
-                    "pld [%[w1], #128]              @ preload cache line, weights r1\n"
-                    "vmla.f32 q2, q7, q13           @ mul add\n"
-                    "pld [%[w2], #128]              @ preload cache line, weights r2\n"
-                    "vmla.f32 q3, q7, q15           @ mul add\n"
-                    "pld [%[w3], #128]              @ preload cache line, weights r3\n"
-
-                    // check loop end
-                    "subs %[loop_cnt], #1           @ sub loop count \n"
-                    "bne .full_connect_loop         @ jump to main loop\n"
-
-                    // pair add to final result
-                    "vld1.32 {d12-d13}, [%[ptr_bias]]    @ load bias, q6\n"
-                    "vpadd.f32 d8, d0, d1           @ pair add, first step\n"
-                    "vpadd.f32 d9, d2, d3           @ pair add, first step\n"
-                    "vpadd.f32 d10, d4, d5          @ pair add, first step\n"
-                    "vpadd.f32 d11, d6, d7          @ pair add, first step\n"
-
-                    "vpadd.f32 d0, d8, d9           @ pair add, second step\n"
-                    "vpadd.f32 d1, d10, d11         @ pair add, second step\n"
-
-                    "vadd.f32  q1, q0, q6           @ add bias\n"
-                    "vst1.32 {d2-d3}, [%[out]]      @ save result\n"
-
-            :[in] "+r"(ptr_in), [w0] "+r"(ptr_w0), [w1] "+r"(ptr_w1), \
-                    [w2] "+r"(ptr_w2), [w3] "+r"(ptr_w3), [out] "+r"(ptr_out), \
-                    [loop_cnt] "+r"(loop_cnt)
-            :[ptr_bias] "r" (ptr_bias)
-            :"q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9", \
-                "q10", "q11", "q12", "q13", "q14", "q15"
-            );
-
-            for (int ii = 0; ii < tail; ++ii) {
-                float data_in = *ptr_in;
-                ptr_out[0] += *(ptr_w0++) * data_in;
-                ptr_out[1] += *(ptr_w1++) * data_in;
-                ptr_out[2] += *(ptr_w2++) * data_in;
-                ptr_out[3] += *(ptr_w3++) * data_in;
-                ptr_in++;
-            }
-        }
-        //! process remains
-#pragma omp parallel for
-        for (int j = out_cnt * 4; j < n; ++j) {
-            float *ptr_out = data_batch_out + j;
-            const float *ptr_in = data_batch_in;
-            const float *ptr_w0 = weights + (k * j);
-
-            int loop_cnt = cnt;
-            asm volatile(
-            "pld [%[in], #128] @ preload cache line, input\n"
-                    "vmov.u32 q0, #0 @ set q0 to 0\n"
-                    "pld [%[w0], #128] @ preload cache line, weights r0\n"
-
-                    ".full_connect_loop2: @ main loop\n"
-                    "vld1.32 {d24-d27}, [%[in]]! @ load input, q12,q13\n"
-                    "vld1.32 {d28-d29}, [%[w0]]! @ load weights r0, q14\n"
-                    "vmla.f32 q0, q12, q14 @ mul add\n"
-                    "vld1.32 {d30-d31}, [%[w0]]! @ load weights r0, q15\n"
-                    "pld [%[in]] @ preload cache line, input\n"
-                    "pld [%[w0]] @ preload cache line, weights r0\n"
-                    "pld [%[in], #128] @ preload cache line, input\n"
-                    "pld [%[w0], #128] @ preload cache line, weights r0\n"
-                    "vmla.f32 q0, q13, q15 @ mul add\n"
-                    "subs %[loop_cnt] , #1 @ sub loop count \n"
-                    "bne .full_connect_loop2 @ jump to main loop\n"
-
-                    // pair add to final result
-                    "vpadd.f32 d2, d0, d1 @ pair add, first step\n"
-                    "vpadd.f32 d3, d2, d2 @ pair add, final step\n"
-                    "vst1.32 {d3[0]}, [%[out]] @ save result\n"
-            :[in] "+r"(ptr_in), [w0] "+r"(ptr_w0), [out] "+r"(ptr_out), \
-                    [loop_cnt] "+r"(loop_cnt)
-            :
-            :"q0", "q1", "q12", "q13", "q14", "q15"
-            );
-
-            for (int ii = 0; ii < tail; ++ii) {
-                *ptr_out += *(ptr_w0++) * *(ptr_in++);
-            }
-            if (flag_bias) {
-                ptr_out[0] += bias[j];
-            }
-        }
-    }
-}
-
 template <DataType OpDtype,
         DataType inDtype,
         DataType outDtype,
@@ -221,14 +62,19 @@ SaberStatus SaberFc<ARM, OpDtype, inDtype, outDtype, \
     if (flag_bias) {
         bias = param.bias->data();
     }
-#if 1
-    _gemmer(din, _k, weights, (param.is_transpose_weights? _n : _k), dout, _n, 1.f, 0.f, false);
-    if (flag_bias) {
-        fill_bias_fc(dout, bias, _m, _n);
+
+    if (_m > 1 || param.is_transpose_weights) {
+        _gemmer(din, _k, weights, (param.is_transpose_weights? _n : _k), dout, _n, 1.f, 0.f, false);
+        if (flag_bias) {
+            fill_bias_fc(dout, bias, _m, _n);
+        }
+    } else {
+        if (flag_bias) {
+            sgemv_bias(false, _n, _k, weights, din, dout, bias);
+        } else {
+            sgemv(false, _n, _k, weights, din, dout);
+        }
     }
-#else
-    fc_kernel(din, weights, bias, dout, _m, _n, _k, param.is_transpose_weights);
-#endif
     return SaberSuccess;
 }
 
diff --git a/saber/funcs/impl/arm/saber_fc.h b/saber/funcs/impl/arm/saber_fc.h
index dc6fc14..ad826d7 100755
--- a/saber/funcs/impl/arm/saber_fc.h
+++ b/saber/funcs/impl/arm/saber_fc.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -25,10 +24,10 @@ namespace anakin{
 
 namespace saber{
 
-//! input size: 1xk
-//! output size: 1xn
-//! weights size: nxk
-//! bias size: 1xn
+//! input size: m x k
+//! output size: m x n
+//! weights size: n x k
+//! bias size: 1 x n
 
 template <DataType OpDtype,
         DataType inDtype,
@@ -58,7 +57,7 @@ public:
         std::vector<DataTensor_out*>& outputs, \
         FcParam<OpTensor> &param, Context<ARM> &ctx) override {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -66,8 +65,9 @@ public:
         std::vector<DataTensor_out*>& outputs, \
         FcParam<OpTensor> &param, Context<ARM> &ctx) override {
 
-        this->_ctx = ctx;
-        int threads = this->_ctx.get_act_ids().size();
+        this->_ctx = &ctx;
+        int threads = 1;
+        this->_ctx->get_mode(threads);
 
         _m = inputs[0]->count_valid(0, param.axis);
         _k = inputs[0]->count_valid(param.axis, inputs[0]->dims());
@@ -78,14 +78,17 @@ public:
         }
         CHECK_EQ(weights_size / _n, _k) << "weights size does not meet the input size";
 
-        int l1_cache = this->_ctx.devs[this->_ctx.get_device_id()]._info._L1_cache;
-        int l2_cache = this->_ctx.devs[this->_ctx.get_device_id()]._info._L2_cache;
+        int l1_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L1_cache;
+        int l2_cache = this->_ctx->devs[this->_ctx->get_device_id()]._info._L2_cache;
         //! if L1 cache size is not provided, set to 31K
         l1_cache = l1_cache > 0? l1_cache : 31000;
         //! if L2 cache size is not provided, set to 2M
         l2_cache = l2_cache > 0? l2_cache : 2000000;
 
-        _gemmer.init(l1_cache, l2_cache, _m, _n, _k, false, !param.is_transpose_weights, threads);
+        LOG(INFO) << "fc weights transpose: " << (param.is_transpose_weights? "true" : "false");
+        if (_m > 1 || param.is_transpose_weights) {
+            _gemmer.init(l1_cache, l2_cache, _m, _n, _k, false, !param.is_transpose_weights, threads);
+        }
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/arm/saber_permute.cpp b/saber/funcs/impl/arm/saber_permute.cpp
index 10bd71f..7755273 100644
--- a/saber/funcs/impl/arm/saber_permute.cpp
+++ b/saber/funcs/impl/arm/saber_permute.cpp
@@ -115,6 +115,8 @@ LayOutType_op, LayOutType_in, LayOutType_out>::create(\
     const std::vector<DataTensor_in*>& inputs, \
         std::vector<DataTensor_out*>& outputs, \
         PermuteParam<OpTensor> &param, Context<ARM> &ctx) {
+
+    this->_ctx = &ctx;
     _num_axes = inputs[0]->dims();
     _count = outputs[0]->valid_size();
     _order_dims.clear();
@@ -142,24 +144,25 @@ LayOutType_op, LayOutType_in, LayOutType_out>::create(\
     std::vector<int> axis_diff;
     int j = 0;
     for (int i = 0; i < _num_axes; ++i) {
-        if (_order_dims[i] != j) {
-            axis_diff.push_back(i);
+        if (_order_dims[j] != i) {
+            axis_diff.push_back(j);
+            //LOG(INFO) << "diff axis: " << _order_dims[j];
         } else {
             j++;
         }
     }
     if (axis_diff.size() == 1) {
         _transpose = true;
-        _trans_num = outputs[0]->count_valid(0, std::max(axis_diff[0] - 1, 0));
-        _trans_h = outputs[0]->count_valid(axis_diff[0] + 1, _num_axes);
-        _trans_w = outputs[0]->valid_shape()[axis_diff[0]];
-        LOG(INFO) << "permute: transpose=true, num=" << _trans_num \
+        _trans_num = inputs[0]->count_valid(0, std::max(axis_diff[0] - 1, 0));
+        _trans_w = inputs[0]->count_valid(axis_diff[0] + 1, _num_axes);
+        _trans_h = inputs[0]->valid_shape()[axis_diff[0]];
+        //LOG(INFO) << "permute: transpose=true, num=" << _trans_num \
             << ", h=" << _trans_h << ", w=" << _trans_w;
     } else {
         _transpose = false;
         _new_steps = outputs[0]->get_stride();
         _old_steps = inputs[0]->get_stride();
-        LOG(INFO) << "permute: transpose=false";
+        //LOG(INFO) << "permute: transpose=false";
     }
 
     return SaberSuccess;
@@ -202,4 +205,4 @@ template class SaberPermute<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>
 
 } // namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/saber_permute.h b/saber/funcs/impl/arm/saber_permute.h
index 0fdf536..177e934 100644
--- a/saber/funcs/impl/arm/saber_permute.h
+++ b/saber/funcs/impl/arm/saber_permute.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -53,8 +52,6 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
         std::vector<DataTensor_out*>& outputs, \
         PermuteParam<OpTensor> &param, Context<ARM> &ctx) override {
-        // get context
-        this->_ctx = ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/arm/saber_pooling.cpp b/saber/funcs/impl/arm/saber_pooling.cpp
index 69b2e7a..47634d4 100644
--- a/saber/funcs/impl/arm/saber_pooling.cpp
+++ b/saber/funcs/impl/arm/saber_pooling.cpp
@@ -13,11 +13,28 @@ SaberStatus SaberPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::c
     std::vector<DataTensor_out*>& outputs, \
     PoolingParam<OpTensor> &param, Context<ARM> &ctx) {
 
+    this->_ctx = &ctx;
+
     if (param.global_pooling) {
         _impl = pooling_global;
         return SaberSuccess;
     }
 
+    if (param.window_w == 3) {
+        if (param.pooling_type == Pooling_max) {
+            if (param.stride_w == 2)
+               _impl = pooling3x3s2_max;
+           else
+               _impl = pooling3x3s1_max;
+        } else {
+            if (param.stride_w == 2)
+               _impl = pooling3x3s2_ave;
+           else
+               _impl = pooling3x3s1_ave;
+        }
+        return SaberSuccess;
+    }
+
     if (param.window_w != param.window_h || param.stride_w != param.stride_h \
         || param.stride_w != 2 || param.pad_w != param.pad_h || param.pad_w > 1) {
         _impl = pooling_basic;
@@ -33,15 +50,6 @@ SaberStatus SaberPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::c
         return SaberSuccess;
     }
 
-    if (param.window_w == 3) {
-        if (param.pooling_type == Pooling_max) {
-            _impl = pooling3x3s2_max;
-        } else {
-            _impl = pooling3x3s2_ave;
-        }
-        return SaberSuccess;
-    }
-
     _impl = pooling_basic;
     return SaberSuccess;
 }
@@ -63,4 +71,4 @@ template class SaberPooling<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>
 
 } // namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
diff --git a/saber/funcs/impl/arm/saber_pooling.h b/saber/funcs/impl/arm/saber_pooling.h
index 8e8d4e3..8502d07 100755
--- a/saber/funcs/impl/arm/saber_pooling.h
+++ b/saber/funcs/impl/arm/saber_pooling.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -55,8 +54,6 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
         std::vector<DataTensor_out*>& outputs, \
         PoolingParam<OpTensor> &param, Context<ARM> &ctx) override {
-        // get context
-        this->_ctx = ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/arm/saber_prelu.cpp b/saber/funcs/impl/arm/saber_prelu.cpp
index f9045f6..4d780aa 100644
--- a/saber/funcs/impl/arm/saber_prelu.cpp
+++ b/saber/funcs/impl/arm/saber_prelu.cpp
@@ -1,5 +1,5 @@
 #include "saber/funcs/impl/arm/saber_prelu.h"
-
+#if 0 //remove prelu
 #ifdef USE_ARM_PLACE
 namespace anakin{
 
@@ -98,4 +98,5 @@ template class SaberPrelu<ARM, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
 
 } // namespace anakin
 
-#endif //USE_ARM_PLACE
\ No newline at end of file
+#endif //USE_ARM_PLACE
+#endif
diff --git a/saber/funcs/impl/arm/saber_prelu.h b/saber/funcs/impl/arm/saber_prelu.h
index 5844367..e7555ec 100644
--- a/saber/funcs/impl/arm/saber_prelu.h
+++ b/saber/funcs/impl/arm/saber_prelu.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -14,7 +13,7 @@
 */
 #ifndef ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_PRELU_H
 #define ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_PRELU_H
-
+#if 0 //remove prelu
 #include "saber/funcs/impl/impl_prelu.h"
 
 #ifdef USE_ARM_PLACE
@@ -51,14 +50,14 @@ typedef typename OpTensor::Dtype OpDataType;
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
         std::vector<DataTensor_out*>& outputs, \
         PreluParam<OpTensor> &param, Context<ARM> &ctx) override {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
     virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs, \
         std::vector<DataTensor_out*>& outputs, \
         PreluParam<OpTensor> &param, Context<ARM> &ctx) override {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
@@ -72,3 +71,4 @@ typedef typename OpTensor::Dtype OpDataType;
 #endif // USE_ARM_PLACE
 
 #endif //ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_POOLING_H
+#endif
diff --git a/saber/funcs/impl/arm/saber_priorbox.h b/saber/funcs/impl/arm/saber_priorbox.h
index 4d9a841..997d278 100644
--- a/saber/funcs/impl/arm/saber_priorbox.h
+++ b/saber/funcs/impl/arm/saber_priorbox.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -52,7 +51,7 @@ public:
                       std::vector<DataTensor_out*>& outputs,
                       PriorBoxParam<OpTensor> &param, Context<ARM> &ctx) override {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -63,6 +62,10 @@ public:
         SABER_CHECK(_output_arm.reshape(outputs[0]->valid_shape()));
         float* output_host = _output_arm.mutable_data();
 
+        float* min_buf = (float*)fast_malloc(sizeof(float) * 4);
+        float* max_buf = (float*)fast_malloc(sizeof(float) * 4);
+        float* com_buf = (float*)fast_malloc(sizeof(float) * param.aspect_ratio.size() * 4);
+
         const int width = inputs[0]->width();
         const int height = inputs[0]->height();
         int img_width = param.img_w;
@@ -89,17 +92,20 @@ public:
                 float box_width;
                 float box_height;
                 for (int s = 0; s < param.min_size.size(); ++s) {
+                    int min_idx = 0;
+                    int max_idx = 0;
+                    int com_idx = 0;
                     int min_size = param.min_size[s];
                     //! first prior: aspect_ratio = 1, size = min_size
                     box_width = box_height = min_size;
                     //! xmin
-                    output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                    min_buf[min_idx++] = (center_x - box_width / 2.f) / img_width;
                     //! ymin
-                    output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                    min_buf[min_idx++] = (center_y - box_height / 2.f) / img_height;
                     //! xmax
-                    output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                    min_buf[min_idx++] = (center_x + box_width / 2.f) / img_width;
                     //! ymax
-                    output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                    min_buf[min_idx++] = (center_y + box_height / 2.f) / img_height;
 
                     if (param.max_size.size() > 0) {
 
@@ -107,13 +113,13 @@ public:
                         //! second prior: aspect_ratio = 1, size = sqrt(min_size * max_size)
                         box_width = box_height = sqrtf(min_size * max_size);
                         //! xmin
-                        output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                        max_buf[max_idx++] = (center_x - box_width / 2.f) / img_width;
                         //! ymin
-                        output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                        max_buf[max_idx++] = (center_y - box_height / 2.f) / img_height;
                         //! xmax
-                        output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                        max_buf[max_idx++] = (center_x + box_width / 2.f) / img_width;
                         //! ymax
-                        output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                        max_buf[max_idx++] = (center_y + box_height / 2.f) / img_height;
                     }
 
                     //! rest of priors
@@ -125,17 +131,35 @@ public:
                         box_width = min_size * sqrt(ar);
                         box_height = min_size / sqrt(ar);
                         //! xmin
-                        output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                        com_buf[com_idx++] = (center_x - box_width / 2.f) / img_width;
                         //! ymin
-                        output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                        com_buf[com_idx++] = (center_y - box_height / 2.f) / img_height;
                         //! xmax
-                        output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                        com_buf[com_idx++] = (center_x + box_width / 2.f) / img_width;
                         //! ymax
-                        output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                        com_buf[com_idx++] = (center_y + box_height / 2.f) / img_height;
+                    }
+
+                    for (const auto &type : param.order) {
+                        if (type == PRIOR_MIN) {
+                            memcpy(output_host + idx, min_buf, sizeof(float) * min_idx);
+                            idx += min_idx;
+                        } else if (type == PRIOR_MAX) {
+                            memcpy(output_host + idx, max_buf, sizeof(float) * max_idx);
+                            idx += max_idx;
+                        } else if (type == PRIOR_COM) {
+                            memcpy(output_host + idx, com_buf, sizeof(float) * com_idx);
+                            idx += com_idx;
+                        }
                     }
                 }
             }
         }
+
+        fast_free(min_buf);
+        fast_free(max_buf);
+        fast_free(com_buf);
+
         //! clip the prior's coordidate such that it is within [0, 1]
         if (param.is_clip) {
             for (int d = 0; d < channel_size; ++d) {
diff --git a/saber/funcs/impl/arm/saber_slice.h b/saber/funcs/impl/arm/saber_slice.h
index c031ada..5108152 100644
--- a/saber/funcs/impl/arm/saber_slice.h
+++ b/saber/funcs/impl/arm/saber_slice.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -60,7 +59,7 @@ public:
     virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
                                std::vector<DataTensor_out*>& outputs,
                                SliceParam<OpTensor> &param, Context<ARM> &ctx) override {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         _slice_num = inputs[0]->count_valid(0, param.axis);
         _slice_size = inputs[0]->count_valid(param.axis + 1, inputs[0]->dims());
        return SaberSuccess;
diff --git a/saber/funcs/impl/arm/saber_softmax.cpp b/saber/funcs/impl/arm/saber_softmax.cpp
index 878e40d..7b5e8e7 100644
--- a/saber/funcs/impl/arm/saber_softmax.cpp
+++ b/saber/funcs/impl/arm/saber_softmax.cpp
@@ -130,13 +130,17 @@ LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(\
     std::vector<DataTensor_out*>& outputs, \
     SoftmaxParam<OpTensor> &param) {
 
+    //LOG(INFO) << "in arm saber softmax";
+
     float* dout = (float*)outputs[0]->mutable_data();
     const float* din = (float*)inputs[0]->data();
 
     if (this->_inner_num == 1) {
+        //LOG(INFO) << "softmax inner1 axis size: " << _axis_size;
         softmax_inner1(din, dout, _outer_num, _axis_size);
     } else {
         int compute_size = inputs[0]->valid_size() / _axis_size;
+        //LOG(INFO) << "softmax compute size: " << compute_size;
         softmax_basic(din, dout, _axis_size, _inner_num, _outer_num, compute_size);
     }
 
diff --git a/saber/funcs/impl/arm/saber_softmax.h b/saber/funcs/impl/arm/saber_softmax.h
index 1c72c96..6d3e33c 100755
--- a/saber/funcs/impl/arm/saber_softmax.h
+++ b/saber/funcs/impl/arm/saber_softmax.h
@@ -1,16 +1,16 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_SOFTMAX_H
 #define ANAKIN_SABER_FUNCS_IMPL_ARM_SABER_SOFTMAX_H
@@ -51,8 +51,6 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
                              std::vector<DataTensor_out*>& outputs,
                              SoftmaxParam<OpTensor> &param, Context<ARM> &ctx) override {
-        // get context
-        this->_ctx = ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -60,6 +58,7 @@ public:
                                std::vector<DataTensor_out*>& outputs,
                                SoftmaxParam<OpTensor> &param, Context<ARM> &ctx) override {
 
+        this->_ctx = &ctx;
         Shape shape_in = inputs[0]->valid_shape();
         Shape shape_out = outputs[0]->valid_shape();
         _outer_num = inputs[0]->count_valid(0, param.axis);
diff --git a/saber/funcs/impl/cuda/base/CMakeLists.txt b/saber/funcs/impl/cuda/base/CMakeLists.txt
index 1f66c81..933efdd 100644
--- a/saber/funcs/impl/cuda/base/CMakeLists.txt
+++ b/saber/funcs/impl/cuda/base/CMakeLists.txt
@@ -1,9 +1,16 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     CMakeLists files in the saber  subdirectory for nvidia gpu code
-# @auther   cuichaowen
-# @date     2017-11-29
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 if(USE_CUDA)
     anakin_fetch_files_with_suffix(${CUDA_BASE_CODE_ROOT}/cuda_c "cu" ANAKIN_SABER_CUDA_C_SRC)
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_activation.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_activation.cu
index 2b72b2a..9f2c42b 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_activation.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_activation.cu
@@ -9,28 +9,22 @@ __global__ void ker_relu_fwd(Dtype * out_data,
                    const Dtype* in_data, const int count, Dtype neg_slop,
                    int in_n, int in_c, int in_h, int in_w,
                    int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
-                   int out_n, int out_c, int out_h, int out_w,
                    int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
     CUDA_KERNEL_LOOP(tid, count){
-        int read_w =  tid % in_w;
-        int read_h = (tid / (in_w)) % in_h;
-        int read_c = (tid / (in_h * in_w)) % in_c;
-        int read_n = (tid / (in_c * in_h * in_w)) % in_n;
-
-        int write_w =  tid % out_w;
-        int write_h = (tid / (out_w)) % out_h;
-        int write_c = (tid / (out_h * out_w)) % out_c;
-        int write_n = (tid / (out_c * out_h * out_w)) % out_n;
-
-        int in_idx = read_n * in_n_stride
-                   + read_c * in_c_stride
-                   + read_h * in_h_stride
-                   + read_w * in_w_stride;
-
-        int out_idx = write_n * out_n_stride
-                     + write_c * out_c_stride
-                     + write_h * out_h_stride
-                     + write_w * out_w_stride;
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
+
+        int in_idx = n * in_n_stride
+                   + c * in_c_stride
+                   + h * in_h_stride
+                   + w * in_w_stride;
+
+        int out_idx =  n * out_n_stride
+                     + c * out_c_stride
+                     + h * out_h_stride
+                     + w * out_w_stride;
 
         Dtype in_var = in_data[in_idx];
         out_data[out_idx] = in_var > Dtype(0) ? in_var : in_var * neg_slop;
@@ -42,29 +36,23 @@ __global__ void ker_sigmoid_fwd(Dtype * out_data,
                              const Dtype* in_data, const int count,
                              int in_n, int in_c, int in_h, int in_w,
                              int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
-                             int out_n, int out_c, int out_h, int out_w,
                              int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
 
     CUDA_KERNEL_LOOP(tid, count){
-        int read_w =  tid % in_w;
-        int read_h = (tid / (in_w)) % in_h;
-        int read_c = (tid / (in_h * in_w)) % in_c;
-        int read_n = (tid / (in_c * in_h * in_w)) % in_n;
-
-        int write_w =  tid % out_w;
-        int write_h = (tid / (out_w)) % out_h;
-        int write_c = (tid / (out_h * out_w)) % out_c;
-        int write_n = (tid / (out_c * out_h * out_w)) % out_n;
-
-        int in_idx = read_n * in_n_stride
-                     + read_c * in_c_stride
-                     + read_h * in_h_stride
-                     + read_w * in_w_stride;
-
-        int out_idx = write_n * out_n_stride
-                      + write_c * out_c_stride
-                      + write_h * out_h_stride
-                      + write_w * out_w_stride;
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
+
+        int in_idx =   n * in_n_stride
+                     + c * in_c_stride
+                     + h * in_h_stride
+                     + w * in_w_stride;
+
+        int out_idx =   n * out_n_stride
+                      + c * out_c_stride
+                      + h * out_h_stride
+                      + w * out_w_stride;
 
         Dtype in_var = in_data[in_idx];
         out_data[out_idx] = Dtype( Dtype(1) / (Dtype(1)+ expf(-in_var)));
@@ -77,29 +65,23 @@ __global__ void ker_tanh_fwd(Dtype * out_data,
                                 const Dtype* in_data, const int count,
                                 int in_n, int in_c, int in_h, int in_w,
                                 int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
-                                int out_n, int out_c, int out_h, int out_w,
                                 int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
 
     CUDA_KERNEL_LOOP(tid, count){
-        int read_w =  tid % in_w;
-        int read_h = (tid / (in_w)) % in_h;
-        int read_c = (tid / (in_h * in_w)) % in_c;
-        int read_n = (tid / (in_c * in_h * in_w)) % in_n;
-
-        int write_w =  tid % out_w;
-        int write_h = (tid / (out_w)) % out_h;
-        int write_c = (tid / (out_h * out_w)) % out_c;
-        int write_n = (tid / (out_c * out_h * out_w)) % out_n;
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
 
-        int in_idx = read_n * in_n_stride
-                     + read_c * in_c_stride
-                     + read_h * in_h_stride
-                     + read_w * in_w_stride;
+        int in_idx =   n * in_n_stride
+                     + c * in_c_stride
+                     + h * in_h_stride
+                     + w * in_w_stride;
 
-        int out_idx = write_n * out_n_stride
-                      + write_c * out_c_stride
-                      + write_h * out_h_stride
-                      + write_w * out_w_stride;
+        int out_idx =   n * out_n_stride
+                      + c * out_c_stride
+                      + h * out_h_stride
+                      + w * out_w_stride;
 
 
         Dtype in_var = in_data[in_idx];
@@ -112,28 +94,22 @@ __global__ void ker_clipped_relu_fwd(Dtype * out_data,
                              const Dtype* in_data, const int count, Dtype clipped_threadhold,
                              int in_n, int in_c, int in_h, int in_w,
                              int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
-                             int out_n, int out_c, int out_h, int out_w,
                              int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
     CUDA_KERNEL_LOOP(tid, count){
-        int read_w =  tid % in_w;
-        int read_h = (tid / (in_w)) % in_h;
-        int read_c = (tid / (in_h * in_w)) % in_c;
-        int read_n = (tid / (in_c * in_h * in_w)) % in_n;
-
-        int write_w =  tid % out_w;
-        int write_h = (tid / (out_w)) % out_h;
-        int write_c = (tid / (out_h * out_w)) % out_c;
-        int write_n = (tid / (out_c * out_h * out_w)) % out_n;
-
-        int in_idx = read_n * in_n_stride
-                     + read_c * in_c_stride
-                     + read_h * in_h_stride
-                     + read_w * in_w_stride;
-
-        int out_idx = write_n * out_n_stride
-                      + write_c * out_c_stride
-                      + write_h * out_h_stride
-                      + write_w * out_w_stride;
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
+
+        int in_idx =   n * in_n_stride
+                     + c * in_c_stride
+                     + h * in_h_stride
+                     + w * in_w_stride;
+
+        int out_idx =   n * out_n_stride
+                      + c * out_c_stride
+                      + h * out_h_stride
+                      + w * out_w_stride;
 
         Dtype in_var = in_data[in_idx];
         in_var = in_var > 0 ? in_var : 0;
@@ -145,34 +121,60 @@ __global__ void ker_elu_fwd(Dtype * out_data,
                                      const Dtype* in_data, const int count, Dtype coef,
                                      int in_n, int in_c, int in_h, int in_w,
                                      int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
-                                     int out_n, int out_c, int out_h, int out_w,
                                      int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
     CUDA_KERNEL_LOOP(tid, count){
-        int read_w =  tid % in_w;
-        int read_h = (tid / (in_w)) % in_h;
-        int read_c = (tid / (in_h * in_w)) % in_c;
-        int read_n = (tid / (in_c * in_h * in_w)) % in_n;
-
-        int write_w =  tid % out_w;
-        int write_h = (tid / (out_w)) % out_h;
-        int write_c = (tid / (out_h * out_w)) % out_c;
-        int write_n = (tid / (out_c * out_h * out_w)) % out_n;
-
-        int in_idx = read_n * in_n_stride
-                     + read_c * in_c_stride
-                     + read_h * in_h_stride
-                     + read_w * in_w_stride;
-
-        int out_idx = write_n * out_n_stride
-                      + write_c * out_c_stride
-                      + write_h * out_h_stride
-                      + write_w * out_w_stride;
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
+
+        int in_idx =   n * in_n_stride
+                     + c * in_c_stride
+                     + h * in_h_stride
+                     + w * in_w_stride;
+
+        int out_idx =   n * out_n_stride
+                      + c * out_c_stride
+                      + h * out_h_stride
+                      + w * out_w_stride;
 
         Dtype in_var = in_data[in_idx];
         out_data[out_idx] = in_var > 0 ? in_var : coef * (expf(in_var)-1);
     }
 }
 
+template<typename Dtype>
+__global__ void ker_prelu_fwd(Dtype * out_data,
+                              const Dtype* in_data, const int count,
+                              const Dtype* slope, bool is_channel_shared,
+                              int in_n, int in_c, int in_h, int in_w,
+                              int in_n_stride, int in_c_stride, int in_h_stride, int in_w_stride,
+                              int out_n_stride, int out_c_stride, int out_h_stride, int out_w_stride) {
+    CUDA_KERNEL_LOOP(tid, count){
+        int w =  tid % in_w;
+        int h = (tid / (in_w)) % in_h;
+        int c = (tid / (in_h * in_w)) % in_c;
+        int n = (tid / (in_c * in_h * in_w)) % in_n;
+
+        int in_idx =   n * in_n_stride
+                     + c * in_c_stride
+                     + h * in_h_stride
+                     + w * in_w_stride;
+
+        int out_idx =   n * out_n_stride
+                      + c * out_c_stride
+                      + h * out_h_stride
+                      + w * out_w_stride;
+
+        Dtype in_var = in_data[in_idx];
+        if (is_channel_shared) {
+            out_data[out_idx] = in_var > 0 ? in_var : slope[0] * in_var;
+        } else {
+            out_data[out_idx] = in_var > 0 ? in_var : slope[c] * in_var;
+        }
+    }
+}
+
 template <>
 SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
         NCHW, NCHW, NCHW>::dispatch( \
@@ -190,7 +192,7 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
     OutDataType *out_data = (OutDataType*)outputs[0]->mutable_data();
 
     const int count = inputs[0]->valid_size();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
     InDataType negative_slope = param.negative_slope;
     InDataType coef = param.coef;
@@ -202,7 +204,6 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
                     out_data, in_data, count, negative_slope,
                     in_shape[0], in_shape[1], in_shape[2], in_shape[3],
                     stride_in[0], stride_in[1], stride_in[2], stride_in[3],
-                    out_shape[0], out_shape[1], out_shape[2], out_shape[3],
                     stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
             break;
 
@@ -213,7 +214,6 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
                     out_data, in_data, count,
                     in_shape[0], in_shape[1], in_shape[2], in_shape[3],
                     stride_in[0], stride_in[1], stride_in[2], stride_in[3],
-                    out_shape[0], out_shape[1], out_shape[2], out_shape[3],
                     stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
             break;
 
@@ -224,7 +224,6 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
                     out_data, in_data, count,
                     in_shape[0], in_shape[1], in_shape[2], in_shape[3],
                     stride_in[0], stride_in[1], stride_in[2], stride_in[3],
-                    out_shape[0], out_shape[1], out_shape[2], out_shape[3],
                     stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
             break;
 
@@ -235,7 +234,6 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
                     out_data, in_data, count, coef,
                     in_shape[0], in_shape[1], in_shape[2], in_shape[3],
                     stride_in[0], stride_in[1], stride_in[2], stride_in[3],
-                    out_shape[0], out_shape[1], out_shape[2], out_shape[3],
                     stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
             break;
 
@@ -246,14 +244,22 @@ SaberStatus SaberActivation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
                     out_data, in_data, count, coef,
                     in_shape[0], in_shape[1], in_shape[2], in_shape[3],
                     stride_in[0], stride_in[1], stride_in[2], stride_in[3],
-                    out_shape[0], out_shape[1], out_shape[2], out_shape[3],
                     stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
             break;
+        case Active_prelu:
+            auto prelu_param  = param.prelu_param;
+            ker_prelu_fwd<InDataType>
+                    <<<CUDA_GET_BLOCKS(count), CUDA_NUM_THREADS, 0, cuda_stream>>>(
+                    out_data, in_data, count, prelu_param.slope->data(), prelu_param.channel_shared,
+                    in_shape[0], in_shape[1], in_shape[2], in_shape[3],
+                    stride_in[0], stride_in[1], stride_in[2], stride_in[3],
+                    stride_out[0], stride_out[1], stride_out[2], stride_out[3]);
+             break;
     }
 
     CUDA_POST_KERNEL_CHECK;
-        return SaberSuccess;
+    return SaberSuccess;
 }
 
 }
-}
\ No newline at end of file
+}
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_argmax.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_argmax.cu
index 77a66b1..7afb491 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_argmax.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_argmax.cu
@@ -484,8 +484,8 @@ __global__ void topk_channel(const Dtype* in_data,
     //
     const Dtype* tmp_in_data = in_data + num_id * channel * inner_dim + inner_id;
     extern  __shared__ Dtype trees[];
-    Dtype* small_heap_tree = trees + thread_id * top_k;
-    Dtype* tree_index = trees + thread_id * top_k + blockDim.x * top_k;
+    Dtype* small_heap_tree = trees + threadIdx.x * top_k;
+    Dtype* tree_index = trees + threadIdx.x * top_k + blockDim.x * top_k;
     for (int i = 0; i < top_k; i++) {
         small_heap_tree[i] = -FLT_MAX;
         tree_index[i] = -1;
@@ -494,7 +494,7 @@ __global__ void topk_channel(const Dtype* in_data,
         Dtype data = tmp_in_data[i*inner_dim];
         if (data > small_heap_tree[0]) {
              small_heap_tree[0] = data;
-             tree_index[i] = i;
+             tree_index[0] = i;
              adjust_small_heap_with_index_device(small_heap_tree, tree_index, 0, top_k);
         }  
     }
@@ -766,182 +766,6 @@ __global__ void topk_heap_shared(Dtype *out_data, int n, int inner_dim, const in
     }
 }
 
-template <typename Dtype, int blockSize>
-__global__ void topk_heap_shared_no_bank(Dtype *out_data, int n, int inner_dim, const int top_k, const bool out_max_val, const Dtype *in_data){
-    extern  __shared__ Dtype trees[];
-    const int block_id = blockIdx.x;
-    const int tid = threadIdx.x;
-    Dtype *cur_tree = trees + tid ;
-    Dtype *cur_tree_index = cur_tree + top_k * blockDim.x;
-    
-    for (int i = 0; i < top_k; i++){
-        cur_tree[i*blockDim.x] = -FLT_MAX;
-        cur_tree_index[i * blockDim.x] = -1;
-    }
-    int stride = blockDim.x;
-    
-/*build small heap for every thread in one picture*/
-    const Dtype* in = in_data + block_id * inner_dim;
-    for (int i = tid; i < inner_dim; i += blockDim.x){
-        if (in[i] > cur_tree[0]) {
-            cur_tree[0] = in[i];
-            cur_tree_index[0] = i;
-            adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-        }
-    }
-    __syncthreads();
-    if (blockSize >= 512) {
-        if (tid < 256) {
-             Dtype* next_tree = cur_tree + 256;
-             Dtype* next_tree_index = cur_tree_index + 256;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 256) {
-        if (tid < 128) {
-             Dtype* next_tree = cur_tree + 128;
-             Dtype* next_tree_index = cur_tree_index + 128;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 128) {
-        if (tid < 64) {
-             Dtype* next_tree = cur_tree + 64;
-             Dtype* next_tree_index = cur_tree_index + 64;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 64) {
-        if (tid < 32) {
-             Dtype* next_tree = cur_tree + 32;
-             Dtype* next_tree_index = cur_tree_index + 32;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 32) {
-        if (tid < 16) {
-             Dtype* next_tree = cur_tree + 16;
-             Dtype* next_tree_index = cur_tree_index + 16;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 16) {
-        if (tid < 8) {
-             Dtype* next_tree = cur_tree + 8;
-             Dtype* next_tree_index = cur_tree_index + 8;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 8) {
-        if (tid < 4) {
-            Dtype* next_tree = cur_tree + 4;
-            Dtype* next_tree_index = cur_tree_index + 4;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 4) {
-        if (tid < 2) {
-            Dtype* next_tree = cur_tree + 2;
-            Dtype* next_tree_index = cur_tree_index + 2;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (blockSize >= 2) {
-        if (tid < 1) {
-            Dtype* next_tree = cur_tree + 1;
-            Dtype* next_tree_index = cur_tree_index + 1;
-            for (int i = 0; i < top_k; i++) {
-                int off = i*stride;
-                if (next_tree[off] > cur_tree[0]) {
-                    cur_tree[0] = next_tree[off];
-                    cur_tree_index[0] = next_tree_index[off];
-                    adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-                }
-            }
-        }
-        __syncthreads();
-    }
-    if (tid == 0) {
-        int stride = out_max_val ? block_id * top_k * 2 : block_id * top_k;
-        Dtype* out =  out_data + stride;
-        for (int i = top_k - 1; i >= 0; i--) {
-            if (!out_max_val) {
-                out[i] = cur_tree_index[0];
-            } else {
-                out[i] = cur_tree[0];
-                out[i + top_k] = cur_tree_index[0];
-            }
-            cur_tree[0] = FLT_MAX;
-            cur_tree_index[0] = -1;
-            adjust_small_heap_with_index_device_stride(cur_tree, cur_tree_index, 0, top_k, stride);
-        }
-    }
-}
-
 /*
 template<DataType dataType, typename LayOutType>
 SaberStatus SaberArgmax<dataType, LayOutType>::dispatch(
@@ -960,7 +784,7 @@ SaberStatus SaberArgmax<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs,
     ArgmaxParam<OpTensor>& param) {
             
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
     const InDataType * in_data = inputs[0]->data();
     OutDataType * out_data = outputs[0]->mutable_data();
@@ -973,7 +797,7 @@ SaberStatus SaberArgmax<NV, OpDtype, inDtype, outDtype,\
         if (param.top_k == 1) {
             top1_channel<InDataType><<<CUDA_GET_BLOCKS(total_threads), CUDA_NUM_THREADS, 0, cuda_stream>>>(in_data, outer_dim, dim, inner_dim, param.out_max_val, out_data);
         } else {
-            topk_channel<InDataType><<<CUDA_GET_BLOCKS(total_threads), CUDA_NUM_THREADS, sizeof(InDataType) * CUDA_NUM_THREADS * param.top_k, cuda_stream>>>(in_data, outer_dim, dim, inner_dim, param.top_k, param.out_max_val, out_data);
+            topk_channel<InDataType><<<CUDA_GET_BLOCKS(total_threads), CUDA_NUM_THREADS, 2 * sizeof(InDataType) * CUDA_NUM_THREADS * param.top_k, cuda_stream>>>(in_data, outer_dim, dim, inner_dim, param.top_k, param.out_max_val, out_data);
         }
     } else {
         int inner_dim = inputs[0]->count(1, inputs[0]->dims());
@@ -990,8 +814,7 @@ SaberStatus SaberArgmax<NV, OpDtype, inDtype, outDtype,\
                 top1<InDataType, CUDA_NUM_THREADS><<<outer_dim, CUDA_NUM_THREADS, 0, cuda_stream>>>(_block_max_value.data(), _block_max_index.data(), outer_dim, block_num, param.out_max_val, out_data);
             }
         } else {
-             //topk_heap_shared<InDataType, CUDA_NUM_THREADS><<<outer_dim,  CUDA_NUM_THREADS, sizeof(InDataType) * CUDA_NUM_THREADS * param.top_k * 2, cuda_stream>>>(out_data, outer_dim, inner_dim, param.top_k, param.out_max_val,  in_data);
-             topk_heap_shared_no_bank<InDataType, CUDA_NUM_THREADS><<<outer_dim,  CUDA_NUM_THREADS, sizeof(InDataType) * CUDA_NUM_THREADS * param.top_k * 2, cuda_stream>>>(out_data, outer_dim, inner_dim, param.top_k, param.out_max_val,  in_data);
+             topk_heap_shared<InDataType, CUDA_NUM_THREADS><<<outer_dim,  CUDA_NUM_THREADS, sizeof(InDataType) * CUDA_NUM_THREADS * param.top_k * 2, cuda_stream>>>(out_data, outer_dim, inner_dim, param.top_k, param.out_max_val,  in_data);
         }
     }
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_axpy.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_axpy.cu
index 15fbd8f..ba3feb8 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_axpy.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_axpy.cu
@@ -26,7 +26,7 @@ SaberStatus SaberAxpy<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs,
     AxpyParam<OpTensor>& param) {
 
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     if (!(inputs[1]->valid_shape() == outputs[0]->valid_shape()) 
         || !(inputs[2]->valid_shape() == outputs[0]->valid_shape())) {
          return SaberUnKownError;
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_cast.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_cast.cu
index 6aafbc3..c9d098b 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_cast.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_cast.cu
@@ -30,7 +30,7 @@ SaberStatus SaberCast<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
     int count = outputs[0]->valid_size();
     outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_concat.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_concat.cu
index 2a19669..769e3c1 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_concat.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_concat.cu
@@ -52,7 +52,7 @@ SaberStatus SaberConcat<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs,
     ConcatParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     int input_size = inputs.size();
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_crop.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_crop.cu
index ad9a267..0a19742 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_crop.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_crop.cu
@@ -45,7 +45,7 @@ SaberStatus SaberCrop<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_ctc_align.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_ctc_align.cu
index ea620c7..bad6376 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_ctc_align.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_ctc_align.cu
@@ -44,7 +44,7 @@ SaberStatus SaberCtcAlign<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int* in_offset = _in_offset.mutable_data();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_deconv.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_deconv.cu
index 79c869f..01766ac 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_deconv.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_deconv.cu
@@ -134,7 +134,7 @@ SaberStatus SaberDeconv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
         const std::vector<DataTensor_in*>& inputs,
         std::vector<DataTensor_out*>& outputs,
         ConvParam<OpTensor>& param) {
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
     //! inputs only has one tensor
 
     const float* din = inputs[0]->data();
@@ -164,7 +164,7 @@ SaberStatus SaberDeconv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
     if (_use_k4_s2_p1) {
         const float * bias_data = (param.bias()->valid_size() > 0) ?
                                   param.bias()->data() : NULL;
-        const float *weights_data = new_weights_dev.data();
+        const float *weights_data = param.weight()->data();
         ker_deconv_implicit_gemm_k4_s2_p1_16x64(dout, din,
                                                 weights_data, bias_data,
                                                 num,
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_deconv_act.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_deconv_act.cu
index 75a2c47..7d64a37 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_deconv_act.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_deconv_act.cu
@@ -138,7 +138,7 @@ SaberStatus SaberDeconv2DAct<NV, OpDtype, inDtype, outDtype,\
     LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(const std::vector<DataTensor_in *>& inputs,
     std::vector<DataTensor_out *>& outputs,
     ConvActiveParam<OpTensor>& param) {
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
     //! inputs only has one tensor
 
     const InDataType* din = inputs[0]->data();
@@ -168,7 +168,7 @@ SaberStatus SaberDeconv2DAct<NV, OpDtype, inDtype, outDtype,\
     if (_use_k4_s2_p1) {
         const InDataType * bias_data = (param.conv_param.bias()->valid_size() > 0) ?
                                   param.conv_param.bias()->data() : NULL;
-        const OpDataType *weights_data = new_weights_dev.data();
+        const OpDataType *weights_data = param.conv_param.weight()->data();
         ker_deconv_implicit_gemm_k4_s2_p1_32x32_relu(dout, din,
                                                 weights_data, bias_data,
                                                 num,
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_deformable_conv.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_deformable_conv.cu
index 60ca9a7..a00c3fd 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_deformable_conv.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_deformable_conv.cu
@@ -133,7 +133,7 @@ SaberStatus SaberDeformableConv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT,\
     InDataType* deformable_col_buffer_data = _deform_col_buffer.mutable_data();
     const InDataType* deform_col_buffer_data_const = _deform_col_buffer.data();
 
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
     for (int n = 0; n < inputs[0]->num(); ++n) {
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_detection_output.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_detection_output.cu
index af08e4d..95b33d0 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_detection_output.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_detection_output.cu
@@ -40,7 +40,7 @@ SaberStatus SaberDetectionOutput<NV, OpDtype, inDtype, outDtype,\
 
     //typedef typename DataTensor_in::Dtype InDataType;
     //typedef typename 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     DataTensor_in* t_loc = inputs[0];
     DataTensor_in* t_conf = inputs[1];
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise.cu
index b4f2e28..45ab4f3 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise.cu
@@ -51,7 +51,7 @@ SaberStatus SaberEltwise<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::di
     float *out_data = outputs[0]->mutable_data();
     const float *in_data_a = inputs[0]->data();
 	const float *in_data_b = inputs[1]->data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     switch(param.operation){
 	case Eltwise_prod:
 		ker_elt_production<InDataType>
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise_act.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise_act.cu
index 3a770c3..876f0a5 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise_act.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_eltwise_act.cu
@@ -21,7 +21,7 @@ SaberStatus SaberEltwiseActive<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCH
     float * out_data = outputs[0]->mutable_data();
     const float *in_data_a = inputs[0]->data();
     const float *in_data_b = inputs[1]->data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     switch(param.eltwise_param.operation){
         case Eltwise_prod:
             LOG(FATAL)<<"NOT IMPLEMENT yet!!";
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_embedding.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_embedding.cu
index 529c386..1279633 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_embedding.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_embedding.cu
@@ -38,7 +38,7 @@ SaberStatus SaberEmbedding<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
     OutDataType *out_data = (OutDataType*)outputs[0]->mutable_data();
 
     const int count = outputs[0]->valid_size();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
     ker_embedding_fwd<InDataType, OpDataType, OutDataType>
             <<<CUDA_GET_BLOCKS(count), CUDA_NUM_THREADS, 0, cuda_stream>>>(
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_fc.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_fc.cu
index cef5f8f..64846e2 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_fc.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_fc.cu
@@ -25,7 +25,7 @@ SaberStatus SaberFc<NV, OpDtype, inDtype, outDtype, \
             std::vector<DataTensor_out *>& outputs,
             FcParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     const InDataType* din = inputs[0]->data();
     OutDataType* dout = outputs[0]->mutable_data();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_gru.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_gru.cu
index 294b9cc..ac6495d 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_gru.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_gru.cu
@@ -1,17 +1,19 @@
 #include "saber/funcs/impl/cuda/saber_gru.h"
 #include "saber/core/tensor_op.h"
-#include "cuda_fp16.h"
+
 namespace anakin {
 
 namespace saber {
 
 ////TODO:can try record vector in shared
+
 template <typename Dtype>
 __global__ void trans_map2in(Dtype* output, const Dtype* input, const int* map, int count,
                              int lastdim) {
     CUDA_KERNEL_LE(tid, count) {
         int seq = tid / lastdim;
         output[tid] = input[map[seq] * lastdim + tid % lastdim];
+//        printf("in %d = %f\n",tid,output[tid]);
     }
 }
 
@@ -21,9 +23,46 @@ __global__ void trans_map2out(Dtype* output, const Dtype* input, const int* map,
     CUDA_KERNEL_LE(tid, count) {
         int seq = tid / lastdim;
         output[map[seq]*lastdim + tid % lastdim] = input[tid];
+//        printf("out %d = %f\n",map[seq]*lastdim + tid % lastdim,output[map[seq]*lastdim + tid % lastdim]);
+    }
+}
+
+template <typename Dtype>
+void trans_map2out_cfunc(const Dtype*  input, Dtype* output, int word_size,int seq_sum, cudaStream_t stream,int *dev_map_vec) {
+    int count = seq_sum * word_size;
+    int block_dim = count;
+    int grid_dim = 1;
+
+    if (count > 1024) {
+        block_dim = 256;
+        grid_dim = (count + block_dim - 1) / block_dim;
     }
+
+    trans_map2out << < grid_dim, block_dim, 0, stream >> > (output, input, dev_map_vec,
+            count, word_size);
+
+//    cudaDeviceSynchronize();
 }
 
+template <typename Dtype>
+void trans_map2in_cfunc(const Dtype*  input, Dtype* output, int hidden_size,int seq_sum, cudaStream_t stream,int *dev_map_vec) {
+    int count = seq_sum * hidden_size;
+    int block_dim = count;
+    int grid_dim = 1;
+
+    if (count > 1024) {
+        block_dim = 256;
+        grid_dim = (count + block_dim - 1) / block_dim;
+    }
+
+    trans_map2in << < grid_dim, block_dim, 0, stream >> > (output, input, dev_map_vec,
+            count, hidden_size);
+//    cudaDeviceSynchronize();
+//    exit(0);
+}
+
+
+
 template <>
 void SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::seq2hw(\
         std::vector<DataTensor_out*> outputs, std::vector<DataTensor_in*> inputs,
@@ -51,7 +90,7 @@ void SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::seq2hw(\
     //source is sequence id in seq target is hw id in seq,map is source to target ptr offset
     int seq_sum = offset_vec[batch_size];
     CUDA_CHECK(cudaMemcpyAsync(_temp_map_dev.mutable_data(), _temp_map_host.data(), sizeof(int)*seq_sum,
-                               cudaMemcpyHostToDevice, _ctx.get_compute_stream()));
+                               cudaMemcpyHostToDevice, _ctx->get_compute_stream()));
     int count=seq_sum * hidden_size;
     int block_dim=count;
     int grid_dim=1;
@@ -59,7 +98,7 @@ void SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::seq2hw(\
         block_dim=256;
         grid_dim=(count+block_dim-1)/block_dim;
     }
-    trans_map2in <<< grid_dim, block_dim, 0, _ctx.get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
+    trans_map2in <<< grid_dim, block_dim, 0, _ctx->get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
             count, hidden_size);
 
 //    trans_map2in_old <<< 4, 128, 0, _ctx.get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
@@ -67,6 +106,7 @@ void SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::seq2hw(\
 
 }
 
+
 //TODO:gem by self, flatten by time, padding by nothing (zhangs)
 template <>
 const float* SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::hw2seq(\
@@ -128,7 +168,7 @@ const float* SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::hw2se
     }
 
     CUDA_CHECK(cudaMemcpyAsync(_temp_map_dev.mutable_data(), _temp_map_host.data(), sizeof(int)*seq_sum,
-                               cudaMemcpyHostToDevice, _ctx.get_compute_stream()));
+                               cudaMemcpyHostToDevice, _ctx->get_compute_stream()));
     int count=seq_sum * wordsize;
     int block_dim=count;
     int grid_dim=1;
@@ -136,7 +176,7 @@ const float* SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::hw2se
         block_dim=256;
         grid_dim=(count+block_dim-1)/block_dim;
     }
-    trans_map2out <<< grid_dim, block_dim, 0, _ctx.get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
+    trans_map2out <<< grid_dim, block_dim, 0, _ctx->get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
             count, wordsize);
 
 //    trans_map2out_old <<< 4, 128, 0, _ctx.get_compute_stream()>>>(target, origin, _temp_map_dev.data(),
@@ -150,32 +190,52 @@ const float* SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::hw2se
 #define SIGMOID_THRESHOLD_MAX_PADDLE 13.0
 #define EXP_MAX_INPUT_PADDLE 40.0
 
-template <typename T>
-inline  static __device__ T identity(const T a) {
+template <typename Dtype>
+ static  __device__ Dtype invalidact(Dtype a) {
+            printf("invalid act\n");
+}
+
+template <typename Dtype>
+ static  __device__ Dtype sigmoid(const Dtype a) {
+    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-a));
+}
+
+
+template <typename Dtype>
+ static __device__ Dtype tanh(const Dtype a) {
+    Dtype tmp = -2.0 * a;
+    return (2.0 / (1.0 + expf(tmp))) - 1.0;
+}
+
+template <typename Dtype>
+  static __device__ Dtype identity(const Dtype a) {
     return a;
 }
 
-template <typename T>
-inline static __device__ T relu(const T a) {
-    return a > static_cast<T>(0.0) ? a : static_cast<T>(0.0);
+template <typename Dtype>
+ static __device__ Dtype relu(const Dtype a) {
+    return a > static_cast<Dtype>(0.0) ? a : static_cast<Dtype>(0.0);
 }
 
+template <typename Dtype>
+ static __device__ Dtype sigmoid_fluid(const Dtype a) {
+    const Dtype min = SIGMOID_THRESHOLD_MIN_PADDLE;
+    const Dtype max = SIGMOID_THRESHOLD_MAX_PADDLE;
+    Dtype tmp = (a < min) ? min : ((a > max) ? max : a);
 
-template <typename T>
-inline static __device__ T sigmoid_paddle(const T a) {
-    const T min = SIGMOID_THRESHOLD_MIN_PADDLE;
-    const T max = SIGMOID_THRESHOLD_MAX_PADDLE;
-    T tmp = (a < min) ? min : ((a > max) ? max : a);
-    return static_cast<T>(1.0) / (static_cast<T>(1.0) + exp(-tmp));
+    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-tmp));
 }
 
-template <typename T>
-inline static __device__ T tanh_paddle(const T a) {
-    T tmp = -2.0 * a;
+template <typename Dtype>
+ static __device__ Dtype tanh_fluid(const Dtype a) {
+    Dtype tmp = -2.0 * a;
     tmp = (tmp > EXP_MAX_INPUT_PADDLE) ? EXP_MAX_INPUT_PADDLE : tmp;
-    return (2.0 / (1.0 + exp(tmp))) - 1.0;
+    return (2.0 / (1.0 + expf(tmp))) - 1.0;
 }
 
+static float (*act_funcs_cu[])(float)= {&invalidact, &sigmoid, &relu, &tanh, &invalidact, \
+                                & invalidact, &identity, &sigmoid_fluid, &tanh_fluid};
+
 static void anakin_NV_gemm(cublasHandle_t handle, const bool TransA,
                            const bool TransB, const int M, const int N, const int K,
                            const float alpha, const float* A, const float* B, const float beta,
@@ -191,63 +251,6 @@ static void anakin_NV_gemm(cublasHandle_t handle, const bool TransA,
                              N, M, K, &alpha, B, ldb, A, lda, &beta, C, N));
 }
 
-/**
- * gridDim=batchsize
- * @tparam Dtype
- * @param w_x_r
- * @param w_h_r
- * @param br
- * @param hidden_size
- * @param output_r
- * @param w_x_z
- * @param w_h_z
- * @param bz
- * @param output_z
- */
-template <typename Dtype>
-__global__ void cal_reset_update(Dtype* w_x_r, Dtype* w_h_r, const Dtype* b_r,
-                                 const int hidden_size, Dtype* output_r,
-                                 Dtype* w_x_z, Dtype* w_h_z, const Dtype* b_z, Dtype* output_z) {
-    int w_base_index = blockIdx.x * hidden_size * 3;
-    int h_base_index = blockIdx.x * hidden_size;
-    Dtype* in_w_x_r = w_x_r + w_base_index;
-    Dtype* in_w_h_r = w_h_r + w_base_index;
-    Dtype* in_w_x_z = w_x_z + w_base_index;
-    Dtype* in_w_h_z = w_h_z + w_base_index;
-    Dtype* out_output_r = output_r + h_base_index;
-    Dtype* out_output_z = output_z + h_base_index;
-
-    for (int index = threadIdx.x; index < hidden_size; index += blockDim.x) {
-        Dtype before_act_r = in_w_x_r[index] + in_w_h_r[index] + b_r[index];
-        out_output_r[index] = Dtype(Dtype(1) / (Dtype(1) + expf(-before_act_r)));
-        Dtype before_act_z = in_w_x_z[index] + in_w_h_z[index] + b_z[index];
-        out_output_z[index] = Dtype(Dtype(1) / (Dtype(1) + expf(-before_act_z)));
-
-    }
-}
-
-template <typename Dtype>
-__global__ void cal_final(Dtype* w_x_o, Dtype* w_h_o, Dtype* reset, const Dtype* b_o,
-                          const int hidden_size, Dtype* update, Dtype* output, Dtype* hidden_pre) {
-    int w_base_index = blockIdx.x * hidden_size * 3;
-    int h_base_index = blockIdx.x * hidden_size;
-
-    Dtype* in_w_x_o = w_x_o + w_base_index;
-    Dtype* in_w_h_o = w_h_o + w_base_index;
-    Dtype* in_hidden_pre = hidden_pre + h_base_index;
-    Dtype* in_update = update + h_base_index;
-    Dtype* in_reset = reset + h_base_index;
-    Dtype* out_output = output + h_base_index;
-
-    for (int index = threadIdx.x; index < hidden_size; index += blockDim.x) {
-        Dtype before_act_h = in_w_x_o[index] + in_w_h_o[index] * in_reset[index]
-                             + b_o[index];
-        Dtype acted = tanhf(before_act_h);
-        Dtype update_t = in_update[index];
-        out_output[index] = (1 - update_t) * acted + update_t* in_hidden_pre[index];
-    }
-}
-
 template <typename Dtype>
 __global__ void cal_one_kernel_paddlesigmoid_tanh_cudnn_formula(Dtype* w_x_r, Dtype* w_x_z,
         Dtype* w_x_o,
@@ -308,237 +311,57 @@ __global__ void cal_one_kernel_sigmoid_tanh_modi_cudnn_formula(Dtype* w_x_r, Dty
     }
 }
 
-template <typename Dtype>
-__global__ void cal_one_kernel_paddlesigmoid_relu_paddle_formula(Dtype* w_x_r, Dtype* w_x_z,
-        Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, const Dtype* w_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre) {
-    int index = threadIdx.x;
-
-    if (index > hidden_size) {
-        return;
-    }
-
-    int w_base_index = blockIdx.x * hidden_size * 3 + index;
-    int u_base_index = blockIdx.x * hidden_size * 2 + index;
-    int h_base_index = blockIdx.x * hidden_size + index;
-    extern __shared__ Dtype shared_hidden_pre[];
-    Dtype hidden_pre_value = hidden_pre[h_base_index];
-    Dtype before_act_r = w_x_r[w_base_index] + w_h_r[u_base_index] + b_r[index];
-    Dtype act_r = sigmoid_paddle(before_act_r);
-    shared_hidden_pre[index] = hidden_pre_value * act_r;
-    Dtype before_act_z = w_x_z[w_base_index] + w_h_z[u_base_index] + b_z[index];
-    Dtype act_z = sigmoid_paddle(before_act_z);
-    Dtype w_h_o = static_cast<Dtype>(0.0);
-    int k_index = index;
-    __syncthreads();
-
-    for (int w_index = 0; w_index < hidden_size; ++w_index) {
-        w_h_o += shared_hidden_pre[w_index] * w_o[k_index];
-        k_index += hidden_size;
-    }
-
-    Dtype before_act_h = w_x_o[w_base_index] + w_h_o
-                         + b_o[index];
-    Dtype acted = relu(before_act_h);
-    output[h_base_index] = (static_cast<Dtype>(1.0) - act_z) * hidden_pre_value + act_z * acted;
-}
-
-template <typename Dtype>
-__global__ void cal_one_kernel_sigmoid_tanh_paddle_formula(Dtype* w_x_r, Dtype* w_x_z, Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, const Dtype* w_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre) {
-    int index = threadIdx.x;
-
-    if (index > hidden_size) {
-        return;
-    }
-
-    int w_base_index = blockIdx.x * hidden_size * 3 + index;
-    int u_base_index = blockIdx.x * hidden_size * 2 + index;
-    int h_base_index = blockIdx.x * hidden_size + index;
-    extern __shared__ Dtype shared_hidden_pre[];
-    Dtype hidden_pre_value = hidden_pre[h_base_index];
-    Dtype before_act_r = w_x_r[w_base_index] + w_h_r[u_base_index] + b_r[index];
-
-    Dtype act_r = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_r));
-//    printf("%d %f=[%f , %f ,%f]\n",index,act_r,w_x_r[w_base_index],w_h_r[u_base_index],b_r[index]);
-    shared_hidden_pre[index] = hidden_pre_value * act_r;
-    Dtype before_act_z = w_x_z[w_base_index] + w_h_z[u_base_index] + b_z[index];
-    Dtype act_z = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_z));
-    Dtype w_h_o = static_cast<Dtype>(0.0);
-    int k_index = index;
-    __syncthreads();
-
-    for (int w_index = 0; w_index < hidden_size; ++w_index) {
-        w_h_o += shared_hidden_pre[w_index] * w_o[k_index];
-        k_index += hidden_size;
-    }
-
-    Dtype before_act_h = w_x_o[w_base_index] + w_h_o
-                         + b_o[index];
-    Dtype acted = tanhf(before_act_h);
-    output[h_base_index] = (static_cast<Dtype>(1.0) - act_z) * hidden_pre_value + act_z * acted;
-//    printf("output %d = %f\n",index,output[h_base_index]);
-}
-
-
-template <typename Dtype>
-__global__ void cal_one_kernel_sigmoid_tanh(Dtype* w_x_r, Dtype* w_x_z, Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, Dtype* w_h_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre) {
-    int w_base_index = blockIdx.x * hidden_size * 3;
-    int h_base_index = blockIdx.x * hidden_size;
-    Dtype* in_w_x_r = w_x_r + w_base_index;
-    Dtype* in_w_h_r = w_h_r + w_base_index;
-    Dtype* in_w_x_z = w_x_z + w_base_index;
-    Dtype* in_w_h_z = w_h_z + w_base_index;
-    Dtype* in_w_x_o = w_x_o + w_base_index;
-    Dtype* in_w_h_o = w_h_o + w_base_index;
-    const Dtype* in_hidden_pre = hidden_pre + h_base_index;
-    Dtype* out_output = output + h_base_index;
 
-    for (int index = threadIdx.x; index < hidden_size; index += blockDim.x) {
-        Dtype before_act_r = in_w_x_r[index] + in_w_h_r[index] + b_r[index];
-        Dtype act_r = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_r));
-        Dtype before_act_z = in_w_x_z[index] + in_w_h_z[index] + b_z[index];
-        Dtype act_z = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_z));
-        Dtype before_act_h = in_w_x_o[index] + in_w_h_o[index] * act_r
-                             + b_o[index];
-        Dtype acted = tanhf(before_act_h);
-        out_output[index] = (static_cast<Dtype>(1.0) - act_z) * acted + act_z * in_hidden_pre[index];
-    }
+#define CAL_KERNEL_DEFINE(GATACTNAME)\
+template <typename Dtype>\
+__global__ void cal_reset_kernel##GATACTNAME(Dtype* w_x_r,Dtype* w_h_r,const Dtype* b_r,int hidden_size, Dtype* output, const Dtype* hidden_pre) {\
+    int index = threadIdx.x;\
+    if (index > hidden_size) {\
+        return;\
+    }\
+    int w_base_index = blockIdx.x * hidden_size * 3 + index;\
+    int u_base_index = blockIdx.x * hidden_size * 2 + index;\
+    int h_base_index = blockIdx.x * hidden_size + index;\
+    Dtype hidden_pre_value = hidden_pre[h_base_index];\
+    Dtype before_act_r = w_x_r[w_base_index] + w_h_r[u_base_index] + b_r[index];\
+    Dtype act_r = GATACTNAME(before_act_r);\
+    output[h_base_index] = hidden_pre_value * act_r;\
+};
+
+
+#define FINAL_KERNEL_DEFINE(GATACTNAME,OUTACTNAME)\
+template <typename Dtype>\
+__global__ void cal_final_kernel##GATACTNAME##OUTACTNAME( Dtype* w_x_z, Dtype* w_x_o,Dtype* w_h_z,const Dtype* b_z, const Dtype* b_o,\
+        int hidden_size, Dtype* output, const Dtype* hidden_pre,const Dtype* w_h_o) {\
+    int index = threadIdx.x;\
+    if (index > hidden_size) {\
+        return;\
+    }\
+\
+    int w_base_index = blockIdx.x * hidden_size * 3 + index;\
+    int u_base_index = blockIdx.x * hidden_size * 2 + index;\
+    int h_base_index = blockIdx.x * hidden_size + index;\
+    Dtype hidden_pre_value = hidden_pre[h_base_index];\
+    Dtype before_act_z = w_x_z[w_base_index] + w_h_z[u_base_index] + b_z[index];\
+    Dtype act_z =  GATACTNAME(before_act_z);\
+    Dtype before_act_h = w_x_o[w_base_index] + w_h_o[h_base_index]\
+                         + b_o[index];\
+    Dtype acted = OUTACTNAME(before_act_h);\
+\
+    output[h_base_index] = (static_cast<Dtype>(1.0) - act_z) * hidden_pre_value + act_z * acted;\
 }
 
-template <typename Dtype>
-__global__ void cal_one_kernel_sigmoid_tanh_index_modi(Dtype* w_x_r, Dtype* w_x_z, Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, Dtype* w_h_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre,
-        int seq_batch_hidden, int batch_size) {
-    int tid = blockIdx.x * blockDim.x + threadIdx.x;
+#define RESET_KERNEL_NAME(GATACTNAME) cal_reset_kernel##GATACTNAME
+#define FINAL_KERNEL_NAME(GATACTNAME,OUTACTNAME) cal_final_kernel##GATACTNAME##OUTACTNAME
 
-    if (tid >= seq_batch_hidden) {
-        return;
-    }
+CAL_KERNEL_DEFINE(sigmoid);
 
-    int batch_id = tid / hidden_size % batch_size;
-    int index = tid % hidden_size;
-    int w_base_index = batch_id * hidden_size * 3;
-    int h_base_index = batch_id * hidden_size;
-    int index_w = index + w_base_index;
-    int index_h = index + h_base_index;
+CAL_KERNEL_DEFINE(sigmoid_fluid);
 
-    {
-        Dtype before_act_r = w_x_r[index_w] + w_h_r[index_w] + b_r[index];
-        Dtype act_r = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_r));
-        Dtype before_act_z = w_x_z[index_w] + w_h_z[index_w] + b_z[index];
-        Dtype act_z = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_z));
-        Dtype before_act_h = w_x_o[index_w] + w_h_o[index_w] * act_r
-                             + b_o[index];
-        Dtype acted = tanhf(before_act_h);
-        output[index_h] = (static_cast<Dtype>(1.0) - act_z) * acted + act_z * hidden_pre[index_h];
-    }
-}
+FINAL_KERNEL_DEFINE(sigmoid_fluid,tanh_fluid);
 
-template <typename Dtype>
-__global__ void cal_one_kernel_sigmoid_tanh_index(Dtype* w_x_r, Dtype* w_x_z, Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, Dtype* w_h_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre,
-        int seq_batch_hidden, int batch_size) {
-    int tid = blockIdx.x * blockDim.x + threadIdx.x;
+FINAL_KERNEL_DEFINE(sigmoid_fluid,relu);
 
-    if (tid >= seq_batch_hidden) {
-        return;
-    }
-
-    int batch_id = tid / hidden_size % batch_size;
-    int index = tid % hidden_size;
-    int w_base_index = batch_id * hidden_size * 3;
-    int h_base_index = batch_id * hidden_size;
-    Dtype* in_w_x_r = w_x_r + w_base_index;
-    Dtype* in_w_h_r = w_h_r + w_base_index;
-    Dtype* in_w_x_z = w_x_z + w_base_index;
-    Dtype* in_w_h_z = w_h_z + w_base_index;
-    Dtype* in_w_x_o = w_x_o + w_base_index;
-    Dtype* in_w_h_o = w_h_o + w_base_index;
-    const Dtype* in_hidden_pre = hidden_pre + h_base_index;
-    Dtype* out_output = output + h_base_index;
-    {
-        Dtype before_act_r = in_w_x_r[index] + in_w_h_r[index] + b_r[index];
-        Dtype act_r = Dtype(Dtype(1) / (Dtype(1) + expf(-before_act_r)));
-        Dtype before_act_z = in_w_x_z[index] + in_w_h_z[index] + b_z[index];
-        Dtype act_z = Dtype(Dtype(1) / (Dtype(1) + expf(-before_act_z)));
-        Dtype before_act_h = in_w_x_o[index] + in_w_h_o[index] * act_r
-                             + b_o[index];
-        Dtype acted = tanhf(before_act_h);
-        out_output[index] = (1 - act_z) * acted + act_z * in_hidden_pre[index];
-    }
-}
-template <typename Dtype>
-__global__ void cal_one_kernel_paddlesigmoid_relu_cudnn_formula(Dtype* w_x_r, Dtype* w_x_z,
-        Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, Dtype* w_h_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre) {
-    int w_base_index = blockIdx.x * hidden_size * 3;
-    int h_base_index = blockIdx.x * hidden_size;
-    Dtype* in_w_x_r = w_x_r + w_base_index;
-    Dtype* in_w_h_r = w_h_r + w_base_index;
-    Dtype* in_w_x_z = w_x_z + w_base_index;
-    Dtype* in_w_h_z = w_h_z + w_base_index;
-    Dtype* in_w_x_o = w_x_o + w_base_index;
-    Dtype* in_w_h_o = w_h_o + w_base_index;
-    const Dtype* in_hidden_pre = hidden_pre + h_base_index;
-    Dtype* out_output = output + h_base_index;
-
-    for (int index = threadIdx.x; index < hidden_size; index += blockDim.x) {
-        const Dtype min = SIGMOID_THRESHOLD_MIN_PADDLE;
-        const Dtype max = SIGMOID_THRESHOLD_MAX_PADDLE;
-
-        Dtype before_act_r = in_w_x_r[index] + in_w_h_r[index] + b_r[index];
-        before_act_r = (before_act_r < min) ? min : ((before_act_r > max) ? max : before_act_r);
-        Dtype act_r = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-before_act_r));
-
-        Dtype before_act_z = in_w_x_z[index] + in_w_h_z[index] + b_z[index];
-        before_act_z = (before_act_z < min) ? min : ((before_act_z > max) ? max : before_act_z);
-        Dtype act_z = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-before_act_z));
-
-        Dtype before_act_h = in_w_x_o[index] + in_w_h_o[index] * act_r
-                             + b_o[index];
-
-        Dtype acted = before_act_h > static_cast<Dtype>(0.0) ? before_act_h : static_cast<Dtype>(0.0);
-        out_output[index] = (1 - act_z) * acted + act_z * in_hidden_pre[index];
-
-    }
-}
-
-template <typename Dtype>
-__global__ void cal_one_kernel_sigmoid_tanh_modi(Dtype* w_x_r, Dtype* w_x_z, Dtype* w_x_o,
-        Dtype* w_h_r, Dtype* w_h_z, Dtype* w_h_o,
-        const Dtype* b_r, const Dtype* b_z, const Dtype* b_o,
-        int hidden_size, Dtype* output, const Dtype* hidden_pre) {
-
-    int w_base_index = blockIdx.x * hidden_size * 3 + threadIdx.x;
-    int h_base_index = blockIdx.x * hidden_size + threadIdx.x;
-
-    for (int index = threadIdx.x; index < hidden_size;
-            index += blockDim.x, w_base_index += blockDim.x, h_base_index += blockDim.x) {
-        Dtype before_act_r = w_x_r[w_base_index] + w_h_r[w_base_index] + b_r[index];
-
-        Dtype act_r = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_r));
-        Dtype before_act_z = w_x_z[w_base_index] + w_h_z[w_base_index] + b_z[index];
-        Dtype act_z = static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + expf(-before_act_z));
-        Dtype before_act_h = w_x_o[w_base_index] + w_h_o[w_base_index] * act_r
-                             + b_o[index];
-        Dtype acted = tanhf(before_act_h);
-        output[h_base_index] = (static_cast<Dtype>(1.0) - act_z) * acted + act_z * hidden_pre[h_base_index];
-    }
-}
 
 template <>
 SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::gru_cudnn(
@@ -564,11 +387,6 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::gru_cu
     int r_offset = 1;
     int z_offset = 2;
 
-//    CHECK_EQ(w_h2h->height(), hidden_size) << "w_h2h->height()==batch_size";
-//    CHECK_EQ(w_h2h->width(), hidden_size * 3) << "w_h2h->width()==hidden_size*3";
-//
-//    CHECK_EQ(w_i2h->height(), word_size) << "w_i2h->height()==word_size";
-//    CHECK_EQ(w_i2h->width(), hidden_size * 3) << "w_i2h->width()==hidden_size*3";
 
     if (isHW2Seq) {
         x_data = hw2seq(inputs, param, _word_size, hidden_size, sequence);
@@ -589,13 +407,15 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::gru_cu
                    _word_size, 1.0, x_data, _weights_i2h.data(), 0.0, _temp_WX.mutable_data());
 
 
+
+
     const OpDataType* b_r = b->data() + r_offset * hidden_size;
     const OpDataType* b_z = b->data() + z_offset * hidden_size;
     const OpDataType* b_o = b->data() + o_offset * hidden_size;
 
     if (inputs.size() == 1) {
         CUDA_CHECK(cudaMemsetAsync(dout_data, 0, sizeof(InDataType) * batch_size * hidden_size,
-                                   _ctx.get_compute_stream()));
+                                   _ctx->get_compute_stream()));
         h = dout_data;
     } else {
         h = inputs[1]->data();
@@ -633,19 +453,13 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::gru_cu
         if (param.gate_activity == Active_sigmoid
                 && param.h_activity == Active_tanh) {
             cal_one_kernel_sigmoid_tanh_modi_cudnn_formula
-                    << < batch_size, frame_per_block, 0, _ctx.get_compute_stream() >> >
+                    << < batch_size, frame_per_block, 0, _ctx->get_compute_stream() >> >
                     (w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_h_o
                      , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
         } else if (param.gate_activity == Active_sigmoid_fluid
                    && param.h_activity == Active_tanh) {
             cal_one_kernel_paddlesigmoid_tanh_cudnn_formula
-                    << < batch_size, frame_per_block, 0, _ctx.get_compute_stream() >> >
-                    (w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_h_o
-                     , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
-        } else if (param.gate_activity == Active_sigmoid_fluid
-                   && param.h_activity == Active_relu) {
-            cal_one_kernel_paddlesigmoid_relu_cudnn_formula
-                    << < batch_size, frame_per_block, 0, _ctx.get_compute_stream() >> >
+                    << < batch_size, frame_per_block, 0, _ctx->get_compute_stream() >> >
                     (w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_h_o
                      , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
         } else {
@@ -661,6 +475,187 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::gru_cu
     return SaberSuccess;
 
 }
+
+template<>
+        SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(\
+const std::vector<DataTensor_in*>& inputs,
+std::vector<DataTensor_out*>& outputs,
+GruParam <OpTensor>& param) {
+    if (param.formula == GRU_CUDNN) {
+                LOG(ERROR) << "saber cudnn formula not support reverse yet";
+        if (param.is_reverse) {
+                    LOG(ERROR) << "saber cudnn formula not support reverse yet";
+
+        }
+        return gru_cudnn(inputs, outputs, param);
+    }
+
+    //    LOG(INFO)<<"gru_paddle";
+    DataTensor_in* x = inputs[0];
+    std::vector<int> offset=x->get_seq_offset();
+    const InDataType* x_data = x->data();
+    const InDataType* h;
+    DataTensor_out* dout = outputs[0];
+    OutDataType* dout_data = dout->mutable_data();
+
+    //TODO:check shape first
+    const OpTensor* b = param.bias();
+
+    int batch_size = offset.size() - 1; //x->get_seq_offset().size()-1;
+    int seq_sum = x->num();
+    int hidden_size = b->valid_size() / 3;
+    bool isHW2Seq=offset.size()>2;
+    int o_offset = 0;
+    int r_offset = 1;
+    int z_offset = 2;
+
+    std::vector<int> emit_offset_vec;
+    int emit_length=0;
+    _temp_map_dev.try_expand_size(seq_sum);
+    isHW2Seq=_seq_util.get_sorted_map(offset,emit_offset_vec,emit_length,_ctx->get_compute_stream());
+    if (isHW2Seq) {
+        Shape seq_shape(1, 1, seq_sum, _word_size);
+        _temp_tensor_in.try_expand_size(seq_shape);
+        Shape seq_out_shape(1, 1, seq_sum, _hidden_size);
+        _temp_tensor_out.try_expand_size(seq_out_shape);
+        _seq_util.seq_2_sorted_seq(x_data,_temp_tensor_in.mutable_data(),_word_size,_ctx->get_compute_stream());
+        x_data=_temp_tensor_in.data();
+        dout_data = _temp_tensor_out.mutable_data();
+    }
+
+    Shape shape_WX(seq_sum, batch_size, 3, hidden_size);
+    _temp_WX.try_expand_size(shape_WX);
+
+    Shape shape_WH(1, batch_size, 2, hidden_size);
+    _temp_WH.try_expand_size(shape_WH);
+
+    Shape shape_WHR(1, batch_size, 1, hidden_size);
+    _temp_WHR.try_expand_size(shape_WHR);
+
+    _gemm_wx(seq_sum * batch_size, 3 * hidden_size, _word_size,1.0, x_data,0.0, _weights_i2h.data(),_temp_WX.mutable_data(),_ctx->get_compute_stream());
+
+    const OpDataType* b_r = b->data() + r_offset * hidden_size;
+    const OpDataType* b_z = b->data() + z_offset * hidden_size;
+    const OpDataType* b_o = b->data() + o_offset * hidden_size;
+
+    if (inputs.size() == 1) {
+        if(_temp_zero.valid_size()<batch_size * hidden_size){
+            _temp_zero.try_expand_size(batch_size * hidden_size);
+            CUDA_CHECK(cudaMemsetAsync(_temp_zero.mutable_data(), 0, sizeof(OutDataType)*batch_size * hidden_size,
+                                       _ctx->get_compute_stream()));
+        }
+
+        h = _temp_zero.data();
+    } else {
+        h = inputs[1]->data();
+    }
+
+
+    for (int word_id = 0; word_id < emit_length; word_id++) {
+        int real_word_id = word_id;
+        int last_word_id = word_id - 1;
+
+        if (param.is_reverse && batch_size == 1) {
+            real_word_id = emit_length - word_id - 1;
+            last_word_id = real_word_id + 1;
+        }
+        int emit_word_id_start = emit_offset_vec[real_word_id];
+        int emit_word_id_end = emit_offset_vec[real_word_id + 1];
+        int emit_word_length = emit_word_id_end - emit_word_id_start;
+
+        const OutDataType* hidden_in;
+        OutDataType* hidden_out = dout_data + emit_offset_vec[real_word_id] * hidden_size;
+
+        if (word_id == 0) {
+            hidden_in = h;
+        } else {
+            hidden_in = dout_data + emit_offset_vec[last_word_id] * hidden_size;
+        }
+
+        _gemm_wh_2(emit_word_length, 2 * hidden_size, hidden_size,1.0, hidden_in,0.0, _weights_h2h.data() + hidden_size * hidden_size,_temp_WH.mutable_data(),_ctx->get_compute_stream());
+
+        OutDataType* w_x_r = _temp_WX.mutable_data() + r_offset * hidden_size
+                             + emit_word_id_start * hidden_size * 3;
+        OutDataType* w_x_z = _temp_WX.mutable_data() + z_offset * hidden_size
+                             + emit_word_id_start * hidden_size * 3;
+        OutDataType* w_x_o = _temp_WX.mutable_data() + o_offset * hidden_size
+                             + emit_word_id_start * hidden_size * 3;
+
+        OutDataType* w_h_r = _temp_WH.mutable_data() + 0 * hidden_size;
+        OutDataType* w_h_z = _temp_WH.mutable_data() + 1 * hidden_size;
+
+
+
+        const OpDataType * w_o = _weights_h2h.data();
+                CHECK_LE(hidden_size, 1024) << "now not support hidden size > 1024 for paddle formula";
+        int frame_per_block = hidden_size <= 1024 ? hidden_size : 1024;
+        if(param.gate_activity == Active_sigmoid) {
+            RESET_KERNEL_NAME(sigmoid) << < emit_word_length, frame_per_block, 0
+                    , _ctx->get_compute_stream() >> > (
+                    w_x_r, w_h_r
+                            , b_r, hidden_size, hidden_out, hidden_in);
+        }else if(param.gate_activity == Active_sigmoid_fluid){
+            RESET_KERNEL_NAME(sigmoid_fluid) << < emit_word_length, frame_per_block, 0
+                    , _ctx->get_compute_stream() >> > (
+                    w_x_r, w_h_r
+                            , b_r, hidden_size, hidden_out, hidden_in);
+        }else{
+            CHECK_EQ(0,1) << "not support gate active  function "<<param.gate_activity;
+        }
+
+        _gemm_wh_o(emit_word_length, hidden_size, hidden_size,1.0, hidden_out,0.0,w_o,_temp_WHR.mutable_data(),_ctx->get_compute_stream());
+
+        if(param.gate_activity == Active_sigmoid_fluid&&param.h_activity == Active_tanh_fluid) {
+            FINAL_KERNEL_NAME(sigmoid_fluid,tanh_fluid)<< < emit_word_length, frame_per_block, 0
+                    , _ctx->get_compute_stream() >> > (
+                    w_x_z, w_x_o, w_h_z, b_z, b_o, hidden_size, hidden_out, hidden_in, _temp_WHR.data());
+        }else if(param.gate_activity == Active_sigmoid_fluid&&param.h_activity == Active_relu){
+            FINAL_KERNEL_NAME(sigmoid_fluid,relu)<< < emit_word_length, frame_per_block, 0
+                    , _ctx->get_compute_stream() >> > (
+                    w_x_z, w_x_o, w_h_z, b_z, b_o, hidden_size, hidden_out, hidden_in, _temp_WHR.data());
+        }else{
+            CHECK_EQ(0,1) << "not support active  function "<<param.gate_activity<<","<<param.h_activity;
+        }
+
+//        if (param.gate_activity == Active_sigmoid
+//            && param.h_activity == Active_tanh) {
+//            cal_one_kernel_sigmoid_tanh_paddle_formula
+//                    <<< emit_word_length, frame_per_block, sizeof(OutDataType)*hidden_size
+//                    , _ctx.get_compute_stream()>>>(
+//                    w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
+//                            , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
+//
+//        } else if (param.gate_activity == Active_sigmoid_fluid
+//                   && param.h_activity == Active_tanh_fluid) {
+//            cal_one_kernel_sigmoidfluid_tanhfluid_paddle_formula
+//                    <<< emit_word_length, frame_per_block, sizeof(OutDataType)*hidden_size
+//                    , _ctx.get_compute_stream()>>>(
+//                    w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
+//                            , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
+//
+//        }  else if (param.gate_activity == Active_sigmoid_fluid
+//                    && param.h_activity == Active_relu) {
+//            cal_one_kernel_paddlesigmoid_relu_paddle_formula
+//                    << < emit_word_length, frame_per_block, sizeof(OutDataType)*hidden_size
+//                    , _ctx.get_compute_stream() >> >
+//                      (w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
+//                              , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
+//
+//        } else {
+//                    LOG(ERROR) << "not support active  function";
+//        }
+    }
+
+    if (isHW2Seq) {
+        _seq_util.sorted_seq_2_seq(_temp_tensor_out.data(),dout->mutable_data(),_hidden_size,_ctx->get_compute_stream());
+//        LOG(INFO)<<"are you ok";
+//        seq2hw(outputs, inputs, param, hidden_size, dout_data);
+    }
+    outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
+    return SaberSuccess;
+}
+
+#if 0
 template<>
 SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(\
         const std::vector<DataTensor_in*>& inputs,
@@ -715,8 +710,10 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispat
     Shape shape_WH(1, batch_size, 2, hidden_size);
     _temp_WH.try_expand_size(shape_WH);
 
-    anakin_NV_gemm(_cublas_handle, false, false, sequence * batch_size, 3 * hidden_size,
-                   _word_size, 1.0, x_data, _weights_i2h.data(), 0.0, _temp_WX.mutable_data());
+//    anakin_NV_gemm(_cublas_handle, false, false, sequence * batch_size, 3 * hidden_size,
+//                   _word_size, 1.0, x_data, _weights_i2h.data(), 0.0, _temp_WX.mutable_data());
+
+    _gemm_wx(sequence * batch_size, 3 * hidden_size, _word_size,1.0, x_data,0.0, _weights_i2h.data(),_temp_WX.mutable_data(),_ctx.get_compute_stream());
 
     const OpDataType* b_r = b->data() + r_offset * hidden_size;
     const OpDataType* b_z = b->data() + z_offset * hidden_size;
@@ -724,7 +721,7 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispat
 
     if (inputs.size() == 1) {
         CUDA_CHECK(cudaMemsetAsync(dout_data, 0, sizeof(OutDataType)*batch_size * hidden_size,
-                                   _ctx.get_compute_stream()));
+                                   _ctx->get_compute_stream()));
         h = dout_data;
     } else {
         h = inputs[1]->data();
@@ -749,10 +746,10 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispat
             hidden_in = dout_data + last_seq * batch_size * hidden_size;
         }
 
-        anakin_NV_gemm(_cublas_handle, false, false, batch_size,
-                       2 * hidden_size, hidden_size, 1.0, hidden_in,
-                       _weights_h2h.data() + hidden_size * hidden_size, 0.0, _temp_WH.mutable_data());
-
+//        anakin_NV_gemm(_cublas_handle, false, false, batch_size,
+//                       2 * hidden_size, hidden_size, 1.0, hidden_in,
+//                       _weights_h2h.data() + hidden_size * hidden_size, 0.0, _temp_WH.mutable_data());
+        _gemm_wh_2(batch_size, 2 * hidden_size, hidden_size,1.0, hidden_in,0.0, _weights_h2h.data() + hidden_size * hidden_size,_temp_WH.mutable_data(),_ctx.get_compute_stream());
 
         OutDataType* w_x_r = _temp_WX.mutable_data() + r_offset * hidden_size
                              + realseq * batch_size * hidden_size * 3;
@@ -775,15 +772,23 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispat
                 && param.h_activity == Active_tanh) {
             cal_one_kernel_sigmoid_tanh_paddle_formula
             <<< batch_size, frame_per_block, sizeof(OutDataType)*hidden_size
-            , _ctx.get_compute_stream()>>>(
+            , _ctx->get_compute_stream()>>>(
                 w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
                 , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
 
+        } else if (param.gate_activity == Active_sigmoid_fluid
+                   && param.h_activity == Active_tanh_fluid) {
+            cal_one_kernel_sigmoidfluid_tanhfluid_paddle_formula
+                    <<< batch_size, frame_per_block, sizeof(OutDataType)*hidden_size
+                    , _ctx.get_compute_stream()>>>(
+                    w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
+                            , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
+
         }  else if (param.gate_activity == Active_sigmoid_fluid
                     && param.h_activity == Active_relu) {
             cal_one_kernel_paddlesigmoid_relu_paddle_formula
                     << < batch_size, frame_per_block, sizeof(OutDataType)*hidden_size
-                    , _ctx.get_compute_stream() >> >
+                    , _ctx->get_compute_stream() >> >
                     (w_x_r, w_x_z, w_x_o, w_h_r, w_h_z, w_o
                      , b_r, b_z, b_o, hidden_size, hidden_out, hidden_in);
 
@@ -798,6 +803,7 @@ SaberStatus SaberGru<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispat
     outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
     return SaberSuccess;
 }
+#endif
 
 }
 }
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_im2sequence.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_im2sequence.cu
index 9c7e63f..16abff3 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_im2sequence.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_im2sequence.cu
@@ -149,7 +149,7 @@ SaberStatus SaberIm2Sequence<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_layer_norm.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_layer_norm.cu
index 4dbe3cc..db94d86 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_layer_norm.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_layer_norm.cu
@@ -175,7 +175,7 @@ SaberStatus SaberLayerNorm<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::
     std::vector<DataTensor_out*>& outputs, \
     LayerNormParam<OpTensor> &param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     int total_size = inputs[0]->valid_size();
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_lrn.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_lrn.cu
index 5ff0c4a..61a15ef 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_lrn.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_lrn.cu
@@ -66,7 +66,7 @@ SaberStatus SaberLrn<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
     int out_h = outputs[0]->height();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_lstm.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_lstm.cu
new file mode 100644
index 0000000..00a9b6c
--- /dev/null
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_lstm.cu
@@ -0,0 +1,19 @@
+#include "saber/funcs/impl/cuda/saber_lstm.h"
+#include "saber/core/tensor_op.h"
+#include "cuda_fp16.h"
+namespace anakin {
+
+namespace saber {
+template<>
+SaberStatus
+SaberLstm<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(
+    const std::vector < DataTensor_in* >& inputs,
+    std::vector < DataTensor_out* >& outputs,
+    LstmParam < OpTensor >& param) {
+
+}
+
+template class SaberLstm<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+}
+}
+
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_mvn.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_mvn.cu
index 4955831..ff77b2e 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_mvn.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_mvn.cu
@@ -209,7 +209,7 @@ SaberStatus SaberMvn<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs, \
     MvnParam<OpTensor>& param) {
 
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     const InDataType * in_data = inputs[0]->data();
     OutDataType * out_data = outputs[0]->mutable_data();
     int num = inputs[0]->num() * inputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_normalize.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_normalize.cu
index c7c7cd5..b1faef6 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_normalize.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_normalize.cu
@@ -227,7 +227,7 @@ SaberStatus SaberNormalize<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::
     const std::vector<DataTensor_in*>& inputs, \
     std::vector<DataTensor_out*>& outputs, \
     NormalizeParam<OpTensor> &param) {
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
     const float* src = inputs[0]->data();
     float* dst = outputs[0]->mutable_data();
     if (!param.across_spatial) {
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_pad.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_pad.cu
index bb52ab7..09cac63 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_pad.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_pad.cu
@@ -46,7 +46,7 @@ SaberStatus SaberPad<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = inputs[0]->valid_size();
     int in_n = inputs[0]->num();
     int in_c = inputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_permute.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_permute.cu
index 38c5d01..1960efc 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_permute.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_permute.cu
@@ -166,7 +166,7 @@ SaberStatus SaberPermute<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs, \
     PermuteParam<OpTensor>& param) {
 
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     const InDataType * in_data = inputs[0]->data();
     OutDataType * out_data = outputs[0]->mutable_data();
     int count = outputs[0]->valid_size();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_permute_power.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_permute_power.cu
index 64c7d47..e487713 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_permute_power.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_permute_power.cu
@@ -218,7 +218,7 @@ SaberStatus SaberPermutePower<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType *in_data = inputs[0]->data();
     OutDataType *out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     const int * permute_order = _permute_order.data();
     const int * new_steps = _new_steps.data();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_pooling_with_index.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_pooling_with_index.cu
index d5aacbe..3eb21b2 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_pooling_with_index.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_pooling_with_index.cu
@@ -78,7 +78,7 @@ SaberStatus SaberPoolingWithIndex<NV, OpDtype, inDtype, outDtype,\
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
     OutDataType* out_index = outputs[1]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_power.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_power.cu
index f7bd9b0..b88c4ff 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_power.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_power.cu
@@ -90,7 +90,7 @@ SaberStatus SaberPower<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     const float scale = param.scale;
     const float shift = param.shift;
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_prelu.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_prelu.cu
deleted file mode 100644
index 1ed805f..0000000
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_prelu.cu
+++ /dev/null
@@ -1,114 +0,0 @@
-#include "saber/funcs/impl/cuda/saber_prelu.h"
-
-namespace anakin{
-
-namespace saber{
-
-template <typename dtype>
-__global__ void prelu_shared_kernel(int n, const dtype* slope, const dtype* src, dtype* dst) {
-    CUDA_KERNEL_LOOP(idx, n) {
-        dst[idx] = src[idx] > 0 ? src[idx] : src[idx] * slope[0];
-    }
-}
-
-template <typename dtype>
-__global__ void prelu_kernel(int n, int channels, int inner_size, \
-    const dtype* slope, const dtype* src, dtype* dst) {
-
-    CUDA_KERNEL_LOOP(idx, n) {
-        int c = (idx / inner_size) % channels;
-        dst[idx] = src[idx] > 0 ? src[idx] : src[idx] * slope[c];
-    }
-}
-
-template <typename dtype>
-__global__ void prelu_shared_roi_kernel(int n, int dims, \
-        const int* input_stride_real, const int* output_stride_real, const int* shape_valid, \
-        const dtype* slope, const dtype* src, dtype* dst) {
-
-    CUDA_KERNEL_LOOP(idx, n) {
-        int index = idx;
-        //! compute real data index
-        int input_real_index = 0;
-        int output_real_index = 0;
-        for (int i = dims - 1; i >= 0; i--) {
-            int x = index % shape_valid[i];
-            input_real_index += x * input_stride_real[i];
-            output_real_index += x * output_stride_real[i];
-            index = index / shape_valid[i];
-        }
-        dst[output_real_index] = src[input_real_index] > 0 ? src[input_real_index] : \
-            src[input_real_index] * slope[0];
-    }
-}
-
-template <typename dtype>
-__global__ void prelu_roi_kernel(int n, int channels, int inner_size, int dims, \
-        const int* input_stride_real, const int* output_stride_real, const int* shape_valid, \
-        const dtype* slope, const dtype* src, dtype* dst) {
-
-    CUDA_KERNEL_LOOP(idx, n) {
-        int index = idx;
-        //! compute real data index
-        int input_real_index = 0;
-        int output_real_index = 0;
-        for (int i = dims - 1; i >= 0; i--) {
-            int x = index % shape_valid[i];
-            input_real_index += x * input_stride_real[i];
-            output_real_index += x * output_stride_real[i];
-            index = index / shape_valid[i];
-        }
-        int c = (idx / inner_size) % channels;
-        dst[output_real_index] = src[input_real_index] > 0 ? src[input_real_index] : \
-            src[input_real_index] * slope[c];
-    }
-}
-
-
-template <DataType OpDtype,
-            DataType inDtype,
-            DataType outDtype,
-            typename LayOutType_op,
-            typename LayOutType_in,
-            typename LayOutType_out>
-SaberStatus SaberPrelu<NV, OpDtype, inDtype, outDtype,\
-    LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(\
-    const std::vector<DataTensor_in *>& inputs, \
-    std::vector<DataTensor_out *>& outputs, \
-    PreluParam<OpTensor>& param) {
-    cudaStream_t stream = this->_ctx.get_compute_stream();
-
-    const InDataType* src = inputs[0]->data();
-    OutDataType* dst = outputs[0]->mutable_data();
-    const int* valid_shape = _valid_shape.data();
-    const int* input_stride = _input_stride.data();
-    const int* output_stride = _output_stride.data();
-
-    if (_is_continue_buf) {
-        if (param.channel_shared) {
-            prelu_shared_kernel<OpDataType><<<CUDA_GET_BLOCKS(_size), CUDA_NUM_THREADS, 0, stream>>>\
-                (_size, param.slope->data(), src, dst);
-        } else {
-            prelu_kernel<OpDataType><<<CUDA_GET_BLOCKS(_size), CUDA_NUM_THREADS, 0, stream>>>\
-                (_size, _channels, _inner_size, param.slope->data(), src, dst);
-        }
-    } else {
-        if (param.channel_shared) {
-            prelu_shared_roi_kernel<OpDataType>\
-                <<<CUDA_GET_BLOCKS(_size), CUDA_NUM_THREADS, 0, stream>>>\
-                (_size, _dims, input_stride, output_stride, valid_shape, \
-                    param.slope->data(), src, dst);
-        } else {
-            prelu_roi_kernel<OpDataType>\
-                <<<CUDA_GET_BLOCKS(_size), CUDA_NUM_THREADS, 0, stream>>>\
-                (_size, _channels, _inner_size, _dims, input_stride, \
-                output_stride, valid_shape, param.slope->data(), src, dst);
-        }
-    }
-
-    return SaberSuccess;
-}
-
-} //namespace anakin
-
-} //namespace anakin
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_resize.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_resize.cu
index 2bfd667..5c2f4cb 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_resize.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_resize.cu
@@ -100,7 +100,7 @@ SaberStatus SaberResize<NV, OpDtype, inDtype, outDtype,\
     const std::vector<DataTensor_in *>& inputs, \
     std::vector<DataTensor_out *>& outputs, \
     ResizeParam<OpTensor>& param) {
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     int w_out = outputs[0]->width();
     int h_out = outputs[0]->height();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_roi_pool.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_roi_pool.cu
index 7204569..4307cf5 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_roi_pool.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_roi_pool.cu
@@ -95,7 +95,7 @@ SaberStatus SaberRoiPool<NV, OpDtype, inDtype, outDtype,\
     if (outputs.size() == 2) {
         out_index = outputs[1]->mutable_data();
     }
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_scale.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_scale.cu
index 4c16e41..ab9a0c9 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_scale.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_scale.cu
@@ -42,7 +42,7 @@ SaberStatus SaberScale<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, \
         std::vector<DataTensor_out*>& outputs,
         ScaleParam<OpTensor>& param) {
 
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
     auto in_data = inputs[0]->data();
     auto out_data = outputs[0]->mutable_data();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_slice.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_slice.cu
index 3391e7f..908c94f 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_slice.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_slice.cu
@@ -32,7 +32,7 @@ SaberStatus SaberSlice<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs, \
     SliceParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
     //! inputs only has one tensor
     Shape shape_in = inputs[0]->valid_shape();
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_softmax.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_softmax.cu
index 653cf9e..d238997 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_softmax.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_softmax.cu
@@ -317,7 +317,7 @@ SaberStatus SaberSoftmax<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs, \
     SoftmaxParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
     //! inputs only has one tensor
     int total_threads = this->_inner_num * this->_outer_num;
     const InDataType* data_in = inputs[0]->data();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_spp.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_spp.cu
index 27688d6..c8fc7a8 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_spp.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_spp.cu
@@ -33,7 +33,7 @@ SaberStatus SaberSpp<NV, OpDtype, inDtype, outDtype,\
 
     const InDataType* in_data = inputs[0]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = outputs[0]->valid_size();
     int out_n = outputs[0]->num();
     int out_c = outputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_transpose.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_transpose.cu
index e01362d..948f2fb 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_transpose.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_transpose.cu
@@ -50,7 +50,7 @@ SaberStatus SaberTranspose<NV, OpDtype, inDtype, outDtype,\
     std::vector<DataTensor_out *>& outputs, \
     TransposeParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     int w_out = outputs[0]->width();
     int h_out = outputs[0]->height();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/saber_unpool.cu b/saber/funcs/impl/cuda/base/cuda_c/saber_unpool.cu
index f3e2f55..853486c 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/saber_unpool.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/saber_unpool.cu
@@ -40,7 +40,7 @@ SaberStatus SaberUnpool<NV, OpDtype, inDtype, outDtype,\
     const InDataType* in_data = inputs[0]->data();
     const OutDataType* in_max_index = inputs[1]->data();
     OutDataType* out_data = outputs[0]->mutable_data();
-    cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+    cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
     int count = inputs[0]->valid_size();
     int in_n = inputs[0]->num();
     int in_c = inputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/base/cuda_c/tensor_op_cuda.cu b/saber/funcs/impl/cuda/base/cuda_c/tensor_op_cuda.cu
index 68e1027..c92cac2 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/tensor_op_cuda.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/tensor_op_cuda.cu
@@ -108,13 +108,13 @@ void print_tensor_device(Tensor_t& tensor, typename Tensor_t::API::stream_t stre
 
 #define FILL_TENSOR_NV(type, layout) \
     template void fill_tensor_device_const<Tensor<NV, type, layout>>\
-        (Tensor<NV, type, layout>& tensor, DataTrait<type>::dtype value, \
+        (Tensor<NV, type, layout>& tensor, DataTrait<NV, type>::dtype value, \
         typename TargetWrapper<NV>::stream_t stream); \
     template void fill_tensor_device_rand<Tensor<NV, type, layout>>\
         (Tensor<NV, type, layout>& tensor, typename TargetWrapper<NV>::stream_t stream); \
     template void fill_tensor_device_rand<Tensor<NV, type, layout>>\
-        (Tensor<NV, type, layout>& tensor, DataTrait<type>::dtype vstart, \
-        DataTrait<type>::dtype vend, typename TargetWrapper<NV>::stream_t stream); \
+        (Tensor<NV, type, layout>& tensor, DataTrait<NV, type>::dtype vstart, \
+        DataTrait<NV, type>::dtype vend, typename TargetWrapper<NV>::stream_t stream); \
     template void print_tensor_device<Tensor<NV, type, layout>>\
         (Tensor<NV, type, layout>& tensor, typename TargetWrapper<NV>::stream_t stream);
 
diff --git a/saber/funcs/impl/cuda/base/cuda_c/vender_fc.cu b/saber/funcs/impl/cuda/base/cuda_c/vender_fc.cu
index 40369bd..621b287 100644
--- a/saber/funcs/impl/cuda/base/cuda_c/vender_fc.cu
+++ b/saber/funcs/impl/cuda/base/cuda_c/vender_fc.cu
@@ -82,7 +82,7 @@ SaberStatus VenderFc<NV, OpDtype, inDtype, outDtype, \
             std::vector<DataTensor_out *>& outputs,
             FcParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     const InDataType* din = inputs[0]->data();
     OutDataType* dout = outputs[0]->mutable_data();
diff --git a/saber/funcs/impl/cuda/base/cuda_funcs.h b/saber/funcs/impl/cuda/base/cuda_funcs.h
index 1adeda9..3e703d5 100644
--- a/saber/funcs/impl/cuda/base/cuda_funcs.h
+++ b/saber/funcs/impl/cuda/base/cuda_funcs.h
@@ -1,3 +1,18 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
 #include <stdio.h>
 #include "saber/core/tensor.h"
 
diff --git a/saber/funcs/impl/cuda/base/sass/sm_50/libanakin_saber_sass_sm_50.a b/saber/funcs/impl/cuda/base/sass/sm_50/libanakin_saber_sass_sm_50.a
index 9396505..3b9e416 100644
Binary files a/saber/funcs/impl/cuda/base/sass/sm_50/libanakin_saber_sass_sm_50.a and b/saber/funcs/impl/cuda/base/sass/sm_50/libanakin_saber_sass_sm_50.a differ
diff --git a/saber/funcs/impl/cuda/base/sass/sm_61/libanakin_saber_sass_sm_61.a b/saber/funcs/impl/cuda/base/sass/sm_61/libanakin_saber_sass_sm_61.a
index 1775b91..2d0cb70 100644
Binary files a/saber/funcs/impl/cuda/base/sass/sm_61/libanakin_saber_sass_sm_61.a and b/saber/funcs/impl/cuda/base/sass/sm_61/libanakin_saber_sass_sm_61.a differ
diff --git a/saber/funcs/impl/cuda/base/sass_funcs.h b/saber/funcs/impl/cuda/base/sass_funcs.h
index 3374cf6..83e90ae 100644
--- a/saber/funcs/impl/cuda/base/sass_funcs.h
+++ b/saber/funcs/impl/cuda/base/sass_funcs.h
@@ -429,12 +429,11 @@ void direct_conv_bias_relu_maxpool2k2s0p_Kindiv4(const DataType* src,
     cudaStream_t cuda_stream);
 
 template<int k>
-void scale_to_new_tensor_k4_s2_p1_decov (Tensor<NV, AK_FLOAT, NCHW> &new_weights_dev,
-                                         const Tensor<NV, AK_FLOAT, NCHW> *weight,
+void scale_to_new_tensor_k4_s2_p1_deconv (Tensor<NV, AK_FLOAT, NCHW> *weight,
                                          int in_channel, int out_channel) {
     Tensor<X86, AK_FLOAT, NCHW> new_weights_h;
     Tensor<X86, AK_FLOAT, NCHW> temp_weights;
-    new_weights_dev.reshape(weight->valid_shape());
+//    new_weights_dev.reshape(weight->valid_shape());
     new_weights_h.reshape(weight->valid_shape());
     temp_weights.reshape(weight->valid_shape());
 
@@ -447,7 +446,7 @@ void scale_to_new_tensor_k4_s2_p1_decov (Tensor<NV, AK_FLOAT, NCHW> &new_weights
                                       trans_w + 3 * offset,
                                       temp_weights.data(),
                                       in_channel, out_channel);
-    new_weights_dev.copy_from(new_weights_h);
+    weight->copy_from(new_weights_h);
 }
 
 void ker_deconv_implicit_gemm_k4_s2_p1_16x64(
@@ -487,6 +486,16 @@ void ker_gemm_32x32x32_NN_vec_bias_relu(const int M, const int N, const int K,
                                         const float beta, const float* B,
                                         float* C, const float* bias, cudaStream_t cuda_stream);
 
+void ker_gemm_32x32x32_NN_bias(const int M, const int N, const int K,
+                               const float alpha, const float* A,
+                               const float beta, const float* B,
+                               float* C, const float* bias, cudaStream_t cuda_stream);
+
+void ker_gemm_32x32x32_NN_vec_bias(const int M, const int N, const int K,
+                                   const float alpha, const float* A,
+                                   const float beta, const float* B,
+                                   float* C, const float* bias, cudaStream_t cuda_stream);
+
 template <int tile>
 void ker_sgemm_nn(const int M, const int N, const int K,
                   const int lda, const int ldb, const int ldc,
diff --git a/saber/funcs/impl/cuda/cudnn_helper.h b/saber/funcs/impl/cuda/cudnn_helper.h
index 8e0105c..7fa0611 100644
--- a/saber/funcs/impl/cuda/cudnn_helper.h
+++ b/saber/funcs/impl/cuda/cudnn_helper.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/cuda/saber_activation.h b/saber/funcs/impl/cuda/saber_activation.h
index 1405d6d..a390044 100644
--- a/saber/funcs/impl/cuda/saber_activation.h
+++ b/saber/funcs/impl/cuda/saber_activation.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ActivationParam<OpTensor>& param, Context<NV>& ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/cuda/saber_argmax.h b/saber/funcs/impl/cuda/saber_argmax.h
index 57af6f9..a5546be 100644
--- a/saber/funcs/impl/cuda/saber_argmax.h
+++ b/saber/funcs/impl/cuda/saber_argmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -55,7 +55,7 @@ public:
                         std::vector<DataTensor_out *>& outputs,
                         ArgmaxParam<OpTensor>& param, 
                         Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         if (!param.has_axis) {
             int inner_dim = inputs[0]->count(1, inputs[0]->dims());
             int outer_dim = inputs[0]->num();
diff --git a/saber/funcs/impl/cuda/saber_axpy.h b/saber/funcs/impl/cuda/saber_axpy.h
index a3a1eac..8a44fcb 100644
--- a/saber/funcs/impl/cuda/saber_axpy.h
+++ b/saber/funcs/impl/cuda/saber_axpy.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -55,7 +55,7 @@ public:
                         std::vector<DataTensor_out *>& outputs,
                         AxpyParam<OpTensor>& param, 
                         Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/cuda/saber_box_coder.h b/saber/funcs/impl/cuda/saber_box_coder.h
index 19c722c..322948b 100644
--- a/saber/funcs/impl/cuda/saber_box_coder.h
+++ b/saber/funcs/impl/cuda/saber_box_coder.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                         BoxCoderParam<OpTensor>& param, 
                         Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_cast.h b/saber/funcs/impl/cuda/saber_cast.h
index ad15fe5..ee93a01 100644
--- a/saber/funcs/impl/cuda/saber_cast.h
+++ b/saber/funcs/impl/cuda/saber_cast.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CAST_H
 #define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CAST_H
@@ -53,7 +54,7 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             CastParam<OpTensor>& param, Context<NV>& ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/cuda/saber_concat.h b/saber/funcs/impl/cuda/saber_concat.h
index 0f9f194..f4a18ff 100644
--- a/saber/funcs/impl/cuda/saber_concat.h
+++ b/saber/funcs/impl/cuda/saber_concat.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -51,7 +51,7 @@ public:
                         ConcatParam<OpTensor>& param, 
                         Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_conv.h b/saber/funcs/impl/cuda/saber_conv.h
index 5a5411b..3702f6b 100644
--- a/saber/funcs/impl/cuda/saber_conv.h
+++ b/saber/funcs/impl/cuda/saber_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -47,99 +47,44 @@ public:
     typedef typename DataTensor_out::Dtype OutDataType;
     typedef typename OpTensor::Dtype OpDataType;
 
-    SaberConv2D():_host_work_space(nullptr), _gpu_work_space(nullptr)
-    {}
-
-    ~SaberConv2D() {
-        if (_host_work_space)
-        {
-            free(_host_work_space);
-        }
-        if (_gpu_work_space)
-        {
-            cudaFree(_gpu_work_space);
-        }
-    }
-
+    SaberConv2D() {}
 
+    ~SaberConv2D() {}
 
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ConvParam<OpTensor>& param, Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         //This is an ugly impl for now
         if (param.stride_h == 1 &&
                 param.stride_w == 1 &&
                 param.weight()->height() == 3 &&
-                param.weight()->width() == 3 && param.group == 1)
-        {
-            //Update weights if need
-            Shape weight_shape = param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_out> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
-
-            int round_in_channel = i_align_up(inputs[0]->channel(),8);
-            int round_out_channel = i_align_up(param.weight()->num(),32);
+                param.weight()->width() == 3 && param.group == 1) {
 
-            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
-            _host_work_space = (OpDataType*)malloc(weight4x4_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight4x4_size*sizeof(OpDataType)));
-            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);
-            CUDA_CHECK(cudaMemcpy((void*)_gpu_work_space,
-                          (void*)_host_work_space,
-                          weight4x4_size * sizeof(OpDataType),
-                          cudaMemcpyHostToDevice)); 
             dispatch_func = winograd_conv<OutDataType, OpDataType>;
-
-        }
-        else if (param.group == 1)
-        {
-
-            int weight_size = (param.weight()->shape()).count();
-            Tensor<X86, OpDtype, LayOutType_out> weight_host;
-            weight_host.re_alloc(param.weight()->shape());
-            weight_host.copy_from(*(param.weight()));
-            const OpDataType *weight_data = weight_host.data();
-            
-            _host_work_space = (OpDataType*)malloc(weight_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight_size * sizeof(OpDataType)));
-
-            transpose_filter_KCRS_2_CRSK(weight_data, _host_work_space, \
-                                         param.weight()->num(), \
-                                         param.weight()->channel(), \
-                                         param.weight()->height(), \
-                                         param.weight()->width());
-            CUDA_CHECK(cudaMemcpy( (void*)_gpu_work_space, \
-                                   (void*)_host_work_space, \
-                                   weight_size * sizeof(OpDataType), \
-                                   cudaMemcpyHostToDevice ));
-
+        } else if (param.group == 1) {
             const int K = param.weight()->num();
-            if (K % 4 == 0)
-            {
-                if (param.bias()->size() > 0)
+            if (K % 4 == 0) {
+                if (param.bias()->size() > 0) {
                     dispatch_func = direct_conv_bias_Kdivis4<OutDataType, OpDataType>;
-                else
+                } else {
                     dispatch_func = direct_conv_Kdivis4<OutDataType, OpDataType>;
-            }
-            else
-            {
-                if (param.bias()->size() > 0)
+                }
+            } else {
+                if (param.bias()->size() > 0) {
                     dispatch_func = direct_conv_bias_Kindiv4<OutDataType, OpDataType>;
-                else
+                } else {
                     dispatch_func = direct_conv_Kindiv4<OutDataType, OpDataType>;
+                }
             }
-        }
-        else
-        {
+        } else {
           return SaberUnImplError;
         }
+        _kernel_height = param.weight()->height();
+        _kernel_width = param.weight()->width();
+        trans_weights(inputs, outputs, param, ctx);
         cudaDeviceSynchronize();
         return create(inputs, outputs, param, ctx);
-
-
     }
     
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
@@ -167,41 +112,94 @@ public:
         //LOG(WARNING) << "group = " << param.group << ", filter = " << outputs[0]->channel();
 
         dispatch_func(inputs[0]->data(), outputs[0]->mutable_data(),
-                    _gpu_work_space,
-                    bias_data,
-                    inputs[0]->num(),
-                    inputs[0]->channel(),
-                    inputs[0]->height(),
-                    inputs[0]->width(),
-                    outputs[0]->channel(),
-                    outputs[0]->height(),
-                    outputs[0]->width(),
-                    shape_in[1],
-                    shape_in[2],
-                    shape_in[3],
-                    shape_out[1],
-                    shape_out[2],
-                    shape_out[3],
-                    param.weight()->height(),
-                    param.weight()->width(),
-                    param.pad_h,
-                    param.pad_w,
-                    param.stride_h,
-                    param.stride_w,
-                    param.dilation_h,
-                    param.dilation_w,
-                    param.group,
-                    param.alpha,
-                    param.beta,
-                    this->_ctx.get_compute_stream()); 
+                      param.weight()->data(),
+                      bias_data,
+                      inputs[0]->num(),
+                      inputs[0]->channel(),
+                      inputs[0]->height(),
+                      inputs[0]->width(),
+                      outputs[0]->channel(),
+                      outputs[0]->height(),
+                      outputs[0]->width(),
+                      shape_in[1],
+                      shape_in[2],
+                      shape_in[3],
+                      shape_out[1],
+                      shape_out[2],
+                      shape_out[3],
+                      _kernel_height,
+                      _kernel_width,
+                      param.pad_h,
+                      param.pad_w,
+                      param.stride_h,
+                      param.stride_w,
+                      param.dilation_h,
+                      param.dilation_w,
+                      param.group,
+                      param.alpha,
+                      param.beta,
+                      this->_ctx->get_compute_stream());
         
         CUDA_CHECK(cudaGetLastError()); 
         return SaberSuccess;
     }
 
+    void trans_weights(const std::vector<DataTensor_in *>& inputs,
+                       std::vector<DataTensor_out *>& outputs,
+                       ConvParam<OpTensor>& param, Context<NV> &ctx) {
+
+        Tensor<X86, OpDtype, LayOutType_op> trans_weights_host;
+        if (param.stride_h == 1 &&
+            param.stride_w == 1 &&
+            param.weight()->height() == 3 &&
+            param.weight()->width() == 3 && param.group == 1)
+        {
+            //Update weights if need
+            Shape weight_shape = param.weight()->shape();
+            Tensor<X86, OpDtype, LayOutType_out> new_weight;
+            new_weight.re_alloc(weight_shape);
+            new_weight.copy_from(*(param.weight()));
+            OpDataType *weight_data = new_weight.mutable_data();
+
+            int round_in_channel = i_align_up(inputs[0]->channel(), 8);
+            int round_out_channel = i_align_up(param.weight()->num(), 32);
+            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
+            Shape old_shape = param.weight()->shape();
+            trans_weights_host.re_alloc({weight4x4_size, 1, 1 ,1});
+            OpDataType* _host_work_space = trans_weights_host.mutable_data();
+            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.weight()->num(),
+                                       round_out_channel, inputs[0]->channel(), round_in_channel);
+
+            param.mutable_weight()->re_alloc({weight4x4_size, 1, 1, 1});
+            param.mutable_weight()->copy_from(trans_weights_host);
+            param.mutable_weight()->set_shape(old_shape);
+
+        } else if (param.group == 1) {
+
+            int weight_size = (param.weight()->shape()).count();
+            Tensor<X86, OpDtype, LayOutType_out> weight_host;
+            weight_host.re_alloc(param.weight()->shape());
+            weight_host.copy_from(*(param.weight()));
+            const OpDataType *weight_data = weight_host.data();
+            trans_weights_host.re_alloc(param.weight()->shape());
+            OpDataType* _host_work_space = trans_weights_host.mutable_data();
+
+            transpose_filter_KCRS_2_CRSK(weight_data, _host_work_space, \
+                                         param.weight()->num(), \
+                                         param.weight()->channel(), \
+                                         param.weight()->height(), \
+                                         param.weight()->width());
+
+            param.mutable_weight()->re_alloc(param.weight()->shape());
+            param.mutable_weight()->copy_from(trans_weights_host);
+        }
+        cudaDeviceSynchronize();
+    }
+
 private:
-    OpDataType* _host_work_space;
-    OpDataType* _gpu_work_space;
+
+    int _kernel_height;
+    int _kernel_width;
     std::function<void(const InDataType*,
       OutDataType*,
       const OpDataType*,
diff --git a/saber/funcs/impl/cuda/saber_conv_act.h b/saber/funcs/impl/cuda/saber_conv_act.h
index a34e444..e12f020 100644
--- a/saber/funcs/impl/cuda/saber_conv_act.h
+++ b/saber/funcs/impl/cuda/saber_conv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -55,126 +55,73 @@ public:
     typedef typename OpTensor::Dtype OpDataType;
 
     SaberConv2DAct()
-            : _host_work_space(nullptr)
-            , _gpu_work_space(nullptr)
-            , _use_k1s1p0(false)
+            : _use_k1s1p0(false)
     {}
 
-    ~SaberConv2DAct() {
-        if (_host_work_space)
-        {
-            free(_host_work_space);
-        }
-        if (_gpu_work_space)
-        {
-            cudaFree(_gpu_work_space);
-        }
-    }
+    ~SaberConv2DAct() {}
 
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ConvActiveParam<OpTensor>& param, Context<NV>& ctx) {
-
-
         return SaberSuccess;
     }
 
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ConvActiveParam<OpTensor>& param, Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
+        _kernel_height = param.conv_param.weight()->height();
+        _kernel_width = param.conv_param.weight()->width();
         _use_k1s1p0 = true;
-        _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.weight()->height() == 1);
-        _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.weight()->width() == 1);
+        _use_k1s1p0 = _use_k1s1p0 && (_kernel_height == 1);
+        _use_k1s1p0 = _use_k1s1p0 && (_kernel_width == 1);
         _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.pad_h == 0);
         _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.pad_w == 0);
         _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.stride_h == 1);
         _use_k1s1p0 = _use_k1s1p0 && (param.conv_param.stride_w == 1);
         _use_k1s1p0 = _use_k1s1p0 && (inputs[0]->num() == 1);
-        //This is an ugly impl for now
+        if (_use_k1s1p0) {
+            return SaberSuccess;
+        }
         if (param.conv_param.group == inputs[0]->channel() && \
             param.conv_param.group == outputs[0]->channel()){
+            return SaberSuccess;
 
         } else if (param.conv_param.stride_h == 1 &&
             param.conv_param.stride_w == 1 && 
-            param.conv_param.weight()->height() == 3 && 
-            param.conv_param.weight()->width() == 3
-            &&param.conv_param.group == 1)
-        {
-            //Update weights if need
-            Shape weight_shape = param.conv_param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_op> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.conv_param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
+            _kernel_height == 3 &&
+            _kernel_width == 3
+            &&param.conv_param.group == 1) {
 
-            int round_in_channel = i_align_up(inputs[0]->channel(),8);
-            int round_out_channel = i_align_up(param.conv_param.weight()->num(),32);
-            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
-            _host_work_space = (OpDataType* )malloc(weight4x4_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight4x4_size * sizeof(OpDataType)));
-            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.conv_param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);    
-            CUDA_CHECK(cudaMemcpy((void*)_gpu_work_space,
-                          (void*)_host_work_space,
-                          weight4x4_size*sizeof(OpDataType),
-                          cudaMemcpyHostToDevice));
             if (param.has_eltwise) {
                 dispatch_func_elt = winograd_conv_eltwise<InDataType, OpDataType>;
             } else {
                 dispatch_func = winograd_conv_relu<InDataType, OpDataType>;
             }
-        }
-        else if(param.conv_param.group == 1)
-        {
-            Shape weight_shape = param.conv_param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_op> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.conv_param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
-
-            int weight_size = param.conv_param.weight()->shape().count();
-            _host_work_space = (OpDataType* )malloc(weight_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight_size * sizeof(OpDataType)));
-
-            //const OpDataType *weight_data = param.conv_param.weight()->data();
-            transpose_filter_KCRS_2_CRSK(weight_data, _host_work_space, \
-                                         param.conv_param.weight()->num(), \
-                                         param.conv_param.weight()->channel(), \
-                                         param.conv_param.weight()->height(), \
-                                         param.conv_param.weight()->width());
-            CUDA_CHECK(cudaMemcpy( (void*)_gpu_work_space, \
-                                   (void*)_host_work_space, \
-                                   weight_size * sizeof(OpDataType), \
-                                   cudaMemcpyHostToDevice ));
-
+        } else if(param.conv_param.group == 1) {
             const int K = param.conv_param.weight()->num();
-            if(K % 4 == 0)
-            {
-                if (param.conv_param.bias()->size() > 0)
-                    dispatch_func = direct_conv_bias_relu_Kdivis4<InDataType, OpDataType>;
-                else
+            if(K % 4 == 0) {
+                if (param.conv_param.bias()->size() > 0){
+                    dispatch_func = param.has_active ?  direct_conv_bias_relu_Kdivis4<InDataType, OpDataType>: direct_conv_bias_Kdivis4<InDataType, OpDataType>;
+                } else {
                     return SaberUnImplError;
-            }
-            else
-            {   // TODO: would merge the bias(with/without) version
-                if (param.conv_param.bias()->size() > 0)
-                    dispatch_func = direct_conv_bias_relu_Kindiv4<InDataType, OpDataType>;
-                else
+                }
+            } else {   // TODO: would merge the bias(with/without) version
+                if (param.conv_param.bias()->size() > 0) {
+                    dispatch_func = param.has_active ? direct_conv_bias_relu_Kindiv4<InDataType, OpDataType> : direct_conv_bias_Kindiv4<InDataType, OpDataType>;
+                } else {
                     return SaberUnImplError;
+                }
             }      
+        } else {
+            return SaberUnImplError;
         }
-        else{
-          return SaberUnImplError;
-        }
+        trans_weights(inputs, outputs, param, ctx);
         cudaDeviceSynchronize();
 
         return create(inputs, outputs, param, ctx);
-        //return SaberSuccess;
-
     }
-
-    
     virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
                           std::vector<DataTensor_out*>& outputs,
                           ConvActiveParam<OpTensor>& param) {
@@ -197,16 +144,32 @@ public:
         int wout = outputs[0]->width();
         int hout = outputs[0]->height();
 
-        int kw = param.conv_param.weight()->width();
-        int kh = param.conv_param.weight()->height();
         //LOG(INFO) << "saber conv act";
         if (_use_k1s1p0) {
 //            LOG(INFO)<<"using k1s1p0";
-            conv_gemm_k1s1p0(outputs[0]->mutable_data(),
-                             inputs[0]->data(),
-                             param.conv_param.weight()->data(),
-                             chout, chin, hin, win, bias_data,
-                             this->_ctx.get_compute_stream());
+            if (param.has_eltwise_act) {
+                //if (param.eltwise_param.operation == Eltwise_sum) {
+                    conv_gemm_k1s1p0(outputs[0]->mutable_data(),
+                                     inputs[0]->data(),
+                                     param.conv_param.weight()->data(),
+                                     chout, chin, hin, win, bias_data,
+                                     this->_ctx->get_compute_stream(), 1.f, 1.f, true);
+                //}
+            } else {
+                if (param.has_active) {
+                    conv_gemm_k1s1p0(outputs[0]->mutable_data(),
+                                     inputs[0]->data(),
+                                     param.conv_param.weight()->data(),
+                                     chout, chin, hin, win, bias_data,
+                                     this->_ctx->get_compute_stream(), 1.f, 0.f, true);
+                } else {
+                    conv_gemm_k1s1p0(outputs[0]->mutable_data(),
+                                     inputs[0]->data(),
+                                     param.conv_param.weight()->data(),
+                                     chout, chin, hin, win, bias_data,
+                                     this->_ctx->get_compute_stream(), 1.f, 0.f, false);
+                }
+            }
             return SaberSuccess;
         }
         if (param.conv_param.group == chin && param.conv_param.group == chout) {
@@ -215,17 +178,17 @@ public:
                 if (param.has_active) {
                     saber_depthwise_conv_act<InDataType, true, true>(inputs[0]->data(), \
                         outputs[0]->mutable_data(), num, chin, hin, win, hout, \
-                        wout, kw, kh, param.conv_param.stride_w, \
+                        wout, _kernel_width, _kernel_height, param.conv_param.stride_w, \
                         param.conv_param.stride_h, param.conv_param.pad_w, param.conv_param.pad_h,\
                         (const OpDataType*)param.conv_param.weight()->data(), bias_data, \
-                        this->_ctx.get_compute_stream());
+                        this->_ctx->get_compute_stream());
                 } else {
                     saber_depthwise_conv_act<InDataType, true, false>(inputs[0]->data(), \
                         outputs[0]->mutable_data(), num, chin, hin, win, hout, \
-                        wout, kw, kh, param.conv_param.stride_w, \
+                        wout, _kernel_width, _kernel_height, param.conv_param.stride_w, \
                         param.conv_param.stride_h, param.conv_param.pad_w, param.conv_param.pad_h,\
                         (const OpDataType*)param.conv_param.weight()->data(), bias_data, \
-                        this->_ctx.get_compute_stream());
+                        this->_ctx->get_compute_stream());
                 }
 
             } else {
@@ -233,28 +196,26 @@ public:
                     saber_depthwise_conv_act<InDataType, false, true>(inputs[0]->data(), \
                         outputs[0]->mutable_data(), inputs[0]->num(), inputs[0]->channel(), \
                         inputs[0]->height(), inputs[0]->width(), outputs[0]->height(), \
-                        outputs[0]->width(), param.conv_param.weight()->width(), \
-                        param.conv_param.weight()->height(), param.conv_param.stride_w, \
+                        outputs[0]->width(), _kernel_width, \
+                        _kernel_height, param.conv_param.stride_w, \
                         param.conv_param.stride_h, param.conv_param.pad_w, param.conv_param.pad_h,\
                         (const OpDataType*)param.conv_param.weight()->data(), bias_data, \
-                        this->_ctx.get_compute_stream());
+                        this->_ctx->get_compute_stream());
                 } else {
                     saber_depthwise_conv_act<InDataType, false, false>(inputs[0]->data(), \
                         outputs[0]->mutable_data(), inputs[0]->num(), inputs[0]->channel(), \
                         inputs[0]->height(), inputs[0]->width(), outputs[0]->height(), \
-                        outputs[0]->width(), param.conv_param.weight()->width(), \
-                        param.conv_param.weight()->height(), param.conv_param.stride_w, \
+                        outputs[0]->width(), _kernel_width, \
+                        _kernel_height, param.conv_param.stride_w, \
                         param.conv_param.stride_h, param.conv_param.pad_w, param.conv_param.pad_h,\
                         (const OpDataType*)param.conv_param.weight()->data(), bias_data, \
-                        this->_ctx.get_compute_stream());
+                        this->_ctx->get_compute_stream());
                 }
-
             }
-
         } else if (param.has_eltwise) {
             //std::cout << "In dispatch_func_elt" << std::endl;
             dispatch_func_elt(inputs[0]->data(), outputs[0]->mutable_data(), \
-                _gpu_work_space, bias_data, num, chin, hin, win, \
+                param.conv_param.weight()->data(), bias_data, num, chin, hin, win, \
                 chout, hout, wout,
                     shape_in[1],
                     shape_in[2],
@@ -262,7 +223,7 @@ public:
                     shape_out[1],
                     shape_out[2],
                     shape_out[3], 
-                    kh, kw,
+                    _kernel_height, _kernel_width,
                     param.conv_param.pad_h,              
                     param.conv_param.pad_w,              
                     param.conv_param.stride_h,              
@@ -273,38 +234,97 @@ public:
                     param.conv_param.alpha, 
                     param.conv_param.beta,
                     param.eltwise_param.operation, 
-                    this->_ctx.get_compute_stream()); 
+                    this->_ctx->get_compute_stream());
             } else {
                 dispatch_func(inputs[0]->data(), outputs[0]->mutable_data(), \
-                    _gpu_work_space, bias_data, num, chin, hin, win, \
+                    param.conv_param.weight()->data(), bias_data, num, chin, hin, win, \
                     chout, hout, wout, \
                     shape_in[1],
-                    shape_in[2],
-                    shape_in[3],
-                    shape_out[1],
-                    shape_out[2],
-                    shape_out[3], 
-                    param.conv_param.weight()->height(),
-                    param.conv_param.weight()->width(),
-                    param.conv_param.pad_h,              
-                    param.conv_param.pad_w,              
-                    param.conv_param.stride_h,              
-                    param.conv_param.stride_w,              
-                    param.conv_param.dilation_h,              
-                    param.conv_param.dilation_w, 
-                    param.conv_param.group, 
-                    param.conv_param.alpha, 
-                    param.conv_param.beta, 
-                    this->_ctx.get_compute_stream());                 
+                          shape_in[2],
+                          shape_in[3],
+                          shape_out[1],
+                          shape_out[2],
+                          shape_out[3],
+                          _kernel_height,
+                          _kernel_width,
+                          param.conv_param.pad_h,
+                          param.conv_param.pad_w,
+                          param.conv_param.stride_h,
+                          param.conv_param.stride_w,
+                          param.conv_param.dilation_h,
+                          param.conv_param.dilation_w,
+                          param.conv_param.group,
+                          param.conv_param.alpha,
+                          param.conv_param.beta,
+                          this->_ctx->get_compute_stream());
             }
 
         return SaberSuccess;
     }
+    void trans_weights(const std::vector<DataTensor_in *>& inputs,
+                       std::vector<DataTensor_out *>& outputs,
+                       ConvActiveParam<OpTensor>& param, Context<NV> &ctx) {
+        Tensor<X86, OpDtype, LayOutType_op> trans_weights_host;
+        if (_use_k1s1p0) {
+            return;
+        }
+        if (param.conv_param.group == inputs[0]->channel() && \
+            param.conv_param.group == outputs[0]->channel()){
+            return;
+
+        } else if (param.conv_param.stride_h == 1 &&
+                   param.conv_param.stride_w == 1 &&
+                   _kernel_height == 3 &&
+                   _kernel_width == 3
+                   &&param.conv_param.group == 1) {
+            //Update weights if need
+            Shape weight_shape = param.conv_param.weight()->shape();
+            Tensor<X86, OpDtype, LayOutType_op> new_weight;
+            new_weight.re_alloc(weight_shape);
+            new_weight.copy_from(*(param.conv_param.weight()));
+            OpDataType *weight_data = new_weight.mutable_data();
+
+            int round_in_channel = i_align_up(inputs[0]->channel(),8);
+            int round_out_channel = i_align_up(param.conv_param.weight()->num(),32);
+            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
+            trans_weights_host.re_alloc({weight4x4_size, 1, 1, 1});
+            OpDataType* _host_work_space;
+            _host_work_space = trans_weights_host.mutable_data();
+
+            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.conv_param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);
+            Shape old_shape = param.conv_param.weight()->shape();
+            param.conv_param.mutable_weight()->re_alloc({weight4x4_size, 1, 1, 1});
+            param.conv_param.mutable_weight()->copy_from(trans_weights_host);
+            param.conv_param.mutable_weight()->set_shape(old_shape);
+        } else if(param.conv_param.group == 1) {
+            Shape weight_shape = param.conv_param.weight()->shape();
+            Tensor<X86, OpDtype, LayOutType_op> new_weight;
+            new_weight.re_alloc(weight_shape);
+            new_weight.copy_from(*(param.conv_param.weight()));
+            OpDataType *weight_data = new_weight.mutable_data();
+
+            int weight_size = param.conv_param.weight()->shape().count();
+            trans_weights_host.re_alloc(param.conv_param.weight()->shape());
+            OpDataType* _host_work_space;
+            _host_work_space = trans_weights_host.mutable_data();
+
+            transpose_filter_KCRS_2_CRSK(weight_data, _host_work_space, \
+                                         param.conv_param.weight()->num(), \
+                                         param.conv_param.weight()->channel(), \
+                                         _kernel_height, \
+                                         _kernel_width);
+
+            param.conv_param.mutable_weight()->re_alloc(param.conv_param.weight()->shape());
+            param.conv_param.mutable_weight()->copy_from(trans_weights_host);
+
+        }
+    }
 
 private:
-    OpDataType* _host_work_space;
-    OpDataType* _gpu_work_space;
-    std::function<void(const InDataType*, 
+    int _kernel_height;
+    int _kernel_width;
+
+    std::function<void(const InDataType*,
       OutDataType*,
       const OpDataType*,
       const InDataType*,
@@ -369,24 +389,41 @@ private:
     void conv_gemm_k1s1p0(float* out, const float* img,
                           const float* weights, int out_channel,
                           int in_channel, int img_h, int img_w,
-                          const float* bias, cudaStream_t cuda_stream) {
-        float alpha = 1.0f;
-        float beta = 0.0f;
+                          const float* bias, cudaStream_t cuda_stream,
+                          float a = 1.f, float b = 0.f, bool relu = true) {
+
+        float alpha = a; float beta = b;
         int m = out_channel;
         int k = in_channel;
         int n = img_h * img_w;
         if (ifVec(m, n, k, k, n, n)) {
-            ker_gemm_32x32x32_NN_vec_bias_relu(m, n, k,
-                                           alpha, weights,
-                                           beta, img,
-                                           out, bias,
-                                           cuda_stream);
+            if (relu) {
+                ker_gemm_32x32x32_NN_vec_bias_relu(m, n, k,
+                                                   alpha, weights,
+                                                   beta, img,
+                                                   out, bias,
+                                                   cuda_stream);
+            } else {
+                ker_gemm_32x32x32_NN_vec_bias(m, n, k,
+                                              alpha, weights,
+                                              beta, img,
+                                              out, bias,
+                                              cuda_stream);
+            }
         } else {
-            ker_gemm_32x32x32_NN_bias_relu(m, n, k,
-                                           alpha, weights,
-                                           beta, img,
-                                           out, bias,
-                                           cuda_stream);
+            if (relu) {
+                ker_gemm_32x32x32_NN_bias_relu(m, n, k,
+                                               alpha, weights,
+                                               beta, img,
+                                               out, bias,
+                                               cuda_stream);
+            } else {
+                ker_gemm_32x32x32_NN_bias(m, n, k,
+                                          alpha, weights,
+                                          beta, img,
+                                          out, bias,
+                                          cuda_stream);
+            }
         }
     }
 
diff --git a/saber/funcs/impl/cuda/saber_conv_act_pooling.h b/saber/funcs/impl/cuda/saber_conv_act_pooling.h
index 5f7e757..9761ce4 100644
--- a/saber/funcs/impl/cuda/saber_conv_act_pooling.h
+++ b/saber/funcs/impl/cuda/saber_conv_act_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -47,123 +47,55 @@ public:
     typedef typename DataTensor_out::Dtype OutDataType;
     typedef typename OpTensor::Dtype OpDataType;
 
-    SaberConv2DActPooling() 
-            : _host_work_space(nullptr)
-            , _gpu_work_space(nullptr)
-    {}
+    SaberConv2DActPooling() {}
 
-    ~SaberConv2DActPooling() {
-        if (_host_work_space)
-        {
-            free(_host_work_space);
-        }
-        if (_gpu_work_space)
-        {
-            cudaFree(_gpu_work_space);
-        }
-    }
+    ~SaberConv2DActPooling() {}
 
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ConvActivePoolingParam<OpTensor>& param, Context<NV> &ctx) {
-        this->_ctx = ctx;
-        if (_host_work_space)
-        {
-            free(_host_work_space);
-        }
-        if (_gpu_work_space)
-        {
-            cudaFree(_gpu_work_space);
-        }
+        this->_ctx = &ctx;
+        _kernel_height = param.conv_param.weight()->height();
+        _kernel_width = param.conv_param.weight()->width();
 
         if (param.conv_param.stride_h == 1 && 
             param.conv_param.stride_w == 1 && 
-            param.conv_param.weight()->height() == 3 && 
-            param.conv_param.weight()->width() == 3 &&
-            param.conv_param.group == 1)
-        {
-            //Update weights if need
-            Shape weight_shape = param.conv_param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_op> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.conv_param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
+            _kernel_height == 3 &&
+            _kernel_width == 3 &&
+            param.conv_param.group == 1) {
 
-            int round_in_channel = i_align_up(inputs[0]->channel(),8);
-            int round_out_channel = i_align_up(param.conv_param.weight()->num(),32);
-            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
-            _host_work_space = (OpDataType*)malloc(weight4x4_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight4x4_size*sizeof(OpDataType)));
-            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.conv_param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);    
-            CUDA_CHECK(cudaMemcpy((void*)_gpu_work_space,
-                          (void*)_host_work_space,
-                          weight4x4_size*sizeof(OpDataType),
-                          cudaMemcpyHostToDevice));
-                
             dispatch_func = winograd_conv_relu_pooling<InDataType, OpDataType>;
-
-        }
-        else if(param.conv_param.group == 1)
-        {
-            //Update weights if need
-            Shape weight_shape = param.conv_param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_op> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.conv_param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
-
-            int weight_size = param.conv_param.weight()->shape().count();
-            _host_work_space = (OpDataType*)malloc(weight_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight_size * sizeof(OpDataType)));
-
-            //const OpDtype *weight_data = param.conv_param.weight()->data();
-            transpose_filter_KCRS_2_CRSK(weight_data, _host_work_space, \
-                                         param.conv_param.weight()->num(), \
-                                         param.conv_param.weight()->channel(), \
-                                         param.conv_param.weight()->height(), \
-                                         param.conv_param.weight()->width());
-            CUDA_CHECK(cudaMemcpy( (void*)_gpu_work_space, \
-                                   (void*)_host_work_space, \
-                                   weight_size * sizeof(OpDataType), \
-                                   cudaMemcpyHostToDevice ));
-
+        } else if(param.conv_param.group == 1) {
             const int K = param.conv_param.weight()->num();
-            if (K % 4 == 0)
-            {
+            if (K % 4 == 0) {
                 if (param.conv_param.bias()->size() > 0)
                     dispatch_func = direct_conv_bias_relu_maxpool2k2s0p_Kdivis4<InDataType, OpDataType>;
                 else
                     return SaberUnImplError;
-            }
-            else
-            {   // TODO: would merge the bias(with/without) version
+            } else {   // TODO: would merge the bias(with/without) version
                 if (param.conv_param.bias()->size() > 0)
                     dispatch_func = direct_conv_bias_relu_maxpool2k2s0p_Kindiv4<InDataType, OpDataType>;
                 else
                     return SaberUnImplError;
             }      
+        } else {
+            return SaberUnImplError;
         }
-        else
-        {
-          return SaberUnImplError;
-        }
+        trans_weights(inputs, outputs, param, ctx);
         cudaDeviceSynchronize();
         return create(inputs, outputs, param, ctx);
-
     }
-
-
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ConvActivePoolingParam<OpTensor>& param, Context<NV>& ctx) {
 
         int input_dim = inputs[0]->height(); // P
-        int kernel_exten = param.conv_param.dilation_h * (param.conv_param.weight()->height() - 1) + 1;
+        int kernel_exten = param.conv_param.dilation_h * (_kernel_height - 1) + 1;
         _conv_out_height = (input_dim + 2 * param.conv_param.pad_h - kernel_exten)
                          / param.conv_param.stride_h + 1;
 
         input_dim = inputs[0]->width(); // Q
-        kernel_exten = param.conv_param.dilation_w * (param.conv_param.weight()->width() - 1) + 1;
+        kernel_exten = param.conv_param.dilation_w * (_kernel_width - 1) + 1;
         _conv_out_width = (input_dim + 2 * param.conv_param.pad_w - kernel_exten)
                      / param.conv_param.stride_w + 1;
                      
@@ -174,7 +106,6 @@ public:
                           std::vector<DataTensor_out*>& outputs,
                           ConvActivePoolingParam<OpTensor>& param)
     {
-      //cudaDeviceSynchronize();
             Shape shape_in = inputs[0]->valid_shape();
             Shape shape_out = outputs[0]->valid_shape();
             const InDataType* bias_data = nullptr;
@@ -183,7 +114,7 @@ public:
             }
 
             dispatch_func(inputs[0]->data(), outputs[0]->mutable_data(),
-                    _gpu_work_space,
+                    param.conv_param.weight()->data(),
                     bias_data,
                     inputs[0]->num(),
                     inputs[0]->channel(),
@@ -198,8 +129,8 @@ public:
                     shape_out[1],
                     shape_out[2],
                     shape_out[3], 
-                    param.conv_param.weight()->height(),
-                    param.conv_param.weight()->width(),
+                    _kernel_height,
+                    _kernel_width,
                     param.conv_param.pad_h,              
                     param.conv_param.pad_w,              
                     param.conv_param.stride_h,              
@@ -209,16 +140,68 @@ public:
                     param.conv_param.group, 
                     param.conv_param.alpha, 
                     param.conv_param.beta, 
-                    this->_ctx.get_compute_stream()); 
+                    this->_ctx->get_compute_stream());
                     
         CUDA_CHECK(cudaGetLastError());
+        return SaberSuccess;
+    }
+    void trans_weights(const std::vector<DataTensor_in *>& inputs,
+                       std::vector<DataTensor_out *>& outputs,
+                       ConvActivePoolingParam<OpTensor>& param, Context<NV> &ctx) {
+        Tensor<X86, OpDtype, LayOutType_op> trans_weights_host;
+        OpDataType* host_work_space;
+        if (param.conv_param.stride_h == 1 &&
+            param.conv_param.stride_w == 1 &&
+            _kernel_height == 3 &&
+            _kernel_width == 3 &&
+            param.conv_param.group == 1)
+        {
+            //Update weights if need
+            Shape weight_shape = param.conv_param.weight()->shape();
+            Tensor<X86, OpDtype, LayOutType_op> new_weight;
+            new_weight.re_alloc(weight_shape);
+            new_weight.copy_from(*(param.conv_param.weight()));
+            OpDataType *weight_data = new_weight.mutable_data();
 
+            int round_in_channel = i_align_up(inputs[0]->channel(),8);
+            int round_out_channel = i_align_up(param.conv_param.weight()->num(),32);
+            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
+            trans_weights_host.re_alloc({weight4x4_size, 1, 1, 1});
+            host_work_space = trans_weights_host.mutable_data();
 
-        return SaberSuccess;
+            transform_3x3_weight_2_4x4(weight_data, host_work_space, param.conv_param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);
+
+            Shape old_shape = param.conv_param.weight()->shape();
+            param.conv_param.mutable_weight()->re_alloc({weight4x4_size, 1, 1, 1});
+            param.conv_param.mutable_weight()->copy_from(trans_weights_host);
+            param.conv_param.mutable_weight()->set_shape(old_shape);
+        } else if(param.conv_param.group == 1) {
+            //Update weights if need
+            Shape weight_shape = param.conv_param.weight()->shape();
+            Tensor<X86, OpDtype, LayOutType_op> new_weight;
+            new_weight.re_alloc(weight_shape);
+            new_weight.copy_from(*(param.conv_param.weight()));
+            OpDataType *weight_data = new_weight.mutable_data();
+
+            int weight_size = param.conv_param.weight()->shape().count();
+            trans_weights_host.re_alloc(param.conv_param.weight()->shape());
+            host_work_space = trans_weights_host.mutable_data();
+
+            transpose_filter_KCRS_2_CRSK(weight_data, host_work_space, \
+                                         param.conv_param.weight()->num(), \
+                                         param.conv_param.weight()->channel(), \
+                                         _kernel_height, \
+                                         _kernel_width);
+
+            param.conv_param.mutable_weight()->re_alloc(param.conv_param.weight()->shape());
+            param.conv_param.mutable_weight()->copy_from(trans_weights_host);
+
+        }
     }
 private:
-    OpDataType* _host_work_space;
-    OpDataType* _gpu_work_space;
+
+    int _kernel_height;
+    int _kernel_width;
     int _conv_out_height;
     int _conv_out_width;
     std::function<void(const InDataType*, 
diff --git a/saber/funcs/impl/cuda/saber_conv_eltwise.h b/saber/funcs/impl/cuda/saber_conv_eltwise.h
deleted file mode 100644
index 240c976..0000000
--- a/saber/funcs/impl/cuda/saber_conv_eltwise.h
+++ /dev/null
@@ -1,192 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CONV_ELTWISE_H
-#define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CONV_ELTWISE_H
-
-#include <vector>
-#include "saber/funcs/impl/impl_conv_eltwise.h"
-#include "saber/funcs/impl/cuda/base/sass_funcs.h"
-#include "saber/funcs/funcs_utils.h"
-
-namespace anakin{
-
-namespace saber{
-
-template <DataType OpDtype,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
-class SaberConv2DEltWise<NV, OpDtype, inDtype, outDtype,\
-    LayOutType_op, LayOutType_in, LayOutType_out> : \
-    public ImplBase<
-        Tensor<NV, inDtype, LayOutType_in>, 
-        Tensor<NV, outDtype, LayOutType_out>,
-        Tensor<NV, OpDtype, LayOutType_op>,
-        ConvActiveParam<Tensor<NV, OpDtype, LayOutType_op> > > 
-{
-public:
-    typedef Tensor<NV, inDtype, LayOutType_in> DataTensor_in;
-    typedef Tensor<NV, outDtype, LayOutType_out> DataTensor_out;
-    typedef Tensor<NV, OpDtype, LayOutType_op> OpTensor;
-    typedef typename DataTensor_in::Dtype InDataType;
-    typedef typename DataTensor_out::Dtype OutDataType;
-    typedef typename OpTensor::Dtype OpDataType;
-
-    SaberConv2DEltWise():_host_work_space(nullptr), _gpu_work_space(nullptr)
-    {}
-
-    ~SaberConv2DEltWise() {
-        if (_host_work_space)
-        {
-            free(_host_work_space);
-        }
-        if (_gpu_work_space)
-        {
-            cudaFree(_gpu_work_space);
-        }
-    }
-
-    virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
-                            std::vector<DataTensor_out *>& outputs,
-                            ConvActiveParam<OpTensor>& param, Context<NV> &ctx)  {
-        this->_ctx = ctx;
-        //This is an ugly impl for now
-        if (param.conv_param.stride_h == 1 && 
-            param.conv_param.stride_w == 1 && 
-            param.conv_param.weight()->height() == 3 && 
-            param.conv_param.weight()->width() == 3)
-        {
-            //Update weights if need
-            Shape weight_shape = param.conv_param.weight()->shape();
-            Tensor<X86, OpDtype, LayOutType_op> new_weight;
-            new_weight.re_alloc(weight_shape);
-            new_weight.copy_from(*(param.conv_param.weight()));
-            OpDataType *weight_data = new_weight.mutable_data();
-
-            int round_in_channel = i_align_up(inputs[0]->channel(),8);
-            int round_out_channel = i_align_up(param.conv_param.weight()->num(),32);
-
-            int weight4x4_size = round_in_channel * round_out_channel * 4 * 4;
-            _host_work_space = (OpDataType*)malloc(weight4x4_size * sizeof(OpDataType));
-            CUDA_CHECK(cudaMalloc((void**)&_gpu_work_space, weight4x4_size*sizeof(OpDataType)));
-            transform_3x3_weight_2_4x4(weight_data, _host_work_space, param.conv_param.weight()->num(), round_out_channel, inputs[0]->channel(), round_in_channel);    
-            CUDA_CHECK(cudaMemcpy((void*)_gpu_work_space,
-                          (void*)_host_work_space,
-                          weight4x4_size*sizeof(OpDataType),
-                          cudaMemcpyHostToDevice));
-                
-            dispatch_func = winograd_conv_eltwise<InDataType, OpDataType>;
-
-        }else{
-          return SaberUnImplError;
-        }
-        cudaDeviceSynchronize();
-        return create(inputs, outputs, param, ctx);
-    }
-
-    virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
-                            std::vector<DataTensor_out *>& outputs,
-                            ConvActiveParam<OpTensor>& param, Context<NV>& ctx) {
-        return SaberSuccess;
-    }
-
-    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
-                          std::vector<DataTensor_out*>& outputs,
-                          ConvActiveParam<OpTensor>& param){
-        //err code?
-            Shape shape_in = inputs[0]->valid_shape();
-            Shape shape_out = outputs[0]->valid_shape();
-            const InDataType* bias_data = NULL;
-            if (param.conv_param.bias()->size() > 0) {
-                bias_data = param.conv_param.bias()->data();
-            }
-            dispatch_func(inputs[0]->data(), outputs[0]->mutable_data(),
-                    _gpu_work_space,
-                    bias_data,
-                    inputs[0]->num(),
-                    inputs[0]->channel(),
-                    inputs[0]->height(),
-                    inputs[0]->width(),
-                    outputs[0]->channel(),
-                    outputs[0]->height(),
-                    outputs[0]->width(),
-                    shape_in[1],
-                    shape_in[2],
-                    shape_in[3],
-                    shape_out[1],
-                    shape_out[2],
-                    shape_out[3], 
-                    param.conv_param.weight()->height(),
-                    param.conv_param.weight()->width(),
-                    param.conv_param.pad_h,              
-                    param.conv_param.pad_w,              
-                    param.conv_param.stride_h,              
-                    param.conv_param.stride_w,              
-                    param.conv_param.dilation_h,              
-                    param.conv_param.dilation_w, 
-                    param.conv_param.group, 
-                    param.conv_param.alpha, 
-                    param.conv_param.beta,
-                    param.eltwise_param.operation, 
-                    this->_ctx.get_compute_stream()); 
-
-        CUDA_CHECK(cudaGetLastError()); 
-        return SaberSuccess;
-    }
-
-private:
-    OpDataType* _host_work_space;
-    OpDataType* _gpu_work_space;
-    std::function<void(const InDataType*, 
-      OutDataType*,
-      const OpDataType*,
-      const InDataType*,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      int,
-      float,
-      float, 
-      EltwiseType,
-      cudaStream_t)> dispatch_func;
-};
-template class SaberConv2DEltWise<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
-}
-
-}
-
-
-#endif //ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CONV_ELTWISE_H
diff --git a/saber/funcs/impl/cuda/saber_crop.h b/saber/funcs/impl/cuda/saber_crop.h
index 04e7db2..06a878c 100644
--- a/saber/funcs/impl/cuda/saber_crop.h
+++ b/saber/funcs/impl/cuda/saber_crop.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -55,7 +55,7 @@ public:
                         std::vector<DataTensor_out *>& outputs,
                         CropParam<OpTensor>& param, 
                         Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_ctc_align.h b/saber/funcs/impl/cuda/saber_ctc_align.h
index d22b60e..7d64f1f 100644
--- a/saber/funcs/impl/cuda/saber_ctc_align.h
+++ b/saber/funcs/impl/cuda/saber_ctc_align.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+ */
 
 #ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CTC_ALIGN_H
 #define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_CTC_ALIGN_H
@@ -54,7 +55,7 @@ public:
                         std::vector<DataTensor_out *>& outputs,
                         CtcAlignParam<OpTensor>& param, 
                         Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         Shape offset_shape = {inputs[0]->num(), 1, 1, 1};
         _in_offset.re_alloc(offset_shape);
         _out_offset.re_alloc(offset_shape);
diff --git a/saber/funcs/impl/cuda/saber_deconv.h b/saber/funcs/impl/cuda/saber_deconv.h
index e44443e..1991ad9 100644
--- a/saber/funcs/impl/cuda/saber_deconv.h
+++ b/saber/funcs/impl/cuda/saber_deconv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             ConvParam<OpTensor>& param, Context<NV>& ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         return create(inputs, outputs, param, ctx);
     }
@@ -72,8 +72,8 @@ public:
         if (_use_k4_s2_p1) {
             int in_channel = inputs[0]->channel();
             int out_channel = outputs[0]->channel();
-            scale_to_new_tensor_k4_s2_p1_decov<4>(new_weights_dev,
-                                               param.weight(), in_channel, out_channel);
+            scale_to_new_tensor_k4_s2_p1_deconv<4>(param.mutable_weight(),
+                                                   in_channel, out_channel);
 //            LOG(INFO)<<"scale weights finished!!";
         } 
         return SaberSuccess;
@@ -84,7 +84,6 @@ public:
                           ConvParam<OpTensor>& param);
 private:
     bool _use_k4_s2_p1;
-    OpTensor new_weights_dev;
 };
 template class SaberDeconv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
 
diff --git a/saber/funcs/impl/cuda/saber_deconv_act.h b/saber/funcs/impl/cuda/saber_deconv_act.h
index d6cb71f..4859e7f 100644
--- a/saber/funcs/impl/cuda/saber_deconv_act.h
+++ b/saber/funcs/impl/cuda/saber_deconv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             ConvActiveParam<OpTensor>& param, Context<NV>& ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -70,10 +70,8 @@ public:
         if (_use_k4_s2_p1) {
             int in_channel = inputs[0]->channel();
             int out_channel = outputs[0]->channel();
-            scale_to_new_tensor_k4_s2_p1_decov<4>(new_weights_dev,
-                                               param.conv_param.weight(),
+            scale_to_new_tensor_k4_s2_p1_deconv<4>(param.conv_param.mutable_weight(),
                                                in_channel, out_channel);
-//            LOG(INFO)<<"scale weights finished!!";
         }
         //update_weights(param);
 
@@ -85,7 +83,7 @@ public:
                           ConvActiveParam<OpTensor>& param);
 private:
     bool _use_k4_s2_p1;
-    OpTensor new_weights_dev;
+
 };
 template class SaberDeconv2DAct<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
 } // namespace saber
diff --git a/saber/funcs/impl/cuda/saber_deformable_conv.h b/saber/funcs/impl/cuda/saber_deformable_conv.h
index c888846..3e0d0d9 100644
--- a/saber/funcs/impl/cuda/saber_deformable_conv.h
+++ b/saber/funcs/impl/cuda/saber_deformable_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -73,9 +73,9 @@ public:
                             DeformableConvParam<OpTensor>& param, Context<NV>& ctx) {
 
         // ---- init cudnn resources ----
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         CUBLAS_CHECK(cublasCreate(&_handle));
-        CUBLAS_CHECK(cublasSetStream(_handle, this->_ctx.get_compute_stream()));
+        CUBLAS_CHECK(cublasSetStream(_handle, this->_ctx->get_compute_stream()));
 
         _kernel_dim = param.weight()->channel()
                       * param.weight()->height()
@@ -99,13 +99,13 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             DeformableConvParam<OpTensor>& param, Context<NV>& ctx) {
 
-        if (!(ctx == this->_ctx)) {
-            this->_ctx = ctx;
+        if (!(&ctx == this->_ctx)) {
+            this->_ctx = &ctx;
             if (_handle != NULL) {
                 CUBLAS_CHECK(cublasDestroy(_handle));
             }
             CUBLAS_CHECK(cublasCreate(&_handle));
-            CUBLAS_CHECK(cublasSetStream(_handle, this->_ctx.get_compute_stream()));
+            CUBLAS_CHECK(cublasSetStream(_handle, this->_ctx->get_compute_stream()));
         }
 
         int in_channel = inputs[0]->channel();
diff --git a/saber/funcs/impl/cuda/saber_detection_output.h b/saber/funcs/impl/cuda/saber_detection_output.h
index 350a017..9463fa3 100644
--- a/saber/funcs/impl/cuda/saber_detection_output.h
+++ b/saber/funcs/impl/cuda/saber_detection_output.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -59,7 +59,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             DetectionOutputParam<OpTensor>& param, Context<NV>& ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_eltwise.h b/saber/funcs/impl/cuda/saber_eltwise.h
index 8c63676..b37a5a5 100644
--- a/saber/funcs/impl/cuda/saber_eltwise.h
+++ b/saber/funcs/impl/cuda/saber_eltwise.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
                          EltwiseParam<OpTensor> &param,
                          Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -60,7 +60,7 @@ public:
                            std::vector<DataTensor_out*>& outputs,
                            EltwiseParam<OpTensor> &param,
                            Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         if ((param.operation == Eltwise_max) && (outputs.size() == 1)) {
             _max_idx.reshape(inputs[0]->shape());
         }
diff --git a/saber/funcs/impl/cuda/saber_eltwise_act.h b/saber/funcs/impl/cuda/saber_eltwise_act.h
index 57e8ff2..72abea5 100644
--- a/saber/funcs/impl/cuda/saber_eltwise_act.h
+++ b/saber/funcs/impl/cuda/saber_eltwise_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              EltwiseActiveParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -62,7 +62,7 @@ public:
                                EltwiseActiveParam<OpTensor> &param,
                                Context<NV> &ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         EltwiseParam<OpTensor> &elt_param = param.eltwise_param;
         if ((elt_param.operation == Eltwise_max) && (outputs.size() == 1)) {
             _max_idx.reshape(inputs[0]->shape());
diff --git a/saber/funcs/impl/cuda/saber_embedding.h b/saber/funcs/impl/cuda/saber_embedding.h
index 9892621..3670803 100644
--- a/saber/funcs/impl/cuda/saber_embedding.h
+++ b/saber/funcs/impl/cuda/saber_embedding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             EmbeddingParam<OpTensor>& param, Context<NV>& ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         
         return SaberSuccess;
     }
@@ -60,7 +60,7 @@ public:
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             EmbeddingParam<OpTensor>& param, Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
     
diff --git a/saber/funcs/impl/cuda/saber_fc.h b/saber/funcs/impl/cuda/saber_fc.h
index 038a7d2..ae93614 100644
--- a/saber/funcs/impl/cuda/saber_fc.h
+++ b/saber/funcs/impl/cuda/saber_fc.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -51,7 +51,7 @@ public:
                              std::vector<DataTensor_out *>& outputs,
                              FcParam<OpTensor>& param, Context<NV>& ctx){
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -59,8 +59,8 @@ public:
                                std::vector<DataTensor_out *>& outputs,
                                FcParam<OpTensor>& param, Context<NV>& ctx){
 
-        if (!(ctx == this->_ctx)) {
-            this->_ctx = ctx;
+        if (!(&ctx == this->_ctx)) {
+            this->_ctx = &ctx;
         }
 
         Shape shape_out = inputs[0]->valid_shape();
diff --git a/saber/funcs/impl/cuda/saber_gru.h b/saber/funcs/impl/cuda/saber_gru.h
index d22c212..990d6e7 100644
--- a/saber/funcs/impl/cuda/saber_gru.h
+++ b/saber/funcs/impl/cuda/saber_gru.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -16,23 +16,182 @@
 #ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_GRU_H
 #define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_GRU_H
 #include "saber/funcs/impl/impl_gru.h"
-
+#include "saber/funcs/impl/cuda/base/sass_funcs.h"
 namespace anakin {
 
 namespace saber {
 
+template <typename Dtype>
+void trans_map2in_cfunc(const Dtype*  input, Dtype* output, int word_size,int seq_sum, cudaStream_t stream,int *dev_map_vec);
+
+template <typename Dtype>
+void trans_map2out_cfunc(const Dtype*  input, Dtype* output, int word_size,int seq_sum, cudaStream_t stream,int *dev_map_vec);
+
+class SeqSortedseqTranseUtil {
+
+public:
+
+    SeqSortedseqTranseUtil(bool is_reverse = false, bool is_bi = false)
+        : _is_reverse(is_reverse),
+          _is_bi(is_bi),
+            _dev_map_vec(nullptr),
+          _dev_map_vec_length(0)
+
+    {};
+
+    ~SeqSortedseqTranseUtil() {
+        if (_dev_map_vec != nullptr) {
+            CUDA_CHECK(cudaFree(_dev_map_vec));
+        }
+    };
+
+    void print_vec(float* in, int size, const char* perfix) {
+        for (int i = 0; i < size; i++) {
+            printf("[%s] %d = %f\n", perfix, i, in[i]);
+        }
+    }
+    template <typename Dtype>
+    void seq_2_sorted_seq(const Dtype*  input, Dtype* output, int word_size, cudaStream_t stream) {
+        int seq_sum = _map_vec.size();
+        trans_map2out_cfunc(input,output,word_size,seq_sum,stream,_dev_map_vec);
+    }
+    template <typename Dtype>
+    void hidden_2_sorted_hidden(const Dtype*  input, Dtype* output, int hidden_size) {
+        //        _map_vec.resize(word_sum);
+        int batch_size = _length_index.size();
+        //        std::cout << "word_sum = " << word_sum << std::endl;
+
+        for (int ori_word_id = 0; ori_word_id < batch_size; ++ori_word_id) {
+            //can param
+            int word_start = ori_word_id * hidden_size;
+            int maped_id = _length_index[ori_word_id];
+            int maped_start = maped_id * hidden_size;
+
+            for (int word_vec_offset = 0; word_vec_offset < hidden_size; ++word_vec_offset) {
+                //                std::cout<<maped_start + word_vec_offset<<" --> "<<word_start + word_vec_offset<<" , = "<<input[maped_start + word_vec_offset]<<std::endl;
+
+                output[word_start + word_vec_offset] = input[maped_start + word_vec_offset];
+
+            }
+        }
+    }
+    template <typename Dtype>
+    void sorted_seq_2_seq(const Dtype* input, Dtype* output, int hidden_size, cudaStream_t stream) {
+        int seq_sum = _map_vec.size();
+        trans_map2in_cfunc(input,output,hidden_size,seq_sum,stream,_dev_map_vec);
+    }
+
+    bool get_sorted_map(std::vector<int>& offset_vec,
+                        std::vector<int>& emit_offset_vec, int& emit_length, cudaStream_t stream_id) {
+        int batch_size = offset_vec.size() - 1;
+        int word_sum = offset_vec[offset_vec.size() - 1];
+        std::vector<int>length_vec(batch_size);
+        _length_index.resize(batch_size);
+
+        if (batch_size == 1) {
+            emit_length = offset_vec[1] - offset_vec[0];
+            emit_offset_vec.resize(emit_length + 1);
+
+            for (int i = 0; i <= emit_length; i++) {
+                emit_offset_vec[i] = i;
+            }
+
+            return false;
+        }
+
+        int max_len = 0;
+
+        for (int i = 0; i < offset_vec.size() - 1; ++i) {
+            int len = offset_vec[i + 1] - offset_vec[i];
+            max_len = max_len > len ? max_len : len;
+            length_vec[i] = len;
+            _length_index[i] = i;
+        }
+
+        emit_length = max_len;
+
+        if (max_len == 1) {
+            emit_offset_vec.push_back(0);
+            emit_offset_vec.push_back(emit_length * batch_size);
+            return false;
+        }
+
+        std::sort(_length_index.begin(), _length_index.end(), [&length_vec](int i1, int i2) {
+            return length_vec[i1] > length_vec[i2];
+        });
+
+        emit_offset_vec.resize(max_len + 1);
+        _map_vec.resize(word_sum);
+
+        if (word_sum > _dev_map_vec_length) {
+            if (_dev_map_vec != nullptr) {
+                CUDA_CHECK(cudaFree(_dev_map_vec));
+            }
+
+            CUDA_CHECK(cudaMalloc(&_dev_map_vec, sizeof(int)*word_sum));
+            _dev_map_vec_length = word_sum;
+        }
+
+        int target_word_id = 0;
+        std::vector<int> length_vec_cnt = length_vec;
+
+        for (int word_id_in_seq = 0; word_id_in_seq < max_len; word_id_in_seq++) {
+            emit_offset_vec[word_id_in_seq] = target_word_id;
+
+            for (int batch_id = 0; batch_id < batch_size; batch_id++) {
+                int old_batch_id = _length_index[batch_id];
+
+                if (length_vec_cnt[old_batch_id] > 0) {
+                    int inner_word_id_in_seq = word_id_in_seq;
+
+                    if (_is_reverse) {
+                        inner_word_id_in_seq = length_vec[old_batch_id] - 1 - word_id_in_seq;
+                    }
+
+                    int old_word_id = offset_vec[old_batch_id] + inner_word_id_in_seq;
+                    _map_vec[old_word_id] = target_word_id;
+                    length_vec_cnt[old_batch_id]--;
+                    target_word_id++;
+                } else {
+
+                    break;
+                }
+            }
+        }
+
+
+        CUDA_CHECK(cudaMemcpyAsync(_dev_map_vec, _map_vec.data(), sizeof(int)*word_sum,
+                                   cudaMemcpyHostToDevice, stream_id));
+
+        emit_offset_vec[max_len] = word_sum;
+        return true;
+    }
+
+private:
+
+    //    std::vector<int> _length_vec;
+    std::vector<int> _length_index;
+    std::vector<int> _map_vec;
+
+    int* _dev_map_vec;
+    int _dev_map_vec_length;
+    bool _is_reverse;
+    bool _is_bi;
+
+};
+
 template <DataType OpDtype,
-            DataType inDtype,
-            DataType outDtype,
-            typename LayOutType_op,
-            typename LayOutType_in,
-            typename LayOutType_out>
-class SaberGru<NV, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>:\
-    public ImplBase<
-        Tensor<NV, inDtype, LayOutType_in>, \
-        Tensor<NV, outDtype, LayOutType_out>, \
-        Tensor<NV, OpDtype, LayOutType_op>, \
-        GruParam<Tensor<NV, OpDtype, LayOutType_op>>> {
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+class SaberGru<NV, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>: \
+    public ImplBase <
+    Tensor<NV, inDtype, LayOutType_in>, \
+    Tensor<NV, outDtype, LayOutType_out>, \
+    Tensor<NV, OpDtype, LayOutType_op>, \
+    GruParam<Tensor<NV, OpDtype, LayOutType_op> >> {
 
 public:
     typedef Tensor<NV, inDtype, LayOutType_in> DataTensor_in;
@@ -49,15 +208,20 @@ public:
             CUBLAS_CHECK(cublasDestroy(_cublas_handle));
         }
     }
-    
+
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
-        std::vector<DataTensor_out*>& outputs, \
-        GruParam <OpTensor>& gru_param, Context<NV>& ctx) {
+                             std::vector<DataTensor_out*>& outputs, \
+                             GruParam <OpTensor>& gru_param, Context<NV>& ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         CUBLAS_CHECK(cublasCreate(&_cublas_handle));
-        CUBLAS_CHECK(cublasSetStream(_cublas_handle, this->_ctx.get_compute_stream()));
-        if(gru_param.formula==GRU_ORIGIN) {
+        CUBLAS_CHECK(cublasSetStream(_cublas_handle, this->_ctx->get_compute_stream()));
+        if(gru_param.init_hidden()!= nullptr){
+            CHECK_EQ(1,0)<<"not support init_hidden now";
+        }
+
+        if (gru_param.formula == GRU_ORIGIN) {
+
             _hidden_size = gru_param.bias()->valid_size() / 3;
 
             int weights_bias_size = _hidden_size * 3;
@@ -70,32 +234,31 @@ public:
             _weights_bias.try_expand_size(weights_bias_size);
 
             int size_data_type = sizeof(InDataType);
-//            memcpy(_weights_i2h.mutable_data(), gru_param.weight()->data(),
-//                   size_data_type * weights_i2h_size);
-//            memcpy(_weights_h2h.mutable_data(), gru_param.weight()->data() + weights_i2h_size,
-//                   size_data_type * weights_h2h_size);
-//            memcpy(_weights_bias.mutable_data(), gru_param.bias()->data(),
-//                   size_data_type * weights_bias_size);
-
-            CUDA_CHECK(cudaMemcpy(_weights_i2h.mutable_data(), gru_param.weight()->data(), size_data_type * weights_i2h_size
-                    ,cudaMemcpyDeviceToDevice));
+
+            CUDA_CHECK(cudaMemcpy(_weights_i2h.mutable_data(), gru_param.weight()->data(),
+                                  size_data_type * weights_i2h_size
+                                  , cudaMemcpyDeviceToDevice));
             CUDA_CHECK(cudaMemcpy(_weights_h2h.mutable_data(), gru_param.weight()->data() + weights_i2h_size,
-                                  size_data_type * weights_h2h_size,cudaMemcpyDeviceToDevice));
-            CUDA_CHECK(cudaMemcpy(_weights_bias.mutable_data(), gru_param.bias()->data(), size_data_type * weights_bias_size
-                    ,cudaMemcpyDeviceToDevice));
+                                  size_data_type * weights_h2h_size, cudaMemcpyDeviceToDevice));
+            CUDA_CHECK(cudaMemcpy(_weights_bias.mutable_data(), gru_param.bias()->data(),
+                                  size_data_type * weights_bias_size
+                                  , cudaMemcpyDeviceToDevice));
+            _seq_util = SeqSortedseqTranseUtil(gru_param.is_reverse);
+
         }
+
         return create(inputs, outputs, gru_param, ctx);
     }
 
     virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs, \
-        std::vector<DataTensor_out*>& outputs, \
-        GruParam<OpTensor>& gru_param, Context<NV>& ctx) {
+                               std::vector<DataTensor_out*>& outputs, \
+                               GruParam<OpTensor>& gru_param, Context<NV>& ctx) {
 
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_cublas_handle != NULL) {
                 CUBLAS_CHECK(cublasDestroy(_cublas_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
@@ -103,6 +266,13 @@ public:
             CUBLAS_CHECK(cublasSetStream(_cublas_handle, cuda_stream));
         }
 
+        int batch_size = inputs[0]->get_seq_offset().size() - 1;
+        int sequence = inputs[0]->num();
+        _gemm_wx = saber_find_fast_sass_gemm(false, false, sequence * batch_size, 3 * _hidden_size,
+                                             _word_size);
+        _gemm_wh_2 = saber_find_fast_sass_gemm(false, false, batch_size, 2 * _hidden_size, _hidden_size);
+
+        _gemm_wh_o = saber_find_fast_sass_gemm(false, false, batch_size, 1 * _hidden_size, _hidden_size);
         return SaberSuccess;
     }
 
@@ -113,18 +283,21 @@ public:
 
 private:
     cublasHandle_t  _cublas_handle;
-/**
- * for hw2seq
- */
+    /**
+     * for hw2seq
+     */
     Tensor<NV, inDtype, LayOutType_in> _temp_tensor_in;
     Tensor<NV, inDtype, LayOutType_in> _temp_tensor_out;
     Tensor<NV, inDtype, LayOutType_in> _temp_WX;
     Tensor<NV, inDtype, LayOutType_in> _temp_WH;
+    Tensor<NV, inDtype, LayOutType_in> _temp_WHR;
+
+    Tensor<NV, inDtype, LayOutType_in> _temp_zero;
 
     Tensor<NV, AK_INT32, LayOutType_in> _temp_vector_offset;
     Tensor<X86, AK_INT32, LayOutType_in> _temp_map_host;
     Tensor<NV, AK_INT32, LayOutType_in> _temp_map_dev;
-
+    SeqSortedseqTranseUtil _seq_util;
     int _word_size;
     int _hidden_size;
 
@@ -132,20 +305,34 @@ private:
     OpTensor _weights_h2h;
     OpTensor _weights_bias;
 
+    std::function<void(const int, const int, const int,
+                       const float, const float*, const float,
+                       const float*, float*, cudaStream_t)> _gemm_wx;
+
+    std::function<void(const int, const int, const int,
+                       const float, const float*, const float,
+                       const float*, float*, cudaStream_t)> _gemm_wh_2;
+
+    std::function<void(const int, const int, const int,
+                       const float, const float*, const float,
+                       const float*, float*, cudaStream_t)> _gemm_wh_o;
+
+    typedef std::function<OpDataType(OpDataType)> ActFunction;
+
     void seq2hw(std::vector<DataTensor_out*> outputs, std::vector<DataTensor_in*> inputs,
-                GruParam<OpTensor>& param, int hidden_size,void* real_temp_out);
-/**
- * dim2 input to seq,batch,wordsize
- * @param inputs
- * @param param
- * @param word_size
- * @param sequence
- * @param out_sequence
- * @param ctx
- * @return sequence length
- */
+                GruParam<OpTensor>& param, int hidden_size, void* real_temp_out);
+    /**
+     * dim2 input to seq,batch,wordsize
+     * @param inputs
+     * @param param
+     * @param word_size
+     * @param sequence
+     * @param out_sequence
+     * @param ctx
+     * @return sequence length
+     */
     const InDataType* hw2seq(std::vector<DataTensor_in*> inputs, GruParam<OpTensor>& param,
-                            int word_size, int hiddensize, int& sequence_len);
+                             int word_size, int hiddensize, int& sequence_len);
 
     SaberStatus gru_cudnn(const std::vector<DataTensor_in*> inputs,
                           std::vector<DataTensor_out*> outputs,
diff --git a/saber/funcs/impl/cuda/saber_im2sequence.h b/saber/funcs/impl/cuda/saber_im2sequence.h
index 1a377a1..0fb6bf1 100644
--- a/saber/funcs/impl/cuda/saber_im2sequence.h
+++ b/saber/funcs/impl/cuda/saber_im2sequence.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              Im2SequenceParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_layer_norm.h b/saber/funcs/impl/cuda/saber_layer_norm.h
index 8cd2061..960446b 100644
--- a/saber/funcs/impl/cuda/saber_layer_norm.h
+++ b/saber/funcs/impl/cuda/saber_layer_norm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              LayerNormParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_lrn.h b/saber/funcs/impl/cuda/saber_lrn.h
index 3125287..bd0619b 100644
--- a/saber/funcs/impl/cuda/saber_lrn.h
+++ b/saber/funcs/impl/cuda/saber_lrn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              LrnParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_lstm.h b/saber/funcs/impl/cuda/saber_lstm.h
new file mode 100644
index 0000000..9717e1d
--- /dev/null
+++ b/saber/funcs/impl/cuda/saber_lstm.h
@@ -0,0 +1,83 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_LSTM_H
+#define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_LSTM_H
+#include "saber/funcs/impl/impl_lstm.h"
+
+namespace anakin {
+
+    namespace saber {
+
+        template <DataType OpDtype,
+                DataType inDtype,
+                DataType outDtype,
+                typename LayOutType_op,
+                typename LayOutType_in,
+                typename LayOutType_out>
+        class SaberLstm<NV, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>:\
+    public ImplBase<
+                Tensor<NV, inDtype, LayOutType_in>, \
+        Tensor<NV, outDtype, LayOutType_out>, \
+        Tensor<NV, OpDtype, LayOutType_op>, \
+        LstmParam<Tensor<NV, OpDtype, LayOutType_op>>> {
+
+        public:
+            typedef Tensor<NV, inDtype, LayOutType_in> DataTensor_in;
+            typedef Tensor<NV, outDtype, LayOutType_out> DataTensor_out;
+            typedef Tensor<NV, OpDtype, LayOutType_op> OpTensor;
+
+            typedef typename DataTensor_in::Dtype InDataType;
+            typedef typename DataTensor_out::Dtype OutDataType;
+            typedef typename OpTensor::Dtype OpDataType;
+
+            SaberLstm() {}
+            ~SaberLstm() {
+
+            }
+
+            virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
+        std::vector<DataTensor_out*>& outputs, \
+        LstmParam <OpTensor>& param, Context<NV>& ctx) {
+
+                this->_ctx = &ctx;
+
+                return create(inputs, outputs, param, ctx);
+            }
+
+            virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs, \
+        std::vector<DataTensor_out*>& outputs, \
+        LstmParam<OpTensor>& param, Context<NV>& ctx) {
+
+
+                return SaberSuccess;
+            }
+
+
+            virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                         std::vector<DataTensor_out*>& outputs,
+                                         LstmParam <OpTensor>& param);
+
+        private:
+
+        };
+
+
+
+    } //namespace saber
+
+} //namespace anakin
+
+#endif //ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_GRU_H
\ No newline at end of file
diff --git a/saber/funcs/impl/cuda/saber_mat_mul.h b/saber/funcs/impl/cuda/saber_mat_mul.h
index 0a4c1b8..f354bcf 100644
--- a/saber/funcs/impl/cuda/saber_mat_mul.h
+++ b/saber/funcs/impl/cuda/saber_mat_mul.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              MatMulParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         return create(inputs, outputs, param, ctx);
     }
@@ -62,7 +62,7 @@ public:
                                std::vector<DataTensor_out*>& outputs,
                                MatMulParam<OpTensor> &param,
                                Context<NV> &ctx) {
-        _kernel =saber_find_fast_sass_gemm(param._is_transpose_X, param._is_transpose_Y, param._M, param._N, param._K);
+        _kernel =saber_find_fast_sass_gemm(param._is_transpose_X, param._is_transpose_Y, param._m, param._n, param._k);
         return SaberSuccess;
     }
 
@@ -70,19 +70,19 @@ public:
                                  std::vector<DataTensor_out*>& outputs,
                                  MatMulParam<OpTensor>  &param)
     {
-        cudaStream_t stream = this->_ctx.get_compute_stream();
+        cudaStream_t stream = this->_ctx->get_compute_stream();
         const InDataType* X = inputs[0]->data();
         const InDataType* Y = inputs[1]->data();
         OutDataType* out = outputs[0]->mutable_data();
 
         //should add batch gemm here
-        for (int b = 0; b < param._B; b++)
+        for (int b = 0; b < param._b; b++)
         {
-            _kernel(param._M, param._N, param._K, 1.f, 
-                X + b * param._M * param._K, 
+            _kernel(param._m, param._n, param._k, 1.f,
+                X + b * param._m * param._k,
                 0.f, 
-                Y + b * param._K * param._N, 
-                out + b * param._M * param._N, stream);
+                Y + b * param._k * param._n,
+                out + b * param._m * param._n, stream);
         }
         return SaberSuccess;
     }
diff --git a/saber/funcs/impl/cuda/saber_multiclass_nms.cpp b/saber/funcs/impl/cuda/saber_multiclass_nms.cpp
index da353cb..7f2536e 100644
--- a/saber/funcs/impl/cuda/saber_multiclass_nms.cpp
+++ b/saber/funcs/impl/cuda/saber_multiclass_nms.cpp
@@ -15,7 +15,7 @@ SaberStatus SaberMultiClassNMS<NV, OpDtype, inDtype, outDtype,\
                           std::vector<DataTensor_out*>& outputs,
                           MultiClassNMSParam<OpTensor>& param) {
 
-    cudaStream_t stream = this->_ctx.get_compute_stream();
+    cudaStream_t stream = this->_ctx->get_compute_stream();
 
     DataTensor_in* t_loc = inputs[0];
     DataTensor_in* t_conf = inputs[1];
diff --git a/saber/funcs/impl/cuda/saber_multiclass_nms.h b/saber/funcs/impl/cuda/saber_multiclass_nms.h
index 71c55d1..a5790ed 100644
--- a/saber/funcs/impl/cuda/saber_multiclass_nms.h
+++ b/saber/funcs/impl/cuda/saber_multiclass_nms.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -59,7 +59,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             MultiClassNMSParam<OpTensor>& param, Context<NV>& ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_mvn.h b/saber/funcs/impl/cuda/saber_mvn.h
index 97dd6f8..378dfd6 100644
--- a/saber/funcs/impl/cuda/saber_mvn.h
+++ b/saber/funcs/impl/cuda/saber_mvn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              MvnParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         return create(inputs, outputs, param, ctx);
     }
diff --git a/saber/funcs/impl/cuda/saber_normalize.h b/saber/funcs/impl/cuda/saber_normalize.h
index 4233109..3f3433a 100644
--- a/saber/funcs/impl/cuda/saber_normalize.h
+++ b/saber/funcs/impl/cuda/saber_normalize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              NormalizeParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_pad.h b/saber/funcs/impl/cuda/saber_pad.h
index 58b32ba..7bdd235 100644
--- a/saber/funcs/impl/cuda/saber_pad.h
+++ b/saber/funcs/impl/cuda/saber_pad.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -54,7 +54,7 @@ public:
                              PadParam<OpTensor> &param,
                              Context<NV> &ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_permute.h b/saber/funcs/impl/cuda/saber_permute.h
index 6b4dee6..2e5811b 100644
--- a/saber/funcs/impl/cuda/saber_permute.h
+++ b/saber/funcs/impl/cuda/saber_permute.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              PermuteParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         _num_axes = inputs[0]->valid_shape().size();
         for (int i = 0; i < _num_axes; i++) {
             if (std::find(_order_dims.begin(), _order_dims.end(),
diff --git a/saber/funcs/impl/cuda/saber_permute_power.h b/saber/funcs/impl/cuda/saber_permute_power.h
index 20c54a7..9d392e5 100644
--- a/saber/funcs/impl/cuda/saber_permute_power.h
+++ b/saber/funcs/impl/cuda/saber_permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              PermutePowerParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_pooling.h b/saber/funcs/impl/cuda/saber_pooling.h
index ccbc36d..6284102 100644
--- a/saber/funcs/impl/cuda/saber_pooling.h
+++ b/saber/funcs/impl/cuda/saber_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/cuda/saber_pooling_with_index.h b/saber/funcs/impl/cuda/saber_pooling_with_index.h
index c269a91..a858dcb 100644
--- a/saber/funcs/impl/cuda/saber_pooling_with_index.h
+++ b/saber/funcs/impl/cuda/saber_pooling_with_index.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              PoolingParam<OpTensor> &param, \
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_power.h b/saber/funcs/impl/cuda/saber_power.h
index b88e95f..829170e 100644
--- a/saber/funcs/impl/cuda/saber_power.h
+++ b/saber/funcs/impl/cuda/saber_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              PowerParam<OpTensor> &power_param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return SaberSuccess;
     }
 
diff --git a/saber/funcs/impl/cuda/saber_prelu.h b/saber/funcs/impl/cuda/saber_prelu.h
deleted file mode 100644
index 39bebbb..0000000
--- a/saber/funcs/impl/cuda/saber_prelu.h
+++ /dev/null
@@ -1,125 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_PRELU_H
-#define ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_PRELU_H
-
-#include "saber/funcs/impl/impl_prelu.h"
-
-namespace anakin{
-
-namespace saber{
-
-template <DataType OpDtype,
-            DataType inDtype,
-            DataType outDtype,
-            typename LayOutType_op,
-            typename LayOutType_in,
-            typename LayOutType_out>
-class SaberPrelu<NV, OpDtype, inDtype, outDtype, \
-    LayOutType_op, LayOutType_in, LayOutType_out>:\
-    public ImplBase<
-            Tensor<NV, inDtype, LayOutType_in>,
-            Tensor<NV, outDtype, LayOutType_out>,
-            Tensor<NV, OpDtype, LayOutType_op>,
-            PreluParam<Tensor<NV, OpDtype, LayOutType_op>>> {
-
-public:
-    typedef Tensor<NV, inDtype, LayOutType_in> DataTensor_in;
-    typedef Tensor<NV, outDtype, LayOutType_out> DataTensor_out;
-    typedef Tensor<NV, OpDtype, LayOutType_op> OpTensor;
-
-    typedef typename DataTensor_in::Dtype InDataType;
-    typedef typename DataTensor_out::Dtype OutDataType;
-    typedef typename OpTensor::Dtype OpDataType;
-
-    SaberPrelu() = default;
-    ~SaberPrelu() {}
-
-    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
-                             std::vector<DataTensor_out*>& outputs,
-                             PreluParam<OpTensor> &param,
-                             Context<NV> &ctx) {
-        // get context
-        this->_ctx = ctx;
-        return create(inputs, outputs, param, ctx);
-    }
-
-    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
-                               std::vector<DataTensor_out*>& outputs,
-                               PreluParam<OpTensor> &param,
-                               Context<NV> &ctx) {
-        // compute inner and outer size
-        int channel_index = inputs[0]->channel_index();
-        _dims = inputs[0]->dims();
-        _size = inputs[0]->valid_size();
-        _channels = inputs[0]->channel();
-        _inner_size = inputs[0]->count_valid(channel_index + 1, _dims);
-        _outer_size = inputs[0]->count_valid(0, channel_index);
-        if (!param.channel_shared) {
-                    CHECK_EQ(_channels, param.slope->valid_size()) << \
-                "slope data size must = channels";
-        }
-        _is_continue_buf = outputs[0]->is_continue_mem() && inputs[0]->is_continue_mem();
-        if (!_is_continue_buf) {
-            Shape sh_input_real_stride = inputs[0]->get_stride();
-            Shape sh_output_real_stride = outputs[0]->get_stride();
-
-            //! re_alloc device memory
-            Shape sh{1, 1, 1, _dims};
-            _valid_shape.reshape(sh);
-            _input_stride.reshape(sh);
-            _output_stride.reshape(sh);
-
-            CUDA_CHECK(cudaMemcpy(_valid_shape.mutable_data(), inputs[0]->valid_shape().data(), \
-                sizeof(int) * _dims, cudaMemcpyHostToDevice));
-            CUDA_CHECK(cudaMemcpy(_input_stride.mutable_data(), sh_input_real_stride.data(), \
-                sizeof(int) * _dims, cudaMemcpyHostToDevice));
-            CUDA_CHECK(cudaMemcpy(_output_stride.mutable_data(), sh_output_real_stride.data(), \
-                sizeof(int) * _dims, cudaMemcpyHostToDevice));
-        }
-        return SaberSuccess;
-    }
-
-    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
-                                 std::vector<DataTensor_out*>& outputs,
-                                 PreluParam<OpTensor> &param);
-
-private:
-    int _size;
-    int _inner_size;
-    int _outer_size;
-    int _channels;
-    int _dims;
-    Tensor<NV, AK_INT32, LayOutType_in> _input_stride;
-    Tensor<NV, AK_INT32, LayOutType_out> _output_stride;
-    Tensor<NV, AK_INT32, LayOutType_op> _valid_shape;
-    bool _is_continue_buf{true};
-};
-
-
-template class SaberPrelu<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
-/*t
-emplate class SaberPrelu<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NHWC, NHWC, NHWC>;
-template class SaberPrelu<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, HW, HW, HW>;
-template class SaberPrelu<NV, AK_INT8, AK_INT8, AK_INT8, NCHW, NCHW, NCHW>;
-template class SaberPrelu<NV, AK_INT8, AK_INT8, AK_INT8, NHWC, NHWC, NHWC>;
-template class SaberPrelu<NV, AK_INT8, AK_INT8, AK_INT8, HW, HW, HW>;
-*/
-} //namespace saber
-
-} //namespace anakin
-
-#endif //ANAKIN_SABER_FUNCS_IMPL_CUDA_SABER_PRELU_H
\ No newline at end of file
diff --git a/saber/funcs/impl/cuda/saber_priorbox.h b/saber/funcs/impl/cuda/saber_priorbox.h
index e732ae0..be02621 100644
--- a/saber/funcs/impl/cuda/saber_priorbox.h
+++ b/saber/funcs/impl/cuda/saber_priorbox.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -56,7 +56,7 @@ public:
                       PriorBoxParam<OpTensor> &param,
                       Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
@@ -65,12 +65,20 @@ public:
                         PriorBoxParam<OpTensor> &param,
                         Context<NV> &ctx){
 
+        CHECK_EQ(param.order.size(), 3)  << "Incorrect size of priorbox order list.";
+        CHECK_EQ(std::accumulate(param.order.begin(), param.order.end(), 0), 3) \
+            << "Incorrect type of priorbox order.";
+
         if (_output_host != nullptr) {
             fast_free(_output_host);
             _output_host = nullptr;
         }
         _output_host = (float*)fast_malloc(sizeof(float) * outputs[0]->valid_size());
 
+        float* min_buf = (float*)fast_malloc(sizeof(float) * 4);
+        float* max_buf = (float*)fast_malloc(sizeof(float) * 4);
+        float* com_buf = (float*)fast_malloc(sizeof(float) * param.aspect_ratio.size() * 4);
+
         const int width = inputs[0]->width();
         const int height = inputs[0]->height();
         int img_width = param.img_w;
@@ -97,17 +105,20 @@ public:
                 float box_width;
                 float box_height;
                 for (int s = 0; s < param.min_size.size(); ++s) {
+                    int min_idx = 0;
+                    int max_idx = 0;
+                    int com_idx = 0;
                     int min_size = param.min_size[s];
                     //! first prior: aspect_ratio = 1, size = min_size
                     box_width = box_height = min_size;
                     //! xmin
-                    _output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                    min_buf[min_idx++] = (center_x - box_width / 2.f) / img_width;
                     //! ymin
-                    _output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                    min_buf[min_idx++] = (center_y - box_height / 2.f) / img_height;
                     //! xmax
-                    _output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                    min_buf[min_idx++] = (center_x + box_width / 2.f) / img_width;
                     //! ymax
-                    _output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                    min_buf[min_idx++] = (center_y + box_height / 2.f) / img_height;
 
                     if (param.max_size.size() > 0) {
 
@@ -115,13 +126,13 @@ public:
                         //! second prior: aspect_ratio = 1, size = sqrt(min_size * max_size)
                         box_width = box_height = sqrtf(min_size * max_size);
                         //! xmin
-                        _output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                        max_buf[max_idx++] = (center_x - box_width / 2.f) / img_width;
                         //! ymin
-                        _output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                        max_buf[max_idx++] = (center_y - box_height / 2.f) / img_height;
                         //! xmax
-                        _output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                        max_buf[max_idx++] = (center_x + box_width / 2.f) / img_width;
                         //! ymax
-                        _output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                        max_buf[max_idx++] = (center_y + box_height / 2.f) / img_height;
                     }
 
                     //! rest of priors
@@ -133,17 +144,35 @@ public:
                         box_width = min_size * sqrt(ar);
                         box_height = min_size / sqrt(ar);
                         //! xmin
-                        _output_host[idx++] = (center_x - box_width / 2.f) / img_width;
+                        com_buf[com_idx++] = (center_x - box_width / 2.f) / img_width;
                         //! ymin
-                        _output_host[idx++] = (center_y - box_height / 2.f) / img_height;
+                        com_buf[com_idx++] = (center_y - box_height / 2.f) / img_height;
                         //! xmax
-                        _output_host[idx++] = (center_x + box_width / 2.f) / img_width;
+                        com_buf[com_idx++] = (center_x + box_width / 2.f) / img_width;
                         //! ymax
-                        _output_host[idx++] = (center_y + box_height / 2.f) / img_height;
+                        com_buf[com_idx++] = (center_y + box_height / 2.f) / img_height;
+                    }
+
+                    for (const auto &type : param.order) {
+                        if (type == PRIOR_MIN) {
+                            memcpy(_output_host + idx, min_buf, sizeof(float) * min_idx);
+                            idx += min_idx;
+                        } else if (type == PRIOR_MAX) {
+                            memcpy(_output_host + idx, max_buf, sizeof(float) * max_idx);
+                            idx += max_idx;
+                        } else if (type == PRIOR_COM) {
+                            memcpy(_output_host + idx, com_buf, sizeof(float) * com_idx);
+                            idx += com_idx;
+                        }
                     }
                 }
             }
         }
+
+        fast_free(min_buf);
+        fast_free(max_buf);
+        fast_free(com_buf);
+
         //! clip the prior's coordidate such that it is within [0, 1]
         if (param.is_clip) {
             for (int d = 0; d < channel_size; ++d) {
@@ -175,7 +204,7 @@ public:
     virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
                           std::vector<DataTensor_out*>& outputs,
                           PriorBoxParam<OpTensor> &param){
-        cudaStream_t stream = this->_ctx.get_compute_stream();
+        cudaStream_t stream = this->_ctx->get_compute_stream();
         CUDA_CHECK(cudaMemcpyAsync(outputs[0]->mutable_data(), _output_nv.data(), \
                 outputs[0]->valid_size() * sizeof(float), cudaMemcpyDeviceToDevice, stream));
         return SaberSuccess;
diff --git a/saber/funcs/impl/cuda/saber_resize.h b/saber/funcs/impl/cuda/saber_resize.h
index fa8da86..95d011d 100644
--- a/saber/funcs/impl/cuda/saber_resize.h
+++ b/saber/funcs/impl/cuda/saber_resize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              ResizeParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_roi_pool.h b/saber/funcs/impl/cuda/saber_roi_pool.h
index ac5cbf5..25086ad 100644
--- a/saber/funcs/impl/cuda/saber_roi_pool.h
+++ b/saber/funcs/impl/cuda/saber_roi_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -56,7 +56,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              RoiPoolParam<OpTensor> &param,
                              Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         Shape out_stride = outputs[0]->get_stride();
         Shape in_stride = inputs[0]->get_stride();
         int in_n_index = inputs[0]->num_index();
diff --git a/saber/funcs/impl/cuda/saber_scale.h b/saber/funcs/impl/cuda/saber_scale.h
index 4b4fe46..66c0f20 100644
--- a/saber/funcs/impl/cuda/saber_scale.h
+++ b/saber/funcs/impl/cuda/saber_scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -52,7 +52,7 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ScaleParam<OpTensor>& param, Context<NV>& ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         _axis = (param.num_axes == 0) ? 0 : param.axis;
         _num_axes = param.num_axes >= 0 ? param.num_axes : inputs[0]->shape().dims() - _axis;
         _bias_term = param.bias_term;
@@ -73,7 +73,7 @@ public:
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ScaleParam<OpTensor>& param, Context<NV> &ctx) {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         _inner_dim = inputs[0]->count(_axis + _num_axes, inputs[0]->shape().dims());
         _scale_dim = inputs[0]->count(_axis, _axis + _num_axes);
         if (inputs.size() == 1) {
diff --git a/saber/funcs/impl/cuda/saber_slice.h b/saber/funcs/impl/cuda/saber_slice.h
index 078f343..4af8c6b 100644
--- a/saber/funcs/impl/cuda/saber_slice.h
+++ b/saber/funcs/impl/cuda/saber_slice.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -53,7 +53,7 @@ public:
                              SliceParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_softmax.h b/saber/funcs/impl/cuda/saber_softmax.h
index 972369b..54e283e 100644
--- a/saber/funcs/impl/cuda/saber_softmax.h
+++ b/saber/funcs/impl/cuda/saber_softmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -61,7 +61,7 @@ public:
                             SoftmaxParam<OpTensor>& param, Context<NV>& ctx) {
 
         //! get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/saber_spp.h b/saber/funcs/impl/cuda/saber_spp.h
index a80eca1..4aba8db 100644
--- a/saber/funcs/impl/cuda/saber_spp.h
+++ b/saber/funcs/impl/cuda/saber_spp.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -67,7 +67,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              SPPParam<OpTensor> &param,
                              Context<NV> &ctx)  {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         _pooling.clear();
         _pooling_output.clear();
         _pooling_param.clear();
diff --git a/saber/funcs/impl/cuda/saber_transpose.h b/saber/funcs/impl/cuda/saber_transpose.h
index 7239e12..e782be0 100644
--- a/saber/funcs/impl/cuda/saber_transpose.h
+++ b/saber/funcs/impl/cuda/saber_transpose.h
@@ -53,7 +53,7 @@ public:
                              TransposeParam<OpTensor> &param,
                              Context<NV> &ctx) {
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param,ctx);
     }
 
@@ -61,8 +61,8 @@ public:
                                std::vector<DataTensor_out*>& outputs,
                                TransposeParam<OpTensor> &param,
                                Context<NV> &ctx) {
-        if (!(ctx == this->_ctx)) {
-            this->_ctx = ctx;
+        if (!(&ctx == this->_ctx)) {
+            this->_ctx = &ctx;
         }
         // do nothing
         return SaberSuccess;
diff --git a/saber/funcs/impl/cuda/saber_unpool.h b/saber/funcs/impl/cuda/saber_unpool.h
index c69bdb5..4eaed4f 100644
--- a/saber/funcs/impl/cuda/saber_unpool.h
+++ b/saber/funcs/impl/cuda/saber_unpool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -56,7 +56,7 @@ public:
                              std::vector<DataTensor_out*>& outputs,
                              PoolingParam<OpTensor> &param,
                              Context<NV> &ctx)  {
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/cuda/vender_activation.h b/saber/funcs/impl/cuda/vender_activation.h
index ee9cb0b..c9965a3 100644
--- a/saber/funcs/impl/cuda/vender_activation.h
+++ b/saber/funcs/impl/cuda/vender_activation.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -65,7 +65,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             ActivationParam<OpTensor>& param, Context<NV>& ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -84,12 +84,14 @@ public:
     virtual SaberStatus create(const std::vector<DataTensor_in *>& inputs,
                             std::vector<DataTensor_out *>& outputs,
                             ActivationParam<OpTensor>& param, Context<NV>& ctx) {
-
-        if (!(ctx == this->_ctx)) {
+        if (param.active == Active_prelu) {
+            return SaberUnImplError;
+        }
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_conv.cpp b/saber/funcs/impl/cuda/vender_conv.cpp
index 4e7c80d..6ffbb70 100644
--- a/saber/funcs/impl/cuda/vender_conv.cpp
+++ b/saber/funcs/impl/cuda/vender_conv.cpp
@@ -11,12 +11,12 @@ SaberStatus VenderConv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::\
             std::vector<DataTensor_out *>& outputs,
             ConvParam<OpTensor>& param, Context<NV>& ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -151,12 +151,12 @@ SaberStatus VenderConv2D<NV, AK_INT8, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::\
             std::vector<DataTensor_out *>& outputs,
             ConvParam<OpTensor>& param, Context<NV>& ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -344,12 +344,12 @@ SaberStatus VenderConv2D<NV, AK_INT8, AK_INT8, AK_INT8, NCHW_C4, NCHW_C4, NCHW_C
     CHECK_EQ(outputs[0]->dims(), 5);
     CHECK_EQ(outputs[0]->shape()[4], 4);
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -514,12 +514,12 @@ SaberStatus VenderConv2D<NV, AK_INT8, AK_INT8, AK_FLOAT, NCHW_C4, NCHW, NCHW>::c
     CHECK_EQ(inputs[0]->dims(), 5);
     CHECK_EQ(inputs[0]->shape()[4], 4);
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_conv.h b/saber/funcs/impl/cuda/vender_conv.h
index c7ccb88..b4c5d8b 100644
--- a/saber/funcs/impl/cuda/vender_conv.h
+++ b/saber/funcs/impl/cuda/vender_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -121,7 +121,7 @@ public:
 
         _workspace_fwd_sizes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -179,7 +179,7 @@ private:
     void *_workspace;  // aliases into _workspaceData
 
     const bool _use_tensor_core = true;
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     const cudnnConvolutionFwdPreference_t _preference = CUDNN_CONVOLUTION_FWD_PREFER_FASTEST;
 
     // create transform descriptor
diff --git a/saber/funcs/impl/cuda/vender_conv_act.cpp b/saber/funcs/impl/cuda/vender_conv_act.cpp
index 33438c8..88bddf9 100644
--- a/saber/funcs/impl/cuda/vender_conv_act.cpp
+++ b/saber/funcs/impl/cuda/vender_conv_act.cpp
@@ -10,11 +10,11 @@ SaberStatus VenderConv2DAct<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>:
             std::vector<DataTensor_out *>& outputs,
             ConvActiveParam<OpTensor>& param, Context<NV>& ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -184,11 +184,11 @@ SaberStatus VenderConv2DAct<NV, AK_INT8, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::
             std::vector<DataTensor_out *>& outputs,
             ConvActiveParam<OpTensor>& param, Context<NV>& ctx> &ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -373,11 +373,11 @@ SaberStatus VenderConv2DAct<AK_INT8, AK_INT8, AK_INT8, NCHW_C4>::\
     CHECK_EQ(inputs[0]->shape()[4], 4);
     CHECK_EQ(outputs[0]->dims(), 5);
     CHECK_EQ(outputs[0]->shape()[4], 4);
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -526,11 +526,11 @@ SaberStatus VenderConv2DAct<AK_INT8, AK_INT8, AK_FLOAT, NCHW_C4, NCHW>::\
 
     CHECK_EQ(inputs[0]->dims(), 5);
     CHECK_EQ(inputs[0]->shape()[4], 4);
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_conv_act.h b/saber/funcs/impl/cuda/vender_conv_act.h
index 802445b..ec72de3 100644
--- a/saber/funcs/impl/cuda/vender_conv_act.h
+++ b/saber/funcs/impl/cuda/vender_conv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -125,7 +125,7 @@ public:
 
         _workspace_fwd_sizes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -182,7 +182,7 @@ private:
     void *_workspace;  // aliases into workspaceData
 
     const bool _use_tensor_core = true;
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     const cudnnConvolutionFwdPreference_t _preference = CUDNN_CONVOLUTION_FWD_PREFER_FASTEST;
 
     // activation descriptor
diff --git a/saber/funcs/impl/cuda/vender_conv_act_pooling.cpp b/saber/funcs/impl/cuda/vender_conv_act_pooling.cpp
index 4daea15..552f8b8 100644
--- a/saber/funcs/impl/cuda/vender_conv_act_pooling.cpp
+++ b/saber/funcs/impl/cuda/vender_conv_act_pooling.cpp
@@ -10,11 +10,11 @@ SaberStatus VenderConv2DActPooling<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW,
             std::vector<DataTensor_out *>& outputs,
             ConvActivePoolingParam<OpTensor>& param, Context<NV> &ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_conv_act_pooling.h b/saber/funcs/impl/cuda/vender_conv_act_pooling.h
index c766ee0..2b3c1d3 100644
--- a/saber/funcs/impl/cuda/vender_conv_act_pooling.h
+++ b/saber/funcs/impl/cuda/vender_conv_act_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -114,7 +114,7 @@ public:
 
         _workspace_fwd_sizes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -175,7 +175,7 @@ private:
     void *_workspace;  // aliases into workspaceData
 
     const bool _use_tensor_core = true;
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     const cudnnConvolutionFwdPreference_t _preference = CUDNN_CONVOLUTION_FWD_PREFER_FASTEST;
 
     // activation descriptor
diff --git a/saber/funcs/impl/cuda/vender_deconv.h b/saber/funcs/impl/cuda/vender_deconv.h
index 8b01ea3..4369425 100644
--- a/saber/funcs/impl/cuda/vender_deconv.h
+++ b/saber/funcs/impl/cuda/vender_deconv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -104,7 +104,7 @@ public:
 
         _workspace_bwd_sizes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -133,11 +133,11 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             ConvParam<OpTensor>& param, Context<NV> &ctx) {
 
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
@@ -281,7 +281,7 @@ private:
     void *workspaceData;  // underlying storage
     void *workspace;  // aliases into workspaceData
     const bool _use_tensor_core = true;
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     const cudnnConvolutionBwdDataPreference_t _preference = CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST;
 };
 template class VenderDeconv2D<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
diff --git a/saber/funcs/impl/cuda/vender_deconv_act.h b/saber/funcs/impl/cuda/vender_deconv_act.h
index 7325d4e..cf2ceb1 100644
--- a/saber/funcs/impl/cuda/vender_deconv_act.h
+++ b/saber/funcs/impl/cuda/vender_deconv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -107,7 +107,7 @@ public:
 
         _workspace_bwd_sizes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -137,11 +137,11 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             ConvActiveParam<OpTensor>& param, Context<NV>& ctx) {
 
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
@@ -301,7 +301,7 @@ private:
     void *_workspaceData;  // underlying storage
     void *_workspace;  // aliases into _workspaceData
     const bool _use_tensor_core = true;
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     const cudnnConvolutionBwdDataPreference_t _preference = CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST;
 };
 template class VenderDeconv2DAct<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
diff --git a/saber/funcs/impl/cuda/vender_fc.h b/saber/funcs/impl/cuda/vender_fc.h
index 0ea154e..eb58977 100644
--- a/saber/funcs/impl/cuda/vender_fc.h
+++ b/saber/funcs/impl/cuda/vender_fc.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -54,7 +54,7 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             FcParam<OpTensor>& param, Context<NV>& ctx){
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
 
@@ -67,11 +67,11 @@ public:
                             std::vector<DataTensor_out *>& outputs,
                             FcParam<OpTensor>& param, Context<NV>& ctx){
 
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUBLAS_CHECK(cublasDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_gru.cpp b/saber/funcs/impl/cuda/vender_gru.cpp
index dff3ad2..7c8b2b7 100644
--- a/saber/funcs/impl/cuda/vender_gru.cpp
+++ b/saber/funcs/impl/cuda/vender_gru.cpp
@@ -256,12 +256,12 @@ create(const std::vector<DataTensor*>& inputs,
        std::vector<OutDataTensor*>& outputs,
        GruParam<OpTensor>& gru_param, Context<NV>& ctx) {
 
-    if (!(ctx == this->_ctx)) {
+    if (!(&ctx == this->_ctx)) {
         if (_handle != NULL) {
             CUDNN_CHECK(cudnnDestroy(_handle));
         }
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -367,7 +367,7 @@ dispatch(const std::vector<DataTensor*>& inputs,
     if (isHW2Seq) {
         DataTensor temp_tensor_in;
         DataTensor temp_tensor_out;
-        hw2seq(inputs, param, _word_size, temp_tensor_in, temp_tensor_out, _ctx);
+        hw2seq(inputs, param, _word_size, temp_tensor_in, temp_tensor_out, *_ctx);
         CUDNN_CHECK(cudnnRNNForwardInference(_handle,
                                              _rnnDesc,
                                              _xDesc->sizes(),//sequence
@@ -388,7 +388,7 @@ dispatch(const std::vector<DataTensor*>& inputs,
                                              _workspace_tensor.mutable_data(),
                                              _workspace_size_in_bytes));
 
-        seq2hw(outputs, inputs, param, _hidden_size, temp_tensor_out, _ctx);
+        seq2hw(outputs, inputs, param, _hidden_size, temp_tensor_out, *_ctx);
         outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
 
     } else {
diff --git a/saber/funcs/impl/cuda/vender_gru.h b/saber/funcs/impl/cuda/vender_gru.h
index 15320ad..1cf4e9b 100644
--- a/saber/funcs/impl/cuda/vender_gru.h
+++ b/saber/funcs/impl/cuda/vender_gru.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_IMPL_CUDA_CUDNN_GRU_H
 #define ANAKIN_SABER_FUNCS_IMPL_CUDA_CUDNN_GRU_H
@@ -106,7 +107,7 @@ public:
 
         _workspace_size_in_bytes = 0;
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -201,7 +202,7 @@ private:
 
 
 //! workspace for cudnn
-    const size_t _workspace_limit_bytes = 64 * 1024 * 1024;
+    const size_t _workspace_limit_bytes = 4 * 1024 * 1024;
     size_t _workspace_size_in_bytes;
     Tensor<NV, AK_INT8, NCHW> _workspace_tensor;  // underlying storage
 
diff --git a/saber/funcs/impl/cuda/vender_permute_power.h b/saber/funcs/impl/cuda/vender_permute_power.h
index e21cf57..efd3297 100644
--- a/saber/funcs/impl/cuda/vender_permute_power.h
+++ b/saber/funcs/impl/cuda/vender_permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -70,7 +70,7 @@ public:
                   PermutePowerParam<OpTensor> &param, \
                   Context<NV> &ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
         cudaStream_t cuda_stream;
@@ -90,11 +90,11 @@ public:
                 std::vector<DataTensor_out*>& outputs,
                 PermutePowerParam<OpTensor> &param, Context<NV> &ctx) {
 
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_pooling.h b/saber/funcs/impl/cuda/vender_pooling.h
index c1cb6b8..46ecd2c 100644
--- a/saber/funcs/impl/cuda/vender_pooling.h
+++ b/saber/funcs/impl/cuda/vender_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -65,7 +65,7 @@ public:
                   std::vector<DataTensor_out*>& outputs,
                   PoolingParam<OpTensor> &pooling_param, Context<NV> &ctx) {
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
 
         cudaStream_t cuda_stream;
         cuda_stream = ctx.get_compute_stream();
@@ -84,11 +84,11 @@ public:
     virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
                 std::vector<DataTensor_out*>& outputs,
                 PoolingParam<OpTensor> &pooling_param, Context<NV> &ctx) {
-        if (!(ctx == this->_ctx)) {
+        if (!(&ctx == this->_ctx)) {
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
 
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
diff --git a/saber/funcs/impl/cuda/vender_softmax.h b/saber/funcs/impl/cuda/vender_softmax.h
index 3494209..ba41006 100644
--- a/saber/funcs/impl/cuda/vender_softmax.h
+++ b/saber/funcs/impl/cuda/vender_softmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -76,10 +76,10 @@ public:
 
         // ---- init cudnn resources ----
 
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         // ---- get cuda resources ----
 
-        cudaStream_t cuda_stream = this->_ctx.get_compute_stream();
+        cudaStream_t cuda_stream = this->_ctx->get_compute_stream();
 
         CUDNN_CHECK(cudnnCreate(&_handle));
         CUDNN_CHECK(cudnnSetStream(_handle, cuda_stream));
@@ -110,7 +110,7 @@ public:
             if (_handle != NULL) {
                 CUDNN_CHECK(cudnnDestroy(_handle));
             }
-            this->_ctx = ctx;
+            this->_ctx = &ctx;
             cudaStream_t cuda_stream;
             cuda_stream = ctx.get_compute_stream();
             CUDNN_CHECK(cudnnCreate(&_handle));
@@ -144,7 +144,7 @@ public:
     virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
                           std::vector<DataTensor_out*>& outputs,
                           SoftmaxParam<OpTensor> &param){
-        cudaStream_t stream = this->_ctx.get_compute_stream();
+        cudaStream_t stream = this->_ctx->get_compute_stream();
         const InDataType* input_data = inputs[0]->data();
         InDataType * output_data = outputs[0]->mutable_data();
         CUDNN_CHECK(cudnnSoftmaxForward(_handle, CUDNN_SOFTMAX_ACCURATE, \
diff --git a/saber/funcs/impl/detection_helper.h b/saber/funcs/impl/detection_helper.h
index 239baee..d14f4b3 100644
--- a/saber/funcs/impl/detection_helper.h
+++ b/saber/funcs/impl/detection_helper.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -48,6 +48,13 @@ void decode_bboxes(const int nthreads, const Dtype* loc_data, const Dtype* prior
                    Dtype* bbox_data, cudaStream_t stream);
 #endif
 
+#ifdef USE_ARM_PLACE
+void decode_bboxes(const int batch_num, const float* loc_data, const float* prior_data, \
+                       const CodeType code_type, const bool variance_encoded_in_target, \
+                       const int num_priors, const bool share_location, \
+                       const int num_loc_classes, const int background_label_id, \
+                       float* bbox_data);
+#endif
 } //namespace saber
 
 } //namespace anakin
diff --git a/saber/funcs/impl/impl_activation.h b/saber/funcs/impl/impl_activation.h
index 5cd4363..b9ade0a 100644
--- a/saber/funcs/impl/impl_activation.h
+++ b/saber/funcs/impl/impl_activation.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_argmax.h b/saber/funcs/impl/impl_argmax.h
index 7478683..f7477fa 100644
--- a/saber/funcs/impl/impl_argmax.h
+++ b/saber/funcs/impl/impl_argmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_axpy.h b/saber/funcs/impl/impl_axpy.h
index c25fb0c..e4a10c5 100644
--- a/saber/funcs/impl/impl_axpy.h
+++ b/saber/funcs/impl/impl_axpy.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_base.h b/saber/funcs/impl/impl_base.h
index 5b593f0..cb86062 100644
--- a/saber/funcs/impl/impl_base.h
+++ b/saber/funcs/impl/impl_base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -57,7 +57,7 @@ public:
 
 protected:
     Param* _param;
-    Context<targetType_t> _ctx;
+    Context<targetType_t>* _ctx;
 };
 
 }
diff --git a/saber/funcs/impl/impl_box_coder.h b/saber/funcs/impl/impl_box_coder.h
index 84386a1..be58498 100644
--- a/saber/funcs/impl/impl_box_coder.h
+++ b/saber/funcs/impl/impl_box_coder.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_cast.h b/saber/funcs/impl/impl_cast.h
index 3e267a7..84282cf 100644
--- a/saber/funcs/impl/impl_cast.h
+++ b/saber/funcs/impl/impl_cast.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_concat.h b/saber/funcs/impl/impl_concat.h
index 4940989..c8b9270 100644
--- a/saber/funcs/impl/impl_concat.h
+++ b/saber/funcs/impl/impl_concat.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_conv.h b/saber/funcs/impl/impl_conv.h
index 1c32dd2..8fdee5a 100644
--- a/saber/funcs/impl/impl_conv.h
+++ b/saber/funcs/impl/impl_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_conv_act.h b/saber/funcs/impl/impl_conv_act.h
index f020e13..7c3402b 100644
--- a/saber/funcs/impl/impl_conv_act.h
+++ b/saber/funcs/impl/impl_conv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_conv_act_pooling.h b/saber/funcs/impl/impl_conv_act_pooling.h
index 1158598..c433eb0 100644
--- a/saber/funcs/impl/impl_conv_act_pooling.h
+++ b/saber/funcs/impl/impl_conv_act_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_conv_eltwise.h b/saber/funcs/impl/impl_conv_eltwise.h
deleted file mode 100644
index 471862d..0000000
--- a/saber/funcs/impl/impl_conv_eltwise.h
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-  http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_IMPL_CONV2DELTWISE_H
-#define ANAKIN_SABER_FUNCS_IMPL_CONV2DELTWISE_H
-
-#include "saber/funcs/impl/impl_macro.h"
-namespace anakin{
-
-namespace saber{
-
-DEFINE_OP_CLASS(Conv2DEltWise, ConvActiveParam);
-
-}
-}
-
-#endif //ANAKIN_SABER_FUNCS_IMPL_CONV2DELTWISE_H
diff --git a/saber/funcs/impl/impl_crf_decoding.h b/saber/funcs/impl/impl_crf_decoding.h
index b4e770f..b05a168 100644
--- a/saber/funcs/impl/impl_crf_decoding.h
+++ b/saber/funcs/impl/impl_crf_decoding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_crop.h b/saber/funcs/impl/impl_crop.h
index d19c9d1..343eae7 100644
--- a/saber/funcs/impl/impl_crop.h
+++ b/saber/funcs/impl/impl_crop.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_ctc_align.h b/saber/funcs/impl/impl_ctc_align.h
index d31a757..a349b62 100644
--- a/saber/funcs/impl/impl_ctc_align.h
+++ b/saber/funcs/impl/impl_ctc_align.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_deconv.h b/saber/funcs/impl/impl_deconv.h
index 3e4d7f9..b840003 100644
--- a/saber/funcs/impl/impl_deconv.h
+++ b/saber/funcs/impl/impl_deconv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_deconv_act.h b/saber/funcs/impl/impl_deconv_act.h
index 590de04..3def35b 100644
--- a/saber/funcs/impl/impl_deconv_act.h
+++ b/saber/funcs/impl/impl_deconv_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_deformable_conv.h b/saber/funcs/impl/impl_deformable_conv.h
index f71d3f9..409e0ac 100644
--- a/saber/funcs/impl/impl_deformable_conv.h
+++ b/saber/funcs/impl/impl_deformable_conv.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_detection_output.h b/saber/funcs/impl/impl_detection_output.h
index fd12722..1313f51 100644
--- a/saber/funcs/impl/impl_detection_output.h
+++ b/saber/funcs/impl/impl_detection_output.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_eltwise.h b/saber/funcs/impl/impl_eltwise.h
index 24c344d..dfad1f6 100644
--- a/saber/funcs/impl/impl_eltwise.h
+++ b/saber/funcs/impl/impl_eltwise.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_eltwise_act.h b/saber/funcs/impl/impl_eltwise_act.h
index 141ec69..9637bae 100644
--- a/saber/funcs/impl/impl_eltwise_act.h
+++ b/saber/funcs/impl/impl_eltwise_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_embedding.h b/saber/funcs/impl/impl_embedding.h
index 1ce4f30..e3e8f1a 100644
--- a/saber/funcs/impl/impl_embedding.h
+++ b/saber/funcs/impl/impl_embedding.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_fc.h b/saber/funcs/impl/impl_fc.h
index b28ede6..bd3357a 100644
--- a/saber/funcs/impl/impl_fc.h
+++ b/saber/funcs/impl/impl_fc.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_flatten.h b/saber/funcs/impl/impl_flatten.h
index bb2a0ea..9a6ebd2 100644
--- a/saber/funcs/impl/impl_flatten.h
+++ b/saber/funcs/impl/impl_flatten.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_gru.h b/saber/funcs/impl/impl_gru.h
index ccf488d..7f769bc 100644
--- a/saber/funcs/impl/impl_gru.h
+++ b/saber/funcs/impl/impl_gru.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_im2sequence.h b/saber/funcs/impl/impl_im2sequence.h
index ce7a6ab..4baee99 100644
--- a/saber/funcs/impl/impl_im2sequence.h
+++ b/saber/funcs/impl/impl_im2sequence.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_layer_norm.h b/saber/funcs/impl/impl_layer_norm.h
index da6ccf1..f98b1cf 100644
--- a/saber/funcs/impl/impl_layer_norm.h
+++ b/saber/funcs/impl/impl_layer_norm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_lrn.h b/saber/funcs/impl/impl_lrn.h
index 658ac4e..4376cce 100644
--- a/saber/funcs/impl/impl_lrn.h
+++ b/saber/funcs/impl/impl_lrn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_lstm.h b/saber/funcs/impl/impl_lstm.h
new file mode 100644
index 0000000..12c767a
--- /dev/null
+++ b/saber/funcs/impl/impl_lstm.h
@@ -0,0 +1,28 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_LSTM_H
+#define ANAKIN_SABER_FUNCS_IMPL_LSTM_H
+
+#include "saber/funcs/impl/impl_macro.h"
+namespace anakin {
+namespace saber {
+
+DEFINE_OP_CLASS(Lstm, LstmParam);
+
+}
+}
+
+#endif // ANAKIN_SABER_FUNCS_IMPL_LSTM_H
diff --git a/saber/funcs/impl/impl_macro.h b/saber/funcs/impl/impl_macro.h
index c6e6fbf..b78a54f 100644
--- a/saber/funcs/impl/impl_macro.h
+++ b/saber/funcs/impl/impl_macro.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_mat_mul.h b/saber/funcs/impl/impl_mat_mul.h
index be8073b..2809eb5 100644
--- a/saber/funcs/impl/impl_mat_mul.h
+++ b/saber/funcs/impl/impl_mat_mul.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_multiclass_nms.h b/saber/funcs/impl/impl_multiclass_nms.h
index 82894a8..b360454 100644
--- a/saber/funcs/impl/impl_multiclass_nms.h
+++ b/saber/funcs/impl/impl_multiclass_nms.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_mvn.h b/saber/funcs/impl/impl_mvn.h
index 54f7e30..d18c5b3 100644
--- a/saber/funcs/impl/impl_mvn.h
+++ b/saber/funcs/impl/impl_mvn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_normalize.h b/saber/funcs/impl/impl_normalize.h
index 4f0b926..828073e 100644
--- a/saber/funcs/impl/impl_normalize.h
+++ b/saber/funcs/impl/impl_normalize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_pad.h b/saber/funcs/impl/impl_pad.h
index f1a4c92..8ac0db5 100644
--- a/saber/funcs/impl/impl_pad.h
+++ b/saber/funcs/impl/impl_pad.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_permute.h b/saber/funcs/impl/impl_permute.h
index 675eecc..09a6eac 100644
--- a/saber/funcs/impl/impl_permute.h
+++ b/saber/funcs/impl/impl_permute.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_permute_power.h b/saber/funcs/impl/impl_permute_power.h
index 81f6b57..ec48641 100644
--- a/saber/funcs/impl/impl_permute_power.h
+++ b/saber/funcs/impl/impl_permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_pooling.h b/saber/funcs/impl/impl_pooling.h
index b2b7195..aeb5ab9 100644
--- a/saber/funcs/impl/impl_pooling.h
+++ b/saber/funcs/impl/impl_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_pooling_with_index.h b/saber/funcs/impl/impl_pooling_with_index.h
index 911fc7e..d4c6bd8 100644
--- a/saber/funcs/impl/impl_pooling_with_index.h
+++ b/saber/funcs/impl/impl_pooling_with_index.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_power.h b/saber/funcs/impl/impl_power.h
index 6e6e9a3..4129b04 100644
--- a/saber/funcs/impl/impl_power.h
+++ b/saber/funcs/impl/impl_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_prelu.h b/saber/funcs/impl/impl_prelu.h
deleted file mode 100644
index f65f26d..0000000
--- a/saber/funcs/impl/impl_prelu.h
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-  http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_IMPL_PRELU_H
-#define ANAKIN_SABER_FUNCS_IMPL_PRELU_H
-
-#include "saber/funcs/impl/impl_macro.h"
-namespace anakin{
-
-namespace saber{
-
-DEFINE_OP_CLASS(Prelu, PreluParam);
-
-}
-}
-
-#endif //ANAKIN_SABER_FUNCS_IMPL_PRELU_H
diff --git a/saber/funcs/impl/impl_priorbox.h b/saber/funcs/impl/impl_priorbox.h
index 94fc72d..5686102 100644
--- a/saber/funcs/impl/impl_priorbox.h
+++ b/saber/funcs/impl/impl_priorbox.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_reshape.h b/saber/funcs/impl/impl_reshape.h
index 025d3cd..65a4337 100644
--- a/saber/funcs/impl/impl_reshape.h
+++ b/saber/funcs/impl/impl_reshape.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_resize.h b/saber/funcs/impl/impl_resize.h
index d7aaae4..5a978b6 100644
--- a/saber/funcs/impl/impl_resize.h
+++ b/saber/funcs/impl/impl_resize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_roi_pooling.h b/saber/funcs/impl/impl_roi_pooling.h
index 38882c5..c559561 100644
--- a/saber/funcs/impl/impl_roi_pooling.h
+++ b/saber/funcs/impl/impl_roi_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_scale.h b/saber/funcs/impl/impl_scale.h
index f00897b..38f467f 100644
--- a/saber/funcs/impl/impl_scale.h
+++ b/saber/funcs/impl/impl_scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_sequence_conv.h b/saber/funcs/impl/impl_sequence_conv.h
new file mode 100644
index 0000000..636dfcc
--- /dev/null
+++ b/saber/funcs/impl/impl_sequence_conv.h
@@ -0,0 +1,29 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_SEQUENCECONV_H
+#define ANAKIN_SABER_FUNCS_IMPL_SEQUENCECONV_H
+
+#include "saber/funcs/impl/impl_macro.h"
+namespace anakin {
+
+namespace saber {
+
+DEFINE_OP_CLASS(SequenceConv, SequenceConvParam);
+
+}
+}
+
+#endif //ANAKIN_SABER_FUNCS_IMPL_SEQUENCEPOOL_H
diff --git a/saber/funcs/impl/impl_sequence_pool.h b/saber/funcs/impl/impl_sequence_pool.h
index c5ceb5a..22730a5 100644
--- a/saber/funcs/impl/impl_sequence_pool.h
+++ b/saber/funcs/impl/impl_sequence_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_slice.h b/saber/funcs/impl/impl_slice.h
index be54fac..d69561f 100644
--- a/saber/funcs/impl/impl_slice.h
+++ b/saber/funcs/impl/impl_slice.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_softmax.h b/saber/funcs/impl/impl_softmax.h
index a91d0af..76aa685 100644
--- a/saber/funcs/impl/impl_softmax.h
+++ b/saber/funcs/impl/impl_softmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_spp.h b/saber/funcs/impl/impl_spp.h
index 6466226..f708f05 100644
--- a/saber/funcs/impl/impl_spp.h
+++ b/saber/funcs/impl/impl_spp.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_transpose.h b/saber/funcs/impl/impl_transpose.h
index f5313f9..22eb54c 100644
--- a/saber/funcs/impl/impl_transpose.h
+++ b/saber/funcs/impl/impl_transpose.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/impl_unpool.h b/saber/funcs/impl/impl_unpool.h
index a2f57ab..3a0f664 100644
--- a/saber/funcs/impl/impl_unpool.h
+++ b/saber/funcs/impl/impl_unpool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/impl/x86/activation_functions.h b/saber/funcs/impl/x86/activation_functions.h
new file mode 100644
index 0000000..c2b9d13
--- /dev/null
+++ b/saber/funcs/impl/x86/activation_functions.h
@@ -0,0 +1,186 @@
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_MATH_ACTIVATION_FUNCTIONS_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_MATH_ACTIVATION_FUNCTIONS_H
+#include <math.h>
+#include <string>
+#include "saber/saber_types.h"
+#include "utils/logger/logger.h"
+#include "saber/funcs/impl/x86/saber_avx2_math.h"
+
+namespace anakin {
+namespace saber {
+namespace math {
+
+template <typename T>
+void sigmoid(size_t len, T *x, T *y) {
+    for (size_t i = 0; i < len; i++) {
+        y[i] = 1. / (1. + exp(-x[i]));
+    }
+}
+
+template <typename T>
+void parallel_sigmoid(size_t len, T *x, T *y) {
+#pragma omp parallel for
+    for (size_t i = 0; i < len; i++) {
+        y[i] = 1. / (1. + exp(-x[i]));
+    }
+}
+
+template <typename T>
+void relu(size_t len, T *x, T *y) {
+    for (size_t i = 0; i < len; i++) {
+        y[i] = x[i] < 0 ? 0 : x[i];
+    }
+}
+
+template <typename T>
+void parallel_relu(size_t len, T *x, T *y) {
+#pragma omp parallel for
+    for (size_t i = 0; i < len; i++) {
+        y[i] = x[i] < 0 ? 0 : x[i];
+    }
+}
+
+template <typename T>
+void tanh(size_t len, T *x, T *y) {
+    for (size_t i = 0; i < len; i++) {
+        T e_x = exp(2 * x[i]);
+        y[i] = (e_x - 1) / (e_x + 1);
+    }
+}
+
+template <typename T>
+void parallel_tanh(size_t len, T *x, T *y) {
+#pragma omp parallel for
+    for (size_t i = 0; i < len; i++) {
+        T e_x = exp(2 * x[i]);
+        y[i] = (e_x - 1) / (e_x + 1);
+    }
+}
+
+template <typename T>
+void stanh(size_t len, T *x, T *y) {
+    for (size_t i = 0; i < len; i++) {
+        T e_x = exp(4. * x[i] / 3.);
+        y[i] = 1.7159 * (e_x - 1) / (e_x + 1);
+    }
+}
+
+template <typename T>
+void parallel_stanh(size_t len, T *x, T *y) {
+#pragma omp parallel for
+    for (size_t i = 0; i < len; i++) {
+        T e_x = exp(4. * x[i] / 3.);
+        y[i] = 1.7159 * (e_x - 1) / (e_x + 1);
+    }
+}
+
+template <typename T>
+void identity(size_t len, T *x, T *y) {
+    for (size_t i = 0; i < len; i++) {
+        y[i] = x[i];
+    }
+}
+
+template <typename T>
+void parallel_identity(size_t len, T *x, T *y) {
+#pragma omp parallel for
+    for (size_t i = 0; i < len; i++) {
+        y[i] = x[i];
+    }
+}
+
+template <typename T>
+struct Active {
+    typedef void (*Act)(size_t, T*, T*);
+    typedef T (*Act_m256)(T);
+};
+
+static Active<float>::Act k_act_float[] = {
+        nullptr,
+        &sigmoid<float>,
+        &relu<float>,
+        &tanh<float>,
+        nullptr,
+        nullptr,
+        &identity<float>,
+        &sigmoid<float>,
+        &tanh<float>,
+        &stanh<float>
+};
+
+static Active<float>::Act k_parallel_act_float[] = {
+        nullptr,
+        &parallel_sigmoid<float>,
+        &parallel_relu<float>,
+        &parallel_tanh<float>,
+        nullptr,
+        nullptr,
+        &parallel_identity<float>,
+        &parallel_sigmoid<float>,
+        &parallel_tanh<float>,
+        &parallel_stanh<float>
+};
+
+inline void activation(size_t len, float *src, float *dst, int index) {
+    auto *func = k_act_float[index];
+    if (!func) {
+                LOG(ERROR) << "activation not implemented!";
+    }
+    func(len, src, dst);
+}
+
+inline void parallel_activation(size_t len, float *src, float *dst, int index) {
+    auto *func = k_parallel_act_float[index];
+    if (!func) {
+                LOG(ERROR) << "activation not implemented!";
+    }
+    func(len, src, dst);
+}
+
+#ifdef __AVX__
+inline __m256 Exp(__m256 a) { return exp256_ps(a); }
+
+inline __m256 Relu(const __m256 a) {
+    __m256 tmp = _mm256_set1_ps(0.0f);
+    return _mm256_max_ps(a, tmp);
+}
+
+inline __m256 Sigmoid(const __m256 a) {
+    __m256 tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), a);
+    tmp = Exp(tmp);
+    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
+    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m256 Tanh(const __m256 a) {
+    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
+    tmp = Exp(tmp);
+    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
+                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
+                         _mm256_set1_ps(1.0f));
+}
+
+inline __m256 Identity(const __m256 a) { return a; }
+
+static Active<__m256>::Act_m256 k_act_avx[] = {
+        nullptr,
+        &Sigmoid,
+        &Relu,
+        &Tanh,
+        nullptr,
+        nullptr,
+        &Identity,
+        &Sigmoid,
+        &Tanh,
+        nullptr
+};
+inline __m256 avx_activation(__m256 a, int index) {
+    return k_act_avx[index](a);
+}
+#endif
+}  // namespace math
+}  // namespace saber
+}  // namespace anakin
+#endif  //ANAKIN_SABER_FUNCS_IMPL_X86_MATH_ACTIVATION_FUNCTIONS_H
diff --git a/saber/funcs/impl/x86/avx_mathfun.h b/saber/funcs/impl/x86/avx_mathfun.h
deleted file mode 100644
index 8e698e7..0000000
--- a/saber/funcs/impl/x86/avx_mathfun.h
+++ /dev/null
@@ -1,735 +0,0 @@
-//  Copyright (c) 2018 PaddlePaddle Authors. All Rights Reserved.
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//    http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-/*
-   AVX implementation of sin, cos, sincos, exp and log
-
-   Based on "sse_mathfun.h", by Julien Pommier
-   http://gruntthepeon.free.fr/ssemath/
-
-   Copyright (C) 2012 Giovanni Garberoglio
-   Interdisciplinary Laboratory for Computational Science (LISC)
-   Fondazione Bruno Kessler and University of Trento
-   via Sommarive, 18
-   I-38123 Trento (Italy)
-
-  This software is provided 'as-is', without any express or implied
-  warranty.  In no event will the authors be held liable for any damages
-  arising from the use of this software.
-
-  Permission is granted to anyone to use this software for any purpose,
-  including commercial applications, and to alter it and redistribute it
-  freely, subject to the following restrictions:
-
-  1. The origin of this software must not be misrepresented; you must not
-     claim that you wrote the original software. If you use this software
-     in a product, an acknowledgment in the product documentation would be
-     appreciated but is not required.
-  2. Altered source versions must be plainly marked as such, and must not be
-     misrepresented as being the original software.
-  3. This notice may not be removed or altered from any source distribution.
-
-  (this is the zlib license)
-*/
-
-#include <immintrin.h>
-
-/* yes I know, the top of this file is quite ugly */
-#define ALIGN32_BEG
-#define ALIGN32_END __attribute__((aligned(32)))
-
-/* __m128 is ugly to write */
-typedef __m256 v8sf;   // vector of 8 float (avx)
-typedef __m256i v8si;  // vector of 8 int   (avx)
-typedef __m128i v4si;  // vector of 8 int   (avx)
-
-#define _PI32AVX_CONST(Name, Val)                                 \
-  static const ALIGN32_BEG int _pi32avx_##Name[4] ALIGN32_END = { \
-      Val, Val, Val, Val}
-
-_PI32AVX_CONST(1, 1);
-_PI32AVX_CONST(inv1, ~1);
-_PI32AVX_CONST(2, 2);
-_PI32AVX_CONST(4, 4);
-
-/* declare some AVX constants -- why can't I figure a better way to do that? */
-#define _PS256_CONST(Name, Val)                                   \
-  static const ALIGN32_BEG float _ps256_##Name[8] ALIGN32_END = { \
-      Val, Val, Val, Val, Val, Val, Val, Val}
-#define _PI32_CONST256(Name, Val)                                  \
-  static const ALIGN32_BEG int _pi32_256_##Name[8] ALIGN32_END = { \
-      Val, Val, Val, Val, Val, Val, Val, Val}
-#define _PS256_CONST_TYPE(Name, Type, Val)                       \
-  static const ALIGN32_BEG Type _ps256_##Name[8] ALIGN32_END = { \
-      Val, Val, Val, Val, Val, Val, Val, Val}
-
-_PS256_CONST(1, 1.0f);
-_PS256_CONST(0p5, 0.5f);
-/* the smallest non denormalized float number */
-_PS256_CONST_TYPE(min_norm_pos, int, 0x00800000);
-_PS256_CONST_TYPE(mant_mask, int, 0x7f800000);
-_PS256_CONST_TYPE(inv_mant_mask, int, ~0x7f800000);
-
-_PS256_CONST_TYPE(sign_mask, int, (int)0x80000000);
-_PS256_CONST_TYPE(inv_sign_mask, int, ~0x80000000);
-
-_PI32_CONST256(0, 0);
-_PI32_CONST256(1, 1);
-_PI32_CONST256(inv1, ~1);
-_PI32_CONST256(2, 2);
-_PI32_CONST256(4, 4);
-_PI32_CONST256(0x7f, 0x7f);
-
-_PS256_CONST(cephes_SQRTHF, 0.707106781186547524);
-_PS256_CONST(cephes_log_p0, 7.0376836292E-2);
-_PS256_CONST(cephes_log_p1, -1.1514610310E-1);
-_PS256_CONST(cephes_log_p2, 1.1676998740E-1);
-_PS256_CONST(cephes_log_p3, -1.2420140846E-1);
-_PS256_CONST(cephes_log_p4, +1.4249322787E-1);
-_PS256_CONST(cephes_log_p5, -1.6668057665E-1);
-_PS256_CONST(cephes_log_p6, +2.0000714765E-1);
-_PS256_CONST(cephes_log_p7, -2.4999993993E-1);
-_PS256_CONST(cephes_log_p8, +3.3333331174E-1);
-_PS256_CONST(cephes_log_q1, -2.12194440e-4);
-_PS256_CONST(cephes_log_q2, 0.693359375);
-
-#ifndef __AVX2__
-
-typedef union imm_xmm_union {
-  v8si imm;
-  v4si xmm[2];
-} imm_xmm_union;
-
-#define COPY_IMM_TO_XMM(imm_, xmm0_, xmm1_)       \
-  {                                               \
-    imm_xmm_union u __attribute__((aligned(32))); \
-    u.imm = imm_;                                 \
-    xmm0_ = u.xmm[0];                             \
-    xmm1_ = u.xmm[1];                             \
-  }
-
-#define COPY_XMM_TO_IMM(xmm0_, xmm1_, imm_)       \
-  {                                               \
-    imm_xmm_union u __attribute__((aligned(32))); \
-    u.xmm[0] = xmm0_;                             \
-    u.xmm[1] = xmm1_;                             \
-    imm_ = u.imm;                                 \
-  }
-
-#define AVX2_BITOP_USING_SSE2(fn)                        \
-  static inline v8si avx2_mm256_##fn(v8si x, int a) {    \
-    /* use SSE2 instruction to perform the bitop AVX2 */ \
-    v4si x1, x2;                                         \
-    v8si ret;                                            \
-    COPY_IMM_TO_XMM(x, x1, x2);                          \
-    x1 = _mm_##fn(x1, a);                                \
-    x2 = _mm_##fn(x2, a);                                \
-    COPY_XMM_TO_IMM(x1, x2, ret);                        \
-    return (ret);                                        \
-  }
-
-//#warning "Using SSE2 to perform AVX2 bitshift ops"
-AVX2_BITOP_USING_SSE2(slli_epi32)
-AVX2_BITOP_USING_SSE2(srli_epi32)
-
-#define AVX2_INTOP_USING_SSE2(fn)                                     \
-  static inline v8si avx2_mm256_##fn(v8si x, v8si y) {                \
-    /* use SSE2 instructions to perform the AVX2 integer operation */ \
-    v4si x1, x2;                                                      \
-    v4si y1, y2;                                                      \
-    v8si ret;                                                         \
-    COPY_IMM_TO_XMM(x, x1, x2);                                       \
-    COPY_IMM_TO_XMM(y, y1, y2);                                       \
-    x1 = _mm_##fn(x1, y1);                                            \
-    x2 = _mm_##fn(x2, y2);                                            \
-    COPY_XMM_TO_IMM(x1, x2, ret);                                     \
-    return (ret);                                                     \
-  }
-
-//#warning "Using SSE2 to perform AVX2 integer ops"
-AVX2_INTOP_USING_SSE2(and_si128)
-AVX2_INTOP_USING_SSE2(andnot_si128)
-AVX2_INTOP_USING_SSE2(cmpeq_epi32)
-AVX2_INTOP_USING_SSE2(sub_epi32)
-AVX2_INTOP_USING_SSE2(add_epi32)
-#define avx2_mm256_and_si256 avx2_mm256_and_si128
-#define avx2_mm256_andnot_si256 avx2_mm256_andnot_si128
-#else
-#define avx2_mm256_slli_epi32 _mm256_slli_epi32
-#define avx2_mm256_srli_epi32 _mm256_srli_epi32
-#define avx2_mm256_and_si256 _mm256_and_si256
-#define avx2_mm256_andnot_si256 _mm256_andnot_si256
-#define avx2_mm256_cmpeq_epi32 _mm256_cmpeq_epi32
-#define avx2_mm256_sub_epi32 _mm256_sub_epi32
-#define avx2_mm256_add_epi32 _mm256_add_epi32
-#endif /* __AVX2__ */
-
-/* natural logarithm computed for 8 simultaneous float
-   return NaN for x <= 0
-*/
-v8sf log256_ps(v8sf x) {
-  v8si imm0;
-  v8sf one = *(v8sf *)_ps256_1;
-
-  // v8sf invalid_mask = _mm256_cmple_ps(x, _mm256_setzero_ps());
-  v8sf invalid_mask = _mm256_cmp_ps(x, _mm256_setzero_ps(), _CMP_LE_OS);
-
-  x = _mm256_max_ps(
-      x, *(v8sf *)_ps256_min_norm_pos); /* cut off denormalized stuff */
-
-  // can be done with AVX2
-  imm0 = avx2_mm256_srli_epi32(_mm256_castps_si256(x), 23);
-
-  /* keep only the fractional part */
-  x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_mant_mask);
-  x = _mm256_or_ps(x, *(v8sf *)_ps256_0p5);
-
-  // this is again another AVX2 instruction
-  imm0 = avx2_mm256_sub_epi32(imm0, *(v8si *)_pi32_256_0x7f);
-  v8sf e = _mm256_cvtepi32_ps(imm0);
-
-  e = _mm256_add_ps(e, one);
-
-  /* part2:
-     if( x < SQRTHF ) {
-       e -= 1;
-       x = x + x - 1.0;
-     } else { x = x - 1.0; }
-  */
-  // v8sf mask = _mm256_cmplt_ps(x, *(v8sf*)_ps256_cephes_SQRTHF);
-  v8sf mask = _mm256_cmp_ps(x, *(v8sf *)_ps256_cephes_SQRTHF, _CMP_LT_OS);
-  v8sf tmp = _mm256_and_ps(x, mask);
-  x = _mm256_sub_ps(x, one);
-  e = _mm256_sub_ps(e, _mm256_and_ps(one, mask));
-  x = _mm256_add_ps(x, tmp);
-
-  v8sf z = _mm256_mul_ps(x, x);
-
-  v8sf y = *(v8sf *)_ps256_cephes_log_p0;
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p1);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p2);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p3);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p4);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p5);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p6);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p7);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p8);
-  y = _mm256_mul_ps(y, x);
-
-  y = _mm256_mul_ps(y, z);
-
-  tmp = _mm256_mul_ps(e, *(v8sf *)_ps256_cephes_log_q1);
-  y = _mm256_add_ps(y, tmp);
-
-  tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
-  y = _mm256_sub_ps(y, tmp);
-
-  tmp = _mm256_mul_ps(e, *(v8sf *)_ps256_cephes_log_q2);
-  x = _mm256_add_ps(x, y);
-  x = _mm256_add_ps(x, tmp);
-  x = _mm256_or_ps(x, invalid_mask);  // negative arg will be NAN
-  return x;
-}
-
-_PS256_CONST(exp_hi, 88.3762626647949f);
-_PS256_CONST(exp_lo, -88.3762626647949f);
-
-_PS256_CONST(cephes_LOG2EF, 1.44269504088896341);
-_PS256_CONST(cephes_exp_C1, 0.693359375);
-_PS256_CONST(cephes_exp_C2, -2.12194440e-4);
-
-_PS256_CONST(cephes_exp_p0, 1.9875691500E-4);
-_PS256_CONST(cephes_exp_p1, 1.3981999507E-3);
-_PS256_CONST(cephes_exp_p2, 8.3334519073E-3);
-_PS256_CONST(cephes_exp_p3, 4.1665795894E-2);
-_PS256_CONST(cephes_exp_p4, 1.6666665459E-1);
-_PS256_CONST(cephes_exp_p5, 5.0000001201E-1);
-
-v8sf exp256_ps(v8sf x) {
-  v8sf tmp = _mm256_setzero_ps(), fx;
-  v8si imm0;
-  v8sf one = *(v8sf *)_ps256_1;
-
-  x = _mm256_min_ps(x, *(v8sf *)_ps256_exp_hi);
-  x = _mm256_max_ps(x, *(v8sf *)_ps256_exp_lo);
-
-  /* express exp(x) as exp(g + n*log(2)) */
-  fx = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_LOG2EF);
-  fx = _mm256_add_ps(fx, *(v8sf *)_ps256_0p5);
-
-  /* how to perform a floorf with SSE: just below */
-  // imm0 = _mm256_cvttps_epi32(fx);
-  // tmp  = _mm256_cvtepi32_ps(imm0);
-
-  tmp = _mm256_floor_ps(fx);
-
-  /* if greater, substract 1 */
-  // v8sf mask = _mm256_cmpgt_ps(tmp, fx);
-  v8sf mask = _mm256_cmp_ps(tmp, fx, _CMP_GT_OS);
-  mask = _mm256_and_ps(mask, one);
-  fx = _mm256_sub_ps(tmp, mask);
-
-  tmp = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C1);
-  v8sf z = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C2);
-  x = _mm256_sub_ps(x, tmp);
-  x = _mm256_sub_ps(x, z);
-
-  z = _mm256_mul_ps(x, x);
-
-  v8sf y = *(v8sf *)_ps256_cephes_exp_p0;
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p1);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p2);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p3);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p4);
-  y = _mm256_mul_ps(y, x);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p5);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, x);
-  y = _mm256_add_ps(y, one);
-
-  /* build 2^n */
-  imm0 = _mm256_cvttps_epi32(fx);
-  // another two AVX2 instructions
-  imm0 = avx2_mm256_add_epi32(imm0, *(v8si *)_pi32_256_0x7f);
-  imm0 = avx2_mm256_slli_epi32(imm0, 23);
-  v8sf pow2n = _mm256_castsi256_ps(imm0);
-  y = _mm256_mul_ps(y, pow2n);
-  return y;
-}
-
-_PS256_CONST(minus_cephes_DP1, -0.78515625);
-_PS256_CONST(minus_cephes_DP2, -2.4187564849853515625e-4);
-_PS256_CONST(minus_cephes_DP3, -3.77489497744594108e-8);
-_PS256_CONST(sincof_p0, -1.9515295891E-4);
-_PS256_CONST(sincof_p1, 8.3321608736E-3);
-_PS256_CONST(sincof_p2, -1.6666654611E-1);
-_PS256_CONST(coscof_p0, 2.443315711809948E-005);
-_PS256_CONST(coscof_p1, -1.388731625493765E-003);
-_PS256_CONST(coscof_p2, 4.166664568298827E-002);
-_PS256_CONST(cephes_FOPI, 1.27323954473516);  // 4 / M_PI
-
-/* evaluation of 8 sines at onces using AVX intrisics
-
-   The code is the exact rewriting of the cephes sinf function.
-   Precision is excellent as long as x < 8192 (I did not bother to
-   take into account the special handling they have for greater values
-   -- it does not return garbage for arguments over 8192, though, but
-   the extra precision is missing).
-
-   Note that it is such that sinf((float)M_PI) = 8.74e-8, which is the
-   surprising but correct result.
-
-*/
-v8sf sin256_ps(v8sf x) {  // any x
-  v8sf xmm1, xmm2 = _mm256_setzero_ps(), xmm3, sign_bit, y;
-  v8si imm0, imm2;
-
-#ifndef __AVX2__
-  v4si imm0_1, imm0_2;
-  v4si imm2_1, imm2_2;
-#endif
-
-  sign_bit = x;
-  /* take the absolute value */
-  x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
-  /* extract the sign bit (upper one) */
-  sign_bit = _mm256_and_ps(sign_bit, *(v8sf *)_ps256_sign_mask);
-
-  /* scale by 4/Pi */
-  y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
-
-/*
-  Here we start a series of integer operations, which are in the
-  realm of AVX2.
-  If we don't have AVX, let's perform them using SSE2 directives
-*/
-
-#ifdef __AVX2__
-  /* store the integer part of y in mm0 */
-  imm2 = _mm256_cvttps_epi32(y);
-  /* j=(j+1) & (~1) (see the cephes sources) */
-  // another two AVX2 instruction
-  imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
-  y = _mm256_cvtepi32_ps(imm2);
-
-  /* get the swap sign flag */
-  imm0 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_4);
-  imm0 = avx2_mm256_slli_epi32(imm0, 29);
-  /* get the polynom selection mask
-     there is one polynom for 0 <= x <= Pi/4
-     and another one for Pi/4<x<=Pi/2
-
-     Both branches will be computed.
-  */
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
-  imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
-#else
-  /* we use SSE2 routines to perform the integer ops */
-  COPY_IMM_TO_XMM(_mm256_cvttps_epi32(y), imm2_1, imm2_2);
-
-  imm2_1 = _mm_add_epi32(imm2_1, *(v4si *)_pi32avx_1);
-  imm2_2 = _mm_add_epi32(imm2_2, *(v4si *)_pi32avx_1);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_inv1);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_inv1);
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-  y = _mm256_cvtepi32_ps(imm2);
-
-  imm0_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_4);
-  imm0_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_4);
-
-  imm0_1 = _mm_slli_epi32(imm0_1, 29);
-  imm0_2 = _mm_slli_epi32(imm0_2, 29);
-
-  COPY_XMM_TO_IMM(imm0_1, imm0_2, imm0);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_2);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_2);
-
-  imm2_1 = _mm_cmpeq_epi32(imm2_1, _mm_setzero_si128());
-  imm2_2 = _mm_cmpeq_epi32(imm2_2, _mm_setzero_si128());
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-#endif
-
-  v8sf swap_sign_bit = _mm256_castsi256_ps(imm0);
-  v8sf poly_mask = _mm256_castsi256_ps(imm2);
-  sign_bit = _mm256_xor_ps(sign_bit, swap_sign_bit);
-
-  /* The magic pass: "Extended precision modular arithmetic"
-     x = ((x - y * DP1) - y * DP2) - y * DP3; */
-  xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
-  xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
-  xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
-  xmm1 = _mm256_mul_ps(y, xmm1);
-  xmm2 = _mm256_mul_ps(y, xmm2);
-  xmm3 = _mm256_mul_ps(y, xmm3);
-  x = _mm256_add_ps(x, xmm1);
-  x = _mm256_add_ps(x, xmm2);
-  x = _mm256_add_ps(x, xmm3);
-
-  /* Evaluate the first polynom  (0 <= x <= Pi/4) */
-  y = *(v8sf *)_ps256_coscof_p0;
-  v8sf z = _mm256_mul_ps(x, x);
-
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_mul_ps(y, z);
-  v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
-  y = _mm256_sub_ps(y, tmp);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
-
-  /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
-
-  v8sf y2 = *(v8sf *)_ps256_sincof_p0;
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_mul_ps(y2, x);
-  y2 = _mm256_add_ps(y2, x);
-
-  /* select the correct result from the two polynoms */
-  xmm3 = poly_mask;
-  y2 = _mm256_and_ps(xmm3, y2);  //, xmm3);
-  y = _mm256_andnot_ps(xmm3, y);
-  y = _mm256_add_ps(y, y2);
-  /* update the sign */
-  y = _mm256_xor_ps(y, sign_bit);
-
-  return y;
-}
-
-/* almost the same as sin_ps */
-v8sf cos256_ps(v8sf x) {  // any x
-  v8sf xmm1, xmm2 = _mm256_setzero_ps(), xmm3, y;
-  v8si imm0, imm2;
-
-#ifndef __AVX2__
-  v4si imm0_1, imm0_2;
-  v4si imm2_1, imm2_2;
-#endif
-
-  /* take the absolute value */
-  x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
-
-  /* scale by 4/Pi */
-  y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
-
-#ifdef __AVX2__
-  /* store the integer part of y in mm0 */
-  imm2 = _mm256_cvttps_epi32(y);
-  /* j=(j+1) & (~1) (see the cephes sources) */
-  imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
-  y = _mm256_cvtepi32_ps(imm2);
-  imm2 = avx2_mm256_sub_epi32(imm2, *(v8si *)_pi32_256_2);
-
-  /* get the swap sign flag */
-  imm0 = avx2_mm256_andnot_si256(imm2, *(v8si *)_pi32_256_4);
-  imm0 = avx2_mm256_slli_epi32(imm0, 29);
-  /* get the polynom selection mask */
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
-  imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
-#else
-
-  /* we use SSE2 routines to perform the integer ops */
-  COPY_IMM_TO_XMM(_mm256_cvttps_epi32(y), imm2_1, imm2_2);
-
-  imm2_1 = _mm_add_epi32(imm2_1, *(v4si *)_pi32avx_1);
-  imm2_2 = _mm_add_epi32(imm2_2, *(v4si *)_pi32avx_1);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_inv1);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_inv1);
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-  y = _mm256_cvtepi32_ps(imm2);
-
-  imm2_1 = _mm_sub_epi32(imm2_1, *(v4si *)_pi32avx_2);
-  imm2_2 = _mm_sub_epi32(imm2_2, *(v4si *)_pi32avx_2);
-
-  imm0_1 = _mm_andnot_si128(imm2_1, *(v4si *)_pi32avx_4);
-  imm0_2 = _mm_andnot_si128(imm2_2, *(v4si *)_pi32avx_4);
-
-  imm0_1 = _mm_slli_epi32(imm0_1, 29);
-  imm0_2 = _mm_slli_epi32(imm0_2, 29);
-
-  COPY_XMM_TO_IMM(imm0_1, imm0_2, imm0);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_2);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_2);
-
-  imm2_1 = _mm_cmpeq_epi32(imm2_1, _mm_setzero_si128());
-  imm2_2 = _mm_cmpeq_epi32(imm2_2, _mm_setzero_si128());
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-#endif
-
-  v8sf sign_bit = _mm256_castsi256_ps(imm0);
-  v8sf poly_mask = _mm256_castsi256_ps(imm2);
-
-  /* The magic pass: "Extended precision modular arithmetic"
-     x = ((x - y * DP1) - y * DP2) - y * DP3; */
-  xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
-  xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
-  xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
-  xmm1 = _mm256_mul_ps(y, xmm1);
-  xmm2 = _mm256_mul_ps(y, xmm2);
-  xmm3 = _mm256_mul_ps(y, xmm3);
-  x = _mm256_add_ps(x, xmm1);
-  x = _mm256_add_ps(x, xmm2);
-  x = _mm256_add_ps(x, xmm3);
-
-  /* Evaluate the first polynom  (0 <= x <= Pi/4) */
-  y = *(v8sf *)_ps256_coscof_p0;
-  v8sf z = _mm256_mul_ps(x, x);
-
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_mul_ps(y, z);
-  v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
-  y = _mm256_sub_ps(y, tmp);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
-
-  /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
-
-  v8sf y2 = *(v8sf *)_ps256_sincof_p0;
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_mul_ps(y2, x);
-  y2 = _mm256_add_ps(y2, x);
-
-  /* select the correct result from the two polynoms */
-  xmm3 = poly_mask;
-  y2 = _mm256_and_ps(xmm3, y2);  //, xmm3);
-  y = _mm256_andnot_ps(xmm3, y);
-  y = _mm256_add_ps(y, y2);
-  /* update the sign */
-  y = _mm256_xor_ps(y, sign_bit);
-
-  return y;
-}
-
-/* since sin256_ps and cos256_ps are almost identical, sincos256_ps could
-   replace both of them..
-   it is almost as fast, and gives you a free cosine with your sine */
-void sincos256_ps(v8sf x, v8sf *s, v8sf *c) {
-  v8sf xmm1, xmm2, xmm3 = _mm256_setzero_ps(), sign_bit_sin, y;
-  v8si imm0, imm2, imm4;
-
-#ifndef __AVX2__
-  v4si imm0_1, imm0_2;
-  v4si imm2_1, imm2_2;
-  v4si imm4_1, imm4_2;
-#endif
-
-  sign_bit_sin = x;
-  /* take the absolute value */
-  x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
-  /* extract the sign bit (upper one) */
-  sign_bit_sin = _mm256_and_ps(sign_bit_sin, *(v8sf *)_ps256_sign_mask);
-
-  /* scale by 4/Pi */
-  y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
-
-#ifdef __AVX2__
-  /* store the integer part of y in imm2 */
-  imm2 = _mm256_cvttps_epi32(y);
-
-  /* j=(j+1) & (~1) (see the cephes sources) */
-  imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
-
-  y = _mm256_cvtepi32_ps(imm2);
-  imm4 = imm2;
-
-  /* get the swap sign flag for the sine */
-  imm0 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_4);
-  imm0 = avx2_mm256_slli_epi32(imm0, 29);
-  // v8sf swap_sign_bit_sin = _mm256_castsi256_ps(imm0);
-
-  /* get the polynom selection mask for the sine*/
-  imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
-  imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
-// v8sf poly_mask = _mm256_castsi256_ps(imm2);
-#else
-  /* we use SSE2 routines to perform the integer ops */
-  COPY_IMM_TO_XMM(_mm256_cvttps_epi32(y), imm2_1, imm2_2);
-
-  imm2_1 = _mm_add_epi32(imm2_1, *(v4si *)_pi32avx_1);
-  imm2_2 = _mm_add_epi32(imm2_2, *(v4si *)_pi32avx_1);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_inv1);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_inv1);
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-  y = _mm256_cvtepi32_ps(imm2);
-
-  imm4_1 = imm2_1;
-  imm4_2 = imm2_2;
-
-  imm0_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_4);
-  imm0_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_4);
-
-  imm0_1 = _mm_slli_epi32(imm0_1, 29);
-  imm0_2 = _mm_slli_epi32(imm0_2, 29);
-
-  COPY_XMM_TO_IMM(imm0_1, imm0_2, imm0);
-
-  imm2_1 = _mm_and_si128(imm2_1, *(v4si *)_pi32avx_2);
-  imm2_2 = _mm_and_si128(imm2_2, *(v4si *)_pi32avx_2);
-
-  imm2_1 = _mm_cmpeq_epi32(imm2_1, _mm_setzero_si128());
-  imm2_2 = _mm_cmpeq_epi32(imm2_2, _mm_setzero_si128());
-
-  COPY_XMM_TO_IMM(imm2_1, imm2_2, imm2);
-#endif
-  v8sf swap_sign_bit_sin = _mm256_castsi256_ps(imm0);
-  v8sf poly_mask = _mm256_castsi256_ps(imm2);
-
-  /* The magic pass: "Extended precision modular arithmetic"
-     x = ((x - y * DP1) - y * DP2) - y * DP3; */
-  xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
-  xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
-  xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
-  xmm1 = _mm256_mul_ps(y, xmm1);
-  xmm2 = _mm256_mul_ps(y, xmm2);
-  xmm3 = _mm256_mul_ps(y, xmm3);
-  x = _mm256_add_ps(x, xmm1);
-  x = _mm256_add_ps(x, xmm2);
-  x = _mm256_add_ps(x, xmm3);
-
-#ifdef __AVX2__
-  imm4 = avx2_mm256_sub_epi32(imm4, *(v8si *)_pi32_256_2);
-  imm4 = avx2_mm256_andnot_si256(imm4, *(v8si *)_pi32_256_4);
-  imm4 = avx2_mm256_slli_epi32(imm4, 29);
-#else
-  imm4_1 = _mm_sub_epi32(imm4_1, *(v4si *)_pi32avx_2);
-  imm4_2 = _mm_sub_epi32(imm4_2, *(v4si *)_pi32avx_2);
-
-  imm4_1 = _mm_andnot_si128(imm4_1, *(v4si *)_pi32avx_4);
-  imm4_2 = _mm_andnot_si128(imm4_2, *(v4si *)_pi32avx_4);
-
-  imm4_1 = _mm_slli_epi32(imm4_1, 29);
-  imm4_2 = _mm_slli_epi32(imm4_2, 29);
-
-  COPY_XMM_TO_IMM(imm4_1, imm4_2, imm4);
-#endif
-
-  v8sf sign_bit_cos = _mm256_castsi256_ps(imm4);
-
-  sign_bit_sin = _mm256_xor_ps(sign_bit_sin, swap_sign_bit_sin);
-
-  /* Evaluate the first polynom  (0 <= x <= Pi/4) */
-  v8sf z = _mm256_mul_ps(x, x);
-  y = *(v8sf *)_ps256_coscof_p0;
-
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
-  y = _mm256_mul_ps(y, z);
-  y = _mm256_mul_ps(y, z);
-  v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
-  y = _mm256_sub_ps(y, tmp);
-  y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
-
-  /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
-
-  v8sf y2 = *(v8sf *)_ps256_sincof_p0;
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
-  y2 = _mm256_mul_ps(y2, z);
-  y2 = _mm256_mul_ps(y2, x);
-  y2 = _mm256_add_ps(y2, x);
-
-  /* select the correct result from the two polynoms */
-  xmm3 = poly_mask;
-  v8sf ysin2 = _mm256_and_ps(xmm3, y2);
-  v8sf ysin1 = _mm256_andnot_ps(xmm3, y);
-  y2 = _mm256_sub_ps(y2, ysin2);
-  y = _mm256_sub_ps(y, ysin1);
-
-  xmm1 = _mm256_add_ps(ysin1, ysin2);
-  xmm2 = _mm256_add_ps(y, y2);
-
-  /* update the sign */
-  *s = _mm256_xor_ps(xmm1, sign_bit_sin);
-  *c = _mm256_xor_ps(xmm2, sign_bit_cos);
-}
diff --git a/saber/funcs/impl/x86/jit_avx2_conv_act.cpp b/saber/funcs/impl/x86/jit_avx2_conv_act.cpp
index 04773d6..9135913 100644
--- a/saber/funcs/impl/x86/jit_avx2_conv_act.cpp
+++ b/saber/funcs/impl/x86/jit_avx2_conv_act.cpp
@@ -43,7 +43,7 @@ SaberStatus JitAvx2ConvAct<OpDtype, inDtype, outDtype,
         const std::vector<inTensor*>& inputs,
         std::vector<outTensor*>& outputs,
         ConvActiveParam<opTensor> &param, Context<X86> &ctx) {
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     ConvParam<opTensor> *conv_param = &(param.conv_param);
     ActivationParam<opTensor> *act_param = &(param.activation_param);
 
diff --git a/saber/funcs/impl/x86/jit_avx512_conv1x1_act.cpp b/saber/funcs/impl/x86/jit_avx512_conv1x1_act.cpp
index fa05ccb..b948ece 100644
--- a/saber/funcs/impl/x86/jit_avx512_conv1x1_act.cpp
+++ b/saber/funcs/impl/x86/jit_avx512_conv1x1_act.cpp
@@ -182,7 +182,7 @@ SaberStatus JitAvx512Conv1x1Act<OpDtype, inDtype, outDtype,
     const std::vector<inTensor*>& inputs,
     std::vector<outTensor*>& outputs,
     ConvActiveParam<opTensor> &param, Context<X86> &ctx) {
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     // TODO: type checking
     // src = dst = nChw16c 
     // weight = group ? gOIhw16i16o : OIhw16i16o
diff --git a/saber/funcs/impl/x86/jit_avx512_conv_act.cpp b/saber/funcs/impl/x86/jit_avx512_conv_act.cpp
index 3c6eb59..53d59a9 100644
--- a/saber/funcs/impl/x86/jit_avx512_conv_act.cpp
+++ b/saber/funcs/impl/x86/jit_avx512_conv_act.cpp
@@ -50,7 +50,7 @@ SaberStatus JitAvx512ConvAct<OpDtype, inDtype, outDtype,
         ConvActiveParam<opTensor> &param,
         Context<X86> &ctx) {
     // get context of avx512_conv_act
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     ConvParam<opTensor> *conv_param = &(param.conv_param);
     ActivationParam<opTensor> *act_param = &(param.activation_param);
 
diff --git a/saber/funcs/impl/x86/jit_uni_dw_convolution.cpp b/saber/funcs/impl/x86/jit_uni_dw_convolution.cpp
index 0a093ac..00c0684 100644
--- a/saber/funcs/impl/x86/jit_uni_dw_convolution.cpp
+++ b/saber/funcs/impl/x86/jit_uni_dw_convolution.cpp
@@ -29,7 +29,7 @@ SaberStatus JitUniDWConvolution<OpDtype, inDtype, outDtype,
     }
     
     // get context of uni_dw_convolution
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     ConvParam<opTensor> *conv_param = &(param.conv_param);
     ActivationParam<opTensor> *act_param = &(param.activation_param);
diff --git a/saber/funcs/impl/x86/mkl_packed_weight.h b/saber/funcs/impl/x86/mkl_packed_weight.h
new file mode 100644
index 0000000..3a52f17
--- /dev/null
+++ b/saber/funcs/impl/x86/mkl_packed_weight.h
@@ -0,0 +1,136 @@
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_MKL_PACKED_WEIGHT_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_MKL_PACKED_WEIGHT_H
+
+#include <mkl_cblas.h>
+#include <mkl_lapacke.h>
+#include <mkl_vml_functions.h>
+#include "saber/core/tensor.h"
+
+namespace anakin {
+namespace saber {
+
+template <typename T>
+class MatrixInfo {
+public:
+    // default construct
+    MatrixInfo() :
+        _buf_(nullptr), _height_(0),  _width_(0) {
+    };
+
+    // construct the class with allocated buf and
+    // the matrix info including height(row number) and width(column number)
+    MatrixInfo(T *buf, size_t height, size_t width) :
+        _buf_(buf), _height_(height),  _width_(width){
+    };
+
+    // get the raw data buf point
+    T *buf() {
+        return _buf_;
+    };
+
+    // return the height of the buffer;
+    // equal to row number
+    size_t height() {
+        return _height_;
+    };
+
+    // return the width of the buffer;
+    // equal to column number
+    size_t width() {
+        return  _width_;
+    }
+
+    // get the sub buf between start and end;
+    // return sub buffer : [start,end)
+    MatrixInfo<T> subMatrixInfo(int start, int end) {
+        MatrixInfo<T> ret(_buf_ + start * _width_, end -start, _width_);
+        return ret;
+    }
+
+    // print the value to log
+    void log_dump() {
+        for (int i = 0;  i < _height_ * _width_; i++) {
+            LOG(INFO) <<"i:" <<i << " value:" <<*(_buf_ + i);
+        }
+    }
+
+    // clean the buffer with zero
+    void zero() {
+        memset(_buf_, 0,_height_ * _width_ * sizeof(T));
+    }
+
+private:
+    T *_buf_;
+    size_t _height_;
+    size_t  _width_;
+};
+
+template <DataType Dtype, typename LayOutType>
+class mkl_packed_weight {
+
+public:
+    typedef Tensor<X86, Dtype, LayOutType> ioTensor;
+    typedef typename ioTensor::Dtype dtype;
+    explicit mkl_packed_weight(MatrixInfo<dtype> *weight, bool transW = false) {
+        packed_weight_ = nullptr;
+        weight_ = weight->buf();
+        height_ = weight->height();
+        width_ = weight->width();
+        trans_w_ = transW;
+    }
+
+    ~mkl_packed_weight() {
+        if (packed_weight_) {
+            cblas_sgemm_free(packed_weight_);
+            packed_weight_ = nullptr;
+        }
+    }
+
+    void pack() {
+        if (!packed_weight_) {
+            packed_weight_ = cblas_sgemm_alloc(CblasBMatrix, 1, width_, height_);
+        }
+        cblas_sgemm_pack(CblasRowMajor,
+                     CblasBMatrix,
+                     CblasNoTrans,
+                     1,
+                     width_,
+                     height_,
+                     1.0,
+                     weight_,
+                     width_,
+                     packed_weight_);
+    }
+
+    void gemm_compute(MatrixInfo<dtype>& src, MatrixInfo<dtype>* dst, float beta = 1.0) {
+        cblas_sgemm_compute(CblasRowMajor,
+                        CblasNoTrans,
+                        CblasPacked,
+                        src.height(),
+                        width_,
+                        height_,
+                        src.buf(),
+                        src.width(),
+                        packed_weight_,
+                        width_,
+                        beta,
+                        dst->buf(),
+                        dst->width()
+                        );
+    }
+protected:
+    /// The pointer of weight
+    dtype * weight_;
+    /// The pointer of cblas packed gemm to weight
+    dtype *packed_weight_;
+    size_t height_;
+    size_t width_;
+    bool trans_w_;
+};
+
+template class mkl_packed_weight<AK_FLOAT, NCHW>;
+
+}  // namespace saber
+}  // namespace anakin
+
+#endif
diff --git a/saber/funcs/impl/x86/saber_activation.cpp b/saber/funcs/impl/x86/saber_activation.cpp
index 4c80446..4891312 100644
--- a/saber/funcs/impl/x86/saber_activation.cpp
+++ b/saber/funcs/impl/x86/saber_activation.cpp
@@ -1,14 +1,16 @@
 
 #include "saber/funcs/impl/x86/saber_activation.h"
+#include <cmath>
+
 namespace anakin{
 namespace saber {
 
 template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
 SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
         LayOutType_op, LayOutType_in, LayOutType_out>::init(
         const std::vector<DataTensor_in*>& inputs,
@@ -20,17 +22,17 @@ SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return create(inputs, outputs, param, ctx);
 }
 
 template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
 SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
         LayOutType_op, LayOutType_in, LayOutType_out>::create(
         const std::vector<DataTensor_in*>& inputs,
@@ -41,17 +43,17 @@ SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return SaberSuccess;
 }
 
 template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
 SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
         LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(
         const std::vector<DataTensor_in*>& inputs,
@@ -65,7 +67,7 @@ SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
     // TODO !! need add other types of activation
     if (param.active == Active_relu) {
         for (size_t vc = 0; vc < inputs.size(); vc++) {
-            size_t len = inputs[vc]->size();
+            size_t len = inputs[vc]->valid_size();
             float *input_data = inputs[vc]->mutable_data();
             float *output_data = outputs[vc]->mutable_data();
 
@@ -81,6 +83,79 @@ SaberStatus SaberActivation<X86, OpDtype, inDtype, outDtype,
             }
         }
     }
+
+    // stanh : b * \frac{e^{a * x} - e^{-a * x}}{e^{a * x} + e^{-a * x}}
+    if (param.active == Active_stanh) {
+        for (size_t i = 0; i < inputs.size(); i++) {
+            size_t len = inputs[i]->valid_size();
+            DataType_in *input_data = inputs[i]->mutable_data();
+            DataType_out *output_data = outputs[i]->mutable_data();
+            //negative_slope = scale_a
+            //coef = scale_b
+            for (size_t j = 0; j < len; j++) {
+                output_data[j] = param.coef * tanh(param.negative_slope * input_data[j]);
+            }
+        }
+    }
+    // sigmoid: 1/(exp(-x) + 1)
+    if (param.active == Active_sigmoid) {
+        for ( size_t i = 0; i < inputs.size() ; i++) {
+            size_t len = inputs[i]->valid_size();
+            DataType_in *input_data = inputs[i]->mutable_data();
+            DataType_out *output_data = outputs[i]->mutable_data();
+
+            for (size_t j = 0; j < len; j++) {
+                output_data[j] = 1.0f / (1.0f + exp(-input_data[j]));
+            }
+        }
+    }
+
+    // tanh : (exp(x) - exp(-x)) / (exp(x) + exp(-x))
+    if (param.active == Active_tanh) {
+        for (size_t i = 0; i < inputs.size(); i++) {
+            size_t len = inputs[i]->valid_size();
+            DataType_in *input_data = inputs[i]->mutable_data();
+            DataType_out *output_data = outputs[i]->mutable_data();
+
+            for (size_t j = 0; j < len; j++) {
+                output_data[j] = tanh(input_data[j]);
+            }
+        }
+    }
+
+    // clipped_relu
+    // x > 0 ? x : 0;
+    // x < threshold ? x : threshold
+    if (param.active == Active_clipped_relu) {
+        DataType_in threshold = param.coef;
+        for (size_t i = 0; i < inputs.size(); i++) {
+            size_t len = inputs[i]->valid_size();
+            DataType_in *input_data = inputs[i]->mutable_data();
+            DataType_out *output_data = outputs[i]->mutable_data();
+
+            for(size_t j = 0; j < len; j++){
+                output_data[j] = input_data[j] > 0 ? input_data[j] : 0;
+                output_data[j] = output_data[j] < threshold ? output_data[j] : threshold;
+            }
+        }
+    }
+
+    //elu:  x > 0 ? x : coef * (exp(x) - 1)
+    if (param.active == Active_elu) {
+        DataType_in coef = param.coef;
+        for (size_t i = 0; i < inputs.size(); i++) {
+            size_t len = inputs[i]->valid_size();
+            DataType_in *input_data = inputs[i]->mutable_data();
+            DataType_out *output_data = outputs[i]->mutable_data();
+
+            for(size_t j = 0; j < len; j++){
+                output_data[j] = input_data[j] > 0 ? input_data[j] : param.coef * (exp(input_data[j]) - 1);
+            }
+        }
+    }
+    for (size_t i = 0; i < inputs.size(); i++) {
+        outputs[i]->set_seq_offset(inputs[i]->get_seq_offset());
+    }
     return SaberSuccess;
 }
 
diff --git a/saber/funcs/impl/x86/saber_avx2_activation.h b/saber/funcs/impl/x86/saber_avx2_activation.h
new file mode 100644
index 0000000..6334f11
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_avx2_activation.h
@@ -0,0 +1,99 @@
+
+
+#ifndef ANAKIN_SABER_AVX2_ACTIVATION_H
+#define ANAKIN_SABER_AVX2_ACTIVATION_H
+
+#include "saber_avx2_math.h"
+#define SIGMOID_THRESHOLD_MIN -40.0
+#define SIGMOID_THRESHOLD_MAX 13.0
+#define EXP_MAX_INPUT 40.0
+
+static inline __m256 _mm256_expfaster_ps(const __m256 &a) {
+
+    const __m256 C1 = _mm256_set1_ps(1064872507.1541044f);
+    const __m256 C2 = _mm256_set1_ps(12102203.161561485f);
+
+    return _mm256_castsi256_ps(_mm256_cvttps_epi32(_mm256_fmadd_ps(C2, a, C1)));
+}
+
+inline __m256 InValidAct(__m256 a) {
+    CHECK_EQ(0,1)<<"InValidAct";
+}
+
+inline __m256 Exp_fast(__m256 a) {
+    return _mm256_expfaster_ps(a);
+}
+
+inline __m256 Exp(__m256 a) {
+    return exp256_ps_fma(a);
+}
+
+inline __m256 Relu(const __m256 a) {
+    __m256 tmp = _mm256_set1_ps(0.0f);
+    return _mm256_max_ps(a, tmp);
+}
+
+inline __m256 Sigmoid_fluid(const __m256 a) {
+    __m256 max = _mm256_set1_ps(SIGMOID_THRESHOLD_MAX);
+    __m256 min = _mm256_set1_ps(SIGMOID_THRESHOLD_MIN);
+    __m256 tmp = _mm256_max_ps(a, min);
+    tmp = _mm256_min_ps(tmp, max);
+    tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), tmp);
+    tmp = Exp(tmp);
+    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
+    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m256 Sigmoid(const __m256 a) {
+    __m256  tmp = a;
+    tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), tmp);
+    tmp = Exp(tmp);
+    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
+    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m256 Sigmoid_fast(const __m256 a) {
+    __m256  tmp = a;
+    tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), tmp);
+    tmp = Exp_fast(tmp);
+    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
+    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m256 Tanh_fluid(const __m256 a) {
+    __m256 max = _mm256_set1_ps(EXP_MAX_INPUT);
+    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
+    tmp = _mm256_min_ps(tmp, max);
+    tmp = Exp(tmp);
+    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
+                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
+                         _mm256_set1_ps(1.0f));
+}
+
+inline __m256 Tanh(const __m256 a) {
+    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
+    tmp = Exp(tmp);
+    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
+                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
+                         _mm256_set1_ps(1.0f));
+}
+
+inline __m256 Tanh_fast(const __m256 a) {
+    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
+    tmp = Exp_fast(tmp);
+    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
+                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
+                         _mm256_set1_ps(1.0f));
+}
+
+inline __m256 Identity(const __m256 a) {
+    return a;
+}
+__m256 (*act_func[])(__m256)= {&InValidAct, &Sigmoid, &Relu, &Tanh, &InValidAct, \
+                                        & InValidAct, &Identity, &Sigmoid_fluid, &Tanh_fluid
+};
+
+#endif //ANAKIN_SABER_AVX2_ACTIVATION_H
diff --git a/saber/funcs/impl/x86/saber_avx2_math.h b/saber/funcs/impl/x86/saber_avx2_math.h
new file mode 100644
index 0000000..12dfb05
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_avx2_math.h
@@ -0,0 +1,593 @@
+//  Copyright (c) 2018 PaddlePaddle Authors. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//    http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+/*
+   AVX implementation of sin, cos, sincos, exp and log
+
+   Based on "sse_mathfun.h", by Julien Pommier
+   http://gruntthepeon.free.fr/ssemath/
+
+   Copyright (C) 2012 Giovanni Garberoglio
+   Interdisciplinary Laboratory for Computational Science (LISC)
+   Fondazione Bruno Kessler and University of Trento
+   via Sommarive, 18
+   I-38123 Trento (Italy)
+
+  This software is provided 'as-is', without any express or implied
+  warranty.  In no event will the authors be held liable for any damages
+  arising from the use of this software.
+
+  Permission is granted to anyone to use this software for any purpose,
+  including commercial applications, and to alter it and redistribute it
+  freely, subject to the following restrictions:
+
+  1. The origin of this software must not be misrepresented; you must not
+     claim that you wrote the original software. If you use this software
+     in a product, an acknowledgment in the product documentation would be
+     appreciated but is not required.
+  2. Altered source versions must be plainly marked as such, and must not be
+     misrepresented as being the original software.
+  3. This notice may not be removed or altered from any source distribution.
+
+  (this is the zlib license)
+*/
+
+#pragma once
+#include <immintrin.h>
+/* yes I know, the top of this file is quite ugly */
+#define ALIGN32_BEG
+#define ALIGN32_END __attribute__((aligned(32)))
+
+/* __m128 is ugly to write */
+typedef __m256 v8sf;   // vector of 8 float (avx)
+typedef __m256i v8si;  // vector of 8 int   (avx)
+
+
+#define _PI32AVX_CONST(Name, Val)                                 \
+  static const ALIGN32_BEG int _pi32avx_##Name[4] ALIGN32_END = { \
+      Val, Val, Val, Val}
+
+_PI32AVX_CONST(1, 1);
+_PI32AVX_CONST(inv1, ~1);
+_PI32AVX_CONST(2, 2);
+_PI32AVX_CONST(4, 4);
+
+/* declare some AVX constants -- why can't I figure a better way to do that? */
+#define _PS256_CONST(Name, Val)                                   \
+  static const ALIGN32_BEG float _ps256_##Name[8] ALIGN32_END = { \
+      Val, Val, Val, Val, Val, Val, Val, Val}
+#define _PI32_CONST256(Name, Val)                                  \
+  static const ALIGN32_BEG int _pi32_256_##Name[8] ALIGN32_END = { \
+      Val, Val, Val, Val, Val, Val, Val, Val}
+#define _PS256_CONST_TYPE(Name, Type, Val)                       \
+  static const ALIGN32_BEG Type _ps256_##Name[8] ALIGN32_END = { \
+      Val, Val, Val, Val, Val, Val, Val, Val}
+
+_PS256_CONST(1, 1.0f);
+_PS256_CONST(0p5, 0.5f);
+/* the smallest non denormalized float number */
+_PS256_CONST_TYPE(min_norm_pos, int, 0x00800000);
+_PS256_CONST_TYPE(mant_mask, int, 0x7f800000);
+_PS256_CONST_TYPE(inv_mant_mask, int, ~0x7f800000);
+
+_PS256_CONST_TYPE(sign_mask, int, (int)0x80000000);
+_PS256_CONST_TYPE(inv_sign_mask, int, ~0x80000000);
+
+_PI32_CONST256(0, 0);
+_PI32_CONST256(1, 1);
+_PI32_CONST256(inv1, ~1);
+_PI32_CONST256(2, 2);
+_PI32_CONST256(4, 4);
+_PI32_CONST256(0x7f, 0x7f);
+
+_PS256_CONST(cephes_SQRTHF, 0.707106781186547524);
+_PS256_CONST(cephes_log_p0, 7.0376836292E-2);
+_PS256_CONST(cephes_log_p1, -1.1514610310E-1);
+_PS256_CONST(cephes_log_p2, 1.1676998740E-1);
+_PS256_CONST(cephes_log_p3, -1.2420140846E-1);
+_PS256_CONST(cephes_log_p4, +1.4249322787E-1);
+_PS256_CONST(cephes_log_p5, -1.6668057665E-1);
+_PS256_CONST(cephes_log_p6, +2.0000714765E-1);
+_PS256_CONST(cephes_log_p7, -2.4999993993E-1);
+_PS256_CONST(cephes_log_p8, +3.3333331174E-1);
+_PS256_CONST(cephes_log_q1, -2.12194440e-4);
+_PS256_CONST(cephes_log_q2, 0.693359375);
+
+
+#define avx2_mm256_slli_epi32 _mm256_slli_epi32
+#define avx2_mm256_srli_epi32 _mm256_srli_epi32
+#define avx2_mm256_and_si256 _mm256_and_si256
+#define avx2_mm256_andnot_si256 _mm256_andnot_si256
+#define avx2_mm256_cmpeq_epi32 _mm256_cmpeq_epi32
+#define avx2_mm256_sub_epi32 _mm256_sub_epi32
+#define avx2_mm256_add_epi32 _mm256_add_epi32
+
+/* natural logarithm computed for 8 simultaneous float
+   return NaN for x <= 0
+*/
+inline v8sf log256_ps(v8sf x) {
+    v8si imm0;
+    v8sf one = *(v8sf *)_ps256_1;
+
+    // v8sf invalid_mask = _mm256_cmple_ps(x, _mm256_setzero_ps());
+    v8sf invalid_mask = _mm256_cmp_ps(x, _mm256_setzero_ps(), _CMP_LE_OS);
+
+    x = _mm256_max_ps(
+            x, *(v8sf *)_ps256_min_norm_pos); /* cut off denormalized stuff */
+
+    // can be done with AVX2
+    imm0 = avx2_mm256_srli_epi32(_mm256_castps_si256(x), 23);
+
+    /* keep only the fractional part */
+    x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_mant_mask);
+    x = _mm256_or_ps(x, *(v8sf *)_ps256_0p5);
+
+    // this is again another AVX2 instruction
+    imm0 = avx2_mm256_sub_epi32(imm0, *(v8si *)_pi32_256_0x7f);
+    v8sf e = _mm256_cvtepi32_ps(imm0);
+
+    e = _mm256_add_ps(e, one);
+
+    /* part2:
+       if( x < SQRTHF ) {
+         e -= 1;
+         x = x + x - 1.0;
+       } else { x = x - 1.0; }
+    */
+    // v8sf mask = _mm256_cmplt_ps(x, *(v8sf*)_ps256_cephes_SQRTHF);
+    v8sf mask = _mm256_cmp_ps(x, *(v8sf *)_ps256_cephes_SQRTHF, _CMP_LT_OS);
+    v8sf tmp = _mm256_and_ps(x, mask);
+    x = _mm256_sub_ps(x, one);
+    e = _mm256_sub_ps(e, _mm256_and_ps(one, mask));
+    x = _mm256_add_ps(x, tmp);
+
+    v8sf z = _mm256_mul_ps(x, x);
+
+    v8sf y = *(v8sf *)_ps256_cephes_log_p0;
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p1);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p2);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p3);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p4);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p5);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p6);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p7);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_log_p8);
+    y = _mm256_mul_ps(y, x);
+
+    y = _mm256_mul_ps(y, z);
+
+    tmp = _mm256_mul_ps(e, *(v8sf *)_ps256_cephes_log_q1);
+    y = _mm256_add_ps(y, tmp);
+
+    tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
+    y = _mm256_sub_ps(y, tmp);
+
+    tmp = _mm256_mul_ps(e, *(v8sf *)_ps256_cephes_log_q2);
+    x = _mm256_add_ps(x, y);
+    x = _mm256_add_ps(x, tmp);
+    x = _mm256_or_ps(x, invalid_mask);  // negative arg will be NAN
+    return x;
+}
+
+_PS256_CONST(exp_hi, 88.3762626647949f);
+_PS256_CONST(exp_lo, -88.3762626647949f);
+
+_PS256_CONST(cephes_LOG2EF, 1.44269504088896341);
+_PS256_CONST(cephes_exp_C1, 0.693359375);
+_PS256_CONST(cephes_exp_C2, -2.12194440e-4);
+
+_PS256_CONST(cephes_exp_p0, 1.9875691500E-4);
+_PS256_CONST(cephes_exp_p1, 1.3981999507E-3);
+_PS256_CONST(cephes_exp_p2, 8.3334519073E-3);
+_PS256_CONST(cephes_exp_p3, 4.1665795894E-2);
+_PS256_CONST(cephes_exp_p4, 1.6666665459E-1);
+_PS256_CONST(cephes_exp_p5, 5.0000001201E-1);
+
+inline v8sf exp256_ps(v8sf x) {
+    v8sf tmp = _mm256_setzero_ps(), fx;
+    v8si imm0;
+    v8sf one = *(v8sf *)_ps256_1;
+
+    x = _mm256_min_ps(x, *(v8sf *)_ps256_exp_hi);
+    x = _mm256_max_ps(x, *(v8sf *)_ps256_exp_lo);
+
+    /* express exp(x) as exp(g + n*log(2)) */
+    fx = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_LOG2EF);
+    fx = _mm256_add_ps(fx, *(v8sf *)_ps256_0p5);
+
+    /* how to perform a floorf with SSE: just below */
+    // imm0 = _mm256_cvttps_epi32(fx);
+    // tmp  = _mm256_cvtepi32_ps(imm0);
+
+    tmp = _mm256_floor_ps(fx);
+
+    /* if greater, substract 1 */
+    // v8sf mask = _mm256_cmpgt_ps(tmp, fx);
+    v8sf mask = _mm256_cmp_ps(tmp, fx, _CMP_GT_OS);
+    mask = _mm256_and_ps(mask, one);
+    fx = _mm256_sub_ps(tmp, mask);
+
+    tmp = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C1);
+    v8sf z = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C2);
+    x = _mm256_sub_ps(x, tmp);
+    x = _mm256_sub_ps(x, z);
+
+    z = _mm256_mul_ps(x, x);
+
+    v8sf y = *(v8sf *)_ps256_cephes_exp_p0;
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p1);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p2);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p3);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p4);
+    y = _mm256_mul_ps(y, x);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_cephes_exp_p5);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, x);
+    y = _mm256_add_ps(y, one);
+
+    /* build 2^n */
+    imm0 = _mm256_cvttps_epi32(fx);
+    // another two AVX2 instructions
+    imm0 = avx2_mm256_add_epi32(imm0, *(v8si *)_pi32_256_0x7f);
+    imm0 = avx2_mm256_slli_epi32(imm0, 23);
+    v8sf pow2n = _mm256_castsi256_ps(imm0);
+    y = _mm256_mul_ps(y, pow2n);
+    return y;
+}
+
+inline v8sf exp256_ps_fma(v8sf x) {
+    v8sf tmp = _mm256_setzero_ps(), fx;
+    v8si imm0;
+    v8sf one = *(v8sf *)_ps256_1;
+
+    x = _mm256_min_ps(x, *(v8sf *)_ps256_exp_hi);
+    x = _mm256_max_ps(x, *(v8sf *)_ps256_exp_lo);
+
+    fx = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_LOG2EF);
+    fx = _mm256_add_ps(fx, *(v8sf *)_ps256_0p5);
+
+
+    tmp = _mm256_floor_ps(fx);
+
+    v8sf mask = _mm256_cmp_ps(tmp, fx, _CMP_GT_OS);
+    mask = _mm256_and_ps(mask, one);
+    fx = _mm256_sub_ps(tmp, mask);
+
+    tmp = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C1);
+    v8sf z = _mm256_mul_ps(fx, *(v8sf *)_ps256_cephes_exp_C2);
+    x = _mm256_sub_ps(x, tmp);
+    x = _mm256_sub_ps(x, z);
+
+    z = _mm256_mul_ps(x, x);
+
+    v8sf y = *(v8sf *)_ps256_cephes_exp_p0;
+    y = _mm256_fmadd_ps(y, x,*(v8sf *)_ps256_cephes_exp_p1);
+    y = _mm256_fmadd_ps(y, x,*(v8sf *)_ps256_cephes_exp_p2);
+    y = _mm256_fmadd_ps(y, x,*(v8sf *)_ps256_cephes_exp_p3);
+    y = _mm256_fmadd_ps(y, x,*(v8sf *)_ps256_cephes_exp_p4);
+    y = _mm256_fmadd_ps(y, x,*(v8sf *)_ps256_cephes_exp_p5);
+    y = _mm256_fmadd_ps(y, z,x);
+    y = _mm256_add_ps(y, one);
+    /* build 2^n */
+    imm0 = _mm256_cvttps_epi32(fx);
+    // another two AVX2 instructions
+    imm0 = avx2_mm256_add_epi32(imm0, *(v8si *)_pi32_256_0x7f);
+    imm0 = avx2_mm256_slli_epi32(imm0, 23);
+    v8sf pow2n = _mm256_castsi256_ps(imm0);
+    y = _mm256_mul_ps(y, pow2n);
+    return y;
+}
+
+_PS256_CONST(minus_cephes_DP1, -0.78515625);
+_PS256_CONST(minus_cephes_DP2, -2.4187564849853515625e-4);
+_PS256_CONST(minus_cephes_DP3, -3.77489497744594108e-8);
+_PS256_CONST(sincof_p0, -1.9515295891E-4);
+_PS256_CONST(sincof_p1, 8.3321608736E-3);
+_PS256_CONST(sincof_p2, -1.6666654611E-1);
+_PS256_CONST(coscof_p0, 2.443315711809948E-005);
+_PS256_CONST(coscof_p1, -1.388731625493765E-003);
+_PS256_CONST(coscof_p2, 4.166664568298827E-002);
+_PS256_CONST(cephes_FOPI, 1.27323954473516);  // 4 / M_PI
+
+/* evaluation of 8 sines at onces using AVX intrisics
+
+   The code is the exact rewriting of the cephes sinf function.
+   Precision is excellent as long as x < 8192 (I did not bother to
+   take into account the special handling they have for greater values
+   -- it does not return garbage for arguments over 8192, though, but
+   the extra precision is missing).
+
+   Note that it is such that sinf((float)M_PI) = 8.74e-8, which is the
+   surprising but correct result.
+
+*/
+inline v8sf sin256_ps(v8sf x) {  // any x
+    v8sf xmm1, xmm2 = _mm256_setzero_ps(), xmm3, sign_bit, y;
+    v8si imm0, imm2;
+
+    sign_bit = x;
+    /* take the absolute value */
+    x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
+    /* extract the sign bit (upper one) */
+    sign_bit = _mm256_and_ps(sign_bit, *(v8sf *)_ps256_sign_mask);
+
+    /* scale by 4/Pi */
+    y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
+
+/*
+  Here we start a series of integer operations, which are in the
+  realm of AVX2.
+  If we don't have AVX, let's perform them using SSE2 directives
+*/
+
+    /* store the integer part of y in mm0 */
+    imm2 = _mm256_cvttps_epi32(y);
+    /* j=(j+1) & (~1) (see the cephes sources) */
+    // another two AVX2 instruction
+    imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
+    y = _mm256_cvtepi32_ps(imm2);
+
+    /* get the swap sign flag */
+    imm0 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_4);
+    imm0 = avx2_mm256_slli_epi32(imm0, 29);
+    /* get the polynom selection mask
+       there is one polynom for 0 <= x <= Pi/4
+       and another one for Pi/4<x<=Pi/2
+
+       Both branches will be computed.
+    */
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
+    imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
+
+    v8sf swap_sign_bit = _mm256_castsi256_ps(imm0);
+    v8sf poly_mask = _mm256_castsi256_ps(imm2);
+    sign_bit = _mm256_xor_ps(sign_bit, swap_sign_bit);
+
+    /* The magic pass: "Extended precision modular arithmetic"
+       x = ((x - y * DP1) - y * DP2) - y * DP3; */
+    xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
+    xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
+    xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
+    xmm1 = _mm256_mul_ps(y, xmm1);
+    xmm2 = _mm256_mul_ps(y, xmm2);
+    xmm3 = _mm256_mul_ps(y, xmm3);
+    x = _mm256_add_ps(x, xmm1);
+    x = _mm256_add_ps(x, xmm2);
+    x = _mm256_add_ps(x, xmm3);
+
+    /* Evaluate the first polynom  (0 <= x <= Pi/4) */
+    y = *(v8sf *)_ps256_coscof_p0;
+    v8sf z = _mm256_mul_ps(x, x);
+
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_mul_ps(y, z);
+    v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
+    y = _mm256_sub_ps(y, tmp);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
+
+    /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
+
+    v8sf y2 = *(v8sf *)_ps256_sincof_p0;
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_mul_ps(y2, x);
+    y2 = _mm256_add_ps(y2, x);
+
+    /* select the correct result from the two polynoms */
+    xmm3 = poly_mask;
+    y2 = _mm256_and_ps(xmm3, y2);  //, xmm3);
+    y = _mm256_andnot_ps(xmm3, y);
+    y = _mm256_add_ps(y, y2);
+    /* update the sign */
+    y = _mm256_xor_ps(y, sign_bit);
+
+    return y;
+}
+
+/* almost the same as sin_ps */
+inline v8sf cos256_ps(v8sf x) {  // any x
+    v8sf xmm1, xmm2 = _mm256_setzero_ps(), xmm3, y;
+    v8si imm0, imm2;
+
+
+    /* take the absolute value */
+    x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
+
+    /* scale by 4/Pi */
+    y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
+
+    /* store the integer part of y in mm0 */
+    imm2 = _mm256_cvttps_epi32(y);
+    /* j=(j+1) & (~1) (see the cephes sources) */
+    imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
+    y = _mm256_cvtepi32_ps(imm2);
+    imm2 = avx2_mm256_sub_epi32(imm2, *(v8si *)_pi32_256_2);
+
+    /* get the swap sign flag */
+    imm0 = avx2_mm256_andnot_si256(imm2, *(v8si *)_pi32_256_4);
+    imm0 = avx2_mm256_slli_epi32(imm0, 29);
+    /* get the polynom selection mask */
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
+    imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
+
+    v8sf sign_bit = _mm256_castsi256_ps(imm0);
+    v8sf poly_mask = _mm256_castsi256_ps(imm2);
+
+    /* The magic pass: "Extended precision modular arithmetic"
+       x = ((x - y * DP1) - y * DP2) - y * DP3; */
+    xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
+    xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
+    xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
+    xmm1 = _mm256_mul_ps(y, xmm1);
+    xmm2 = _mm256_mul_ps(y, xmm2);
+    xmm3 = _mm256_mul_ps(y, xmm3);
+    x = _mm256_add_ps(x, xmm1);
+    x = _mm256_add_ps(x, xmm2);
+    x = _mm256_add_ps(x, xmm3);
+
+    /* Evaluate the first polynom  (0 <= x <= Pi/4) */
+    y = *(v8sf *)_ps256_coscof_p0;
+    v8sf z = _mm256_mul_ps(x, x);
+
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_mul_ps(y, z);
+    v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
+    y = _mm256_sub_ps(y, tmp);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
+
+    /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
+
+    v8sf y2 = *(v8sf *)_ps256_sincof_p0;
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_mul_ps(y2, x);
+    y2 = _mm256_add_ps(y2, x);
+
+    /* select the correct result from the two polynoms */
+    xmm3 = poly_mask;
+    y2 = _mm256_and_ps(xmm3, y2);  //, xmm3);
+    y = _mm256_andnot_ps(xmm3, y);
+    y = _mm256_add_ps(y, y2);
+    /* update the sign */
+    y = _mm256_xor_ps(y, sign_bit);
+
+    return y;
+}
+
+/* since sin256_ps and cos256_ps are almost identical, sincos256_ps could
+   replace both of them..
+   it is almost as fast, and gives you a free cosine with your sine */
+inline void sincos256_ps(v8sf x, v8sf *s, v8sf *c) {
+    v8sf xmm1, xmm2, xmm3 = _mm256_setzero_ps(), sign_bit_sin, y;
+    v8si imm0, imm2, imm4;
+
+
+
+    sign_bit_sin = x;
+    /* take the absolute value */
+    x = _mm256_and_ps(x, *(v8sf *)_ps256_inv_sign_mask);
+    /* extract the sign bit (upper one) */
+    sign_bit_sin = _mm256_and_ps(sign_bit_sin, *(v8sf *)_ps256_sign_mask);
+
+    /* scale by 4/Pi */
+    y = _mm256_mul_ps(x, *(v8sf *)_ps256_cephes_FOPI);
+
+    /* store the integer part of y in imm2 */
+    imm2 = _mm256_cvttps_epi32(y);
+
+    /* j=(j+1) & (~1) (see the cephes sources) */
+    imm2 = avx2_mm256_add_epi32(imm2, *(v8si *)_pi32_256_1);
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_inv1);
+
+    y = _mm256_cvtepi32_ps(imm2);
+    imm4 = imm2;
+
+    /* get the swap sign flag for the sine */
+    imm0 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_4);
+    imm0 = avx2_mm256_slli_epi32(imm0, 29);
+    // v8sf swap_sign_bit_sin = _mm256_castsi256_ps(imm0);
+
+    /* get the polynom selection mask for the sine*/
+    imm2 = avx2_mm256_and_si256(imm2, *(v8si *)_pi32_256_2);
+    imm2 = avx2_mm256_cmpeq_epi32(imm2, *(v8si *)_pi32_256_0);
+
+    v8sf swap_sign_bit_sin = _mm256_castsi256_ps(imm0);
+    v8sf poly_mask = _mm256_castsi256_ps(imm2);
+
+    /* The magic pass: "Extended precision modular arithmetic"
+       x = ((x - y * DP1) - y * DP2) - y * DP3; */
+    xmm1 = *(v8sf *)_ps256_minus_cephes_DP1;
+    xmm2 = *(v8sf *)_ps256_minus_cephes_DP2;
+    xmm3 = *(v8sf *)_ps256_minus_cephes_DP3;
+    xmm1 = _mm256_mul_ps(y, xmm1);
+    xmm2 = _mm256_mul_ps(y, xmm2);
+    xmm3 = _mm256_mul_ps(y, xmm3);
+    x = _mm256_add_ps(x, xmm1);
+    x = _mm256_add_ps(x, xmm2);
+    x = _mm256_add_ps(x, xmm3);
+
+    imm4 = avx2_mm256_sub_epi32(imm4, *(v8si *)_pi32_256_2);
+    imm4 = avx2_mm256_andnot_si256(imm4, *(v8si *)_pi32_256_4);
+    imm4 = avx2_mm256_slli_epi32(imm4, 29);
+
+    v8sf sign_bit_cos = _mm256_castsi256_ps(imm4);
+
+    sign_bit_sin = _mm256_xor_ps(sign_bit_sin, swap_sign_bit_sin);
+
+    /* Evaluate the first polynom  (0 <= x <= Pi/4) */
+    v8sf z = _mm256_mul_ps(x, x);
+    y = *(v8sf *)_ps256_coscof_p0;
+
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p1);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_coscof_p2);
+    y = _mm256_mul_ps(y, z);
+    y = _mm256_mul_ps(y, z);
+    v8sf tmp = _mm256_mul_ps(z, *(v8sf *)_ps256_0p5);
+    y = _mm256_sub_ps(y, tmp);
+    y = _mm256_add_ps(y, *(v8sf *)_ps256_1);
+
+    /* Evaluate the second polynom  (Pi/4 <= x <= 0) */
+
+    v8sf y2 = *(v8sf *)_ps256_sincof_p0;
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p1);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_add_ps(y2, *(v8sf *)_ps256_sincof_p2);
+    y2 = _mm256_mul_ps(y2, z);
+    y2 = _mm256_mul_ps(y2, x);
+    y2 = _mm256_add_ps(y2, x);
+
+    /* select the correct result from the two polynoms */
+    xmm3 = poly_mask;
+    v8sf ysin2 = _mm256_and_ps(xmm3, y2);
+    v8sf ysin1 = _mm256_andnot_ps(xmm3, y);
+    y2 = _mm256_sub_ps(y2, ysin2);
+    y = _mm256_sub_ps(y, ysin1);
+
+    xmm1 = _mm256_add_ps(ysin1, ysin2);
+    xmm2 = _mm256_add_ps(y, y2);
+
+    /* update the sign */
+    *s = _mm256_xor_ps(xmm1, sign_bit_sin);
+    *c = _mm256_xor_ps(xmm2, sign_bit_cos);
+}
diff --git a/saber/funcs/impl/x86/saber_avx512_activation.h b/saber/funcs/impl/x86/saber_avx512_activation.h
new file mode 100644
index 0000000..517d8e8
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_avx512_activation.h
@@ -0,0 +1,95 @@
+//
+// Created by Liu,Junjie(SYS) on 2018/6/7.
+//
+
+#ifndef ANAKIN_SABER_AVX512_ACTIVATION_H
+#define ANAKIN_SABER_AVX512_ACTIVATION_H
+
+#include "saber_avx512_math.h"
+
+inline __m512 Relu(const __m512 a) {
+    __m512 tmp = _mm512_set1_ps(0.0f);
+    return _mm512_max_ps(a, tmp);
+}
+inline __m512 InValidAct(__m512 a) {
+    CHECK_EQ(0,1)<<"InValidAct";
+}
+
+inline __m512 Exp_fast(__m512 a) {
+    return exp512_ps_fma(a);
+}
+
+inline __m512 Exp(__m512 a) {
+    return exp512_ps(a);
+}
+
+inline __m512 Relu(const __m512 a) {
+    __m512 tmp = _mm512_set1_ps(0.0f);
+    return _mm512_max_ps(a, tmp);
+}
+
+inline __m512 Sigmoid_fluid(const __m512 a) {
+    __m512 max = _mm512_set1_ps(SIGMOID_THRESHOLD_MAX);
+    __m512 min = _mm512_set1_ps(SIGMOID_THRESHOLD_MIN);
+    __m512 tmp = _mm512_max_ps(a, min);
+    tmp = _mm512_min_ps(tmp, max);
+    tmp = _mm512_sub_ps(_mm512_set1_ps(0.0f), tmp);
+    tmp = Exp(tmp);
+    tmp = _mm512_add_ps(_mm512_set1_ps(1.0f), tmp);
+    tmp = _mm512_div_ps(_mm512_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m512 Sigmoid(const __m512 a) {
+    __m512  tmp = a;
+    tmp = _mm512_sub_ps(_mm512_set1_ps(0.0f), tmp);
+    tmp = Exp(tmp);
+    tmp = _mm512_add_ps(_mm512_set1_ps(1.0f), tmp);
+    tmp = _mm512_div_ps(_mm512_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m512 Sigmoid_fast(const __m512 a) {
+    __m512  tmp = a;
+    tmp = _mm512_sub_ps(_mm512_set1_ps(0.0f), tmp);
+    tmp = Exp_fast(tmp);
+    tmp = _mm512_add_ps(_mm512_set1_ps(1.0f), tmp);
+    tmp = _mm512_div_ps(_mm512_set1_ps(1.0f), tmp);
+    return tmp;
+}
+
+inline __m512 Tanh_fluid(const __m512 a) {
+    __m512 max = _mm512_set1_ps(EXP_MAX_INPUT);
+    __m512 tmp = _mm512_mul_ps(_mm512_set1_ps(-2.0f), a);
+    tmp = _mm512_min_ps(tmp, max);
+    tmp = Exp(tmp);
+    return _mm512_sub_ps(_mm512_div_ps(_mm512_set1_ps(2.0f),
+                                       _mm512_add_ps(_mm512_set1_ps(1.0f), tmp)),
+                         _mm512_set1_ps(1.0f));
+}
+
+inline __m512 Tanh(const __m512 a) {
+    __m512 tmp = _mm512_mul_ps(_mm512_set1_ps(-2.0f), a);
+    tmp = Exp(tmp);
+    return _mm512_sub_ps(_mm512_div_ps(_mm512_set1_ps(2.0f),
+                                       _mm512_add_ps(_mm512_set1_ps(1.0f), tmp)),
+                         _mm512_set1_ps(1.0f));
+}
+
+inline __m512 Tanh_fast(const __m512 a) {
+    __m512 tmp = _mm512_mul_ps(_mm512_set1_ps(-2.0f), a);
+    tmp = Exp_fast(tmp);
+    return _mm512_sub_ps(_mm512_div_ps(_mm512_set1_ps(2.0f),
+                                       _mm512_add_ps(_mm512_set1_ps(1.0f), tmp)),
+                         _mm512_set1_ps(1.0f));
+}
+
+inline __m512 Identity(const __m512 a) {
+    return a;
+}
+
+
+__m512 (*act_func[])(__m512)= {&InValidAct, &Sigmoid_fast, &Relu, &Tanh, &InValidAct, \
+                                        & InValidAct, &Identity, &Sigmoid_fluid, &Tanh_fluid
+};
+#endif //ANAKIN_SABER_AVX512_ACTIVATION_H
diff --git a/saber/funcs/impl/x86/saber_avx512_math.h b/saber/funcs/impl/x86/saber_avx512_math.h
new file mode 100644
index 0000000..9908e93
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_avx512_math.h
@@ -0,0 +1,79 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN_SABER_AVX512_MATH_H
+#define ANAKIN_SABER_AVX512_MATH_H
+
+#include <immintrin.h>
+static inline __m512 _mm512_expfaster_ps(const __m512 &a) {
+
+    const __m512 C1 = _mm512_set1_ps(1064872507.1541044f);
+    const __m512 C2 = _mm512_set1_ps(12102203.161561485f);
+
+    return _mm512_castsi512_ps(_mm512_cvttps_epi32(_mm512_fmadd_ps(C2, a, C1)));
+}
+
+__mm512 exp512_ps_fma(__mm512 x) {
+    __m512 tmp = _mm512_setzero_ps(), fx;
+    __m512i imm0;
+    __m512 one=_mm256_set1_ps(1.f);
+    __m512 _ps512_exp_hi=_mm512_set1_ps(88.3762626647949f);
+    __m512 _ps512_exp_lo=_mm512_set1_ps(-88.3762626647949f);
+    x = _mm512_min_ps(x, _ps512_exp_hi);
+    x = _mm512_max_ps(x, _ps512_exp_lo);
+
+    __m512 _ps512_cephes_LOG2EF=_mm512_set1_ps(1.44269504088896341f);
+    fx = _mm512_mul_ps(x, _ps512_cephes_LOG2EF);
+    __m512 _ps512_0p5=_mm512_set1_ps(0.5);
+    fx = _mm512_add_ps(fx, _ps512_0p5);
+
+    tmp = _mm512_floor_ps(fx);
+
+    __m512 mask = _mm512_cmp_ps(tmp, fx, _CMP_GT_OS);
+    mask = _mm512_and_ps(mask, one);
+    fx = _mm512_sub_ps(tmp, mask);
+
+    __m512 _ps512_cephes_exp_C1=_mm512_set1_ps(0.693359375f);
+    __m512 _ps512_cephes_exp_C2=_mm512_set1_ps(-2.12194440E-4f);
+    tmp = _mm512_mul_ps(fx, _ps512_cephes_exp_C1);
+    __m512 z = _mm512_mul_ps(fx, _ps512_cephes_exp_C2);
+    x = _mm512_sub_ps(x, tmp);
+    x = _mm512_sub_ps(x, z);
+    z = _mm512_mul_ps(x, x);
+
+    __m512 _ps512_cephes_exp_p0=_mm512_set1_ps(1.9875691500E-4f);
+    __m512 _ps512_cephes_exp_p1=_mm512_set1_ps(1.3981999507E-3f);
+    __m512 _ps512_cephes_exp_p2=_mm512_set1_ps(8.3334519073E-3f);
+    __m512 _ps512_cephes_exp_p3=_mm512_set1_ps(4.1665795894E-2f);
+    __m512 _ps512_cephes_exp_p4=_mm512_set1_ps(1.6666665459E-1f);
+    __m512 _ps512_cephes_exp_p5=_mm512_set1_ps(5.0000001201E-1f);
+    __m512 y = _ps512_cephes_exp_p0;
+    y = _mm512_fmadd_ps(y, x,_ps512_cephes_exp_p1);
+    y = _mm512_fmadd_ps(y, x,_ps512_cephes_exp_p2);
+    y = _mm512_fmadd_ps(y, x,_ps512_cephes_exp_p3);
+    y = _mm512_fmadd_ps(y, x,_ps512_cephes_exp_p4);
+    y = _mm512_fmadd_ps(y, x,_ps512_cephes_exp_p5);
+    y = _mm512_fmadd_ps(y, z,x);
+    y = _mm512_add_ps(y, one);
+    /* build 2^n */
+    imm0 = _mm512_cvttps_epi32(fx);
+    // another two AVX2 instructions
+    __m512i _pi32_512_0x7f=_mm512_set1_epi32(0x7f);
+    imm0 = avx2_mm512_add_epi32(imm0, _pi32_512_0x7f);
+    imm0 = avx2_mm512_slli_epi32(imm0, 23);
+    __mm512 pow2n = _mm512_castsi512_ps(imm0);
+    y = _mm512_mul_ps(y, pow2n);
+    return y;
+}
+#endif //ANAKIN_SABER_AVX512_MATH_H
diff --git a/saber/funcs/impl/x86/saber_concat.h b/saber/funcs/impl/x86/saber_concat.h
index 49681da..386b1a1 100644
--- a/saber/funcs/impl/x86/saber_concat.h
+++ b/saber/funcs/impl/x86/saber_concat.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -54,7 +54,7 @@ public:
                       std::vector<DataTensor_out*>& outputs,
                       ConcatParam<OpTensor> &param, Context<X86> &ctx){
         // get context
-        this->_ctx = ctx;
+        this->_ctx = &ctx;
         return create(inputs, outputs, param, ctx);
     }
 
diff --git a/saber/funcs/impl/x86/saber_crf_decoding.cpp b/saber/funcs/impl/x86/saber_crf_decoding.cpp
index ea85ebc..0ea171b 100644
--- a/saber/funcs/impl/x86/saber_crf_decoding.cpp
+++ b/saber/funcs/impl/x86/saber_crf_decoding.cpp
@@ -23,7 +23,7 @@ SaberStatus SaberCrfDecoding<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     return create(inputs, outputs, param, ctx);
 }
 
@@ -43,7 +43,7 @@ SaberStatus SaberCrfDecoding<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
 
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     _alpha.re_alloc(inputs[0]->valid_shape());
     _track.re_alloc(inputs[0]->valid_shape());
     return SaberSuccess;
diff --git a/saber/funcs/impl/x86/saber_eltwise.cpp b/saber/funcs/impl/x86/saber_eltwise.cpp
index 1ea374a..7ae5aed 100644
--- a/saber/funcs/impl/x86/saber_eltwise.cpp
+++ b/saber/funcs/impl/x86/saber_eltwise.cpp
@@ -22,7 +22,7 @@ SaberStatus SaberEltwise<X86, OpDtype, inDtype, outDtype,
         Context<X86> &ctx)
 {
     // get context
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     return create(inputs, outputs, param, ctx);
 }
 
@@ -48,7 +48,7 @@ SaberStatus SaberEltwise<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return SaberSuccess;
 }
diff --git a/saber/funcs/impl/x86/saber_eltwise_act.cpp b/saber/funcs/impl/x86/saber_eltwise_act.cpp
index 14a701c..e23edd2 100644
--- a/saber/funcs/impl/x86/saber_eltwise_act.cpp
+++ b/saber/funcs/impl/x86/saber_eltwise_act.cpp
@@ -96,7 +96,7 @@ SaberStatus SaberEltwiseActive<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return create(inputs, outputs, param, ctx);
 }
@@ -116,7 +116,7 @@ SaberStatus SaberEltwiseActive<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return SaberSuccess;
 }
diff --git a/saber/funcs/impl/x86/saber_embedding.cpp b/saber/funcs/impl/x86/saber_embedding.cpp
index 3e92ab9..5556d9c 100644
--- a/saber/funcs/impl/x86/saber_embedding.cpp
+++ b/saber/funcs/impl/x86/saber_embedding.cpp
@@ -22,7 +22,7 @@ SaberStatus SaberEmbedding<X86, OpDtype, inDtype, outDtype,
         Context<X86> &ctx)
 {
     // get context
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     return create(inputs, outputs, param, ctx);
 }
 
diff --git a/saber/funcs/impl/x86/saber_gru.cpp b/saber/funcs/impl/x86/saber_gru.cpp
index 18ec585..f9713c4 100644
--- a/saber/funcs/impl/x86/saber_gru.cpp
+++ b/saber/funcs/impl/x86/saber_gru.cpp
@@ -4,77 +4,12 @@
 #include "saber/core/tensor_op.h"
 #include "mkl_cblas.h"
 #include <immintrin.h>
-#include "avx_mathfun.h"
+#include "sys/time.h"
+
 namespace anakin {
 
 namespace saber {
 
-
-#define SIGMOID_THRESHOLD_MIN -40.0
-#define SIGMOID_THRESHOLD_MAX 13.0
-#define EXP_MAX_INPUT 40.0
-
-inline __m256 InValidAct(__m256 a) {
-            CHECK_EQ(0,1)<<"InValidAct";
-}
-
-inline __m256 Exp(__m256 a) {
-    return exp256_ps(a);
-    //    return exp(a);
-}
-
-inline __m256 Relu(const __m256 a) {
-    __m256 tmp = _mm256_set1_ps(0.0f);
-    return _mm256_max_ps(a, tmp);
-}
-
-inline __m256 Sigmoid_fluid(const __m256 a) {
-    __m256 max = _mm256_set1_ps(SIGMOID_THRESHOLD_MAX);
-    __m256 min = _mm256_set1_ps(SIGMOID_THRESHOLD_MIN);
-    __m256 tmp = _mm256_max_ps(a, min);
-    tmp = _mm256_min_ps(tmp, max);
-    tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), tmp);
-    tmp = Exp(tmp);
-    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
-    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
-    return tmp;
-}
-
-inline __m256 Sigmoid(const __m256 a) {
-    __m256  tmp = a;
-    tmp = _mm256_sub_ps(_mm256_set1_ps(0.0f), tmp);
-    tmp = Exp(tmp);
-    tmp = _mm256_add_ps(_mm256_set1_ps(1.0f), tmp);
-    tmp = _mm256_div_ps(_mm256_set1_ps(1.0f), tmp);
-    return tmp;
-}
-
-inline __m256 Tanh_fluid(const __m256 a) {
-    __m256 max = _mm256_set1_ps(EXP_MAX_INPUT);
-    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
-    tmp = _mm256_min_ps(tmp, max);
-    tmp = Exp(tmp);
-    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
-                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
-                         _mm256_set1_ps(1.0f));
-}
-
-inline __m256 Tanh(const __m256 a) {
-    __m256 tmp = _mm256_mul_ps(_mm256_set1_ps(-2.0f), a);
-    tmp = Exp(tmp);
-    return _mm256_sub_ps(_mm256_div_ps(_mm256_set1_ps(2.0f),
-                                       _mm256_add_ps(_mm256_set1_ps(1.0f), tmp)),
-                         _mm256_set1_ps(1.0f));
-}
-
-__m256 Identity(const __m256 a) {
-    return a;
-}
-
-static  __m256 ( *act_funcs[10])(const __m256)={&InValidAct,&Sigmoid,&Relu,&Tanh,&InValidAct,\
-                       &InValidAct,&Identity,&Sigmoid_fluid,&Tanh_fluid};
-
-
 //inline
 static void gemm(const bool TransA, const bool TransB, int m, int n, int k, const float alpha,
                  const float* a, const float* b, const float beta, float* c) {
@@ -85,49 +20,21 @@ static void gemm(const bool TransA, const bool TransB, int m, int n, int k, cons
         (!TransA/* == CblasNoTrans*/) ? CblasNoTrans : CblasTrans;
     CBLAS_TRANSPOSE cuTransB =
         (!TransB/* == CblasNoTrans*/) ? CblasNoTrans : CblasTrans;
-    cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, m, n, k, alpha, a, k, b, n, beta, c, n);
+    cblas_sgemm(CblasRowMajor, cuTransA, cuTransB, m, n, k, alpha, a, k, b, n, beta, c, n);
 };
 
-template <typename Dtype>
-inline Dtype Sigmoid(const Dtype a) {
-    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-a));
-}
-
-template <typename Dtype>
-inline Dtype Sigmoid_fluid(const Dtype a) {
-    const Dtype min = SIGMOID_THRESHOLD_MIN;
-    const Dtype max = SIGMOID_THRESHOLD_MAX;
-    Dtype tmp = (a < min) ? min : ((a > max) ? max : a);
-    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-tmp));
-}
-
-template <typename Dtype>
-inline Dtype Tanh_fluid(const Dtype a) {
-    Dtype tmp = -2.0 * a;
-    tmp = (tmp > EXP_MAX_INPUT) ? EXP_MAX_INPUT : tmp;
-    return (2.0 / (1.0 + exp(tmp))) - 1.0;
-}
-
-template <typename Dtype>
-inline Dtype Tanh(const Dtype a) {
-    Dtype tmp = -2.0 * a;
-    return (2.0 / (1.0 + exp(tmp))) - 1.0;
-}
-
-template <typename Dtype>
-inline Dtype Relu(const Dtype a) {
-    return a > static_cast<Dtype>(0.0) ? a : static_cast<Dtype>(0.0);
-}
-
-template <typename Dtype>
-inline Dtype Identity(const Dtype a) {
-    return a;
-}
-
-
-static float ( *act_funcs_f[10])(const float)={&InValidAct,&Sigmoid,&Relu,&Tanh,&InValidAct,\
-               &InValidAct,&Identity,&Sigmoid_fluid,&Tanh_fluid};
-
+//template <typename Dtype>
+////class ActivationArray{
+////    typedef Dtype (*Act)(Dtype);
+////    typedef Dtype (*Acts[])(Dtype);
+////    Acts funcs={&InValidAct, &Sigmoid_fast, &Relu, &Tanh, &InValidAct, \
+////                                        & InValidAct, &Identity, &Sigmoid_fluid, &Tanh_fluid};
+////    Act get(int index){
+////        return funcs[index];
+////    }
+////};
+
+#if 0
 template<>
 SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_gru(\
         const std::vector<DataTensor_in*>& inputs,
@@ -138,8 +45,8 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
     const OpDataType* weight_w = _weights_i2h.data();
     const OpDataType* bias = _weights_bias.data();
 
-    float(* gat_act)(const float)=act_funcs_f[param.gate_activity];
-    float(* h_act)(const float)=act_funcs_f[param.h_activity];
+    float(* gat_act)(const float) = act_funcs_f[param.gate_activity];
+    float(* h_act)(const float) = act_funcs_f[param.h_activity];
 
     std::vector<int> offset_vec = inputs[0]->get_seq_offset();
     bool is_hw2seq = offset_vec.size() > 2;
@@ -162,9 +69,9 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
         h_init = inputs[1]->data();
     } else if (param.init_hidden() != nullptr) {
         h_init = param.init_hidden()->data();
-    }else{
-        _init_hidden.try_expand_size(batch_size*_hidden_size);
-        h_init=_init_hidden.data();
+    } else {
+        _init_hidden.try_expand_size(batch_size * _hidden_size);
+        h_init = _init_hidden.data();
     }
 
     const InDataType* x = inputs[0]->data();
@@ -182,8 +89,8 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
     OutDataType* temp_whr = _temp_whr.mutable_data();
 
 
-//    LOG(INFO) << "gemm b" << inputs[0]->valid_shape().count() << "," <<
-//              _weights_i2h.valid_shape().count() << "," << _temp_wx.valid_shape().count();
+    //    LOG(INFO) << "gemm b" << inputs[0]->valid_shape().count() << "," <<
+    //              _weights_i2h.valid_shape().count() << "," << _temp_wx.valid_shape().count();
     //wx
     gemm(false, false, seqsum, 3 * _hidden_size, _word_size, 1.f, x, weight_w, 0.f, temp_wx);
 
@@ -235,7 +142,8 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
             OutDataType* w_h_r = temp_wh + 0 * _hidden_size;
             OutDataType* w_h_z = temp_wh + 1 * _hidden_size;
             OpDataType* w_o = weight_h;
-//#pragma simd
+
+            //#pragma simd
             for (int frame_id = 0; frame_id < _hidden_size; ++frame_id) {
                 r = w_x_r[frame_id] + w_h_r[frame_id] + b_r[frame_id]; //h_out=gate_r
                 r = gat_act(r);
@@ -244,7 +152,8 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
 
 
             gemm(false, false, 1, _hidden_size, _hidden_size, 1.0, hout, w_o, 0.f, temp_whr);
-//#pragma simd
+
+            //#pragma simd
             for (int frame_id = 0; frame_id < _hidden_size; ++frame_id) {
                 z = gat_act(w_x_z[frame_id] + w_h_z[frame_id] + b_z[frame_id]);
                 _h = w_x_o[frame_id] + temp_whr[frame_id] + b_o[frame_id];
@@ -257,7 +166,9 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::naiv_
 
     return SaberSuccess;
 };
+#endif
 
+#if 0
 template<>
 SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::batch_gru(\
         const std::vector<DataTensor_in*>& inputs,
@@ -415,6 +326,7 @@ SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::batch
     if (transform) {
         transe_util.sorted_seq_2_seq(inner_h_out, out, _hidden_size);
     }
+
     return SaberSuccess;
 }
 
@@ -559,17 +471,16 @@ naiv_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
     const OpDataType* weight_h = _aligned_weights_h2h.data();
     const OpDataType* weight_w = _aligned_weights_i2h.data();
     const OpDataType* bias = _aligned_weights_bias.data();
-    CHECK_GE(inputs[0]->get_seq_offset().size(), 2);
-    std::vector<int> offset_vec = inputs[0]->get_seq_offset();
 
+    std::vector<int> offset_vec = inputs[0]->get_seq_offset();
     std::vector<int> length_vec(offset_vec.size() - 1);
     int batch_size = offset_vec.size() - 1;
     int seqsum = 0;
     int max_seq_len = 0;
     bool is_hw2seq = offset_vec.size() > 2;
     int word_sum = is_hw2seq ? offset_vec[offset_vec.size() - 1] : inputs[0]->channel();
-    __m256 (*gate_act)(const __m256)=act_funcs[param.gate_activity];
-    __m256 (*hid_act)(const __m256)=act_funcs[param.h_activity];
+    __m256(*gate_act)(const __m256) = act_func[param.gate_activity];
+    __m256(*hid_act)(const __m256) = act_func[param.h_activity];
     utils::AlignedUtils aligned_utils;
     utils::VectorPrint vector_print;
     const OutDataType* h_init = nullptr;
@@ -705,8 +616,8 @@ batch_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
     const OpDataType* weight_h = _aligned_weights_h2h.data();
     const OpDataType* weight_w = _aligned_weights_i2h.data();
     const OpDataType* bias = _aligned_weights_bias.data();
-    __m256 (*gate_act)(const __m256)=act_funcs[param.gate_activity];
-    __m256 (*hid_act)(const __m256)=act_funcs[param.h_activity];
+    __m256(*gate_act)(const __m256) = act_func[param.gate_activity];
+    __m256(*hid_act)(const __m256) = act_func[param.h_activity];
     std::vector<int> offset_vec = inputs[0]->get_seq_offset();
     std::vector<int> length_vec(offset_vec.size() - 1);
     int batch_size = offset_vec.size() - 1;
@@ -790,14 +701,14 @@ batch_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
 
     int mod_num = _hidden_size % 8;
 
-    int reverse_out_offset=seqsum;
+    int reverse_out_offset = seqsum;
 
 
     for (int word_id = 0; word_id < emit_length; word_id++) {
         int real_word_id = word_id;
         int last_word_id = word_id - 1;
 
-        if (param.is_reverse&&batch_size==1) {
+        if (param.is_reverse && batch_size == 1) {
             real_word_id = emit_length - word_id - 1;
             last_word_id = real_word_id + 1;
         }
@@ -810,29 +721,20 @@ batch_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
         if (word_id == 0) {
             hin = inner_h_init;
         } else {
-//            if(is_reverse){
-//                hin = inner_h_out + reverse_out_offset * _aligned_hidden_size;
-//            }else{
-//                hin = inner_h_out + emit_offset_vec[last_word_id] * _aligned_hidden_size;
-//            }
             hin = inner_h_out + emit_offset_vec[last_word_id] * _aligned_hidden_size;
         }
 
         float* hout = nullptr;
-//        if(is_reverse){
-//            reverse_out_offset-=emit_word_length;
-//            hout=reverse_out_offset*_aligned_hidden_size + inner_h_out;
-//        } else{
-            hout=emit_offset_vec[real_word_id] * _aligned_hidden_size + inner_h_out;
-//        }
+        hout = emit_offset_vec[real_word_id] * _aligned_hidden_size + inner_h_out;
+
         //wh
         gemm(false, false, emit_word_length, 2 * _aligned_hidden_size, _aligned_hidden_size, 1.0, hin,
              weight_h + _hidden_size * _aligned_hidden_size,
              0.f, temp_wh);
 
-         __m256 r;
-         __m256 z;
-         __m256 _h;
+        __m256 r;
+        __m256 z;
+        __m256 _h;
         __m256* hout_256 = (__m256*) hout;
         const __m256* hin_256 = (__m256*) hin;
 
@@ -878,6 +780,187 @@ batch_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
                 z = gate_act(w_x_z[frame_id] + w_h_z[frame_id] + b_z[frame_id]);
                 _h = w_x_o[frame_id] + w_h_o[frame_id] + b_o[frame_id];
                 _h = hid_act(_h);
+                emit_hout[frame_id] = (1 - z) * emit_hin[frame_id] + z * _h;
+            }
+        }
+
+    }
+
+    if (transform) {
+        transe_util.sorted_seq_2_seq(inner_h_out, out, _hidden_size, _aligned_hidden_size);
+    } else if (_hidden_size != _aligned_hidden_size) {
+        aligned_utils.unaligned_last_dim(_temp_out.data(), out, seqsum * _hidden_size, _hidden_size,
+                                         _aligned_hidden_size);
+    }
+
+    return SaberSuccess;
+};
+
+template<typename OpDataType,typename BIT,BIT(*GATACT)(BIT),BIT(*OUTACT)(BIT)>
+SaberStatus batch_256_s_aligned_template(std::vector<int> &offset_vec,const OpDataType* weight_h,const OpDataType* weight_w,const OpDataType* bias,
+                         const OpDataType* x,OpDataType* out,const OpDataType* h_init_from_input,const OpDataType* h_init_from_parm,
+                         int &_aligned_hidden_size,int &_hidden_size,int &_word_size,int &num_direction,bool &is_reverse,
+                    Tensor<X86,AK_FLOAT,NCHW> &_aligned_init_hidden,Tensor<X86,AK_FLOAT,NCHW> &_temp_wx,Tensor<X86,AK_FLOAT,NCHW> &_temp_wh,
+                         Tensor<X86,AK_FLOAT,NCHW> &_temp_whr,Tensor<X86,AK_FLOAT,NCHW> &_temp_out,Tensor<X86,AK_FLOAT,NCHW> &_temp_x,
+                         Tensor<X86,AK_FLOAT,NCHW> &_temp_h_init
+                    ) {
+    std::vector<int> length_vec(offset_vec.size() - 1);
+    int batch_size = offset_vec.size() - 1;
+    int seqsum = 0;
+    int max_seq_len = 0;
+    bool is_hw2seq = offset_vec.size() > 2;
+    int word_sum = offset_vec[offset_vec.size() - 1];
+    utils::AlignedUtils aligned_utils;
+    utils::VectorPrint vector_print;
+    const OpDataType* h_init = nullptr;
+
+
+    if (h_init_from_input != nullptr) {
+        h_init = h_init_from_input;
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);
+        aligned_utils.aligned_last_dim(h_init, _aligned_init_hidden.mutable_data(),
+                                       batch_size * _hidden_size, _hidden_size, _aligned_hidden_size);
+        h_init = _aligned_init_hidden.data();
+    } else if (h_init_from_parm != nullptr) {
+        h_init = h_init_from_parm;
+        //FIXME:is it correct?
+    } else {
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);
+        h_init = _aligned_init_hidden.data();
+    }
+
+    std::vector<int> emit_offset_vec;
+    int emit_length = 0;
+    utils::SeqSortedseqTranseUtil transe_util(is_reverse);
+    bool transform = transe_util.get_sorted_map(offset_vec, emit_offset_vec, emit_length);
+
+    float* inner_h_out = out;
+    float* inner_x = x;
+    const float* inner_h_init = h_init;
+
+    for (int i = 0; i < offset_vec.size() - 1; ++i) {
+        int len = offset_vec[i + 1] - offset_vec[i];
+        length_vec[i] = len;
+        max_seq_len = max_seq_len > len ? max_seq_len : len;
+        seqsum += len;
+    }
+
+    _temp_wx.try_expand_size(seqsum * 3 * _aligned_hidden_size);
+    _temp_wh.try_expand_size(batch_size * 2 * _aligned_hidden_size);
+    _temp_whr.try_expand_size(batch_size * _aligned_hidden_size);
+    _temp_out.try_expand_size(seqsum * _aligned_hidden_size * num_direction);
+
+    if (transform) {
+        _temp_x.try_expand_size(seqsum * _word_size);
+        inner_h_out = _temp_out.mutable_data();
+        inner_x = _temp_x.mutable_data();
+        transe_util.seq_2_sorted_seq(x, inner_x, _word_size);
+
+        if (inner_h_init != nullptr) {
+            _temp_h_init.try_expand_size(batch_size * _aligned_hidden_size);
+            transe_util.hidden_2_sorted_hidden(inner_h_init, _temp_h_init.mutable_data(), _aligned_hidden_size);
+            inner_h_init = _temp_h_init.data();
+        }
+
+    } else if (_hidden_size != _aligned_hidden_size) {
+        inner_h_out = _temp_out.mutable_data();
+    }
+
+    OpDataType* temp_wh = _temp_wh.mutable_data();
+    OpDataType* temp_wx = _temp_wx.mutable_data();
+    OpDataType* temp_whr = _temp_whr.mutable_data();
+    /////////////////////////////////////////////////
+    //wx
+    gemm(false, false, seqsum, 3 * _aligned_hidden_size, _word_size, 1.f, inner_x, weight_w, 0.f,
+         temp_wx);
+
+    int o_offset = 0;
+    int r_offset = 1;
+    int z_offset = 2;
+    const BIT* b_r = (BIT*)(bias + r_offset * _aligned_hidden_size);
+    const BIT* b_z = (BIT*)(bias + z_offset * _aligned_hidden_size);
+    const BIT* b_o = (BIT*)(bias + o_offset * _aligned_hidden_size);
+
+    int mod_num = _hidden_size % 8;
+
+    int reverse_out_offset = seqsum;
+
+
+    for (int word_id = 0; word_id < emit_length; word_id++) {
+        int real_word_id = word_id;
+        int last_word_id = word_id - 1;
+
+        if (is_reverse && batch_size == 1) {
+            real_word_id = emit_length - word_id - 1;
+            last_word_id = real_word_id + 1;
+        }
+
+        int emit_word_id_start = emit_offset_vec[real_word_id];
+        int emit_word_id_end = emit_offset_vec[real_word_id + 1];
+        int emit_word_length = emit_word_id_end - emit_word_id_start;
+        const float* hin;
+
+        if (word_id == 0) {
+            hin = inner_h_init;
+        } else {
+            hin = inner_h_out + emit_offset_vec[last_word_id] * _aligned_hidden_size;
+        }
+
+        float* hout = nullptr;
+        hout = emit_offset_vec[real_word_id] * _aligned_hidden_size + inner_h_out;
+
+        gemm(false, false, emit_word_length, 2 * _aligned_hidden_size, _aligned_hidden_size, 1.0, hin,
+             weight_h + _hidden_size * _aligned_hidden_size,
+             0.f, temp_wh);
+
+        BIT r;
+        BIT z;
+        BIT _h;
+        BIT* hout_256 = (BIT*) hout;
+        const BIT* hin_256 = (BIT*) hin;
+
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {
+            int emit_id_offset = emit_word_id - emit_word_id_start;
+            BIT* w_x_r = (BIT*)(temp_wx + r_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+            BIT* w_h_r = (BIT*)(temp_wh + 0 * _aligned_hidden_size
+                                      + emit_id_offset * _aligned_hidden_size * 2);
+            BIT* emit_hout = (BIT*)(hout + emit_id_offset * _aligned_hidden_size);
+            const BIT* emit_hin = (BIT*)(hin + emit_id_offset * _aligned_hidden_size);
+
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / 8; ++frame_id) {
+                r = w_x_r[frame_id] + w_h_r[frame_id] + b_r[frame_id]; //h_out=gate_r
+                r = GATACT(r);
+
+                emit_hout[frame_id] = r * emit_hin[frame_id];
+            }
+
+        }
+
+        //        cout << "hout = " << hout[0] << endl;
+        gemm(false, false, emit_word_length, _aligned_hidden_size, _aligned_hidden_size, 1.0, hout,
+             weight_h, 0.f, temp_whr);
+
+
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {
+            int emit_offset = emit_word_id - emit_word_id_start;
+            BIT* w_x_z = (BIT*)(temp_wx + z_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+            BIT* w_x_o = (BIT*)(temp_wx + o_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+
+            BIT* w_h_z = (BIT*)(temp_wh + 1 * _aligned_hidden_size
+                                      + emit_offset * _aligned_hidden_size * 2);
+
+            BIT* w_h_o = (BIT*)(temp_whr + emit_offset * _aligned_hidden_size);
+            BIT* emit_hout = (BIT*)(hout + emit_offset * _aligned_hidden_size) ;
+            const BIT* emit_hin = (BIT*)(hin + emit_offset * _aligned_hidden_size) ;
+
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / 8; ++frame_id) {
+
+                z = GATACT(w_x_z[frame_id] + w_h_z[frame_id] + b_z[frame_id]);
+                _h = w_x_o[frame_id] + w_h_o[frame_id] + b_o[frame_id];
+                _h = OUTACT(_h);
                 //                vector_print.print_float(&z);
                 emit_hout[frame_id] = (1 - z) * emit_hin[frame_id] + z * _h;
             }
@@ -885,28 +968,462 @@ batch_256_s_aligned(const std::vector<DataTensor_in*>& inputs,
 
     }
 
-    if (transform){
+    if (transform) {
+        transe_util.sorted_seq_2_seq(inner_h_out, out, _hidden_size, _aligned_hidden_size);
+    } else if (_hidden_size != _aligned_hidden_size) {
+        aligned_utils.unaligned_last_dim(_temp_out.data(), out, seqsum * _hidden_size, _hidden_size,
+                                         _aligned_hidden_size);
+    }
+
+    return SaberSuccess;
+};
+
+#endif
+
+
+#ifdef GRU_TIMER
+double fmsecond() {
+    struct timeval tv;
+    gettimeofday(&tv, NULL);
+    return (double)tv.tv_sec*1000.0 + (double)tv.tv_usec / 1000.0;
+}
+#endif
+
+template <>
+template<typename BIT>
+SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::
+batch_s_aligned(const std::vector<DataTensor_in*>& inputs,
+                    std::vector<DataTensor_out*>& outputs,
+                    GruParam<OpTensor>& param) {
+            CHECK_NE(param.formula, GRU_CUDNN) << "X86 gru not support cudnn formula now";
+    int loop_div= sizeof(BIT)/4;
+//    LOG(INFO)<<"loop_div "<<loop_div;
+    const OpDataType* weight_h = _aligned_weights_h2h.data();
+    const OpDataType* weight_w = _aligned_weights_i2h.data();
+    const OpDataType* bias = _aligned_weights_bias.data();
+
+//    BIT(*gate_act)(const BIT) = ActivationArray<BIT>().get(param.gate_activity);
+//    BIT(*hid_act)(const BIT) = ActivationArray<BIT>().get(param.h_activity);
+    BIT(*gate_act)(const BIT) = act_func[param.gate_activity];
+    BIT(*hid_act)(const BIT) = act_func[param.h_activity];
+    std::vector<int> offset_vec = inputs[0]->get_seq_offset();
+    std::vector<int> length_vec(offset_vec.size() - 1);
+    int batch_size = offset_vec.size() - 1;
+    int seqsum = 0;
+    int max_seq_len = 0;
+    bool is_hw2seq = offset_vec.size() > 2;
+    int word_sum = is_hw2seq ? offset_vec[offset_vec.size() - 1] : inputs[0]->channel();
+    utils::AlignedUtils aligned_utils;
+    utils::VectorPrint vector_print;
+    const OutDataType* h_init = nullptr;
+
+    const InDataType* x = inputs[0]->data();
+    OutDataType* out = outputs[0]->mutable_data();
+    bool is_reverse = param.is_reverse;
+
+    if (inputs.size() > 1) {
+        h_init = inputs[1]->data();
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);
+        aligned_utils.aligned_last_dim(h_init, _aligned_init_hidden.mutable_data(),
+                                       batch_size * _hidden_size, _hidden_size, _aligned_hidden_size);
+        h_init = _aligned_init_hidden.data();
+    } else if (param.init_hidden() != nullptr) {
+        h_init = param.init_hidden()->data();
+        //FIXME:is it correct?
+    } else {
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);
+        h_init = _aligned_init_hidden.data();
+    }
+
+    std::vector<int> emit_offset_vec;
+    int emit_length = 0;
+    utils::SeqSortedseqTranseUtil transe_util(is_reverse);
+    bool transform = transe_util.get_sorted_map(offset_vec, emit_offset_vec, emit_length);
+
+    float* inner_h_out = out;
+    float* inner_x = x;
+    const float* inner_h_init = h_init;
+
+    for (int i = 0; i < offset_vec.size() - 1; ++i) {
+        int len = offset_vec[i + 1] - offset_vec[i];
+        length_vec[i] = len;
+        max_seq_len = max_seq_len > len ? max_seq_len : len;
+        seqsum += len;
+    }
+
+    _temp_wx.try_expand_size(seqsum * 3 * _aligned_hidden_size);
+    _temp_wh.try_expand_size(batch_size * 2 * _aligned_hidden_size);
+    _temp_whr.try_expand_size(batch_size * _aligned_hidden_size);
+    _temp_out.try_expand_size(seqsum * _aligned_hidden_size * param.num_direction);
+
+    if (transform) {
+        _temp_x.try_expand_size(seqsum * _word_size);
+        inner_h_out = _temp_out.mutable_data();
+        inner_x = _temp_x.mutable_data();
+        transe_util.seq_2_sorted_seq(x, inner_x, _word_size);
+
+        if (inner_h_init != nullptr) {
+            _temp_h_init.try_expand_size(batch_size * _aligned_hidden_size);
+            transe_util.hidden_2_sorted_hidden(inner_h_init, _temp_h_init.mutable_data(), _aligned_hidden_size);
+            inner_h_init = _temp_h_init.data();
+        }
+
+    } else if (_hidden_size != _aligned_hidden_size) {
+        inner_h_out = _temp_out.mutable_data();
+    }
+
+    OutDataType* temp_wh = _temp_wh.mutable_data();
+    OutDataType* temp_wx = _temp_wx.mutable_data();
+    OutDataType* temp_whr = _temp_whr.mutable_data();
+    /////////////////////////////////////////////////
+    //wx
+#ifdef GRU_TIMER
+    double t1, t2;
+    t1 = fmsecond();
+#endif
+    gemm(false, false, seqsum, 3 * _aligned_hidden_size, _word_size, 1.f, inner_x, weight_w, 0.f,
+         temp_wx);
+#ifdef GRU_TIMER
+    t2 = fmsecond();
+    LOG(INFO) << " GRU WX execute "<<seqsum<<" : "<< t2 - t1 << "ms";
+#endif
+    int o_offset = 0;
+    int r_offset = 1;
+    int z_offset = 2;
+    const BIT* b_r = (BIT*)(bias + r_offset * _aligned_hidden_size);
+    const BIT* b_z = (BIT*)(bias + z_offset * _aligned_hidden_size);
+    const BIT* b_o = (BIT*)(bias + o_offset * _aligned_hidden_size);
+
+
+    int reverse_out_offset = seqsum;
+
+
+    for (int word_id = 0; word_id < emit_length; word_id++) {
+        int real_word_id = word_id;
+        int last_word_id = word_id - 1;
+
+        if (param.is_reverse && batch_size == 1) {
+            real_word_id = emit_length - word_id - 1;
+            last_word_id = real_word_id + 1;
+        }
+
+        int emit_word_id_start = emit_offset_vec[real_word_id];
+        int emit_word_id_end = emit_offset_vec[real_word_id + 1];
+        int emit_word_length = emit_word_id_end - emit_word_id_start;
+        const float* hin;
+
+        if (word_id == 0) {
+            hin = inner_h_init;
+        } else {
+            hin = inner_h_out + emit_offset_vec[last_word_id] * _aligned_hidden_size;
+        }
+
+        float* hout = nullptr;
+        hout = emit_offset_vec[real_word_id] * _aligned_hidden_size + inner_h_out;
+
+        //wh
+        gemm(false, false, emit_word_length, 2 * _aligned_hidden_size, _aligned_hidden_size, 1.0, hin,
+             weight_h + _hidden_size * _aligned_hidden_size,
+             0.f, temp_wh);
+
+        BIT r;
+        BIT z;
+        BIT _h;
+        BIT* hout_256 = (BIT*) hout;
+        const BIT* hin_256 = (BIT*) hin;
+//#pragma omp parallel for
+
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {
+            int emit_id_offset = emit_word_id - emit_word_id_start;
+            BIT* w_x_r = (BIT*)(temp_wx + r_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+            BIT* w_h_r = (BIT*)(temp_wh + 0 * _aligned_hidden_size
+                                      + emit_id_offset * _aligned_hidden_size * 2);
+            BIT* emit_hout = (BIT*)(hout + emit_id_offset * _aligned_hidden_size);
+            const BIT* emit_hin = (BIT*)(hin + emit_id_offset * _aligned_hidden_size);
+
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / (sizeof(BIT)/4); ++frame_id) {
+                r = w_x_r[frame_id] + w_h_r[frame_id] + b_r[frame_id]; //h_out=gate_r
+                r = gate_act(r);
+
+                emit_hout[frame_id] = r * emit_hin[frame_id];
+            }
+
+        }
+
+        gemm(false, false, emit_word_length, _aligned_hidden_size, _aligned_hidden_size, 1.0, hout,
+             weight_h, 0.f, temp_whr);
+
+//#pragma omp parallel for
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {
+            int emit_offset = emit_word_id - emit_word_id_start;
+            BIT* w_x_z = (BIT*)(temp_wx + z_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+            BIT* w_x_o = (BIT*)(temp_wx + o_offset * _aligned_hidden_size
+                                      + emit_word_id * _aligned_hidden_size * 3);
+
+            BIT* w_h_z = (BIT*)(temp_wh + 1 * _aligned_hidden_size
+                                      + emit_offset * _aligned_hidden_size * 2);
+
+            BIT* w_h_o = (BIT*)(temp_whr + emit_offset * _aligned_hidden_size);
+            BIT* emit_hout = (BIT*)(hout + emit_offset * _aligned_hidden_size) ;
+            const BIT* emit_hin = (BIT*)(hin + emit_offset * _aligned_hidden_size) ;
+
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / (sizeof(BIT)/4); ++frame_id) {
+
+                z = gate_act(w_x_z[frame_id] + w_h_z[frame_id] + b_z[frame_id]);
+                _h = w_x_o[frame_id] + w_h_o[frame_id] + b_o[frame_id];
+                _h = hid_act(_h);
+                emit_hout[frame_id] = (1 - z) * emit_hin[frame_id] + z * _h;
+            }
+        }
+
+    }
+
+    if (transform) {
         transe_util.sorted_seq_2_seq(inner_h_out, out, _hidden_size, _aligned_hidden_size);
-    }else if (_hidden_size != _aligned_hidden_size) {
+    } else if (_hidden_size != _aligned_hidden_size) {
         aligned_utils.unaligned_last_dim(_temp_out.data(), out, seqsum * _hidden_size, _hidden_size,
                                          _aligned_hidden_size);
     }
+
     return SaberSuccess;
 };
+
+#if 0
+#define BATCH_ALIGNED(BIT,GATACT,OUTACT)\
+template<>\
+SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::\
+batch_s_aligned##BIT##GATACT##OUTACT(const std::vector<DataTensor_in*>& inputs,\
+                    std::vector<DataTensor_out*>& outputs,\
+                    GruParam<OpTensor>& param) {\
+            CHECK_NE(param.formula, GRU_CUDNN) << "X86 gru not support cudnn formula now";\
+    const OpDataType* weight_h = _aligned_weights_h2h.data();\
+    const OpDataType* weight_w = _aligned_weights_i2h.data();\
+    const OpDataType* bias = _aligned_weights_bias.data();\
+    std::vector<int> offset_vec = inputs[0]->get_seq_offset();\
+    std::vector<int> length_vec(offset_vec.size() - 1);\
+    int batch_size = offset_vec.size() - 1;\
+    int seqsum = 0;\
+    int max_seq_len = 0;\
+    bool is_hw2seq = offset_vec.size() > 2;\
+    int word_sum = is_hw2seq ? offset_vec[offset_vec.size() - 1] : inputs[0]->channel();\
+    utils::AlignedUtils aligned_utils;\
+    utils::VectorPrint vector_print;\
+    const OutDataType* h_init = nullptr;\
+\
+    const InDataType* x = inputs[0]->data();\
+    OutDataType* out = outputs[0]->mutable_data();\
+    bool is_reverse = param.is_reverse;\
+\
+    if (inputs.size() > 1) {\
+        h_init = inputs[1]->data();\
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);\
+        aligned_utils.aligned_last_dim(h_init, _aligned_init_hidden.mutable_data(),\
+                                       batch_size * _hidden_size, _hidden_size, _aligned_hidden_size);\
+        h_init = _aligned_init_hidden.data();\
+    } else if (param.init_hidden() != nullptr) {\
+        h_init = param.init_hidden()->data();\
+    } else {\
+        _aligned_init_hidden.try_expand_size(batch_size * _aligned_hidden_size);\
+        h_init = _aligned_init_hidden.data();\
+    }\
+\
+    std::vector<int> emit_offset_vec;\
+    int emit_length = 0;\
+    utils::SeqSortedseqTranseUtil transe_util(is_reverse);\
+    bool transform = transe_util.get_sorted_map(offset_vec, emit_offset_vec, emit_length);\
+\
+    float* inner_h_out = out;\
+    float* inner_x = x;\
+    const float* inner_h_init = h_init;\
+\
+    for (int i = 0; i < offset_vec.size() - 1; ++i) {\
+        int len = offset_vec[i + 1] - offset_vec[i];\
+        length_vec[i] = len;\
+        max_seq_len = max_seq_len > len ? max_seq_len : len;\
+        seqsum += len;\
+    }\
+\
+    _temp_wx.try_expand_size(seqsum * 3 * _aligned_hidden_size);\
+    _temp_wh.try_expand_size(batch_size * 2 * _aligned_hidden_size);\
+    _temp_whr.try_expand_size(batch_size * _aligned_hidden_size);\
+    _temp_out.try_expand_size(seqsum * _aligned_hidden_size * param.num_direction);\
+\
+    if (transform) {\
+        _temp_x.try_expand_size(seqsum * _word_size);\
+        inner_h_out = _temp_out.mutable_data();\
+        inner_x = _temp_x.mutable_data();\
+        transe_util.seq_2_sorted_seq(x, inner_x, _word_size);\
+\
+        if (inner_h_init != nullptr) {\
+            _temp_h_init.try_expand_size(batch_size * _aligned_hidden_size);\
+            transe_util.hidden_2_sorted_hidden(inner_h_init, _temp_h_init.mutable_data(), _aligned_hidden_size);\
+            inner_h_init = _temp_h_init.data();\
+        }\
+\
+    } else if (_hidden_size != _aligned_hidden_size) {\
+        inner_h_out = _temp_out.mutable_data();\
+    }\
+\
+    OutDataType* temp_wh = _temp_wh.mutable_data();\
+    OutDataType* temp_wx = _temp_wx.mutable_data();\
+    OutDataType* temp_whr = _temp_whr.mutable_data();\
+\
+    gemm(false, false, seqsum, 3 * _aligned_hidden_size, _word_size, 1.f, inner_x, weight_w, 0.f,\
+         temp_wx);\
+\
+    int o_offset = 0;\
+    int r_offset = 1;\
+    int z_offset = 2;\
+    const BIT* b_r = (BIT*)(bias + r_offset * _aligned_hidden_size);\
+    const BIT* b_z = (BIT*)(bias + z_offset * _aligned_hidden_size);\
+    const BIT* b_o = (BIT*)(bias + o_offset * _aligned_hidden_size);\
+\
+    int mod_num = _hidden_size % 8;\
+\
+    int reverse_out_offset=seqsum;\
+\
+\
+    for (int word_id = 0; word_id < emit_length; word_id++) {\
+        int real_word_id = word_id;\
+        int last_word_id = word_id - 1;\
+\
+        if (param.is_reverse&&batch_size==1) {\
+            real_word_id = emit_length - word_id - 1;\
+            last_word_id = real_word_id + 1;\
+        }\
+\
+        int emit_word_id_start = emit_offset_vec[real_word_id];\
+        int emit_word_id_end = emit_offset_vec[real_word_id + 1];\
+        int emit_word_length = emit_word_id_end - emit_word_id_start;\
+        const float* hin;\
+\
+        if (word_id == 0) {\
+            hin = inner_h_init;\
+        } else {\
+            hin = inner_h_out + emit_offset_vec[last_word_id] * _aligned_hidden_size;\
+        }\
+\
+        float* hout = nullptr;\
+        hout=emit_offset_vec[real_word_id] * _aligned_hidden_size + inner_h_out;\
+\
+\
+        gemm(false, false, emit_word_length, 2 * _aligned_hidden_size, _aligned_hidden_size, 1.0, hin,\
+             weight_h + _hidden_size * _aligned_hidden_size,\
+             0.f, temp_wh);\
+\
+        BIT r;\
+        BIT z;\
+        BIT _h;\
+        BIT* hout_BIT = (BIT*) hout;\
+        const BIT* hin_BIT = (BIT*) hin;\
+\
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {\
+            int emit_id_offset = emit_word_id - emit_word_id_start;\
+            BIT* w_x_r = (BIT*)(temp_wx + r_offset * _aligned_hidden_size\
+                                      + emit_word_id * _aligned_hidden_size * 3);\
+            BIT* w_h_r = (BIT*)(temp_wh + 0 * _aligned_hidden_size\
+                                      + emit_id_offset * _aligned_hidden_size * 2);\
+            BIT* emit_hout = (BIT*)(hout + emit_id_offset * _aligned_hidden_size);\
+            const BIT* emit_hin = (BIT*)(hin + emit_id_offset * _aligned_hidden_size);\
+\
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / 8; ++frame_id) {\
+                r = w_x_r[frame_id] + w_h_r[frame_id] + b_r[frame_id]; \
+                r = GATACT(r);\
+\
+                emit_hout[frame_id] = r * emit_hin[frame_id];\
+            }\
+\
+        }\
+\
+\
+        gemm(false, false, emit_word_length, _aligned_hidden_size, _aligned_hidden_size, 1.0, hout,\
+             weight_h, 0.f, temp_whr);\
+\
+\
+        for (int emit_word_id = emit_word_id_start; emit_word_id < emit_word_id_end; emit_word_id++) {\
+            int emit_offset = emit_word_id - emit_word_id_start;\
+            BIT* w_x_z = (BIT*)(temp_wx + z_offset * _aligned_hidden_size\
+                                      + emit_word_id * _aligned_hidden_size * 3);\
+            BIT* w_x_o = (BIT*)(temp_wx + o_offset * _aligned_hidden_size\
+                                      + emit_word_id * _aligned_hidden_size * 3);\
+\
+            BIT* w_h_z = (BIT*)(temp_wh + 1 * _aligned_hidden_size\
+                                      + emit_offset * _aligned_hidden_size * 2);\
+\
+            BIT* w_h_o = (BIT*)(temp_whr + emit_offset * _aligned_hidden_size);\
+            BIT* emit_hout = (BIT*)(hout + emit_offset * _aligned_hidden_size) ;\
+            const BIT* emit_hin = (BIT*)(hin + emit_offset * _aligned_hidden_size) ;\
+\
+            for (int frame_id = 0; frame_id < _aligned_hidden_size / 8; ++frame_id) {\
+\
+                z = GATACT(w_x_z[frame_id] + w_h_z[frame_id] + b_z[frame_id]);\
+                _h = w_x_o[frame_id] + w_h_o[frame_id] + b_o[frame_id];\
+                _h = OUTACT(_h);\
+                emit_hout[frame_id] = (1 - z) * emit_hin[frame_id] + z * _h;\
+            }\
+        }\
+\
+    }\
+\
+    if (transform){\
+        transe_util.sorted_seq_2_seq(inner_h_out, out, _hidden_size, _aligned_hidden_size);\
+    }else if (_hidden_size != _aligned_hidden_size) {\
+        aligned_utils.unaligned_last_dim(_temp_out.data(), out, seqsum * _hidden_size, _hidden_size,\
+                                         _aligned_hidden_size);\
+    }\
+    return SaberSuccess;\
+};
+
+BATCH_ALIGNED(__m256,Sigmoid,Tanh);
+#endif
 template<>
 SaberStatus SaberGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(\
         const std::vector<DataTensor_in*>& inputs,
         std::vector<DataTensor_out*>& outputs,
         GruParam<OpTensor>& param) {
     //        return naiv_256_s_aligned(inputs, outputs, param);
-//            return naiv_gru(inputs, outputs, param);
-//        return batch_gru(inputs, outputs, param);
+//                return naiv_gru(inputs, outputs, param);
+    //        return batch_gru(inputs, outputs, param);
+
+//    float *h_init_from_input= nullptr;
+//    if(inputs.size()>1)
+//        h_init_from_input=inputs[1]->data();
+//
+//    const float *h_init_from_parm= nullptr;
+//    if(param.init_hidden()!= nullptr)
+//        h_init_from_parm=param.init_hidden()->data();
+//
+//    std::vector<int>offset=inputs[0]->get_seq_offset();
+//    return batch_256_s_aligned_template<float,__m256,Sigmoid,Tanh>(offset,_aligned_weights_h2h.data(),_aligned_weights_i2h.data(),
+//    _aligned_weights_bias.data(),inputs[0]->data(),outputs[0]->mutable_data(),h_init_from_input,h_init_from_parm,_aligned_hidden_size,
+//    _aligned_hidden_size,_word_size,param.num_direction,param.is_reverse,_aligned_init_hidden,_temp_wx,_temp_wh,_temp_whr,_temp_out,_temp_x,_temp_h_init);
+//    return batch_256_s_aligned(inputs, outputs, param);
+//    return batch_gru(inputs, outputs, param);
+
+//    return batch_s_aligned__m256SigmoidTanh(inputs, outputs, param);
+
+
+
     outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
-    if(inputs[0]->get_seq_offset().size()>2) {
-        return batch_256_s_aligned(inputs, outputs, param);
-    }else {
-        return naiv_256_s_aligned(inputs, outputs, param);
-    }
+//    nobatch_small_input_gru<SABER_X86_TYPE >(inputs, outputs, param);
+#ifdef GRU_TIMER
+    double t1, t2;
+    t1 = fmsecond();
+#endif
+     batch_s_aligned<SABER_X86_TYPE >(inputs, outputs, param);
+#ifdef GRU_TIMER
+    t2 = fmsecond();
+    LOG(INFO) << " GRU ALL execute:  "<< t2 - t1 << "ms";
+#endif
+    return SaberSuccess;
+
+//    if (inputs[0]->get_seq_offset().size() > 2) {
+//        return batch_256_s_aligned(inputs, outputs, param);
+//    } else {
+//        return naiv_256_s_aligned(inputs, outputs, param);
+//    }
 
 };
 
diff --git a/saber/funcs/impl/x86/saber_gru.h b/saber/funcs/impl/x86/saber_gru.h
index f787a47..29397ad 100644
--- a/saber/funcs/impl/x86/saber_gru.h
+++ b/saber/funcs/impl/x86/saber_gru.h
@@ -4,6 +4,19 @@
 #define ANAKIN_SABER_FUNCS_IMPL_X86_SABER_GRU_H
 #include "saber/funcs/impl/impl_gru.h"
 #include "saber/funcs/impl/x86/x86_utils.h"
+
+
+#ifdef __AVX512F__
+#include "saber_avx512_activation.h"
+#define SABER_X86_TYPE __m512
+#elif __AVX2__
+#include "saber_avx2_activation.h"
+#define SABER_X86_TYPE __m256
+#else
+#include "saber_normal_activation.h"
+#define SABER_X86_TYPE float
+#endif
+
 namespace anakin {
 
 namespace saber {
@@ -37,12 +50,12 @@ public:
     virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs, \
                              std::vector<DataTensor_out*>& outputs, \
                              GruParam<OpTensor>& gru_param, Context<X86>& ctx) {
-        this->_ctx=ctx;
+        this->_ctx = &ctx;
         CHECK_EQ(gru_param.formula ,GRU_ORIGIN)<<"only support gru_origin now";
         _hidden_size = gru_param.bias()->valid_size() / 3;
         if (gru_param.formula == GRU_ORIGIN&&_aligned_way) {
             //FIXME:aligned should be determine by framework
-            int aligned_byte=64;
+            int aligned_byte= sizeof(SABER_X86_TYPE);
             int c_size=aligned_byte/sizeof(OpDataType);
 
             _hidden_size = gru_param.bias()->valid_size() / 3;
@@ -132,6 +145,7 @@ private:
     int _word_size;
     int _hidden_size;
 
+//    typedef  __m256 _aligned_type;
     bool _aligned_way=true;
     int _aligned_word_size;
     int _aligned_hidden_size;
@@ -142,25 +156,21 @@ private:
     OpTensor _weights_i2h;
     OpTensor _weights_h2h;
     OpTensor _weights_bias;
-    DataTensor_out _init_hidden;
+    OpTensor _init_hidden;
 
     OpTensor _aligned_weights_i2h;
     OpTensor _aligned_weights_h2h;
     OpTensor _aligned_weights_bias;
-    DataTensor_out _aligned_init_hidden;
-
-    DataTensor_out _temp_wx;
-    DataTensor_out _temp_wh;
-    DataTensor_out _temp_whr;
-
-    DataTensor_in _temp_x;
-    DataTensor_out _temp_out;
-    DataTensor_out _temp_h_init;
-//    lod_no_batch_gru(const OpDataType* weight_w, const OpDataType* weight_h,const OpDataType* b, const OutDataType* h_init, OutDataType* h_out,
-//                     const InDataType* x,OutDataType *temp_wx,OutDataType *temp_wh,OutDataType *temp_whr,
-//                     int hidden_size, int word_size, std::vector<int>& offset_vec, bool is_reverse);
+    OpTensor _aligned_init_hidden;
 
+    OpTensor _temp_wx;
+    OpTensor _temp_wh;
+    OpTensor _temp_whr;
 
+    OpTensor _temp_x;
+    OpTensor _temp_out;
+    OpTensor _temp_h_init;
+#if 0
     SaberStatus batch_gru(\
         const std::vector<DataTensor_in*>& inputs,
         std::vector<DataTensor_out*>& outputs,
@@ -180,6 +190,17 @@ private:
     const std::vector<DataTensor_in*>& inputs,
                        std::vector<DataTensor_out*>& outputs,
                        GruParam<OpTensor>& param);
+    SaberStatus batch_s_aligned__m256SigmoidTanh(\
+    const std::vector<DataTensor_in*>& inputs,
+    std::vector<DataTensor_out*>& outputs,
+    GruParam<OpTensor>& param);
+#endif
+    template <typename BIT>
+    SaberStatus batch_s_aligned(\
+    const std::vector<DataTensor_in*>& inputs,
+    std::vector<DataTensor_out*>& outputs,
+    GruParam<OpTensor>& param);
+
 };
 
 }
diff --git a/saber/funcs/impl/x86/saber_lstm.cpp b/saber/funcs/impl/x86/saber_lstm.cpp
new file mode 100644
index 0000000..c6c4044
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_lstm.cpp
@@ -0,0 +1,484 @@
+#include "saber/funcs/impl/x86/saber_lstm.h"
+#include "saber/funcs/impl/x86/activation_functions.h"
+#include "saber/funcs/impl/x86/kernel/jit_generator.h"
+
+namespace anakin {
+namespace saber {
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+void SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::compute_with_avx(LstmMetaValue<DataType_in> value,
+                                                                        int hidden_size, int batch_size,
+                                                                        const ActiveType &gate_act,
+                                                                        const ActiveType &cell_act,
+                                                                        const ActiveType &cand_act) {
+#ifdef __AVX__
+#pragma omp parallel for if(this->max_thread_num_ > 1) collapse(2)
+    for (int b = 0; b < batch_size; b++) {
+        for (int i = 0; i < hidden_size/8; i++) {
+            __m256 r_checkI = _mm256_set1_ps(0.0f);
+            __m256 r_checkF = _mm256_set1_ps(0.0f);
+            __m256 r_checkO = _mm256_set1_ps(0.0f);
+            __m256 prev_state_v = _mm256_set1_ps(0.0f);
+            int batch_offset = b * hidden_size;
+            __m256 *value_ig = reinterpret_cast<__m256 *>(value.gate_value + batch_offset * 4);
+            __m256 *value_fg = reinterpret_cast<__m256 *>(value.gate_value + batch_offset * 4 + hidden_size);
+            __m256 *value_in = reinterpret_cast<__m256 *>(value.gate_value + batch_offset * 4 + hidden_size * 2);
+            __m256 *value_og = reinterpret_cast<__m256 *>(value.gate_value + batch_offset * 4 + hidden_size * 3);
+
+            __m256 *state_active = reinterpret_cast<__m256 *>(value.state_active_value + batch_offset);
+            __m256 *state = reinterpret_cast<__m256 *>(value.state_value + batch_offset);
+            __m256 *output = reinterpret_cast<__m256 *>(value.output_value + batch_offset);
+
+            if (value.prev_state_value) {
+                prev_state_v = (reinterpret_cast<__m256 *>(value.prev_state_value + batch_offset))[i];
+            }
+            if (value.check_ig) {
+                r_checkI = (reinterpret_cast<const __m256 *>(value.check_ig))[i];
+                r_checkF = (reinterpret_cast<const __m256 *>(value.check_fg))[i];
+                r_checkO = (reinterpret_cast<const __m256 *>(value.check_og))[i];
+            }
+
+            value_in[i] = math::avx_activation(value_in[i], cand_act);
+            value_ig[i] = math::avx_activation(_mm256_add_ps(value_ig[i], _mm256_mul_ps(prev_state_v, r_checkI)), gate_act);
+            value_fg[i] = math::avx_activation(_mm256_add_ps(value_fg[i], _mm256_mul_ps(prev_state_v, r_checkF)), gate_act);
+            state[i] = _mm256_add_ps(_mm256_mul_ps(value_in[i],value_ig[i]), _mm256_mul_ps(prev_state_v, value_fg[i]));
+            value_og[i] = math::avx_activation(_mm256_add_ps(value_og[i], _mm256_mul_ps(state[i], r_checkO)), gate_act);
+            state_active[i] = math::avx_activation(state[i], cell_act);
+            output[i] = _mm256_mul_ps(value_og[i], state_active[i]);
+        }
+    }
+#endif
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+void SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::compute(LstmMetaValue<DataType_in> value,
+                                                               int hidden_size, int batch_size,
+                                                               const ActiveType &gate_act,
+                                                               const ActiveType &cell_act,
+                                                               const ActiveType &cand_act) {
+#pragma omp parallel for if(this->max_thread_num_ > 1) collapse(2)
+    for (int b = 0; b < batch_size; b++) {
+        for (int i = 0; i < hidden_size; i++) {
+            DataType_in *value_ig = value.gate_value + b * hidden_size * 4;
+            DataType_in *value_fg = value_ig + hidden_size;
+            DataType_in *value_in = value_ig + hidden_size * 2;
+            DataType_in *value_og = value_ig + hidden_size * 3;
+            DataType_in *state_active = value.state_active_value + b * hidden_size;
+            DataType_in *state = value.state_value + b * hidden_size;
+            DataType_in *output = value.output_value + b * hidden_size;
+            DataType_in prev_state_v = 0;
+            if (value.prev_state_value) {
+                prev_state_v = *(value.prev_state_value + b * hidden_size + i);
+            }
+
+            DataType_in r_checkI = value.check_ig ? value.check_ig[i] : 0;
+            DataType_in r_checkF = value.check_fg ? value.check_fg[i] : 0;
+            DataType_in r_checkO = value.check_og ? value.check_og[i] : 0;
+
+            math::activation(1, value_in + i, value_in + i, cand_act);
+            DataType_in tmp = value_ig[i] + prev_state_v * r_checkI;
+            math::activation(1, &tmp, value_ig + i, gate_act);
+            tmp = value_fg[i] + prev_state_v * r_checkF;
+            math::activation(1, &tmp, value_fg + i, gate_act);
+            state[i] = value_in[i] * value_ig[i] + prev_state_v * value_fg[i];
+            tmp = value_og[i] + state[i] * r_checkO;
+            math::activation(1, &tmp, value_og + i, gate_act);
+            math::activation(1, state + i, state_active + i, cell_act);
+            output[i] = value_og[i] * state_active[i];
+        }
+    }
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::init(
+        const std::vector<DataTensor_in*>& inputs,
+        std::vector<DataTensor_out*>& outputs,
+        LstmParam<OpTensor> &param, Context<X86> &ctx) {
+    avx2_available_ = jit::mayiuse(jit::avx2);
+
+    DataTensor_in *input = inputs[0];
+
+    const OpTensor *bias = param.bias();
+    int frame_size = input->channel();
+    int hidden_size = outputs[0]->channel();
+
+    // aligned hidden_size with 8 float
+    int aligned_size = 8;
+    this->aligned_hidden_size_ = (hidden_size % aligned_size) ? ((hidden_size / aligned_size) + 1) * aligned_size : hidden_size;
+
+    OpTensor *aligned_weights_data_h = nullptr;
+    if (this->aligned_hidden_size_ != hidden_size) {
+        Shape aligned_w_shape(this->aligned_hidden_size_, this->aligned_hidden_size_ * 4, 1, 1);
+        aligned_weights_data_h = new OpTensor(aligned_w_shape);
+    }
+
+    DataType_op *weights_data = const_cast<DataType_op *>(param.weight()->data());
+    MatrixInfo<DataType_op> *weight_x = nullptr;
+    MatrixInfo<DataType_op> *weight_h = nullptr;
+    MatrixInfo<DataType_op> *weight_h_tmp = nullptr;
+    if (param.skip_input) {
+        // if skip_input is true, the weights just includes [Wih, Wfh, Wch, Wph]
+        weight_h = new MatrixInfo<DataType_op>(weights_data, hidden_size, (hidden_size * 4));
+    }
+    else {
+        // split the weight to two parts: [Wix, Wfx, Wcx, Wox], [Wih, Wfh, Wch, Woh]
+        weight_x = new MatrixInfo<DataType_op>(weights_data, frame_size, (hidden_size * 4));
+        weight_h = new MatrixInfo<DataType_op>((weights_data + frame_size * hidden_size * 4), hidden_size, (hidden_size * 4));
+    }
+
+    if (this->aligned_hidden_size_ != hidden_size) {
+        weight_h_tmp = weight_h;
+        weight_h = new MatrixInfo<DataType_op>(aligned_weights_data_h->mutable_data(), this->aligned_hidden_size_, (this->aligned_hidden_size_ * 4));
+        // do weight align
+        int stride = 0;
+        int diff = this->aligned_hidden_size_ - hidden_size;
+        DataType_op *src = nullptr;
+        DataType_op *dst = nullptr;
+        for (int i = 0; i < this->aligned_hidden_size_; i++) {
+            stride = 4 * (this->aligned_hidden_size_);
+
+            dst = weight_h->buf() + i * stride;
+            if (i >= hidden_size) {
+                memset(dst, 0, stride * sizeof(DataType_op));
+            } else {
+                src = weight_h_tmp->buf() + i * 4 * hidden_size;
+                for (int j = 0; j < 4; j++) {
+                    memcpy(dst + j * this->aligned_hidden_size_,
+                           src + j * hidden_size, hidden_size * sizeof(DataType_op));
+                    memset(dst + j * this->aligned_hidden_size_ + hidden_size,
+                           0, diff * sizeof(DataType_op));
+                }
+            }
+        }
+
+        delete weight_h_tmp;
+    }
+
+    // clean the packed weight
+    safe_free(&(this->packed_w_x_));
+    safe_free(&(this->packed_w_h_));
+    // pack weights for Wix, Wfx, Wcx, Wox] and [Wih, Wfh, Wch, Woh]
+    if (weight_x) {
+        int m = input->num();
+        this->packed_w_x_ = new mkl_packed_weight<OpDtype, LayOutType_op>(weight_x, m);
+        this->packed_w_x_->pack();
+    }
+    this->packed_w_h_ = new mkl_packed_weight<OpDtype, LayOutType_op>(weight_h);
+    this->packed_w_h_->pack();
+
+    const OpTensor *init_t0 = param.init_hidden();
+    safe_free(&batch_c0_);
+    safe_free(&batch_h0_);
+    // tensor for batched init cell and batched init hidden, they are both with size batch_size * hidden_size
+    if (init_t0) {
+        int batch_size = input->get_seq_offset().size() - 1;
+        Shape batched_state_shape(batch_size, this->aligned_hidden_size_, 1 , 1);
+
+        // create buf in create func, batch_size * hidden_size
+        batch_c0_ = new OpTensor(batched_state_shape);
+
+        // create buf in create func, batch_size * hidden_size
+        batch_h0_ = new OpTensor(batched_state_shape);
+    }
+
+    bool with_peephole = param.with_peephole;
+    if (bias && with_peephole) {
+        const DataType_op *bias_data = bias->data();
+        // shape for Wic, Wfc, Woc
+        Shape weights_c_shape(1, this->aligned_hidden_size_, 1, 1);
+        safe_free(&(this->check_ig_));
+        safe_free(&(this->check_fg_));
+        safe_free(&(this->check_og_));
+        this->check_ig_ = new OpTensor(weights_c_shape);
+        this->check_fg_ = new OpTensor(weights_c_shape);
+        this->check_og_ = new OpTensor(weights_c_shape);
+        memcpy(this->check_ig_->mutable_data(), bias_data + 4 * hidden_size, hidden_size * sizeof(DataType_op));
+        memcpy(this->check_fg_->mutable_data(), bias_data + 5 * hidden_size, hidden_size * sizeof(DataType_op));
+        memcpy(this->check_og_->mutable_data(), bias_data + 6 * hidden_size, hidden_size * sizeof(DataType_op));
+    }
+
+    safe_free(&weight_x);
+    safe_free(&weight_h);
+    safe_free(&aligned_weights_data_h);
+
+    this->_ctx = &ctx;
+    this->max_thread_num_ = omp_get_max_threads();
+
+    return create(inputs, outputs, param, ctx);
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::create(
+        const std::vector<DataTensor_in*>& inputs,
+        std::vector<DataTensor_out*>& outputs,
+        LstmParam<OpTensor> &param,
+        Context<X86> &ctx) {
+    DataTensor_in *input = inputs[0];
+    DataTensor_out *hidden_out = outputs[0];
+    int hidden_size = hidden_out->channel();
+
+    // aligned hidden_size with AVX-512
+    int aligned_size = 8;
+    this->aligned_hidden_size_ = (hidden_size % aligned_size) ? ((hidden_size / aligned_size) + 1) * aligned_size : hidden_size;
+    Shape aligned_output_shape(hidden_out->num(), this->aligned_hidden_size_, 1, 1);
+
+    // xx = x * [Wix, Wfx, Wcx, Wox]
+    Shape xx_shape(input->num(), hidden_size * 4, 1, 1);
+    Shape aligned_xx_shape(input->num(), this->aligned_hidden_size_ * 4, 1, 1);
+    // if current size < request size, realloc a buf
+    this->xx_ = request_buf_for_input(this->xx_, xx_shape);
+    this->batch_xx_ = request_buf_for_input(this->batch_xx_, aligned_xx_shape);
+    this->batch_hidden_ = request_buf_for_input(this->batch_hidden_, aligned_output_shape);
+    this->batch_cell_ = request_buf_for_input(this->batch_cell_, aligned_output_shape);
+    this->batch_cell_act_ = request_buf_for_input(this->batch_cell_act_, aligned_output_shape);
+
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(
+        const std::vector<DataTensor_in*>& inputs,
+        std::vector<DataTensor_out*>& outputs,
+        LstmParam<OpTensor> &param) {
+    DataTensor_in *input = inputs[0];
+    DataTensor_out *hidden_out = outputs[0];
+    DataTensor_out *cell_out = nullptr;
+    if (outputs.size() >= 2) {
+        cell_out = outputs[1];
+    }
+    const OpTensor *bias = param.bias();
+    const OpTensor *init_t0 = param.init_hidden();
+
+    int hidden_size = hidden_out->channel();
+    int batch_size = input->get_seq_offset().size() - 1;
+    Shape offset(0, 0, 0, 0);
+
+    // init state shape
+    Shape init_state_shape(batch_size, hidden_size, 1 , 1);
+    math::ReorderInitState<OpDtype, LayOutType_op> reorder;
+
+    DataTensor_in *xx = nullptr;
+
+    if (param.skip_input) {
+        // if skip_input is true, the input memory layout should be
+        // total_seq_len * (4 * hidden_size)
+        xx = input;
+    } else {
+        // if skip_input is false, the input memory layout should be
+        // total_seq_len * input_size
+        // xx = x * [Wix, Wfx, Wcx, Wox]
+        Shape xx_shape(input->num(), hidden_size * 4, 1, 1);
+
+        // if current size < request size, realloc a buf for using
+        xx = new DataTensor_in();
+        this->xx_ = request_buf_for_input(this->xx_, xx_shape);
+        xx->share_sub_buffer(*(this->xx_), xx_shape, offset);
+
+        MatrixInfo<DataType_in> src((input->mutable_data()), input->num(), input->channel());
+        MatrixInfo<DataType_in> dst((xx->mutable_data()), xx->num(), xx->channel());
+        packed_w_x_->gemm_compute(src, &dst, 0.0f);
+
+        // input activation
+        int cnt = xx->size();
+        DataType_out *p = xx->mutable_data();
+        switch (param.input_activity) {
+            case Active_stanh:
+            case Active_tanh:
+                math::parallel_activation(cnt, p, p, param.input_activity);
+                break;
+            case Active_unknow:
+                break;
+            default:
+                        LOG(ERROR) << "not supported input activation";
+                return SaberUnImplError;
+        }
+    }
+
+    DataTensor_in batch_xx;
+    Shape aligned_xx_shape(xx->num(), this->aligned_hidden_size_ * 4, 1 , 1);
+    batch_xx.share_sub_buffer(*(this->batch_xx_), aligned_xx_shape, offset);
+
+    DataTensor_out batch_hidden;
+    Shape aligned_output_shape(hidden_out->num(), this->aligned_hidden_size_, 1 , 1);
+    batch_hidden.share_sub_buffer(*(this->batch_hidden_), aligned_output_shape, offset);
+
+    DataTensor_out batch_cell;
+    batch_cell.share_sub_buffer(*(this->batch_cell_), aligned_output_shape, offset);
+
+    DataTensor_out batch_cell_act;
+    batch_cell_act.share_sub_buffer(*(this->batch_cell_act_), aligned_output_shape, offset);
+
+    MatrixInfo<DataType_in> xx_matrix(xx->mutable_data(), xx->num(), xx->channel());
+    MatrixInfo<DataType_in> batch_xx_matrix(batch_xx.mutable_data(), batch_xx.num(), batch_xx.channel());
+    MatrixInfo<DataType_out> batch_hidden_matrix(batch_hidden.mutable_data(), batch_hidden.num(), batch_hidden.channel());
+    MatrixInfo<DataType_out> batch_cell_matrix(batch_cell.mutable_data(), batch_cell.num(), batch_cell.channel());
+    MatrixInfo<DataType_out> batch_cell_act_matrix(batch_cell_act.mutable_data(), batch_cell_act.num(), batch_cell_act.channel());
+
+    // handle bias info
+    if (bias) {
+        // row-wise-add bias to batch_xx, the layout of bias [bi, bf, bc, bo]
+        const DataType_op *bias_data = bias->data();
+        for (int i = 0; i < input->num(); i++) {
+            int row_size = 4 * hidden_size;
+            cblas_saxpby(row_size, 1, bias_data, 1, 1, (xx_matrix.buf() + i * row_size), 1);
+        }
+    }
+
+    // seq to batch meta data
+    std::vector<std::vector<int>> seq_to_batch_meta;
+    seq_to_batch_meta.push_back(input->get_seq_offset());
+
+    // sequence to batch
+    bool is_reverse = param.is_reverse;
+    math::Seq2BatchFunctor<inDtype, LayOutType_in> to_batch;
+    to_batch(xx, &batch_xx, seq_to_batch_meta, true, is_reverse, 4);
+
+    std::vector<int> order(seq_to_batch_meta[2]);
+    LstmMetaValue<DataType_in> lstm_value;
+    bool with_peephole = param.with_peephole;
+    if (bias && with_peephole) {
+        // with peephole enable, [Wic, Wfc, Woc] is at the behind of bias
+        const DataType_op *bias_data = bias->data();
+        lstm_value.check_ig = this->check_ig_->data();
+        lstm_value.check_fg = this->check_fg_->data();
+        lstm_value.check_og = this->check_og_->data();
+    } else {
+        lstm_value.check_ig = nullptr;
+        lstm_value.check_fg = nullptr;
+        lstm_value.check_og = nullptr;
+    }
+    lstm_value.prev_state_value = nullptr;
+    auto gate_act = param.gate_activity;
+    auto cell_act = param.cell_activity;
+    auto cand_act = param.candidate_activity;
+
+    if (init_t0) {
+        // if have init cell info, fill it to lstm value
+        // get init_c0 from init_t0 and reorder it
+        Shape offset(batch_size, 0, 0, 0);
+        OpTensor init_c0;
+        init_c0.share_sub_buffer(*init_t0, init_state_shape, offset);
+        reorder(&init_c0, order, batch_c0_, true);
+
+        lstm_value.prev_state_value = batch_c0_->mutable_data();
+    }
+
+    auto batch_starts = seq_to_batch_meta[0];
+    size_t num_batch = batch_starts.size() - 1;
+    for (size_t n = 0; n < num_batch; n++) {
+        int bstart = batch_starts[n];
+        int bend = batch_starts[n + 1];
+        int cur_batch_size = bend - bstart;
+
+        // xx += Ht-1 * [Wih, Wfh, Wch, Woh] according to batch number
+        MatrixInfo<DataType_in> dst = batch_xx_matrix.subMatrixInfo(bstart, bend);
+        if (n > 0) {
+            // if n > 0, get Ht-1 information from last calc, and convert it to src
+            int pre_h_start = batch_starts[n - 1];
+            int pre_h_end = pre_h_start + cur_batch_size;
+            MatrixInfo<DataType_in> src = batch_hidden_matrix.subMatrixInfo(pre_h_start, pre_h_end);
+            packed_w_h_->gemm_compute(src, &dst);
+        } else if (init_t0) {
+            // if this is the fisrt time calc and the batch_h0_ is not NULL, then using the init hidden value as src
+            // get init_h0 from init_t0 and reorder it
+            Shape offset(0, 0, 0, 0);
+            OpTensor init_h0;
+            init_h0.share_sub_buffer(*init_t0, init_state_shape, offset);
+            reorder(&init_h0, order, batch_h0_, true);
+
+            MatrixInfo<DataType_in> src((batch_h0_->mutable_data()), batch_h0_->num(), batch_h0_->channel());
+            packed_w_h_->gemm_compute(src, &dst);
+        }
+
+        // calc [Wic*Ct-1, Wfc*Ct-1, WocCt] and activation
+        // fill lstm value with the calc result before and the output buf
+        lstm_value.gate_value = dst.buf();
+        lstm_value.output_value = batch_hidden_matrix.subMatrixInfo(bstart, bend).buf();
+        lstm_value.state_value = batch_cell_matrix.subMatrixInfo(bstart, bend).buf();
+        lstm_value.state_active_value = batch_cell_act_matrix.subMatrixInfo(bstart, bend).buf();
+        if (avx2_available_) {
+            compute_with_avx(lstm_value, this->aligned_hidden_size_, cur_batch_size, gate_act, cell_act, cand_act);
+        } else {
+            compute(lstm_value, this->aligned_hidden_size_, cur_batch_size, gate_act, cell_act, cand_act);
+        }
+        lstm_value.prev_state_value = lstm_value.state_value;
+    }
+
+    // batch to sequence
+    math::Batch2SeqFunctor<outDtype, LayOutType_out> to_seq;
+    to_seq(&batch_hidden, hidden_out, seq_to_batch_meta);
+
+    if (cell_out) {
+        to_seq(&batch_cell, cell_out, seq_to_batch_meta);
+    }
+
+    if (!param.skip_input && xx) {
+        delete xx;
+        xx = nullptr;
+    }
+
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::init_conf(
+        const std::vector<DataTensor_in*>& inputs,
+        std::vector<DataTensor_out*>& outputs,
+        LstmParam<OpTensor> &param) {
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+SaberStatus SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>::check_conf(
+        const std::vector<DataTensor_in*>& inputs,
+        std::vector<DataTensor_out*>& outputs,
+        LstmParam<OpTensor> &param) {
+    return SaberSuccess;
+}
+
+template class SaberLstm<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+
+} // namespace saber
+} // namespace anakin
diff --git a/saber/funcs/impl/x86/saber_lstm.h b/saber/funcs/impl/x86/saber_lstm.h
new file mode 100644
index 0000000..4817d1c
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_lstm.h
@@ -0,0 +1,185 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_SABER_LSTM_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_SABER_LSTM_H
+
+#include "saber/saber_types.h"
+#include "saber/funcs/impl/impl_base.h"
+#include "saber/saber_funcs_param.h"
+#include "mkl_packed_weight.h"
+#include "sequence2batch.h"
+
+#include "saber/funcs/impl/impl_lstm.h"
+
+namespace anakin {
+namespace saber {
+
+template <class T>
+struct LstmMetaValue {
+    T *gate_value;
+    T *prev_state_value;
+    T *state_value;
+    T *state_active_value;
+    T *output_value;
+    const T *check_ig;
+    const T *check_fg;
+    const T *check_og;
+};
+
+template <DataType OpDtype,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+class SaberLstm<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>: public ImplBase<
+        Tensor<X86, inDtype, LayOutType_in>,
+        Tensor<X86, outDtype, LayOutType_out>,
+        Tensor<X86, OpDtype, LayOutType_op>,
+        LstmParam<Tensor<X86, OpDtype, LayOutType_op> > > {
+public:
+    typedef Tensor<X86, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<X86, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<X86, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype DataType_in;
+    typedef typename DataTensor_out::Dtype DataType_out;
+    typedef typename OpTensor::Dtype DataType_op;
+
+    SaberLstm() :
+            avx2_available_(false), max_thread_num_(1),
+            packed_w_x_(nullptr), packed_w_h_(nullptr),
+            batch_h0_(nullptr), batch_c0_(nullptr), check_ig_(nullptr),
+            check_fg_(nullptr), check_og_(nullptr),
+            xx_(nullptr), batch_xx_(nullptr), batch_hidden_(nullptr),
+            batch_cell_(nullptr), batch_cell_act_(nullptr), aligned_hidden_size_(0) {
+    }
+
+    ~SaberLstm() {
+        safe_free(&packed_w_x_);
+        safe_free(&packed_w_h_);
+        safe_free(&batch_h0_);
+        safe_free(&batch_c0_);
+        safe_free(&check_ig_);
+        safe_free(&check_fg_);
+        safe_free(&check_og_);
+        safe_free(&xx_);
+        safe_free(&batch_xx_);
+        safe_free(&batch_hidden_);
+        safe_free(&batch_cell_);
+        safe_free(&batch_cell_act_);
+    }
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             LstmParam<OpTensor> &param,
+                             Context<X86> &ctx) override;
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
+                               std::vector<DataTensor_out*>& outputs,
+                               LstmParam<OpTensor> &param,
+                               Context<X86> &ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                 std::vector<DataTensor_out*>& outputs,
+                                 LstmParam<OpTensor> &param) override;
+
+    virtual SaberStatus init_conf(
+            const std::vector<DataTensor_in*>& inputs,
+            std::vector<DataTensor_out*>& outputs,
+            LstmParam<OpTensor>& param);
+
+private:
+    inline void safe_free(MatrixInfo<DataType_op> **ptr) {
+        if (*ptr) {
+            delete (*ptr);
+            (*ptr) = nullptr;
+        }
+    }
+
+    inline void safe_free(DataTensor_in **ptr) {
+        if (*ptr) {
+            delete (*ptr);
+            (*ptr) = nullptr;
+        }
+    }
+
+    inline void safe_free(mkl_packed_weight<OpDtype, LayOutType_op> **ptr) {
+        if (*ptr) {
+            delete (*ptr);
+            (*ptr) = nullptr;
+        }
+    }
+
+    inline DataTensor_in* request_buf_for_input(DataTensor_in *input, Shape required_shape) {
+        if (input) {
+            int len = 1;
+            if (required_shape.size() == 0) {
+                len = 0;
+            }
+            for (int i = 0; i < required_shape.size(); i++) {
+                len *= required_shape[i];
+            }
+            if (input->size() < len) {
+                input->re_alloc(required_shape);
+            }
+        } else {
+            input = new DataTensor_in(required_shape);
+        }
+        return input;
+    }
+
+    bool avx2_available_;
+    int max_thread_num_;
+
+    mkl_packed_weight<OpDtype, LayOutType_op> *packed_w_x_;
+    mkl_packed_weight<OpDtype, LayOutType_op> *packed_w_h_;
+    OpTensor *batch_h0_;
+    OpTensor *batch_c0_;
+    OpTensor *check_ig_;
+    OpTensor *check_fg_;
+    OpTensor *check_og_;
+    // buf for storing data after calculating x * [Wix, Wfx, Wcx, Wox]
+    DataTensor_in *xx_;
+    // buf for storing data after xx calculating seq to batch
+    DataTensor_in *batch_xx_;
+
+    // buf for storing batch tmp data
+    DataTensor_out *batch_hidden_;
+    DataTensor_out *batch_cell_;
+    DataTensor_out *batch_cell_act_;
+    /*aligned with 256bit(8 float)*/
+    size_t aligned_hidden_size_;
+
+    virtual SaberStatus check_conf(const std::vector<DataTensor_in*>& inputs,
+                                   std::vector<DataTensor_out*>& outputs,
+                                   LstmParam<OpTensor>& param);
+
+    virtual void compute(LstmMetaValue<DataType_in> value,
+                         int hidden_size, int batch_size,
+                         const ActiveType &gate_act,
+                         const ActiveType &cell_act,
+                         const ActiveType &cand_act);
+    virtual void compute_with_avx(LstmMetaValue<DataType_in> value,
+                                  int hidden_size, int batch_size,
+                                  const ActiveType &gate_act,
+                                  const ActiveType &cell_act,
+                                  const ActiveType &cand_act);
+};
+
+} // namespace saber
+} // namespace anakin
+
+#endif // ANAKIN_SABER_FUNCS_IMPL_X86_SABER_LSTM_H
diff --git a/saber/funcs/impl/x86/saber_normal_activation.h b/saber/funcs/impl/x86/saber_normal_activation.h
new file mode 100644
index 0000000..41d5f6f
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_normal_activation.h
@@ -0,0 +1,91 @@
+
+#ifndef ANAKIN_SABER_NORMAL_ACTIVATION_H
+#define ANAKIN_SABER_NORMAL_ACTIVATION_H
+
+#define SIGMOID_THRESHOLD_MIN -40.0
+#define SIGMOID_THRESHOLD_MAX 13.0
+#define EXP_MAX_INPUT 40.0
+/*
+template <typename Dtype>
+inline Dtype InValidAct(Dtype a) {
+    CHECK_EQ(0,1)<<"InValidAct";
+}
+
+template <typename Dtype>
+inline Dtype Sigmoid(const Dtype a) {
+    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-a));
+}
+
+template <typename Dtype>
+inline Dtype Sigmoid_fluid(const Dtype a) {
+    const Dtype min = SIGMOID_THRESHOLD_MIN;
+    const Dtype max = SIGMOID_THRESHOLD_MAX;
+    Dtype tmp = (a < min) ? min : ((a > max) ? max : a);
+    return static_cast<Dtype>(1.0) / (static_cast<Dtype>(1.0) + exp(-tmp));
+}
+
+template <typename Dtype>
+inline Dtype Tanh_fluid(const Dtype a) {
+    Dtype tmp = -2.0 * a;
+    tmp = (tmp > EXP_MAX_INPUT) ? EXP_MAX_INPUT : tmp;
+    return (2.0 / (1.0 + exp(tmp))) - 1.0;
+}
+
+template <typename Dtype>
+inline Dtype Tanh(const Dtype a) {
+    Dtype tmp = -2.0 * a;
+    return (2.0 / (1.0 + exp(tmp))) - 1.0;
+}
+
+template <typename Dtype>
+inline Dtype Relu(const Dtype a) {
+    return a > static_cast<Dtype>(0.0) ? a : static_cast<Dtype>(0.0);
+}
+
+template <typename Dtype>
+inline Dtype Identity(const Dtype a) {
+    return a;
+}
+*/
+
+inline float InValidAct(float a) {
+            CHECK_EQ(0,1)<<"InValidAct";
+}
+
+
+inline float Sigmoid(const float a) {
+    return static_cast<float>(1.0) / (static_cast<float>(1.0) + exp(-a));
+}
+
+
+inline float Sigmoid_fluid(const float a) {
+    const float min = SIGMOID_THRESHOLD_MIN;
+    const float max = SIGMOID_THRESHOLD_MAX;
+    float tmp = (a < min) ? min : ((a > max) ? max : a);
+    return static_cast<float>(1.0) / (static_cast<float>(1.0) + exp(-tmp));
+}
+
+
+inline float Tanh_fluid(const float a) {
+    float tmp = -2.0 * a;
+    tmp = (tmp > EXP_MAX_INPUT) ? EXP_MAX_INPUT : tmp;
+    return (2.0 / (1.0 + exp(tmp))) - 1.0;
+}
+
+inline float Tanh(const float a) {
+    float tmp = -2.0 * a;
+    return (2.0 / (1.0 + exp(tmp))) - 1.0;
+}
+
+inline float Relu(const float a) {
+    return a > static_cast<float>(0.0) ? a : static_cast<float>(0.0);
+}
+
+
+inline float Identity(const float a) {
+    return a;
+}
+float (*act_funcs[])(float)= {&InValidAct, &Sigmoid, &Relu, &Tanh, &InValidAct, \
+                                        & InValidAct, &Identity, &Sigmoid_fluid, &Tanh_fluid
+};
+#endif //ANAKIN_SABER_NORMAL_ACTIVATION_H
diff --git a/saber/funcs/impl/x86/saber_pooling.cpp b/saber/funcs/impl/x86/saber_pooling.cpp
index 5c2118d..7b54f89 100644
--- a/saber/funcs/impl/x86/saber_pooling.cpp
+++ b/saber/funcs/impl/x86/saber_pooling.cpp
@@ -25,7 +25,7 @@ SaberStatus SaberPooling<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return create(inputs, outputs, param, ctx);
 }
diff --git a/saber/funcs/impl/x86/saber_scale.cpp b/saber/funcs/impl/x86/saber_scale.cpp
index 230c617..5c5d10f 100644
--- a/saber/funcs/impl/x86/saber_scale.cpp
+++ b/saber/funcs/impl/x86/saber_scale.cpp
@@ -20,7 +20,7 @@ SaberStatus SaberScale<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return create(inputs, outputs, param, ctx);
 }
diff --git a/saber/funcs/impl/x86/saber_sequence_conv.cpp b/saber/funcs/impl/x86/saber_sequence_conv.cpp
new file mode 100644
index 0000000..e5a5965
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_sequence_conv.cpp
@@ -0,0 +1,76 @@
+#include "saber/funcs/impl/x86/saber_sequence_conv.h"
+#include "saber/saber_funcs_param.h"
+#include "saber/core/tensor_op.h"
+#include "mkl_cblas.h"
+namespace anakin {
+namespace saber {
+
+static void gemm(const bool TransA, const bool TransB, int m, int n, int k, const float alpha,
+                 const float* a, const float* b, const float beta, float* c) {
+    //    cout << "(" << m << "," << n << "," << k << ")" << endl;
+    int lda = (!TransA/* == CblasNoTrans*/) ? k : m;
+    int ldb = (!TransB/* == CblasNoTrans*/) ? n : k;
+    CBLAS_TRANSPOSE cuTransA =
+        (!TransA/* == CblasNoTrans*/) ? CblasNoTrans : CblasTrans;
+    CBLAS_TRANSPOSE cuTransB =
+        (!TransB/* == CblasNoTrans*/) ? CblasNoTrans : CblasTrans;
+    cblas_sgemm(CblasRowMajor, cuTransA, cuTransB, m, n, k, alpha, a, k, b, n, beta, c, n);
+};
+
+template <typename Dtype>
+static void im2col_2d_ocf(const Dtype* in, int stride, int pad_up, int pad_down, int kernel_size,
+                          Dtype* out, int seq_length, int hidden_size) {
+    for (int out_row = 0; out_row < seq_length; ++out_row) {
+        for (int col = 0; col < kernel_size; ++col) {
+            int index = out_row + col - pad_up;
+            int out_index = (out_row * kernel_size + col) * hidden_size;
+
+            for (int hidden_index = 0; hidden_index < hidden_size; ++hidden_index) {
+                if (index < 0 || index >= seq_length) {
+                    out[out_index + hidden_index] = 0;
+                } else {
+                    //                    printf("%d -> %d [%f]\n",index+hidden_index,out_index+hidden_index,in[index+hidden_index]);
+                    out[out_index + hidden_index] = in[index * hidden_size + hidden_index];
+                }
+            }
+        }
+    }
+}
+
+template <>
+SaberStatus SaberSequenceConv<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>::dispatch(
+    const std::vector<DataTensor_in*>& inputs,
+    std::vector<DataTensor_out*>& outputs,
+    SequenceConvParam<OpTensor>& param) {
+    DataTensor_in* in_data = inputs[0];
+    DataTensor_out* out_data = outputs[0];
+    std::vector<int> offset = in_data->get_seq_offset();
+    out_data->set_seq_offset(offset);
+
+    int word_num = offset[offset.size() - 1];
+    _temp_im2col_tensor.try_expand_size(word_num * param.filter_tensor->height());
+
+
+    for (int i = 0; i < offset.size() - 1; ++i) {
+        int start = offset[i];
+        int seq_length = offset[i + 1] - offset[i];
+        im2col_2d_ocf(in_data->data() + _hidden_size * start, param.context_stride, _up_pad, _down_pad,
+                      param.context_length, _temp_im2col_tensor.mutable_data() + _hidden_kernel_size * start, seq_length,
+                      _hidden_size);
+    }
+
+    //    printf("up and down %d,%d\n",_up_pad,_down_pad);
+//    for (int i = 0; i < word_num * param.filter_tensor->height(); i++) {
+//        printf("[%d] = %f\n", i, _temp_im2col_tensor.data()[i]);
+//    }
+
+    gemm(false, false, word_num, _feature_size, _hidden_kernel_size, 1.f, _temp_im2col_tensor.data(),
+         param.filter_tensor->data(), 0.f, out_data->mutable_data());
+
+    out_data->set_seq_offset(offset);
+    return SaberSuccess;
+}
+
+
+}
+}
diff --git a/saber/funcs/impl/x86/saber_sequence_conv.h b/saber/funcs/impl/x86/saber_sequence_conv.h
new file mode 100644
index 0000000..09590fd
--- /dev/null
+++ b/saber/funcs/impl/x86/saber_sequence_conv.h
@@ -0,0 +1,91 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_SABER_SEQUENCE_CONV_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_SABER_SEQUENCE_CONV_H
+
+#include "saber/funcs/impl/impl_sequence_conv.h"
+#include "saber/saber_funcs_param.h"
+
+
+namespace anakin {
+namespace saber {
+
+template <DataType OpDtype,
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+class SaberSequenceConv<X86, OpDtype, inDtype, outDtype,
+          LayOutType_op, LayOutType_in, LayOutType_out> : public ImplBase <
+          Tensor<X86, inDtype, LayOutType_in>,
+          Tensor<X86, outDtype, LayOutType_out>,
+          Tensor<X86, OpDtype, LayOutType_op>,
+          SequenceConvParam<Tensor<X86, OpDtype, LayOutType_op> > > {
+public:
+    typedef Tensor<X86, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<X86, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<X86, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype DataType_in;
+    typedef typename DataTensor_out::Dtype DataType_out;
+    typedef typename OpTensor::Dtype DataType_op;
+
+    SaberSequenceConv() = default;
+
+    ~SaberSequenceConv() {}
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             SequenceConvParam<OpTensor>& param,
+                             Context<X86>& ctx) {
+        this->_ctx = &ctx;
+        CHECK_EQ(param.padding_trainable, false) << "not support padding_trainable==true";
+        CHECK_EQ(param.context_stride, 1) << "not support context_stride!=1";
+
+        if (param.padding_tensor != nullptr) {
+            CHECK_EQ(1, 0) << "not support padding_tensor";
+        }
+
+        CHECK_NOTNULL(param.filter_tensor);
+        _hidden_size = param.filter_tensor->height() / param.context_length;
+        _feature_size = param.filter_tensor->width();
+        _up_pad = std::max(0, -param.context_start);
+        _down_pad = std::max(0, param.context_start + param.context_length - 1);
+        _hidden_kernel_size = _hidden_size * param.context_length;
+        return create(inputs, outputs, param, ctx);
+    };
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
+                               std::vector<DataTensor_out*>& outputs,
+                               SequenceConvParam<OpTensor>& param,
+                               Context<X86>& ctx) {
+        return SaberSuccess;
+    };
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                 std::vector<DataTensor_out*>& outputs,
+                                 SequenceConvParam<OpTensor>& param);
+private:
+    OpTensor _temp_im2col_tensor;
+    int _hidden_size;
+    int _feature_size;
+    int _hidden_kernel_size;
+    int _up_pad;
+    int _down_pad;
+};
+}
+}
+
+#endif
\ No newline at end of file
diff --git a/saber/funcs/impl/x86/saber_sequence_pool.cpp b/saber/funcs/impl/x86/saber_sequence_pool.cpp
index ab4d4e1..246186b 100644
--- a/saber/funcs/impl/x86/saber_sequence_pool.cpp
+++ b/saber/funcs/impl/x86/saber_sequence_pool.cpp
@@ -12,8 +12,12 @@ template <typename dtype>
 void seq_pool_average(dtype* dst, const dtype* src_in,
                   const int slice_num, const int slice_size) {
     dtype sum = 0.f;
+#pragma omp parallel for
     for (int i = 0; i < slice_size; ++i) {
         sum = src_in[i];
+#pragma vector aligned
+#pragma simd reduction(+:sum)
+#pragma unroll(8)
         for (int s = 1; s < slice_num; ++s) {
             dtype src_in_read = src_in[s * slice_size +i];
             sum += src_in_read;
@@ -26,8 +30,12 @@ template <typename dtype>
 void seq_pool_sum(dtype* dst, const dtype* src_in,
                   const int slice_num, const int slice_size) {
     dtype sum = 0.f;
+#pragma omp parallel for
     for (int i = 0; i < slice_size; ++i) {
         sum = src_in[i];
+#pragma vector aligned
+#pragma simd reduction(+:sum)
+#pragma unroll(8)
         for (int s = 1; s < slice_num; ++s) {
             dtype src_in_read = src_in[s * slice_size +i];
             sum += src_in_read;
@@ -41,8 +49,12 @@ void seq_pool_sqrt(dtype* dst, const dtype* src_in,
                   const int slice_num, const int slice_size) {
     dtype sqrt_len = sqrtf(slice_num);
     dtype sum = 0.f;
+#pragma omp parallel for
     for (int i = 0; i < slice_size; ++i) {
         sum = src_in[i];
+#pragma vector aligned
+#pragma simd reduction(+:sum)
+#pragma unroll(4)
         for (int s = 1; s < slice_num; ++s) {
             dtype src_in_read = src_in[s * slice_size +i];
             sum += src_in_read;
@@ -55,6 +67,7 @@ template <typename dtype>
 void seq_pool_max(dtype* dst, const dtype* src_in,
                   const int slice_num, const int slice_size) {
     dtype max = 0.f;
+#pragma omp parallel for
     for (int i = 0; i < slice_size; ++i) {
         max = src_in[i];
         for (int s = 1; s < slice_num; ++s) {
@@ -82,7 +95,7 @@ SaberStatus SaberSequencePool<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_in::Dtype DataType_in;
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     kernel_direct_map = {
             {Sequence_pool_unknow, [](
                     DataType_in*, const DataType_in*, const int, const int){
@@ -125,7 +138,7 @@ SaberStatus SaberSequencePool<X86, OpDtype, inDtype, outDtype,
     typedef typename DataTensor_out::Dtype DataType_out;
     typedef typename OpTensor::Dtype DataType_op;
 
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return SaberSuccess;
 }
@@ -166,6 +179,12 @@ SaberStatus SaberSequencePool<X86, OpDtype, inDtype, outDtype,
         dst_ptr += slice_size;
         src_ptr += slice_size * slice_num;
     }
+    int batch_size=seq_offset.size()-1;
+    std::vector<int> offset_new(batch_size+1);
+    for(int i=0;i<=batch_size;++i){
+        offset_new[i]=i;
+    }
+    outputs[0]->set_seq_offset(offset_new);
     return SaberSuccess;
 
 }
diff --git a/saber/funcs/impl/x86/saber_softmax.cpp b/saber/funcs/impl/x86/saber_softmax.cpp
index f9f3d4d..36a4c3d 100644
--- a/saber/funcs/impl/x86/saber_softmax.cpp
+++ b/saber/funcs/impl/x86/saber_softmax.cpp
@@ -19,7 +19,7 @@ SaberStatus SaberSoftmax<X86, OpDtype, inDtype, outDtype,
         std::vector<DataTensor_out*>& outputs,
         SoftmaxParam<OpTensor> &param, Context<X86> &ctx)
 {
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
     return create(inputs, outputs, param, ctx);
 }
 
@@ -37,7 +37,7 @@ SaberStatus SaberSoftmax<X86, OpDtype, inDtype, outDtype,
 {
 //    LOG(INFO)<<"here!!!";
     this->_param = &param;
-    this->_ctx = ctx;
+    this->_ctx = &ctx;
 
     return SaberSuccess;
 }
@@ -142,6 +142,7 @@ SaberStatus SaberSoftmax<X86, OpDtype, inDtype, outDtype,
     int channel = inputs[0]->channel();
     float *src_ptr = inputs[0]->mutable_data();
     float *dst_ptr = outputs[0]->mutable_data();
+    outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
 
 #pragma omp parallel for schedule(static)
     for (int ou = 0; ou < num ; ou++) {
diff --git a/saber/funcs/impl/x86/sequence2batch.cpp b/saber/funcs/impl/x86/sequence2batch.cpp
new file mode 100644
index 0000000..b7a3ab6
--- /dev/null
+++ b/saber/funcs/impl/x86/sequence2batch.cpp
@@ -0,0 +1,64 @@
+#include "sequence2batch.h"
+
+namespace anakin {
+namespace saber {
+namespace math {
+
+template <DataType Dtype, typename LayOutType>
+void CopyMatrixRowsFunctor<Dtype, LayOutType>::operator()(
+        ioTensor* src,
+        std::vector<int> index_lod, ioTensor* dst,
+        bool is_src_index, int fragment_num) {
+    int* index = index_lod.data();
+    auto src_shape = src->valid_shape();
+    auto dst_shape = dst->valid_shape();
+    /*if (src_shape.size() != 2) {
+        LOG(ERROR) << "The src must be matrix with rank 2.";
+        exit(-1);
+    }
+    if (dst_shape.size() != 2) {
+        LOG(ERROR) << "The dst must be matrix with rank 2.";
+        exit(-1);
+    }
+    if (dst_shape[1] != src_shape[1]) {
+        LOG(ERROR) << "The width of src and dst must be same.";
+        exit(-1);
+    }*/
+    if (dst_shape[1] % fragment_num != 0 && src_shape[1] % fragment_num != 0) {
+                LOG(ERROR) << "hidden size should be divided with no remainder by fragment_num.";
+        exit(-1);
+    }
+    auto height = dst_shape[0];
+    auto dst_width = dst_shape[1] / fragment_num;
+    auto src_width = src_shape[1] / fragment_num;
+    auto real_width = (dst_width > src_width ? src_width: dst_width);
+    auto* src_data = src->data();
+    auto* dst_data = dst->mutable_data();
+    if (is_src_index) {
+#pragma omp parallel for collapse(2)
+        for (int i = 0; i < height; ++i) {
+            for (int j = 0; j < fragment_num; j++) {
+                memcpy(dst_data + i * fragment_num * dst_width + j * dst_width, src_data + index[i] * fragment_num * src_width + j * src_width,
+                       real_width * sizeof(dtype));
+            }
+        }
+    } else {
+#pragma omp parallel for collapse(2)
+        for (int i = 0; i < height; ++i) {
+            for (int j = 0; j < fragment_num; j++) {
+                memcpy(dst_data + index[i] * fragment_num * dst_width + j * dst_width, src_data + i * fragment_num * src_width + j * src_width,
+                       real_width * sizeof(dtype));
+            }
+        }
+    }
+}
+
+template class CopyMatrixRowsFunctor<AK_FLOAT, NCHW>;
+
+template class Seq2BatchFunctor<AK_FLOAT, NCHW>;
+template class Batch2SeqFunctor<AK_FLOAT, NCHW>;
+template class ReorderInitState<AK_FLOAT, NCHW>;
+
+}  // namespace math
+}  // namespace saber
+}  // namespace anakin
diff --git a/saber/funcs/impl/x86/sequence2batch.h b/saber/funcs/impl/x86/sequence2batch.h
new file mode 100644
index 0000000..50bc55f
--- /dev/null
+++ b/saber/funcs/impl/x86/sequence2batch.h
@@ -0,0 +1,367 @@
+#ifndef ANAKIN_SABER_FUNC_IMPL_X86_MATH_SEQUENCE_BATCH_H
+#define ANAKIN_SABER_FUNC_IMPL_X86_MATH_SEQUENCE_BATCH_H
+
+#include <algorithm>
+#include <vector>
+#include "saber/core/tensor.h"
+#include "omp.h"
+
+namespace anakin {
+namespace saber {
+namespace math {
+
+template <DataType Dtype, typename LayOutType>
+class CopyMatrixRowsFunctor {
+public:
+    typedef Tensor<X86, Dtype, LayOutType> ioTensor;
+    typedef typename ioTensor::Dtype dtype;
+
+    // If is_src_index is true,
+    // copy the indexed rows of input src to the output dst.
+    // If is_src_index is false,
+    // copy the input src to the indexed rows of output dst.
+    // The indexed rows are based on the input index.
+    void operator()(ioTensor* src,
+                    std::vector<int> index_lod, ioTensor* dst,
+                    bool is_src_index, int fragment_num);
+};
+
+template <DataType Dtype, typename LayOutType>
+class Seq2BatchFunctor {
+    // Calculate the length of each sequence and
+    // sort sequence index by the length.
+    // example:  sequences = {s0, s1, s2}
+    //           s0: 0 0 0 0, s1: 1 1 1 1 1, s2: 2 2 2
+    //           seq_info[3] = {(4, 5, 1), (0, 4, 0), (9, 3, 2)}
+    //
+    struct SeqInfo {
+        SeqInfo(int start, int length, int seq_idx)
+            : start(start), length(length), seq_idx(seq_idx) {}
+        int start;
+        int length;
+        int seq_idx;
+    };
+
+public:
+    typedef Tensor<X86, Dtype, LayOutType> ioTensor;
+    void operator()(ioTensor* seq,
+                    ioTensor* batch, std::vector<std::vector<int>>& seq_to_batch_meta, bool is_cal_batch_lod,
+                    bool is_reverse = false, int fragment_num = 1) const {
+        if (!is_cal_batch_lod) {
+            if (seq_to_batch_meta.size() < 2) {
+                LOG(ERROR) << "The size of seq_to_batch_meta should inlcude at least 2-level sequence information.";
+                exit(-1);
+            }
+
+            if (seq_to_batch_meta[1].size() != static_cast<int>(seq->num())) {
+                LOG(ERROR) << "The seq_to_batch information should be consistent with the dims.";
+                exit(-1);
+            }
+
+            CopyMatrixRowsFunctor<Dtype, LayOutType> to_batch;
+            to_batch(seq, seq_to_batch_meta[1], batch, true, fragment_num);
+            return;
+        }
+
+        if (seq_to_batch_meta.size() != 1) {
+            LOG(ERROR) << "Only support one level sequence now.";
+            exit(-1);
+        }
+
+        auto seq_meta = seq_to_batch_meta[0];
+
+        std::vector<SeqInfo> seq_info;
+
+        for (int seq_id = 0; seq_id < seq_meta.size() - 1; ++seq_id) {
+            int length = seq_meta[seq_id + 1] - seq_meta[seq_id];
+            seq_info.emplace_back(seq_meta[seq_id], length, seq_id);
+            //LOG(INFO) << "seq_meta[seq_id]:" << seq_meta[seq_id] << " length:" << length << " seq_id:" <<seq_id;
+        }
+
+        std::sort(seq_info.begin(), seq_info.end(),
+        [](SeqInfo a, SeqInfo b) {
+            return a.length > b.length;
+        });
+
+        // Calculate the start position of each batch.
+        // example:  sequences = {s0, s1, s2}
+        //           s0: 0 0 0 0, s1: 1 1 1 1 1, s2: 2 2 2
+        //           num_batch = 5,
+        //           batchIndex = {b0, b1, b2, b3, b4}
+        //           b0: 1 0 2, b1: 1 0 2, b2: 1 0 2, b3: 1 0, b4: 1
+        //           batch_start_positions[6] = {0, 3, 6, 9, 11, 12}
+        //              batch_start_positions[0] = len(b0)
+        //              batch_start_positions[1] = len(b0) + len(b1)
+        //              batch_start_positions[2] = len(b0) + len(b1) + len(b2)
+        //              ...
+        //           seq2batch_idx[12] = {4, 0, 9,
+        //                                5, 1, 10,
+        //                                6, 2, 11,
+        //                                7, 3,
+        //                                8}
+        //           seq_order = {1, 0, 2}, the sort order.
+        //               where 1 is the second sequence,
+        //                     0 is the first sequence,
+        //                     2 is the third sequence.
+        // The num_batch represents batch size after rearranging the
+        // input LodTensor. It is also the maximum length of input sequence.
+
+        std::vector<std::vector<int>> batch_seq_meta;
+        batch_seq_meta.emplace_back(std::vector<int> {0});
+        batch_seq_meta.emplace_back(std::vector<int> {0});
+        batch_seq_meta.emplace_back(std::vector<int> {0});
+
+        // batch_seq_meta[0] is the start positions for batch LoDTensor
+        int num_batch = seq_info[0].length;
+        batch_seq_meta[0].resize(static_cast<int>(num_batch + 1));
+        // batch_seq_meta[1] is the raw index in the input LoDTensor
+        batch_seq_meta[1].resize(static_cast<int>(seq->num()));
+        // batch_seq_meta[2] is the sort order for the input LoDTensor.
+        batch_seq_meta[2].resize(seq_info.size());
+
+        int* batch_starts = batch_seq_meta[0].data();
+        int* seq2batch_idx = batch_seq_meta[1].data();
+        batch_starts[0] = 0;
+
+        for (int n = 0; n < num_batch; n++) {
+            auto batch_id = static_cast<int>(batch_starts[n]);
+
+            for (int i = 0; i < seq_info.size(); ++i) {
+                int seq_len = seq_info[i].length;
+                int start = seq_info[i].start;
+
+                if (n < seq_len) {
+                    seq2batch_idx[batch_id] =
+                        is_reverse ? start + seq_len - 1 - n : start + n;
+                    batch_id++;
+                } else {
+                    break;
+                }
+            }
+
+            batch_starts[n + 1] = static_cast<int>(batch_id);
+        }
+
+        int* seq_order = batch_seq_meta[2].data();
+
+        for (int i = 0; i < seq_info.size(); ++i) {
+            seq_order[i] = seq_info[i].seq_idx;
+        }
+
+        seq_to_batch_meta = batch_seq_meta;
+
+        CopyMatrixRowsFunctor<Dtype, LayOutType> to_batch;
+        to_batch(seq, batch_seq_meta[1], batch, true, fragment_num);
+    }
+};
+
+template <DataType Dtype, typename LayOutType>
+class Batch2SeqFunctor {
+public:
+    typedef Tensor<X86, Dtype, LayOutType> ioTensor;
+    void operator()(ioTensor* batch,
+                    ioTensor* seq, std::vector<std::vector<int>>& seq_to_batch_meta, int fragment_num = 1) const {
+        if (seq_to_batch_meta.size() < 2) {
+            LOG(ERROR) << "The size of seq_to_batch_meta should inlcude at least 2-level sequence information.";
+            exit(-1);
+        }
+
+        if (seq_to_batch_meta[1].size() != static_cast<int>(seq->num())) {
+            LOG(ERROR) << "The seq_to_batch information should be consistent with the dims.";
+            exit(-1);
+        }
+
+        CopyMatrixRowsFunctor<Dtype, LayOutType> to_seq;
+        to_seq(batch, seq_to_batch_meta[1], seq, false, fragment_num);
+    }
+};
+
+template <DataType Dtype, typename LayOutType>
+class ReorderInitState {
+public:
+    typedef Tensor<X86, Dtype, LayOutType> ioTensor;
+    void operator()(ioTensor* src, std::vector<int> ind_lod, ioTensor* dst, bool indexed_src,
+                    int fragment_num = 1) {
+        math::CopyMatrixRowsFunctor<Dtype, LayOutType> row_shuffle;
+        row_shuffle(src, ind_lod, dst, indexed_src, fragment_num);
+    }
+};
+
+
+/*
+ * This class can used to modify the matrix structure of sequence matrix into
+ * batch structure.
+ * sequence matrix: [C1_s ... Cn_s | ...... | C1_t ... Cn_t]
+ * batch matrix:    [C1_s ... C1_t | ...... | Cn_s ... Cn_t]
+ * Cn_s is the state for sequence s at time n.
+ *
+ *  Exampel:  sequence matrix = {{0, 0, 0, 0}, {1, 1, 1, 1, 1}, {2, 2, 2}}
+ *            s0: 0 0 0 0, s1: 1 1 1 1 1, s2: 2 2 2
+ *            batch matrix = {{1, 0, 2}, {1, 0, 2}, {1, 0, 2}, {1, 0}, {1}}
+ *            b0: 1 0 2, b1: 1 0 2, b2: 1 0 2, b3: 1 0, b4: 1
+ *
+ *  Use:
+ *            Input: seqMatrix, seqStarts(Sequence Start Positions)
+ *            Output: batchMatrix
+ *            1. SequenceToBatch seq2batch;
+ *            2. seq2batch.resizeOrCreateBatch(seqStarts);     // calculate seq2BatchIdx
+ *            3. seq2batch.copy(seqMatrix, batchMatrix, true); // copy seq to batch matrix
+ *
+ */
+
+class SequenceToBatch {
+public:
+    SequenceToBatch() {};
+
+    template <typename Dtype>
+    void seq_2_bat(const Dtype*  input, Dtype* output, int word_size) {
+        int word_sum = seq2BatchIdx_.size();
+        #pragma omp parallel for if(thread_num > 1)
+
+        for (int old_id = 0; old_id < word_sum; ++old_id) {
+            int word_start = old_id * word_size;
+            int maped_id = seq2BatchIdx_[old_id];
+            int maped_start = maped_id * word_size;
+
+            for (int word_offset = 0; word_offset < word_size; ++word_offset) {
+                output[word_start + word_offset] = input[maped_start + word_offset];
+            }
+        }
+    }
+
+    template <typename Dtype>
+    void hidden_2_bat(const Dtype* input, Dtype* output, int hidden_size) {
+        int batch_size = seqStartAndLength_.size();
+
+        for (int old_id = 0; old_id < batch_size; ++old_id) {
+            int word_start = old_id * hidden_size;
+            int maped_id = seqStartAndLength_[old_id].seqIdx_;
+            int maped_start = maped_id * hidden_size;
+
+            for (int word_offset = 0; word_offset < hidden_size; ++word_offset) {
+                output[word_start + word_offset] = input[maped_start + word_offset];
+            }
+        }
+    }
+
+    template <typename Dtype>
+    void bat_2_seq(const Dtype* input, Dtype* output, int hidden_size) {
+        int word_sum = seq2BatchIdx_.size();
+        #pragma omp parallel for if(thread_num > 1)
+
+        for (int old_id = 0; old_id < word_sum; old_id++) {
+            int word_start = old_id * hidden_size;
+            int maped_id = seq2BatchIdx_[old_id];
+            int maped_start = maped_id * hidden_size;
+
+            for (int word_offset = 0; word_offset < hidden_size; word_offset++) {
+                output[maped_start + word_offset] = input[word_start + word_offset];
+            }
+        }
+    }
+
+    template <typename Dtype>
+    void bat_2_seq(const Dtype* input, Dtype* output, int hidden_size, int aligned_hidden_size) {
+        int word_sum = seq2BatchIdx_.size();
+        #pragma omp parallel for if(thread_num > 1)
+
+        for (int old_id = 0; old_id < word_sum; old_id++) {
+            int word_start = old_id * aligned_hidden_size;
+            int maped_id = seq2BatchIdx_[old_id];
+            int maped_start = maped_id * hidden_size;
+
+            for (int word_offset = 0; word_offset < hidden_size; word_offset++) {
+                output[maped_start + word_offset] = input[word_start + word_offset];
+            }
+        }
+    }
+
+    void get_batch_offset(std::vector<int>& bat_offset) {
+        for (size_t i = 0; i < batchStartPositions_.size(); i++) {
+            bat_offset[i] = batchStartPositions_[i];
+        }
+    }
+
+    size_t get_batch_num() const {
+        return numBatch_;
+    }
+
+    void create_batch(int batchSize, size_t numSequences, std::vector<int>& seqStarts,
+                      bool reversed) {
+        CHECK_EQ(seqStarts[numSequences], batchSize);
+        seq2BatchIdx_.resize(batchSize);
+
+        /*
+         * calculate the length of each sequence & sort sequence index by the length
+         * Exampel:  Sequences = {s0, s1, s2}
+         *           s0: 0 0 0 0, s1: 1 1 1 1 1, s2: 2 2 2
+         *           seqStartAndLength_[3] = {(4, 5, 1), (0, 4, 0), (9, 3, 2)}
+         */
+        for (size_t seqId = 0; seqId < numSequences; ++seqId) {
+            int length = seqStarts[seqId + 1] - seqStarts[seqId];
+            seqStartAndLength_.emplace_back(seqStarts[seqId], length, seqId);
+        }
+
+        std::sort(seqStartAndLength_.begin(), seqStartAndLength_.end(),
+        [](SeqStartAndLength a, SeqStartAndLength b) {
+            return a.length_ > b.length_;
+        });
+
+        /*
+         * calculate the start position of each batch
+         * (numBatch equal the maxLength of sequences)
+         * Exampel:  Sequences = {s0, s1, s2}
+         *           s0: 0 0 0 0, s1: 1 1 1 1 1, s2: 2 2 2
+         *           numBatch = 5,
+         *           batchIndex = {b0, b1, b2, b3, b4}
+         *           b0: 1 0 2, b1: 1 0 2, b2: 1 0 2, b3: 1 0, b4: 1
+         *           batchStartPositions[6] = {0, 3, 6, 9, 11, 12}
+         */
+        numBatch_ = (size_t)seqStartAndLength_[0].length_;
+        batchStartPositions_.resize(numBatch_ + 1);
+        batchStartPositions_[0] = 0;
+
+        for (size_t n = 0; n < numBatch_; n++) {
+            int batchId = batchStartPositions_[n];
+
+            for (size_t i = 0; i < seqStartAndLength_.size(); ++i) {
+                size_t seqLength = seqStartAndLength_[i].length_;
+                int start = seqStartAndLength_[i].start_;
+
+                if (n < seqLength) {
+                    if (!reversed) {
+                        seq2BatchIdx_[batchId] = start + n;
+                    } else {
+                        seq2BatchIdx_[batchId] = start + seqLength - 1 - n;
+                    }
+
+                    batchId++;
+                } else {
+                    break;
+                }
+            }
+
+            batchStartPositions_[n + 1] = batchId;
+        }
+    }
+
+
+protected:
+    struct SeqStartAndLength {
+        int start_;
+        int length_;
+        int seqIdx_;
+        SeqStartAndLength(int start, int length, int seqIdx)
+            : start_(start), length_(length), seqIdx_(seqIdx) {}
+    };
+    std::vector<SeqStartAndLength> seqStartAndLength_;
+    std::vector<int> batchStartPositions_;
+    std::vector<int> seq2BatchIdx_;
+    size_t numBatch_;
+    int thread_num = omp_get_max_threads();
+};
+}  // namespace math
+}  // namespace saber
+}  // namespace anakin
+
+#endif
diff --git a/saber/funcs/impl/x86/vender_fc.cpp b/saber/funcs/impl/x86/vender_fc.cpp
index d9b93e9..7b4c3d0 100644
--- a/saber/funcs/impl/x86/vender_fc.cpp
+++ b/saber/funcs/impl/x86/vender_fc.cpp
@@ -1,97 +1,143 @@
-#include "saber/funcs/impl/x86/vender_fc.h"
-#include "mkl_cblas.h"
-
-namespace anakin{
-namespace saber {
-
-typedef MKL_INT cblas_int;
-
-template class VenderFc<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
-
-template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
-SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
-        LayOutType_op, LayOutType_in, LayOutType_out>
-    ::init(const std::vector<DataTensor_in*>& inputs,
-                  std::vector<DataTensor_out*>& outputs,
-                  FcParam<OpTensor> &param, Context<X86> &ctx)
-{
-
-    typedef typename DataTensor_in::Dtype DataType_in;
-    typedef typename DataTensor_out::Dtype DataType_out;
-    typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
-
-    return create(inputs, outputs, param, ctx);
-}
-
-template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
-SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
-        LayOutType_op, LayOutType_in, LayOutType_out>
-    ::create(const std::vector<DataTensor_in*>& inputs,
-                  std::vector<DataTensor_out*>& outputs,
-                  FcParam<OpTensor> &param, Context<X86> &ctx)
-{
-    typedef typename DataTensor_in::Dtype DataType_in;
-    typedef typename DataTensor_out::Dtype DataType_out;
-    typedef typename OpTensor::Dtype DataType_op;
-    this->_ctx = ctx;
-    this->_param = &param;
-
-    return SaberSuccess;
-}
-
-template <DataType OpDtype ,
-    DataType inDtype,
-    DataType outDtype,
-    typename LayOutType_op,
-    typename LayOutType_in,
-    typename LayOutType_out>
-SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
-        LayOutType_op, LayOutType_in, LayOutType_out>
-    ::dispatch(const std::vector<DataTensor_in*>& inputs,
-                  std::vector<DataTensor_out*>& outputs,
-                  FcParam<OpTensor> &param)
-{
-    if (inDtype == AK_FLOAT) {
-        const float* src = static_cast<const float*>(inputs[0]->get_buf()->get_data());
-        const float* weights = static_cast<const float*>(param.weights->get_buf()->get_data());
-        const float* bias = NULL;
-        if (param.bias)
-            bias = static_cast<const float*>(param.bias->get_buf()->get_data());
-        float* dst = static_cast<float*>(outputs[0]->get_buf()->get_data_mutable());
-
-        // TODO: consistency checks
-        int m = inputs[0]->count_valid(0, param.axis);
-        int k = inputs[0]->count_valid(param.axis, inputs[0]->dims());
-        const cblas_int MB = m;
-        int channel_idx = outputs[0]->channel_index();
-        Shape output_shape = outputs[0]->shape();
-        const cblas_int OC = output_shape[channel_idx];
-        const cblas_int IC = k;
-
-        cblas_sgemm(CblasColMajor, param.is_transpose_weights ? CblasNoTrans : CblasTrans,
-                          CblasNoTrans, OC, MB, IC,
-                          1.0, weights, IC, src, IC, 0.0, dst, OC);
-        if (bias) {
-#pragma omp parallel for schedule(static)
-            for (cblas_int mb = 0; mb < MB; mb++) {
-                cblas_saxpy(OC, 1.0, bias, 1, dst + mb * OC, 1);
-            }
-        }
-    }
-    outputs[0]->set_seq_offset(inputs[0]->get_seq_offset());
-    return SaberSuccess;
-}
-
-}
-} // namespace anakin
+#include "saber/funcs/impl/x86/vender_fc.h"
+#include "saber/funcs/impl/x86/x86_utils.h"
+#include "mkl_cblas.h"
+#include "mkl_vml_functions.h"
+
+namespace anakin {
+namespace saber {
+
+typedef MKL_INT cblas_int;
+
+template class VenderFc<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+
+template <DataType OpDtype,
+    DataType inDtype,
+    DataType outDtype,
+    typename LayOutType_op,
+    typename LayOutType_in,
+    typename LayOutType_out>
+SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>
+    ::init(const std::vector<DataTensor_in*>& inputs,
+                  std::vector<DataTensor_out*>& outputs,
+                  FcParam<OpTensor> &param, Context<X86> &ctx) {
+    this->_ctx = &ctx;
+
+    return create(inputs, outputs, param, ctx);
+}
+
+template <DataType OpDtype,
+    DataType inDtype,
+    DataType outDtype,
+    typename LayOutType_op,
+    typename LayOutType_in,
+    typename LayOutType_out>
+SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>
+    ::create(const std::vector<DataTensor_in*>& inputs,
+                  std::vector<DataTensor_out*>& outputs,
+                  FcParam<OpTensor> &param, Context<X86> &ctx) {
+    if (inDtype != AK_FLOAT) {
+        LOG(ERROR) << "vender fc only supports FP32 currently";
+        return SaberUnImplError;
+    }
+
+    this->_ctx = &ctx;
+    this->_param = &param;
+
+    MB = inputs[0]->count_valid(0, param.axis);
+    OC = outputs[0]->channel();
+
+    // weights
+    for (int i = packed_weights.size() - 1; i >= 0; i--) {
+       cblas_sgemm_free(packed_weights[i]);
+    }
+    std::vector<DataType_op*> ().swap(packed_weights);
+
+    const DataType_op* weights = param.weights->data();
+    int total_IC = 0;
+    for (int i = 0; i < inputs.size(); i++) {
+        cblas_int IC = inputs[i]->count_valid(param.axis, inputs[i]->dims());
+        packed_weights.push_back(cblas_sgemm_alloc(CblasAMatrix, OC, MB, IC));
+        // LOG(INFO) << "anakin input[" << i << "] alloc passed";
+        cblas_sgemm_pack(CblasColMajor,
+                         CblasAMatrix,
+                         param.is_transpose_weights ? CblasNoTrans : CblasTrans,
+                         OC, MB, IC,
+                         1.0,
+                         weights + total_IC * OC, IC,
+                         packed_weights[i]);
+        total_IC += IC;
+        // LOG(INFO) << "anakin input[" << i << "] pack passed";
+    }
+
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+    DataType inDtype,
+    DataType outDtype,
+    typename LayOutType_op,
+    typename LayOutType_in,
+    typename LayOutType_out>
+SaberStatus VenderFc<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out>
+    ::dispatch(const std::vector<DataTensor_in*>& inputs,
+                  std::vector<DataTensor_out*>& outputs,
+                  FcParam<OpTensor> &param) {
+    if (inDtype == AK_FLOAT) {
+        float* dst = outputs[0]->mutable_data();
+        const float* bias = NULL;
+
+        if (param.bias) {
+            bias = param.bias->data();
+        }
+
+        for (int i = 0; i < inputs.size(); i++) {
+            const float* src = static_cast<const float*>(inputs[i]->data());
+            cblas_int IC = inputs[i]->count_valid(param.axis, inputs[i]->dims());
+            if(i == 0) {
+                // C := alpha * op(A) * op(B) + beta * C
+                cblas_sgemm_compute(CblasColMajor,                                     // Layout
+                                    CblasPacked,                                       // a
+                                    CblasNoTrans,                                      // b是否转置
+                                    OC, MB, IC,                                        // m, n, k
+                                    packed_weights[i], IC,                             // a, lda
+                                    src, IC,                                           // b, ldb
+                                    0.0,                                               // beta
+                                    dst, OC);                                          // c, ldc
+            } else {
+                cblas_sgemm_compute(CblasColMajor,                                     // Layout
+                                    CblasPacked,                                       // a
+                                    CblasNoTrans,                                      // b是否转置
+                                    OC, MB, IC,                                        // m, n, k
+                                    packed_weights[i], IC,                             // a, lda
+                                    src, IC,                                           // b, ldb
+                                    1.0,                                               // beta
+                                    dst, OC);                                          // c, ldc
+            }
+            //LOG(INFO) << "anakin compute[" << i << "] passed";
+
+            // LOG(INFO) << "inputs[]:dims: " << inputs[0]->dims();
+            // LOG(INFO) << "inputs:size: " << inputs.size();
+            // LOG(INFO) << "inputs:capacity: " << inputs.capacity();
+            // LOG(INFO) << "output:size: " << outputs.size();
+            // LOG(INFO) << "OC, MB, IC: " << OC << " "<< MB << " " << IC;
+        }
+
+        if (bias) {
+            #pragma omp parallel for schedule(static)
+            for (cblas_int mb = 0; mb < MB; mb++) {
+                cblas_saxpy(OC, 1.0, bias, 1.0, dst + mb * OC, 1);
+            }
+        }
+    } else {
+        LOG(ERROR) << "non fp32 fc is not implemented yet";
+        return SaberUnImplError;
+    }
+
+    return SaberSuccess;
+}
+
+} // namespace saber
+} // namespace anakin
diff --git a/saber/funcs/impl/x86/vender_fc.h b/saber/funcs/impl/x86/vender_fc.h
index 2c6d5f5..38afddd 100644
--- a/saber/funcs/impl/x86/vender_fc.h
+++ b/saber/funcs/impl/x86/vender_fc.h
@@ -1,66 +1,90 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-   http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. */
-
-#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_SABER_VENDER_FC_H
-#define ANAKIN_SABER_FUNCS_IMPL_X86_SABER_VENDER_FC_H
-
-#include "saber/funcs/impl/impl_fc.h"
-
-namespace anakin{
-namespace saber {
-
-template <DataType OpDtype ,
-        DataType inDtype,
-        DataType outDtype,
-        typename LayOutType_op,
-        typename LayOutType_in,
-        typename LayOutType_out>
-class VenderFc<X86, OpDtype, inDtype, outDtype,
-        LayOutType_op, LayOutType_in, LayOutType_out> : public ImplBase<
-        Tensor<X86, inDtype, LayOutType_in>,
-        Tensor<X86, outDtype, LayOutType_out>,
-        Tensor<X86, OpDtype, LayOutType_op>,
-        FcParam<Tensor<X86, OpDtype, LayOutType_op> > >
-{
-public:
-    typedef Tensor<X86, inDtype, LayOutType_in> DataTensor_in;
-    typedef Tensor<X86, outDtype, LayOutType_out> DataTensor_out;
-    typedef Tensor<X86, OpDtype, LayOutType_op> OpTensor;
-
-    VenderFc() {}
-
-    ~VenderFc() {}
-
-    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
-                             std::vector<DataTensor_out*>& outputs,
-                             FcParam<OpTensor> &param,
-                             Context<X86> &ctx) override;
-
-    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
-                               std::vector<DataTensor_out*>& outputs,
-                               FcParam<OpTensor> &param,
-                               Context<X86> &ctx) override;
-
-    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
-                                 std::vector<DataTensor_out*>& outputs,
-                                 FcParam<OpTensor> &param) override;
-
-private:
-
-};
-
-}
-}
-
-#endif
\ No newline at end of file
+/* Copyright (c) 2018 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_SABER_VENDER_FC_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_SABER_VENDER_FC_H
+
+#include <vector>
+
+#include "mkl_cblas.h"
+#include "saber/funcs/impl/impl_fc.h"
+
+namespace anakin {
+namespace saber {
+
+template <DataType OpDtype ,
+        DataType inDtype,
+        DataType outDtype,
+        typename LayOutType_op,
+        typename LayOutType_in,
+        typename LayOutType_out>
+class VenderFc<X86, OpDtype, inDtype, outDtype,
+        LayOutType_op, LayOutType_in, LayOutType_out> : public ImplBase<
+        Tensor<X86, inDtype, LayOutType_in>,
+        Tensor<X86, outDtype, LayOutType_out>,
+        Tensor<X86, OpDtype, LayOutType_op>,
+        FcParam<Tensor<X86, OpDtype, LayOutType_op> > > {
+public:
+    typedef Tensor<X86, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<X86, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<X86, OpDtype, LayOutType_op> OpTensor;
+    typedef typename DataTensor_in::Dtype DataType_in;
+    typedef typename DataTensor_out::Dtype DataType_out;
+    typedef typename OpTensor::Dtype DataType_op;
+
+    VenderFc() : bias_sum(nullptr)
+    {}
+
+    ~VenderFc() {
+        if (bias_sum) {
+            free(bias_sum);
+            bias_sum = nullptr;
+        }
+
+        for (int i = packed_weights.size() - 1; i >= 0; i--) {
+           DataType_op *pw = packed_weights[i];
+           cblas_sgemm_free(pw);
+           pw = nullptr;
+           packed_weights.pop_back();
+        }
+        std::vector<DataType_op*> ().swap(packed_weights);
+    }
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             FcParam<OpTensor> &param,
+                             Context<X86> &ctx) override;
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
+                               std::vector<DataTensor_out*>& outputs,
+                               FcParam<OpTensor> &param,
+                               Context<X86> &ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                 std::vector<DataTensor_out*>& outputs,
+                                 FcParam<OpTensor> &param) override;
+
+private:
+    DataType_op *bias_sum;
+    int MB;
+    int OC;
+    std::vector<DataType_op*> packed_weights;
+};
+
+
+} // namespace saber
+} // namespace anakin
+
+#endif // ANAKIN_SABER_FUNCS_IMPL_X86_SABER_VENDER_FC_H
diff --git a/saber/funcs/impl/x86/vender_gru.cpp b/saber/funcs/impl/x86/vender_gru.cpp
new file mode 100644
index 0000000..ad1bdea
--- /dev/null
+++ b/saber/funcs/impl/x86/vender_gru.cpp
@@ -0,0 +1,430 @@
+#include "mkl_cblas.h"
+#include "mkl_vml_functions.h"
+
+#include "saber/funcs/impl/x86/vender_gru.h"
+#include "sequence2batch.h"
+#include "saber/funcs/impl/x86/activation_functions.h"
+#include "saber/funcs/impl/x86/x86_utils.h"
+#include "saber/funcs/impl/x86/kernel/jit_generator.h"
+
+namespace anakin {
+namespace saber {
+
+template <DataType OpDtype,
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+SaberStatus VenderGru<X86, OpDtype, inDtype, outDtype,
+            LayOutType_op, LayOutType_in, LayOutType_out>::init(
+                const std::vector<DataTensor_in*>& inputs,
+                std::vector<DataTensor_out*>& outputs,
+GruParam<OpTensor>& param, Context<X86>& ctx) {
+    this->_ctx = &ctx;
+    this->max_thread_num_ = omp_get_max_threads();
+    hidden_size_ = outputs[0]->channel();
+    word_size_ = inputs[0]->channel();
+
+    int aligned_size = 8;
+    aligned_hidden_size_ = (hidden_size_ % aligned_size) ? ((hidden_size_ / aligned_size) + 1) *
+                           aligned_size : hidden_size_;
+
+    avx2_available_ = jit::mayiuse(jit::avx2);
+    // LOG(ERROR) << "AVX2 available: " << avx2_available_;
+
+    if (param.formula == GRU_ORIGIN) {
+        OpDataType* weights_data = const_cast<float*>(param.weight()->data());
+
+        OpDataType* wx = weights_data;
+        OpDataType* wch = wx + word_size_ * hidden_size_ * 3;
+        OpDataType* wh = wch + hidden_size_ * hidden_size_;
+
+        OpDataType* aligned_wx = nullptr;
+        OpDataType* aligned_wch = nullptr;
+        OpDataType* aligned_wh = nullptr;
+
+        int delta = aligned_hidden_size_ - hidden_size_;
+
+
+        if (aligned_bias_ == nullptr) {
+            aligned_bias_ = (OpDataType*)zmalloc(3 * aligned_hidden_size_ * sizeof(float), 4096);
+            const OpDataType* bias_data = param.bias()->data();
+
+            for (int i = 0; i < 3; i++) {
+                memcpy(aligned_bias_ + i * aligned_hidden_size_, bias_data + i * hidden_size_,
+                       hidden_size_ * sizeof(float));
+
+                if (delta > 0) {
+                    memset(aligned_bias_ + i * aligned_hidden_size_ + hidden_size_, 0, delta * sizeof(float));
+                }
+            }
+        } else {
+            LOG(ERROR) << "aligned bias in init should not be a non-nullptr";
+        }
+
+
+        if (delta > 0) {
+            aligned_wx = (OpDataType*)zmalloc(word_size_ * aligned_hidden_size_ * 3 * sizeof(float), 4096);
+            aligned_wch = (OpDataType*)zmalloc(aligned_hidden_size_ * aligned_hidden_size_ * sizeof(float),
+                                               4096);
+            aligned_wh = (OpDataType*)zmalloc(2 * aligned_hidden_size_ * aligned_hidden_size_ * sizeof(float),
+                                              4096);
+
+            for (int i = 0; i < word_size_; i++) {
+                float* aligned_row = aligned_wx + i * aligned_hidden_size_ * 3;
+                float* row = wx + i * hidden_size_ * 3;
+
+                for (int j = 0; j < 3; j++) {
+                    memcpy(aligned_row + j * aligned_hidden_size_, row + j * hidden_size_,
+                           hidden_size_ * sizeof(float));
+                    memset(aligned_row + j * aligned_hidden_size_ + hidden_size_, 0, delta * sizeof(float));
+                }
+            }
+
+            for (int i = 0; i < aligned_hidden_size_; i++) {
+                float* aligned_row = aligned_wch + i * aligned_hidden_size_;
+                float* row = wch + i * hidden_size_;
+
+                if (i < hidden_size_) {
+                    memcpy(aligned_row, row, hidden_size_ * sizeof(float));
+                    memset(aligned_row + hidden_size_, 0, delta * sizeof(float));
+                } else {
+                    memset(aligned_row, 0, aligned_hidden_size_ * sizeof(float));
+                }
+            }
+
+            for (int i = 0; i < aligned_hidden_size_; i++) {
+                float* aligned_row = aligned_wh + i * aligned_hidden_size_ * 2;
+                float* row = wh + i * hidden_size_ * 2;
+
+                if (i < hidden_size_) {
+                    for (int j = 0; j < 2; j++) {
+                        memcpy(aligned_row + j * aligned_hidden_size_, row + j * hidden_size_,
+                               hidden_size_ * sizeof(float));
+                        memset(aligned_row + j * aligned_hidden_size_ + hidden_size_, 0, delta * sizeof(float));
+                    }
+                } else {
+                    memset(aligned_row, 0, 2 * aligned_hidden_size_ * sizeof(float));
+                }
+            }
+        } else {
+            aligned_wx = wx;
+            aligned_wch = wch;
+            aligned_wh = wh;
+        }
+
+        if (weight_x_packed_) {
+            cblas_sgemm_free(weight_x_packed_);
+            weight_x_packed_ = nullptr;
+        }
+
+        if (weight_ru_packed_) {
+            cblas_sgemm_free(weight_ru_packed_);
+            weight_ru_packed_ = nullptr;
+        }
+
+        if (weight_c_packed_) {
+            cblas_sgemm_free(weight_c_packed_);
+            weight_c_packed_ = nullptr;
+        }
+
+        weight_x_packed_ = cblas_sgemm_alloc(CblasBMatrix, inputs[0]->num(), 3 * aligned_hidden_size_,
+                                             word_size_);
+
+        if (!weight_x_packed_) {
+            LOG(ERROR) << "cannot alloc weight_x_packed_ for gru";
+            return SaberOutOfMem;
+        }
+
+        cblas_sgemm_pack(CblasRowMajor, CblasBMatrix, CblasNoTrans, inputs[0]->num(),
+                         3 * aligned_hidden_size_, word_size_, 1.0,
+                         aligned_wx, 3 * aligned_hidden_size_, weight_x_packed_);
+
+        weight_ru_packed_ = cblas_sgemm_alloc(CblasBMatrix, 1, 2 * aligned_hidden_size_,
+                                              aligned_hidden_size_);
+
+        if (!weight_ru_packed_) {
+            LOG(ERROR) << "cannot alloc weight_ru_packed_ for gru";
+            return SaberOutOfMem;
+        }
+
+        cblas_sgemm_pack(CblasRowMajor, CblasBMatrix, CblasNoTrans, 1, 2 * aligned_hidden_size_,
+                         aligned_hidden_size_, 1.0,
+                         aligned_wh, 2 * aligned_hidden_size_, weight_ru_packed_);
+
+        weight_c_packed_ = cblas_sgemm_alloc(CblasBMatrix, 1, aligned_hidden_size_, aligned_hidden_size_);
+
+        if (!weight_c_packed_) {
+            LOG(ERROR) << "cannot alloc weight_c_packed_ for gru";
+            return SaberOutOfMem;
+        }
+
+        cblas_sgemm_pack(CblasRowMajor, CblasBMatrix, CblasNoTrans, 1, aligned_hidden_size_,
+                         aligned_hidden_size_, 1.0,
+                         aligned_wch, aligned_hidden_size_, weight_c_packed_);
+
+        if (delta > 0) {
+            zfree(aligned_wx);
+            wx = nullptr;
+            zfree(aligned_wh);
+            wh = nullptr;
+            zfree(aligned_wch);
+            wch = nullptr;
+        }
+    } else {
+        LOG(ERROR) << "only support GRU_ORIGIN now";
+        return SaberUnImplError;
+    }
+
+    return create(inputs, outputs, param, ctx);
+}
+
+template <DataType OpDtype,
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+SaberStatus VenderGru<X86, OpDtype, inDtype, outDtype,
+            LayOutType_op, LayOutType_in, LayOutType_out>::create(
+                const std::vector<DataTensor_in*>& inputs,
+                std::vector<DataTensor_out*>& outputs,
+                GruParam<OpTensor>& param,
+Context<X86>& ctx) {
+    batched_h.try_expand_size(inputs[0]->num() * aligned_hidden_size_ * param.num_direction);
+    batched_x.try_expand_size(inputs[0]->num() * word_size_);
+    batched_xx.try_expand_size(inputs[0]->num() * 3 * aligned_hidden_size_);
+
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+SaberStatus VenderGru<X86, OpDtype, inDtype, outDtype,
+            LayOutType_op, LayOutType_in, LayOutType_out>::dispatch(
+                const std::vector<DataTensor_in*>& inputs,
+                std::vector<DataTensor_out*>& outputs,
+GruParam<OpTensor>& param) {
+
+    const OpDataType* bias = param.bias()->data();
+    std::vector<int> seq_offset = inputs[0]->get_seq_offset();
+    int word_sum = inputs[0]->num();
+    const InDataType* x = inputs[0]->data();
+    OutDataType* out = outputs[0]->mutable_data();
+    bool is_reverse = param.is_reverse;
+    int batch_size = seq_offset.size() - 1;
+
+    batched_h.try_expand_size(inputs[0]->num() * aligned_hidden_size_ * param.num_direction);
+    OutDataType* batched_h_data = batched_h.mutable_data();
+    batched_x.try_expand_size(inputs[0]->num() * word_size_);
+    batched_xx.try_expand_size(inputs[0]->num() * 3 * aligned_hidden_size_);
+    InDataType* batched_xx_data = batched_xx.mutable_data();
+
+    // input sequence to batch
+    math::SequenceToBatch batch_value;
+    batch_value.create_batch(word_sum, batch_size, seq_offset, is_reverse);
+
+    int bat_length = batch_value.get_batch_num();
+    std::vector<int> bat_offset(bat_length + 1);
+    batch_value.get_batch_offset(bat_offset);
+    batch_value.seq_2_bat(x, batched_x.mutable_data(), word_size_);
+
+    int delta = aligned_hidden_size_ - hidden_size_;
+
+    // init h
+    Shape h_init_shape(batch_size, aligned_hidden_size_, 1, 1);
+    aligned_init_hidden.try_expand_size(h_init_shape);
+    const OutDataType* h0 = nullptr;
+
+    if (param.init_hidden() != nullptr) {
+        CHECK_EQ(param.init_hidden()->valid_shape().count(),
+                 batch_size * hidden_size_) << "hidden init must match batch size";
+        h0 = param.init_hidden()->data();
+        OpTensor h_init_tmp(h_init_shape);
+        float* aligned_init = h_init_tmp.mutable_data();
+        int delta = aligned_hidden_size_ - hidden_size_;
+
+        if (delta > 0) {
+            for (int i = 0; i < batch_size; i++) {
+                float* aligned_row = aligned_init + i * aligned_hidden_size_;
+                const float* row = h0 + i * hidden_size_;
+                memcpy(aligned_row, row, hidden_size_ * sizeof(float));
+                memset(aligned_row + hidden_size_, 0, delta * sizeof(float));
+            }
+
+            batch_value.hidden_2_bat(h_init_tmp.data(), aligned_init_hidden.mutable_data(),
+                                     aligned_hidden_size_);
+            h0 = aligned_init_hidden.data();
+        } else {
+            batch_value.hidden_2_bat(h0, aligned_init_hidden.mutable_data(), aligned_hidden_size_);
+            h0 = aligned_init_hidden.data();
+        }
+    } else {
+        fill_tensor_host_const(aligned_init_hidden, 0);
+        h0 = aligned_init_hidden.data();
+    }
+
+    // batched_xx = batched_x * [Wcx, Wrx, Wux]
+    cblas_sgemm_compute(CblasRowMajor,
+                        CblasNoTrans,
+                        CblasPacked,
+                        word_sum,
+                        3 * aligned_hidden_size_,
+                        word_size_,
+                        batched_x.data(),
+                        word_size_,
+                        weight_x_packed_,
+                        3 * aligned_hidden_size_,
+                        0.f,
+                        batched_xx_data,
+                        3 * aligned_hidden_size_);
+
+    // batched_xx += bias
+    int xx_num = inputs[0]->num();
+    int hidden_stride = 3 * aligned_hidden_size_;
+    #pragma omp parallel for if(this->max_thread_num_ > 1)
+
+    for (int i = 0; i < xx_num; i++) {
+        cblas_saxpy(hidden_stride, 1, aligned_bias_, 1, batched_xx_data + i * hidden_stride, 1);
+    }
+
+    int c_offset = 0;
+    int r_offset = 1;
+    int u_offset = 2;
+
+    for (int word_id = 0; word_id < bat_length; word_id++) {
+        int bat_word_id_start = bat_offset[word_id];
+        int bat_word_id_end = bat_offset[word_id + 1];
+        int bat_word_length = bat_word_id_end - bat_word_id_start;
+        const float* ht_1;
+
+        if (word_id == 0) {
+            ht_1 = h0;
+        } else {
+            ht_1 = batched_h_data + bat_offset[word_id - 1] * aligned_hidden_size_;
+        }
+
+        float* ht = batched_h_data + bat_offset[word_id] * aligned_hidden_size_;
+
+        // xx = xx + ht_1 * Wh
+        cblas_sgemm_compute(CblasRowMajor,
+                            CblasNoTrans,
+                            CblasPacked,
+                            bat_word_length,
+                            2 * aligned_hidden_size_,
+                            aligned_hidden_size_,
+                            ht_1,
+                            aligned_hidden_size_,
+                            weight_ru_packed_,
+                            2 * aligned_hidden_size_,
+                            1.f,
+                            batched_xx_data + bat_word_id_start * hidden_stride + r_offset * aligned_hidden_size_,
+                            hidden_stride);
+
+        // compute reset gate output r and rh
+        if (avx2_available_) {
+            for (int bat_word_id = bat_word_id_start; bat_word_id < bat_word_id_end; bat_word_id++) {
+                int intra_bat_offset = bat_word_id - bat_word_id_start;
+                __m256* r = (__m256*)(batched_xx_data + bat_word_id * hidden_stride + r_offset *
+                                      aligned_hidden_size_);
+                __m256* hit = (__m256*)(ht + intra_bat_offset * aligned_hidden_size_);
+                __m256* hit_1 = (__m256*)(ht_1 + intra_bat_offset * aligned_hidden_size_);
+
+                for (int i = 0; i < aligned_hidden_size_ / 8; ++i) {
+                    r[i] = math::avx_activation(r[i], param.gate_activity);
+                    hit[i] = r[i] * hit_1[i];
+                }
+            }
+        } else {
+            for (int bat_word_id = bat_word_id_start; bat_word_id < bat_word_id_end; bat_word_id++) {
+                int intra_bat_offset = bat_word_id - bat_word_id_start;
+                float* r = (float*)(batched_xx_data + bat_word_id * hidden_stride + r_offset *
+                                    aligned_hidden_size_);
+                float* hit = (float*)(ht + intra_bat_offset * aligned_hidden_size_);
+                float* hit_1 = (float*)(ht_1 + intra_bat_offset * aligned_hidden_size_);
+
+                for (int i = 0; i < aligned_hidden_size_; ++i) {
+                    math::activation(1, r + i, r + i, param.gate_activity);
+                    hit[i] = r[i] * hit_1[i];
+                }
+            }
+        }
+
+        // xx = xx + rh * Wch
+        cblas_sgemm_compute(CblasRowMajor,
+                            CblasNoTrans,
+                            CblasPacked,
+                            bat_word_length,
+                            aligned_hidden_size_,
+                            aligned_hidden_size_,
+                            ht,
+                            aligned_hidden_size_,
+                            weight_c_packed_,
+                            aligned_hidden_size_,
+                            1.f,
+                            batched_xx_data + bat_word_id_start * hidden_stride + c_offset * aligned_hidden_size_,
+                            hidden_stride);
+
+        // compute candidate activation output and h
+        if (avx2_available_) {
+            for (int bat_word_id = bat_word_id_start; bat_word_id < bat_word_id_end; bat_word_id++) {
+                int intra_bat_offset = bat_word_id - bat_word_id_start;
+                int h_word_id_offset = bat_word_id * hidden_stride;
+                __m256* u = (__m256*)(batched_xx_data + h_word_id_offset + u_offset * aligned_hidden_size_);
+                __m256* c = (__m256*)(batched_xx_data + h_word_id_offset + c_offset * aligned_hidden_size_);
+                __m256* hit = (__m256*)(ht + intra_bat_offset * aligned_hidden_size_);
+                __m256* hit_1 = (__m256*)(ht_1 + intra_bat_offset * aligned_hidden_size_);
+
+                for (int i = 0; i < aligned_hidden_size_ / 8; ++i) {
+                    u[i] = math::avx_activation(u[i], param.gate_activity);
+                    c[i] = math::avx_activation(c[i], param.h_activity);
+                    hit[i] = (c[i] - hit_1[i]) * u[i] + hit_1[i];
+                }
+            }
+        } else {
+            for (int bat_word_id = bat_word_id_start; bat_word_id < bat_word_id_end; bat_word_id++) {
+                int intra_bat_offset = bat_word_id - bat_word_id_start;
+                int h_word_id_offset = bat_word_id * hidden_stride;
+                float* u = (float*)(batched_xx_data + h_word_id_offset + u_offset * aligned_hidden_size_);
+                float* c = (float*)(batched_xx_data + h_word_id_offset + c_offset * aligned_hidden_size_);
+                float* hit = (float*)(ht + intra_bat_offset * aligned_hidden_size_);
+                float* hit_1 = (float*)(ht_1 + intra_bat_offset * aligned_hidden_size_);
+
+                for (int i = 0; i < aligned_hidden_size_; ++i) {
+                    math::activation(1, u + i, u + i, param.gate_activity);
+                    math::activation(1, c + i, c + i, param.h_activity);
+                    hit[i] = (c[i] - hit_1[i]) * u[i] + hit_1[i];
+                }
+            }
+        }
+    }
+
+    // batch to sequence
+    batch_value.bat_2_seq(batched_h_data, out, hidden_size_, aligned_hidden_size_);
+
+    return SaberSuccess;
+}
+
+template <DataType OpDtype,
+          DataType inDtype,
+          DataType outDtype,
+          typename LayOutType_op,
+          typename LayOutType_in,
+          typename LayOutType_out>
+SaberStatus VenderGru<X86, OpDtype, inDtype, outDtype,
+            LayOutType_op, LayOutType_in, LayOutType_out>::check_conf(
+                const std::vector<DataTensor_in*>& inputs,
+                std::vector<DataTensor_out*>& outputs,
+GruParam<OpTensor>& param) {
+    return SaberSuccess;
+}
+
+template class VenderGru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW>;
+
+} // namespace saber
+} // namespace anakin
diff --git a/saber/funcs/impl/x86/vender_gru.h b/saber/funcs/impl/x86/vender_gru.h
new file mode 100644
index 0000000..fb415ad
--- /dev/null
+++ b/saber/funcs/impl/x86/vender_gru.h
@@ -0,0 +1,122 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN_SABER_FUNCS_IMPL_X86_VENDER_GRU_H
+#define ANAKIN_SABER_FUNCS_IMPL_X86_VENDER_GRU_H
+
+#include "saber/saber_types.h"
+#include "saber/funcs/impl/impl_base.h"
+#include "saber/funcs/impl/impl_gru.h"
+#include "saber/saber_funcs_param.h"
+#include "saber/core/tensor_op.h"
+#include "saber/funcs/impl/x86/x86_utils.h"
+
+
+#include <mkl_cblas.h>
+#include <mkl_lapacke.h>
+
+namespace anakin {
+namespace saber {
+
+template<DataType OpDtype,
+         DataType inDtype,
+         DataType outDtype,
+         typename LayOutType_op,
+         typename LayOutType_in,
+         typename LayOutType_out>
+
+class VenderGru<X86, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out> :
+    public ImplBase <
+    Tensor<X86, inDtype, LayOutType_in>,
+    Tensor<X86, outDtype, LayOutType_out>,
+    Tensor<X86, OpDtype, LayOutType_op>,
+    GruParam<Tensor<X86, OpDtype, LayOutType_op> >> {
+public:
+    typedef Tensor<X86, inDtype, LayOutType_in> DataTensor_in;
+    typedef Tensor<X86, outDtype, LayOutType_out> DataTensor_out;
+    typedef Tensor<X86, OpDtype, LayOutType_op> OpTensor;
+
+    typedef typename DataTensor_in::Dtype InDataType;
+    typedef typename DataTensor_out::Dtype OutDataType;
+    typedef typename OpTensor::Dtype OpDataType;
+
+    VenderGru() : avx2_available_(false), aligned_bias_(nullptr),
+                  max_thread_num_(1),
+        weight_x_packed_(nullptr),
+        weight_ru_packed_(nullptr),
+        weight_c_packed_(nullptr) {
+        LOG(INFO)<<"init vender gru";
+    }
+
+    ~VenderGru() {
+        if (this->weight_x_packed_) {
+            cblas_sgemm_free(this->weight_x_packed_);
+            this->weight_x_packed_ = nullptr;
+        }
+
+        if (this->weight_ru_packed_) {
+            cblas_sgemm_free(this->weight_ru_packed_);
+            this->weight_ru_packed_ = nullptr;
+        }
+
+        if (this->weight_c_packed_) {
+            cblas_sgemm_free(this->weight_c_packed_);
+            this->weight_c_packed_ = nullptr;
+        }
+
+        if (this->aligned_bias_) {
+            zfree(this->aligned_bias_);
+            this->aligned_bias_ = nullptr;
+        }
+    }
+
+    virtual SaberStatus init(const std::vector<DataTensor_in*>& inputs,
+                             std::vector<DataTensor_out*>& outputs,
+                             GruParam<OpTensor>& gru_param,
+                             Context<X86>& ctx) override;
+
+    virtual SaberStatus create(const std::vector<DataTensor_in*>& inputs,
+                               std::vector<DataTensor_out*>& outputs,
+                               GruParam<OpTensor>& gru_param,
+                               Context<X86>& ctx) override;
+
+    virtual SaberStatus dispatch(const std::vector<DataTensor_in*>& inputs,
+                                 std::vector<DataTensor_out*>& outputs,
+                                 GruParam<OpTensor>& param) override;
+
+private:
+    bool avx2_available_;
+    int max_thread_num_;
+    int word_size_;
+    int hidden_size_;
+    int aligned_hidden_size_;
+
+    float* aligned_bias_;
+    OpTensor aligned_init_hidden;
+
+    OpDataType* weight_x_packed_ = nullptr;
+    OpDataType* weight_ru_packed_ = nullptr;
+    OpDataType* weight_c_packed_ = nullptr;
+    DataTensor_out batched_h;
+    DataTensor_in batched_x;
+    DataTensor_out batched_xx;
+
+    SaberStatus check_conf(const std::vector<DataTensor_in*>& inputs,
+                           std::vector<DataTensor_out*>& outputs,
+                           GruParam<OpTensor>& param);
+};
+
+} // namespace saber
+} // namespace anakin
+#endif // ANAKIN_SABER_FUNCS_IMPL_X86_VENDER_GRU_H
diff --git a/saber/funcs/impl/x86/x86_utils.h b/saber/funcs/impl/x86/x86_utils.h
index fbb0285..ef432a9 100644
--- a/saber/funcs/impl/x86/x86_utils.h
+++ b/saber/funcs/impl/x86/x86_utils.h
@@ -597,7 +597,7 @@ inline void yield_thread() { }
 // reorder weight layout from NCHW(oc, ic, kh, kw) to OIhw16i16o
 inline void weight_reorder_OIhw16i16o(Tensor<X86, AK_FLOAT, NCHW>& input,
                                       Tensor<X86, AK_FLOAT, NCHW>& output) {
-    Shape shape = input.shape();
+    Shape shape = input.valid_shape();
     int oc_value = shape[0], ic_value = shape[1], kh_value = shape[2], kw_value = shape[3];
     #pragma omp parallel for collapse(6) schedule(static)
 
diff --git a/saber/funcs/layer_norm.h b/saber/funcs/layer_norm.h
index fb6261b..2acdd71 100644
--- a/saber/funcs/layer_norm.h
+++ b/saber/funcs/layer_norm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/funcs/lrn.h b/saber/funcs/lrn.h
index 3b29ac2..362a472 100644
--- a/saber/funcs/lrn.h
+++ b/saber/funcs/lrn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_lrn.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_lrn.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/lstm.h b/saber/funcs/lstm.h
new file mode 100644
index 0000000..ea45db5
--- /dev/null
+++ b/saber/funcs/lstm.h
@@ -0,0 +1,127 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_LSTM_H
+#define ANAKIN_SABER_FUNCS_LSTM_H
+
+#include "saber/funcs/base.h"
+#include "saber/funcs/impl/impl_base.h"
+#ifdef NVIDIA_GPU
+#include "saber/funcs/impl/cuda/saber_lstm.h"
+//#include "saber/funcs/impl/cuda/vender_lstm.h"
+#endif
+
+#ifdef USE_X86_PLACE
+#include "saber/funcs/impl/x86/saber_lstm.h"
+#endif
+
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/impl_lstm.h"
+#endif
+
+namespace anakin {
+namespace saber {
+
+template<typename TargetType,
+         DataType OpDtype,
+         DataType inDtype = AK_FLOAT,
+         DataType outDtype = AK_FLOAT,
+         typename LayOutType_op = NCHW,
+         typename LayOutType_in = NCHW,
+         typename LayOutType_out = NCHW
+         >
+class Lstm : public BaseFunc <
+    Tensor<TargetType, inDtype, LayOutType_in>,
+    Tensor<TargetType, outDtype, LayOutType_out>,
+    Tensor<TargetType, OpDtype, LayOutType_op>,
+    ImplBase,
+    LstmParam
+    > {
+public:
+    using BaseFunc <
+    Tensor<TargetType, inDtype, LayOutType_in>,
+           Tensor<TargetType, outDtype, LayOutType_out>,
+           Tensor<TargetType, OpDtype, LayOutType_op>,
+           ImplBase,
+           LstmParam >::BaseFunc;
+
+    Lstm() = default;
+
+    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
+    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
+    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
+    typedef LstmParam<OpTensor> Param_t;
+    typedef std::vector<InDataTensor*> Input_v;
+    typedef std::vector<OutDataTensor*> Output_v;
+    typedef std::vector<Shape> Shape_v;
+
+    // TODO:calc output shape
+    virtual SaberStatus compute_output_shape(const Input_v& input, Output_v& output, \
+            Param_t& param) override {
+        int seqLength = input[0]->num();
+        int hiddenSize=0;
+        if(param.with_peephole){
+            hiddenSize=param.bias()->valid_size()/7;
+        } else{
+            hiddenSize=param.bias()->valid_size()/4;
+        }
+
+        Shape output_shape = Shape(seqLength, hiddenSize, param.num_direction, 1);
+        output[0]->set_seq_offset(input[0]->get_seq_offset());
+        if(output.size()>=2){
+            output[1]->set_seq_offset(input[0]->get_seq_offset());
+        }
+        return output[0]->set_shape(output_shape);
+    }
+
+    virtual SaberStatus init_impl(ImplEnum implenum) override {
+        switch (implenum) {
+            case SABER_IMPL:
+                this->_impl.push_back(new SaberLstm<TargetType, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>);
+                return SaberSuccess;
+            case VENDER_IMPL:
+                this->_impl.push_back(new VenderLstm<TargetType, OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>);
+                return SaberSuccess;
+            default:
+                return SaberUnImplError;
+        }
+    }
+
+private:
+
+    virtual void pick_best_static() override {
+        //! lstm only has vendor implementation
+        this->_best_impl = this->_impl[0];
+    }
+
+    virtual void pick_best_runtime(Input_v input, Output_v output, \
+                                   Param_t& param, Context<TargetType>& ctx) override {
+        //! lstm only has vendor implementation
+        this->_best_impl = this->_impl[0];
+    }
+
+    virtual void pick_best_specify(ImplEnum implenum) override {
+        //! lstm only has vendor implementation
+        this->_best_impl = this->_impl[0];
+    }
+
+};
+
+} // namespace saber
+} // namepace anakin
+
+
+#endif // ANAKIN_SABER_FUNCS_LSTM_H
+
diff --git a/saber/funcs/mat_mul.h b/saber/funcs/mat_mul.h
index e5ec842..24e0119 100644
--- a/saber/funcs/mat_mul.h
+++ b/saber/funcs/mat_mul.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -90,10 +90,10 @@ public:
         }
         CHECK_EQ(K0, K1);
 
-        param._B = input[0]->num() * input[0]->channel();
-        param._M = M;
-        param._N = N;
-        param._K = K0;
+        param._b = input[0]->num() * input[0]->channel();
+        param._m = M;
+        param._n = N;
+        param._k = K0;
         return output[0]->set_shape({input[0]->num(), input[0]->channel(), M, N});
     }
 
diff --git a/saber/funcs/multiclass_nms.h b/saber/funcs/multiclass_nms.h
deleted file mode 100644
index 98f22ed..0000000
--- a/saber/funcs/multiclass_nms.h
+++ /dev/null
@@ -1,123 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_MULTICLASS_NMS_H
-#define ANAKIN_SABER_FUNCS_MULTICLASS_NMS_H
-
-#include "saber/funcs/base.h"
-#include "saber/funcs/impl/impl_base.h"
-#ifdef NVIDIA_GPU
-#include "saber/funcs/impl/cuda/saber_multiclass_nms.h"
-#endif
-
-#ifdef USE_X86_PLACE
-#include "saber/funcs/impl/impl_multiclass_nms.h"
-#endif
-
-namespace anakin{
-
-namespace saber{
-
-template<typename TargetType,
-        DataType OpDtype,
-        DataType inDtype = AK_FLOAT,
-        DataType outDtype = AK_FLOAT,
-        typename LayOutType_op = NHW,
-        typename LayOutType_in = NHW,
-        typename LayOutType_out = NW
->
-class MultiClassNMS : public BaseFunc<
-        Tensor<TargetType, inDtype, LayOutType_in>,
-        Tensor<TargetType, outDtype, LayOutType_out>,
-        Tensor<TargetType, OpDtype, LayOutType_op>,
-        ImplBase,
-        MultiClassNMSParam
-> {
-public:
-    using BaseFunc<
-            Tensor<TargetType, inDtype, LayOutType_in>,
-            Tensor<TargetType, outDtype, LayOutType_out>,
-            Tensor<TargetType, OpDtype, LayOutType_op>,
-            ImplBase,
-            MultiClassNMSParam>::BaseFunc;
-
-    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
-    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
-    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
-    typedef MultiClassNMSParam<OpTensor> Param_t;
-    typedef std::vector<InDataTensor *> Input_v;
-    typedef std::vector<OutDataTensor *> Output_v;
-    typedef std::vector<Shape> Shape_v;
-
-    MultiClassNMS() = default;
-
-    virtual SaberStatus compute_output_shape(const Input_v& input, Output_v& output, \
-        Param_t& param) override {
-        //! inputs[0]: bbox map, dims = 3 {N, boxes, 4(xmin, ymin, xmax, ymax)}
-        //! inputs[1]: score map, dims = 3 {N, classes, boxes}
-        //! output[0]: output detection result, dims = 2 {No., 6}
-        Shape sh1 = input[0]->valid_shape();
-        Shape sh2 = input[1]->valid_shape();
-        CHECK_EQ(sh1.dims(), 3) << "only support 3d (NHW) layout";
-        Shape shape_out = output[0]->valid_shape();
-        CHECK_EQ(shape_out.dims(), 2) << "only support 2d(NW) layout";
-        int boxes = sh1[1];
-        shape_out[0] = 1;
-        shape_out[1] = 7;
-        return output[0]->set_shape(shape_out);
-    }
-
-    virtual SaberStatus init_impl(ImplEnum implenum) override {
-        switch (implenum) {
-            case VENDER_IMPL:
-                this->_impl.push_back(new VenderMultiClassNMS <TargetType, OpDtype, inDtype, outDtype,
-                LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            case SABER_IMPL:
-                this->_impl.push_back(new SaberMultiClassNMS <TargetType, OpDtype, inDtype, outDtype,
-                LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            default:
-                return SaberUnImplError;            
-        }
-    }
-
-private:
-
-    virtual void pick_best_static() override {
-        //! Fc only has saber implementation
-        this->_best_impl = this->_impl[0];
-    }
-
-    virtual void pick_best_runtime(Input_v input, Output_v output, \
-        Param_t& param, Context<TargetType> &ctx) override {
-        //! Fc only has saber implementation
-        this->_best_impl = this->_impl[0];
-    }
-
-    virtual void pick_best_specify(ImplEnum implenum) override {
-        //! Fc only has saber implementation
-        this->_best_impl = this->_impl[0];
-    }
-
-};
-
-} //namespace saber
-
-} //namespace anakin
-
-#endif //ANAKIN_SABER_FUNCS_MULTICLASS_NMS_H
diff --git a/saber/funcs/mvn.h b/saber/funcs/mvn.h
index b85f9f3..37222ce 100644
--- a/saber/funcs/mvn.h
+++ b/saber/funcs/mvn.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_mvn.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_mvn.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/normalize.h b/saber/funcs/normalize.h
index 5ece04b..3246414 100644
--- a/saber/funcs/normalize.h
+++ b/saber/funcs/normalize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_normalize.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_normalize.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/pad.h b/saber/funcs/pad.h
index cd64eb8..2a35a54 100644
--- a/saber/funcs/pad.h
+++ b/saber/funcs/pad.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_pad.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_pad.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/permute.h b/saber/funcs/permute.h
index 0e36191..617ac1e 100644
--- a/saber/funcs/permute.h
+++ b/saber/funcs/permute.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_permute.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_permute.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/permute_power.h b/saber/funcs/permute_power.h
index 04116e2..c3e61f9 100644
--- a/saber/funcs/permute_power.h
+++ b/saber/funcs/permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,7 +26,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_permute_power.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_permute_power.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/pooling.h b/saber/funcs/pooling.h
index 09ab802..b5f83ac 100644
--- a/saber/funcs/pooling.h
+++ b/saber/funcs/pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,7 +26,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_pooling.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_pooling.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/pooling_with_index.h b/saber/funcs/pooling_with_index.h
index f2fc943..a95bbc4 100644
--- a/saber/funcs/pooling_with_index.h
+++ b/saber/funcs/pooling_with_index.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_pooling_with_index.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_pooling_with_index.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/power.h b/saber/funcs/power.h
index e9773b4..adb2a1c 100644
--- a/saber/funcs/power.h
+++ b/saber/funcs/power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_power.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_power.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/prelu.h b/saber/funcs/prelu.h
deleted file mode 100644
index 1d2bde0..0000000
--- a/saber/funcs/prelu.h
+++ /dev/null
@@ -1,117 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_SABER_FUNCS_PRELU_H
-#define ANAKIN_SABER_FUNCS_PRELU_H
-
-#include "saber/funcs/base.h"
-#include "saber/funcs/impl/impl_base.h"
-#ifdef NVIDIA_GPU
-#include "saber/funcs/impl/cuda/saber_prelu.h"
-#endif
-
-#ifdef USE_X86_PLACE
-#include "saber/funcs/impl/impl_prelu.h"
-#endif
-
-namespace anakin{
-
-namespace saber{
-
-template<typename TargetType,
-        DataType OpDtype,
-        DataType inDtype = AK_FLOAT,
-        DataType outDtype = AK_FLOAT,
-        typename LayOutType_op = NCHW,
-        typename LayOutType_in = NCHW,
-        typename LayOutType_out = NCHW
->
-class Prelu : public BaseFunc<
-        Tensor<TargetType, inDtype, LayOutType_in>,
-        Tensor<TargetType, outDtype, LayOutType_out>,
-        Tensor<TargetType, OpDtype, LayOutType_op>,
-        ImplBase,
-        PreluParam
-> {
-public:
-    using BaseFunc<
-            Tensor<TargetType, inDtype, LayOutType_in>,
-            Tensor<TargetType, outDtype, LayOutType_out>,
-            Tensor<TargetType, OpDtype, LayOutType_op>,
-            ImplBase,
-            PreluParam>::BaseFunc;
-
-    Prelu() = default;
-
-    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
-    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
-    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
-    typedef PreluParam<OpTensor> Param_t;
-    typedef std::vector<InDataTensor *> Input_v;
-    typedef std::vector<OutDataTensor *> Output_v;
-    typedef std::vector<Shape> Shape_v;
-
-    virtual SaberStatus compute_output_shape(const Input_v& input, Output_v& output, \
-        Param_t& param) override {
-
-        //! support inplace computation, output shape = input shape
-        Shape output_shape = input[0]->valid_shape();
-        output[0]->set_shape(output_shape);
-        return SaberSuccess;
-    }
-
-    virtual SaberStatus init_impl(ImplEnum implenum) override {
-        switch (implenum) {
-            case VENDER_IMPL:
-                this->_impl.push_back(new VenderPrelu<TargetType, \
-                OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            case SABER_IMPL:
-                this->_impl.push_back(new SaberPrelu<TargetType, \
-                OpDtype, inDtype, outDtype, LayOutType_op, LayOutType_in, LayOutType_out>);
-                return SaberSuccess;
-
-            default:
-                return SaberUnImplError;
-        }
-    }
-
-
-private:
-
-    virtual void pick_best_static() override {
-        //! Prelu only has saber implementation
-        this->_best_impl = this->_impl[0];
-    }
-
-    //virtual void pick_best_runtime(Input_v input, Output_v output, \
-    //    Param_t& param, Context<TargetType> &ctx) override {
-    //    //! Prelu only has saber implementation
-    //    this->_best_impl = this->_impl[0];
-    //}
-
-    virtual void pick_best_specify(ImplEnum implenum) override {
-        //! Prelu only has saber implementation
-        this->_best_impl = this->_impl[0];
-    }
-
-};
-
-} //namespace saber
-
-} //namespace anakin
-
-#endif //ANAKIN_SABER_FUNCS_PRELU_H
diff --git a/saber/funcs/priorbox.h b/saber/funcs/priorbox.h
index cb42a2f..c40afd5 100644
--- a/saber/funcs/priorbox.h
+++ b/saber/funcs/priorbox.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_priorbox.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_priorbox.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/reshape.h b/saber/funcs/reshape.h
index 5dad625..aece095 100644
--- a/saber/funcs/reshape.h
+++ b/saber/funcs/reshape.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -102,7 +102,7 @@ public:
     //Reshape ops do nothing
     virtual SaberStatus operator()(const Input_v& input, Output_v& output, Param_t& param, \
         Context<TargetType> &ctx) {
-
+        return SaberSuccess;
     }
 private:
 
diff --git a/saber/funcs/resize.h b/saber/funcs/resize.h
index 4bbceed..2c1d199 100644
--- a/saber/funcs/resize.h
+++ b/saber/funcs/resize.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_resize.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_resize.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/roi_pooling.h b/saber/funcs/roi_pooling.h
index d4abb8d..97aa728 100644
--- a/saber/funcs/roi_pooling.h
+++ b/saber/funcs/roi_pooling.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_roi_pooling.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_roi_pooling.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/scale.h b/saber/funcs/scale.h
index 1cf9d62..4c3e745 100644
--- a/saber/funcs/scale.h
+++ b/saber/funcs/scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -28,7 +28,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_scale.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_scale.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/sequence_conv.h b/saber/funcs/sequence_conv.h
new file mode 100644
index 0000000..bd6d0e7
--- /dev/null
+++ b/saber/funcs/sequence_conv.h
@@ -0,0 +1,108 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
+#ifndef ANAKIN_SABER_FUNCS_SEQUENCE_CONV_H
+#define ANAKIN_SABER_FUNCS_SEQUENCE_CONV_H
+
+#include "saber/funcs/base.h"
+#include "saber/funcs/impl/impl_base.h"
+#include "saber/saber_funcs_param.h"
+
+#ifdef NVIDIA_GPU
+#endif
+
+#ifdef USE_X86_PLACE
+#include "saber/funcs/impl/x86/saber_sequence_conv.h"
+#endif
+namespace anakin {
+namespace saber {
+
+template<typename TargetType,
+         DataType OpDtype,
+         DataType inDtype = AK_FLOAT,
+         DataType outDtype = AK_FLOAT,
+         typename LayOutType_op = NCHW,
+         typename LayOutType_in = NCHW,
+         typename LayOutType_out = NCHW
+         >
+class SequenceConv : public BaseFunc <
+    Tensor<TargetType, inDtype, LayOutType_in>,
+    Tensor<TargetType, outDtype, LayOutType_out>,
+    Tensor<TargetType, OpDtype, LayOutType_op>,
+    ImplBase,
+    SequenceConvParam
+    > {
+public:
+    using BaseFunc <
+    Tensor<TargetType, inDtype, LayOutType_in>,
+           Tensor<TargetType, outDtype, LayOutType_out>,
+           Tensor<TargetType, OpDtype, LayOutType_op>,
+           ImplBase,
+           SequenceConvParam >::BaseFunc;
+
+    SequenceConv() = default;
+
+    typedef Tensor<TargetType, inDtype, LayOutType_in> InDataTensor;
+    typedef Tensor<TargetType, outDtype, LayOutType_out> OutDataTensor;
+    typedef Tensor<TargetType, OpDtype, LayOutType_op> OpTensor;
+    typedef SequenceConvParam<OpTensor> Param_t;
+    typedef std::vector<InDataTensor*> Input_v;
+    typedef std::vector<OutDataTensor*> Output_v;
+    typedef std::vector<Shape> Shape_v;
+
+    virtual SaberStatus compute_output_shape(const Input_v& input, \
+            Output_v& output, Param_t& param) override {
+        InDataTensor* input_tensor = input[0];
+        Shape new_shape(input_tensor->num(), param.filter_tensor->width(), 1, 1);
+        return output[0]->set_shape(new_shape);
+    }
+
+    virtual SaberStatus init_impl(ImplEnum implenum) override {
+        switch (implenum) {
+#ifdef USE_X86_PLACE
+        case VENDER_IMPL:
+            CHECK_EQ(1, 0) << "Sequence conv No Vender imp";
+            //                        this->_impl.push_back(new VenderSequencePool <TargetType, OpDtype, inDtype, outDtype,
+            //                                LayOutType_op, LayOutType_in, LayOutType_out>);
+            return SaberSuccess;
+
+        case SABER_IMPL:
+            this->_impl.push_back(new SaberSequenceConv <TargetType, OpDtype, inDtype, outDtype,
+                                  LayOutType_op, LayOutType_in, LayOutType_out>);
+            return SaberSuccess;
+#endif
+
+        default:
+            return SaberUnImplError;
+        }
+    }
+private:
+
+    virtual void pick_best_static() override {
+        if (true) { // some condition?
+            this->_best_impl = this->_impl[0];
+        }
+    }
+
+    virtual void pick_best_specify(ImplEnum implenum) override {
+        this->_best_impl = this->_impl[0];
+    }
+
+};
+}
+}
+
+
+#endif
diff --git a/saber/funcs/sequence_pool.h b/saber/funcs/sequence_pool.h
index 1a5f4a1..2dac392 100644
--- a/saber/funcs/sequence_pool.h
+++ b/saber/funcs/sequence_pool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -27,7 +27,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_sequence_pool.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_sequence_pool.h"
+#endif
 namespace anakin {
 namespace saber {
 
@@ -69,8 +72,19 @@ public:
         Shape output_shape = (input[0]->valid_shape());
         int num_idx = input[0]->num_index();
         std::vector<int> offset = input[0]->get_seq_offset();
-        CHECK_GT(offset.size(), 1) << "seq num error! " << offset.size();
-        output_shape[num_idx] = offset.size() - 1;
+        //CHECK_GT(offset.size(), 1) << "seq num error! " << offset.size();
+        int output_shape_num=0;
+        if (offset.size() > 1) {
+            output_shape_num = offset.size() - 1;
+        } else {
+            output_shape_num = input[0]->num();
+        }
+        output_shape[num_idx]=output_shape_num;
+        std::vector<int> offset_new(output_shape_num+1);
+        for(int i=0;i<=output_shape_num;++i){
+            offset_new[i]=i;
+        }
+        output[0]->set_seq_offset(offset_new);
         return output[0]->set_shape(output_shape);
     }
 
diff --git a/saber/funcs/slice.h b/saber/funcs/slice.h
index 99cc621..a5dce84 100644
--- a/saber/funcs/slice.h
+++ b/saber/funcs/slice.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_slice.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_slice.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/softmax.h b/saber/funcs/softmax.h
index 3fa5d85..593440a 100644
--- a/saber/funcs/softmax.h
+++ b/saber/funcs/softmax.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -26,7 +26,9 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/x86/saber_softmax.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+#include "saber/funcs/impl/arm/saber_softmax.h"
+#endif
 namespace anakin{
 
 namespace saber{
@@ -65,7 +67,7 @@ public:
 
     virtual SaberStatus compute_output_shape(const Input_v& input,\
      Output_v &output, Param_t& param) override {
-
+        output[0]->set_seq_offset(input[0]->get_seq_offset());
         //! "input" only has one input tensor
         return output[0]->set_shape(input[0]->valid_shape());
     }
diff --git a/saber/funcs/spp.h b/saber/funcs/spp.h
index 5ff5d58..2202227 100644
--- a/saber/funcs/spp.h
+++ b/saber/funcs/spp.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -25,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_spp.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_spp.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/funcs/timer.h b/saber/funcs/timer.h
index 4b16893..98c5192 100644
--- a/saber/funcs/timer.h
+++ b/saber/funcs/timer.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -32,11 +32,6 @@ namespace saber{
 template <typename TargetType>
 class SaberTimer final {
 
-};
-
-template <>
-class SaberTimer<X86> final {
-
 public:
     SaberTimer() {}
 
@@ -46,11 +41,11 @@ public:
         ms_time.clear();
     }
 
-    void start(Context<X86> &ctx) {
+    void start(Context<TargetType> &ctx) {
         tstart = std::chrono::system_clock::now();
     }
 
-    void end(Context<X86> &ctx) {
+    void end(Context<TargetType> &ctx) {
         tend = std::chrono::system_clock::now();
         auto ts = std::chrono::duration_cast<std::chrono::microseconds>(tend - tstart);
         float elapse_ms = 1000.f * float(ts.count()) * std::chrono::microseconds::period::num / \
diff --git a/saber/funcs/transpose.h b/saber/funcs/transpose.h
index c776668..fedd291 100644
--- a/saber/funcs/transpose.h
+++ b/saber/funcs/transpose.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_FUNCS_TRANSPOSE_H
 #define ANAKIN_SABER_FUNCS_TRANSPOSE_H
@@ -24,7 +25,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_transpose.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_transpose.h"
+#endif
 namespace anakin{
 
 namespace saber{
diff --git a/saber/funcs/unpool.h b/saber/funcs/unpool.h
index 088454c..ff84b44 100644
--- a/saber/funcs/unpool.h
+++ b/saber/funcs/unpool.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -24,7 +24,10 @@
 #ifdef USE_X86_PLACE
 #include "saber/funcs/impl/impl_unpool.h"
 #endif
-
+#ifdef USE_ARM_PLACE
+//todo
+#include "saber/funcs/impl/impl_unpool.h"
+#endif
 namespace anakin {
 namespace saber {
 
diff --git a/saber/lite/core/buffer_lite.cpp b/saber/lite/core/buffer_lite.cpp
index a75c639..b6f6b9a 100644
--- a/saber/lite/core/buffer_lite.cpp
+++ b/saber/lite/core/buffer_lite.cpp
@@ -94,12 +94,11 @@ void Buffer<CPU>::mem_set(int c, size_t size) {
     memset(_data, c, size);
 }
 
-template <>
-size_t Buffer<CPU>::get_capacity() {
+template <ARMType ttype>
+size_t Buffer<ttype>::get_capacity() {
     return _capacity;
 }
 
-
 } //namespace lite
 
 } //namespace saber
diff --git a/saber/lite/core/buffer_lite.h b/saber/lite/core/buffer_lite.h
index d51c881..120d9b2 100644
--- a/saber/lite/core/buffer_lite.h
+++ b/saber/lite/core/buffer_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/core/common_lite.h b/saber/lite/core/common_lite.h
index 17db7b4..93d3f6d 100644
--- a/saber/lite/core/common_lite.h
+++ b/saber/lite/core/common_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -16,7 +15,6 @@
 #ifndef ANAKIN_SABER_LITE_CORE_COMMON_H
 #define ANAKIN_SABER_LITE_CORE_COMMON_H
 
-#include "logger/logger.h"
 #include <memory>
 #include <vector>
 #include <cassert>
@@ -95,8 +93,11 @@ inline const char* get_error_string_lite(SaberStatus error_code) {
             return "ANAKIN_SABER_STATUS_OUT_OF_MEMORY";
         case SaberUnImplError:
             return "ANAKIN_SABER_STATUS_UNIMPL_ERROR";
+        case SaberWrongDevice:
+            return "ANAKIN_SABER_STATUS_WRONG_DEVICE";
+        default:
+            return "ANAKIN SABER UNKOWN ERRORS";
     }
-    return "ANAKIN SABER UNKOWN ERRORS";
 }
 #if 0 //add support for opencl device memory
 template <typename dtype>
diff --git a/saber/lite/core/context_lite.cpp b/saber/lite/core/context_lite.cpp
index 97e13b2..9010743 100644
--- a/saber/lite/core/context_lite.cpp
+++ b/saber/lite/core/context_lite.cpp
@@ -29,7 +29,7 @@ namespace saber{
 
 namespace lite{
 
-static int arm_get_cpucount() {
+int arm_get_cpucount() {
 #ifdef PLATFORM_ANDROID
     // get cpu count from /proc/cpuinfo
     FILE* fp = fopen("/proc/cpuinfo", "rb");
@@ -188,7 +188,7 @@ int sort_cpuid_by_max_frequency(int cpu_count, std::vector<int>& cpuids, \
 #endif // __ANDROID__
 
 #ifdef __IOS__
-static int sort_cpuid_by_max_frequency(int cpu_count, std::vector<int>& cpuids, \
+int sort_cpuid_by_max_frequency(int cpu_count, std::vector<int>& cpuids, \
        std::vector<int>& cpu_freq, std::vector<int>& cluster_ids){
     if (cpu_count == 0) {
         return 0;
@@ -231,7 +231,7 @@ int set_sched_affinity(const std::vector<int>& cpuids) {
     return 0;
 }
 
-static int set_cpu_affinity(const std::vector<int>& cpuids){
+int set_cpu_affinity(const std::vector<int>& cpuids){
 #ifdef USE_OPENMP
     int num_threads = cpuids.size();
     omp_set_num_threads(num_threads);
@@ -255,11 +255,12 @@ static int set_cpu_affinity(const std::vector<int>& cpuids){
             return -1;
         }
 #endif
+    return 0;
 }
 #endif //PLATFORN_ANDROID
 
 //template <>
-static void Env::get_info(DeviceInfo& dev) {
+void Env::get_info(DeviceInfo& dev) {
     //! set to const value, need to fetch from device
     dev._L1_cache = 31000;
     dev._L2_cache = 2000000;
diff --git a/saber/lite/core/context_lite.h b/saber/lite/core/context_lite.h
index edc513d..063d2d3 100644
--- a/saber/lite/core/context_lite.h
+++ b/saber/lite/core/context_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/core/shape_lite.h b/saber/lite/core/shape_lite.h
index 8c47e1e..2e712a8 100644
--- a/saber/lite/core/shape_lite.h
+++ b/saber/lite/core/shape_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -119,7 +118,7 @@ public:
     }
 
     Shape operator+(const Shape& shape) {
-        assert(dims() = shape.dims());
+        assert(dims() == shape.dims());
         Shape tmp_shape(*this);
         int* p = data();
         for (size_t i = 0; i < size(); i++) {
@@ -129,7 +128,7 @@ public:
     }
 
     Shape operator-(const Shape& shape) {
-        assert(dims() = shape.dims());
+        assert(dims() == shape.dims());
         Shape tmp_shape(*this);
         int* p = data();
         for (size_t i = 0; i < size(); i++) {
diff --git a/saber/lite/core/tensor_lite.cpp b/saber/lite/core/tensor_lite.cpp
index 7929446..1a8a503 100644
--- a/saber/lite/core/tensor_lite.cpp
+++ b/saber/lite/core/tensor_lite.cpp
@@ -251,6 +251,19 @@ const std::shared_ptr<Buffer<ttype>>& Tensor<ttype, dtype>::get_buf() const {
 }
 
 template<ARMType ttype, DataType dtype>
+template <typename Tensor_t>
+SaberStatus Tensor<ttype, dtype>::share_from(const Tensor_t& tensor) {
+
+    LCHECK_EQ(_shape.dims() > 0, true, "current tensor is not initialized (no shape info, use set_shape)");
+    typedef typename Tensor_t::Dtype_real dtype_real_t;
+    LCHECK_LE(size() * _type_len, tensor.size() * sizeof(dtype_real_t), "current tensor size should <= input tensor size");
+    _buf = tensor.get_buf();
+    _is_shared = true;
+    _is_subbuf = false;
+    return SaberSuccess;
+}
+
+template<ARMType ttype, DataType dtype>
 SaberStatus Tensor<ttype, dtype>::share_sub_buffer(const Tensor<ttype, dtype>& tensor, \
         Shape valid_shape, Shape offset) {
 
@@ -265,6 +278,18 @@ SaberStatus Tensor<ttype, dtype>::share_sub_buffer(const Tensor<ttype, dtype>& t
 }
 
 template<ARMType ttype, DataType dtype>
+template <class Tensor_t>
+SaberStatus Tensor<ttype, dtype>::copy_from(const Tensor_t& tensor) {
+
+    size_t cap_dst = valid_size() * _type_len;
+    typedef typename Tensor_t::Dtype_real dtype_real_t;
+    size_t cap_src = tensor.valid_size() * sizeof(dtype_real_t);
+    LCHECK_EQ(cap_dst, cap_src, "sizes of two valid shapes must be the same");
+    _buf->copy_from(*tensor.get_buf());
+    return SaberSuccess;
+}
+
+template<ARMType ttype, DataType dtype>
 void Tensor<ttype, dtype>::sync() {
     //!fixme
 }
diff --git a/saber/lite/core/tensor_lite.h b/saber/lite/core/tensor_lite.h
index 468414f..8729ba8 100644
--- a/saber/lite/core/tensor_lite.h
+++ b/saber/lite/core/tensor_lite.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -194,15 +194,7 @@ public:
      */
 
     template <class Tensor_t>
-    SaberStatus share_from(const Tensor_t& tensor) {
-		LCHECK_EQ(_shape.dims() > 0, true, "current tensor is not initialized (no shape info, use set_shape)");
-    	typedef typename Tensor_t::Dtype_real dtype_real_t;
-    	LCHECK_LE(size() * _type_len, tensor.size() * sizeof(dtype_real_t), "current tensor size should <= input tensor size");
-    	_buf = tensor.get_buf();
-    	_is_shared = true;
-    	_is_subbuf = false;
-    	return SaberSuccess;
-	}
+    SaberStatus share_from(const Tensor_t& tensor);
 
     SaberStatus share_sub_buffer(const Tensor<ttype, dtype>& tensor, \
         Shape valid_shape, Shape offset);
@@ -211,14 +203,7 @@ public:
      *  \brief Deep copy data within region of interest from input tensor.
      */
      template <class Tensor_t>
-    SaberStatus copy_from(const Tensor_t& tensor) {
-    	size_t cap_dst = valid_size() * _type_len;
-    	typedef typename Tensor_t::Dtype_real dtype_real_t;
-    	size_t cap_src = tensor.valid_size() * sizeof(dtype_real_t);
-    	LCHECK_EQ(cap_dst, cap_src, "sizes of two valid shapes must be the same");
-    	_buf->copy_from(*tensor.get_buf());
-    	return SaberSuccess;
-	}
+    SaberStatus copy_from(const Tensor_t& tensor);
 
     /**
      *  \brief Synchronize the event tree, wait util all events are done.
diff --git a/saber/lite/core/tensor_op_lite.h b/saber/lite/core/tensor_op_lite.h
index dc33ada..ffd0ccb 100644
--- a/saber/lite/core/tensor_op_lite.h
+++ b/saber/lite/core/tensor_op_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/neon/impl/conv3x3s1_direct.cpp b/saber/lite/funcs/neon/impl/conv3x3s1_direct.cpp
index 6b19823..0b1e4f2 100644
--- a/saber/lite/funcs/neon/impl/conv3x3s1_direct.cpp
+++ b/saber/lite/funcs/neon/impl/conv3x3s1_direct.cpp
@@ -66,6 +66,11 @@ void conv_3x3s1_direct(const float* din, float* dout, \
 
             for (int i = 0; i < chin; ++i) {
 
+                int relu = 0;
+                if ((i == chin - 1) && flag_relu) {
+                    relu = 1;
+                }
+
                 const float *din_channel = din_batch + i * size_in_channel;
 
                 const float* wcin0 = wc0 + i * 9;
@@ -177,18 +182,26 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
                                 "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
 
-                                "vext.32  q12, q15, q10, #3               @ shift right r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][0]            @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][0]            @ mul weight1 20, out1r1\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][0]          @ mul weight1 20, out1r1\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tl                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_tl:                              @ store top left result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
 
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r1], #192]                @ preload data\n"
 
                                 "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
@@ -200,73 +213,81 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "blt  start_top_right                   @ jump to main loop start point\n"
                                 "start_top_mid:                         @ main loop start point\n"
 
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]      @ load din r1\n"
                                 "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tm                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_tm:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
 
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r1], #192]                @ preload data\n"
 
                                 "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
@@ -277,81 +298,91 @@ void conv_3x3s1_direct(const float* din, float* dout, \
 
                                 //! process right pad
                                 "start_top_right:                       @ right pad entry\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r1\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r1\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]              @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]              @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r2\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r2\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r3\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r3\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_tr                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                "store_tr:                              @ store top mid result\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 "vmvn.32  q12, q15                      @ \n"
                                 "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
-                                "vbif q13, q10, q15                      @ bit select\n"
-                                "vbif q14, q11, q15                      @ bit select\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q14, q11, q15                     @ bit select\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout1r1\n"
 
                                 "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
                                 "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
 
                                 "vbif q8, q10, q15                      @ bit select\n"
                                 "vbif q9, q11, q15                      @ bit select\n"
@@ -370,7 +401,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                             [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
                         :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
                             [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub)
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \
+                            [relu] "r"(relu)
                         :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
                         );
 #endif //__aarch64__
@@ -421,77 +453,85 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
                                 "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
-                                "vmov.u32 q15, #0                         @ dump zero\n"
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr00][0]            @ mul weight0 00, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][0]            @ mul weight1 00, out1r0\n"
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][0]            @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][0]            @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][0]            @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][0]            @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r2\n"
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
-
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
-
-                                "vext.32  q12, q15, q10, #3               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][0]            @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][0]            @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][0]            @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][0]            @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
+
+                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
 
                                 //! 4rd row
-                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!     @ load din r3\n"
                                 "pld [%[din3_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][1]           @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][1]           @ mul weight1 21, out1r1\n"
+                                "vmla.f32 q14, q10, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][1]          @ mul weight1 21, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
 
-                                "vext.32  q12, q15, q10, #3               @ shift right r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][0]            @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][0]            @ mul weight1 20, out1r1\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][0]          @ mul weight1 20, out1r1\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_ml                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_ml:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
 
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r1], #192]                @ preload data\n"
 
                                 "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
@@ -504,87 +544,95 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "blt  start_mid_right                   @ jump to main loop start point\n"
                                 "start_mid_mid:                         @ main loop start point\n"
 
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
                                 "pld [%[din0_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!     @ load din r2\n"
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
                                 //! 4rd row
-                                "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
+                                "vld1.32  {d20-d22}, [%[din3_ptr]]!     @ load din r3\n"
                                 "pld [%[din3_ptr], #192]                @ preload data\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
-                                "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
+                                "vmla.f32 q14, q10, %e[wr02][0]         @ mul weight0 20, out0r1\n"
+                                "vmla.f32 q9, q10, %e[wr12][0]          @ mul weight1 20, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]         @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]          @ mul weight1 21, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]         @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]          @ mul weight1 22, out1r1\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_mm                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
+
+                                "store_mm:                              @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
 
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
                                 "pld [%[doutc1r1], #192]                @ preload data\n"
 
                                 "sub %[din0_ptr], #8                    @ 2 float data overlap with previous data\n"
@@ -597,103 +645,113 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 //! process right pad
                                 "start_mid_right:                       @ right pad entry\n"
 
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!      @ load din r1\n"
                                 "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
                                 "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]          @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]          @ mul weight0 00, out0r1\n"
                                 "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
                                 "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1              @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]          @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]          @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]           @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]           @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2              @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]          @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]           @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]           @ mul weight1 02, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]!       @ load din r2\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]!      @ load din r2\n"
                                 "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
                                 "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]          @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]          @ mul weight0 10, out0r1\n"
                                 "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
                                 "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #1              @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]          @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]          @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]           @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]           @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vext.32  q12, q10, q11, #2              @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]          @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]          @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]           @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]           @ mul weight1 12, out1r1\n"
 
                                 //! 4rd row
                                 "vld1.32  {d20-d22}, [%[din3_ptr]]!      @ load din r3\n"
                                 "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
                                 "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q14, q10, %e[wr02][0]           @ mul weight0 20, out0r1\n"
+
+                                "vmla.f32 q14, q10, %e[wr02][0]          @ mul weight0 20, out0r1\n"
                                 "vmla.f32 q9, q10, %e[wr12][0]           @ mul weight1 20, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %e[wr02][1]            @ mul weight0 21, out0r1\n"
-                                "vmla.f32 q9, q12, %e[wr12][1]            @ mul weight1 21, out1r1\n"
+                                "vext.32  q12, q10, q11, #1              @ shift left r3\n"
+                                "vmla.f32 q14, q12, %e[wr02][1]          @ mul weight0 21, out0r1\n"
+                                "vmla.f32 q9, q12, %e[wr12][1]           @ mul weight1 21, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #2              @ shift left r3\n"
+                                "vmla.f32 q14, q12, %f[wr02][0]          @ mul weight0 22, out0r1\n"
+                                "vmla.f32 q9, q12, %f[wr12][0]           @ mul weight1 22, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r3\n"
-                                "vmla.f32 q14, q12, %f[wr02][0]            @ mul weight0 22, out0r1\n"
-                                "vmla.f32 q9, q12, %f[wr12][0]            @ mul weight1 22, out1r1\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_mr                        @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "store_mr:                              @ store top mid result\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 "vmvn.32  q12, q15                      @ \n"
                                 "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
-                                "vbif q13, q10, q15                      @ bit select\n"
-                                "vbif q14, q11, q15                      @ bit select\n"
+                                "vbif q13, q10, q15                     @ bit select\n"
+                                "vbif q14, q11, q15                     @ bit select\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
 
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc1r0]]       @ load dout1r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout1r1\n"
+                                "vld1.32  {d20-d21}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout1r1\n"
 
                                 "vbif q8, q10, q15                      @ bit select\n"
                                 "vbif q9, q11, q15                      @ bit select\n"
 
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
 
                                 "sub %[doutc0r0], %[doutc0r0], %[right_pad_sub] @ sub \n"
                                 "sub %[doutc0r1], %[doutc0r1], %[right_pad_sub] @ sub \n"
@@ -707,7 +765,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                             [cnt] "+r"(cnt)
                         :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
                             [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub)
+                            [vmask_rp] "w" (vmask_rp), [right_pad_sub] "r" (right_pad_sub), \
+                            [relu] "r"(relu)
                         :"q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
                         );
 #endif //__aarch64__
@@ -774,6 +833,12 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vmla.f32 q6, q12, %e[wr01][0]          @ mul weight0 10, out0r0\n"
                                 "vmla.f32 q7, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
 
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bl_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_bl_1:                            @ store top mid result\n"
                                 "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
 
@@ -822,6 +887,12 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
                                 "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
 
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bm_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_bm_1:                            @ store top mid result\n"
                                 "vst1.32  {d12-d13}, [%[doutc0r0]]!     @ store result, add pointer\n"
                                 "vst1.32  {d14-d15}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0]]                      @ preload data\n"
@@ -871,6 +942,13 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vmla.f32 q6, q12, %f[wr01][0]          @ mul weight0 12, out0r0\n"
                                 "vmla.f32 q7, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
 
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_br_1                      @ jump to store without relu\n"
+                                "vmax.f32   q6, q6, q15                 @ relu\n"
+                                "vmax.f32   q7, q7, q15                 @ relu\n"
+
+                                "store_br_1:                            @ store top mid result\n"
+
                                 "vld1.32  {d16-d17}, [%[doutc0r0]]      @ load dout0r0\n"
                                 "vld1.32  {d18-d19}, [%[doutc1r0]]      @ load dout0r0\n"
 
@@ -886,8 +964,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                             [cnt] "+r"(cnt)
                         :[wr00] "w"(wr00), [wr01] "w"(wr01), \
                             [wr10] "w"(wr10), [wr11] "w"(wr11), \
-                            [vmask_rp] "w" (vmask_rp)
-                        :"q6", "q7", "q8", "q9", "q10", "q11", "q12", "q13", "q15"
+                            [vmask_rp] "w" (vmask_rp), [relu] "r"(relu)
+                        :"q6", "q7", "q8", "q9", "q10", "q11", "q12", "q13", "q14", "q15"
                         );
 #endif //__aarch64__
 
@@ -903,73 +981,81 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
                                 "pld [%[doutc1r1], #192]                @ preload data\n"
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
+
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
                                 "pld [%[din0_ptr], #192]                @ preload data\n"
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vmla.f32 q13, q10, %e[wr00][1]           @ mul weight0 01, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][1]           @ mul weight1 01, out1r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
                                 "pld [%[din0_ptr], #192]                @ preload data\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]              @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]              @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
-                                "vmov.u32 q15, #0                         @ dump zero\n"
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr00][0]            @ mul weight0 00, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][0]            @ mul weight1 00, out1r0\n"
+                                "vmov.u32 q15, #0                       @ dump zero\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vmla.f32 q13, q10, %e[wr01][1]           @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][1]           @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][1]           @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][1]           @ mul weight1 01, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
-                                "vext.32  q12, q15, q10, #3               @ shift right r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][0]            @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][0]            @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][0]            @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][0]            @ mul weight1 00, out1r1\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vmla.f32 q13, q10, %e[wr02][1]           @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][1]           @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][1]           @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][1]           @ mul weight1 11, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
-                                "vext.32  q12, q15, q10, #3               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][0]            @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][0]            @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][0]            @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][0]            @ mul weight1 10, out1r1\n"
+                                "vext.32  q12, q15, q10, #3             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][0]          @ mul weight1 10, out1r1\n"
 
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bl_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "store_bl_2:                            @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
 
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
@@ -977,8 +1063,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "sub %[din0_ptr], #12                   @ 1pad + 2 float data overlap\n"
                                 "sub %[din1_ptr], #12                   @ 1pad + 2 float data overlap\n"
 
-                                "vst1.32  {d28-d29}, [%[doutc0r1]]!    @ store result, add pointer\n"
-                                "vst1.32  {d18-d19}, [%[doutc1r1]]!    @ store result, add pointer\n"
+                                "vst1.32  {d28-d29}, [%[doutc0r1]]!     @ store result, add pointer\n"
+                                "vst1.32  {d18-d19}, [%[doutc1r1]]!     @ store result, add pointer\n"
                                 "add %[din2_ptr], #12                   @ 1pad + 2 float data overlap\n"
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
                                 "pld [%[doutc0r1], #192]                @ preload data\n"
@@ -986,71 +1072,79 @@ void conv_3x3s1_direct(const float* din, float* dout, \
 
                                 //! process mid cols
                                 "cmp %[cnt], #1                         @ check whether has mid cols\n"
-                                "blt  conv3x3_bot_right_2                   @ jump to main loop start point\n"
-                                "conv3x3_bot_mid_2:                         @ main loop start point\n"
+                                "blt  conv3x3_bot_right_2               @ jump to main loop start point\n"
+                                "conv3x3_bot_mid_2:                     @ main loop start point\n"
 
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
                                 "pld [%[din0_ptr], #192]                @ preload data\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
                                 "pld [%[din1_ptr], #192]                @ preload data\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_bm_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
 
-                                "vst1.32  {d26-d27}, [%[doutc0r0]]!    @ store result, add pointer\n"
-                                "vst1.32  {d16-d17}, [%[doutc1r0]]!    @ store result, add pointer\n"
+                                "store_bm_2:                            @ store top mid result\n"
+                                "vst1.32  {d26-d27}, [%[doutc0r0]]!     @ store result, add pointer\n"
+                                "vst1.32  {d16-d17}, [%[doutc1r0]]!     @ store result, add pointer\n"
                                 "pld [%[doutc0r0], #192]                @ preload data\n"
                                 "pld [%[doutc1r0], #192]                @ preload data\n"
 
@@ -1065,75 +1159,84 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "pld [%[din2_ptr], #192]                @ preload data\n"
 
                                 "subs %[cnt], #1                        @ loop count minus 1\n"
-                                "bne    conv3x3_bot_mid_2                   @ jump to main loop start point\n"
+                                "bne    conv3x3_bot_mid_2               @ jump to main loop start point\n"
 
                                 //! process right pad
-                                "conv3x3_bot_right_2:                       @ right pad entry\n"
+                                "conv3x3_bot_right_2:                   @ right pad entry\n"
 
-                                "vld1.32  {d26-d27}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d28-d29}, [%[doutc0r1]]       @ load dout0r1\n"
+                                "vld1.32  {d26-d27}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d28-d29}, [%[doutc0r1]]      @ load dout0r1\n"
 
                                 //! 1st row
-                                "vld1.32  {d20-d22}, [%[din0_ptr]]!      @ load din r0\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr00][0]           @ mul weight0 00, out0r0\n"
-                                "vld1.32  {d16-d17}, [%[doutc1r0]]        @ load dout1r0\n"
-                                "vld1.32  {d18-d19}, [%[doutc1r1]]        @ load dout1r1\n"
-                                "vmla.f32 q8, q10, %e[wr10][0]           @ mul weight1 00, out1r0\n"
+                                "vld1.32  {d20-d22}, [%[din0_ptr]]!     @ load din r0\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr00][0]         @ mul weight0 00, out0r0\n"
+                                "vld1.32  {d16-d17}, [%[doutc1r0]]      @ load dout1r0\n"
+                                "vld1.32  {d18-d19}, [%[doutc1r1]]      @ load dout1r1\n"
+                                "vmla.f32 q8, q10, %e[wr10][0]          @ mul weight1 00, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #1                 @ shift left r0\n"
-                                "vmla.f32 q13, q12, %e[wr00][1]              @ mul weight0 01, out0r0\n"
-                                "vmla.f32 q8, q12, %e[wr10][1]              @ mul weight1 01, out1r0\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %e[wr00][1]         @ mul weight0 01, out0r0\n"
+                                "vmla.f32 q8, q12, %e[wr10][1]          @ mul weight1 01, out1r0\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r0\n"
-                                "vmla.f32 q13, q12, %f[wr00][0]            @ mul weight0 02, out0r0\n"
-                                "vmla.f32 q8, q12, %f[wr10][0]            @ mul weight1 02, out1r0\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r0\n"
+                                "vmla.f32 q13, q12, %f[wr00][0]         @ mul weight0 02, out0r0\n"
+                                "vmla.f32 q8, q12, %f[wr10][0]          @ mul weight1 02, out1r0\n"
 
                                 //! 2nd row
-                                "vld1.32  {d20-d22}, [%[din1_ptr]]!       @ load din r1\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr01][0]           @ mul weight0 10, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr00][0]           @ mul weight0 00, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr11][0]           @ mul weight1 10, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr10][0]           @ mul weight1 00, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din1_ptr]]!     @ load din r1\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr01][0]         @ mul weight0 10, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr00][0]         @ mul weight0 00, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr11][0]          @ mul weight1 10, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr10][0]          @ mul weight1 00, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %e[wr01][1]            @ mul weight0 11, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr00][1]            @ mul weight0 01, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr11][1]            @ mul weight1 11, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr10][1]            @ mul weight1 01, out1r1\n"
+                                "vext.32  q12, q10, q11, #1             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %e[wr01][1]         @ mul weight0 11, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr00][1]         @ mul weight0 01, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr11][1]          @ mul weight1 11, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr10][1]          @ mul weight1 01, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift left r1\n"
-                                "vmla.f32 q13, q12, %f[wr01][0]            @ mul weight0 12, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr00][0]            @ mul weight0 02, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr11][0]            @ mul weight1 12, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr10][0]            @ mul weight1 02, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift left r1\n"
+                                "vmla.f32 q13, q12, %f[wr01][0]         @ mul weight0 12, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr00][0]         @ mul weight0 02, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr11][0]          @ mul weight1 12, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr10][0]          @ mul weight1 02, out1r1\n"
 
                                 //! 3rd row
-                                "vld1.32  {d20-d22}, [%[din2_ptr]]       @ load din r2\n"
-                                "vbif d21, d31, %e[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vbif d22, d31, %f[vmask_rp]             @ bit select, deal with right pad\n"
-                                "vmla.f32 q13, q10, %e[wr02][0]           @ mul weight0 20, out0r0\n"
-                                "vmla.f32 q14, q10, %e[wr01][0]           @ mul weight0 10, out0r1\n"
-                                "vmla.f32 q8, q10, %e[wr12][0]           @ mul weight1 20, out1r0\n"
-                                "vmla.f32 q9, q10, %e[wr11][0]           @ mul weight1 10, out1r1\n"
+                                "vld1.32  {d20-d22}, [%[din2_ptr]]      @ load din r2\n"
+                                "vbif d21, d31, %e[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vbif d22, d31, %f[vmask_rp]            @ bit select, deal with right pad\n"
+                                "vmla.f32 q13, q10, %e[wr02][0]         @ mul weight0 20, out0r0\n"
+                                "vmla.f32 q14, q10, %e[wr01][0]         @ mul weight0 10, out0r1\n"
+                                "vmla.f32 q8, q10, %e[wr12][0]          @ mul weight1 20, out1r0\n"
+                                "vmla.f32 q9, q10, %e[wr11][0]          @ mul weight1 10, out1r1\n"
+
+                                "vext.32  q12, q10, q11, #1             @ shift left r2\n"
+                                "vmla.f32 q13, q12, %e[wr02][1]         @ mul weight0 21, out0r0\n"
+                                "vmla.f32 q14, q12, %e[wr01][1]         @ mul weight0 11, out0r1\n"
+                                "vmla.f32 q8, q12, %e[wr12][1]          @ mul weight1 21, out1r0\n"
+                                "vmla.f32 q9, q12, %e[wr11][1]          @ mul weight1 11, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #1               @ shift left r2\n"
-                                "vmla.f32 q13, q12, %e[wr02][1]            @ mul weight0 21, out0r0\n"
-                                "vmla.f32 q14, q12, %e[wr01][1]            @ mul weight0 11, out0r1\n"
-                                "vmla.f32 q8, q12, %e[wr12][1]            @ mul weight1 21, out1r0\n"
-                                "vmla.f32 q9, q12, %e[wr11][1]            @ mul weight1 11, out1r1\n"
+                                "vext.32  q12, q10, q11, #2             @ shift right r2\n"
+                                "vmla.f32 q13, q12, %f[wr02][0]         @ mul weight0 22, out0r0\n"
+                                "vmla.f32 q14, q12, %f[wr01][0]         @ mul weight0 12, out0r1\n"
+                                "vmla.f32 q8, q12, %f[wr12][0]          @ mul weight1 22, out1r0\n"
+                                "vmla.f32 q9, q12, %f[wr11][0]          @ mul weight1 12, out1r1\n"
 
-                                "vext.32  q12, q10, q11, #2               @ shift right r2\n"
-                                "vmla.f32 q13, q12, %f[wr02][0]            @ mul weight0 22, out0r0\n"
-                                "vmla.f32 q14, q12, %f[wr01][0]            @ mul weight0 12, out0r1\n"
-                                "vmla.f32 q8, q12, %f[wr12][0]            @ mul weight1 22, out1r0\n"
-                                "vmla.f32 q9, q12, %f[wr11][0]            @ mul weight1 12, out1r1\n"
+                                "cmp %[relu], #1                        @ check whether has mid cols\n"
+                                "blt    store_br_2                      @ jump to store without relu\n"
+                                "vmax.f32   q13, q13, q15               @ relu\n"
+                                "vmax.f32   q14, q14, q15               @ relu\n"
+                                "vmax.f32   q8, q8, q15                 @ relu\n"
+                                "vmax.f32   q9, q9, q15                 @ relu\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc0r0]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r0]]       @ load dout0r1\n"
+                                "store_br_2:                            @ store top mid result\n"
+
+                                "vld1.32  {d20-d21}, [%[doutc0r0]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r0]]      @ load dout0r1\n"
 
                                 "vmvn.32  q12, q15                      @ \n"
                                 "vext.32  q15, q12, %q[vmask_rp], #3    @ shift mask right 1\n"
@@ -1143,8 +1246,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                 "vst1.32  {d26-d27}, [%[doutc0r0]]      @ store result, add pointer\n"
                                 "vst1.32  {d16-d17}, [%[doutc1r0]]      @ store result, add pointer\n"
 
-                                "vld1.32  {d20-d21}, [%[doutc0r1]]       @ load dout0r0\n"
-                                "vld1.32  {d22-d23}, [%[doutc1r1]]       @ load dout0r1\n"
+                                "vld1.32  {d20-d21}, [%[doutc0r1]]      @ load dout0r0\n"
+                                "vld1.32  {d22-d23}, [%[doutc1r1]]      @ load dout0r1\n"
 
                                 "vbif q14, q10, q15                     @ bit select\n"
                                 "vbif q9, q11, q15                      @ bit select\n"
@@ -1158,7 +1261,7 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                             [din2_ptr] "+r"(din2_ptr), [cnt] "+r"(cnt)
                         :[wr00] "w"(wr00), [wr01] "w"(wr01), [wr02] "w"(wr02), \
                             [wr10] "w"(wr10), [wr11] "w"(wr11), [wr12] "w"(wr12), \
-                            [vmask_rp] "w" (vmask_rp)
+                            [vmask_rp] "w" (vmask_rp), [relu] "r" (relu)
                         :"q8", "q9", "q10", \
                             "q11", "q12", "q13", "q14", "q15"
                         );
@@ -1182,13 +1285,16 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                 const float* wc0 = weights + cidx * w_stride;
 
                 for (int i = 0; i < chin; ++i) {
+
+                    bool relu = (i == chin - 1) && flag_relu;
+
                     const float* din_channel = din_batch + i * size_in_channel;
                     for (int h = 0; h < hout; ++h) {
 
                         int hstart = h - pad_h;
                         int hend = hstart + 3;
-                        hstart = hstart > 0? hstart : 0;
-                        hend = hend < hin? hend : hin;
+                        hstart = std::max(hstart, 0);
+                        hend = std::min(hend, hin);
 
                         int khstart = hend < kernel_h? kernel_h - hend : 0;
 
@@ -1197,8 +1303,8 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                         for (int w = 0; w < wout; ++w) {
                             int wstart = w - pad_w;
                             int wend = wstart + 3;
-                            wstart = wstart > 0? wstart : 0;
-                            wend = wend < win? wend : win;
+                            wstart = std::max(wstart, 0);
+                            wend = std::min(wend, win);
                             int kwstart = wend < kernel_w? kernel_w - wend : 0;
 
                             for (int kh = hstart; kh < hend; ++kh) {
@@ -1207,6 +1313,9 @@ void conv_3x3s1_direct(const float* din, float* dout, \
                                         wc0[(khstart + kh - hstart) * 3 + kwstart + kw - wstart];
                                 }
                             }
+                            if (relu) {
+                                dout_row[w] = dout_row[w] > 0.f? dout_row[w] : 0.f;
+                            }
                         }
                     }
                     wc0 += 9;
@@ -1223,4 +1332,4 @@ void conv_3x3s1_direct(const float* din, float* dout, \
 
 } //namespace anakin
 
-#endif
\ No newline at end of file
+#endif
diff --git a/saber/lite/funcs/neon/impl/pooling_arm_impl.h b/saber/lite/funcs/neon/impl/pooling_arm_impl.h
index 1aec7f1..ae28178 100644
--- a/saber/lite/funcs/neon/impl/pooling_arm_impl.h
+++ b/saber/lite/funcs/neon/impl/pooling_arm_impl.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/neon/impl/sgemm_arm.h b/saber/lite/funcs/neon/impl/sgemm_arm.h
index b631330..25f357b 100644
--- a/saber/lite/funcs/neon/impl/sgemm_arm.h
+++ b/saber/lite/funcs/neon/impl/sgemm_arm.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -77,4 +76,4 @@ private:
 
 #endif // USE_ARM_PLACE
 
-#endif //ANAKIN_SABER_LITE_FUNCS_NEON_IMPL_SGEMM_ARM_H
\ No newline at end of file
+#endif //ANAKIN_SABER_LITE_FUNCS_NEON_IMPL_SGEMM_ARM_H
diff --git a/saber/lite/funcs/neon/impl/sgemv_arm.h b/saber/lite/funcs/neon/impl/sgemv_arm.h
index b02c01f..706bbb2 100644
--- a/saber/lite/funcs/neon/impl/sgemv_arm.h
+++ b/saber/lite/funcs/neon/impl/sgemv_arm.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -45,4 +44,4 @@ void sgemv_bias_relu(const bool transA, const int M, const int N, \
 
 #endif // USE_ARM_PLACE
 
-#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMV_ARM_H
\ No newline at end of file
+#endif //ANAKIN_SABER_FUNCS_ARM_IMPL_SGEMV_ARM_H
diff --git a/saber/lite/funcs/neon/saber_detection_output.cpp b/saber/lite/funcs/neon/saber_detection_output.cpp
index ea3181f..7d38c95 100644
--- a/saber/lite/funcs/neon/saber_detection_output.cpp
+++ b/saber/lite/funcs/neon/saber_detection_output.cpp
@@ -742,6 +742,7 @@ SaberStatus SaberDetectionOutput::load_param(bool share_loc,
     _nms_top_k = nms_topk;
     _nms_thresh = nms_thresh;
     _nms_eta = nms_eta;
+    return SaberSuccess;
 }
 
 SaberStatus SaberDetectionOutput::compute_output_shape(const std::vector<Tensor<CPU, AK_FLOAT> *> &inputs,
diff --git a/saber/lite/funcs/neon/saber_softmax.cpp b/saber/lite/funcs/neon/saber_softmax.cpp
index 200f9a1..3ba6a2d 100644
--- a/saber/lite/funcs/neon/saber_softmax.cpp
+++ b/saber/lite/funcs/neon/saber_softmax.cpp
@@ -127,6 +127,7 @@ SaberSoftmax::SaberSoftmax(int axis) {
 
 SaberStatus SaberSoftmax::load_param(int axis) {
     _axis = axis;
+    return SaberSuccess;
 }
 
 SaberStatus SaberSoftmax::init(const std::vector<Tensor<CPU, AK_FLOAT> *> &inputs,
diff --git a/saber/lite/funcs/op_base.h b/saber/lite/funcs/op_base.h
index 77b5580..73e9a2c 100644
--- a/saber/lite/funcs/op_base.h
+++ b/saber/lite/funcs/op_base.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_activation.h b/saber/lite/funcs/saber_activation.h
index b32900e..15ad2e7 100644
--- a/saber/lite/funcs/saber_activation.h
+++ b/saber/lite/funcs/saber_activation.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_concat.h b/saber/lite/funcs/saber_concat.h
index 0ba3d18..6d92d4f 100644
--- a/saber/lite/funcs/saber_concat.h
+++ b/saber/lite/funcs/saber_concat.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_conv.h b/saber/lite/funcs/saber_conv.h
index 4de2aa2..fb94ade 100755
--- a/saber/lite/funcs/saber_conv.h
+++ b/saber/lite/funcs/saber_conv.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_conv_act.h b/saber/lite/funcs/saber_conv_act.h
index d2a8ce2..7c0d6b5 100755
--- a/saber/lite/funcs/saber_conv_act.h
+++ b/saber/lite/funcs/saber_conv_act.h
@@ -1,5 +1,4 @@
 /* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_conv_batchnorm_scale.h b/saber/lite/funcs/saber_conv_batchnorm_scale.h
index 5427e40..69cab82 100755
--- a/saber/lite/funcs/saber_conv_batchnorm_scale.h
+++ b/saber/lite/funcs/saber_conv_batchnorm_scale.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/lite/funcs/saber_conv_batchnorm_scale_relu.h b/saber/lite/funcs/saber_conv_batchnorm_scale_relu.h
index 321743b..58cbdcf 100755
--- a/saber/lite/funcs/saber_conv_batchnorm_scale_relu.h
+++ b/saber/lite/funcs/saber_conv_batchnorm_scale_relu.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/lite/funcs/saber_detection_output.h b/saber/lite/funcs/saber_detection_output.h
index be2359d..089f8c1 100644
--- a/saber/lite/funcs/saber_detection_output.h
+++ b/saber/lite/funcs/saber_detection_output.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
@@ -13,8 +12,8 @@
    limitations under the License. 
 */
 
-#ifndef ANAKIN_SABER_LITE_FUNCS_SABER_ELTWISE_H
-#define ANAKIN_SABER_LITE_FUNCS_SABER_ELTWISE_H
+#ifndef ANAKIN_SABER_LITE_FUNCS_SABER_DETECTION_OUTPUT_H
+#define ANAKIN_SABER_LITE_FUNCS_SABER_DETECTION_OUTPUT_H
 
 #include "saber/lite/core/tensor_lite.h"
 #include "saber/lite/core/context_lite.h"
diff --git a/saber/lite/funcs/saber_eltwise.h b/saber/lite/funcs/saber_eltwise.h
index de7bacb..f2511b2 100644
--- a/saber/lite/funcs/saber_eltwise.h
+++ b/saber/lite/funcs/saber_eltwise.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/lite/funcs/saber_fc.h b/saber/lite/funcs/saber_fc.h
index 0f6af79..3e90ac1 100755
--- a/saber/lite/funcs/saber_fc.h
+++ b/saber/lite/funcs/saber_fc.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_permute.h b/saber/lite/funcs/saber_permute.h
index 83a6280..6d34402 100644
--- a/saber/lite/funcs/saber_permute.h
+++ b/saber/lite/funcs/saber_permute.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_pooling.h b/saber/lite/funcs/saber_pooling.h
index 84206f8..7dedfce 100755
--- a/saber/lite/funcs/saber_pooling.h
+++ b/saber/lite/funcs/saber_pooling.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_prelu.h b/saber/lite/funcs/saber_prelu.h
index d7521bd..bde1f67 100644
--- a/saber/lite/funcs/saber_prelu.h
+++ b/saber/lite/funcs/saber_prelu.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_priorbox.h b/saber/lite/funcs/saber_priorbox.h
index 78647f2..9950ca8 100644
--- a/saber/lite/funcs/saber_priorbox.h
+++ b/saber/lite/funcs/saber_priorbox.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/saber_slice.h b/saber/lite/funcs/saber_slice.h
index e59453e..351f4af 100644
--- a/saber/lite/funcs/saber_slice.h
+++ b/saber/lite/funcs/saber_slice.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/timer_lite.h b/saber/lite/funcs/timer_lite.h
index af21261..8bfbc67 100644
--- a/saber/lite/funcs/timer_lite.h
+++ b/saber/lite/funcs/timer_lite.h
@@ -1,5 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
diff --git a/saber/lite/funcs/utils_arm.h b/saber/lite/funcs/utils_arm.h
index cc3199b..e6d8b5d 100644
--- a/saber/lite/funcs/utils_arm.h
+++ b/saber/lite/funcs/utils_arm.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/saber/saber.h b/saber/saber.h
index 62bc216..f50161e 100644
--- a/saber/saber.h
+++ b/saber/saber.h
@@ -1,3 +1,18 @@
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+*/
+
 #ifndef ANAKIN_SABER_SABER_H
 #define ANAKIN_SABER_SABER_H
 
diff --git a/saber/saber_funcs_param.h b/saber/saber_funcs_param.h
index 4b0f170..1103030 100644
--- a/saber/saber_funcs_param.h
+++ b/saber/saber_funcs_param.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -38,28 +38,25 @@ struct MatMulParam {
     bool operator==(const MatMulParam &right) {
         bool comp_eq = true;
         comp_eq = comp_eq && (_is_transpose_X == right._is_transpose_X);        
-        comp_eq = comp_eq && (_is_transpose_Y == right._is_transpose_Y);        
+        comp_eq = comp_eq && (_is_transpose_Y == right._is_transpose_Y);
+        return comp_eq;
     }
 
     bool _is_transpose_X{false};
     bool _is_transpose_Y{false};
-    int _M = 0;
-    int _N = 0;
-    int _K = 0;
-    int _B = 0;//batch_size
+    int _m = 0;
+    int _n = 0;
+    int _k = 0;
+    int _b = 0;//batch_size
 
 };
 
-    
 //should design this one for pick_best_specify()
 enum ImplEnum{
     VENDER_IMPL = 0,
     SABER_IMPL
 };
 
-
-
-
 enum SequencePoolType{
     Sequence_pool_unknow = 0,
     Sequence_pool_average,
@@ -190,71 +187,83 @@ private:
 };
 
 template <typename opTensor>
-struct LSTMParam{
-
+struct LstmParam{
 
-
-    LSTMParam() :
-             weight_tensor(nullptr)
+    LstmParam() :
+            weight_tensor(nullptr)
             ,bias_tensor(nullptr)
             ,init_hidden_tensor(nullptr)
             ,dropout_param(1.0f)
             ,num_direction(1)
             ,num_layers(1)
             ,is_reverse(false)
+            ,input_activity(Active_unknow)
             ,gate_activity(Active_sigmoid)
             ,cell_activity(Active_tanh)
             ,candidate_activity(Active_tanh)
             ,with_peephole(true)
-
-    {}
-
-    LSTMParam(opTensor* weight_in, opTensor* bias_in,
-             ActiveType gate_activity_in=Active_sigmoid, ActiveType cell_activity_in=Active_tanh,
-                     ActiveType candidate_activity_in=Active_tanh,bool with_peephole_in=true,
-             bool is_reverse_in=false,opTensor* hidden_init_in=nullptr,
-             float dropout_param_in=1.f
-            ,int num_direction_in=1,int numLayers_in=1)
+            ,skip_input(false)
+
+    {}
+
+    LstmParam(opTensor* weight_in, opTensor* bias_in,
+              opTensor* hidden_init_in = nullptr,
+              ActiveType input_activity = Active_unknow,
+              ActiveType gate_activity_in = Active_sigmoid,
+              ActiveType cell_activity_in = Active_tanh,
+              ActiveType candidate_activity_in = Active_tanh,
+              bool with_peephole_in = true,
+              bool skip_input_in = false,
+              bool is_reverse_in = false,
+              float dropout_param_in = 1.f,
+              int num_direction_in = 1,
+              int numLayers_in = 1)
             :
-             weight_tensor(weight_in)
+            weight_tensor(weight_in)
             ,bias_tensor(bias_in)
             ,dropout_param(dropout_param_in)
             ,num_direction(num_direction_in)
             ,num_layers(numLayers_in)
             ,is_reverse(is_reverse_in)
+            ,input_activity(input_activity)
             ,gate_activity(gate_activity_in)
             ,candidate_activity(candidate_activity_in)
             ,cell_activity(cell_activity_in)
             ,init_hidden_tensor(hidden_init_in)
             ,with_peephole(with_peephole_in)
+            ,skip_input(skip_input_in)
     {}
 
 
-    LSTMParam &operator=(const LSTMParam &right) {
+    LstmParam &operator=(const LstmParam &right) {
         weight_tensor = right.weight_tensor;
         dropout_param=right.dropout_param;
         num_direction=right.num_direction;
         num_layers=right.num_layers;
         bias_tensor = right.bias_tensor;
+        input_activity=right.input_activity;
         gate_activity=right.gate_activity;
         cell_activity=right.cell_activity;
         candidate_activity=right.candidate_activity;
         with_peephole=right.with_peephole;
+        skip_input=right.skip_input;
         is_reverse=right.is_reverse;
         init_hidden_tensor=right.init_hidden_tensor;
         return *this;
     }
 
-    bool operator==(const LSTMParam &right) {
+    bool operator==(const LstmParam &right) {
         bool comp_eq = true;
         comp_eq = comp_eq && (weight_tensor == right.weight_tensor);
         comp_eq = comp_eq && (dropout_param == right.dropout_param);
         comp_eq = comp_eq && (num_direction == right.num_direction);
         comp_eq = comp_eq && (num_layers == right.num_layers);
         comp_eq = comp_eq && (bias_tensor == right.bias_tensor);
+        comp_eq = comp_eq && (input_activity==right.input_activity);
         comp_eq = comp_eq && (gate_activity==right.gate_activity);
         comp_eq = comp_eq && (cell_activity==right.cell_activity);
         comp_eq = comp_eq && (with_peephole==right.with_peephole);
+        comp_eq = comp_eq && (skip_input==right.skip_input);
         comp_eq = comp_eq && (candidate_activity==right.candidate_activity);
         comp_eq = comp_eq && (is_reverse=right.is_reverse);
         comp_eq = comp_eq && (init_hidden_tensor==right.init_hidden_tensor);
@@ -276,18 +285,23 @@ struct LSTMParam{
     int num_direction;
     float dropout_param;
     int num_layers;
+    ActiveType input_activity;
     ActiveType gate_activity;
     ActiveType cell_activity;
     ActiveType candidate_activity;
     bool is_reverse;
     bool with_peephole;
+    // skip input (X * [Wix, Wfx, Wcx, Wox]) or not;
+    // if true, the input's memory layout should be total_seq_len * (4 * hidden_size),
+    // and you should calc this information in fc layer before;
+    // otherwise the input's memory layout should be total_seq_len * input_size;
+    bool skip_input;
 private:
     opTensor* weight_tensor;
     opTensor* bias_tensor;
     opTensor* init_hidden_tensor;
 };
 
-
 template <typename opTensor>
 struct ConvParam {
 
@@ -736,27 +750,56 @@ struct BatchnormParam {
 };
 
 template <typename opTensor>
+struct PreluParam {
+    PreluParam() = default;
+    PreluParam(bool is_channel_shared, opTensor* input_slope) {
+        channel_shared = is_channel_shared;
+        slope = input_slope;
+    }
+    PreluParam(const PreluParam<opTensor>& right) {
+        channel_shared = right.channel_shared;
+        slope = right.slope;
+    }
+    PreluParam<opTensor>& operator=(const PreluParam<opTensor>& right) {
+        this->channel_shared = right.channel_shared;
+        this->slope = right.slope;
+        return *this;
+    }
+    bool operator==(const PreluParam<opTensor>& right) {
+        bool flag = this->channel_shared == right.channel_shared;
+        return flag && (this->slope == right.slope);
+    }
+    bool channel_shared{false};
+    opTensor* slope{nullptr};
+};
+
+template <typename opTensor>
 struct ActivationParam {
     typedef typename opTensor::Dtype DataDtype;
     ActivationParam()
             : active(Active_unknow)
             , negative_slope(DataDtype(-1))
-            , coef(DataDtype(-1)) {}
+            , coef(DataDtype(-1))
+            , prelu_param(PreluParam<opTensor>(false, nullptr)) {}
     ActivationParam(ActiveType act, DataDtype n_slope = DataDtype(0),
-                    DataDtype co = DataDtype(1))
+                    DataDtype co = DataDtype(1), 
+                    PreluParam<opTensor> prelu = PreluParam<opTensor>(false, nullptr))
             : active(act)
             , negative_slope(n_slope)
             , coef(co)
+            , prelu_param(prelu)
     {}
     ActivationParam(const ActivationParam &right)
             : active(right.active)
             , negative_slope(right.negative_slope)
             , coef(right.coef)
+            , prelu_param(right.prelu_param)
     {}
     ActivationParam &operator=(const ActivationParam &right) {
         active = right.active;
         negative_slope = right.negative_slope;
         coef = right.coef;
+        prelu_param = right.prelu_param;
         return *this;
     }
     bool operator==(const ActivationParam &right) {
@@ -764,6 +807,7 @@ struct ActivationParam {
         comp_eq = comp_eq && (active == right.active);
         comp_eq = comp_eq && (negative_slope == right.negative_slope);
         comp_eq = comp_eq && (coef == right.coef);
+        comp_eq = comp_eq && (prelu_param == right.prelu_param);
         return comp_eq;
     }
     bool has_negative_slope(){
@@ -772,6 +816,7 @@ struct ActivationParam {
     ActiveType active;
     DataDtype negative_slope;
     DataDtype coef;
+    PreluParam<opTensor> prelu_param;
 };
 template <typename opTensor>
 struct ScaleParam {
@@ -887,6 +932,62 @@ struct PoolingParam {
 };
 
 template <typename opTensor>
+struct SequenceConvParam {
+    SequenceConvParam()
+            : filter_tensor(nullptr),
+              padding_tensor(nullptr),
+              context_length(1),
+              context_start(0),
+              context_stride(1),
+              padding_trainable(false)
+    {}
+    SequenceConvParam(opTensor* filter_tensor_in,int context_length_in,
+                      int context_start_in=0,int context_stride_in=1,bool padding_trainable_in=false,
+                              opTensor* padding_tensor_in= nullptr)
+            : filter_tensor(filter_tensor_in),
+              padding_tensor(padding_tensor_in),
+              context_length(context_length_in),
+              context_start(context_start_in),
+              context_stride(context_stride_in),
+              padding_trainable(padding_trainable_in)
+    {}
+    SequenceConvParam(const SequenceConvParam &right)
+            : filter_tensor(right.filter_tensor),
+              padding_tensor(right.padding_tensor),
+              context_length(right.context_length),
+              context_start(right.context_start),
+              context_stride(right.context_stride),
+              padding_trainable(right.padding_trainable)
+    {}
+    SequenceConvParam &operator=(const SequenceConvParam &right) {
+        filter_tensor=right.filter_tensor;
+        padding_tensor=right.padding_tensor;
+        context_length=right.context_length;
+        context_start=right.context_start;
+        context_stride=right.context_stride;
+        padding_trainable=right.padding_trainable;
+        return *this;
+    }
+    bool operator==(const SequenceConvParam &right) {
+        bool comp_eq = true;
+        comp_eq = comp_eq && (filter_tensor=right.filter_tensor);
+        comp_eq = comp_eq && (padding_tensor=right.padding_tensor);
+        comp_eq = comp_eq && (context_length=right.context_length);
+        comp_eq = comp_eq && (context_start=right.context_start);
+        comp_eq = comp_eq && (context_stride=right.context_stride);
+        comp_eq = comp_eq && (padding_trainable=right.padding_trainable);
+        return comp_eq;
+    }
+
+    opTensor *filter_tensor;
+    opTensor *padding_tensor;
+    int context_length;
+    int context_start;
+    int context_stride;
+    bool padding_trainable;
+};
+
+template <typename opTensor>
 struct SequencePoolParam {
     SequencePoolParam()
             : sequence_pool_type(Sequence_pool_unknow)
@@ -950,14 +1051,21 @@ private:
 
 template <typename opTensor>
 struct EltwiseParam;
+template <typename opTensor>
+struct EltwiseActiveParam;
 // Fusion conv with batchnorm, scale, activation, eltwise(sigmoid, relu, tanh, clipped_relu, elu)
 template <typename opTensor>
 struct ConvActiveParam {
-    ConvActiveParam() : has_batchnorm(false), has_scale(false), has_active(false), has_eltwise(false){}
-
+    ConvActiveParam()
+            : has_batchnorm(false)
+            , has_scale(false)
+            , has_active(false)
+            , has_eltwise(false)
+            , has_eltwise_act(false)
+    {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in)
         : conv_param(conv_param_in), has_active(false)
-        , has_batchnorm(false), has_scale(false), has_eltwise(false)
+        , has_batchnorm(false), has_scale(false), has_eltwise(false), has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in,
                     ActivationParam<opTensor> &activation_param_in)
@@ -966,6 +1074,7 @@ struct ConvActiveParam {
         , has_scale(false)
         , has_active(true)
         , has_eltwise(false)
+        , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
                     , ActivationParam<opTensor> &activation_param_in
@@ -977,6 +1086,7 @@ struct ConvActiveParam {
         , has_scale(false)
         , has_active(true)
         , has_eltwise(true)
+        , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -988,6 +1098,7 @@ struct ConvActiveParam {
             , has_scale(false)
             , has_active(true)
             , has_eltwise(false)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -1001,6 +1112,7 @@ struct ConvActiveParam {
             , has_scale(false)
             , has_active(true)
             , has_eltwise(true)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -1012,6 +1124,7 @@ struct ConvActiveParam {
             , has_scale(true)
             , has_active(true)
             , has_eltwise(false)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -1025,6 +1138,7 @@ struct ConvActiveParam {
             , has_scale(true)
             , has_active(true)
             , has_eltwise(true)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -1038,6 +1152,7 @@ struct ConvActiveParam {
             , has_scale(true)
             , has_active(true)
             , has_eltwise(false)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , BatchnormParam<opTensor> &batchnorm_param_in
@@ -1049,6 +1164,21 @@ struct ConvActiveParam {
             , has_scale(true)
             , has_active(false)
             , has_eltwise(false)
+            , has_eltwise_act(false)
+    {}
+    ConvActiveParam(ConvParam<opTensor> &conv_param_in
+            , BatchnormParam<opTensor> &batchnorm_param_in
+            , ScaleParam<opTensor> &scale_param_in
+            , EltwiseActiveParam<opTensor> &elt_act_param_in)
+            : conv_param(conv_param_in)
+            , batchnorm_param(batchnorm_param_in)
+            , scale_param(scale_param_in)
+            , eltwise_act_param(elt_act_param_in)
+            , has_batchnorm(true)
+            , has_scale(true)
+            , has_active(false)
+            , has_eltwise(false)
+            , has_eltwise_act(true)
     {}
     ConvActiveParam(ConvParam<opTensor> &conv_param_in
             , ActivationParam<opTensor> &activation_param_in
@@ -1064,6 +1194,7 @@ struct ConvActiveParam {
             , has_scale(true)
             , has_active(true)
             , has_eltwise(true)
+            , has_eltwise_act(false)
     {}
     ConvActiveParam(const ConvActiveParam &right)
             : conv_param(right.conv_param)
@@ -1073,6 +1204,7 @@ struct ConvActiveParam {
             , has_batchnorm(right.has_batchnorm)
             , has_scale(right.has_scale)
             , has_active(right.has_active)
+            , has_eltwise_act(right.has_active)
     {}
     ConvActiveParam &operator=(const ConvActiveParam &right) {
         conv_param = right.conv_param;
@@ -1082,6 +1214,8 @@ struct ConvActiveParam {
         has_batchnorm = right.has_batchnorm;
         has_scale = right.has_scale;
         has_active = right.has_active;
+        has_eltwise = right.has_eltwise;
+        has_eltwise_act = right.has_eltwise_act;
         return *this;
     }
     bool operator==(const ConvActiveParam &right) {
@@ -1092,6 +1226,9 @@ struct ConvActiveParam {
         comp_eq = comp_eq && (scale_param == right.scale_param);
         comp_eq = comp_eq && (has_batchnorm == right.has_batchnorm);
         comp_eq = comp_eq && (has_scale == right.has_scale);
+        comp_eq = comp_eq && (has_active == right.has_active);
+        comp_eq = comp_eq && (has_eltwise == right.has_eltwise);
+        comp_eq = comp_eq && (has_eltwise_act == right.has_eltwise_act);
         return comp_eq;
     }
     ConvParam<opTensor> conv_param;
@@ -1099,10 +1236,13 @@ struct ConvActiveParam {
     BatchnormParam<opTensor> batchnorm_param;
     ScaleParam<opTensor> scale_param;
     EltwiseParam<opTensor> eltwise_param;
+    EltwiseActiveParam<opTensor> eltwise_act_param;
+
     bool has_batchnorm;
     bool has_scale;
     bool has_active;
     bool has_eltwise;
+    bool has_eltwise_act;
 };
 // Fusion conv with batchnorm, scale, activation(sigmoid, relu, tanh, clipped_relu, elu)
 template <typename opTensor>
@@ -1223,29 +1363,6 @@ struct ResizeParam {
     float width_scale{0.f};
     float height_scale{0.f};
 };
-template <typename opTensor>
-struct PreluParam {
-    PreluParam() = default;
-    PreluParam(bool is_channel_shared, opTensor* input_slope) {
-        channel_shared = is_channel_shared;
-        slope = input_slope;
-    }
-    PreluParam(const PreluParam<opTensor>& right) {
-        channel_shared = right.channel_shared;
-        slope = right.slope;
-    }
-    PreluParam<opTensor>& operator=(const PreluParam<opTensor>& right) {
-        this->channel_shared = right.channel_shared;
-        this->slope = right.slope;
-        return *this;
-    }
-    bool operator==(const PreluParam<opTensor>& right) {
-        bool flag = this->channel_shared == right.channel_shared;
-        return flag && (this->slope == right.slope);
-    }
-    bool channel_shared{false};
-    opTensor* slope{nullptr};
-};
 
 template <typename opTensor>
 struct MvnParam {
@@ -1493,6 +1610,7 @@ struct EltwiseParam {
         for (int i = 0; i < coeff.size(); ++i) {
             comp_eq = comp_eq && (coeff[i] == right.coeff[i]);
         }
+        return comp_eq;
     }
     EltwiseType operation;
     std::vector<DataDtype> coeff;
@@ -1542,7 +1660,7 @@ struct PriorBoxParam {
     PriorBoxParam(std::vector<float> min_in, std::vector<float> max_in, \
         std::vector<float> aspect_in, std::vector<float> variance_in,
         bool flip, bool clip, int image_width, int image_height, \
-        float step_width, float step_height, float offset_in) {
+        float step_width, float step_height, float offset_in, std::vector<PriorType> order_in) {
         is_flip = flip;
         is_clip = clip;
         min_size = min_in;
@@ -1551,6 +1669,7 @@ struct PriorBoxParam {
         step_w = step_width;
         step_h = step_height;
         offset = offset_in;
+        order = order_in;
         aspect_ratio.clear();
         aspect_ratio.push_back(1.f);
 
@@ -1607,6 +1726,7 @@ struct PriorBoxParam {
         step_w = right.step_w;
         step_h = right.step_h;
         offset = right.offset;
+        order = right.order;
         prior_num = right.prior_num;
     }
     PriorBoxParam<opTensor>& operator=(const PriorBoxParam<opTensor>& right) {
@@ -1621,6 +1741,7 @@ struct PriorBoxParam {
         this->step_w = right.step_w;
         this->step_h = right.step_h;
         this->offset = right.offset;
+        this->order = right.order;
         this->prior_num = right.prior_num;
         return *this;
     }
@@ -1664,6 +1785,7 @@ struct PriorBoxParam {
         flag = flag && (step_w == right.step_w);
         flag = flag && (step_h == right.step_h);
         flag = flag && (offset == right.offset);
+        flag = flag && (order == right.order);
         flag = flag && (prior_num == right.prior_num);
         return flag;
     }
@@ -1680,8 +1802,8 @@ struct PriorBoxParam {
     float step_h{0};
     float offset{0.5};
     int prior_num{0};
+    std::vector<PriorType> order;
 };
-
 template <typename opTensor>
 struct DeformableConvParam {
 
@@ -2232,7 +2354,7 @@ template <class opTensor>
 struct FlattenParam {
     FlattenParam() = default;
     FlattenParam(const FlattenParam& right) {}
-    FlattenParam& operator=(const FlattenParam& right){}
+    FlattenParam& operator=(const FlattenParam& right){ return *this;}
     bool operator==(const FlattenParam& right){
         return true;
     }
@@ -2240,8 +2362,8 @@ struct FlattenParam {
 template <class opTensor>
 struct AxpyParam {
     AxpyParam() = default;
-    AxpyParam(const AxpyParam& right) {}
-    AxpyParam& operator=(const AxpyParam& right){}
+    AxpyParam(const AxpyParam& right) { }
+    AxpyParam& operator=(const AxpyParam& right){ return *this;}
     bool operator==(const AxpyParam& right){
         return true;
     }
@@ -2319,6 +2441,7 @@ struct Im2SequenceParam {
         stride_w = right.stride_w;
         dilation_h = right.dilation_h;
         dilation_w = right.dilation_w;
+        return *this;
     }
     bool operator==(const Im2SequenceParam &right) {
         bool comp_eq = true;
diff --git a/saber/saber_types.h b/saber/saber_types.h
index fbb95db..2c41e17 100644
--- a/saber/saber_types.h
+++ b/saber/saber_types.h
@@ -1,16 +1,17 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
-   http://www.apache.org/licenses/LICENSE-2.0
+       http://www.apache.org/licenses/LICENSE-2.0
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
-   limitations under the License. */
+   limitations under the License.
+*/
 
 #ifndef ANAKIN_SABER_CORE_TYPES_H
 #define ANAKIN_SABER_CORE_TYPES_H
@@ -113,10 +114,12 @@ typedef enum{
     Active_relu = 2,
     Active_tanh = 3,
     Active_clipped_relu = 4,
-    Active_elu=5,
-    Active_identity=6,
-    Active_sigmoid_fluid=7,
-    Active_tanh_fluid=8
+    Active_elu = 5,
+    Active_identity = 6,
+    Active_sigmoid_fluid = 7,
+    Active_tanh_fluid = 8,
+    Active_stanh = 9,
+    Active_prelu = 10
 
 } ActiveType;
 
@@ -162,6 +165,12 @@ typedef enum {
     BORDER_REPLICATE
 } BorderType;
 
+typedef enum {
+    PRIOR_MIN = 0,
+    PRIOR_MAX = 1,
+    PRIOR_COM = 2
+} PriorType;
+
 } //namespace saber
 
 } //namespace anakin
diff --git a/saber/utils.h b/saber/utils.h
index 31b5759..4e1ad87 100644
--- a/saber/utils.h
+++ b/saber/utils.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/CMakeLists.txt b/test/CMakeLists.txt
index 157dffd..c36887c 100644
--- a/test/CMakeLists.txt
+++ b/test/CMakeLists.txt
@@ -1,9 +1,17 @@
-# ----------------------------------------------------------------------------
-# Copyright (c) 2016 Baidu.com, Inc. All Rights Reserved
-# @file     CMakeLists files in the unit test directory of project
-# @auther   cuichaowen
-# @date     2017-10-24
-# ----------------------------------------------------------------------------
+# Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 # used for temporary
 anakin_fetch_include_recursively(${ANAKIN_FRAMEWORK})
 anakin_fetch_include_recursively(${ANAKIN_MODEL_PARSER})
@@ -33,6 +41,15 @@ if(USE_ARM_PLACE) #build unit test for arm devices
 	if(USE_OPENMP)
 		set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fopenmp")
 	endif()
+#	if (USE_PROTOBUF)
+#		find_library( # Sets the name of the path variable.
+#				log-lib
+#
+#				# Specifies the name of the NDK library that
+#				# you want CMake to locate.
+#				log )
+#	endif()
+
 endif()
 
 file(REMOVE ${PROJECT_SOURCE_DIR}/output/unit_test/*)
@@ -47,10 +64,13 @@ foreach(SRC_NAME ${ANAKIN_TEST_CASE_SRC})
 	list(GET SEXY_LIST 0 TEST_CASE_NAME)
 	add_executable(${TEST_CASE_NAME}  ${SRC_NAME})
 	if(BUILD_SHARED)
-        	target_link_libraries(${TEST_CASE_NAME} ${anakin_lib_so})
-    	else()
-        	target_link_libraries(${TEST_CASE_NAME} ${anakin_lib_static})
-    	endif()	
+		target_link_libraries(${TEST_CASE_NAME} ${anakin_lib_so})
+	else()
+		target_link_libraries(${TEST_CASE_NAME} -Wl,--whole-archive ${anakin_lib_static} -Wl,--no-whole-archive)
+	endif()
+#	if(USE_ARM_PLACE)
+#		target_link_libraries(${TEST_CASE_NAME} ${log-lib})
+#	endif()
 	set_target_properties(${TEST_CASE_NAME} PROPERTIES
 						RUNTIME_OUTPUT_DIRECTORY 
 						${PROJECT_SOURCE_DIR}/output/unit_test)
diff --git a/test/framework/core/core_test.h b/test/framework/core/core_test.h
index 6107eef..b7a78fa 100644
--- a/test/framework/core/core_test.h
+++ b/test/framework/core/core_test.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/framework/graph/graph_test.h b/test/framework/graph/graph_test.h
index db837c8..1402509 100644
--- a/test/framework/graph/graph_test.h
+++ b/test/framework/graph/graph_test.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/framework/net/benchmark.cpp b/test/framework/net/benchmark.cpp
index 41c31c8..04f3681 100644
--- a/test/framework/net/benchmark.cpp
+++ b/test/framework/net/benchmark.cpp
@@ -9,6 +9,18 @@
 #include <unistd.h>  
 #include <fcntl.h>
 #include <map>
+#include "framework/operators/ops.h"
+
+#if defined(USE_CUDA)
+using Target = NV;
+using Target_H = X86;
+#elif defined(USE_X86_PLACE)
+using Target = X86;
+using Target_H = X86;
+#elif defined(USE_ARM_PLACE)
+using Target = ARM;
+using Target_H = ARM;
+#endif
 
 #ifdef USE_GFLAGS
 #include <gflags/gflags.h>
@@ -26,14 +38,6 @@ int FLAGS_warmup_iter = 10;
 int FLAGS_epoch = 1000;
 #endif
 
-#ifdef USE_CUDA
-typedef NV Target;
-#elif defined(USE_X86_PLACE)
-typedef X86 Target;
-#else
-typedef ARM Target;
-#endif
-
 void getModels(std::string path, std::vector<std::string>& files) {
     DIR *dir;
     struct dirent *ptr;
@@ -67,13 +71,17 @@ TEST(NetTest, net_execute_base_test) {
         if (!status) {
             LOG(FATAL) << " [ERROR] " << status.info();
         }
-        graph.ResetBatchSize("input_0", FLAGS_num);        
+        LOG(INFO) << "set batchsize to " << FLAGS_num;
+        graph.ResetBatchSize("input_0", FLAGS_num);
+        LOG(INFO) << "optimize the graph";
         graph.Optimize();
         // constructs the executer net
+        LOG(INFO) << "create net to execute";
         Net<Target, AK_FLOAT, Precision::FP32> net_executer(graph, true);
         // get in
+        LOG(INFO) << "get input";
         auto d_tensor_in_p = net_executer.get_in("input_0");
-        Tensor4d<X86, AK_FLOAT> h_tensor_in;
+        Tensor4d<Target_H, AK_FLOAT> h_tensor_in;
         auto valid_shape_in = d_tensor_in_p->valid_shape();
         for (int i = 0; i < valid_shape_in.size(); i++) {
             LOG(INFO) << "detect input dims[" << i << "]" << valid_shape_in[i];
@@ -125,6 +133,9 @@ TEST(NetTest, net_execute_base_test) {
     }
 }
 int main(int argc, const char** argv){
+
+    Env<Target>::env_init();
+
     // initial logger
     logger::init(argv[0]);
 
diff --git a/test/framework/net/benchmark_arm.cpp b/test/framework/net/benchmark_arm.cpp
new file mode 100644
index 0000000..b479c9a
--- /dev/null
+++ b/test/framework/net/benchmark_arm.cpp
@@ -0,0 +1,203 @@
+#include <string>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h> 
+#include <sys/stat.h> 
+#include <sys/types.h> 
+#include <unistd.h>  
+#include <fcntl.h>
+#include <map>
+#ifdef USE_ARM_PLACE
+#ifdef USE_GFLAGS
+#include <gflags/gflags.h>
+
+DEFINE_string(model_dir, "", "model dir");
+DEFINE_string(model_file, "", "model file");
+DEFINE_int32(num, 1, "batchSize");
+DEFINE_int32(warmup_iter, 10, "warm up iterations");
+DEFINE_int32(epoch, 1000, "time statistic epoch");
+#else
+std::string FLAGS_model_dir;
+std::string FLAGS_model_file;
+int FLAGS_num = 1;
+int FLAGS_warmup_iter = 10;
+int FLAGS_epoch = 10;
+int FLAGS_threads = 1;
+#endif
+
+using Target = ARM;
+using Target_H = ARM;
+
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR *dir;
+    struct dirent *ptr;
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+    while((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0)
+            continue;
+        else if (ptr->d_type == 8)//file
+            files.push_back(path + "/" + ptr->d_name);
+        else if (ptr->d_type == 4) {
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+    closedir(dir);
+}
+TEST(NetTest, net_execute_base_test) {
+
+    std::shared_ptr<Context<ARM>> ctx1 = std::make_shared<Context<ARM>>();
+
+    ctx1->set_run_mode(SABER_POWER_HIGH, FLAGS_threads);
+
+    LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+        LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    std::vector<std::string> models;
+    if (FLAGS_model_file == "") {
+        getModels(FLAGS_model_dir, models);
+    } else {
+        models.push_back(FLAGS_model_dir + FLAGS_model_file);
+    }
+    for (auto iter = models.begin(); iter < models.end(); iter++)
+    {
+        LOG(WARNING) << "load anakin model file from " << *iter << " ...";
+        Graph<Target, AK_FLOAT, Precision::FP32> graph;   
+        auto status = graph.load(*iter);
+        if (!status) {
+            LOG(FATAL) << " [ERROR] " << status.info();
+        }
+        LOG(INFO) << "set batchsize to " << FLAGS_num;
+        graph.ResetBatchSize("input_0", FLAGS_num);
+        LOG(INFO) << "optimize the graph";
+        graph.Optimize();
+        // constructs the executer net
+        LOG(INFO) << "create net to execute";
+        Net<Target, AK_FLOAT, Precision::FP32, OpRunType::SYNC> net_executer(graph, ctx1, true);
+        // get in
+        LOG(INFO) << "get input";
+        auto d_tensor_in_p = net_executer.get_in("input_0");
+        Tensor4d<Target_H, AK_FLOAT> h_tensor_in;
+        auto valid_shape_in = d_tensor_in_p->valid_shape();
+        for (int i = 0; i < valid_shape_in.size(); i++) {
+            LOG(INFO) << "detect input dims[" << i << "]" << valid_shape_in[i];
+        }
+        h_tensor_in.re_alloc(valid_shape_in);
+        fill_tensor_host_rand(h_tensor_in, -1.0f,1.0f);
+        d_tensor_in_p->copy_from(h_tensor_in);
+        // do inference
+        Context<Target> ctx(0, 0, 0);
+        saber::SaberTimer<Target> my_time;
+        LOG(WARNING) << "EXECUTER !!!!!!!! ";
+        for (int i = 0; i < FLAGS_warmup_iter; i++) {
+            net_executer.prediction();
+        }
+#ifdef ENABLE_OP_TIMER
+        net_executer.reset_op_time();
+#endif
+        double to = 0;
+        double tmin = 1000000;
+        double tmax = 0;
+        my_time.start(ctx);
+        saber::SaberTimer<Target> t1;
+        for (int i = 0; i < FLAGS_epoch; i++) {
+            t1.clear();
+            t1.start(ctx);
+            net_executer.prediction();
+            t1.end(ctx);
+            double tdiff = t1.get_average_ms();
+            if (tdiff > tmax) {
+                tmax = tdiff;
+            }
+            if (tdiff < tmin) {
+                tmin = tdiff;
+            }
+            to += tdiff;
+            LOG(INFO) << "iter: " << i << ", time: " << tdiff << "ms";
+        }
+        my_time.end(ctx);
+#ifdef ENABLE_OP_TIMER
+        std::vector<float> op_time = net_executer.get_op_time();
+        auto exec_funcs = net_executer.get_exec_funcs();
+        auto op_param = net_executer.get_op_param();
+        for (int i = 0; i <  op_time.size(); i++) {
+            LOG(INFO) << "name: " << exec_funcs[i].name << " op_type: " << exec_funcs[i].op_name << " op_param: " << op_param[i] << " time " << op_time[i]/FLAGS_epoch;
+        }
+        std::map<std::string, float> op_map;
+        for (int i = 0; i < op_time.size(); i++) {
+            auto it = op_map.find(op_param[i]);
+            if (it != op_map.end())
+                op_map[op_param[i]] += op_time[i];
+            else
+                op_map.insert(std::pair<std::string, float>(op_param[i], op_time[i]));
+        }
+        for (auto it = op_map.begin(); it != op_map.end(); ++it) {
+            LOG(INFO)<< it->first << "  " << (it->second) / FLAGS_epoch<< " ms";
+        }
+#endif
+        size_t end = (*iter).find(".anakin.bin");
+        size_t start = FLAGS_model_dir.length();
+        std::string model_name = (*iter).substr(start, end-start);
+        
+        LOG(INFO) << model_name << " batch_size " << FLAGS_num << " average time " << to/ FLAGS_epoch << \
+            ", min time: " << tmin << "ms, max time: " << tmax << " ms";
+       //my_time.get_average_ms() / FLAGS_epoch << " ms";
+    }
+}
+int main(int argc, const char** argv){
+
+    Env<Target>::env_init();
+    // initial logger
+    logger::init(argv[0]);
+
+#ifdef USE_GFLAGS
+    google::ParseCommandLineFlags(&argc, &argv, true);
+#else 
+    LOG(INFO)<< "BenchMark usage:";
+    LOG(INFO)<< "   $benchmark <model_dir> <model_file> <num> <warmup_iter> <epoch>";
+    LOG(INFO)<< "   model_dir:      model directory";
+    LOG(INFO)<< "   model_file:     path to model";
+    LOG(INFO)<< "   num:            batchSize default to 1";
+    LOG(INFO)<< "   warmup_iter:    warm up iterations default to 10";
+    LOG(INFO)<< "   epoch:          time statistic epoch default to 1000";
+    if(argc < 3) {
+        LOG(ERROR) << "You should fill in the variable model_dir and model_file at least.";
+        return 0;
+    }
+    FLAGS_model_dir = argv[1];
+    if(argc > 2) {
+        FLAGS_model_file = argv[2];
+    }
+    if(argc > 3) {
+        FLAGS_num = atoi(argv[3]);
+    }
+    if(argc > 4) {
+        FLAGS_warmup_iter = atoi(argv[4]);
+    }
+    if(argc > 5) {
+        FLAGS_epoch = atoi(argv[5]);
+    }
+    if(argc > 6) {
+        FLAGS_threads = atoi(argv[6]);
+    }
+#endif
+    InitTest();
+    RUN_ALL_TESTS(argv[0]); 
+    return 0;
+}
+
+#else
+int main(int argc, const char** argv) {
+    LOG(INFO) << "this benchmark is only for arm device";
+}
+#endif
\ No newline at end of file
diff --git a/test/framework/net/chinese_ner_test.cpp b/test/framework/net/chinese_ner_test.cpp
index 37785f7..1aa4340 100644
--- a/test/framework/net/chinese_ner_test.cpp
+++ b/test/framework/net/chinese_ner_test.cpp
@@ -17,6 +17,18 @@
 DEFINE_GLOBAL(std::string, model_dir, "");
 DEFINE_GLOBAL(std::string, input_file, "");
 
+
+#if defined(USE_CUDA)
+using Target = NV;
+using Target_H = X86;
+#elif defined(USE_X86_PLACE)
+using Target = X86;
+using Target_H = X86;
+#elif defined(USE_ARM_PLACE)
+using Target = ARM;
+using Target_H = ARM;
+#endif
+
 //#define WITH_MENTION
 
 void getModels(std::string path, std::vector<std::string>& files) {
@@ -194,6 +206,7 @@ TEST(NetTest, chinese_ner_executor) {
 #endif
 
 int main(int argc, const char** argv) {
+    Env<Target>::env_init();
     // initial logger
     LOG(INFO) << "argc " << argc;
 
diff --git a/test/framework/net/model_test.cpp b/test/framework/net/model_test.cpp
index 1f8055d..b2fe441 100644
--- a/test/framework/net/model_test.cpp
+++ b/test/framework/net/model_test.cpp
@@ -18,6 +18,17 @@ DEFINE_GLOBAL(int, height, 640);
 DEFINE_GLOBAL(int, width, 640);
 DEFINE_GLOBAL(bool, is_input_shape, false);
 
+#if defined(USE_CUDA)
+using Target = NV;
+using Target_H = X86;
+#elif defined(USE_X86_PLACE)
+using Target = X86;
+using Target_H = X86;
+#elif defined(USE_ARM_PLACE)
+using Target = ARM;
+using Target_H = ARM;
+#endif
+
 void getModels(std::string path, std::vector<std::string>& files) {
     DIR* dir= nullptr;
     struct dirent* ptr;
@@ -67,7 +78,7 @@ TEST(NetTest, nv_net_execute_base_test) {
         Net<NV, AK_FLOAT, Precision::FP32> net_executer(graph, true);
         // get in
         auto d_tensor_in_p = net_executer.get_in("input_0");
-        Tensor4d<X86, AK_FLOAT> h_tensor_in;
+        Tensor4d<Target_H, AK_FLOAT> h_tensor_in;
         auto valid_shape_in = d_tensor_in_p->valid_shape();
 
         for (int i = 0; i < valid_shape_in.size(); i++) {
@@ -140,6 +151,9 @@ TEST(NetTest, nv_net_execute_base_test) {
 #endif
 
 int main(int argc, const char** argv) {
+
+    Env<Target>::env_init();
+
     // initial logger
     LOG(INFO) << "argc " << argc;
 
diff --git a/test/framework/net/net_exec_multi_thread_test.cpp b/test/framework/net/net_exec_multi_thread_test.cpp
index 547827d..838ec68 100644
--- a/test/framework/net/net_exec_multi_thread_test.cpp
+++ b/test/framework/net/net_exec_multi_thread_test.cpp
@@ -3,9 +3,17 @@
 #include "saber/funcs/timer.h"
 #include <chrono>
 
-//std::string model_path = "/home/chaowen/anakin_v2/model_v2/anakin-models/adu/anakin_models/diepsie_light_head/yolo_lane_v2.anakin.bin";
-std::string model_path = "/home/cuichaowen/anakin2/anakin2/benchmark/CNN/models/vgg16.anakin.bin";
-
+#if defined(USE_CUDA)
+using Target = NV;
+using Target_H = X86;
+#elif defined(USE_X86_PLACE)
+using Target = X86;
+using Target_H = X86;
+#elif defined(USE_ARM_PLACE)
+using Target = ARM;
+using Target_H = ARM;
+#endif
+std::string model_path = "/home/chaowen/anakin_v2/model_v2/anakin-models/adu/anakin_models/diepsie_light_head/yolo_lane_v2.anakin.bin";
 
 #ifdef USE_CUDA
 #if 0
@@ -143,6 +151,9 @@ TEST(NetTest, net_execute_muti_thread_async_test) {
 #endif
 
 int main(int argc, const char** argv){
+
+	Env<Target>::env_init();
+
     // initial logger
     logger::init(argv[0]);
 	InitTest();
diff --git a/test/framework/net/net_exec_nv_rnn_oneinput.cpp b/test/framework/net/net_exec_nv_rnn_oneinput.cpp
new file mode 100644
index 0000000..ed4b8c1
--- /dev/null
+++ b/test/framework/net/net_exec_nv_rnn_oneinput.cpp
@@ -0,0 +1,461 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+#include "sys/time.h"
+#include "debug.h"
+#include "string"
+
+#ifdef USE_CUDA
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+DEFINE_GLOBAL(std::string, split_word, "\t");
+DEFINE_GLOBAL(std::string, output_name, "");
+DEFINE_GLOBAL(std::string, run_mode, "instance");
+DEFINE_GLOBAL(int, split_index, 0);
+
+//#define AVG_INPUT
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir = nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+
+    closedir(dir);
+}
+
+int read_file(std::vector<float>& results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+
+    LOG(INFO) << "found filename: " << file_name;
+    std::string line;
+
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c) {
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+
+    while (std::string::npos != pos2) {
+        v.push_back(s.substr(pos1, pos2 - pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+
+    if (pos1 != s.length()) {
+        v.push_back(s.substr(pos1));
+    }
+}
+
+int split_word_from_file(
+    std::vector<std::vector<float> >& word_idx,
+    const std::string input_file_path,
+    const std::string split_token,
+    const std::string inner_split_token,
+    const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+
+    LOG(INFO) << "found filename: " << input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count = 0;
+
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+        CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+            //            printf("%d,",atoi(w.c_str()));
+        }
+
+        //        printf("\n");
+        //        exit(0);
+        word_idx.push_back(word);
+    }
+
+    GLB_word_count = word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+    std::vector<float>& out_data,
+    const std::vector<std::vector<float> >& seq_data,
+    std::vector<int>& seq_offset,
+    const int start_idx,
+    const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+            //            printf("%.0f, ",d);
+        }
+
+        //        printf("\n");
+        seq_offset.push_back(len);
+    }
+
+    return len;
+}
+
+void anakin_net_thread(std::vector<Tensor4dPtr<NV, AK_FLOAT> >* data_in, std::string model_path
+                      , bool is_save_result=false,int thread_id=0) {
+    Graph<NV, AK_FLOAT, Precision::FP32>* graph = new Graph<NV, AK_FLOAT, Precision::FP32>();
+    LOG(WARNING) << "load anakin model file from " << model_path << " ... ";
+    // load anakin model files.
+    auto status = graph->load(model_path);
+    if (!status) {
+        LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    graph->Reshape("input_0", {GLB_max_word_len, 1, 1, 1});
+    //anakin graph optimization
+    graph->Optimize();
+    Net<NV, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+    //    SaberTimer<X86> timer;
+    //    Context<X86> ctx;
+    struct timeval time_start, time_end;
+
+    int slice_10 = data_in->size() / 10;
+    slice_10 = slice_10 > 0 ? slice_10 : 1;
+    int word_sum = 0;
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < data_in->size(); ++i) {
+        auto input_tensor = (*data_in)[i];
+        auto word_in_p = net_executer.get_in("input_0");
+        int len_sum = input_tensor->valid_size();
+        word_in_p->reshape({len_sum, 1, 1, 1});
+        word_sum += len_sum;
+
+        word_in_p->copy_from(*input_tensor);
+
+        word_in_p->set_seq_offset(input_tensor->get_seq_offset());
+        //        timer.start(ctx);
+//        LOG(INFO)<<"ready to prediction size = "<<input_tensor->get_seq_offset().size();
+        net_executer.prediction();
+
+
+        if(is_save_result) {
+            int k = net_executer.get_out_list().size();
+                    LOG(INFO) << "out size = " << k;
+            auto outs = net_executer.get_out(GLB_output_name);
+            int out_cnt = 0;
+            record_dev_tensorfile(outs,("output_" + std::to_string(thread_id) + "_" + std::to_string(i)+ ".txt").data());
+        }
+
+//        out_cnt++;
+
+        //        timer.end(ctx);
+        if (i % slice_10 == 0) {
+            LOG(INFO) << "thread run " << i << " of " << data_in->size();
+        }
+    }
+    cudaDeviceSynchronize();
+    gettimeofday(&time_end, nullptr);
+    float use_ms = (time_end.tv_sec - time_start.tv_sec) * 1000.f + (time_end.tv_usec -
+                   time_start.tv_usec) / 1000.f;
+    LOG(INFO) << "summary_thread :thread total : " << use_ms << " ms, avg = " <<
+              (use_ms / data_in->size()) << ", consume words = " << word_sum;
+    free(graph);
+}
+
+
+std::string get_model_path(){
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+    return models[0];
+}
+std::vector<std::vector<float> > get_input_data(){
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, GLB_split_word, " ", GLB_split_index)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+    return word_idx;
+};
+std::vector<std::vector<Tensor<NV, AK_FLOAT>* >> get_slice_input_data(std::vector<std::vector<float> > &word_idx,
+                                                                       int thread_num,int &real_max_batch_word_len,int batch_num){
+    std::vector<std::vector<Tensor<NV, AK_FLOAT>* >> host_tensor_p_in_list;
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    for (int tid = 0; tid < thread_num; ++tid) {
+        std::vector<Tensor<NV, AK_FLOAT>* > data4thread;
+        int start_wordid = tid * (word_idx.size() / thread_num);
+        int end_wordid = (tid + 1) * (word_idx.size() / thread_num);
+
+        for (int i = start_wordid; i < end_wordid; i += batch_num) {
+            int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+            real_max_batch_word_len = real_max_batch_word_len < word_len ? word_len : real_max_batch_word_len;
+            saber::Shape valid_shape({word_len, 1, 1, 1});
+            Tensor4d<NV, AK_FLOAT>* tensor_p = new Tensor4d<NV, AK_FLOAT>(valid_shape);
+            Tensor4d<NVHX86, AK_FLOAT> temp_tensor(valid_shape);
+                    CHECK_EQ(word_len, word_idx_data.size()) << "word_len == word_idx_data.size";
+
+            for (int j = 0; j < word_idx_data.size(); ++j) {
+                temp_tensor.mutable_data()[j] = word_idx_data[j];
+            }
+            tensor_p->copy_from(temp_tensor);
+
+            tensor_p->set_seq_offset(word_seq_offset);
+            data4thread.push_back(tensor_p);
+        }
+        host_tensor_p_in_list.push_back(data4thread);
+    }
+    return host_tensor_p_in_list;
+};
+void instance_run(){
+
+    std::string model_path=get_model_path();
+
+
+    std::vector<std::vector<float> > word_idx;
+    word_idx=get_input_data();
+
+    int batch_num = GLB_batch_size;
+    int thread_num = GLB_run_threads;
+
+    int real_max_batch_word_len = 0;
+
+
+    std::vector<std::vector<Tensor<NV, AK_FLOAT>* >> host_tensor_p_in_list;
+#ifdef AVG_INPUT
+    host_tensor_p_in_list=get_slice_input_data(word_idx,1,real_max_batch_word_len,batch_num);
+#else
+    host_tensor_p_in_list=get_slice_input_data(word_idx,thread_num,real_max_batch_word_len,batch_num);
+#endif
+
+
+    GLB_max_word_len = real_max_batch_word_len;
+
+    if(real_max_batch_word_len<=0){
+        LOG(INFO)<<"can`t read any data";
+        exit(-1);
+    }
+
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+        LOG(INFO) << "splite  " << i << " in " << GLB_split_word.size() << "  is " << int(char(
+        GLB_split_word[i]));
+    }
+
+
+    LOG(WARNING) << "Async Runing multi_threads for model: " << model_path << ",batch dim = " <<
+                 batch_num
+                 << ",line num = " << word_idx.size() << ", number of word = " << GLB_word_count <<
+                 ",thread number size = " << thread_num << ",real max = " << real_max_batch_word_len;
+
+    std::vector<std::unique_ptr<std::thread>> threads;
+    struct timeval time_start, time_end;
+
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < thread_num; ++i) {
+#ifdef AVG_INPUT
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[0], model_path,GLB_output_name!="",i));
+#else
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i], model_path,GLB_output_name!="",i));
+#endif
+        //        threads.emplace_back(
+        //                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i]),models[0]);
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+
+    gettimeofday(&time_end, nullptr);
+    float use_ms = (time_end.tv_sec - time_start.tv_sec) * 1000.f + (time_end.tv_usec -
+                                                                     time_start.tv_usec) / 1000.f;
+
+            LOG(INFO) << "summary: " << "thread num = " << thread_num << ",total time = " << use_ms <<
+                      "ms ,batch = " << batch_num
+                      << ",word sum = " << GLB_word_count << ", seconde/line = " << (use_ms / word_idx.size())
+#ifdef AVG_INPUT
+                      << ",AVG_INPUT QPS  = " << (thread_num*word_idx.size() / use_ms * 1000)
+                      <<"line/second, "<<(GLB_word_count*thread_num)/use_ms*1000<<" words/second";
+#else
+                         << ",QPS = " << (word_idx.size() / use_ms * 1000)
+                         <<"line/second, "<<(GLB_word_count)/use_ms*1000<<" words/second";
+#endif
+}
+void worker_run(){
+    std::string model_path=get_model_path();
+    Worker<NV, AK_FLOAT, Precision::FP32>  workers(model_path, 10);
+    workers.register_inputs({"input_0"});
+    if(GLB_output_name!=""){
+        workers.register_outputs({GLB_output_name});
+    }
+
+    std::vector<std::vector<float> > word_idx;
+    word_idx=get_input_data();
+
+    int batch_num = GLB_batch_size;
+    int thread_num = GLB_run_threads;
+    int real_max_batch_word_len = 0;
+
+    std::vector<std::vector<Tensor<NV, AK_FLOAT>* >> host_tensor_p_in_list;
+    host_tensor_p_in_list=get_slice_input_data(word_idx,1,real_max_batch_word_len,batch_num);
+
+    workers.Reshape("input_0", {real_max_batch_word_len,1,1,1});
+
+    workers.launch();
+
+
+
+    for(int i=0; i<host_tensor_p_in_list[0].size(); i++) {
+        std::vector<Tensor4dPtr<target_host<NV>::type, AK_FLOAT> > tensor_in_vec(1);
+//        tensor_in_vec[0]=host_tensor_p_in_list[0][i];
+        workers.sync_prediction(tensor_in_vec);
+//        auto  d_tensor_p_out_list = workers.sync_prediction(host_tensor_p_in_list);
+
+        // get the output
+//        auto d_tensor_p = d_tensor_p_out_list[0];
+    }
+}
+
+
+TEST(NetTest, net_execute_base_test) {
+    if(GLB_run_mode=="instance"){
+        instance_run();
+        return;
+
+    }
+    if(GLB_run_mode=="worker"){
+        worker_run();
+        return;
+    }
+    LOG(ERROR)<<"No support running mode ["<<GLB_run_mode<<"]";
+    exit(-1);
+}
+
+
+int main(int argc, const char** argv) {
+
+    Env<NV>::env_init();
+    // initial logger
+    LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+
+    if (argc >= 4) {
+        GLB_run_threads = atoi(argv[3]);
+    }
+
+    if (argc >= 5) {
+        GLB_batch_size = atoi(argv[4]);
+    }
+
+    if (argc >= 6) {
+
+        GLB_output_name = std::string(argv[5]);
+        if(GLB_output_name=="no_out")
+            GLB_output_name="";
+    }
+
+    if (argc >= 7) {
+        GLB_run_mode = argv[6];
+        LOG(INFO)<<"run mode = "<<GLB_run_mode;
+    }
+
+    if (argc >= 8) {
+        GLB_split_index = atoi(argv[7]);
+    }
+
+    if (argc >= 9) {
+        GLB_split_word = std::string(argv[8]);
+    }
+
+
+
+    logger::init(argv[0]);
+
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+        LOG(INFO) << "splite  " << i << " in " << GLB_split_word.size() << "  is " << int(char(
+                      GLB_split_word[i]));
+    }
+
+    //    exit(0);
+    //    run_my_test();
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv) {
+    return 0;
+}
+
+#endif
\ No newline at end of file
diff --git a/test/framework/net/net_exec_test.cpp b/test/framework/net/net_exec_test.cpp
index 3f40fc3..5a414d8 100644
--- a/test/framework/net/net_exec_test.cpp
+++ b/test/framework/net/net_exec_test.cpp
@@ -3,6 +3,17 @@
 #include "saber/funcs/timer.h"
 #include <chrono>
 
+#if defined(USE_CUDA)
+using Target = NV;
+using Target_H = X86;
+#elif defined(USE_X86_PLACE)
+using Target = X86;
+using Target_H = X86;
+#elif defined(USE_ARM_PLACE)
+using Target = ARM;
+using Target_H = ARM;
+#endif
+
 //#define USE_DIEPSE
 
 //std::string model_path = "/home/chaowen/anakin_v2/model_v2/anakin-models/adu/anakin_models/diepsie_light_head/diepsie_light_head.anakin.bin";
@@ -30,7 +41,17 @@
 //std::string model_path = "/home/cuichaowen/anakin2/anakin2/benchmark/CNN/mobilenet_v2.anakin.bin";
 
 // vgg16
-std::string model_path = "/home/cuichaowen/anakin2/anakin2/benchmark/CNN/models/vgg16.anakin.bin";
+// std::string model_path = "/home/cuichaowen/anakin2/anakin2/benchmark/CNN/models/vgg16.anakin.bin";
+
+// resnet 101
+//std::string model_path = "/home/cuichaowen/parsing/external_converter_v2/output/ResNet-101.anakin.bin";
+
+// animal
+//std::string model_path = "/home/cuichaowen/parsing/external_converter_v2/output/animal.anakin.bin";
+
+// std::string model_path = "/home/cuichaowen/github_anakin/icode_model/anakin-models/vis/anakin-models/mainbody/mainbody.anakin2.bin";
+
+std::string model_path = "/home/cuichaowen/github_anakin/icode_model/anakin-models/vis/anakin-models/MobileNetSSD/mobilenet-ssd_fluid.anakin2.bin";
 
 #ifdef USE_CUDA
 #if 1
@@ -45,18 +66,20 @@ TEST(NetTest, net_execute_base_test) {
 
     // reshape the input_0 's shape for graph model
     //graph->Reshape("input_0", {1, 8, 640, 640});
+	graph->ResetBatchSize("input_0", 2);
 
     // register all tensor inside graph
-    //graph->RegistAllOut();
-	
+    // graph->RegistAllOut();
+
     // register edge
     // graph->RegistOut("conv2_2/expand/scale", "relu2_2/expand");
+	//graph->RegistOut("conv2d#1(conv2d_0) ","relu#3(conv2d_0)");
 
     //anakin graph optimization
     graph->Optimize();
 
     // constructs the executer net
-	{ // inner scope
+	//{ // inner scope
 #ifdef USE_DIEPSE
     Net<NV, AK_FLOAT, Precision::FP32, OpRunType::SYNC> net_executer(*graph, true);
 #else
@@ -65,7 +88,7 @@ TEST(NetTest, net_execute_base_test) {
 
     // get in
     auto d_tensor_in_p = net_executer.get_in("input_0");
-    Tensor4d<X86, AK_FLOAT> h_tensor_in;
+    Tensor4d<Target_H, AK_FLOAT> h_tensor_in;
 
     auto valid_shape_in = d_tensor_in_p->valid_shape();
     for (int i=0; i<valid_shape_in.size(); i++) {
@@ -146,7 +169,7 @@ TEST(NetTest, net_execute_base_test) {
 #ifdef USE_CUDA
 	cudaDeviceSynchronize();
 #endif
-    
+
     for (int i = 0; i < 3; i++) {
     	net_executer.execute_start_from_node("relu2_2/expand");
     }
@@ -163,11 +186,12 @@ TEST(NetTest, net_execute_base_test) {
     my_time.end(ctx);
     LOG(INFO)<<"aveage time "<<my_time.get_average_ms()/epoch << " ms";
 
-	} // inner scope over
+	//} // inner scope over
 
 	LOG(ERROR) << "inner net exe over !";
 
     //auto& tensor_out_inner_p = net_executer.get_tensor_from_edge("data_perm", "conv1");
+	
 
     // get out yolo_v2
     /*auto tensor_out_0_p = net_executer.get_out("loc_pred_out");
@@ -184,16 +208,22 @@ TEST(NetTest, net_execute_base_test) {
 	auto tensor_out_4_p = net_executer.get_out("class_score_out");
 	auto tensor_out_5_p = net_executer.get_out("heading_pt_out");
 	auto tensor_out_6_p = net_executer.get_out("height_pt_out");*/
+
+	// restnet 101
+	// auto tensor_out_0_p = net_executer.get_out("elementwise_add_0.tmp_0_out");
+	auto tensor_out_0_p = net_executer.get_out("detection_output_0.tmp_0_out");
+
     // get out result
-    //test_print<NV>(tensor_out_4_p);
+    //LOG(WARNING)<< "result avg: " << tensor_average(tensor_out_0_p);
+	test_print(tensor_out_0_p);
 
 
     // save the optimized model to disk.
-    /*std::string save_model_path = model_path + std::string(".saved");
+    std::string save_model_path = model_path + std::string(".saved");
     status = graph->save(save_model_path);
     if (!status ) { 
         LOG(FATAL) << " [ERROR] " << status.info(); 
-    }*/
+    }
 }
 #endif 
 #endif
@@ -265,6 +295,8 @@ TEST(NetTest, net_execute_reconstruction_test) {
 #endif
 
 int main(int argc, const char** argv){
+
+	Env<Target>::env_init();
     // initial logger
     logger::init(argv[0]);
 	InitTest();
diff --git a/test/framework/net/net_exec_test_chinese_ner.cpp b/test/framework/net/net_exec_test_chinese_ner.cpp
new file mode 100644
index 0000000..113e393
--- /dev/null
+++ b/test/framework/net/net_exec_test_chinese_ner.cpp
@@ -0,0 +1,316 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+
+#include "sys/time.h"
+
+#ifdef USE_X86_PLACE
+#include <mkl_service.h>
+#include "omp.h"
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+
+
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir= nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+    closedir(dir);
+}
+
+int read_file(std::vector<float> &results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+            LOG(INFO)<<"found filename: "<<file_name;
+    std::string line;
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c)
+{
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+    while(std::string::npos != pos2)
+    {
+        v.push_back(s.substr(pos1, pos2-pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+    if(pos1 != s.length())
+        v.push_back(s.substr(pos1));
+}
+
+int split_word_from_file(
+        std::vector<std::vector<float> > &word_idx,
+        const std::string input_file_path,
+        const std::string split_token,
+        const std::string inner_split_token,
+        const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+            LOG(INFO)<<"found filename: "<<input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count=0;
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+                CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+//            printf("%d,",atoi(w.c_str()));
+        }
+//        printf("\n");
+//        exit(0);
+        word_idx.push_back(word);
+    }
+    GLB_word_count=word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+        std::vector<float> &out_data,
+        const std::vector<std::vector<float> > &seq_data,
+        std::vector<int> &seq_offset,
+        const int start_idx,
+        const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+//            printf("%.0f, ",d);
+        }
+//        printf("\n");
+        seq_offset.push_back(len);
+    }
+    return len;
+}
+
+void anakin_net_thread(std::vector<Tensor4dPtr<X86, AK_FLOAT> > *data_in,
+                       std::vector<Tensor4dPtr<X86, AK_FLOAT> > *mention_in,
+                       std::string model_path
+) {
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+    Graph<X86, AK_FLOAT, Precision::FP32> *graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+    //graph = new Graph<Target, AK_FLOAT, Precision::FP32>();
+    LOG(WARNING) << "load anakin model file from " << model_path << " ...";
+    // load anakin model files.
+    auto status = graph->load(model_path);
+    if(!status ) {
+         LOG(FATAL) << " [ERROR] " << status.info();
+    }
+    graph->Reshape("input_0", {GLB_max_word_len, 1, 1, 1});
+    graph->Reshape("input_1", {GLB_max_word_len, 1, 1, 1});
+    graph->Optimize();
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+    struct timeval time_start,time_end;
+
+    int slice_10=data_in->size()/10;
+    gettimeofday(&time_start, nullptr);
+    for (int i = 0; i < data_in->size(); ++i) {
+        auto input_tensor=(*data_in)[i];
+        auto input_mention_tensor=(*mention_in)[i];
+        auto word_in_p = net_executer.get_in("input_0");
+        auto mention_in_p = net_executer.get_in("input_1");
+        int len_sum=input_tensor->valid_size();
+        word_in_p->reshape({len_sum, 1, 1, 1});
+        for (int j = 0; j < len_sum; ++j) {
+            word_in_p->mutable_data()[j] = input_tensor->data()[j];
+        }
+        word_in_p->set_seq_offset(input_tensor->get_seq_offset());
+        int mention_sum=input_mention_tensor->valid_size();
+        mention_in_p->reshape({len_sum, 1, 1, 1});
+        for (int j = 0; j < mention_sum; ++j) {
+            mention_in_p->mutable_data()[j] = input_mention_tensor->data()[j];
+        }
+        mention_in_p->set_seq_offset(input_mention_tensor->get_seq_offset());
+//        timer.start(ctx);
+        net_executer.prediction();
+//        timer.end(ctx);
+        if(i%slice_10==0)
+                    LOG(INFO)<<"thread run "<<i<<" of "<<data_in->size();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+            LOG(INFO)<<"summary_thread :thread total : "<<use_ms<<" ms, avg = "<<(use_ms/data_in->size()/GLB_batch_size);
+}
+
+TEST(NetTest, net_execute_base_test) {
+
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+
+    std::vector<std::vector<float> > word_idx;
+    std::vector<std::vector<float> > mention_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, ";", " ", 1)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+    if (split_word_from_file(mention_idx, GLB_input_file, ";", " ", 3)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    std::vector<float> mention_idx_data;
+    std::vector<int> mention_seq_offset;
+    int batch_num =GLB_batch_size;
+    int max_batch_word_len=2000;
+    int thread_num=GLB_run_threads;
+
+    int real_max_batch_word_len=0;
+
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> mention_tensor_p_in_list;
+    for(int tid=0;tid<thread_num;++tid){
+        std::vector<Tensor<X86, AK_FLOAT>* > data4thread;
+        std::vector<Tensor<X86, AK_FLOAT>* > data4thread_m;
+        int start_wordid=tid*(word_idx.size()/thread_num);
+        int end_wordid=(tid+1)*(word_idx.size()/thread_num);
+        for (int i = start_wordid; i < end_wordid; i+=batch_num) {
+            int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+            int mention_len = get_batch_data_offset(mention_idx_data, mention_idx, word_seq_offset, i, batch_num);
+            real_max_batch_word_len=real_max_batch_word_len<word_len?word_len:real_max_batch_word_len;
+            saber::Shape valid_shape({word_len, 1, 1, 1});
+            Tensor4d<X86, AK_FLOAT>* tensor_p=new Tensor4d<X86, AK_FLOAT>(valid_shape);
+            CHECK_EQ(word_len,word_idx_data.size())<<"word_len == word_idx_data.size";
+
+            saber::Shape valid_shape_m({word_len, 1, 1, 1});
+            Tensor4d<X86, AK_FLOAT>* tensor_m=new Tensor4d<X86, AK_FLOAT>(valid_shape);
+            CHECK_EQ(mention_len,mention_idx_data.size())<<"mention_len == mention_idx_data.size";
+            for (int j = 0; j < word_idx_data.size(); ++j) {
+                tensor_p->mutable_data()[j] = word_idx_data[j];
+            }
+            for (int j = 0; j < mention_idx_data.size(); ++j) {
+                tensor_m->mutable_data()[j] = mention_idx_data[j];
+            }
+            tensor_p->set_seq_offset(word_seq_offset);
+            data4thread.push_back(tensor_p);
+            tensor_m->set_seq_offset(mention_seq_offset);
+            data4thread_m.push_back(tensor_m);
+        }
+        host_tensor_p_in_list.push_back(data4thread);
+        mention_tensor_p_in_list.push_back(data4thread_m);
+    }
+    GLB_max_word_len=real_max_batch_word_len;
+    LOG(WARNING) << "Async Runing multi_threads for model: " << models[0]<<",batch dim = "<<batch_num
+                 <<",line num = "<<word_idx.size()<<", number of word = "<<GLB_word_count<<",thread number size = "<<thread_num<<",real max = "<<real_max_batch_word_len;
+
+    std::vector<std::unique_ptr<std::thread>> threads;
+    struct timeval time_start,time_end;
+
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i],
+                                &mention_tensor_p_in_list[i], models[0]));
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+
+    LOG(INFO)<<"summary: "<<"thread num = "<<thread_num<<",total time = "<<use_ms<<"ms ,batch = "<<batch_num
+             <<",word sum = "<<GLB_word_count<<", seconde/line = "<<(use_ms/word_idx.size())
+             <<",QPS = "<<(word_idx.size()/use_ms*1000)<<" line/s , QPS_W = "<<(GLB_word_count/use_ms*1000);
+}
+
+
+int main(int argc, const char** argv){
+
+    Env<X86>::env_init();
+    // initial logger
+            LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+                LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+    if(argc>=4){
+        GLB_run_threads=atoi(argv[3]);
+    }
+    if(argc>=4){
+        GLB_batch_size=atoi(argv[4]);
+    }
+
+
+    logger::init(argv[0]);
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv){
+    return 0;
+}
+
+#endif
diff --git a/test/framework/net/net_exec_test_language.cpp b/test/framework/net/net_exec_test_language.cpp
new file mode 100644
index 0000000..fd6c5b2
--- /dev/null
+++ b/test/framework/net/net_exec_test_language.cpp
@@ -0,0 +1,311 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+
+#include "sys/time.h"
+
+#ifdef USE_X86_PLACE
+#include <mkl_service.h>
+#include "omp.h"
+using Target = X86;
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+DEFINE_GLOBAL(std::string, split_word, "\t");
+DEFINE_GLOBAL(int, split_index, 0);
+
+
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir= nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+    closedir(dir);
+}
+
+int read_file(std::vector<float> &results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+            LOG(INFO)<<"found filename: "<<file_name;
+    std::string line;
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c)
+{
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+    while(std::string::npos != pos2)
+    {
+        v.push_back(s.substr(pos1, pos2-pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+    if(pos1 != s.length())
+        v.push_back(s.substr(pos1));
+}
+
+int split_word_from_file(
+        std::vector<std::vector<float> > &word_idx,
+        const std::string input_file_path,
+        const std::string split_token,
+        const std::string inner_split_token,
+        const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+            LOG(INFO)<<"found filename: "<<input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count=0;
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+                CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+        }
+        word_idx.push_back(word);
+    }
+    GLB_word_count=word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+        std::vector<float> &out_data,
+        const std::vector<std::vector<float> > &seq_data,
+        std::vector<int> &seq_offset,
+        const int start_idx,
+        const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+//            printf("%.0f, ",d);
+        }
+//        printf("\n");
+        seq_offset.push_back(len);
+    }
+    return len;
+}
+
+void anakin_net_thread(std::vector<Tensor4dPtr<X86, AK_FLOAT> > *data_in,std::string model_path
+        ) {
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+    Graph<X86, AK_FLOAT, Precision::FP32> *graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+            LOG(WARNING) << "load anakin model file from " << model_path << " ...";
+    // load anakin model files.
+    auto status = graph->load(model_path);
+    if(!status ) {
+                LOG(FATAL) << " [ERROR] " << status.info();
+    }
+    graph->Reshape("input_0", {GLB_max_word_len, 1, 1, 1});
+    //anakin graph optimization
+    graph->Optimize();
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+//    SaberTimer<X86> timer;
+//    Context<X86> ctx;
+    struct timeval time_start,time_end;
+
+    int slice_10=data_in->size()/10;
+    slice_10=slice_10>0?slice_10:1;
+    int word_sum=0;
+    gettimeofday(&time_start, nullptr);
+    for (int i = 0; i < data_in->size(); ++i) {
+        auto input_tensor=(*data_in)[i];
+        auto word_in_p = net_executer.get_in("input_0");
+        int len_sum=input_tensor->valid_size();
+        word_in_p->reshape({len_sum, 1, 1, 1});
+        word_sum+=len_sum;
+        for (int j = 0; j < len_sum; ++j) {
+            word_in_p->mutable_data()[j] = input_tensor->data()[j];
+        }
+        word_in_p->set_seq_offset(input_tensor->get_seq_offset());
+//        timer.start(ctx);
+        net_executer.prediction();
+//        timer.end(ctx);
+        if(i%slice_10==0)
+            LOG(INFO)<<"thread run "<<i<<" of "<<data_in->size();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+    LOG(INFO)<<"summary_thread :thread total : "<<use_ms<<" ms, avg = "<<(use_ms/data_in->size())<<", consume words = "<<word_sum;
+    free(graph);
+}
+#define ONE_THREAD 1
+
+TEST(NetTest, net_execute_base_test) {
+
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, GLB_split_word, " ", GLB_split_index)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    int batch_num =GLB_batch_size;
+    int thread_num=GLB_run_threads;
+
+    int real_max_batch_word_len=0;
+
+
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+    for(int tid=0;tid<thread_num;++tid){
+        std::vector<Tensor<X86, AK_FLOAT>* > data4thread;
+        int start_wordid=tid*(word_idx.size()/thread_num);
+        int end_wordid=(tid+1)*(word_idx.size()/thread_num);
+        for (int i = start_wordid; i < end_wordid; i+=batch_num) {
+            int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+            real_max_batch_word_len=real_max_batch_word_len<word_len?word_len:real_max_batch_word_len;
+            saber::Shape valid_shape({word_len, 1, 1, 1});
+            Tensor4d<X86, AK_FLOAT>* tensor_p=new Tensor4d<X86, AK_FLOAT>(valid_shape);
+                    CHECK_EQ(word_len,word_idx_data.size())<<"word_len == word_idx_data.size";
+            for (int j = 0; j < word_idx_data.size(); ++j) {
+                tensor_p->mutable_data()[j] = word_idx_data[j];
+            }
+            tensor_p->set_seq_offset(word_seq_offset);
+            data4thread.push_back(tensor_p);
+        }
+        host_tensor_p_in_list.push_back(data4thread);
+    }
+    GLB_max_word_len=real_max_batch_word_len;
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+        LOG(INFO) << "splite  " << i <<" in "<<GLB_split_word.size()<< "  is " << int(char(GLB_split_word[i]));
+    }
+        LOG(WARNING) << "Async Runing multi_threads for model: " << models[0]<<",batch dim = "<<batch_num
+                         <<",line num = "<<word_idx.size()<<", number of word = "<<GLB_word_count<<",thread number size = "<<thread_num<<",real max = "<<real_max_batch_word_len;
+
+    std::vector<std::unique_ptr<std::thread>> threads;
+    struct timeval time_start,time_end;
+
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i],models[0]));
+//        threads.emplace_back(
+//                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i]),models[0]);
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+
+    LOG(INFO)<<"summary: "<<"thread num = "<<thread_num<<",total time = "<<use_ms<<"ms ,batch = "<<batch_num
+             <<",word sum = "<<GLB_word_count<<", seconde/line = "<<(use_ms/word_idx.size())
+             <<",QPS = "<<(word_idx.size()/use_ms*1000);
+
+}
+
+
+int main(int argc, const char** argv) {
+    // initial logger
+    Env<X86>::env_init();
+            LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+                LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+    if (argc >= 4) {
+        GLB_run_threads = atoi(argv[3]);
+    }
+    if (argc >= 5) {
+        GLB_batch_size = atoi(argv[4]);
+    }
+
+    if (argc >= 6) {
+        GLB_split_index = atoi(argv[5]);
+    }
+    if (argc >= 7) {
+        GLB_split_word = std::string(argv[6]);
+    }
+
+    logger::init(argv[0]);
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+            LOG(INFO) << "splite  " << i <<" in "<<GLB_split_word.size()<< "  is " << int(char(GLB_split_word[i]));
+    }
+
+//    exit(0);
+//    run_my_test();
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv){
+    return 0;
+}
+
+#endif
\ No newline at end of file
diff --git a/test/framework/net/net_exec_test_sequence_labeling.cpp b/test/framework/net/net_exec_test_sequence_labeling.cpp
new file mode 100644
index 0000000..cfe2e18
--- /dev/null
+++ b/test/framework/net/net_exec_test_sequence_labeling.cpp
@@ -0,0 +1,506 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+
+#include "sys/time.h"
+
+#ifdef USE_X86_PLACE
+#include <mkl_service.h>
+#include "omp.h"
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+
+
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir= nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+    closedir(dir);
+}
+
+int read_file(std::vector<float> &results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+            LOG(INFO)<<"found filename: "<<file_name;
+    std::string line;
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c)
+{
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+    while(std::string::npos != pos2)
+    {
+        v.push_back(s.substr(pos1, pos2-pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+    if(pos1 != s.length())
+        v.push_back(s.substr(pos1));
+}
+
+int split_word_from_file(
+        std::vector<std::vector<float> > &word_idx,
+        const std::string input_file_path,
+        const std::string split_token,
+        const std::string inner_split_token,
+        const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+            LOG(INFO)<<"found filename: "<<input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count=0;
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+                CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+        }
+        word_idx.push_back(word);
+    }
+    GLB_word_count=word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+        std::vector<float> &out_data,
+        const std::vector<std::vector<float> > &seq_data,
+        std::vector<int> &seq_offset,
+        const int start_idx,
+        const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+//            printf("%.0f, ",d);
+        }
+//        printf("\n");
+        seq_offset.push_back(len);
+    }
+    return len;
+}
+
+void anakin_net_thread(std::vector<Tensor4dPtr<X86, AK_FLOAT> > *data_in,std::string model_path
+        ) {
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+    Graph<X86, AK_FLOAT, Precision::FP32> *graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+    //graph = new Graph<Target, AK_FLOAT, Precision::FP32>();
+    LOG(WARNING) << "load anakin model file from " << model_path << " ...";
+    // load anakin model files.
+    auto status = graph->load(model_path);
+    if(!status ) {
+                LOG(FATAL) << " [ERROR] " << status.info();
+    }
+    graph->Reshape("input_0", {1000, 1, 1, 1});
+    //anakin graph optimization
+    graph->Optimize();
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+//    SaberTimer<X86> timer;
+//    Context<X86> ctx;
+    struct timeval time_start,time_end;
+
+    int slice_10=data_in->size()/10;
+    gettimeofday(&time_start, nullptr);
+    for (int i = 0; i < data_in->size(); ++i) {
+        auto input_tensor=(*data_in)[i];
+        auto word_in_p = net_executer.get_in("input_0");
+        int len_sum=input_tensor->valid_size();
+        word_in_p->reshape({len_sum, 1, 1, 1});
+        for (int j = 0; j < len_sum; ++j) {
+            word_in_p->mutable_data()[j] = input_tensor->data()[j];
+        }
+        word_in_p->set_seq_offset(input_tensor->get_seq_offset());
+//        timer.start(ctx);
+        net_executer.prediction();
+//        timer.end(ctx);
+        if(i%slice_10==0)
+            LOG(INFO)<<"thread run "<<i<<" of "<<data_in->size();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+    LOG(INFO)<<"summary_thread :thread total : "<<use_ms<<" ms, avg = "<<(use_ms/data_in->size()/GLB_batch_size);
+}
+#define ONE_THREAD 1
+
+TEST(NetTest, net_execute_base_test) {
+
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, ";", " ", 1)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    int batch_num =GLB_batch_size;
+    int max_batch_word_len=2000;
+    int thread_num=GLB_run_threads;
+
+    int real_max_batch_word_len=0;
+
+
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+    for(int tid=0;tid<thread_num;++tid){
+        std::vector<Tensor<X86, AK_FLOAT>* > data4thread;
+        int start_wordid=tid*(word_idx.size()/thread_num);
+        int end_wordid=(tid+1)*(word_idx.size()/thread_num);
+        for (int i = start_wordid; i < end_wordid; i+=batch_num) {
+            int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+            real_max_batch_word_len=real_max_batch_word_len<word_len?word_len:real_max_batch_word_len;
+            saber::Shape valid_shape({word_len, 1, 1, 1});
+            Tensor4d<X86, AK_FLOAT>* tensor_p=new Tensor4d<X86, AK_FLOAT>(valid_shape);
+                    CHECK_EQ(word_len,word_idx_data.size())<<"word_len == word_idx_data.size";
+            for (int j = 0; j < word_idx_data.size(); ++j) {
+                tensor_p->mutable_data()[j] = word_idx_data[j];
+            }
+            tensor_p->set_seq_offset(word_seq_offset);
+            data4thread.push_back(tensor_p);
+        }
+        host_tensor_p_in_list.push_back(data4thread);
+    }
+    GLB_max_word_len=real_max_batch_word_len;
+            LOG(WARNING) << "Async Runing multi_threads for model: " << models[0]<<",batch dim = "<<batch_num
+                         <<",line num = "<<word_idx.size()<<", number of word = "<<GLB_word_count<<",thread number size = "<<thread_num<<",real max = "<<real_max_batch_word_len;
+
+    std::vector<std::unique_ptr<std::thread>> threads;
+    struct timeval time_start,time_end;
+
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i],models[0]));
+//        threads.emplace_back(
+//                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i]),models[0]);
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+    gettimeofday(&time_end, nullptr);
+    float use_ms=(time_end.tv_sec-time_start.tv_sec)*1000.f+(time_end.tv_usec-time_start.tv_usec)/1000.f;
+
+    LOG(INFO)<<"summary: "<<"thread num = "<<thread_num<<",total time = "<<use_ms<<"ms ,batch = "<<batch_num
+             <<",word sum = "<<GLB_word_count<<", seconde/line = "<<(use_ms/word_idx.size())
+             <<",QPS = "<<(word_idx.size()/use_ms*1000);
+
+#if 0
+    Graph<X86, AK_FLOAT, Precision::FP32> *graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+//            LOG(WARNING) << "load anakin model file from " << model_path << " ...";
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, "\t", " ", 0)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+    LOG(INFO) << "READ SUCCESS!! I got " << word_idx.size() << " records";
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    int batch_num = 6;
+    int max_batch_word_len=2000;
+    graph = new Graph<Target, AK_FLOAT, Precision::FP32>();
+            LOG(WARNING) << "load anakin model file from " << models[0] << " ...";
+    // load anakin model files.
+    auto status = graph->load(models[0]);
+    if(!status ) {
+                LOG(FATAL) << " [ERROR] " << status.info();
+    }
+    graph->Reshape("input_0", {max_batch_word_len, 1, 1, 1});
+    //anakin graph optimization
+    graph->Optimize();
+    Net<Target, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+    SaberTimer<X86> timer;
+    Context<X86> ctx;
+    for (int i = 0; i < word_idx.size(); i += batch_num) {
+        int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+        auto word_in_p = net_executer.get_in("input_0");
+        word_in_p->reshape({word_len, 1, 1, 1});
+        for (int j = 0; j < word_idx_data.size(); ++j) {
+            word_in_p->mutable_data()[j] = word_idx_data[j];
+        }
+        word_in_p->set_seq_offset(word_seq_offset);
+        timer.start(ctx);
+        net_executer.prediction();
+        timer.end(ctx);
+    }
+    LOG(INFO)<<"elapse time: "<<timer.get_average_ms()<<" ms";
+
+    return;
+#endif
+
+//    std::vector<float> word_idx_data;
+//    std::vector<int> word_seq_offset;
+//    int batch_num = 6;
+//    int pool_size=10;
+//
+//
+//
+//    std::vector<std::string> models;
+//    getModels(GLB_model_dir, models);
+//    std::vector<std::vector<float> > word_idx;
+//    if (split_word_from_file(word_idx, GLB_input_file, "\t", " ", 0)) {
+//                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+//        exit(-1);
+//    }
+//    std::vector<std::vector<Tensor4dPtr<X86, AK_FLOAT> >> host_tensor_p_in_list;
+//    // get in
+//#ifdef ONE_THREAD
+//
+//    omp_set_dynamic(0);
+//    omp_set_num_threads(1);
+//    mkl_set_num_threads(1);
+//    Graph<X86, AK_FLOAT, Precision::FP32> *graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+//    graph = new Graph<Target, AK_FLOAT, Precision::FP32>();
+//            LOG(WARNING) << "load anakin model file from " << models[0] << " ...";
+//    // load anakin model files.
+//    auto status = graph->load(models[0]);
+//    if(!status ) {
+//                LOG(FATAL) << " [ERROR] " << status.info();
+//    }
+//    graph->Reshape("input_0", {2000, 1, 1, 1});
+//    graph->Optimize();
+//    Net<Target, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+//#endif
+//    int real_max_batch_word_len=0;
+//    for (int i = 0; i < word_idx.size(); i += batch_num) {
+//
+//        int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+//        saber::Shape valid_shape({word_len, 1, 1, 1});
+//        real_max_batch_word_len=word_len>real_max_batch_word_len?word_len:real_max_batch_word_len;
+//        Tensor4dPtr<X86, AK_FLOAT>  word_in_p = new Tensor4d<X86, AK_FLOAT>(valid_shape);
+//        word_in_p->reshape({word_len, 1, 1, 1});
+//        for (int j = 0; j < word_idx_data.size(); ++j) {
+//            word_in_p->mutable_data()[j] = word_idx_data[j];
+//        }
+//        word_in_p->set_seq_offset(word_seq_offset);
+//        std::vector<Tensor4dPtr<X86, AK_FLOAT> >list;
+//        list.push_back(word_in_p);
+//        host_tensor_p_in_list.push_back(list);
+//    }
+//#ifdef ONE_THREAD
+//    SaberTimer<X86> timer;
+//    Context<X86> ctx;
+//    for (int i = 0; i < word_idx.size(); i += batch_num) {
+//        Tensor4dPtr<X86, AK_FLOAT> input_tensor=host_tensor_p_in_list[i][0];
+//        auto word_in_p = net_executer.get_in("input_0");
+//        word_in_p->reshape(input_tensor->valid_shape());
+//        for (int j = 0; j < word_idx_data.size(); ++j) {
+//            word_in_p->mutable_data()[j] = input_tensor->data()[j];
+//        }
+//        word_in_p->set_seq_offset(word_seq_offset);
+//        timer.start(ctx);
+//        net_executer.prediction();
+//        timer.end(ctx);
+//        LOG(INFO)<<"run "<<i<<" of "<<word_idx.size();
+//    }
+//    LOG(INFO)<<"elapse time: "<<timer.get_average_ms()<<" ms";
+//#endif
+//
+//#ifdef ONE_THREAD
+//    return ;
+//#endif
+//
+//
+//    LOG(WARNING) << "Async Runing multi_threads for model: " << models[0]<<",batch dim = "<<batch_num
+//                 <<",batch num = "<<word_idx.size()<<",pool size = "<<pool_size<<",real max = "<<real_max_batch_word_len;
+//    Worker<Target, AK_FLOAT, Precision::FP32>  workers(models[0], pool_size);
+//    workers.register_inputs({"input_0"});
+//    workers.register_outputs({"softmax_7(fc_1)"});
+//    workers.Reshape("input_0", {real_max_batch_word_len,1,1,1});
+//    workers.launch();
+//
+//    // get the output
+//    int iterator = word_idx.size();
+////    timer.start(ctx);
+//
+//    for(int i=0;i<word_idx.size();i++){
+//        workers.sync_prediction(host_tensor_p_in_list[i]);
+//    }
+
+//    while(iterator) {
+//        if(!workers.empty()) {
+//            auto d_tensor_p = workers.async_get_result()[0];
+//            iterator--;
+//        }
+//    }
+
+
+
+//    timer.end(ctx);
+
+
+//    for(int i=0;i<word_seq_offset.size()-1;i++){
+//
+//    }
+//    net_executer.prediction();
+#if 0
+// load anakin model files.
+    auto status = graph->load(model_path);
+    if(!status ) {
+                LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    graph->Reshape("input_0", {7,1,1,1});     // right results
+//graph->Reshape("input_0", {1, 1, 48, 1500});     // wrong results
+
+    graph->Optimize();
+
+    //Net <NV, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+
+    Net<X86, AK_FLOAT, Precision::FP32, OpRunType::SYNC> net_executer(*graph, true);
+
+//    std::vector<float> input_data;
+//    std::string img_path = "/home/public/anakin2_ocr/inputs/48_194.txt";
+//    int res = read_file(input_data, img_path.c_str());
+
+
+    auto d_tensor_in_p = net_executer.get_in("input_0");
+    //Shape new_shape(1, 1, 48, 194);
+    //d_tensor_in_p->reshape(new_shape);
+//    float *h_data_in = input_data.data();
+    Shape input_shape(7,1,1,1);
+    Tensor4d<X86, AK_FLOAT> h_tensor_in;
+    h_tensor_in.re_alloc(input_shape);
+    float* h_data = h_tensor_in.mutable_data();
+
+    for (int i=0; i<h_tensor_in.size(); i++) {
+        h_data[i] = 20+i;
+    }
+    for (int i = 0; i < d_tensor_in_p->valid_shape().size(); i++) {
+                LOG(INFO) << " shape IN (" << i << ") " << d_tensor_in_p->valid_shape()[i];
+    }
+//    return ;
+    d_tensor_in_p->copy_from(h_tensor_in);
+    d_tensor_in_p->set_seq_offset({0,5,7});
+
+//    for (int i = 0; i < h_tensor_in.valid_shape().count(); i++) {
+//                LOG(INFO) << " GET IN (" << i << ") " << h_tensor_in.mutable_data()[i];
+//    }
+
+    int epoch = 1;
+// do inference
+    Context<X86> ctx(0, 0, 0);
+    saber::SaberTimer<X86> my_time;
+            LOG(WARNING) << "EXECUTER !!!!!!!! ";
+// warm up
+    for(int i=0; i<epoch; i++) {
+        net_executer.prediction();
+//        cudaDeviceSynchronize();
+    }
+
+//    Tensor4d<X86, AK_FLOAT> h_tensor_result;
+//    auto h_tensor_out_p = &h_tensor_result;
+//    auto d_tensor_out_p = net_executer.get_out("fc_2.tmp_4_out");
+//    LOG(INFO) <<"d_tensor_out_p :" <<d_tensor_out_p->data();
+//    h_tensor_out_p->re_alloc(d_tensor_out_p->valid_shape());
+//    h_tensor_out_p->copy_from(*d_tensor_out_p);
+//    for (int i = 0; i < h_tensor_out_p->valid_shape().count(); i++) {
+//                LOG(INFO) << " GET OUT (" << i << ") " << h_tensor_out_p->mutable_data()[i];
+//    }
+#endif
+}
+
+
+int main(int argc, const char** argv){
+    Env<X86>::env_init();
+    // initial logger
+    LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+                LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+    if(argc>=4){
+        GLB_run_threads=atoi(argv[3]);
+    }
+    if(argc>=4){
+        GLB_batch_size=atoi(argv[4]);
+    }
+
+
+    logger::init(argv[0]);
+//    run_my_test();
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv){
+    return 0;
+}
+
+#endif
diff --git a/test/framework/net/net_exec_x86_oneinput.cpp b/test/framework/net/net_exec_x86_oneinput.cpp
new file mode 100644
index 0000000..8af1238
--- /dev/null
+++ b/test/framework/net/net_exec_x86_oneinput.cpp
@@ -0,0 +1,475 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+
+#include "sys/time.h"
+#include "debug.h"
+#include "string"
+
+#ifdef USE_X86_PLACE
+#include <mkl_service.h>
+#include "omp.h"
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, run_threads, 1);
+volatile DEFINE_GLOBAL(int, batch_size, 1);
+volatile DEFINE_GLOBAL(int, max_word_len, 0);
+volatile DEFINE_GLOBAL(int, word_count, 0);
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+DEFINE_GLOBAL(std::string, split_word, "\t");
+DEFINE_GLOBAL(std::string, output_name, "");
+DEFINE_GLOBAL(std::string, run_mode, "instance");
+DEFINE_GLOBAL(int, split_index, 0);
+
+#define AVG_INPUT
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir = nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+
+    closedir(dir);
+}
+
+int read_file(std::vector<float>& results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return false;
+    }
+
+    LOG(INFO) << "found filename: " << file_name;
+    std::string line;
+
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+
+    return 0;
+}
+void SplitString(const std::string& s,
+                 std::vector<std::string>& v, const std::string& c) {
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+
+    while (std::string::npos != pos2) {
+        v.push_back(s.substr(pos1, pos2 - pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+
+    if (pos1 != s.length()) {
+        v.push_back(s.substr(pos1));
+    }
+}
+
+int split_word_from_file(
+    std::vector<std::vector<float> >& word_idx,
+    const std::string input_file_path,
+    const std::string split_token,
+    const std::string inner_split_token,
+    const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+
+    LOG(INFO) << "found filename: " << input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    int word_count = 0;
+
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+        CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+            word_count++;
+            //            printf("%d,",atoi(w.c_str()));
+        }
+
+        //        printf("\n");
+        //        exit(0);
+        word_idx.push_back(word);
+    }
+
+    GLB_word_count = word_count;
+    return 0;
+}
+
+int get_batch_data_offset(
+    std::vector<float>& out_data,
+    const std::vector<std::vector<float> >& seq_data,
+    std::vector<int>& seq_offset,
+    const int start_idx,
+    const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+            //            printf("%.0f, ",d);
+        }
+
+        //        printf("\n");
+        seq_offset.push_back(len);
+    }
+
+    return len;
+}
+
+void anakin_net_thread(std::vector<Tensor4dPtr<X86, AK_FLOAT> >* data_in, std::string model_path
+                      , bool is_save_result=false,int thread_id=0) {
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+    Graph<X86, AK_FLOAT, Precision::FP32>* graph = new Graph<X86, AK_FLOAT, Precision::FP32>();
+    LOG(WARNING) << "load anakin model file from " << model_path << " ...";
+    // load anakin model files.
+    auto status = graph->load(model_path);
+    if (!status) {
+        LOG(FATAL) << " [ERROR] " << status.info();
+    }
+
+    graph->Reshape("input_0", {GLB_max_word_len, 1, 1, 1});
+    //anakin graph optimization
+    graph->Optimize();
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(*graph, true);
+    //    SaberTimer<X86> timer;
+    //    Context<X86> ctx;
+    struct timeval time_start, time_end;
+
+    int slice_10 = data_in->size() / 10;
+    slice_10 = slice_10 > 0 ? slice_10 : 1;
+    int word_sum = 0;
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < data_in->size(); ++i) {
+        auto input_tensor = (*data_in)[i];
+        auto word_in_p = net_executer.get_in("input_0");
+        int len_sum = input_tensor->valid_size();
+        word_in_p->reshape({len_sum, 1, 1, 1});
+        word_sum += len_sum;
+
+        for (int j = 0; j < len_sum; ++j) {
+            word_in_p->mutable_data()[j] = input_tensor->data()[j];
+        }
+
+        word_in_p->set_seq_offset(input_tensor->get_seq_offset());
+        //        timer.start(ctx);
+
+        net_executer.prediction();
+        if(is_save_result) {
+            int k = net_executer.get_out_list().size();
+                    LOG(INFO) << "out size = " << k;
+            auto outs = net_executer.get_out(GLB_output_name);
+            int out_cnt = 0;
+            record_dev_tensorfile(outs,
+                                  ("output_" + std::to_string(thread_id) + "_" + std::to_string(i)+ ".txt").data());
+        }
+//        out_cnt++;
+
+        //        timer.end(ctx);
+        if (i % slice_10 == 0) {
+            LOG(INFO) << "thread run " << i << " of " << data_in->size();
+        }
+    }
+
+    gettimeofday(&time_end, nullptr);
+    float use_ms = (time_end.tv_sec - time_start.tv_sec) * 1000.f + (time_end.tv_usec -
+                   time_start.tv_usec) / 1000.f;
+    LOG(INFO) << "summary_thread :thread total : " << use_ms << " ms, avg = " <<
+              (use_ms / data_in->size()) << ", consume words = " << word_sum;
+    free(graph);
+}
+
+
+std::string get_model_path(){
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+    return models[0];
+}
+std::vector<std::vector<float> > get_input_data(){
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, GLB_split_word, " ", GLB_split_index)) {
+                LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+    return word_idx;
+};
+std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> get_slice_input_data(std::vector<std::vector<float> > &word_idx,
+                                                                       int thread_num,int &real_max_batch_word_len,int batch_num){
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    for (int tid = 0; tid < thread_num; ++tid) {
+        std::vector<Tensor<X86, AK_FLOAT>* > data4thread;
+        int start_wordid = tid * (word_idx.size() / thread_num);
+        int end_wordid = (tid + 1) * (word_idx.size() / thread_num);
+
+        for (int i = start_wordid; i < end_wordid; i += batch_num) {
+            int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+            real_max_batch_word_len = real_max_batch_word_len < word_len ? word_len : real_max_batch_word_len;
+            saber::Shape valid_shape({word_len, 1, 1, 1});
+            Tensor4d<X86, AK_FLOAT>* tensor_p = new Tensor4d<X86, AK_FLOAT>(valid_shape);
+                    CHECK_EQ(word_len, word_idx_data.size()) << "word_len == word_idx_data.size";
+
+            for (int j = 0; j < word_idx_data.size(); ++j) {
+                tensor_p->mutable_data()[j] = word_idx_data[j];
+            }
+
+            tensor_p->set_seq_offset(word_seq_offset);
+            data4thread.push_back(tensor_p);
+        }
+        host_tensor_p_in_list.push_back(data4thread);
+    }
+    return host_tensor_p_in_list;
+};
+void instance_run(){
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
+
+    std::string model_path=get_model_path();
+
+
+    std::vector<std::vector<float> > word_idx;
+    word_idx=get_input_data();
+
+    int batch_num = GLB_batch_size;
+    int thread_num = GLB_run_threads;
+
+    int real_max_batch_word_len = 0;
+
+
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+#ifdef AVG_INPUT
+    host_tensor_p_in_list=get_slice_input_data(word_idx,1,real_max_batch_word_len,batch_num);
+#else
+    host_tensor_p_in_list=get_slice_input_data(word_idx,thread_num,real_max_batch_word_len,batch_num);
+#endif
+
+
+    GLB_max_word_len = real_max_batch_word_len;
+
+    if(real_max_batch_word_len<=0){
+        LOG(INFO)<<"can`t read any data";
+        exit(-1);
+    }
+
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+        LOG(INFO) << "splite  " << i << " in " << GLB_split_word.size() << "  is " << int(char(
+        GLB_split_word[i]));
+    }
+
+    std::string first_line="";
+    Tensor<X86, AK_FLOAT>* first_tensor=host_tensor_p_in_list[0][0];
+    for(int  i=0 ;i<first_tensor->valid_size() ;++i){
+        first_line=first_line+std::to_string(first_tensor->data()[i])+",";
+        LOG(INFO)<<"first line : "<<first_tensor->data()[i];
+    }
+    LOG(INFO)<<"first line2 :"<<first_line;
+
+    LOG(WARNING) << "Async Runing multi_threads for model: " << model_path << ",batch dim = " <<
+                 batch_num
+                 << ",line num = " << word_idx.size() << ", number of word = " << GLB_word_count <<
+                 ",thread number size = " << thread_num << ",real max = " << real_max_batch_word_len;
+
+    std::vector<std::unique_ptr<std::thread>> threads;
+    struct timeval time_start, time_end;
+
+    gettimeofday(&time_start, nullptr);
+
+    for (int i = 0; i < thread_num; ++i) {
+#ifdef AVG_INPUT
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[0], model_path,GLB_output_name!="",i));
+#else
+        threads.emplace_back(
+                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i], model_path,GLB_output_name!="",i));
+#endif
+        //        threads.emplace_back(
+        //                new std::thread(&anakin_net_thread, &host_tensor_p_in_list[i]),models[0]);
+    }
+
+    for (int i = 0; i < thread_num; ++i) {
+        threads[i]->join();
+    }
+
+    gettimeofday(&time_end, nullptr);
+    float use_ms = (time_end.tv_sec - time_start.tv_sec) * 1000.f + (time_end.tv_usec -
+                                                                     time_start.tv_usec) / 1000.f;
+
+            LOG(INFO) << "summary: " << "thread num = " << thread_num << ",total time = " << use_ms <<
+                      "ms ,batch = " << batch_num
+                      << ",word sum = " << GLB_word_count << ", seconde/line = " << (use_ms / word_idx.size())
+#ifdef AVG_INPUT
+                      << ",AVG_INPUT QPS  = " << (thread_num*word_idx.size() / use_ms * 1000)
+                      <<"line/second, "<<(GLB_word_count*thread_num)/use_ms*1000<<" words/second";
+#else
+                         << ",QPS = " << (word_idx.size() / use_ms * 1000);
+                         <<"line/second, "<<(GLB_word_count)/use_ms*1000<<" words/second";
+#endif
+}
+void worker_run(){
+    std::string model_path=get_model_path();
+    Worker<X86, AK_FLOAT, Precision::FP32>  workers(model_path, 10);
+    workers.register_inputs({"input_0"});
+    if(GLB_output_name!=""){
+        workers.register_outputs({GLB_output_name});
+    }
+
+    std::vector<std::vector<float> > word_idx;
+    word_idx=get_input_data();
+
+    int batch_num = GLB_batch_size;
+    int thread_num = GLB_run_threads;
+    int real_max_batch_word_len = 0;
+
+    std::vector<std::vector<Tensor<X86, AK_FLOAT>* >> host_tensor_p_in_list;
+    host_tensor_p_in_list=get_slice_input_data(word_idx,1,real_max_batch_word_len,batch_num);
+
+    workers.Reshape("input_0", {real_max_batch_word_len,1,1,1});
+
+    workers.launch();
+
+
+
+    for(int i=0; i<host_tensor_p_in_list[0].size(); i++) {
+        std::vector<Tensor4dPtr<target_host<X86>::type, AK_FLOAT> > tensor_in_vec(1);
+        tensor_in_vec[0]=host_tensor_p_in_list[0][i];
+        workers.sync_prediction(tensor_in_vec);
+//        auto  d_tensor_p_out_list = workers.sync_prediction(host_tensor_p_in_list);
+
+        // get the output
+//        auto d_tensor_p = d_tensor_p_out_list[0];
+    }
+}
+
+
+TEST(NetTest, net_execute_base_test) {
+    if(GLB_run_mode=="instance"){
+        instance_run();
+        return;
+
+    }
+    if(GLB_run_mode=="worker"){
+        worker_run();
+        return;
+    }
+    LOG(ERROR)<<"No support running mode ["<<GLB_run_mode<<"]";
+    exit(-1);
+}
+
+
+int main(int argc, const char** argv) {
+
+    Env<X86>::env_init();
+
+    // initial logger
+    LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc >= 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+
+    if (argc >= 4) {
+        GLB_run_threads = atoi(argv[3]);
+    }
+
+    if (argc >= 5) {
+        GLB_batch_size = atoi(argv[4]);
+    }
+
+    if (argc >= 6) {
+
+        GLB_output_name = std::string(argv[5]);
+        if(GLB_output_name=="no_out")
+            GLB_output_name="";
+    }
+
+    if (argc >= 7) {
+        GLB_run_mode = argv[6];
+        LOG(INFO)<<"run mode = "<<GLB_run_mode;
+    }
+
+    if (argc >= 8) {
+        GLB_split_index = atoi(argv[7]);
+    }
+
+    if (argc >= 9) {
+        GLB_split_word = std::string(argv[8]);
+    }
+
+
+
+    logger::init(argv[0]);
+
+    for (int i = 0; i < GLB_split_word.size(); i++) {
+        LOG(INFO) << "splite  " << i << " in " << GLB_split_word.size() << "  is " << int(char(
+                      GLB_split_word[i]));
+    }
+
+    //    exit(0);
+    //    run_my_test();
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv) {
+    return 0;
+}
+
+#endif
\ No newline at end of file
diff --git a/test/framework/net/net_test.h b/test/framework/net/net_test.h
index c240afb..4c1f6a5 100644
--- a/test/framework/net/net_test.h
+++ b/test/framework/net/net_test.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -69,10 +69,9 @@ double tensor_average(Tensor4dPtr<Ttype, Dtype>& out_tensor_p) {
     for (int i=0; i<out_tensor_p->valid_size(); i++) {
 		sum+=h_data[i];
     }
-    return sum/out_tensor_p->valid_size();
+    return sum/*/out_tensor_p->valid_size()*/;
 }
 
-
 #ifdef USE_X86_PLACE
 static int record_dev_tensorfile(const Tensor4d<X86, AK_FLOAT>* dev_tensor, const char* locate) {
     Tensor<target_host<X86>::type, AK_FLOAT, NCHW> host_temp;
diff --git a/test/framework/net/padde_api_test.cpp b/test/framework/net/padde_api_test.cpp
index 6e0dfe8..5857c8e 100644
--- a/test/framework/net/padde_api_test.cpp
+++ b/test/framework/net/padde_api_test.cpp
@@ -18,15 +18,7 @@ DEFINE_GLOBAL(int, channel, 8);
 DEFINE_GLOBAL(int, height, 640);
 DEFINE_GLOBAL(int, width, 640);
 DEFINE_GLOBAL(bool, is_input_shape, false);
-
 #ifdef USE_CUDA
-typedef NV Target;
-#elif defined(USE_X86_PLACE)
-typedef X86 Target;
-#else
-typedef ARM Target;
-#endif
-
 void getModels(std::string path, std::vector<std::string>& files)
 {
     DIR *dir;
@@ -54,7 +46,7 @@ TEST(NetTest, net_execute_base_test) {
     getModels(GLB_model_dir, models);
     for (auto iter = models.begin(); iter < models.end(); iter++)
     {
-        AnakinEngine<Target, AK_FLOAT, Precision::FP32> anakin_engine;
+        AnakinEngine<NV, AK_FLOAT, Precision::FP32> anakin_engine;
         LOG(WARNING) << "load anakin model file from " << *iter << " ...";
         std::vector<int> shape{GLB_num, GLB_channel, GLB_height, GLB_width};
         //anakin_engine.Build(*iter, shape);
@@ -71,8 +63,8 @@ TEST(NetTest, net_execute_base_test) {
         int warmup_iter = 10;
         int epoch = 1000;
         // do inference
-        Context<Target> ctx(0, 0, 0);
-        saber::SaberTimer<Target> my_time;
+        Context<NV> ctx(0, 0, 0);
+        saber::SaberTimer<NV> my_time;
         LOG(WARNING) << "EXECUTER !!!!!!!! ";
         for (int i = 0; i < warmup_iter; i++) {
             anakin_engine.Execute();
@@ -88,6 +80,8 @@ TEST(NetTest, net_execute_base_test) {
 }
 
 int main(int argc, const char** argv){
+
+    Env<NV>::env_init();
     // initial logger
     LOG(INFO)<<"argc"<<argc;
     if (argc < 1) {
@@ -119,3 +113,10 @@ int main(int argc, const char** argv){
     RUN_ALL_TESTS(argv[0]); 
     return 0;
 }
+
+#else
+int main(int argc, char** argv) {
+        return 0;
+}
+
+#endif
diff --git a/test/framework/net/paddle_api.h b/test/framework/net/paddle_api.h
index 44cb3a3..9e85d78 100644
--- a/test/framework/net/paddle_api.h
+++ b/test/framework/net/paddle_api.h
@@ -11,6 +11,8 @@
 #include <fcntl.h>
 #include <map>
 
+#ifdef USE_CUDA
+
 class EngineBase {
  public:
   // Build the model and do some preparation, for example, in TensorRT, run
@@ -26,9 +28,9 @@ class EngineBase {
 template <typename Ttype, DataType Dtype, Precision Ptype>
 class AnakinEngine : public EngineBase {
 public:
-  typedef typename anakin::saber::DataTrait<Dtype>::dtype Dtype_t;
+  typedef typename anakin::saber::DataTrait<NV, Dtype>::dtype Dtype_t;
   typedef anakin::saber::TargetWrapper<X86> X86_API;
-  typedef anakin::saber::TargetWrapper<Ttype> NV_API;
+  typedef anakin::saber::TargetWrapper<NV> NV_API;
   AnakinEngine(){}
 
   ~AnakinEngine(){};
@@ -58,7 +60,7 @@ public:
   void SetInputFromCPU(const std::string name, Dtype_t* data, size_t size)
   {
     auto input_tensor = _net_executer.get_in(name);
-    anakin::Tensor<Ttype, Dtype> tmp_tensor(data, anakin::saber::X86(), X86_API::get_device_id(), input_tensor->valid_shape());
+    anakin::Tensor<Ttype, Dtype> tmp_tensor(data, X86(), 0, input_tensor->valid_shape());
     *input_tensor = tmp_tensor;
   };
 
@@ -76,13 +78,11 @@ public:
   {
     return _net_executer.get_out(name);
   }
-
 private:
     anakin::graph::Graph<Ttype, Dtype, Ptype> _graph;
     anakin::Net<Ttype, Dtype, Ptype> _net_executer;
 };  // class TensorRTEngine
 
-#ifdef USE_CUDA
 template 
 class AnakinEngine<NV, anakin::saber::AK_FLOAT, anakin::Precision::FP32>;
 #endif
diff --git a/test/framework/net/text_classification_test.cpp b/test/framework/net/text_classification_test.cpp
new file mode 100644
index 0000000..1df87e2
--- /dev/null
+++ b/test/framework/net/text_classification_test.cpp
@@ -0,0 +1,209 @@
+
+#include "anakin_config.h"
+#include <string>
+#include <fstream>
+#include "net_test.h"
+#include "saber/funcs/timer.h"
+#include <chrono>
+#include "saber/core/tensor_op.h"
+#include <dirent.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <map>
+
+#ifdef USE_X86_PLACE
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(std::string, model_dir, "");
+DEFINE_GLOBAL(std::string, input_file, "");
+
+void getModels(std::string path, std::vector<std::string>& files) {
+    DIR* dir= nullptr;
+    struct dirent* ptr;
+
+    if ((dir = opendir(path.c_str())) == NULL) {
+        perror("Open dri error...");
+        exit(1);
+    }
+
+    while ((ptr = readdir(dir)) != NULL) {
+        if (strcmp(ptr->d_name, ".") == 0 || strcmp(ptr->d_name, "..") == 0) {
+            continue;
+        } else if (ptr->d_type == 8) { //file
+            files.push_back(path + "/" + ptr->d_name);
+        } else if (ptr->d_type == 4) {
+            //files.push_back(ptr->d_name);//dir
+            getModels(path + "/" + ptr->d_name, files);
+        }
+    }
+    closedir(dir);
+}
+void SplitString(const std::string& s,
+                  std::vector<std::string>& v, const std::string& c)
+{
+    std::string::size_type pos1, pos2;
+    pos2 = s.find(c);
+    pos1 = 0;
+    while(std::string::npos != pos2)
+    {
+        v.push_back(s.substr(pos1, pos2-pos1));
+
+        pos1 = pos2 + c.size();
+        pos2 = s.find(c, pos1);
+    }
+    if(pos1 != s.length())
+        v.push_back(s.substr(pos1));
+}
+
+int split_word_from_file(
+        std::vector<std::vector<float> > &word_idx,
+        const std::string input_file_path,
+        const std::string split_token,
+        const std::string inner_split_token,
+        const int col_select) {
+
+    std::ifstream infile(input_file_path.c_str());
+    if (!infile.good()) {
+        std::cout << "Cannot open " << std::endl;
+        return 1;
+    }
+            LOG(INFO)<<"found filename: "<<input_file_path;
+    std::string line;
+    std::vector<std::string> split_v;
+    std::vector<std::string> split_w;
+    while (std::getline(infile, line)) {
+        split_v.clear();
+        SplitString(line, split_v, split_token);
+                CHECK_GE(split_v.size(), col_select + 1) << " file need ; split";
+        std::vector<float> word;
+        std::vector<float> mention;
+        split_w.clear();
+        SplitString(split_v[col_select], split_w, inner_split_token);
+        for (auto w : split_w) {
+            word.push_back(atof(w.c_str()));
+        }
+        word_idx.push_back(word);
+    }
+    return 0;
+}
+
+int get_batch_data_offset(
+        std::vector<float> &out_data,
+        const std::vector<std::vector<float> > &seq_data,
+        std::vector<int> &seq_offset,
+        const int start_idx,
+        const int batch_num) {
+
+    seq_offset.clear();
+    out_data.clear();
+    seq_offset.push_back(0);
+    int len = 0;
+    for (int i = 0; i < batch_num; ++i) {
+        for (auto d : seq_data[i + start_idx]) {
+            len += 1;
+            out_data.push_back(d);
+        }
+        seq_offset.push_back(len);
+    }
+    return len;
+}
+
+TEST(NetTest, chinese_ner_executor) {
+
+    std::vector<std::string> models;
+    getModels(GLB_model_dir, models);
+    std::vector<std::vector<float> > word_idx;
+    if (split_word_from_file(word_idx, GLB_input_file, "\t", " ", 0)) {
+        LOG(ERROR) << " NOT FOUND " << GLB_input_file;
+        exit(-1);
+    }
+    LOG(INFO) << "READ SUCCESS!! I got " << word_idx.size() << " records";
+    std::vector<float> word_idx_data;
+    std::vector<int> word_seq_offset;
+    int batch_num = 6;
+
+    Graph<X86, AK_FLOAT, Precision::FP32> *graph_p;
+    graph_p = new Graph<X86, AK_FLOAT, Precision::FP32>();
+    LOG(WARNING) << "load anakin model file from " << models[0] << " ...";
+    // load anakin model files.
+    auto status = graph_p->load(models[0]);
+    if(!status ) {
+        LOG(FATAL) << " [ERROR] " << status.info();
+    }
+    graph_p->Reshape("input_0", {1000, 1, 1, 1});
+    //anakin graph optimization
+    graph_p->Optimize();
+    Net<X86, AK_FLOAT, Precision::FP32> net_executer(*graph_p, true);
+    SaberTimer<X86> timer;
+    Context<X86> ctx;
+
+//    for (int i = 0; i < word_idx.size(); i += batch_num) {
+    {
+#if 1
+        int i = 0;
+        //int word_len = get_batch_data_offset(word_idx_data, word_idx, word_seq_offset, i, batch_num);
+        int word_len = 7;
+        word_idx_data = {20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0};
+        word_seq_offset = {0, 5, 7};
+        for(int i=0;i<word_seq_offset.size();i++){
+            LOG(INFO)<<"seq offset ["<<i<<"] = "<<word_seq_offset[i];
+        }
+        LOG(INFO)<<"word len = "<<word_len<<",word_idx_data = "<<word_idx_data.size();
+        auto word_in_p = net_executer.get_in("input_0");
+        word_in_p->reshape({word_len, 1, 1, 1});
+
+        for (int j = 0; j < word_idx_data.size(); ++j) {
+            word_in_p->mutable_data()[j] = word_idx_data[j];
+//            word_in_p->mutable_data()[j] = j % 5000;
+        }
+
+        word_in_p->set_seq_offset(word_seq_offset);
+#endif
+//        auto word_in_p = net_executer.get_in("input_0");
+//        word_in_p->mutable_data()[0]=1;
+//        word_in_p->mutable_data()[1]=2;
+//        word_in_p->mutable_data()[2]=3;
+//        word_in_p->set_seq_offset({0,3});
+
+//        timer.start(ctx);
+        net_executer.prediction();
+//        timer.end(ctx);
+
+
+//        auto tensor_out_5_p = net_executer.get_out("fc_2.tmp_2_out");
+//        int v_size = tensor_out_5_p->valid_size();
+//        for (int j = 0; j < v_size; ++j) {
+//            std::cout << tensor_out_5_p->data()[j]<<" ";
+//        }
+//        std::cout << std::endl;
+    }
+    //LOG(INFO)<<"elapse time: "<<timer.get_average_ms()<<" ms";
+}
+
+int main(int argc, const char** argv) {
+
+    Env<X86>::env_init();
+    // initial logger
+    LOG(INFO) << "argc " << argc;
+
+    if (argc < 3) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/model_test\n \
+            anakin_models\n input file\n";
+        exit(0);
+    } else if (argc == 3) {
+        GLB_model_dir = std::string(argv[1]);
+        GLB_input_file = std::string(argv[2]);
+    }
+//    logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+#else
+int main(int argc, const char** argv) {
+    return 0;
+}
+#endif
diff --git a/test/framework/operators/operator_tests.h b/test/framework/operators/operator_tests.h
index 38f16b8..8ef440d 100644
--- a/test/framework/operators/operator_tests.h
+++ b/test/framework/operators/operator_tests.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
@@ -37,11 +37,6 @@ public:
 protected:
 };
 
-
-
-
-
-
 #endif
 
 
diff --git a/test/framework/operators/pooling_test.cpp b/test/framework/operators/pooling_test.cpp
index 47b66be..9628a87 100644
--- a/test/framework/operators/pooling_test.cpp
+++ b/test/framework/operators/pooling_test.cpp
@@ -14,6 +14,8 @@ TEST(OperatorsTest, PoolingFactoryTest) {
     std::vector<Tensor4dPtr<Target, AK_FLOAT> > in;
     std::vector<Tensor4dPtr<Target, AK_FLOAT> > out;
 
+    auto* Op_name_in =
+            OpFactory<Target, AK_FLOAT, Precision::FP32>::Global()["input"];
 
     /*Operator<RTCUDA, float>*/ auto* Op_name1 =
         OpFactory<Target, AK_FLOAT, Precision::FP32>::Global()["pooling"];
@@ -36,6 +38,7 @@ TEST(OperatorsTest, PoolingFactoryTest) {
 
 int main(int argc, const char** argv) {
     // initial logger
+    Env<Target>::env_init();
     logger::init(argv[0]);
     InitTest();
     RUN_ALL_TESTS(argv[0]);
diff --git a/test/saber/arm/test_saber_buffer_arm.cpp b/test/saber/arm/test_saber_buffer_arm.cpp
new file mode 100644
index 0000000..91d30d5
--- /dev/null
+++ b/test/saber/arm/test_saber_buffer_arm.cpp
@@ -0,0 +1,88 @@
+#include "test_saber_buffer_arm.h"
+#include "core/data_traits.h"
+using namespace anakin::saber;
+template <DataType datatype>
+void test_buffer(){
+
+    typedef TargetWrapper<ARM> ARM_API;
+    typedef typename DataTrait<ARM, datatype>::dtype Dtype;
+    typedef Buffer<ARM> BufferH;
+
+    int n0 = 1024;
+    int n1 = 2048;
+
+    void* tmp_ptr = nullptr;
+    Dtype* arm_ptr;
+    ARM_API::mem_alloc(&tmp_ptr, sizeof(Dtype) * n0);
+    arm_ptr = static_cast<Dtype*>(tmp_ptr);
+    for(int i = 0; i < n0; i++){
+        arm_ptr[i] = static_cast<Dtype>(i);
+    }
+
+    LOG(INFO) << "Buffer: test default(empty) constructor";
+    BufferH arm_buf0;
+
+    LOG(INFO) << "Buffer: test constructor with data size";
+    BufferH arm_buf1(n0 * sizeof(Dtype));
+
+    LOG(INFO) << "Buffer: test constructor with data pointer, size and device id";
+    BufferH arm_buf2(arm_ptr, n0 * sizeof(Dtype), ARM_API::get_device_id());
+
+    LOG(INFO) << "Buffer: test copy constructor";
+    BufferH arm_buf3(arm_buf2);
+    CHECK_EQ(arm_buf3.get_count(), arm_buf2.get_count()) << "shared buffer should have same data count";
+
+
+    LOG(INFO) << "Buffer: test operator =";
+    arm_buf0 = arm_buf2;
+    CHECK_EQ(arm_buf0.get_count(), arm_buf2.get_count()) << "shared buffer should have same data count";
+
+    LOG(INFO) << "Buffer: test re_alloc";
+    arm_buf1.re_alloc(n1 * sizeof(Dtype));
+    CHECK_EQ(arm_buf1.get_count(), n1 * sizeof(Dtype)) << "buffer count error";
+    CHECK_EQ(arm_buf1.get_capacity(), n1 * sizeof(Dtype)) << "buffer capacity error";
+
+    arm_buf1.re_alloc(n0 * sizeof(Dtype));
+    CHECK_EQ(arm_buf1.get_count(), n0 * sizeof(Dtype)) << "buffer count error";
+    CHECK_EQ(arm_buf1.get_capacity(), n1 * sizeof(Dtype)) << "buffer capacity error";
+
+    LOG(INFO) << "Buffer: test get_id()";
+    LOG(INFO) << "ARM device id: " << arm_buf0.get_id();
+    CHECK_EQ(ARM_API::get_device_id(), arm_buf0.get_id()) << "ARM device id error";
+
+    LOG(INFO) << "Buffer: test deep_cpy()";
+    arm_buf1.sync_copy_from(arm_buf2);
+    LOG(INFO) << "deep copy between two host buffer: ";
+    Dtype* data_ptr1 = (Dtype*)arm_buf1.get_data();
+    LOG(INFO) << "data in buffer 1";
+    for(int i = 0; i < n0;i++) {
+        printf("%.2f ", data_ptr1[i]);
+        if ((i + 1) % 10 == 0) {
+            printf("\n");
+        }
+    }
+    Dtype* data_ptr2 = (Dtype*)arm_buf2.get_data();
+    LOG(INFO) << "data in buffer2";
+    for(int i = 0; i < n0;i++) {
+        printf("%.2f ", data_ptr2[i]);
+        if ((i + 1) % 10 == 0) {
+            printf("\n");
+        }
+    }
+    CHECK_EQ(data_ptr1[n0 / 2], data_ptr2[n0 / 2]) << "deep copy between host is incorrect";
+    LOG(INFO) << "deep copy from host buffer to device buffer";
+}
+
+TEST(TestSaberBufferARM, test_buffer_memcpy) {
+    test_buffer<AK_FLOAT>();
+}
+
+int main(int argc, const char** argv){
+    // initial logger
+    logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
+
diff --git a/test/saber/arm/test_saber_buffer_arm.h b/test/saber/arm/test_saber_buffer_arm.h
new file mode 100644
index 0000000..df703c5
--- /dev/null
+++ b/test/saber/arm/test_saber_buffer_arm.h
@@ -0,0 +1,35 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN2_TEST_SABER_TEST_SABER_BUFFER_ARM_H
+#define ANAKIN2_TEST_SABER_TEST_SABER_BUFFER_ARM_H
+
+#include "utils/unit_test/aktest.h"
+#include "utils/logger/logger.h"
+#include "saber/core/buffer.h"
+
+using namespace anakin::test;
+
+class TestSaberBufferARM : public Test {
+public:
+    TestSaberBufferARM() {}
+    ~TestSaberBufferARM() {}
+
+protected:
+    virtual void setup() {}
+    virtual void teardown() {}
+
+};
+
+#endif //ANAKIN2_TEST_SABER_TEST_SABER_BUFFER_ARM_H
diff --git a/test/saber/arm/test_saber_context_ARM.cpp b/test/saber/arm/test_saber_context_ARM.cpp
new file mode 100644
index 0000000..e23f1fa
--- /dev/null
+++ b/test/saber/arm/test_saber_context_ARM.cpp
@@ -0,0 +1,43 @@
+#include "test_saber_context_ARM.h"
+
+#ifdef USE_ARM_PLACE
+
+using namespace anakin::saber;
+
+TEST(TestSaberContextARM, test_arm_context) {
+
+    Context<ARM> ctx;
+    LOG(INFO) << "create runtime ctx";
+    //ctx.set_power_mode(MERC_HIGH);
+    //ctx.set_act_cores({4, 5, 6, 7});
+    ctx.set_run_mode(SABER_POWER_HIGH, 4);
+    LOG(INFO) << "set active ids";
+
+    LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+        int threads = omp_get_num_threads();
+        printf("number of threads: %d\n", threads);
+    }
+    int th_id;
+#pragma omp parallel private(th_id)
+    {
+        th_id = omp_get_thread_num();
+#pragma omp parallel
+        printf("thread1 core ID: %d\n", th_id);
+
+    }
+}
+
+#endif
+
+int main(int argc, const char** argv){
+
+    Env<ARM>::env_init(8);
+
+    // initial logger
+    logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
\ No newline at end of file
diff --git a/test/saber/arm/test_saber_context_ARM.h b/test/saber/arm/test_saber_context_ARM.h
new file mode 100644
index 0000000..5b3dd41
--- /dev/null
+++ b/test/saber/arm/test_saber_context_ARM.h
@@ -0,0 +1,37 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN2_SABER_TEST_TEST_SABER_CONTEXT_ARM_H
+#define ANAKIN2_SABER_TEST_TEST_SABER_CONTEXT_ARM_H
+#include "utils/unit_test/aktest.h"
+#include "utils/logger/logger.h"
+#include "core/device.h"
+#include "core/env.h"
+#include "core/context.h"
+
+using namespace anakin::test;
+
+class TestSaberContextARM : public Test {
+public:
+    TestSaberContextARM() {}
+    ~TestSaberContextARM() {}
+
+protected:
+    virtual void setup() {}
+    virtual void teardown() {}
+
+};
+
+
+#endif //ANAKIN2_SABER_TEST_TEST_SABER_CONTEXT_ARM_H
diff --git a/test/saber/arm/test_saber_func_concat_arm.cpp b/test/saber/arm/test_saber_func_concat_arm.cpp
new file mode 100644
index 0000000..a0ccea0
--- /dev/null
+++ b/test/saber/arm/test_saber_func_concat_arm.cpp
@@ -0,0 +1,122 @@
+#include "core/context.h"
+#include "funcs/concat.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber_types.h"
+#include <vector>
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+TEST(TestSaberFuncTest, test_func_concat_arm) {
+
+    const int test_iter = 100;
+
+    int concat_axis = 2; // height
+    int w_in = 8;
+    int sum_hin = 8;
+    std::vector<int> h_in = {1, 2, 3, 2};
+    int ch_in = 2;
+    int num_in = 2;
+
+    Shape shape_out(num_in, ch_in, sum_hin, w_in);
+
+    ConcatParam<TensorHf4> param(concat_axis);
+
+    LOG(INFO) << " input size, num=" << num_in << ", channel=" << \
+              ch_in << ", height=" << h_in[0] << ", width=" << w_in;
+    LOG(INFO) << "input 4 tensor: h = " << h_in[0] << ", " << \
+              h_in[1] << ", " << h_in[2] << ", " << h_in[3];
+    LOG(INFO) << "concat axis= " << param.axis;
+
+    std::vector<TensorHf4*> vin;
+    std::vector<TensorHf4*> vout;
+
+    TensorHf4 th1, th2, th3, th4;
+    Shape sh1(num_in, ch_in, h_in[0], w_in);
+    Shape sh2(num_in, ch_in, h_in[1], w_in);
+    Shape sh3(num_in, ch_in, h_in[2], w_in);
+    Shape sh4(num_in, ch_in, h_in[3], w_in);
+    th1.re_alloc(sh1);
+    th2.re_alloc(sh2);
+    th3.re_alloc(sh3);
+    th4.re_alloc(sh4);
+
+    for (int j = 0; j < th1.size(); ++j) {
+        th1.mutable_data()[j] = j;
+    }
+
+    for (int j = 0; j < th2.size(); ++j) {
+        th2.mutable_data()[j] = j;
+    }
+
+    for (int j = 0; j < th3.size(); ++j) {
+        th3.mutable_data()[j] = j;
+    }
+
+    for (int j = 0; j < th4.size(); ++j) {
+        th4.mutable_data()[j] = j;
+    }
+
+    vin.push_back(&th1);
+    vin.push_back(&th2);
+    vin.push_back(&th3);
+    vin.push_back(&th4);
+
+    // start Reshape & doInfer
+    Context<ARM> ctx1(0, 1, 1);
+
+    Concat<ARM, AK_FLOAT> concat_arm;
+
+    TensorHf4 tdev_out;
+
+    vout.push_back(&tdev_out);
+
+    LOG(INFO) << "concat compute output shape";
+    concat_arm.compute_output_shape(vin, vout, param);
+    LOG(INFO) << "output shape: " << tdev_out.valid_shape()[0] << ", " \
+              << tdev_out.valid_shape()[1] << ", " << tdev_out.valid_shape()[2] \
+              << ", " << tdev_out.valid_shape()[3];
+    tdev_out.re_alloc(shape_out);
+
+    LOG(INFO) << "concat initialization";
+    concat_arm.init(vin, vout, param, SPECIFY, SABER_IMPL, ctx1);
+
+    LOG(INFO) << "concat compute";
+    SaberTimer<ARM> t1;
+    t1.clear();
+    t1.start(ctx1);
+
+    for (int i = 0; i < test_iter; ++i) {
+        concat_arm(vin, vout, param, ctx1);
+        vout[0]->record_event(ctx1.get_compute_stream());
+        vout[0]->sync();
+    }
+
+    t1.end(ctx1);
+    float ts = t1.get_average_ms();
+    printf("total time : %.4f, avg time : %.4f\n", ts, ts / test_iter);
+    print_tensor_host(*vout[0]);
+}
+
+int main(int argc, const char** argv) {
+    // initial logger
+    //logger::init(argv[0]);
+    Env<ARM>::env_init(4);
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_conv3x3_arm.cpp b/test/saber/arm/test_saber_func_conv3x3_arm.cpp
new file mode 100644
index 0000000..8b42f5e
--- /dev/null
+++ b/test/saber/arm/test_saber_func_conv3x3_arm.cpp
@@ -0,0 +1,441 @@
+#include "funcs/conv.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+int test_iter = 10;
+
+bool compare_result = false;
+bool flag_relu = false;
+bool flag_bias = true;
+
+int num = 1;
+int ch_in = 32;
+int h_in = 112;
+int w_in = 112;
+
+int ch_out = 32;
+int group = 1;
+int kernel = 3;
+int pad = 1;
+int stride = 1;
+int dila = 1;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_conv(std::vector<TensorHf4*>& tin, \
+    int ch_out, int kernel, int stride, int pad, \
+    int dila, int group, bool bias_flag, int thread_num, int cluster_id) {
+
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, thread_num);
+    LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+        LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+
+    tvout_saber.push_back(&tout_saber);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "conv param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " group = " << group;
+    LOG(INFO) << " pad = " << pad;
+    LOG(INFO) << " stride = " << stride;
+    LOG(INFO) << " dilation = " << dila;
+    LOG(INFO) << " kernel = " << kernel;
+    LOG(INFO) << " out_channels = " << ch_out;
+    LOG(INFO) << "bias flag = " << (bias_flag? "true" : "false");
+
+    int input_dim = tin[0]->height(); // P
+    int kernel_exten = dila * (kernel - 1) + 1;
+    int hout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    input_dim = tin[0]->width(); // Q
+    kernel_exten = dila * (kernel - 1) + 1;
+    int wout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    Shape shape_out{num, ch_out, hout, wout};
+
+    Shape shw{ch_out, chin / group, kernel, kernel};
+    Shape shb{1, ch_out, 1, 1};
+    TensorHf4 pweiht(shw);
+    TensorHf4 pbias(shb);
+
+    fill_tensor_host_rand(pweiht, -1.f, 1.f);
+    fill_tensor_host_rand(pbias, -1.f, 1.f);
+
+    //fill_tensor_host_const(pweiht, 1.f);
+    //fill_tensor_host_const(pbias, 1.f);
+
+    TensorHf4* bias_ptr = nullptr;
+    if (bias_flag) {
+        bias_ptr = &pbias;
+    }
+
+    ConvParam<TensorHf4> conv_param(group, pad, pad,
+                                    stride, stride,
+                                    dila, dila,
+                                    &pweiht, bias_ptr);
+    Sgemm gemmer;
+
+    if (compare_result) {
+        LOG(INFO) << "run basic conv for precision comparation";
+        tout_basic.re_alloc(shape_out);
+        size_t workspace_size = sizeof(float) * num * chin * (hin + 2 * pad) * (win + 2 * pad);
+        void* work_space_data = fast_malloc(workspace_size);
+        
+        //conv_direct_basic1(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias_flag, flag_relu, &gemmer, work_space_data);
+         to = 0;
+        for (int i = 0; i < test_iter; ++i) {
+            t1.clear();
+            t1.start(ctx1);
+            conv_arm_basic(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+             kernel, stride, stride, dila, dila, pad, pad, bias_flag, flag_relu, gemmer, nullptr);
+            t1.end(ctx1);
+            to += t1.get_average_ms();
+            if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+            }
+        }
+        LOG(INFO) << "saber basic conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+        fast_free(work_space_data);
+        //print_tensor_host(tout_basic);
+    }
+
+    Conv<ARM, AK_FLOAT> conv_saber;
+
+    conv_saber.compute_output_shape(tin, tvout_saber, conv_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber conv impl init";
+    SABER_CHECK(conv_saber.init(tin, tvout_saber, conv_param, SPECIFY, SABER_IMPL, ctx1));
+
+#if 0 //GEMMM_CONV
+    LOG(INFO) << "saber sgemm conv 3x3";
+    //! gemm impl
+    const int m = ch_out;
+    const int n = hout * wout;
+    const int k = chin * kernel * kernel;
+
+    std::shared_ptr<Buffer<ARM>> _workspace_data = std::make_shared<Buffer<ARM>>();
+    _workspace_data->re_alloc(sizeof(float) * k * n);
+
+    int l1_cache = ctx1.devs[ctx1.get_device_id()]._info._L1_cache;
+    int l2_cache = ctx1.devs[ctx1.get_device_id()]._info._L2_cache;
+    gemmer.init(l1_cache, l2_cache, m, n, k, false, false, threads);
+
+    to = 0;
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_im2col_gemm(tout_saber, *thin, pweiht.data(), pbias.data(), \
+            group, kernel, kernel, stride, stride, dila, dila, pad, pad, \
+            flag_bias, flag_relu, gemmer, _workspace_data->get_data_mutable());
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+
+    LOG(INFO) << "saber sgemm conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+
+#endif //USE_CONV_GEMM
+
+#if 0 //USE_WINOGRAD
+    LOG(INFO) << "saber winograd conv 3x3";
+    //! space for transform weights
+    std::shared_ptr<Buffer<ARM>> weigths_trans_space = std::make_shared<Buffer<ARM>>();
+    weigths_trans_space->re_alloc(sizeof(float) * 8 * 8 * ch_out * chin * 2);
+    //! space for computation
+    int tile_w = (shape_out[3] + 5) / 6;
+    int tile_h = (shape_out[2] + 5) / 6;
+    int size_tile = tile_h * tile_w;
+    int size_trans_channel = 8 * 8 * size_tile;
+    int max_ch = ch_in > ch_out? ch_in : ch_out;
+    std::shared_ptr<Buffer<ARM>> compute_space = std::make_shared<Buffer<ARM>>();
+    compute_space->re_alloc(sizeof(float) * size_trans_channel * max_ch * 2);
+
+    float* weights_trans = (float*)weigths_trans_space->get_data_mutable();
+    winograd_transform_weights(weights_trans, pweiht.data(), ch_out, chin, \
+        (void*)((char*)weigths_trans_space->get_data_mutable() + sizeof(float) * 8 * 8 * ch_out * chin));
+
+    const int m_wino = ch_out;
+    const int n_wino = size_tile;
+    const int k_wino = chin;
+    Sgemm gemmer_wino;
+    int l1_cache_wino = ctx1.devs[ctx1.get_device_id()]._info._L1_cache;
+    int l2_cache_wino = ctx1.devs[ctx1.get_device_id()]._info._L2_cache;
+    gemmer_wino.init(l1_cache_wino, l2_cache_wino, m_wino, n_wino, k_wino, false, false, threads);
+    LOG(INFO) << "l1: " << l1_cache_wino << ", l2: " << l2_cache_wino << ", m: " << m_wino << ", n: " << n_wino << \
+              ", k: " << k_wino << ", threads: " << threads;
+
+    to = 0;
+    min_time = 100000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_arm_winograd3x3(tout_saber, *thin, weights_trans, pbias.data(), group, 3, 3, 1, 1, 1, 1, 1, 1, \
+            flag_bias, flag_relu, gemmer_wino, compute_space->get_data_mutable());
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+
+    LOG(INFO) << "saber winograd conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-3f, true) << "compute result error";
+    }
+
+#endif //USE_WINOGRAD
+
+#if 1 //USE_direct
+    LOG(INFO) << "saber direct conv 3x3";
+
+    //float* dout = tout_saber.mutable_data();
+   // const float* din = thin->data();
+   //const float* wptr = pweiht.data();
+   // const float* bptr = pbias.data();
+    to = 0;
+    min_time = 100000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        //conv_3x3s1_direct(tout_saber, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias_flag, flag_relu, gemmer, nullptr);
+        conv_saber(tin, tvout_saber, conv_param, ctx1);
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+
+    LOG(INFO) << "saber direct conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        TensorHf4 tdiff(tout_basic.valid_shape());
+        tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-3f, true) << "compute result error";
+    }
+
+
+#endif //USE_direct
+
+#if 0 //ncnn_winograd
+    //! compute
+    LOG(INFO) << "ncnn winograd conv 3x3";
+    to = 0;
+    min_time = 10000000;
+    Shape sh_pad = thin->valid_shape();
+    sh_pad[2] += 2;
+    sh_pad[3] += 2;
+    Tensor<ARM, AK_FLOAT, NCHW> tin_pad(sh_pad);
+    ncnn::Mat mat_in(win, hin, chin, thin->mutable_data(), 4);
+
+    int w_ncnn = win + pad * 2;
+    int h_ncnn = hin + pad * 2;
+
+    int outw = (w_ncnn - kernel) / stride + 1;
+    int outh = (h_ncnn - kernel) / stride + 1;
+
+    ncnn::Mat top_blob(outw, outh, ch_out);
+    ncnn::Mat weight_3x3_winograd64_data;
+    ncnn::Mat weight_data_ncnn(3 * 3, chin, ch_out, pweiht.mutable_data(), 4);
+
+    conv3x3s1_winograd64_transform_kernel_neon(weight_data_ncnn, weight_3x3_winograd64_data, chin, ch_out);
+
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        //conv_saber(tin, tvout_saber, conv_param, ctx1);
+        //tensor_pad_cpu(tin_pad, *thin, 1, 1, 1, 1, BORDER_CONSTANT, 0);
+
+        ncnn::Mat bottom_blob_bordered = mat_in;
+        if (pad > 0) {
+            copy_make_border(mat_in, bottom_blob_bordered, pad, pad, pad, pad, BORDER_CONSTANT, 0.f);
+        }
+
+        conv3x3s1_winograd64_neon4(bottom_blob_bordered, top_blob, weight_3x3_winograd64_data, pbias.data());
+
+        //conv3x3s1_neon(tin_pad, tout_saber, pweiht.data(), pbias.data());
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+#endif //ncnn winograd
+
+}
+
+#if 1
+TEST(TestSaberFuncTest, test_conv_custom_size) {
+
+    int chin = ch_in;
+    int hin = h_in;
+    int win = w_in;
+
+    int dilation = dila;
+    int chout = ch_out;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if (argc >= 4) {
+        test_iter = atoi(argv[3]);
+    }
+    if (argc >= 5) {
+        compare_result = atoi(argv[4]) > 0;
+    }
+    if (argc >= 6) {
+        flag_bias = atoi(argv[5]) > 0;
+    }
+    if (argc >= 7) {
+        flag_relu = atoi(argv[6]) > 0;
+    }
+    if(argc >= 8) {
+        if (argc < 17) {
+            LOG(ERROR) << "usage: ./" << argv[0] << " cluster  threads  test_iter " << \
+                " compare_result flag_bias flag_relu num ch_in h_in w_in ch_out group" << \
+                " kernel pad stride dila";
+            return 0;
+        }
+        num = atoi(argv[7]);
+        ch_in = atoi(argv[8]);
+        h_in = atoi(argv[9]);
+        w_in = atoi(argv[10]);
+        ch_out = atoi(argv[11]);
+        group = atoi(argv[12]);
+        kernel = atoi(argv[13]);
+        pad = atoi(argv[14]);
+        stride = atoi(argv[15]);
+        dila = atoi(argv[16]);
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_conv7x7_arm.cpp b/test/saber/arm/test_saber_func_conv7x7_arm.cpp
new file mode 100644
index 0000000..3ae67a6
--- /dev/null
+++ b/test/saber/arm/test_saber_func_conv7x7_arm.cpp
@@ -0,0 +1,275 @@
+#include "funcs/conv.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 1;
+int test_iter = 10;
+
+bool compare_result = true;
+bool flag_relu = false;
+bool flag_bias = false;
+
+int num = 1;
+int ch_in = 3;
+int h_in = 7;
+int w_in = 7;
+
+int ch_out = 3;
+int group = 1;
+int kernel = 7;
+int pad = 3;
+int stride = 1;
+int dila = 1;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+        
+    }
+}
+
+void test_arm_conv(int thread_num, int cluster_id) {
+
+    int test_iter = 10;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, thread_num);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    Shape shape_in(num, ch_in, h_in, w_in);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+    TensorHf4 tout_ncnn;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+
+    tvout_saber.push_back(&tout_saber);
+    //tvout_saber.push_back(&tout_ncnn);
+    tvout_basic.push_back(&tout_basic);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "conv param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " group = " << group;
+    LOG(INFO) << " pad = " << pad;
+    LOG(INFO) << " stride = " << stride;
+    LOG(INFO) << " dilation = " << dila;
+    LOG(INFO) << " kernel = " << kernel;
+    LOG(INFO) << " out_channels = " << ch_out;
+
+    int input_dim = tin[0]->height(); // P
+    int kernel_exten = dila * (kernel - 1) + 1;
+    int hout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    input_dim = tin[0]->width(); // Q
+    kernel_exten = dila * (kernel - 1) + 1;
+    int wout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    Shape shape_out{num, ch_out, hout, wout};
+
+    Shape shw{ch_out, chin / group, kernel, kernel};
+    Shape shb{1, ch_out, 1, 1};
+    TensorHf4 pweiht(shw);
+    TensorHf4 pbias(shb);
+
+    fill_tensor_host_rand(pweiht, -1.f, 1.f);
+    //fill_tensor_host_rand(pbias, -1.f, 1.f);
+    //fill_tensor_host_const(pweiht, 1.f);
+    fill_tensor_host_const(pbias, 1.f);
+
+    TensorHf4 bias_ptr;
+    if (flag_bias) {
+        bias_ptr = pbias;
+    }
+    /*
+    printf("initial input tensor: \n");
+    print_tensor_host(*tin[0]); 
+  
+    printf("initial weights tensor: \n");
+    print_tensor_host(pweiht);
+   */
+    ConvParam<TensorHf4> conv_param(group, pad, pad,
+                                    stride, stride,
+                                    dila, dila,
+                                    &pweiht, &bias_ptr);
+
+     size_t workspace_size = sizeof(float) * num * chin * (hin + 2 * pad) * (win + 2 * pad);
+     void* work_space_data = fast_malloc(workspace_size);
+    if (compare_result) {
+                LOG(INFO) << "run basic conv for precision comparation";
+        tout_basic.re_alloc(shape_out);
+       
+        Sgemm gemmer;
+        //int test_iter = 10;
+        //double to = 0;
+        //double min_time = 1000000;
+        SaberTimer<ARM> t1;
+        for (int i = 0; i < test_iter; ++i) {
+            t1.clear();
+            t1.start(ctx1);
+            //eltwise_basic(ctx1, tout_basic, tin, operation, coeffs_ptr, num_coeff);
+            conv_arm_basic(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+               kernel, stride, stride, dila, dila, pad, pad, flag_bias, flag_relu, gemmer,work_space_data);
+            tvout_basic[0] ->record_event(ctx1.get_compute_stream());
+            tvout_basic[0] ->sync();
+            t1.end(ctx1);
+            to += t1.get_average_ms();
+            if (t1.get_average_ms() < min_time) {
+                min_time = t1.get_average_ms();
+             }
+        }
+        fast_free(work_space_data);
+        LOG(INFO) << "basic conv7x7 running time, ave: " << to / test_iter << ", min time: " << min_time;
+        //print_tensor_host(tout_basic);
+        
+        //fast_free(work_space_data);
+        //print_tensor_host(tout_basic);
+    }
+
+    Conv<ARM, AK_FLOAT> conv_saber;
+
+    conv_saber.compute_output_shape(tin, tvout_saber, conv_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+   //LOG(INFO) << "output shape1: " << sh_out_saber[0] << ", " << sh_out_saber[1] << ", " \
+        << sh_out_saber[2] << ", " << sh_out_saber[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+    //tvout_saber[1]->re_alloc(shape_out);
+
+    Sgemm gemmer;
+
+    LOG(INFO) << "saber conv7x7 impl init";
+    SABER_CHECK(conv_saber.init(tin, tvout_saber, conv_param, SPECIFY, SABER_IMPL, ctx1));
+    //int test_iter = 10;
+    to = 0;
+    min_time = 1000000;
+    //SaberTimer<ARM> t1;
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_saber(tin, tvout_saber, conv_param, ctx1);
+        //conv_arm_7x7s1(tout_saber, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, flag_bias, flag_relu, &gemmer,work_space_data);
+        tvout_saber[0] ->record_event(ctx1.get_compute_stream());
+        tvout_saber[0] ->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+
+    //fast_free(work_space_data);
+    LOG(INFO) << "saber conv7x7 running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        TensorHf4 tdiff(tout_basic.valid_shape());
+        tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+}
+
+TEST(TestSaberFuncTest, test_func_conv_basic) {
+    test_arm_conv(threads, cluster);
+}
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if(argc >= 4) {
+        if (argc < 15) {
+            LOG(ERROR) << "usage: ./" << argv[0] << " cluster  threads  num ch_in" << \
+                " h_in w_in ch_out group kernel pad stride dila flag_bias flag_relu test_iter compare_result";
+            return 0;
+        }
+        num = atoi(argv[3]);
+        ch_in = atoi(argv[4]);
+        h_in = atoi(argv[5]);
+        w_in = atoi(argv[6]);
+        ch_out = atoi(argv[7]);
+        group = atoi(argv[8]);
+        kernel = atoi(argv[9]);
+        pad = atoi(argv[10]);
+        stride = atoi(argv[11]);
+        dila = atoi(argv[12]);
+        flag_bias = atoi(argv[13]) > 0;
+        flag_relu = atoi(argv[14]) > 0;
+    }
+    if (argc > 15) {
+        test_iter = atoi(argv[15]);
+    }
+    if (argc > 16) {
+        compare_result = atoi(argv[16]) > 0;
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_conv_arm.cpp b/test/saber/arm/test_saber_func_conv_arm.cpp
new file mode 100644
index 0000000..4062b39
--- /dev/null
+++ b/test/saber/arm/test_saber_func_conv_arm.cpp
@@ -0,0 +1,442 @@
+#include "funcs/conv.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+int test_iter = 10;
+
+bool compare_result = false;
+bool flag_relu = false;
+bool flag_bias = true;
+
+int num = 1;
+int ch_in = 32;
+int h_in = 112;
+int w_in = 112;
+
+int ch_out = 64;
+int group = 1;
+int kernel = 3;
+int pad = 1;
+int stride = 1;
+int dila = 1;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_conv(std::vector<TensorHf4*>& tin, \
+    int ch_out, int kernel, int stride, int pad, \
+    int dila, int group, bool bias_flag, int thread_num, int cluster_id) {
+
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, thread_num);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+
+    tvout_saber.push_back(&tout_saber);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "conv param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " group = " << group;
+    LOG(INFO) << " pad = " << pad;
+    LOG(INFO) << " stride = " << stride;
+    LOG(INFO) << " dilation = " << dila;
+    LOG(INFO) << " kernel = " << kernel;
+    LOG(INFO) << " out_channels = " << ch_out;
+    LOG(INFO) << "bias flag = " << (bias_flag? "true" : "false");
+
+    int input_dim = tin[0]->height(); // P
+    int kernel_exten = dila * (kernel - 1) + 1;
+    int hout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    input_dim = tin[0]->width(); // Q
+    kernel_exten = dila * (kernel - 1) + 1;
+    int wout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    Shape shape_out{num, ch_out, hout, wout};
+
+    Shape shw{ch_out, chin / group, kernel, kernel};
+    Shape shb{1, ch_out, 1, 1};
+    TensorHf4 pweiht(shw);
+    TensorHf4 pbias(shb);
+
+    fill_tensor_host_rand(pweiht, -1.f, 1.f);
+    fill_tensor_host_rand(pbias, -1.f, 1.f);
+
+    //fill_tensor_host_const(pweiht, 1.f);
+    //fill_tensor_host_const(pbias, 1.f);
+
+    TensorHf4* bias_ptr = nullptr;
+    if (bias_flag) {
+        bias_ptr = &pbias;
+    }
+
+    ConvParam<TensorHf4> conv_param(group, pad, pad,
+                                    stride, stride,
+                                    dila, dila,
+                                    &pweiht, bias_ptr);
+
+    if (compare_result) {
+        LOG(INFO) << "run basic conv for precision comparation";
+        tout_basic.re_alloc(shape_out);
+        //size_t workspace_size = sizeof(float) * num * chin * (hin + 2 * pad) * (win + 2 * pad);
+        //void* work_space_data = fast_malloc(workspace_size);
+        Sgemm gemmer;
+        conv_arm_basic(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias_flag, flag_relu, gemmer, nullptr);
+        //conv_direct_basic1(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias_flag, flag_relu, &gemmer, work_space_data);
+        //fast_free(work_space_data);
+        //print_tensor_host(tout_basic);
+    }
+
+    Conv<ARM, AK_FLOAT> conv_saber;
+
+    conv_saber.compute_output_shape(tin, tvout_saber, conv_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber conv impl init";
+    SABER_CHECK(conv_saber.init(tin, tvout_saber, conv_param, SPECIFY, SABER_IMPL, ctx1));
+
+    //! compute
+    LOG(INFO) << "saber conv compute";
+    to = 0;
+
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_saber(tin, tvout_saber, conv_param, ctx1);
+        //tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        //tvout_saber[0]->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(*tvout_saber[0]);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+
+}
+
+#if 0
+TEST(TestSaberFuncTest, test_func_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 3;
+    int hin = 224;
+    int win = 224;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    //fill_tensor_host_rand(tdin, -1.f, 1.f);
+    fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, 4, 0);
+    //LOG(WARNING) << "conv3x3s1 not support yet";
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, -1.f);
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 0;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, -1.f);
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 0;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, -1.f);
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+
+#if 1
+TEST(TestSaberFuncTest, test_conv_custom_size) {
+
+    int chin = ch_in;
+    int hin = h_in;
+    int win = w_in;
+
+    int dilation = dila;
+    int chout = ch_out;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if (argc >= 4) {
+        test_iter = atoi(argv[3]);
+    }
+    if (argc >= 5) {
+        compare_result = atoi(argv[4]) > 0;
+    }
+    if (argc >= 6) {
+        flag_bias = atoi(argv[5]) > 0;
+    }
+    if (argc >= 7) {
+        flag_relu = atoi(argv[6]) > 0;
+    }
+    if(argc >= 8) {
+        if (argc < 17) {
+            LOG(ERROR) << "usage: ./" << argv[0] << " cluster  threads  test_iter " << \
+                " compare_result flag_bias flag_relu num ch_in h_in w_in ch_out group" << \
+                " kernel pad stride dila";
+            return 0;
+        }
+        num = atoi(argv[7]);
+        ch_in = atoi(argv[8]);
+        h_in = atoi(argv[9]);
+        w_in = atoi(argv[10]);
+        ch_out = atoi(argv[11]);
+        group = atoi(argv[12]);
+        kernel = atoi(argv[13]);
+        pad = atoi(argv[14]);
+        stride = atoi(argv[15]);
+        dila = atoi(argv[16]);
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_convact_arm.cpp b/test/saber/arm/test_saber_func_convact_arm.cpp
new file mode 100644
index 0000000..6aee66f
--- /dev/null
+++ b/test/saber/arm/test_saber_func_convact_arm.cpp
@@ -0,0 +1,369 @@
+#include "funcs/conv_act.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+#define USE_COMPARE
+const bool FLAG_RELU = true;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_conv(std::vector<TensorHf4*>& tin, \
+    int ch_out, int kernel, int stride, int pad, \
+    int dila, int group, bool bias, int thread_num, int cluster_id) {
+
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, thread_num);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+
+    tvout_saber.push_back(&tout_saber);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "conv param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " group = " << group;
+    LOG(INFO) << " pad = " << pad;
+    LOG(INFO) << " stride = " << stride;
+    LOG(INFO) << " dilation = " << dila;
+    LOG(INFO) << " kernel = " << kernel;
+    LOG(INFO) << " out_channels = " << ch_out;
+
+    int input_dim = tin[0]->height(); // P
+    int kernel_exten = dila * (kernel - 1) + 1;
+    int hout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    input_dim = tin[0]->width(); // Q
+    kernel_exten = dila * (kernel - 1) + 1;
+    int wout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    Shape shape_out{num, ch_out, hout, wout};
+
+    Shape shw{ch_out, chin / group, kernel, kernel};
+    Shape shb{1, ch_out, 1, 1};
+    TensorHf4 pweiht(shw);
+    TensorHf4 pbias(shb);
+
+    fill_tensor_host_rand(pweiht, -1.f, 1.f);
+    fill_tensor_host_rand(pbias, -1.f, 1.f);
+
+    //fill_tensor_host_const(pweiht, 1.f);
+    //fill_tensor_host_const(pbias, 1.f);
+
+    TensorHf4* bias_ptr = nullptr;
+    if (bias) {
+        bias_ptr = &pbias;
+    }
+
+    ConvParam<TensorHf4> conv_param(group, pad, pad,
+                                    stride, stride,
+                                    dila, dila,
+                                    &pweiht, bias_ptr);
+
+    ActivationParam<TensorHf4> act_param(Active_relu);
+
+    ConvActiveParam<TensorHf4> conv_act_param(conv_param, act_param);
+
+#ifdef USE_COMPARE
+    LOG(INFO) << "run basic conv for precision comparation";
+    tout_basic.re_alloc(shape_out);
+    size_t workspace_size = sizeof(float) * num * chin * (hin + 2 * pad) * (win + 2 * pad);
+    void* work_space_data = fast_malloc(workspace_size);
+    Sgemm gemmer;
+    //conv_direct_basic1(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias, true, &gemmer,work_space_data);
+    fast_free(work_space_data);
+    //print_tensor_host(tout_basic);
+#endif
+    ConvAct<ARM, AK_FLOAT> conv_saber;
+
+    conv_saber.compute_output_shape(tin, tvout_saber, conv_act_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber conv impl init";
+    SABER_CHECK(conv_saber.init(tin, tvout_saber, conv_act_param, SPECIFY, SABER_IMPL, ctx1));
+
+    //! compute
+    LOG(INFO) << "saber conv compute";
+    to = 0;
+
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_saber(tin, tvout_saber, conv_act_param, ctx1);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(*tvout_saber[0]);
+
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+#if 0
+TEST(TestSaberFuncTest, test_func_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 3;
+    int hin = 224;
+    int win = 224;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    //fill_tensor_host_rand(tdin, -1.f, 1.f);
+    fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, thread, cluster);
+    //LOG(WARNING) << "conv3x3s1 not support yet";
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv_relu_3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_convactpooling_arm.cpp b/test/saber/arm/test_saber_func_convactpooling_arm.cpp
new file mode 100644
index 0000000..75d1043
--- /dev/null
+++ b/test/saber/arm/test_saber_func_convactpooling_arm.cpp
@@ -0,0 +1,373 @@
+#include "funcs/conv_act_pooling.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/conv_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+#define USE_COMPARE
+const bool FLAG_RELU = true;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_conv(std::vector<TensorHf4*>& tin, \
+    int ch_out, int kernel, int stride, int pad, \
+    int dila, int group, bool bias, int thread_num, int cluster_id) {
+
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, thread_num);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+
+    tvout_saber.push_back(&tout_saber);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "conv param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " group = " << group;
+    LOG(INFO) << " pad = " << pad;
+    LOG(INFO) << " stride = " << stride;
+    LOG(INFO) << " dilation = " << dila;
+    LOG(INFO) << " kernel = " << kernel;
+    LOG(INFO) << " out_channels = " << ch_out;
+
+    int input_dim = tin[0]->height(); // P
+    int kernel_exten = dila * (kernel - 1) + 1;
+    int hout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    input_dim = tin[0]->width(); // Q
+    kernel_exten = dila * (kernel - 1) + 1;
+    int wout = (input_dim + 2 * pad - kernel_exten) / stride + 1;
+
+    Shape shape_out{num, ch_out, 1, 1};
+
+    Shape shw{ch_out, chin / group, kernel, kernel};
+    Shape shb{1, ch_out, 1, 1};
+    TensorHf4 pweiht(shw);
+    TensorHf4 pbias(shb);
+
+    fill_tensor_host_rand(pweiht, -1.f, 1.f);
+    fill_tensor_host_rand(pbias, -1.f, 1.f);
+
+    //fill_tensor_host_const(pweiht, 1.f);
+    //fill_tensor_host_const(pbias, 1.f);
+
+    TensorHf4* bias_ptr = nullptr;
+    if (bias) {
+        bias_ptr = &pbias;
+    }
+
+    ConvParam<TensorHf4> conv_param(group, pad, pad,
+                                    stride, stride,
+                                    dila, dila,
+                                    &pweiht, bias_ptr);
+
+    ActivationParam<TensorHf4> act_param(Active_relu);
+
+    PoolingParam<TensorHf4> pool_param(1, 1, 1, 1, 1, 1, Pooling_average_exclude_padding, true);
+
+    //ConvActiveParam<TensorHf4> conv_act_param(conv_param, act_param);
+
+    ConvActivePoolingParam<TensorHf4> conv_act_pool_param(conv_param, act_param, pool_param);
+
+#ifdef USE_COMPARE
+    LOG(INFO) << "run basic conv for precision comparation";
+    tout_basic.re_alloc(shape_out);
+    size_t workspace_size = sizeof(float) * num * chin * (hin + 2 * pad) * (win + 2 * pad);
+    void* work_space_data = fast_malloc(workspace_size);
+    Sgemm gemmer;
+    //conv_direct_basic1(tout_basic, *thin, pweiht.data(), pbias.data(), group, kernel, \
+        kernel, stride, stride, dila, dila, pad, pad, bias, true, &gemmer,work_space_data);
+    fast_free(work_space_data);
+    //print_tensor_host(tout_basic);
+#endif
+    ConvActPooling<ARM, AK_FLOAT> conv_saber;
+
+    conv_saber.compute_output_shape(tin, tvout_saber, conv_act_pool_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber conv impl init";
+    SABER_CHECK(conv_saber.init(tin, tvout_saber, conv_act_pool_param, SPECIFY, SABER_IMPL, ctx1));
+
+    //! compute
+    LOG(INFO) << "saber conv compute";
+    to = 0;
+
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        conv_saber(tin, tvout_saber, conv_act_pool_param, ctx1);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(*tvout_saber[0]);
+
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+#if 0
+TEST(TestSaberFuncTest, test_func_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 3;
+    int hin = 224;
+    int win = 224;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    //fill_tensor_host_rand(tdin, -1.f, 1.f);
+    fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, thread, cluster);
+    //LOG(WARNING) << "conv3x3s1 not support yet";
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv_relu_3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_conv1x1s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = 1;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 1;
+    int chout = 64;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s1_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 1;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+#if 1
+TEST(TestSaberFuncTest, test_func_depthwise_conv3x3s2_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int group = chin;
+    int pad = 1;
+    int stride = 2;
+    int dilation = 1;
+    int kernel = 3;
+    int chout = chin;
+
+    bool bias_term = true;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_conv(tin, chout, kernel, stride, pad, dilation, group, bias_term, threads, cluster);
+}
+#endif
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_detection_output_arm.cpp b/test/saber/arm/test_saber_func_detection_output_arm.cpp
new file mode 100644
index 0000000..eab6ca9
--- /dev/null
+++ b/test/saber/arm/test_saber_func_detection_output_arm.cpp
@@ -0,0 +1,158 @@
+#include "funcs/detection_output.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+#define USE_DUMP_TENSOR 1
+
+TEST(TestSaberFuncTest, test_detection_output) {
+
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    int iter = 100;
+
+    typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+    //! batch size = 16, boxes = 1917, loc = boxes * 4
+    Shape sh_loc{16, 7668, 1, 1};
+    //! batch size = 16, boxes = 1917, conf = boxes * 21
+    Shape sh_conf{16, 40257, 1, 1};
+    //! size = 2, boxes * 4
+    Shape sh_prior{1, 1, 2, 7668};
+
+    Shape sh_res_cmp{1, 1, 16, 7};
+
+#if USE_DUMP_TENSOR
+    std::vector<float> loc_data; //!first input tensor
+    std::vector<float> conf_data;//! second input tensor
+    std::vector<float> prior_data;//! third input tensor
+
+    std::vector<float> result_data;//! output tensor to compare with
+
+    if (read_file(loc_data, "data/loc_data.txt") != 0) {
+        LOG(FATAL) << "file not exist!!!";
+    }
+
+    if (read_file(conf_data, "data/conf_data.txt") != 0) {
+        LOG(FATAL) << "file not exist!!!";
+    }
+
+    if (read_file(prior_data, "data/prior_data.txt") != 0) {
+        LOG(FATAL) << "file not exist!!!";
+    }
+
+    if (read_file(result_data, "data/detection_output.txt") != 0) {
+        LOG(FATAL) << "file not exist!!!";
+    }
+
+    TensorHf4 tdloc(loc_data.data(), ARM(), 0, sh_loc);
+    TensorHf4 tdconf(conf_data.data(), ARM(), 0, sh_conf);
+    TensorHf4 tdprior(prior_data.data(), ARM(), 0, sh_prior);
+#else
+
+    TensorHf4 tdloc(sh_loc);
+    TensorHf4 tdconf(sh_conf);
+    TensorHf4 tdprior(sh_prior);
+    fill_tensor_host_rand(tdloc, 0.f, 1.f);
+    fill_tensor_host_rand(tdconf, 0.f, .2f);
+    fill_tensor_host_rand(tdprior, 0.f, 1.f);
+#endif
+
+    TensorHf4 tdout;
+
+    std::vector<TensorHf4*> inputs;
+    std::vector<TensorHf4*> outputs;
+
+    inputs.push_back(&tdloc);
+    inputs.push_back(&tdconf);
+    inputs.push_back(&tdprior);
+    outputs.push_back(&tdout);
+
+    DetectionOutputParam<TensorHf4> param;
+    param.init(21, 0, 100, 100, 0.45f, 0.25f, true, false, 2);
+
+    DetectionOutput<ARM, AK_FLOAT> det_dev;
+
+    LOG(INFO) << "detection output compute output shape";
+    SABER_CHECK(det_dev.compute_output_shape(inputs, outputs, param));
+    Shape va_sh{1, 1, param.keep_top_k, 7};
+    LOG(INFO) << "output shape pre alloc: " << va_sh[0] << ", " << va_sh[1] << \
+              ", " << va_sh[2] << ", " << va_sh[3];
+    CHECK_EQ(va_sh == outputs[0]->valid_shape(), true) << "compute shape error";
+
+    LOG(INFO) << "detection output init";
+    SABER_CHECK(det_dev.init(inputs, outputs, param, RUNTIME, SABER_IMPL, ctx1));
+
+    LOG(INFO) << "detection output compute";
+    double to = 0;
+    double tmin = 1000000;
+    SaberTimer<ARM> t1;
+    for (int i = 0; i < iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        SABER_CHECK(det_dev(inputs, outputs, param, ctx1));
+        //outputs[0]->record_event(ctx1.get_compute_stream());
+        //outputs[0]->sync();
+        //cudaDeviceSynchronize();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < tmin) {
+            tmin = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "output size: " << outputs[0]->valid_shape()[0] << ", " << \
+              outputs[0]->valid_shape()[1] << ", " << outputs[0]->valid_shape()[2] << \
+              ", " << outputs[0]->valid_shape()[3];
+    LOG(INFO) << "avg time: " << to / iter << ", min time: " << tmin;
+
+    print_tensor_host(*outputs[0]);
+
+#if USE_DUMP_TENSOR
+    TensorHf4 thout(outputs[0]->valid_shape());
+    thout.copy_from(*outputs[0]);
+
+    CHECK_EQ(thout.size(), result_data.size()) << "detection compute error";
+
+    double max_ratio = 0;
+    double max_diff = 0;
+    tensor_cmp_host(result_data.data(), thout.data(), thout.size(), max_ratio, max_diff);
+    LOG(INFO) << "detection output error: " << max_diff << ", max_ratio: " << max_ratio;
+    CHECK_EQ(max_ratio < 1e-5f, true) << "detection compute error";
+#else
+    LOG(INFO) << "current unit test need read tensor from disk file";
+
+#endif //USE_DUMP_TENSOR
+}
+
+int main(int argc, const char** argv) {
+    Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_eltwise_active_arm.cpp b/test/saber/arm/test_saber_func_eltwise_active_arm.cpp
new file mode 100755
index 0000000..ef50c7b
--- /dev/null
+++ b/test/saber/arm/test_saber_func_eltwise_active_arm.cpp
@@ -0,0 +1,277 @@
+#include "saber/funcs/eltwise_act.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber_types.h"
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, threads, 1);
+DEFINE_GLOBAL(int, cluster_id, 0);
+DEFINE_GLOBAL(int, operation, 1);
+DEFINE_GLOBAL(int, num_coeff, 0);
+#define USE_COMPARE
+
+using namespace anakin::saber;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+void test_arm_eltwise(std::vector<TensorHf4*>& tin, EltwiseType operation, \
+     std::vector<float> coeffs_ptr, int num_coeff, int threads, int cluster_id) {
+
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+    SaberTimer<ARM> t2;
+
+    Context<ARM> ctx1;
+    Context<ARM> ctx2;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    //TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+    tvout_saber.push_back(&tout_saber);
+    tvout_basic.push_back(&tout_basic);
+
+    int numin = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+    int pad = 0;
+
+    LOG(INFO) << "eltwise active param: ";
+    LOG(INFO) << " img_num = " << numin;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+   // enum { Eltwise_prod = 1, Eltwise_sum = 2, Eltwise_max = 3 };
+    if (operation == 1)
+        LOG(INFO) << " operation = " << Eltwise_prod;
+    if (operation == 2)
+        LOG(INFO) << " operation = " << Eltwise_sum;
+    if (operation == 3)
+        LOG(INFO) << " operation = " << Eltwise_max;
+    LOG(INFO) << "active =" << (ActiveType) Active_relu;
+
+    int input_dim = 1;
+    Shape shape_out = tin[0]->valid_shape();
+    for (int i = 0; i < 4; i++){
+    	shape_out[i] = tin[0]->valid_shape()[i];
+    }
+   //Shape shape_out{num, ch_out, h_out, w_out}
+
+#ifdef USE_COMPARE
+
+/*
+    LOG(INFO) << "initial input tensor data 0:";
+    print_tensor_host(*tin[0]);
+    LOG(INFO) << "initial input tensor data 1:";
+    print_tensor_host(*tin[1]);
+*/
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+
+    /* LOG(INFO) << "run basic eltwise active for precision comparation";
+    tout_basic.re_alloc(shape_out);
+    size_t workspace_size = sizeof(float) * numin * chin * (hin + 2 * pad) * (win + 2 * pad);
+    void* work_space_data = fast_malloc(workspace_size);
+   
+   to = 0;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        eltwise_active_basic(ctx1, tout_basic, tin, operation, coeffs_ptr, num_coeff, Active_relu);
+        
+        tvout_basic[0] ->record_event(ctx1.get_compute_stream());
+        tvout_basic[0] ->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    fast_free(work_space_data);
+    LOG(INFO) << "basic eltwise running time, ave: " << to / test_iter << ", min time: " << min_time;
+   // print_tensor_host(tout_basic);
+
+    
+  
+  LOG(INFO) << "run ncnn eltwise for precision comparation";
+    TensorHf4 tout_basic2;
+    tout_basic2.re_alloc(shape_out);
+     to = 0;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+
+        eltwise_act_ncnn(ctx1, tout_basic2, tin, operation, coeffs_ptr, num_coeff, Active_relu);
+
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "ncnn eltwise running time, ave: " << to/test_iter << ", min time: " << min_time;
+    double max_ratio1 = 0;
+    double max_diff1 = 0;
+    tensor_cmp_host(tout_basic.data(), tout_basic2.data(), tout_basic.valid_size(), max_ratio1, max_diff1);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff1 << ", max ratio: " << max_ratio1;
+    //CHECK_EQ(fabsf(max_ratio1) < 1e-5f, true) << "compute result error";
+*/
+#endif
+    
+    EltwiseActive<ARM, AK_FLOAT> eltwise_act_saber;
+    EltwiseParam<TensorHf4> eltwise_param(operation, coeffs_ptr);
+    ActivationParam<TensorHf4> activation_param(Active_relu);
+    EltwiseActiveParam<TensorHf4> eltwise_act_param(eltwise_param, activation_param);
+
+    eltwise_act_saber.compute_output_shape(tin, tvout_saber, eltwise_act_param);
+
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape_1: " << sh_out_saber[0] << ", " << sh_out_saber[1] << ", " \
+        << sh_out_saber[2] << ", " << sh_out_saber[3];
+    //LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber eltwise act impl init";
+    SABER_CHECK(eltwise_act_saber.init(tin, tvout_saber, eltwise_act_param, SPECIFY, SABER_IMPL, ctx1));
+
+    //! compute
+    LOG(INFO) << "saber eltwise act compute";
+    to = 0;
+    min_time = 1000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t2.clear();
+        t2.start(ctx1);
+       // pooling_saber(tin, tvout_saber, pooling_param, ctx1);
+        //eltwise_arm(ctx2, tout_saber, tin, operation, coeffs_ptr, num_coeff);
+        eltwise_act_saber(tin, tvout_saber, eltwise_act_param, ctx1);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t2.end(ctx1);
+        //printf("i: %d \n",i);
+        to += t2.get_average_ms();
+        if (t2.get_average_ms() < min_time) {
+            min_time = t2.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber eltwise active running time, ave: " << to / test_iter << ", min time: " << min_time;
+   // print_tensor_host(tout_saber);
+    //print_tensor_host(*tvout_saber[0]);
+
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+  //  tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+#if 1
+TEST(TestSaberFuncTest, test_func_eltwise_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int pad = 1;
+    int stride = 2;
+    int kernel = 3;
+    //int chout = 3;
+
+   // bool bias_term = false;
+   // bool global = true;
+   // PoolingType type = 1;
+
+    Shape shape_in(num, chin, hin, win);
+
+    
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    TensorHf4 tdin;
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    TensorHf4 tdin1;
+    tdin1.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin1, -1.f, 1.f);
+    
+    tin.push_back(&tdin);
+    tin.push_back(&tdin1);
+    
+    
+    std::vector<float> coeffs_ptr;
+   
+	coeffs_ptr.push_back(1.0f);
+	coeffs_ptr.push_back(1.0f);
+    //printf("test_arm_eltwise: GLB_operation: %d \n", GLB_operation);
+    test_arm_eltwise(tin, (EltwiseType)GLB_operation, coeffs_ptr, GLB_num_coeff, GLB_threads, GLB_cluster_id);
+    //LOG(WARNING) << "pooling not support yet";
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    // initial logger
+    //logger::init(argv[0]);
+   // printf("Test0:\n");
+     if (argc < 1) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/eltwise_test\n \
+            threads\n \
+            cluster_id\n \
+            operation\n \
+            num_coeff\n  ";
+        exit(0);
+    } else if (argc == 3){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+    }else if (argc == 5){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+        GLB_operation = atoi(argv[3]);
+        GLB_num_coeff = atoi(argv[4]);
+    }
+    //printf("Test:\n");
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
+
+
diff --git a/test/saber/arm/test_saber_func_eltwise_arm.cpp b/test/saber/arm/test_saber_func_eltwise_arm.cpp
new file mode 100644
index 0000000..a8c853a
--- /dev/null
+++ b/test/saber/arm/test_saber_func_eltwise_arm.cpp
@@ -0,0 +1,428 @@
+#include "saber/funcs/eltwise.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, threads, 1);
+DEFINE_GLOBAL(int, cluster_id, 0);
+DEFINE_GLOBAL(int, operation, 1);
+DEFINE_GLOBAL(int, num_coeff, 0);
+#define USE_COMPARE
+
+using namespace anakin::saber;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+void eltwise_basic(const Context<ARM> &ctx, Tensor<ARM, AK_FLOAT, NCHW>& tensor_out, \ 
+    std::vector<Tensor<ARM, AK_FLOAT, NCHW>*> &tensor_in,\
+    int op_type, std::vector<float> coeffs_ptr, int num_coeff) {
+    CHECK_GT(tensor_out.size(), 0) << "output tensor is empty";
+    CHECK_GT(tensor_in.size(), 1) << "input tensor is empty";
+
+    int w_in = tensor_in[0]->width();
+    int h_in = tensor_in[0]->height();
+    int ch_in = tensor_in[0]->channel();
+    int num = tensor_in[0]->num();
+    int size_in = w_in * h_in;
+
+    float* data_out = tensor_out.mutable_data();
+    const float* data_in0 = tensor_in[0]->data();
+    const float* data_in1 = tensor_in[1]->data();
+    
+    if (op_type == 1){ //Operation_PROD
+        for (int n = 0; n < num; n++){
+            float* data_out_batch = data_out + n * ch_in * size_in;
+            const float* data_in0_batch = data_in0 + n * ch_in * size_in;
+            const float* data_in1_batch = data_in1 + n * ch_in * size_in;
+
+#pragma omp parallel for
+            for (int c = 0; c < ch_in; c++){
+                float* data_out_channel = data_out_batch + c * size_in;
+                const float* data_in0_channel = data_in0_batch + c * size_in;
+                const float* data_in1_channel = data_in1_batch + c * size_in;
+                for (int i = 0; i < size_in; i++){
+                    data_out_channel[i] = data_in0_channel[i] * data_in1_channel[i];
+                }
+            }
+        }
+        for (int b = 2; b <tensor_in.size(); b++){
+            const float* data_in = tensor_in[b]->data();
+            for (int n = 0; n < num; n++){
+                float* data_out_batch = data_out + n * ch_in * size_in;
+                const float* data_in_batch = data_in + n * ch_in * size_in;
+
+#pragma omp parallel for
+                for (int c = 0; c < ch_in; c++){
+                    float* data_out_channel = data_out_batch + c * size_in;
+                    const float* data_in_channel = data_in_batch + c * size_in;
+                    for (int i = 0; i < size_in; i++){
+                        data_out_channel[i] = data_out_channel[i] * data_in_channel[i];
+                    }
+                }
+            }
+        }
+    }
+    if (op_type == 2){ //Operation_SUM
+        if (num_coeff == 0){
+            for (int n = 0; n < num; n++){
+                float* data_out_batch = data_out + n * ch_in * size_in;
+                const float* data_in0_batch = data_in0 + n * ch_in * size_in;
+                const float* data_in1_batch = data_in1 + n * ch_in * size_in;
+
+#pragma omp parallel for
+                for (int c = 0; c < ch_in; c++){
+                    float* data_out_channel = data_out_batch + c * size_in;
+                    const float* data_in0_channel = data_in0_batch + c * size_in;
+                    const float* data_in1_channel = data_in1_batch + c * size_in;
+                    for (int i = 0; i < size_in; i++){
+                        data_out_channel[i] = data_in0_channel[i] + data_in1_channel[i];
+                    }
+                }
+            }
+            for (int b = 2; b <tensor_in.size(); b++){
+                const float* data_in = tensor_in[b]->data();
+                for (int n = 0; n < num; n++){
+                    float* data_out_batch = data_out + n * ch_in * size_in;
+                    const float* data_in_batch = data_in + n * ch_in * size_in;
+
+#pragma omp parallel for
+                    for (int c = 0; c < ch_in; c++){
+                        float* data_out_channel = data_out_batch + c * size_in;
+                        const float* data_in_channel = data_in_batch + c * size_in;
+                        for (int i = 0; i < size_in; i++){
+                            data_out_channel[i] = data_out_channel[i] + data_in_channel[i];
+                        }
+                    }
+                }
+            }
+        }else{
+            for (int n = 0; n < num; n++){
+                float* data_out_batch = data_out + n * ch_in * size_in;
+                const float* data_in0_batch = data_in0 + n * ch_in * size_in;
+                const float* data_in1_batch = data_in1 + n * ch_in * size_in;
+
+#pragma omp parallel for
+                for (int c = 0; c < ch_in; c++){
+                    float* data_out_channel = data_out_batch + c * size_in;
+                    const float* data_in0_channel = data_in0_batch + c * size_in;
+                    const float* data_in1_channel = data_in1_batch + c * size_in;
+                    for (int i = 0; i < size_in; i++){
+                        data_out_channel[i] = data_in0_channel[i]*coeffs_ptr[0] + \ 
+                        data_in1_channel[i]*coeffs_ptr[1];
+                    }
+                }
+            }
+            for (int b = 2; b <tensor_in.size(); b++){
+                const float* data_in = tensor_in[b]->data();
+                for (int n = 0; n < num; n++){
+                    float* data_out_batch = data_out + n * ch_in * size_in;
+                    const float* data_in_batch = data_in + n * ch_in * size_in;
+
+#pragma omp parallel for
+                    for (int c = 0; c < ch_in; c++){
+                        float* data_out_channel = data_out_batch + c * size_in;
+                        const float* data_in_channel = data_in_batch + c * size_in;
+                        for (int i = 0; i < size_in; i++){
+                            data_out_channel[i] = data_out_channel[i] + \ 
+                            data_in_channel[i] * coeffs_ptr[b];
+                        }
+                    }
+                }
+            }
+        }
+    }
+    if (op_type == 3){ //Operation_MAX
+        for (int n = 0; n < num; n++){
+            float* data_out_batch = data_out + n * ch_in * size_in;
+            const float* data_in0_batch = data_in0 + n * ch_in * size_in;
+            const float* data_in1_batch = data_in1 + n * ch_in * size_in;
+
+#pragma omp parallel for
+            for (int c = 0; c < ch_in; c++){
+                float* data_out_channel = data_out_batch + c * size_in;
+                const float* data_in0_channel = data_in0_batch + c * size_in;
+                const float* data_in1_channel = data_in1_batch + c * size_in;
+                for (int i = 0; i < size_in; i++){
+                    data_out_channel[i] = std::max(data_in0_channel[i], data_in1_channel[i]);
+                }
+            }
+        }
+        for (int b = 2; b <tensor_in.size(); b++){
+            const float* data_in = tensor_in[b]->data();
+            for (int n = 0; n < num; n++){
+                float* data_out_batch = data_out + n * ch_in * size_in;
+                const float* data_in_batch = data_in + n * ch_in * size_in;
+
+#pragma omp parallel for
+                for (int c = 0; c < ch_in; c++){
+                    float* data_out_channel = data_out_batch + c * size_in;
+                    const float* data_in_channel = data_in_batch + c * size_in;
+                    for (int i = 0; i < size_in; i++){
+                        data_out_channel[i] = std::max(data_out_channel[i], data_in_channel[i]);
+                    }
+                }
+            }
+        }
+    }
+    
+}
+
+
+void test_arm_eltwise(std::vector<TensorHf4*>& tin, EltwiseType operation, \
+     std::vector<float> coeffs_ptr, int num_coeff, int threads, int cluster_id) {
+
+    //printf("operation: %d \n", operation);
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+    SaberTimer<ARM> t2;
+
+    Context<ARM> ctx1;
+    Context<ARM> ctx2;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    //TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+    tvout_saber.push_back(&tout_saber);
+    tvout_basic.push_back(&tout_basic);
+
+    int numin = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+    int pad = 0;
+
+    LOG(INFO) << "eltwise param: ";
+    LOG(INFO) << " img_num = " << numin;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    enum { Eltwise_prod = 1, Eltwise_sum = 2, Eltwise_max = 3 };
+    if (operation == 1)
+        LOG(INFO) << " operation = " << Eltwise_prod;
+    if (operation == 2)
+        LOG(INFO) << " operation = " << Eltwise_sum;
+    if (operation == 3)
+        LOG(INFO) << " operation = " << Eltwise_max;
+
+    int input_dim = 1;
+    Shape shape_out = tin[0]->valid_shape();
+    for (int i = 0; i < 4; i++){
+    	shape_out[i] = tin[0]->valid_shape()[i];
+    }
+   //Shape shape_out{num, ch_out, h_out, w_out}
+
+#ifdef USE_COMPARE
+
+/*
+    LOG(INFO) << "initial input tensor data 0:";
+    print_tensor_host(*tin[0]);
+    LOG(INFO) << "initial input tensor data 1:";
+    print_tensor_host(*tin[1]);
+*/
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+
+    LOG(INFO) << "run basic eltwise for precision comparation";
+    tout_basic.re_alloc(shape_out);
+    size_t workspace_size = sizeof(float) * numin * chin * (hin + 2 * pad) * (win + 2 * pad);
+    void* work_space_data = fast_malloc(workspace_size);
+   
+    to = 0;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        eltwise_basic(ctx1, tout_basic, tin, operation, coeffs_ptr, num_coeff);
+        
+        tvout_basic[0] ->record_event(ctx1.get_compute_stream());
+        tvout_basic[0] ->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    fast_free(work_space_data);
+    LOG(INFO) << "basic eltwise running time, ave: " << to / test_iter << ", min time: " << min_time;
+   // print_tensor_host(tout_basic);
+
+    
+  /*
+  LOG(INFO) << "run ncnn eltwise for precision comparation";
+    TensorHf4 tout_basic2;
+    tout_basic2.re_alloc(shape_out);
+     to = 0;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+
+        //eltwise_ncnn(ctx1, tout_basic2, tin, operation, coeffs_ptr, num_coeff);
+
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "ncnn eltwise running time, ave: " << to/test_iter << ", min time: " << min_time;
+    double max_ratio1 = 0;
+    double max_diff1 = 0;
+    tensor_cmp_host(tout_basic.data(), tout_basic2.data(), tout_basic.valid_size(), max_ratio1, max_diff1);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff1 << ", max ratio: " << max_ratio1;
+    //CHECK_EQ(fabsf(max_ratio1) < 1e-5f, true) << "compute result error";
+*/
+#endif
+    
+    Eltwise<ARM, AK_FLOAT> eltwise_saber;
+    EltwiseParam<TensorHf4> eltwise_param(operation, coeffs_ptr);
+
+    eltwise_saber.compute_output_shape(tin, tvout_saber, eltwise_param);
+
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape_1: " << sh_out_saber[0] << ", " << sh_out_saber[1] << ", " \
+        << sh_out_saber[2] << ", " << sh_out_saber[3];
+    //LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber eltwise impl init";
+    SABER_CHECK(eltwise_saber.init(tin, tvout_saber, eltwise_param, SPECIFY, SABER_IMPL, ctx2));
+
+    //! compute
+    LOG(INFO) << "saber eltwise compute";
+    to = 0;
+    min_time = 1000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t2.clear();
+        t2.start(ctx2);
+       // pooling_saber(tin, tvout_saber, pooling_param, ctx1);
+        //eltwise_arm(ctx2, tout_saber, tin, operation, coeffs_ptr, num_coeff);
+        eltwise_saber(tin, tvout_saber, eltwise_param, ctx2);
+        tvout_saber[0]->record_event(ctx2.get_compute_stream());
+        tvout_saber[0]->sync();
+        t2.end(ctx2);
+        //printf("i: %d \n",i);
+        to += t2.get_average_ms();
+        if (t2.get_average_ms() < min_time) {
+            min_time = t2.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber eltwise running time, ave: " << to / test_iter << ", min time: " << min_time;
+   // print_tensor_host(tout_saber);
+    //print_tensor_host(*tvout_saber[0]);
+
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+#if 1
+TEST(TestSaberFuncTest, test_func_eltwise_arm) {
+
+    int num = 1;
+    int chin = 32;
+    int hin = 112;
+    int win = 112;
+
+    int pad = 1;
+    int stride = 2;
+    int kernel = 3;
+    //int chout = 3;
+
+   // bool bias_term = false;
+   // bool global = true;
+   // PoolingType type = 1;
+
+    Shape shape_in(num, chin, hin, win);
+
+    
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    TensorHf4 tdin;
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    TensorHf4 tdin1;
+    tdin1.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin1, -1.f, 1.f);
+    
+    tin.push_back(&tdin);
+    tin.push_back(&tdin1);
+    
+    
+    std::vector<float> coeffs_ptr;
+   
+	coeffs_ptr.push_back(1.0f);
+	coeffs_ptr.push_back(-1.0f);
+    //printf("test_arm_eltwise: GLB_operation: %d \n", GLB_operation);
+    test_arm_eltwise(tin, (EltwiseType)GLB_operation, coeffs_ptr, GLB_num_coeff, GLB_threads, GLB_cluster_id);
+    //LOG(WARNING) << "pooling not support yet";
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    // initial logger
+    //logger::init(argv[0]);
+   // printf("Test0:\n");
+     if (argc < 1) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/eltwise_test\n \
+            threads\n \
+            cluster_id\n \
+            operation\n \
+            num_coeff\n  ";
+        exit(0);
+    } else if (argc == 3){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+    }else if (argc == 5){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+        GLB_operation = atoi(argv[3]);
+        GLB_num_coeff = atoi(argv[4]);
+    }
+    //printf("Test:\n");
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
+
diff --git a/test/saber/arm/test_saber_func_permute_arm.cpp b/test/saber/arm/test_saber_func_permute_arm.cpp
new file mode 100644
index 0000000..c3fbe77
--- /dev/null
+++ b/test/saber/arm/test_saber_func_permute_arm.cpp
@@ -0,0 +1,337 @@
+#include "saber/funcs/permute.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, threads, 1);
+DEFINE_GLOBAL(int, cluster_id, 0);
+DEFINE_GLOBAL(int, num, 0);
+DEFINE_GLOBAL(int, ch, 1);
+DEFINE_GLOBAL(int, h, 2);
+DEFINE_GLOBAL(int, w, 3);
+#define USE_COMPARE
+
+using namespace anakin::saber;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+// global_pooling test
+void test_arm_permute(std::vector<TensorHf4*>& tin, int num_axes, \
+     std::vector<int> permute, int threads, int cluster_id) {
+	
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+    SaberTimer<ARM> t2;
+
+    Context<ARM> ctx1;
+    Context<ARM> ctx2;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+    tvout_saber.push_back(&tout_saber);
+    tvout_basic.push_back(&tout_basic);
+
+    int numin = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+    int pad = 0;
+
+    LOG(INFO) << "permute param: ";
+    LOG(INFO) << " img_num = " << numin;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+
+    int input_dim = 1;
+    Shape shape_out = tin[0]->valid_shape();
+    for (int i = 0; i < num_axes; i ++){
+    	shape_out[i] = tin[0]->valid_shape()[permute[i]];
+    }
+   //Shape shape_out{num, ch_out, h_out, w_out}
+
+#ifdef USE_COMPARE
+
+   // LOG(INFO) << "initial input tensor data:";
+   // print_tensor_host(*thin);
+
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+
+    LOG(INFO) << "run basic permute for precision comparation";
+    tout_basic.re_alloc(shape_out);
+    size_t workspace_size = sizeof(float) * numin * chin * (hin + 2 * pad) * (win + 2 * pad);
+    void* work_space_data = fast_malloc(workspace_size);
+    int numout = tvout_basic[0]->num();
+    int chout = tvout_basic[0]->channel();
+    int hout = tvout_basic[0]->height();
+    int wout = tvout_basic[0]->width(); 
+    std::vector<int> new_steps;
+    std::vector<int> old_steps;
+
+    old_steps.push_back(chin * hin * win);
+    old_steps.push_back(hin * win);
+    old_steps.push_back(win);
+    old_steps.push_back(1);
+    
+    new_steps.push_back(chout * hout * wout);
+    new_steps.push_back(hout * wout);
+    new_steps.push_back(wout);
+    new_steps.push_back(1);
+
+    bool need_permute = false;
+    for (int i = 0; i < num_axes; i ++){
+    	if (permute[i] != i){
+    		need_permute = true;
+    		break;
+    	}
+    }
+    int num_ones = 0;
+    if (chin == 1)num_ones ++;
+    if (win == 1)num_ones ++;
+    if (hin == 1)num_ones ++;
+        // order_type
+        // 0 = c h w 1 2 3
+        // 1 = h w c 2 3 1
+        // 2 = w c h 3 1 2
+        // 3 = c w h 1 3 2
+        // 4 = h c w 2 1 3
+        // 5 = w h c 3 2 1
+    bool transpose = false;
+    int order_type = 0;
+    if (permute[1] == 1){
+        if (permute[2] == 2){
+            order_type = 0;
+        }else//3
+            order_type = 3;
+    }else if (permute[1] == 2){
+        if (permute[2] == 1){
+            order_type = 4;
+        }else//3
+            order_type = 1;
+    }else if (permute[1] == 3){
+        if (permute[2] == 2){
+            order_type = 5;
+        }else//1{
+            order_type = 2;
+    }
+    if (need_permute){
+            if (num_ones > 1)
+                need_permute = false;
+            else if (num_ones == 1){
+                //panduan nchw
+                if (chin == 1){
+                    if (order_type == 0 || order_type == 1 || order_type == 4)
+                        transpose = false;
+                    else
+                        transpose = true;
+                }
+                if (hin == 1){
+                    if (order_type == 0 || order_type == 3 || order_type == 4)
+                        transpose = false;
+                    else
+                        transpose = true;
+                }
+                if (win == 1){
+                    if (order_type == 0 || order_type == 2 || order_type == 3)
+                        transpose = false;
+                    else
+                        transpose = true;
+                }
+            }
+        }
+    int count = tout_basic.valid_size();
+    //Sgemm gemmer;
+    to = 0;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        //permute_basic(ctx1,tout_basic, *thin, need_permute,num_axes, \
+              count, new_steps, old_steps, permute);
+        
+        tvout_basic[0] ->record_event(ctx1.get_compute_stream());
+        tvout_basic[0] ->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    fast_free(work_space_data);
+    LOG(INFO) << "basic permute running time, ave: " << to / test_iter << ", min time: " << min_time;
+   // print_tensor_host(tout_basic);
+
+    LOG(INFO) << "run ncnn permute for precision comparation";
+    TensorHf4 tout_basic2;
+    tout_basic2.re_alloc(shape_out);
+    t1.clear();
+    t1.start(ctx1);
+    //permute_ncnn(ctx1,tout_basic2, *thin, need_permute, order_type, num_axes, count, permute);
+    t1.end(ctx1);
+    LOG(INFO) << "ncnn permute running time, ave: " << t1.get_average_ms() << ", min time: " << min_time;
+    double max_ratio1 = 0;
+    double max_diff1 = 0;
+    tensor_cmp_host(tout_basic.data(), tout_basic2.data(), tout_basic.valid_size(), max_ratio1, max_diff1);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff1 << ", max ratio: " << max_ratio1;
+    CHECK_EQ(fabsf(max_ratio1) < 1e-5f, true) << "compute result error";
+
+#endif
+    
+    Permute<ARM, AK_FLOAT> permute_saber;
+    PermuteParam<Tensor<ARM, AK_FLOAT, NCHW>> permute_param(permute);
+
+    permute_saber.compute_output_shape(tin, tvout_saber, permute_param);
+
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape_1: " << sh_out_saber[0] << ", " << sh_out_saber[1] << ", " \
+        << sh_out_saber[2] << ", " << sh_out_saber[3];
+    //LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber permute impl init";
+    SABER_CHECK(permute_saber.init(tin, tvout_saber, permute_param, SPECIFY, SABER_IMPL, ctx2));
+
+    //! compute
+    LOG(INFO) << "saber permute compute";
+    to = 0;
+    min_time = 1000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t2.clear();
+        t2.start(ctx2);
+       // pooling_saber(tin, tvout_saber, pooling_param, ctx1);
+       // permute_arm2(ctx2,tout_saber, *thin, need_permute,transpose, order_type, num_axes, count, permute);
+       // permute_arm2(ctx2,tout_saber, *thin, permute_saber._need_permute,permute_saber._transpose, .permute_saber_order_type, permute_saber._num_axes, permute_saber._count, permute);
+        permute_saber(tin, tvout_saber, permute_param, ctx2);
+        tvout_saber[0]->record_event(ctx2.get_compute_stream());
+        tvout_saber[0]->sync();
+        t2.end(ctx2);
+        //printf("i: %d \n",i);
+        to += t2.get_average_ms();
+        if (t2.get_average_ms() < min_time) {
+            min_time = t2.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber permute running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+    //print_tensor_host(*tvout_saber[0]);
+
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+#if 1
+TEST(TestSaberFuncTest, test_func_pooling_global_arm) {
+
+    int num = 1;
+    int chin = 6;
+    int hin = 224;
+    int win = 224;
+
+    int pad = 1;
+    int stride = 2;
+    int kernel = 3;
+    //int chout = 3;
+
+   // bool bias_term = false;
+   // bool global = true;
+   // PoolingType type = 1;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    int count = num * chin * win * hin;
+    int num_axes = 4;
+    std::vector<int> permute;
+    /*
+    permute.push_back(0);
+    permute.push_back(1);
+    permute.push_back(3);
+    permute.push_back(2);
+	*/
+	permute.push_back(GLB_num);
+	permute.push_back(GLB_ch);
+	permute.push_back(GLB_h);
+	permute.push_back(GLB_w);
+    test_arm_permute(tin, num_axes, permute,GLB_threads, GLB_cluster_id);
+    //LOG(WARNING) << "pooling not support yet";
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    // initial logger
+    //logger::init(argv[0]);
+     if (argc < 1) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/pooloing_test\n \
+            type\n \
+            global\n \
+            threads\n \
+            cluster_id\n ";
+        exit(0);
+    } else if (argc == 3){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+    }else if (argc == 7) {
+    	GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+        GLB_num = atoi(argv[3]);
+        GLB_ch = atoi(argv[4]);
+        GLB_h = atoi(argv[5]);
+        GLB_w = atoi(argv[6]);
+    }
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
+
diff --git a/test/saber/arm/test_saber_func_pool_arm.cpp b/test/saber/arm/test_saber_func_pool_arm.cpp
new file mode 100755
index 0000000..4530090
--- /dev/null
+++ b/test/saber/arm/test_saber_func_pool_arm.cpp
@@ -0,0 +1,248 @@
+#include "saber/funcs/pooling.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/pooling_arm_impl.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+int test_iter = 10;
+
+bool compare_result = false;
+bool global_pool = false;
+
+int num = 1;
+int ch_in = 32;
+int h_in = 112;
+int w_in = 112;
+
+int kernel = 2;
+int pad = 0;
+int stride = 2;
+
+PoolingType type = Pooling_max;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+            CHECK_EQ(size1, size2) << "wrong shape";
+            CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_pooling(std::vector<TensorHf4*>& tin, \
+    int kernel, int stride, int pad, \
+    PoolingType type, bool global, int threads, int cluster_id) {
+
+    //int test_iter = 1000;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+    SaberTimer<ARM> t2;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+    tvout_saber.push_back(&tout_saber);
+    tvout_basic.push_back(&tout_basic);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "pooling param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << "kernel size = " << kernel;
+    LOG(INFO) << "stride = " << stride;
+    LOG(INFO) << "pad = " << pad;
+    LOG(INFO) << "type = " << type;
+    int wout = 1;
+    int hout = 1;
+    if(!global) {
+        int hin = tin[0]->height(); // P
+        hout = static_cast<int>(ceilf(static_cast<float>(
+                             hin + 2 * pad - kernel) / stride)) + 1;
+        int win = tin[0]->width(); // Q
+        wout = static_cast<int>(ceilf(static_cast<float>(
+                             win + 2 * pad - kernel) / stride)) + 1;
+  }
+   Shape shape_out{num, chin, hout, wout};
+   PoolingParam<TensorHf4> pooling_param(kernel,kernel, pad, pad,
+                                    stride,stride,type,global);
+   //LOG(INFO) << "input tensor";
+   //print_tensor_host(*tin[0]);
+
+    if (compare_result) {
+        LOG(INFO) << "run basic pooling for precision comparation";
+        tout_basic.re_alloc(shape_out);
+        //pooling_basic(tout_basic, *thin, type,global, kernel, \
+                kernel, stride, stride, pad, pad);
+        //print_tensor_host(tout_basic);
+         LOG(INFO) << "basic pooling compute";
+        to = 0;
+        min_time = 1000000;
+        for (int i = 0; i < test_iter; ++i) {
+           t1.clear();
+           t1.start(ctx1);
+           pooling_basic(tout_basic, *thin, type,global, kernel, \
+                kernel, stride, stride, pad, pad);
+           tvout_basic[0]->record_event(ctx1.get_compute_stream());
+           tvout_basic[0]->sync();
+           t1.end(ctx1);
+           to += t1.get_average_ms();
+           if (t1.get_average_ms() < min_time) {
+               min_time = t1.get_average_ms();
+             }
+        }
+        LOG(INFO) << "basic pooling running time, ave: " << to / test_iter << ", min time: " << min_time;
+       // print_tensor_host(tout_basic);
+
+    }
+
+    Pooling<ARM, AK_FLOAT> pooling_saber;
+
+    pooling_saber.compute_output_shape(tin, tvout_saber, pooling_param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    LOG(INFO) << "output shape_1: " << sh_out_saber[0] << ", " << sh_out_saber[1] << ", " \
+        << sh_out_saber[2] << ", " << sh_out_saber[3];
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber pooling impl init";
+    SABER_CHECK(pooling_saber.init(tin, tvout_saber, pooling_param, SPECIFY, SABER_IMPL, ctx1));
+
+    //print_tensor_host(*thin);
+
+    //! compute
+    LOG(INFO) << "saber pooling compute";
+    to = 0;
+    min_time = 1000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t2.clear();
+        t2.start(ctx1);
+        pooling_saber(tin, tvout_saber, pooling_param, ctx1);
+        //pooling3x3s2_max(tout_saber,*thin,type,global,kernel, \
+            kernel, stride, stride, pad, pad);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t2.end(ctx1);
+        to += t2.get_average_ms();
+        if (t2.get_average_ms() < min_time) {
+            min_time = t2.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber pooling running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tout_saber);
+
+    if (compare_result) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        TensorHf4 tdiff(tout_basic.valid_shape());
+        tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tout_saber.data(), tout_basic.valid_size(), max_ratio, max_diff);
+
+        // LOG(INFO) << "tout_basic";
+        // print_tensor_host(tout_basic);
+        // LOG(INFO) << "tout_saber";
+        // print_tensor_host(tout_saber);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+}
+
+#if 1
+TEST(TestSaberFuncTest, test_func_pooling_global_arm) {
+
+    Shape shape_in(num, ch_in, h_in, w_in);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    test_arm_pooling(tin, kernel, stride, pad, type, global_pool, threads, cluster);
+}
+#endif
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if (argc >= 4) {
+        test_iter = atoi(argv[3]);
+    }
+    if (argc >= 5) {
+        compare_result = atoi(argv[4]) > 0;
+    }
+    if (argc >= 6) {
+        global_pool = atoi(argv[5]) > 0;
+    }
+    if(argc >= 7) {
+        if (argc < 14) {
+            LOG(ERROR) << "usage: ./" << argv[0] << " cluster  threads  test_iter " << \
+                " compare_result global_pool num ch_in h_in w_in kernel pad stride pool_type";
+            return 0;
+        }
+        num = atoi(argv[6]);
+        ch_in = atoi(argv[7]);
+        h_in = atoi(argv[8]);
+        w_in = atoi(argv[9]);
+        kernel = atoi(argv[10]);
+        pad = atoi(argv[11]);
+        stride = atoi(argv[12]);
+        type = (PoolingType)atoi(argv[13]);
+    }
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_priorbox_arm.cpp b/test/saber/arm/test_saber_func_priorbox_arm.cpp
new file mode 100644
index 0000000..29ea334
--- /dev/null
+++ b/test/saber/arm/test_saber_func_priorbox_arm.cpp
@@ -0,0 +1,162 @@
+#include "core/context.h"
+#include "funcs/priorbox.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+#define USE_COMPARE
+const bool FLAG_RELU = false;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+            CHECK_EQ(size1, size2) << "wrong shape";
+            CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+void test_arm_priorbox(std::vector<TensorHf4*>& tin, \
+    int thread_num, int cluster_id) {
+
+    int test_iter = 100;
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_saber;
+    std::vector<TensorHf4*> tvout_saber;
+    tvout_saber.push_back(&tout_saber);
+
+    LOG(INFO) << "create priorbox param";
+    std::vector<float> min_size{60.f};
+    std::vector<float> max_size;
+    std::vector<float> aspect_ratio{2};
+    std::vector<float> variance{0.1f, 0.1f, 0.2f, 0.2f};
+    bool flip = true;
+    bool clip = false;
+    float step_h = 0;
+    float step_w = 0;
+    int img_w = 0;
+    int img_h = 0;
+    float offset = 0.5;
+
+    std::vector<PriorType> order;
+
+    order.push_back(PRIOR_MIN);
+    order.push_back(PRIOR_MAX);
+    order.push_back(PRIOR_COM);
+
+    PriorBoxParam<TensorHf4> param(min_size, max_size, aspect_ratio, \
+        variance, flip, clip, img_w, img_h, step_w, step_h, offset, order);
+    PriorBox<ARM, AK_FLOAT> priorbox_saber;
+
+    priorbox_saber.compute_output_shape(tin, tvout_saber, param);
+    Shape sh_out_saber = tvout_saber[0]->valid_shape();
+    Shape shape_out{1, 1, 2, tin[0]->width() * tin[0]->height() * 4 * param.prior_num};
+
+    LOG(INFO) << "output shape: " << shape_out[0] << ", " << shape_out[1] << ", " \
+        << shape_out[2] << ", " << shape_out[3];
+    CHECK_EQ(shape_out == sh_out_saber, true) << "compute output shape error";
+
+    //! re_alloc mem for output tensor
+    tvout_saber[0]->re_alloc(shape_out);
+
+    LOG(INFO) << "saber priorbox impl init";
+    SABER_CHECK(priorbox_saber.init(tin, tvout_saber, param, SPECIFY, SABER_IMPL, ctx1));
+
+    //! compute
+    LOG(INFO) << "saber priorbox compute";
+    to = 0;
+
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        priorbox_saber(tin, tvout_saber, param, ctx1);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    print_tensor_host(*tvout_saber[0]);
+
+}
+
+TEST(TestSaberFuncTest, test_func_priorbox_arm) {
+
+    int width = 300;
+    int height = 300;
+    int channel = 3;
+    int num = 1;
+    int w_fea = 19;
+    int h_fea = 19;
+    int c_fea = 512;
+
+    LOG(INFO) << " input data size, num=" << num << ", channel=" << \
+        channel << ", height=" << height << ", width=" << width;
+
+    LOG(INFO) << " input feature tensor size, num=" << num << ", channel=" << \
+        c_fea << ", height=" << h_fea << ", width=" << w_fea;
+    //! create input output tensor
+    Shape sh_fea{num, c_fea, h_fea, w_fea};
+    Shape sh_data{num, channel, height, width};
+    TensorHf4 tfea(sh_fea);
+    TensorHf4 tdata(sh_data);
+
+    std::vector<TensorHf4*> tin;
+
+    tin.push_back(&tfea);
+    tin.push_back(&tdata);
+
+    test_arm_priorbox(tin, threads, cluster);
+}
+
+int main(int argc, const char** argv){
+
+    Env<ARM>::env_init();
+
+    // initial logger
+    //logger::init(argv[0]);
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_sgemm_arm.cpp b/test/saber/arm/test_saber_func_sgemm_arm.cpp
new file mode 100644
index 0000000..b6d24b3
--- /dev/null
+++ b/test/saber/arm/test_saber_func_sgemm_arm.cpp
@@ -0,0 +1,236 @@
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+#include "saber/funcs/impl/arm/impl/sgemm_arm.h"
+#include "saber/funcs/timer.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+int batch = 1;
+int M = 100;
+int N = 100;
+int K = 100;
+bool traA = false;
+bool traB = false;
+
+int test_iter = 10;
+
+bool COMPARE_RESULT = false;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+template  <typename type>
+void basic_gemm(int m, int n, int k, const type* a, const type* b, type* c, type alpha, type beta, \
+    bool trans_a = false, bool trans_b = false) {
+//#pragma omp parallel for
+    for (int i = 0; i < m; ++i) {
+        for (int j = 0; j < n; ++j) {
+            type sum = static_cast<type>(0);
+            for (int l = 0; l < k; ++l) {
+                type av;
+                type bv;
+                if (trans_a) {
+                    av = a[l * m + i];
+                } else{
+                    av = a[i * k + l];
+                }
+                if (trans_b) {
+                    bv = b[j * k + l];
+                } else {
+                    bv = b[l * n + j];
+                }
+                sum += av * bv;
+            }
+            c[i * n + j] = alpha * sum + beta * c[i * n + j];
+        }
+    }
+}
+
+void test_arm_sgemm(TensorHf4& ta, TensorHf4& tb, TensorHf4& tc, \
+    bool flag_bias, bool flag_relu, int thread_num, int cluster_id) {
+
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    LOG(INFO) << "sgemm M: " << M << ", N: " << N << ", K: " << K;
+    LOG(INFO) << "transA: " << (traA? "true" : "false") << ", transB: " << (traB? "true" : "false");
+    LOG(INFO) << "test iter: " << test_iter;
+    LOG(INFO) << "compare result with basic sgemm: " << (COMPARE_RESULT? "true" : "false");
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+    Shape shape_out = tc.valid_shape();
+    int m = ta.height();
+    int n = tb.width();
+    int k = ta.width();
+
+    const float* da = ta.data();
+    const float* db = tb.data();
+
+    if(COMPARE_RESULT) {
+        LOG(INFO) << "run basic conv for precision comparation";
+        tout_basic.re_alloc(shape_out);
+        float* dc_basic = tout_basic.mutable_data();
+        basic_gemm(m, n, k, da, db, dc_basic, 1.f, 0.f, traA, traB);
+        //print_tensor_host(tout_basic);
+    }
+
+    //! sgemm init
+    int l1_cache = ctx1.devs[ctx1.get_device_id()]._info._L1_cache;
+    int l2_cache = ctx1.devs[ctx1.get_device_id()]._info._L2_cache;
+    //! if L1 cache size is not provided, set to 31K
+    l1_cache = l1_cache > 0? l1_cache : 31000;
+    //! if L2 cache size is not provided, set to 2M
+    l2_cache = l2_cache > 0? l2_cache : 2000000;
+    Sgemm gemmer;
+    gemmer.init(l1_cache, l2_cache, m, n, k, traA, traB, threads);
+
+    //! compute
+    LOG(INFO) << "saber sgemm compute";
+    to = 0;
+    int lda, ldb, ldc;
+    if (traA) {
+        lda = m;
+    } else {
+        lda = k;
+    }
+    if (traB) {
+        ldb = k;
+    } else {
+        ldb = n;
+    }
+    ldc = n;
+
+    float* dc_saber = tc.mutable_data();
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        gemmer(da, lda, db, ldb, dc_saber, ldc, 1.f, 0.f);
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tc);
+
+    if (COMPARE_RESULT) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(tout_basic.data(), tc.data(), tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+}
+
+TEST(TestSaberFuncTest, test_func_sgemm_arm) {
+
+    int num = batch;
+    int ch = 1;
+    int h_a = M;
+    int w_a = K;
+
+    int h_b = K;
+    int w_b = N;
+
+    int h_c = M;
+    int w_c = N;
+
+    bool flag_relu = true;
+    bool flag_bias = true;
+
+    Shape sha(num, ch, h_a, w_a);
+    Shape shb(num, ch, h_b, w_b);
+    Shape shc(num, ch, h_c, w_c);
+
+    TensorHf4 ta, tb, tc;
+
+    ta.re_alloc(sha);
+    tb.re_alloc(shb);
+    tc.re_alloc(shc);
+#if 0
+    float* ptr_a = ta.mutable_data();
+    for (int i = 0; i < ta.valid_size(); ++i) {
+        ptr_a[i] = i;
+    }
+    float* ptr_b = tb.mutable_data();
+    for (int i = 0; i < tb.valid_size(); ++i) {
+        ptr_b[i] = i;
+    }
+#else
+    fill_tensor_host_rand(ta, -1.f, 1.f);
+    fill_tensor_host_rand(tb, -1.f, 1.f);
+#endif
+    test_arm_sgemm(ta, tb, tc, flag_bias, flag_relu, threads, cluster);
+    //LOG(WARNING) << "conv3x3s1 not support yet";
+}
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if(argc >= 4) {
+        if (argc < 8) {
+            LOG(ERROR) << "usage: ./" << argv[0] << " cluster  threads  m  n  k transA transB";
+            return 0;
+        }
+        M = atoi(argv[3]);
+        N = atoi(argv[4]);
+        K = atoi(argv[5]);
+        traA = atoi(argv[6]) > 0;
+        traB = atoi(argv[7]) > 0;
+    }
+    if (argc > 8) {
+        test_iter = atoi(argv[8]);
+    }
+    if (argc > 9) {
+        COMPARE_RESULT = atoi(argv[9]) > 0;
+    }
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_sgemv_arm.cpp b/test/saber/arm/test_saber_func_sgemv_arm.cpp
new file mode 100644
index 0000000..55fc994
--- /dev/null
+++ b/test/saber/arm/test_saber_func_sgemv_arm.cpp
@@ -0,0 +1,198 @@
+#include "test_saber_func_test_arm.h"
+#include "saber/core/tensor_op.h"
+#include "saber/funcs/impl/arm/impl/sgemv_arm.h"
+#include "saber/funcs/timer.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+int batch = 1;
+int M = 100;
+int K = 100;
+
+int test_iter = 10;
+
+bool flag_bias = false;
+bool flag_relu = false;
+bool COMPARE_RESULT = false;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+template <typename Tensor_t>
+void tensor_diff(Tensor_t& t1, Tensor_t& t2, Tensor_t& tdiff) {
+
+    typedef typename Tensor_t::Dtype dtype;
+    int size1 = t1.valid_size();
+    int size2 = t2.valid_size();
+    int size_out = tdiff.valid_size();
+    CHECK_EQ(size1, size2) << "wrong shape";
+    CHECK_EQ(size1, size_out) << "wrong shape";
+    const dtype* ptr1 = t1.data();
+    const dtype* ptr2 = t2.data();
+    dtype* ptr_out = tdiff.mutable_data();
+    for (int i = 0; i < size1; ++i) {
+        ptr_out[i] = ptr1[i] - ptr2[i];
+    }
+}
+
+template  <typename type>
+void basic_gemv(int m, int k, const type* a, const type* b, type* c, const type* bias, bool flag_bias, \
+    type alpha, type beta, bool flag_relu = false, bool trans_a = false) {
+//#pragma omp parallel for
+    for (int i = 0; i < m; ++i) {
+        type sum = 0;
+        for (int j = 0; j < k; ++j) {
+            type av;
+            if (trans_a) {
+                av = a[j * m + i];
+            } else {
+                av = a[i * k + j];
+            }
+            sum += av * b[j];
+        }
+        //printf("sum: %0.2f, alpha: %.2f, beta: %.2f, c: %.2f, flag: %d\n", sum, alpha, beta, c[i], flag_bias);
+        c[i] = alpha * sum + beta * c[i] + (flag_bias? bias[i] : 0);
+        if (flag_relu) {
+            c[i] = c[i] > type(0)? c[i] : type(0);
+        }
+    }
+}
+
+void test_arm_sgemv(const int m, const int k, bool flag_bias, bool flag_relu, int thread_num, int cluster_id) {
+
+    double to = 0;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    LOG(INFO) << "sgemv M: " << M << ", K: " << K;
+    //LOG(INFO) << "transA: " << (traA? "true" : "false") << ", transB: " << (traB? "true" : "false");
+    LOG(INFO) << "test iter: " << test_iter;
+    LOG(INFO) << "compare result with basic sgemv: " << (COMPARE_RESULT? "true" : "false");
+
+    TensorHf4 tin;
+    TensorHf4 tw, tb;
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    tin.reshape(Shape(1, 1, 1, k));
+    tw.reshape(Shape(1, 1, m, k));
+    tb.reshape(Shape(1, 1, 1, m));
+    tout_basic.reshape(Shape(1, 1, 1, m));
+    tout_saber.reshape(Shape(1, 1, 1, m));
+
+    fill_tensor_host_rand(tin, -1.f, 1.f);
+    fill_tensor_host_rand(tw, -1.f, 1.f);
+    fill_tensor_host_rand(tb, -1.f, 1.f);
+
+    //fill_tensor_host_const(tin, 1.f);
+    //fill_tensor_host_const(tw, 1.f);
+    //fill_tensor_host_const(tb, 1.f);
+
+    const float* da = tw.data();
+    const float* db = tin.data();
+    const float* dbias = tb.data();
+    float* dc_basic = tout_basic.mutable_data();
+    float* dc_saber = tout_saber.mutable_data();
+
+    if(COMPARE_RESULT) {
+        LOG(INFO) << "run basic conv for precision comparation";
+        basic_gemv(m, k, da, db, dc_basic, dbias, flag_bias, 1.f, 0.f, flag_relu);
+        //print_tensor_host(tout_basic);
+    }
+    for (int i = 0; i < 20; ++i) {
+        sgemv(false, m, k, da, db, dc_saber);
+    }
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        if (flag_bias) {
+            if (flag_relu) {
+                sgemv_bias_relu(false, m, k, da, db, dc_saber, dbias);
+            } else {
+                sgemv_bias(false, m, k, da, db, dc_saber, dbias);
+            }
+
+        } else {
+            if (flag_relu) {
+                sgemv_relu(false, m, k, da, db, dc_saber);
+            } else {
+                sgemv(false, m, k, da, db, dc_saber);
+            }
+        }
+        t1.end(ctx1);
+        to += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    LOG(INFO) << "saber conv running time, ave: " << to / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tc);
+
+    if (COMPARE_RESULT) {
+        double max_ratio = 0;
+        double max_diff = 0;
+        //TensorHf4 tdiff(tout_basic.valid_shape());
+        //tensor_diff(tout_basic, tout_saber, tdiff);
+        //print_tensor_host(tdiff);
+        tensor_cmp_host(dc_basic, dc_saber, tout_basic.valid_size(), max_ratio, max_diff);
+        LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+        CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+}
+
+TEST(TestSaberFuncTest, test_func_sgemv_arm) {
+
+    test_arm_sgemv(M, K, flag_bias, flag_relu, threads, cluster);
+    //LOG(WARNING) << "conv3x3s1 not support yet";
+}
+
+int main(int argc, const char** argv){
+    anakin::saber::Env<ARM>::env_init();
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+    if(argc >= 4) {
+        if (argc < 5) {
+            LOG(ERROR) << "usage: " << argv[0] << " cluster  threads  m  k [iters] [flag_compare] [flag_bias] [flag_relu]";
+            return 0;
+        }
+        M = atoi(argv[3]);
+        K = atoi(argv[4]);
+    }
+    if (argc > 5) {
+        test_iter = atoi(argv[5]);
+    }
+    if (argc > 6) {
+        COMPARE_RESULT = atoi(argv[6]) > 0;
+    }
+    if (argc > 7) {
+        flag_bias = atoi(argv[7]) > 0;
+    }
+    if (argc > 8) {
+        flag_relu = atoi(argv[8]) > 0;
+    }
+    // initial logger
+    //logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_slice_arm.cpp b/test/saber/arm/test_saber_func_slice_arm.cpp
new file mode 100644
index 0000000..ddb8224
--- /dev/null
+++ b/test/saber/arm/test_saber_func_slice_arm.cpp
@@ -0,0 +1,214 @@
+#include "saber/funcs/slice.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+#define DEFINE_GLOBAL(type, var, value) \
+        type (GLB_##var) = (value)
+DEFINE_GLOBAL(int, threads, 1);
+DEFINE_GLOBAL(int, cluster_id, 0);
+DEFINE_GLOBAL(int, axis, 1);
+
+#define USE_COMPARE
+
+using namespace anakin::saber;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+void test_arm_slice(std::vector<TensorHf4*>& tin, int axis, \ 
+    std::vector<int> slice_point, int threads, int cluster_id) {
+
+
+    Context<ARM> ctx1;
+    PowerMode mode = cluster_id == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    TensorHf4 tout_basic;
+    TensorHf4 tout_saber;
+
+    TensorHf4* thin = tin[0];
+
+    std::vector<TensorHf4*> tvout_saber;
+    std::vector<TensorHf4*> tvout_basic;
+
+   // tvout_saber.push_back(&tout_saber);
+    //tvout_basic.push_back(&tout_basic);
+
+    int num = tin[0]->num();
+    int chin = tin[0]->channel();
+    int hin = tin[0]->height();
+    int win = tin[0]->width();
+
+    LOG(INFO) << "slice param: ";
+    LOG(INFO) << " img_num = " << num;
+    LOG(INFO) << " in_channels = " << chin;
+    LOG(INFO) << " img_h = " << hin;
+    LOG(INFO) << " img_w = " << win;
+    LOG(INFO) << " axis = " << axis;
+
+    LOG(INFO) << " slice_point : " ;
+    for (int i = 0; i < slice_point.size(); i ++){
+    	printf ("%d, ",slice_point[i]);
+    }
+    printf("\n");
+    int num_out = 0;
+    int ch_out = 0;
+    int w_out = 0;
+    int h_out = 0;
+    int count = slice_point.size() + 1;
+    std::vector<TensorHf4> tdev(count);
+    for (int i = 0; i < count; ++i) {
+        tvout_saber.push_back(&tdev[i]);
+        tvout_basic.push_back(&tdev[i]);
+    }
+
+   SliceParam<TensorHf4> slice_param(axis, slice_point);
+   Slice<ARM, AK_FLOAT> slice_saber;
+   LOG(INFO) << "slice compute output shape";
+   slice_saber.compute_output_shape(tin, tvout_saber, slice_param);
+   slice_saber.compute_output_shape(tin, tvout_basic, slice_param);
+
+    for (int j = 0; j < tvout_saber.size(); ++j) {
+        Shape sh = tvout_saber[j]->valid_shape();
+        LOG(INFO) << "output shape: "<< sh[0] << ", " << sh[1] << \
+            ", " << sh[2] << ", " << sh[3];
+    }
+
+    for (int i = 0; i < 4; ++i) {
+        tvout_saber[i]->re_alloc(tvout_saber[i]->shape());
+        tvout_basic[i]->re_alloc(tvout_basic[i]->shape());
+    }
+
+
+
+#ifdef USE_COMPARE
+    LOG(INFO) << "run basic slice for precision comparation";
+    size_t workspace_size = sizeof(float) * num * chin * hin  * win;
+    void* work_space_data = fast_malloc(workspace_size);
+    //Sgemm gemmer;
+    int test_iter = 10;
+    double to1 = 0.f;
+    double to2 = 0.f;
+    double min_time = 1000000;
+    SaberTimer<ARM> t1;
+    SaberTimer<ARM> t2;
+     for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        //slice_basic(ctx1,tvout_basic, tin, axis, slice_point);
+        tvout_basic[0]->record_event(ctx1.get_compute_stream());
+        tvout_basic[0]->sync();
+        t1.end(ctx1);
+        to1 += t1.get_average_ms();
+        if (t1.get_average_ms() < min_time) {
+            min_time = t1.get_average_ms();
+        }
+    }
+    fast_free(work_space_data);
+    LOG(INFO) << "basic slice running time, ave: " << to1 / test_iter << ", min time: " << min_time;
+    //print_tensor_host(tin[0]);
+    //for(int i = 0; i < tvout_basic.size(); i ++)
+    //	print_tensor_host(tvout_basic[i]);
+     LOG(INFO) << "slice initialization";
+    SABER_CHECK(slice_saber.init(tin, tvout_saber, slice_param, RUNTIME, SABER_IMPL, ctx1));
+    LOG(INFO) << "saber slice compute";
+    min_time = 1000000;
+    for (int i = 0; i < test_iter; ++i) {
+        t2.clear();
+        t2.start(ctx1);
+        slice_saber(tin, tvout_saber, slice_param, ctx1);
+       // slice_arm(ctx1,tvout_saber, tin, axis, slice_point);
+        tvout_saber[0]->record_event(ctx1.get_compute_stream());
+        tvout_saber[0]->sync();
+        t2.end(ctx1);
+        to2 += t2.get_average_ms();
+        if (t2.get_average_ms() < min_time) {
+            min_time = t2.get_average_ms();
+        }
+        //printf("to2: %.3f\n");
+    }
+    LOG(INFO) << "saber slice running time, ave: " << to2 / test_iter << ", min time: " << min_time;
+    
+#endif
+   
+#ifdef USE_COMPARE
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    for (int i = 0; i < count; i ++){
+    	tensor_cmp_host(tvout_basic[i]->data(), tvout_saber[i]->data(), tvout_basic[i]->valid_size(), max_ratio, max_diff);
+    	LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    	CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+    }
+   // LOG(INFO) << "tout_basic";
+   // print_tensor_host(tout_basic);
+  // LOG(INFO) << "tout_saber";
+   // print_tensor_host(tout_saber);
+    //LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    //CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+
+}
+
+
+TEST(TestSaberFuncTest, test_func_slice_arm) {
+
+    int num = 1;
+    int chin = 64;
+    int hin = 224;
+    int win = 224;
+
+
+   // bool bias_term = false;
+   // bool global = true;
+   // PoolingType type = 1;
+
+    Shape shape_in(num, chin, hin, win);
+
+    TensorHf4 tdin;
+
+    tdin.re_alloc(shape_in);
+    fill_tensor_host_rand(tdin, -1.f, 1.f);
+    //fill_tensor_host_const(tdin, 1.f);
+
+    std::vector<TensorHf4*> tin;
+    tin.push_back(&tdin);
+
+    std::vector<int> slice_point;
+    slice_point.push_back(10);
+    slice_point.push_back(32);
+    slice_point.push_back(50);
+    test_arm_slice(tin, GLB_axis, slice_point, GLB_threads, GLB_cluster_id);
+    //LOG(WARNING) << "pooling not support yet";
+}
+int main(int argc, const char** argv){
+	anakin::saber::Env<ARM>::env_init();
+    // initial logger
+    //logger::init(argv[0]);
+     if (argc < 1) {
+        LOG(INFO) << "Example of Usage:\n \
+        ./output/unit_test/pooloing_test\n \
+            type\n \
+            global\n \
+            threads\n \
+            cluster_id\n ";
+        exit(0);
+    } else if (argc == 4){
+        GLB_threads = atoi(argv[1]);
+        GLB_cluster_id = atoi(argv[2]);
+        GLB_axis = atoi(argv[3]);
+    }
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
\ No newline at end of file
diff --git a/test/saber/arm/test_saber_func_softmax_arm.cpp b/test/saber/arm/test_saber_func_softmax_arm.cpp
new file mode 100644
index 0000000..2399dce
--- /dev/null
+++ b/test/saber/arm/test_saber_func_softmax_arm.cpp
@@ -0,0 +1,180 @@
+#include "funcs/softmax.h"
+#include "test_saber_func_test_arm.h"
+#include "tensor_op.h"
+
+using namespace anakin::saber;
+
+int cluster = 0;
+int threads = 4;
+
+typedef Tensor<ARM, AK_FLOAT, NCHW> TensorHf4;
+
+#define COMPARE_RESULT 1
+
+void softmax_basic(TensorHf4& tin, int axis, TensorHf4& tout) {
+    Shape shin = tin.valid_shape();
+    Shape shtmp = shin;
+    int axis_size = shin[axis];
+    shtmp[axis] = 1;
+
+    int cnt = shtmp.count();
+    int inner_num = tin.count(axis + 1, tin.dims());
+    int outer_num = tin.count(0, axis);
+
+    //TensorHf4 tmax(shtmp);
+
+    const float* din = tin.data();
+    float* dout = tout.mutable_data();
+    //float* dtmp = tmax.mutable_data();
+
+    for (int i = 0; i < cnt; ++i) {
+        int idx_inner = i % inner_num;
+        int idx_outer = (i / inner_num) * axis_size;
+        int real_index = idx_outer * inner_num + idx_inner;
+
+        float max_data = din[real_index];
+        //! get max
+        for (int j = 1; j < axis_size; ++j) {
+            real_index += inner_num;
+            max_data = din[real_index] > max_data? din[real_index] : max_data;
+        }
+        //printf("max data: %.2f\n", max_data);
+
+        real_index = idx_outer * inner_num + idx_inner;
+        //! sub, exp and sum
+        dout[real_index] = expf(din[real_index] - max_data);
+        float sum_data = dout[real_index];
+        for (int j = 1; j < axis_size; ++j) {
+            real_index += inner_num;
+            dout[real_index] = expf(din[real_index] - max_data);
+            sum_data += dout[real_index];
+        }
+
+        //printf("sum exp data: %.2f\n", sum_data);
+
+        float sum_inv = 1.f / sum_data;
+
+        real_index = idx_outer * inner_num + idx_inner;
+        //! get softmax result
+        for (int j = 0; j < axis_size; ++j) {
+            dout[real_index] *= sum_inv;
+            real_index += inner_num;
+        }
+    }
+}
+
+TEST(TestSaberFuncTest, test_func_softmax_arm) {
+    // start Reshape & doInfer
+    Context<ARM> ctx1;
+    LOG(INFO) << "set runtine context";
+    PowerMode mode = cluster == 0? SABER_POWER_HIGH : SABER_POWER_LOW;
+    ctx1.set_run_mode(mode, threads);
+            LOG(INFO) << "test threads activated";
+#pragma omp parallel
+    {
+#ifdef USE_OPENMP
+        int thread = omp_get_num_threads();
+                LOG(INFO) << "number of threads: " << thread;
+#endif
+    }
+
+    int test_iter = 100;
+
+    int softmax_axis = 2; // channel
+    int w_in = 1;
+    int h_in = 21;
+    int ch_in = 1917;
+    int num_in = 1;
+
+    Shape shape_in(num_in, ch_in, h_in, w_in);
+    Shape shape_out = shape_in;
+
+    SoftmaxParam<TensorHf4> param(softmax_axis);
+
+    LOG(INFO) << " input tensor size, num=" << num_in << ", channel=" << \
+        ch_in << ", height=" << h_in << ", width=" << w_in;
+
+    LOG(INFO) << "softmax axis= " << param.axis;
+
+    std::vector<TensorHf4*> vin;
+    std::vector<TensorHf4*> vout;
+
+    Tensor<ARM, AK_FLOAT, NCHW> thin(shape_in);
+    for (int i = 0; i < thin.size(); ++i) {
+        thin.mutable_data()[i] = i % 4;
+    }
+    TensorHf4 tout;
+    TensorHf4 tout_basic(shape_out);
+    vin.push_back(&thin);
+
+#if COMPARE_RESULT
+    softmax_basic(thin, param.axis, tout_basic);
+    //print_tensor_host(tout_basic);
+#endif
+
+    Softmax<ARM, AK_FLOAT> softmax_arm;
+
+    LOG(INFO) << "shape out 4d: " << shape_out[0] << ", " << shape_out[1] << ", " << \
+              shape_out[2] << ", " << shape_out[3];
+
+    vout.push_back(&tout);
+    softmax_arm.compute_output_shape(vin, vout, param);
+    CHECK_EQ(shape_out == vout[0]->valid_shape(), true) << "compute shape error";
+
+    LOG(INFO) << "re-alloc tensor buffer";
+    vout[0]->re_alloc(vout[0]->valid_shape());
+
+    LOG(INFO) << "softmax initialized to saber impl";
+    softmax_arm.init(vin, vout, param, SPECIFY, SABER_IMPL, ctx1);
+
+    SaberTimer<ARM> t1;
+
+    LOG(INFO) << "saber softmax compute";
+    double to = 0;
+    double min_time = 100000;
+    for (int i = 0; i < test_iter; ++i) {
+        t1.clear();
+        t1.start(ctx1);
+        softmax_arm(vin, vout, param, ctx1);
+        vout[0]->record_event(ctx1.get_compute_stream());
+        vout[0]->sync();
+        t1.end(ctx1);
+        double tdiff = t1.get_average_ms();
+        to += tdiff;
+        if (tdiff < min_time) {
+            min_time = tdiff;
+        }
+    }
+
+    printf("saber softmax total time : %.4f, avg time : %.4f\n", to, to / test_iter, min_time);
+    //print_tensor_host(*vout[0]);
+
+#if COMPARE_RESULT
+    double max_ratio = 0;
+    double max_diff = 0;
+    //TensorHf4 tdiff(tout_basic.valid_shape());
+    //tensor_diff(tout_basic, tout_saber, tdiff);
+    //print_tensor_host(tdiff);
+    tensor_cmp_host(tout_basic.data(), tout.data(), tout_basic.valid_size(), max_ratio, max_diff);
+    LOG(INFO) << "compare result, max diff: " << max_diff << ", max ratio: " << max_ratio;
+    CHECK_EQ(fabsf(max_ratio) < 1e-5f, true) << "compute result error";
+#endif
+}
+
+int main(int argc, const char** argv){
+    // initial logger
+    //logger::init(argv[0]);
+    Env<ARM>::env_init(4);
+
+    if (argc >= 2) {
+        cluster = atoi(argv[1]);
+    }
+    if (argc >= 3) {
+        threads = atoi(argv[2]);
+    }
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
+
diff --git a/test/saber/arm/test_saber_func_test_arm.h b/test/saber/arm/test_saber_func_test_arm.h
new file mode 100644
index 0000000..439ead7
--- /dev/null
+++ b/test/saber/arm/test_saber_func_test_arm.h
@@ -0,0 +1,51 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN2_TEST_SABER_TEST_SABER_FUNC_TEST_ARM_H
+#define ANAKIN2_TEST_SABER_TEST_SABER_FUNC_TEST_ARM_H
+
+#include "utils/unit_test/aktest.h"
+#include "utils/logger/logger.h"
+#include <fstream>
+#include <vector>
+
+using namespace anakin::test;
+
+int read_file(std::vector<float> &results, const char* file_name) {
+
+    std::ifstream infile(file_name);
+    if (!infile.good()) {
+        LOG(ERROR) << "Cannot open " << file_name;
+        return false;
+    }
+    LOG(INFO) << "found filename: " << file_name;
+    std::string line;
+    while (std::getline(infile, line)) {
+        results.push_back((float)atof(line.c_str()));
+    }
+    return 0;
+}
+
+class TestSaberFuncTest : public Test {
+public:
+    TestSaberFuncTest() {}
+    ~TestSaberFuncTest() {}
+
+protected:
+    virtual void setup() {}
+    virtual void teardown() {}
+
+};
+
+#endif //ANAKIN2_TEST_SABER_TEST_SABER_FUNC_TEST_ARM_H
diff --git a/test/saber/arm/test_saber_tensor_arm.cpp b/test/saber/arm/test_saber_tensor_arm.cpp
new file mode 100644
index 0000000..4bc4b4e
--- /dev/null
+++ b/test/saber/arm/test_saber_tensor_arm.cpp
@@ -0,0 +1,218 @@
+#include "test_saber_tensor_arm.h"
+#include "tensor_op.h"
+#include <vector>
+using namespace anakin::saber;
+
+typedef TargetWrapper<ARM> ARM_API;
+typedef Tensor<ARM, AK_FLOAT, NCHW> Tensor4f;
+//typedef Tensor<ARM, AK_FLOAT, HW> Tensor2f;
+
+TEST(TestSaberTensorARM, test_tensor_constructor) {
+
+//! test empty constructor
+    LOG(INFO) << "test default (empty) constructor";
+    Tensor4f thost0;
+
+//! test tensor re_alloc function empty constructor
+    Shape sh0(2, 3, 10, 10);
+    LOG(INFO) << "|--test tensor re_alloc function on empty tensor";
+    thost0.re_alloc(sh0);
+    LOG(INFO) << "|--tensor size of host: " << thost0.size();
+    CHECK_EQ(thost0.size(), 600) << "error with tensor size";
+
+//! test tensor re_alloc function on tensor with data
+    LOG(INFO) << "|--test tensor re_alloc function on tensor with data";
+    Shape sh1(1, 3, 10, 10);
+    thost0.re_alloc(sh1);
+    LOG(INFO) << "|--tensor size of host: " << thost0.size();
+    CHECK_EQ(thost0.size(), 300) << "error with tensor size";
+
+
+//! test tensor shape() function
+    LOG(INFO) << "|--test tensor shape() function";
+    Shape sho = thost0.shape();
+    LOG(INFO) << "|--shape of tensor: " << sho[0] << ", " << sho[1] << "," << sho[2] << "," <<sho[3];
+    LOG(INFO) << "|--test get tensor n, c, h, w function, num = " \
+        << thost0.num() << ", channel = " << thost0.channel() << ", height = " \
+        << thost0.height() << ", width = " << thost0.width();
+
+//! test tensor mutable_data() function
+    LOG(INFO) << "|--test tensor mutable_data() function, write tensor data buffer with 1.f";
+    fill_tensor_host_const(thost0, 1.f);
+    LOG(INFO) << "|--test tensor data() function, show the const data, 1.f";
+    print_tensor_host(thost0);
+
+//! test tensor constructor with shape
+    LOG(INFO) << "test tensor constructor with shape";
+    Tensor4f thost1(sh1);
+
+//! test tensor copy_from() function
+    LOG(INFO) << "test copy_from() function, input tensor could be any target";
+    thost1.copy_from(thost0);
+    print_tensor_host(thost1);
+
+//! test tensor constructor with data, if target is different, create buffer, and copy the data
+    LOG(INFO) << "test tensor constructor with data, if target is different, create buffer, and copy the data";
+    float* host_data_ptr;
+    void* tmp_ptr;
+    ARM_API::mem_alloc(&tmp_ptr, sizeof(float) * sh1.count());
+    host_data_ptr = static_cast<float*>(tmp_ptr);
+    for (int i = 0; i < sh1.count(); ++i) {
+        host_data_ptr[i] = i;
+    }
+    LOG(INFO) << "|--construct host tensor from host data ptr";
+    Tensor4f thost3(host_data_ptr, ARM(), ARM_API::get_device_id(), sh1);
+    print_tensor_host(thost3);
+
+//! test tensor copy constructor
+    LOG(INFO) << "test tensor copy constructor";
+    LOG(INFO) << "|--normal copy constructor";
+    Tensor4f thost4(thost3);
+
+    LOG(INFO) << "|--push back to vector";
+    std::vector<Tensor4f> vthost;
+    vthost.push_back(thost0);
+    vthost.push_back(thost1);
+    vthost.push_back(thost3);
+    vthost.push_back(thost4);
+    print_tensor_host(vthost[3]);
+
+//! test share_from function, if targets are the same, buffer is shared, otherwise, buffer is copied
+    LOG(INFO) << "test share_from function";
+    Tensor4f thost5;
+    Shape sh2(1, 3, 5, 5);
+    Shape offset(0, 0, 5, 5);
+    LOG(INFO) << "|--shared host";
+    thost5.set_shape(sh2, thost3.shape(), offset);
+    thost5.share_from(thost3);
+
+    LOG(INFO) << "|--change data in shared tensor";
+    Shape sh_real = thost5.shape();
+    Shape sh_act = thost5.valid_shape();
+    Shape offset_act = thost5.offset();
+    int start_w = offset_act[3];
+    int start_h = offset_act[2];
+    int start_c = offset_act[1];
+    int start_n = offset_act[0];
+    int stride_h = sh_real.count(3);
+    int stride_c = sh_real.count(2);
+    int stride_n = sh_real.count(1);
+//int stride_n = sh_real.count(0);
+    int w = thost5.width();
+    int h = thost5.height();
+    int c = thost5.channel();
+    int n = thost5.num();
+    float* ptr_host = thost5.mutable_data();
+    for (int in = 0; in < n; ++in) {
+        float* ptr_batch = ptr_host + (in + start_n) * stride_n;
+        for (int ic = 0; ic < c; ++ic) {
+            float* ptr_channel = ptr_batch + (ic + start_c) * stride_c;
+            for (int ih = 0; ih < h; ++ih) {
+                float* ptr_row = ptr_channel + (ih + start_h) * stride_h;
+                for (int iw = 0; iw < w; ++iw) {
+                    ptr_row[start_w + iw] = 1.f;
+                }
+            }
+        }
+    }
+
+    LOG(INFO) << "|--show root tensor while data is changed by shared tensor";
+    print_tensor_host(thost3);
+}
+#if 0
+TEST(TestSaberTensorARM, test_tensor_deepcopy) {
+    //! tensor constructor with alloc data, if target is different, create buffer, and copy the data
+    LOG(INFO) << "tensor constructor with data, if target is different, create buffer, and copy the data";
+
+    Shape sh0(2, 4, 8, 8);
+    Shape va_sh0(2, 4, 4, 4);
+    Shape off_sh0(0, 0, 2, 2);
+    Shape sh1(2, 4, 10, 4);
+    Shape va_sh1(va_sh0);
+    Shape off_sh1(0, 0, 4, 0);
+    Shape sh2(4, 64);
+    Shape va_sh2(2, 64);
+    Shape off_sh2(1, 0);
+
+    LOG(INFO) << "|--construct host tensor from host data ptr";
+    //! create thost0, thost1, thost01 are source tensor
+    Tensor4f thost0(sh0);
+    for (int i = 0; i < sh0.count(); ++i) {
+        thost0.mutable_data()[i] = i;
+    }
+    print_tensor_host(thost0);
+    //! create shared tensor, with valid shape and offset
+    Tensor4f thost01;
+    thost01.set_shape(va_sh0, sh0, off_sh0);
+    thost01.share_from(thost0);
+    //! create tensor with entire shape, valid shape and offset
+    Tensor4f thost1(va_sh0);
+    for (int i = 0; i < va_sh0.count(); ++i) {
+        thost1.mutable_data()[i] = i;
+    }
+
+    //! create thost2, thost3, thost21 as dst tensor, same layout with src
+    Tensor4f thost2(sh1);
+    fill_tensor_host_const(thost2, 0.f);
+    Tensor4f thost21;
+    thost21.set_shape(va_sh1, sh1, off_sh1);
+    thost21.share_from(thost2);
+    Tensor4f thost3(va_sh1);
+
+    //! create thost4, thost5, thost41 as dst tensor, different layout with src
+    Tensor2f thost4(sh2);
+    fill_tensor_host_const(thost4, 0.f);
+    Tensor2f thost41;
+    thost41.set_shape(va_sh2, sh2, off_sh2);
+    thost41.share_from(thost4);
+    Tensor2f thost5(va_sh2);
+
+    //! test tensor deep copy, entire buffer copy
+    LOG(INFO) << "test tensor deep copy, entire buffer copy";
+    thost3.copy_from(thost1);
+    print_tensor_host(thost3);
+
+    //! test tensor deep copy, src with roi
+    LOG(INFO) << "test tensor deep copy, src with roi";
+    thost3.copy_from(thost01);
+    print_tensor_host(thost3);
+
+    //! test tensor deep copy, dst with roi
+    LOG(INFO) << "test tensor deep copy, dst with roi";
+    thost21.copy_from(thost1);
+    print_tensor_host(thost21);
+
+    //! test tensor deep copy, src and dst are with roi
+    LOG(INFO) << "test tensor deep copy, src and dst are with roi";
+    thost21.copy_from(thost01);
+    print_tensor_host(thost21);
+
+    //! test tensor deep copy, entire buffer copy
+    LOG(INFO) << "test tensor deep copy, entire buffer copy, different layout";
+    thost5.copy_from(thost1);
+    print_tensor_host(thost5);
+
+    //! test tensor deep copy, src with roi
+    LOG(INFO) << "test tensor deep copy, src with roi, different layout";
+    thost5.copy_from(thost01);
+    print_tensor_host(thost5);
+
+    //! test tensor deep copy, dst with roi
+    LOG(INFO) << "test tensor deep copy, dst with roi, different layout";
+    thost41.copy_from(thost1);
+    print_tensor_host(thost41);
+
+    //! test tensor deep copy, src and dst are with roi
+    LOG(INFO) << "test tensor deep copy, src and dst are with roi, different layout";
+    thost41.copy_from(thost01);
+    print_tensor_host(thost41);
+}
+#endif
+
+int main(int argc, const char** argv){
+    // initial logger
+    logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
\ No newline at end of file
diff --git a/test/saber/arm/test_saber_tensor_arm.h b/test/saber/arm/test_saber_tensor_arm.h
new file mode 100644
index 0000000..9dcf5dd
--- /dev/null
+++ b/test/saber/arm/test_saber_tensor_arm.h
@@ -0,0 +1,33 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN2_TEST_SABER_TEST_SABER_TENSOR_ARM_H
+#define ANAKIN2_TEST_SABER_TEST_SABER_TENSOR_ARM_H
+#include "utils/unit_test/aktest.h"
+#include "utils/logger/logger.h"
+#include "core/tensor.h"
+
+using namespace anakin::test;
+
+class TestSaberTensorARM : public Test {
+public:
+    TestSaberTensorARM() {}
+    ~TestSaberTensorARM() {}
+
+protected:
+    virtual void setup() {}
+    virtual void teardown() {}
+
+};
+#endif //ANAKIN2_TEST_SABER_TEST_SABER_TENSOR_ARM_H
diff --git a/test/saber/cuda/test_saber_buffer_NV.cpp b/test/saber/cuda/test_saber_buffer_NV.cpp
index b4cf50e..dca122d 100644
--- a/test/saber/cuda/test_saber_buffer_NV.cpp
+++ b/test/saber/cuda/test_saber_buffer_NV.cpp
@@ -10,7 +10,7 @@ void test_buffer() {
 
     typedef TargetWrapper<X86> X86_API;
     typedef TargetWrapper<NV> NV_API;
-    typedef typename DataTrait<datatype>::dtype Dtype;
+    typedef typename DataTrait<NV, datatype>::dtype Dtype;
     typedef Buffer<X86> BufferH;
     typedef Buffer<NV> BufferD;
 
diff --git a/test/saber/cuda/test_saber_buffer_NV.h b/test/saber/cuda/test_saber_buffer_NV.h
index 34b0b23..fc11167 100644
--- a/test/saber/cuda/test_saber_buffer_NV.h
+++ b/test/saber/cuda/test_saber_buffer_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_context_NV.h b/test/saber/cuda/test_saber_context_NV.h
index 8f99f9c..f4a6b20 100644
--- a/test/saber/cuda/test_saber_context_NV.h
+++ b/test/saber/cuda/test_saber_context_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_device_NV.h b/test/saber/cuda/test_saber_device_NV.h
index 69f12ab..54cce6c 100644
--- a/test/saber/cuda/test_saber_device_NV.h
+++ b/test/saber/cuda/test_saber_device_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_NV.h b/test/saber/cuda/test_saber_func_NV.h
index a215b99..c470ab6 100644
--- a/test/saber/cuda/test_saber_func_NV.h
+++ b/test/saber/cuda/test_saber_func_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_activation.cpp b/test/saber/cuda/test_saber_func_activation.cpp
index 6a5f5dd..0e5b4ae 100644
--- a/test/saber/cuda/test_saber_func_activation.cpp
+++ b/test/saber/cuda/test_saber_func_activation.cpp
@@ -6,170 +6,105 @@
 #include <vector>
 
 using namespace anakin::saber;
+typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
+typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
 
-template <typename Tensor>
-void print_tensor_shape(std::string name, Tensor& t0) {
-
-    LOG(INFO) << name << " valid shape is ["
-              << t0.valid_shape()[0] << ", "
-              << t0.valid_shape()[1] << ", "
-              << t0.valid_shape()[2] << ", "
-              << t0.valid_shape()[3] << "].";
-
-    LOG(INFO) << name << " real shape is ["
-              << t0.shape()[0] << ", "
-              << t0.shape()[1] << ", "
-              << t0.shape()[2] << ", "
-              << t0.shape()[3] << "].";
-
-    LOG(INFO) << name << " offset is ["
-              << t0.offset()[0] << ", "
-              << t0.offset()[1] << ", "
-              << t0.offset()[2] << ", "
-              << t0.offset()[3] << "].";
-}
-
-TEST(TestSaberFuncNV, test_func_constructor) {
-
+void test_activation(Shape input_big_shape, Shape input_shape, 
+         ActivationParam<TensorDf4> param, Shape offset, bool is_share_from) {
+    Context<NV> ctx(0, 1, 1);
     typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
     typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
 
-    int img_num = 1;
-    int in_channels = 2;
-    int img_h = 8;
-    int img_w = 8;
-
-    Shape img_s(img_num, in_channels, img_h, img_w);
-
-    TensorHf4 img_host;
-    TensorDf4 img_dev;
-
-    img_host.re_alloc(img_s);
-    img_dev.re_alloc(img_s);
-
-    for (int i = 0; i < img_host.size(); ++i) {
-        img_host.mutable_data()[i] = (float)(0.05 * (i & 0x1f) * -1);
+    TensorDf4 big_input;
+    TensorDf4 small_input;
+    TensorDf4 big_output;
+    TensorDf4 small_output;
+
+    big_input.re_alloc(input_big_shape);
+    big_output.re_alloc(input_big_shape);
+    small_input.set_shape(input_shape, input_shape);
+    small_output.set_shape(input_shape, input_shape);
+    TensorHf4 host_big_input(input_big_shape);
+    fill_tensor_host_rand(host_big_input, -1, 1);
+    big_input.copy_from(host_big_input);
+    //fill_tensor_device_rand(big_input, -1, 1);
+
+    if (is_share_from) {
+        small_input.share_from(big_input);
+        small_output.share_from(big_output);
+    } else {
+        small_input.share_sub_buffer(big_input, input_shape, offset);
+        small_output.share_sub_buffer(big_output, input_shape, offset);
     }
 
-    img_dev.copy_from(img_host);
     TensorDf4 output_dev;
-
     // start Reshape & doInfer
 
-    Context<NV> ctx1(0, 1, 1);
-
-    ActivationParam<TensorDf4> param(Active_elu, 0.1f, 0.1f);
+    std::vector<TensorDf4*> inputs;
+    std::vector<TensorDf4*> outputs;
 
-    std::vector<TensorDf4*> input;
-    std::vector<TensorDf4*> output;
-
-    input.push_back(&img_dev);
-    output.push_back(&output_dev);
+    inputs.push_back(&small_input);
+    outputs.push_back(&small_output);
 
     Activation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW> act;
-    act.compute_output_shape(input, output, param);
-    output_dev.re_alloc(output[0]->shape());
 
+    act.compute_output_shape(inputs, outputs, param);
     // init assume output tensor has been reshpaed by user.
-    act.init(input, output, param, SPECIFY, VENDER_IMPL, ctx1);
-    act(input, output, param, ctx1);
-
-    cudaStream_t cuda_stream = ctx1.get_compute_stream();
-    output[0]->record_event(cuda_stream);
-    output_dev.sync();
-    print_tensor_device(output_dev);
+    act.init(inputs, outputs, param, SPECIFY, SABER_IMPL, ctx);
+    act(inputs, outputs, param, ctx);
+    cudaStream_t cuda_stream = ctx.get_compute_stream();
+    outputs[0]->record_event(cuda_stream);
+    outputs[0]->sync();
+    print_tensor_device(big_output);
+    print_tensor_device(big_input);
+    if (param.prelu_param.slope) {
+        print_tensor_device((*param.prelu_param.slope));
+    }
     cudaDeviceSynchronize();
     CUDA_POST_KERNEL_CHECK;
 }
 
-TEST(TestSaberFuncNV, test_func_sub_tensor) {
-
-    typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
-    typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
-
-    int img_num = 1;
-    int in_channels = 2;
-    int img_h = 8;
-    int img_w = 8;
 
-    Shape img_s(img_num, in_channels, img_h, img_w);
-
-    TensorHf4 img_host;
-    TensorDf4 img_dev;
-
-    img_host.re_alloc(img_s);
-    img_dev.re_alloc(img_s);
-
-    for (int i = 0; i < img_host.size(); ++i) {
-        img_host.mutable_data()[i] = (float)(0.05 * (i & 0x1f) * -1);
+TEST(TestSaberFuncNV, test_func_activation) {
+    int num = 1;
+    int channel = 2;
+    int height = 5;
+    int width = 4;
+
+    Shape input_shape(num, channel, height, width);
+    Shape input_big_shape(num, channel, height+1, width+1);
+    Shape offset_0(0, 0, 0, 0);
+    Shape offset_1(0, 0, 1, 1);
+    Shape slope_shape_0(1, channel, 1, 1);
+    Shape slope_shape_1(1, 1, 1, 1);
+    TensorDf4 prelu_slope_0;
+    prelu_slope_0.reshape(slope_shape_0);
+    PreluParam<TensorDf4> prelu_0(false, &prelu_slope_0);
+    
+    TensorDf4 prelu_slope_1;
+    prelu_slope_1.reshape(slope_shape_1);
+    PreluParam<TensorDf4> prelu_1(true, &prelu_slope_1);
+    fill_tensor_device_rand(prelu_slope_0, 0, 1);
+    fill_tensor_device_rand(prelu_slope_1, 0, 1);
+
+    ActivationParam<TensorDf4> param_elu(Active_elu, 0.1f, 0.1f);
+    ActivationParam<TensorDf4> param_relu(Active_relu, 0.0f, 0.0f);
+    ActivationParam<TensorDf4> param_sigmoid(Active_sigmoid, 0.1f, 0.1f);
+	ActivationParam<TensorDf4> param_tanh(Active_tanh, 0.1f, 0.1f);
+    ActivationParam<TensorDf4> param_prelu_0(Active_prelu, 0.f, 0.f, prelu_0);
+    ActivationParam<TensorDf4> param_prelu_1(Active_prelu, 0.f, 0.f, prelu_1);
+
+    for (ActivationParam<TensorDf4> param : {param_elu, param_relu, param_sigmoid, param_tanh, param_prelu_0, param_prelu_1}) {
+    //for (ActivationParam<TensorDf4> param : {param_sigmoid}) {
+        for (auto share_from : {false, true}) {
+            for (auto offset: {offset_0, offset_1}) {
+                test_activation(input_big_shape,
+                        input_shape, param, offset, share_from);
+            }
+        }
     }
 
-    img_dev.copy_from(img_host);
-    Shape img_s_t0(img_num, in_channels, 4, 4);
-
-    TensorDf4 t0;
-    TensorDf4 t1;
-
-    t0.share_sub_buffer(img_dev, img_s_t0, {0, 0, 0, 0});
-    t1.share_sub_buffer(img_dev, img_s_t0, {0, 0, 4, 4});
-
-    print_tensor_shape("t0", t0);
-    print_tensor_shape("t1", t1);
-
-    TensorDf4 output_dev;
-
-    TensorDf4 out0;
-    TensorDf4 out1;
-
-    // start Reshape & doInfer
-    Context<NV> ctx1(0, 1, 1);
-    Context<NV> ctx2(0, 2, 2);
-
-    ActivationParam<TensorDf4> param1(Active_elu, 0.1f, 0.1f);
-    ActivationParam<TensorDf4> param2(Active_elu, 0.1f, 0.1f);
-
-    std::vector<TensorDf4*> input1, input2;
-    std::vector<TensorDf4*> output1, output2;
-
-    input1.push_back(&t0);
-    input2.push_back(&t1);
-
-    output1.push_back(&out0);
-    output2.push_back(&out1);
-
-    //FIXME where do I get img_s and all those shapes ????
-    output_dev.re_alloc(img_s);
-
-    out0.share_sub_buffer(output_dev, img_s_t0, {0, 0, 0, 0});
-    out1.share_sub_buffer(output_dev, img_s_t0, {0, 0, 4, 4});
-
-    print_tensor_shape("output_dev", output_dev);
-
-    Activation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW> act1;
-    Activation<NV, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW> act2;
-
-    act1.compute_output_shape(output1, input1, param1);
-    act2.compute_output_shape(output2, input2, param2);
-
-    print_tensor_shape("out0", out0);
-    print_tensor_shape("out1", out1);
-
-    // init assume output tensor has been reshpaed by user.
-    act1.init(input1, output1, param1, SPECIFY, SABER_IMPL, ctx1);
-    act1(input1, output1, param1, ctx1);
-    cudaStream_t cuda_stream = ctx1.get_compute_stream();
-    output1[0]->record_event(cuda_stream);
-
-    act2.init(input2, output2, param2, SPECIFY, SABER_IMPL, ctx2);
-    act2(input2, output2, param2, ctx2);
-    cudaStream_t cuda_stream2 = ctx2.get_compute_stream();
-    output2[0]->record_event(cuda_stream2);
-
-    out0.sync();
-    out1.sync();
-    print_tensor_device(output_dev);
-    cudaDeviceSynchronize();
-    CUDA_POST_KERNEL_CHECK;
+    
 }
 
 int main(int argc, const char** argv) {
diff --git a/test/saber/cuda/test_saber_func_argmax_NV.cpp b/test/saber/cuda/test_saber_func_argmax_NV.cpp
index 4d588de..3b934bd 100644
--- a/test/saber/cuda/test_saber_func_argmax_NV.cpp
+++ b/test/saber/cuda/test_saber_func_argmax_NV.cpp
@@ -91,7 +91,7 @@ void test_argmax(std::vector<TensorType*>& inputs_big, std::vector<TensorType*>&
 
     cudaDeviceSynchronize();
     //print_tensor_device(*inputs[0]);
-    //print_tensor_device(*outputs[0]);
+    print_tensor_device(*outputs[0]);
     //cudaDeviceSynchronize();
     //print_tensor_device(out_valid);
     cudaDeviceSynchronize();
@@ -106,12 +106,12 @@ TEST(TestSaberFuncNV, test_func_argmax) {
     typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
 
     int n = 10;
-    int c = 16;
-    int h = 8;
-    int w = 8;
+    int c = 3;
+    int h = 20;
+    int w = 20;
 
     //Shape img_s(img_num, in_channels, img_h, img_w);
-    Shape real_shape(n + 1, c + 1, h + 1, w + 1);
+    Shape real_shape(n, c, h, w );
     Shape valid_shape(n, c, h, w);
     Shape input_offset(0, 0, 0, 0);
     Shape output_offset(0, 0, 0, 0);
diff --git a/test/saber/cuda/test_saber_func_concat_NV.h b/test/saber/cuda/test_saber_func_concat_NV.h
index bc07319..c22a8ea 100644
--- a/test/saber/cuda/test_saber_func_concat_NV.h
+++ b/test/saber/cuda/test_saber_func_concat_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_conv_act_eltwise_sass.cpp b/test/saber/cuda/test_saber_func_conv_act_eltwise_sass.cpp
index 0d873bc..b522507 100644
--- a/test/saber/cuda/test_saber_func_conv_act_eltwise_sass.cpp
+++ b/test/saber/cuda/test_saber_func_conv_act_eltwise_sass.cpp
@@ -15,21 +15,26 @@ typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
 typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
 
 #if 0
-std::vector<int> param0 {3, 3, 480, 1440, 16};
-std::vector<int> param1{3, 16, 240, 720, 32};
-std::vector<int> param2{3, 32, 120, 360, 64};
-std::vector<int> param3{3, 64, 60, 180, 128};
-std::vector<int> param4{3, 128, 30, 90, 128};
-std::vector<int> param5{3, 256, 15, 45, 512};
-std::vector<int> param6{3, 512, 15, 45, 512};
-std::vector<int> param7{3, 1024, 15, 45, 512};
+std::vector<int> param0 {3, 3, 480, 1440, 16, 1, 3};
+std::vector<int> param1{3, 16, 240, 720, 32, 1, 3};
+std::vector<int> param2{3, 32, 120, 360, 64, 1, 3};
+std::vector<int> param3{3, 64, 60, 180, 128, 1, 3};
+std::vector<int> param4{3, 128, 30, 90, 128, 1, 3};
+std::vector<int> param5{3, 256, 15, 45, 512, 1, 3};
+std::vector<int> param6{3, 512, 15, 45, 512, 1, 3};
+std::vector<int> param7{3, 1024, 15, 45, 512, 1, 3};
 #else
-std::vector<int> param_test {1, 256, 16, 16, 512};
+std::vector<int> param_test {1, 256, 16, 16, 512, 0, 1};
+std::vector<int> param_test1 {1, 16, 240, 720, 32, 0, 1};
+std::vector<int> param_test2 {1, 32, 120, 360, 64, 0, 1};
+std::vector<int> param_test3 {1, 64, 60, 180, 128, 0, 1};
+std::vector<int> param_test4 {1, 512, 15, 45, 512, 0, 1};
+std::vector<int> param_test5 {1, 256, 16, 16, 512, 1, 3};
 #endif
 std::map<std::string, std::vector<int>> param_map;
 
 //std::vector<EltwiseType> elt = {Eltwise_prod, Eltwise_sum, Eltwise_max};
-std::vector<EltwiseType> elt = {Eltwise_prod};
+std::vector<EltwiseType> elt = {Eltwise_sum};
 
 
 TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
@@ -43,10 +48,14 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
     param_map.insert(std::pair<std::string, std::vector<int>>("conv6", param6));
     param_map.insert(std::pair<std::string, std::vector<int>>("conv7", param7));
 #else
-    param_map.insert(std::pair<std::string, std::vector<int>>("conv4", param_test));
+    param_map.insert(std::pair<std::string, std::vector<int>>("conv1", param_test1));
+    param_map.insert(std::pair<std::string, std::vector<int>>("conv2", param_test2));
+    param_map.insert(std::pair<std::string, std::vector<int>>("conv3", param_test3));
+    param_map.insert(std::pair<std::string, std::vector<int>>("conv4", param_test4));
+    param_map.insert(std::pair<std::string, std::vector<int>>("conv5", param_test5));
 #endif
 
-    for (int jj = 0; jj < 20; jj ++) {
+//    for (int jj = 0; jj < 20; jj ++) {
         for (int a = 0; a < elt.size(); a++) {
             EltwiseType elt_type = elt[a];
 
@@ -59,15 +68,15 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
                 int out_channel = iter->second[4];
 
                 int group = 1;
-                int pad_h = 1;
-                int pad_w = 1;
+                int pad_h = iter->second[5];
+                int pad_w = iter->second[5];
                 int stride_h = 1;
                 int stride_w = 1;
                 int dilation_h = 1;
                 int dilation_w = 1;
 
-                int kernel_h = 3;
-                int kernel_w = 3;
+                int kernel_h = iter->second[6];
+                int kernel_w = iter->second[6];
                 bool bias_term = true;
 
                 Shape img_s(img_num, in_channels, img_h, img_w);
@@ -135,7 +144,7 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
                 conv.compute_output_shape(input, output, param);
                 output_dev.re_alloc(output[0]->shape());
 
-                std::cout << "output shape = " << output[0]->shape()[0] << " " << output[0]->shape()[1] << " "
+                std::cout << "kernel = "<<iter->second[6]<<" output shape = " << output[0]->shape()[0] << " " << output[0]->shape()[1] << " "
                           << output[0]->shape()[2] << " " << output[0]->shape()[3] << std::endl;
                 result_cudnn.re_alloc(output[0]->shape());
                 cudaDeviceSynchronize();
@@ -146,7 +155,7 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
                 output_dev.sync();
                 result_cudnn.copy_from(*output[0]);
                 cudaDeviceSynchronize();
-
+                std::cout<<"calling saber conv !!!"<<std::endl;
                 ConvAct<NV, AK_FLOAT> conv_saber;
                 output1.push_back(&output_dev1);
                 output_dev1.re_alloc(output[0]->shape());
@@ -173,11 +182,11 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
                     float err;
 
                     if (elt_type == Eltwise_prod) {
-                        err = result_saber.data(0)[i] - (result_cudnn.data(0)[i] * output_host.data(0)[i]);
+                        err = result_saber.data()[i] - (result_cudnn.data()[i] * output_host.data()[i]);
                     } else if (elt_type == Eltwise_sum) {
-                        err = result_saber.data(0)[i] - (result_cudnn.data(0)[i] + output_host.data(0)[i]);
+                        err = result_saber.data()[i] - (result_cudnn.data()[i] + output_host.data()[i]);
                     } else if (elt_type == Eltwise_max) {
-                        err = result_saber.data(0)[i] - std::max(result_cudnn.data(0)[i], output_host.data(0)[i]);
+                        err = result_saber.data()[i] - std::max(result_cudnn.data()[i], output_host.data()[i]);
                     }
 
                     if (abs(err) > 0.001) {
@@ -194,7 +203,7 @@ TEST(TestSaberFuncNV, test_func_conv_relu_elt_fusion) {
                 }
             }
         }
-    }
+//    }
 }
 
 int main(int argc, const char** argv) {
diff --git a/test/saber/cuda/test_saber_func_eltwise.h b/test/saber/cuda/test_saber_func_eltwise.h
index 149887c..b131971 100644
--- a/test/saber/cuda/test_saber_func_eltwise.h
+++ b/test/saber/cuda/test_saber_func_eltwise.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_eltwise_act.h b/test/saber/cuda/test_saber_func_eltwise_act.h
index 43d2059..fc1f8a0 100644
--- a/test/saber/cuda/test_saber_func_eltwise_act.h
+++ b/test/saber/cuda/test_saber_func_eltwise_act.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_fc_NV.h b/test/saber/cuda/test_saber_func_fc_NV.h
index 65c6688..2aa56b2 100644
--- a/test/saber/cuda/test_saber_func_fc_NV.h
+++ b/test/saber/cuda/test_saber_func_fc_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_gru.cpp b/test/saber/cuda/test_saber_func_gru.cpp
index 9ed306c..dcf872d 100644
--- a/test/saber/cuda/test_saber_func_gru.cpp
+++ b/test/saber/cuda/test_saber_func_gru.cpp
@@ -70,8 +70,8 @@ void anakin_NV_gemm_2(cublasHandle_t handle, const int M, const int N, const int
 #define GRUOFFSET
 //#define CUDNNGRU
 //#define TEST_X86
-void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 22,
-                    int hidden_size = 33) {
+void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 222,
+                    int hidden_size = 333) {
 
 #ifdef TEST_X86
     Context<X86> ctx_dev(0, 1, 1);
@@ -85,7 +85,7 @@ void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 2
 
 
 #ifdef GRUOFFSET
-    std::vector<int> offsets = {0,10,15,30};
+    std::vector<int> offsets = {0,12,40,90,100,101};
     bool is_reverse = true;
     batch_size = offsets.size() - 1;
     Shape shape_ux(1, 1, offsets[offsets.size() - 1], hidden_size * 3);
@@ -163,7 +163,7 @@ void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 2
     std::vector<TensorDf4*> input_dev_4d;
     std::vector<TensorDf4*> output_dev_4d;
     input_dev_4d.push_back(&dev_x);
-    input_dev_4d.push_back(&dev_h);
+//    input_dev_4d.push_back(&dev_h);
     output_dev_4d.push_back(&dev_out);
 
 #ifdef CUDNNGRU
@@ -239,7 +239,7 @@ void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 2
 #ifdef GRUOFFSET
 
     dev_x.set_seq_offset(offsets);
-    GruParam<TensorDf4> param(&dev_wu, &dev_b, GRU_ORIGIN,Active_sigmoid_fluid,Active_relu,is_reverse);
+    GruParam<TensorDf4> param(&dev_wu, &dev_b, GRU_ORIGIN,Active_sigmoid_fluid,Active_tanh_fluid,is_reverse);
 #else
 #ifdef CUDNNGRU
     GruParam<TensorDf4> param(&dev_w, &dev_u, &dev_b, false, GRU_CUDNN);
@@ -268,7 +268,7 @@ void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 2
 
     dev_gru(input_dev_4d, output_dev_4d, param, ctx_dev);
 
-    int test_iter = 1;
+    int test_iter = 1000;
 
     t1.start(ctx_dev);
 
@@ -300,9 +300,9 @@ void test_saber_gru(int sequence_size = 2, int batch_size = 1, int word_size = 2
     tensor_cmp_host(host_g.data(), compare_g.data(), host_g.valid_size(), maxratio, maxdiff);
 
     if (abs(maxratio) <= 0.001) {
-        LOG(INFO) << "passed  " << maxratio;
+        LOG(INFO) << "passed  " << maxratio<<","<<maxdiff;
     } else {
-        LOG(INFO) << "failed : ratio " << maxratio;
+        LOG(INFO) << "failed : ratio " << maxratio<<","<<maxdiff;
     }
 
 #elif (!defined(FAKEINPUT)&&defined(CUDNNGRU))
diff --git a/test/saber/cuda/test_saber_func_multiclass_nms_NV.cpp b/test/saber/cuda/test_saber_func_multiclass_nms_NV.cpp
deleted file mode 100644
index b9f958a..0000000
--- a/test/saber/cuda/test_saber_func_multiclass_nms_NV.cpp
+++ /dev/null
@@ -1,131 +0,0 @@
-#include "core/context.h"
-#include "funcs/multiclass_nms.h"
-#include "test_saber_func_NV.h"
-#include "tensor_op.h"
-#include "saber_types.h"
-
-using namespace anakin::saber;
-#define USE_DUMP_TENSOR 0
-
-TEST(TestSaberFuncNV, test_multiclass_nms) {
-
-    int iter = 10;
-
-    typedef Tensor<X86, AK_FLOAT, NHW> TensorHf3;
-    typedef Tensor<NV, AK_FLOAT, NHW> TensorDf3;
-
-    typedef Tensor<X86, AK_FLOAT, NW> TensorHf2;
-    typedef Tensor<NV, AK_FLOAT, NW> TensorDf2;
-
-    //! batch size = 16, boxes = 1917, loc = boxes * 4
-    Shape sh_loc{16, 1917, 4};
-    //! batch size = 16, boxes = 1917, conf = boxes * 21
-    Shape sh_conf{16, 21, 1917};
-
-#if USE_DUMP_TENSOR
-    std::vector<float> loc_data; //!first input tensor
-    std::vector<float> conf_data;//! second input tensor
-
-    std::vector<float> result_data;//! output tensor to compare with
-
-    if (read_file(loc_data, "../../test/saber/data/bbox_data.txt") != 0) {
-        LOG(FATAL) << "file not exist!!!";
-    }
-
-    if (read_file(conf_data, "../../test/saber/data/score_data.txt") != 0) {
-        LOG(FATAL) << "file not exist!!!";
-    }
-
-    if (read_file(result_data, "../../test/saber/data/detection_output.txt") != 0) {
-        LOG(FATAL) << "file not exist!!!";
-    }
-
-    LOG(INFO) << "read bbox data, size: " << loc_data.size();
-    LOG(INFO) << "read score data, size: " << conf_data.size();
-
-    TensorDf3 tdloc(loc_data.data(), X86(), 0, sh_loc);
-    TensorDf3 tdconf(conf_data.data(), X86(), 0, sh_conf);
-
-#else
-    TensorDf3 tdloc(sh_loc);
-    TensorDf3 tdconf(sh_conf);
-    fill_tensor_device_rand(tdloc, 0.1f, 0.9f);
-    fill_tensor_device_rand(tdconf, 0.1f, 0.3f);
-#endif
-
-    TensorDf2 tdout;
-
-    std::vector<TensorDf3*> inputs;
-    std::vector<TensorDf2*> outputs;
-
-    inputs.push_back(&tdloc);
-    inputs.push_back(&tdconf);
-    outputs.push_back(&tdout);
-
-    MultiClassNMSParam<TensorDf3> param;
-    param.init(0, 100, 100, 0.45f, 0.25f);
-
-    Context<NV> ctx_dev(0, 1, 1);
-
-    MultiClassNMS<NV, AK_FLOAT> det_dev;
-
-    LOG(INFO) << "detection output compute output shape";
-    SABER_CHECK(det_dev.compute_output_shape(inputs, outputs, param));
-    Shape va_sh{1, 7};
-    LOG(INFO) << "output shape pre alloc: " << va_sh[0] << ", " << va_sh[1];
-    CHECK_EQ(va_sh == outputs[0]->valid_shape(), true) << "compute shape error";
-
-    LOG(INFO) << "detection output init";
-    SABER_CHECK(det_dev.init(inputs, outputs, param, RUNTIME, SABER_IMPL, ctx_dev));
-
-    LOG(INFO) << "detection output compute";
-    SaberTimer<NV> t1;
-    t1.clear();
-    t1.start(ctx_dev);
-
-    for (int i = 0; i < iter; ++i) {
-        SABER_CHECK(det_dev(inputs, outputs, param, ctx_dev));
-        outputs[0]->record_event(ctx_dev.get_compute_stream());
-        outputs[0]->sync();
-        //cudaDeviceSynchronize();
-    }
-
-    CUDA_POST_KERNEL_CHECK;
-    t1.end(ctx_dev);
-    float ts = t1.get_average_ms();
-    LOG(INFO) << "output size: " << outputs[0]->valid_shape()[0] << ", " << \
-              outputs[0]->valid_shape()[1];
-    LOG(INFO) << "total time: " << ts << "avg time: " << ts / iter;
-
-    print_tensor_device(*outputs[0]);
-    cudaDeviceSynchronize();
-
-#if USE_DUMP_TENSOR
-    TensorHf2 thout(outputs[0]->valid_shape());
-    thout.copy_from(*outputs[0]);
-
-    TensorHf2 thcmp(result_data.data(), X86(), 0, Shape{16, 7});
-    print_tensor_host(thcmp);
-
-    CHECK_EQ(thout.size(), result_data.size()) << "detection compute error";
-
-    double max_ratio = 0;
-    double max_diff = 0;
-    tensor_cmp_host(result_data.data(), thout.data(), thout.size(), max_ratio, max_diff);
-    CHECK_EQ(max_ratio < 1e-5f, true) << "detection compute error";
-    LOG(INFO) << "detection output error: " << max_diff << ", max_ratio: " << max_ratio;
-#else
-    LOG(INFO) << "current unit test need read tensor from disk file";
-
-#endif //USE_DUMP_TENSOR
-}
-
-int main(int argc, const char** argv) {
-    Env<NV>::env_init();
-    // initial logger
-    //logger::init(argv[0]);
-    InitTest();
-    RUN_ALL_TESTS(argv[0]);
-    return 0;
-}
-
diff --git a/test/saber/cuda/test_saber_func_normalize_NV.h b/test/saber/cuda/test_saber_func_normalize_NV.h
index c31effc..6e681b0 100644
--- a/test/saber/cuda/test_saber_func_normalize_NV.h
+++ b/test/saber/cuda/test_saber_func_normalize_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_permute.h b/test/saber/cuda/test_saber_func_permute.h
index 2a61379..3ee0050 100644
--- a/test/saber/cuda/test_saber_func_permute.h
+++ b/test/saber/cuda/test_saber_func_permute.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_permute_power.h b/test/saber/cuda/test_saber_func_permute_power.h
index 64e8651..b61c6c8 100644
--- a/test/saber/cuda/test_saber_func_permute_power.h
+++ b/test/saber/cuda/test_saber_func_permute_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_power.h b/test/saber/cuda/test_saber_func_power.h
index a664105..cf32a37 100644
--- a/test/saber/cuda/test_saber_func_power.h
+++ b/test/saber/cuda/test_saber_func_power.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_prelu_NV.cpp b/test/saber/cuda/test_saber_func_prelu_NV.cpp
deleted file mode 100644
index 18050d1..0000000
--- a/test/saber/cuda/test_saber_func_prelu_NV.cpp
+++ /dev/null
@@ -1,229 +0,0 @@
-
-#include "core/context.h"
-#include "funcs/prelu.h"
-#include "test_saber_func_prelu_NV.h"
-#include "tensor_op.h"
-#include "saber_types.h"
-#include <vector>
-
-using namespace anakin::saber;
-
-TEST(TestSaberFuncPreluNV, test_func_prelu_without_roi_NV) {
-
-    typedef TargetWrapper<NV> API;
-
-    typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
-
-    typedef TensorDf4::Dtype dtype;
-
-    int test_iter = 1000;
-
-    int w_in = 10;
-    int h_in = 2;
-    int ch_in = 2;
-    int num_in = 1;
-
-    Shape shape_in(num_in, ch_in, h_in, w_in);
-    Shape shape_out = shape_in;
-    Shape sh_slope{1, 1, 1, ch_in};
-    Tensor<X86, AK_FLOAT, NCHW> th_slope(sh_slope);
-    TensorDf4 tslop(sh_slope);
-
-    for (int i = 0; i < ch_in; ++i) {
-        th_slope.mutable_data()[i] = 0.1f * (i + 1);
-    }
-
-    tslop.copy_from(th_slope);
-
-    PreluParam<TensorDf4> param_shared(true, &tslop);
-    PreluParam<TensorDf4> param(false, &tslop);
-
-    LOG(INFO) << " input tensor size, num=" << num_in << ", channel=" << \
-              ch_in << ", height=" << h_in << ", width=" << w_in;
-
-    std::vector<TensorDf4*> input_dev_4d;
-    std::vector<TensorDf4*> output_dev_4d1, output_dev_4d2;
-
-    Tensor<X86, AK_FLOAT, NCHW> thin(shape_in);
-
-    for (int i = 0; i < thin.size(); ++i) {
-        thin.mutable_data()[i] = -i + thin.size() / 2 / ch_in;
-    }
-
-    TensorDf4 tdin, tdout1, tdout2;
-    tdin.re_alloc(shape_in);
-    tdin.copy_from(thin);
-    input_dev_4d.push_back(&tdin);
-
-    // start Reshape & doInfer
-    Context<NV> ctx_dev(0, 1, 1);
-
-    Prelu<NV, AK_FLOAT> prelu_dev1;
-    Prelu<NV, AK_FLOAT> prelu_dev2;
-
-    LOG(INFO) << "shape out 4d: " << shape_out[0] << ", " << shape_out[1] << ", " << \
-              shape_out[2] << ", " << shape_out[3];
-
-    output_dev_4d1.push_back(&tdout1);
-    output_dev_4d2.push_back(&tdout2);
-    SABER_CHECK(prelu_dev1.compute_output_shape(input_dev_4d, output_dev_4d1, param));
-    SABER_CHECK(prelu_dev2.compute_output_shape(input_dev_4d, output_dev_4d2, param_shared));
-
-    LOG(INFO) << "re-alloc tensor buffer";
-    output_dev_4d1[0]->re_alloc(output_dev_4d1[0]->valid_shape());
-    output_dev_4d2[0]->re_alloc(output_dev_4d2[0]->valid_shape());
-    Shape va_sh = tdout1.valid_shape();
-    LOG(INFO) << "shape out 4d: " << va_sh[0] << ", " << va_sh[1] << ", " << \
-              va_sh[2] << ", " << va_sh[3];
-    va_sh = tdout2.valid_shape();
-    LOG(INFO) << "shape out 4d: " << va_sh[0] << ", " << va_sh[1] << ", " << \
-              va_sh[2] << ", " << va_sh[3];
-    CHECK_EQ(tdout1.valid_shape() == shape_out, true) << "compute output shape error";
-    CHECK_EQ(tdout2.valid_shape() == shape_out, true) << "compute output shape error";
-
-    LOG(INFO) << "prelu initialization";
-    SABER_CHECK(prelu_dev1.init(input_dev_4d, output_dev_4d1, param, RUNTIME, SABER_IMPL, ctx_dev));
-    SABER_CHECK(prelu_dev2.init(input_dev_4d, output_dev_4d2, param_shared, RUNTIME, SABER_IMPL,
-                                ctx_dev));
-
-    LOG(INFO) << "prelu compute";
-    SaberTimer<NV> t1;
-    t1.clear();
-    t1.start(ctx_dev);
-
-    for (int i = 0; i < test_iter; ++i) {
-        SABER_CHECK(prelu_dev1(input_dev_4d, output_dev_4d1, param, ctx_dev));
-        output_dev_4d1[0]->record_event(ctx_dev.get_compute_stream());
-        SABER_CHECK(prelu_dev2(input_dev_4d, output_dev_4d2, param_shared, ctx_dev));
-        output_dev_4d2[0]->record_event(ctx_dev.get_compute_stream());
-        output_dev_4d1[0]->sync();
-        output_dev_4d2[0]->sync();
-    }
-
-    CUDA_POST_KERNEL_CHECK;
-    t1.end(ctx_dev);
-    float ts = t1.get_average_ms();
-    LOG(INFO) << "total time: " << ts << "avg time: " << ts / test_iter;
-    print_tensor_device(*output_dev_4d1[0]);
-    print_tensor_device(*output_dev_4d2[0]);
-    cudaDeviceSynchronize();
-}
-
-TEST(TestSaberFuncPreluNV, test_func_prelu_ROI_NV) {
-
-    typedef TargetWrapper<NV> API;
-
-    typedef Tensor<NV, AK_FLOAT, NCHW> TensorDf4;
-
-    typedef TensorDf4::Dtype dtype;
-
-    int test_iter = 1000;
-
-    int w_in = 10;
-    int h_in = 4;
-    int ch_in = 2;
-    int num_in = 1;
-
-    Shape shape_in(num_in, ch_in, h_in, w_in);
-    Shape shape_in_roi{num_in, ch_in, h_in / 2, w_in / 2};
-    Shape off1{0, 0, 0, 0};
-    Shape off2{0, 0, 2, 5};
-    Shape shape_out = shape_in_roi;
-
-    Shape sh_slope{1, 1, 1, ch_in};
-    Tensor<X86, AK_FLOAT, NCHW> th_slope(sh_slope);
-    TensorDf4 tslop(sh_slope);
-
-    for (int i = 0; i < ch_in; ++i) {
-        th_slope.mutable_data()[i] = 0.1f * (i + 1);
-    }
-
-    tslop.copy_from(th_slope);
-
-    PreluParam<TensorDf4> param_shared(true, &tslop);
-    PreluParam<TensorDf4> param(false, &tslop);
-
-    LOG(INFO) << " input tensor size, num=" << num_in << ", channel=" << \
-              ch_in << ", height=" << h_in << ", width=" << w_in;
-
-    std::vector<TensorDf4*> in_4d1, in_4d2;
-    std::vector<TensorDf4*> out_4d1, out_4d2;
-
-    Tensor<X86, AK_FLOAT, NCHW> thin(shape_in);
-
-    for (int i = 0; i < thin.size(); ++i) {
-        thin.mutable_data()[i] = -i + thin.size() / 2 / ch_in;
-    }
-
-    TensorDf4 tdin, tdin_roi1, tdin_roi2, tdout, tdout_roi1, tdout_roi2;
-    tdin.re_alloc(shape_in);
-    tdout.re_alloc(shape_in);
-    tdin.copy_from(thin);
-    tdin_roi1.share_sub_buffer(tdin, shape_in_roi, off1);
-    tdin_roi2.share_sub_buffer(tdin, shape_in_roi, off2);
-    in_4d1.push_back(&tdin_roi1);
-    in_4d2.push_back(&tdin_roi2);
-    out_4d1.push_back(&tdout_roi1);
-    out_4d2.push_back(&tdout_roi2);
-
-    // start Reshape & doInfer
-    Context<NV> ctx_dev(0, 1, 1);
-
-    Prelu<NV, AK_FLOAT> prelu_dev1;
-    Prelu<NV, AK_FLOAT> prelu_dev2;
-
-    LOG(INFO) << "shape out 4d: " << shape_out[0] << ", " << shape_out[1] << ", " << \
-              shape_out[2] << ", " << shape_out[3];
-
-    prelu_dev1.compute_output_shape(in_4d1, out_4d1, param);
-    prelu_dev2.compute_output_shape(in_4d2, out_4d2, param_shared);
-
-    LOG(INFO) << "re-alloc tensor buffer";
-    out_4d1[0]->share_sub_buffer(tdout, shape_in_roi, off1);
-    out_4d2[0]->share_sub_buffer(tdout, shape_in_roi, off2);
-
-    CHECK_EQ(out_4d1[0]->valid_shape() == shape_out, true) << "compute shape error";
-
-    LOG(INFO) << "prelu initialization";
-    prelu_dev1.init(in_4d1, out_4d1, param, SPECIFY, SABER_IMPL, ctx_dev);
-    prelu_dev2.init(in_4d2, out_4d2, param_shared, SPECIFY, SABER_IMPL, ctx_dev);
-
-    LOG(INFO) << "prelu compute";
-    SaberTimer<NV> t1;
-    t1.clear();
-    t1.start(ctx_dev);
-
-    for (int i = 0; i < test_iter; ++i) {
-        prelu_dev1(in_4d1, out_4d1, param, ctx_dev);
-        out_4d1[0]->record_event(ctx_dev.get_compute_stream());
-        prelu_dev2(in_4d2, out_4d2, param_shared, ctx_dev);
-        out_4d2[0]->record_event(ctx_dev.get_compute_stream());
-        out_4d1[0]->sync();
-        out_4d2[0]->sync();
-    }
-
-    CUDA_POST_KERNEL_CHECK;
-    t1.end(ctx_dev);
-    float ts = t1.get_average_ms();
-    printf("total time : %.4f, avg time : %.4f\n", ts, ts / test_iter);
-    print_tensor_device(tdout);
-    cudaDeviceSynchronize();
-    TensorDf4 troi(out_4d1[0]->valid_shape());
-    troi.copy_from(*out_4d1[0]);
-    print_tensor_device(troi);
-    cudaDeviceSynchronize();
-    troi.copy_from(*out_4d2[0]);
-    print_tensor_device(troi);
-    CUDA_POST_KERNEL_CHECK;
-    cudaDeviceSynchronize();
-}
-
-int main(int argc, const char** argv) {
-    // initial logger
-    //logger::init(argv[0]);
-    Env<NV>::env_init();
-    InitTest();
-    RUN_ALL_TESTS(argv[0]);
-    return 0;
-}
-
diff --git a/test/saber/cuda/test_saber_func_prelu_NV.h b/test/saber/cuda/test_saber_func_prelu_NV.h
deleted file mode 100644
index 90d9733..0000000
--- a/test/saber/cuda/test_saber_func_prelu_NV.h
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-
-#ifndef ANAKIN_TEST_SABER_TEST_SABER_FUNC_PRELU_NV_H
-#define ANAKIN_TEST_SABER_TEST_SABER_FUNC_PRELU_NV_H
-
-#include "utils/unit_test/aktest.h"
-#include "utils/logger/logger.h"
-#include "core/tensor.h"
-
-using namespace anakin::test;
-
-class TestSaberFuncPreluNV : public Test {
-public:
-    TestSaberFuncPreluNV() {}
-    ~TestSaberFuncPreluNV() {}
-
-protected:
-    virtual void setup() {}
-    virtual void teardown() {}
-
-};
-
-#endif //ANAKIN_TEST_SABER_TEST_SABER_FUNC_PRELU_NV_H
diff --git a/test/saber/cuda/test_saber_func_priorbox_NV.cpp b/test/saber/cuda/test_saber_func_priorbox_NV.cpp
index 92fea44..f3404c2 100644
--- a/test/saber/cuda/test_saber_func_priorbox_NV.cpp
+++ b/test/saber/cuda/test_saber_func_priorbox_NV.cpp
@@ -52,10 +52,14 @@ TEST(TestSaberFuncNV, test_func_priorbox_NV) {
     int img_w = 0;
     int img_h = 0;
     float offset = 0.5;
+    std::vector<PriorType> order;
 
-    PriorBoxParam<TensorDf4> param(min_size, max_size, aspect_ratio, \
-                                   variance, flip, clip, img_w, img_h, step_w, step_h, offset);
+    order.push_back(PRIOR_MIN);
+    order.push_back(PRIOR_MAX);
+    order.push_back(PRIOR_COM);
 
+    PriorBoxParam<TensorDf4> param(min_size, max_size, aspect_ratio, \
+                                   variance, flip, clip, img_w, img_h, step_w, step_h, offset, order);
 
 
     std::vector<TensorDf4*> vin;
diff --git a/test/saber/cuda/test_saber_func_reshape_NV.cpp b/test/saber/cuda/test_saber_func_reshape_NV.cpp
index 8c3194e..d956e39 100644
--- a/test/saber/cuda/test_saber_func_reshape_NV.cpp
+++ b/test/saber/cuda/test_saber_func_reshape_NV.cpp
@@ -64,7 +64,7 @@ TEST(TestSaberFuncReshapeNV, test_func_reshape) {
 
     // start Reshape & doInfer
     Context<NV> ctx_dev(0, 1, 1);
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
 
     std::vector<TensorHf4*> input_host_4d;
     std::vector<TensorHf4*> output_host_4d;
@@ -113,9 +113,9 @@ TEST(TestSaberFuncReshapeNV, test_func_reshape) {
 
     // init assume output tensor has been reshpaed by user.
     LOG(INFO) << "reshape initialization";
-    SABER_CHECK(host_reshape_4d.init(input_host_4d, output_host_4d, param_host_4d, \
+    //SABER_CHECK(host_reshape_4d.init(input_host_4d, output_host_4d, param_host_4d, \
                                      RUNTIME, SABER_IMPL, ctx_host));
-    SABER_CHECK(host_reshape_2d.init(input_host_4d, output_host_2d, param_host_2d, \
+    //SABER_CHECK(host_reshape_2d.init(input_host_4d, output_host_2d, param_host_2d, \
                                      RUNTIME, SABER_IMPL, ctx_host));
     SABER_CHECK(dev_reshape_4d.init(input_dev_4d, output_dev_4d, param_dev_4d, \
                                     RUNTIME, SABER_IMPL, ctx_dev));
@@ -123,8 +123,8 @@ TEST(TestSaberFuncReshapeNV, test_func_reshape) {
                                     RUNTIME, SABER_IMPL, ctx_dev));
 
     LOG(INFO) << "reshape compute";
-    host_reshape_4d(input_host_4d, output_host_4d, param_host_4d, ctx_host);
-    host_reshape_2d(input_host_4d, output_host_2d, param_host_2d, ctx_host);
+    //host_reshape_4d(input_host_4d, output_host_4d, param_host_4d, ctx_host);
+    //host_reshape_2d(input_host_4d, output_host_2d, param_host_2d, ctx_host);
     dev_reshape_4d(input_dev_4d, output_dev_4d, param_dev_4d, ctx_dev);
     dev_reshape_2d(input_dev_4d, output_dev_2d, param_dev_2d, ctx_dev);
     print_tensor_host(*output_host_4d[0]);
diff --git a/test/saber/cuda/test_saber_func_reshape_NV.h b/test/saber/cuda/test_saber_func_reshape_NV.h
index 9fd8c3b..1e6090b 100644
--- a/test/saber/cuda/test_saber_func_reshape_NV.h
+++ b/test/saber/cuda/test_saber_func_reshape_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_resize_NV.cpp b/test/saber/cuda/test_saber_func_resize_NV.cpp
index 51c3cd5..55ea4ab 100644
--- a/test/saber/cuda/test_saber_func_resize_NV.cpp
+++ b/test/saber/cuda/test_saber_func_resize_NV.cpp
@@ -61,7 +61,7 @@ TEST(TestSaberFuncResizeNV, test_func_resize_NCHW) {
 
     // start Reshape & doInfer
     Context<NV> ctx_dev(0, 1, 1);
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
 
     std::vector<TensorDf4*> input_dev_4d;
     std::vector<TensorDf4*> output_dev_4d;
@@ -153,7 +153,7 @@ TEST(TestSaberFuncResizeNV, test_func_resize_NCHW_INT8) {
 
     // start Reshape & doInfer
     Context<NV> ctx_dev(0, 1, 1);
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
 
     std::vector<TensorDc4*> input_dev_4d;
     std::vector<TensorDc4*> output_dev_4d;
@@ -240,7 +240,7 @@ TEST(TestSaberFuncResizeNV, test_func_resize_HW) {
 
     // start Reshape & doInfer
     Context<NV> ctx_dev(0, 1, 1);
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
 
     std::vector<TensorDf2*> input_dev_2d;
     std::vector<TensorDf2*> output_dev_2d;
@@ -291,7 +291,7 @@ TEST(TestSaberFuncResizeNV, test_resize_image_NHWC) {
     typedef Tensor<X86, AK_FLOAT, NHWC> TensorHf4;
     typedef Tensor<NV, AK_FLOAT, NHWC> TensorDf4;
 
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
     Context<NV> ctx_dev;
 
     typedef TensorDf4::Dtype dtype;
@@ -333,7 +333,7 @@ TEST(TestSaberFuncResizeNV, test_resize_image_NHWC) {
 
     Mat im_r;
     SaberTimer<X86> t1;
-    t1.start(ctx_host);
+    //t1.start(ctx_host);
 
     //auto ts1 = std::chrono::system_clock::now();
     //double tcv = getTickCount();
@@ -341,7 +341,7 @@ TEST(TestSaberFuncResizeNV, test_resize_image_NHWC) {
         resize(imf, im_r, Size(0, 0), scale_w, scale_h, INTER_LINEAR);
     }
 
-    t1.end(ctx_host);
+    //t1.end(ctx_host);
     //auto ts2 = std::chrono::system_clock::now();
     //tcv = getTickCount() - tcv;
     //tcv = tcv / getTickFrequency();
@@ -411,7 +411,7 @@ TEST(TestSaberFuncResizeNV, test_resize_image_NHWC_WITH_ROI) {
     typedef Tensor<X86, AK_FLOAT, NHWC> TensorHf4;
     typedef Tensor<NV, AK_FLOAT, NHWC> TensorDf4;
 
-    Context<X86> ctx_host;
+    //Context<X86> ctx_host;
     Context<NV> ctx_dev;
 
     typedef TensorDf4::Dtype dtype;
diff --git a/test/saber/cuda/test_saber_func_resize_NV.h b/test/saber/cuda/test_saber_func_resize_NV.h
index 4aec7cb..623464d 100644
--- a/test/saber/cuda/test_saber_func_resize_NV.h
+++ b/test/saber/cuda/test_saber_func_resize_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_slice_NV.h b/test/saber/cuda/test_saber_func_slice_NV.h
index 7f1c274..054ebda 100644
--- a/test/saber/cuda/test_saber_func_slice_NV.h
+++ b/test/saber/cuda/test_saber_func_slice_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_func_softmax_NV.h b/test/saber/cuda/test_saber_func_softmax_NV.h
index dbe41ef..d3cb268 100644
--- a/test/saber/cuda/test_saber_func_softmax_NV.h
+++ b/test/saber/cuda/test_saber_func_softmax_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_shape.h b/test/saber/cuda/test_saber_shape.h
index 255c624..36fbee0 100644
--- a/test/saber/cuda/test_saber_shape.h
+++ b/test/saber/cuda/test_saber_shape.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/cuda/test_saber_tensor_NV.h b/test/saber/cuda/test_saber_tensor_NV.h
index 19e0876..df42b2f 100644
--- a/test/saber/cuda/test_saber_tensor_NV.h
+++ b/test/saber/cuda/test_saber_tensor_NV.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/x86/test_saber_func_activation_x86.cpp b/test/saber/x86/test_saber_func_activation_x86.cpp
index 8fbf7e4..cb75212 100644
--- a/test/saber/x86/test_saber_func_activation_x86.cpp
+++ b/test/saber/x86/test_saber_func_activation_x86.cpp
@@ -61,18 +61,348 @@ void test(int n, int c, int h, int w) {
     }
 }
 
+void test_stanh(int n, int c, int h, int w){
+    int n_in = n;
+    int c_in = c;
+    int h_in = h;
+    int w_in = w;
+    float scale_a = 2.0f / 3.0f;
+    float scale_b = 1.7159f;
+
+    Shape shape_in(n_in, c_in, h_in, w_in);
+    Shape shape_out(n_in, c_in, h_in, w_in);
+
+    Tensor4f src, dst, dst_host;
+    src.re_alloc(shape_in);
+
+    float *src_ptr = src.mutable_data();
+    for (int i = 0; i<src.valid_size(); i++) {
+        src_ptr[i] = 0.12345f + (float)i*1e-4;
+    }
+
+    dst_host.re_alloc(shape_in);
+    float *dst_host_ptr = dst_host.mutable_data();
+    for (int i = 0; i< dst_host.valid_size(); i++) {
+        dst_host_ptr[i] = 0.12345f + (float)i*1e-4;
+        dst_host_ptr[i] = scale_b * tanh(scale_a * dst_host_ptr[i]);
+    }
+
+
+    Context<X86> ctx_host;
+
+    std::vector<Tensor4f*> input_stanh;
+    std::vector<Tensor4f*> output_stanh;
+
+    input_stanh.push_back(&src);
+
+    dst.re_alloc(shape_out);
+    output_stanh.push_back(&dst);
+
+    ActivationParam<Tensor4f> param_host(Active_stanh, scale_a, scale_b);
+
+    Activation<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> op_stanh;
+
+    op_stanh.init(input_stanh, output_stanh, param_host, SPECIFY, SABER_IMPL, ctx_host);
+
+    op_stanh(input_stanh, output_stanh, param_host, ctx_host);
+
+    const float *dst_ptr = dst.data();
+    std::cout<< std::endl;
+    std::cout<< "This tensor size is:" << dst.size()<< std::endl;
+    for (int i = 0; i < dst.size(); i++) {
+        if(i%5==0 && i)
+            std::cout << std::endl;
+        std::cout << dst_ptr[i] <<"  ";
+
+    }
+
+    bool pass = compare_tensor<Tensor4f>(dst_host, dst, 1e-6);
+    if (pass) {
+        LOG(INFO) << "Test Passed";
+    }
+    else {
+        LOG(ERROR) << "Test Failed";
+    }
+}
+
+void test_sigmoid(int n, int c, int h, int w){
+    int n_in = n;
+    int c_in = c;
+    int h_in = h;
+    int w_in = w;
+
+    Shape shape_in(n_in, c_in, h_in, w_in);
+    Shape shape_out(n_in, c_in, h_in, w_in);
+
+    Tensor4f src, dst, dst_host;
+    src.re_alloc(shape_in);
+    fill_tensor_host_rand(src);
+
+    dst_host.re_alloc(shape_in);
+    float *dst_host_ptr = dst_host.mutable_data();
+    float *src_ptr = src.mutable_data();
+    for (int i = 0; i< dst_host.valid_size(); i++) {
+        dst_host_ptr[i] = 1.0f / (exp(-src_ptr[i]) + 1.0f);
+    }
+
+
+    Context<X86> ctx_host;
+
+    std::vector<Tensor4f*> input;
+    std::vector<Tensor4f*> output;
+
+    input.push_back(&src);
+
+    dst.re_alloc(shape_out);
+    output.push_back(&dst);
+
+    ActivationParam<Tensor4f> param_host(Active_sigmoid);
+
+    Activation<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> op_stanh;
+
+    op_stanh.init(input, output, param_host, SPECIFY, SABER_IMPL, ctx_host);
+
+    op_stanh(input, output, param_host, ctx_host);
+
+    bool pass = compare_tensor<Tensor4f>(dst_host, dst, 1e-6);
+    if (pass) {
+        LOG(INFO) << "Test Passed";
+    }
+    else {
+        LOG(ERROR) << "Test Failed";
+    }
+}
+
+void test_tanh(int n, int c, int h, int w){
+    int n_in = n;
+    int c_in = c;
+    int h_in = h;
+    int w_in = w;
+
+    Shape shape_in(n_in, c_in, h_in, w_in);
+    Shape shape_out(n_in, c_in, h_in, w_in);
+
+    Tensor4f src, dst, dst_host;
+    src.re_alloc(shape_in);
+    fill_tensor_host_rand(src);
+
+    dst_host.re_alloc(shape_in);
+    float *dst_host_ptr = dst_host.mutable_data();
+    float *src_ptr = src.mutable_data();
+    for (int i = 0; i< dst_host.valid_size(); i++) {
+        dst_host_ptr[i] = tanh(src_ptr[i]);
+    }
+
+
+    Context<X86> ctx_host;
+
+    std::vector<Tensor4f*> input;
+    std::vector<Tensor4f*> output;
+
+    input.push_back(&src);
+
+    dst.re_alloc(shape_out);
+    output.push_back(&dst);
+
+    ActivationParam<Tensor4f> param_host(Active_tanh);
+
+    Activation<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> op_tanh;
+
+    op_tanh.init(input, output, param_host, SPECIFY, SABER_IMPL, ctx_host);
+
+    op_tanh(input, output, param_host, ctx_host);
+
+    bool pass = compare_tensor<Tensor4f>(dst_host, dst, 1e-6);
+    if (pass) {
+        LOG(INFO) << "Test Passed";
+    }
+    else {
+        LOG(ERROR) << "Test Failed";
+    }
+}
+
+void test_clipped_relu(int n, int c, int h, int w){
+    int n_in = n;
+    int c_in = c;
+    int h_in = h;
+    int w_in = w;
+
+    float threshold = 0.85f;
+
+    Shape shape_in(n_in, c_in, h_in, w_in);
+    Shape shape_out(n_in, c_in, h_in, w_in);
+
+    Tensor4f src, dst, dst_host;
+    src.re_alloc(shape_in);
+    fill_tensor_host_rand(src);
+
+    dst_host.re_alloc(shape_in);
+    float *dst_host_ptr = dst_host.mutable_data();
+    float *src_ptr = src.mutable_data();
+    for (int i = 0; i< dst_host.valid_size(); i++) {
+        src_ptr[i] = src_ptr[i] > 0 ? src_ptr[i] : 0;
+        dst_host_ptr[i] = src_ptr[i] < threshold ? src_ptr[i] : threshold;
+    }
+
+
+    Context<X86> ctx_host;
+
+    std::vector<Tensor4f*> input;
+    std::vector<Tensor4f*> output;
+
+    input.push_back(&src);
+
+    dst.re_alloc(shape_out);
+    output.push_back(&dst);
+
+    ActivationParam<Tensor4f> param_host(Active_clipped_relu);
+    param_host.coef = threshold;
+
+    Activation<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> op_clipped_relu;
+
+    op_clipped_relu.init(input, output, param_host, SPECIFY, SABER_IMPL, ctx_host);
+
+    op_clipped_relu(input, output, param_host, ctx_host);
+
+    bool pass = compare_tensor<Tensor4f>(dst_host, dst, 1e-6);
+    if (pass) {
+        LOG(INFO) << "Test Passed";
+    }
+    else {
+        LOG(ERROR) << "Test Failed";
+    }
+}
+
+void test_elu(int n, int c, int h, int w){
+    int n_in = n;
+    int c_in = c;
+    int h_in = h;
+    int w_in = w;
+
+    float coef = 0.37f;
+
+    Shape shape_in(n_in, c_in, h_in, w_in);
+    Shape shape_out(n_in, c_in, h_in, w_in);
+
+    Tensor4f src, dst, dst_host;
+    src.re_alloc(shape_in);
+    fill_tensor_host_rand(src);
+
+    dst_host.re_alloc(shape_in);
+    float *dst_host_ptr = dst_host.mutable_data();
+    float *src_ptr = src.mutable_data();
+    for (int i = 0; i< dst_host.valid_size(); i++) {
+        dst_host_ptr[i] = src_ptr[i] > 0 ? src_ptr[i] : coef * (exp(src_ptr[i]) - 1);
+    }
+
+
+    Context<X86> ctx_host;
+
+    std::vector<Tensor4f*> input;
+    std::vector<Tensor4f*> output;
+
+    input.push_back(&src);
+
+    dst.re_alloc(shape_out);
+    output.push_back(&dst);
+
+    ActivationParam<Tensor4f> param_host(Active_elu);
+    param_host.coef = coef;
+
+    Activation<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> op_elu;
+
+    op_elu.init(input, output, param_host, SPECIFY, SABER_IMPL, ctx_host);
+
+    op_elu(input, output, param_host, ctx_host);
+
+    bool pass = compare_tensor<Tensor4f>(dst_host, dst, 1e-6);
+    if (pass) {
+        LOG(INFO) << "Test Passed";
+    }
+    else {
+        LOG(ERROR) << "Test Failed";
+    }
+}
 
 TEST(TestSaberActivationX86, test_tensor_activation) {
     Env<X86>::env_init();
 
-    LOG(INFO) << "case 1:"; 
+    LOG(INFO) << "case 1:";
     test(1, 1, 1, 1024);
-    LOG(INFO) << "case 2:"; 
+    LOG(INFO) << "case 2:";
     test(1, 1, 1024, 1024);
-    LOG(INFO) << "case 3:"; 
+    LOG(INFO) << "case 3:";
     test(2, 2, 32, 32);
-    LOG(INFO) << "case 4:"; 
+    LOG(INFO) << "case 4:";
     test(2, 32, 512, 512);
+
+    LOG(INFO) << "test for stanh:";
+
+    std::cout << "case 1:" << std::endl;
+    test_stanh(1, 1, 1, 4);
+    std::cout << "case 2:" << std::endl;
+    test_stanh(1, 1, 20, 2);
+    std::cout << "case 3:" << std::endl;
+    test_stanh(2, 2, 32, 1);
+    std::cout << "case 4:" << std::endl;
+    test_stanh(2, 32, 2, 2);
+
+}
+
+TEST(TestSaberActivationX86, test_activation_sigmoid) {
+    Env<X86>::env_init();
+
+    LOG(INFO) << "case 1:";
+    test_sigmoid(1, 1, 1, 1024);
+    LOG(INFO) << "case 2:";
+    test_sigmoid(1, 1, 1024, 1024);
+    LOG(INFO) << "case 3:";
+    test_sigmoid(2, 2, 32, 32);
+    LOG(INFO) << "case 4:";
+    test_sigmoid(2, 32, 512, 512);
+
+}
+
+TEST(TestSaberActivationX86, test_activation_tanh) {
+    Env<X86>::env_init();
+
+    LOG(INFO) << "case 1:";
+    test_tanh(1, 1, 1, 1024);
+    LOG(INFO) << "case 2:";
+    test_tanh(1, 1, 1024, 1024);
+    LOG(INFO) << "case 3:";
+    test_tanh(2, 2, 32, 32);
+    LOG(INFO) << "case 4:";
+    test_tanh(2, 32, 512, 512);
+
+}
+
+TEST(TestSaberActivationX86, test_activation_clipped_relu) {
+    Env<X86>::env_init();
+
+    LOG(INFO) << "case 1:";
+    test_clipped_relu(1, 1, 1, 1024);
+    LOG(INFO) << "case 2:";
+    test_clipped_relu(1, 1, 1024, 1024);
+    LOG(INFO) << "case 3:";
+    test_clipped_relu(2, 2, 32, 32);
+    LOG(INFO) << "case 4:";
+    test_clipped_relu(2, 32, 512, 512);
+
+}
+
+TEST(TestSaberActivationX86, test_activation_elu) {
+    Env<X86>::env_init();
+
+    LOG(INFO) << "case 1:";
+    test_elu(1, 1, 1, 1024);
+    LOG(INFO) << "case 2:";
+    test_elu(1, 1, 1024, 1024);
+    LOG(INFO) << "case 3:";
+    test_elu(2, 2, 32, 32);
+    LOG(INFO) << "case 4:";
+    test_elu(2, 32, 512, 512);
+
 }
 
 int main(int argc, const char** argv) {
@@ -81,4 +411,3 @@ int main(int argc, const char** argv) {
     RUN_ALL_TESTS(argv[0]);
     return 0;
 }
-
diff --git a/test/saber/x86/test_saber_func_fc_x86.cpp b/test/saber/x86/test_saber_func_fc_x86.cpp
index c872d47..18c29e2 100644
--- a/test/saber/x86/test_saber_func_fc_x86.cpp
+++ b/test/saber/x86/test_saber_func_fc_x86.cpp
@@ -103,8 +103,11 @@ bool inner_product_test(inprod_test_params& p) {
     // get saber result
     Context<X86> ctx_host;
     saberFc.init(input_host_4d, output_host_4d, param_host_4d, SPECIFY, VENDER_IMPL, ctx_host);
+    SaberTimer<X86> timer;
+    timer.start(ctx_host);
     saberFc(input_host_4d, output_host_4d, param_host_4d, ctx_host);
-
+    timer.end(ctx_host);
+    LOG(INFO)<<" time: "<< timer.get_average_ms()<<" ms";
     bool ret = false;
     ret = compare_tensor<Tensor4f>(saberOutput, refOutput);
     return ret;
diff --git a/test/saber/x86/test_saber_func_lstm_x86.cpp b/test/saber/x86/test_saber_func_lstm_x86.cpp
new file mode 100644
index 0000000..7fe0e7e
--- /dev/null
+++ b/test/saber/x86/test_saber_func_lstm_x86.cpp
@@ -0,0 +1,368 @@
+#include <time.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <vector>
+
+#include "mkl_cblas.h"
+#include "mkl_vml_functions.h"
+
+#include "saber/core/context.h"
+#include "saber/funcs/lstm.h"
+#include "saber/funcs/impl/x86/x86_utils.h"
+#include "saber/core/tensor_op.h"
+#include "saber/saber_types.h"
+#include "x86_test_common.h"
+#include "test_saber_func_x86.h"
+
+using namespace anakin::saber;
+using namespace std;
+
+typedef struct _test_lstm_params {
+    int mb;
+    int input_size;
+    int layer_size;
+    ActiveType input_activation;
+    ActiveType gate_activation;
+    ActiveType candidate_activation;
+    ActiveType cell_activation;
+    bool with_peephole;
+    bool with_init_hidden;
+    bool skip_input;
+} test_lstm_params;
+
+typedef Tensor<X86, AK_FLOAT, NCHW> Tensor4f;
+
+inline void sigmoid(int len, float *x, float *y) {
+    for (int i = 0; i < len; i++) {
+        y[i] = 1. / (1. + exp(-x[i]));
+    }
+}
+
+inline void relu(int len, float *x, float *y) {
+    for (int i = 0; i < len; i++) {
+        y[i] = x[i] < 0 ? 0 : x[i];
+    }
+}
+
+inline void tanh(int len, float *x, float *y) {
+    for (int i = 0; i < len; i++) {
+        float e_x = exp(x[i]);
+        float e_minus_x = 1 / e_x;
+        y[i] = (e_x - e_minus_x) / (e_x + e_minus_x);
+    }
+}
+
+inline void stanh(int len, float *x, float *y) {
+    for (int i = 0; i < len; i++) {
+        float e_x = exp(2 * x[i] / 3);
+        float e_minus_x = 1 / e_x;
+        y[i] = 1.7159 * (e_x - e_minus_x) / (e_x + e_minus_x);
+    }
+}
+
+void compute_ref_lstm_fwd(std::vector<Tensor4f*> &src, std::vector<Tensor4f*> &dst, LstmParam<Tensor4f> &param) {
+    SaberStatus status = SaberSuccess;
+
+    const Tensor4f *weights = param.weight();
+    const Tensor4f *bias = param.bias();
+    const Tensor4f *init_hidden = param.init_hidden();
+
+    Tensor4f *input = src[0];
+    float *h = dst[0]->mutable_data();
+    float *c = nullptr;
+
+    // get Wx = [Wix, Wfx, Wcx, Woc] while they are all input_size * layer_size matrices
+    const float *x = input->data();
+    int N = input->num();
+    int input_size = input->channel();
+    int layer_size = dst[0]->channel();
+
+    if (dst.size() >= 2) {
+        c = dst[1]->mutable_data();
+    } else {
+        c = (float*)zmalloc(N * layer_size * sizeof(float), 4096);
+    }
+
+    float *xx = nullptr;
+    if (param.skip_input) {
+        // the input is x * Wx
+        xx = const_cast<float *>(x);
+    } else {
+        // get xx = x * Wx
+        const float *Wx = weights->data();
+        xx = (float*)zmalloc(N * 4 * layer_size * sizeof(float), 4096);
+        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, N, 4 * layer_size, input_size, 1, x, input_size, Wx, 4 * layer_size, 0, xx, 4 * layer_size);
+        if (param.input_activity != Active_unknow) {
+            if (param.input_activity == Active_stanh) {
+                stanh(N * 4 * layer_size, xx, xx);
+            } else if (param.input_activity == Active_tanh) {
+                tanh(N * 4 * layer_size, xx, xx);
+            } else {
+                LOG(ERROR) << "unsupported gate activation now";
+            }
+        }
+    }
+
+    float* ihcot = (float*)zmalloc(4 * layer_size * sizeof(float), 4096);
+    float* act = (float*)zmalloc(layer_size * sizeof(float), 4096);
+    float* p = (float*)zmalloc(layer_size * sizeof(float), 4096);
+
+    std::vector<int> seq_offset = input->get_seq_offset();
+    int seq_num = seq_offset.size() - 1;
+
+    const float *Wh = nullptr;
+    if (param.skip_input) {
+        Wh = weights->data();
+    } else {
+        Wh = weights->data() + 4 * input_size * layer_size;
+    }
+    const float *b = bias->data();
+    const float *peephole = nullptr;
+    if (param.with_peephole) {
+        peephole = bias->data() + 4 * layer_size;
+    }
+
+    float* init_h = (float*)zmalloc(layer_size * sizeof(float), 4096);
+    float* init_c = (float*)zmalloc(layer_size * sizeof(float), 4096);
+    memset(init_h, 0, layer_size * sizeof(float));
+    memset(init_c, 0, layer_size * sizeof(float));
+
+    for (int i = 0; i < seq_num; i++) {
+        if (param.init_hidden()) {
+            const float *init_state = param.init_hidden()->data();
+            memcpy(init_h, init_state + i * layer_size, layer_size * sizeof(float));
+            memcpy(init_c, init_state + (i + seq_num)* layer_size, layer_size * sizeof(float));
+        }
+        // do LSTM per sequence
+        int seq_len = seq_offset[i + 1] - seq_offset[i];
+        for (int j = 0; j < seq_len; j++) {
+            float *ht = h + (seq_offset[i] + j) * layer_size;
+            float *ct = c + (seq_offset[i] + j) * layer_size;
+            float *xxt = xx + (seq_offset[i] + j) * 4 * layer_size;
+            float *ht_1 = nullptr;
+            float *ct_1 = nullptr;
+            cblas_saxpby (4 * layer_size, 1, xxt, 1, 0, ihcot, 1);
+
+            if (j == 0) {
+                ht_1 = init_h;
+                ct_1 = init_c;
+            } else {
+                ht_1 = h + (seq_offset[i] + (j - 1)) * layer_size;
+                ct_1 = c + (seq_offset[i] + (j - 1)) * layer_size;
+            }
+
+            cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 1, 4 * layer_size, layer_size, 1, ht_1, layer_size, Wh,
+                        4 * layer_size, 1, ihcot, 4 * layer_size);
+
+            if (peephole) {
+                // peephole for it
+                vsMul(layer_size, ct_1, peephole, p);
+                cblas_saxpby(layer_size, 1, p, 1, 1, ihcot, 1);
+                // peephole for ft
+                vsMul(layer_size, ct_1, peephole + layer_size, p);
+                cblas_saxpby(layer_size, 1, p, 1, 1, ihcot + layer_size, 1);
+            }
+            // add bias
+            cblas_saxpby(4 * layer_size, 1, b, 1, 1, ihcot, 1);
+
+            // gate activity for it and ft, candidate activity for cct
+            if (param.gate_activity == Active_sigmoid) {
+                sigmoid(layer_size, ihcot, ihcot);
+                sigmoid(layer_size, ihcot + layer_size, ihcot + layer_size);
+            } else {
+                LOG(ERROR) << "unsupported gate activation now";
+            }
+
+            if (param.candidate_activity == Active_relu) {
+                relu(layer_size, ihcot + 2 * layer_size, ihcot + 2 * layer_size);
+            } else {
+                LOG(ERROR) << "unsupported candidate activation now";
+            }
+
+            // calc ct
+            vsMul(layer_size, ihcot, ihcot + 2 * layer_size, p);
+            cblas_saxpby(layer_size, 1, p, 1, 0, ct, 1);
+            vsMul(layer_size, ihcot + layer_size, ct_1, p);
+            cblas_saxpby(layer_size, 1, p, 1, 1, ct, 1);
+
+            // peephole for ot
+            if (peephole) {
+                vsMul(layer_size, ct, peephole + 2 * layer_size, p);
+                cblas_saxpby(layer_size, 1, p, 1, 1, ihcot + 3 * layer_size, 1);
+            }
+            if (param.gate_activity == Active_sigmoid) {
+                sigmoid(layer_size, ihcot + 3 * layer_size, ihcot + 3 * layer_size);
+            }
+
+            // calc ht
+            if (param.cell_activity == Active_sigmoid) {
+                sigmoid(layer_size, ct, act);
+            }
+            vsMul(layer_size, ihcot + 3 * layer_size, act, ht);
+        }
+    }
+
+    if (!param.skip_input && xx) {
+        zfree(xx);
+        xx = nullptr;
+    }
+    if (ihcot) {
+        zfree(ihcot);
+        ihcot = nullptr;
+    }
+    if (act) {
+        zfree(act);
+        act = nullptr;
+    }
+    if (p) {
+        zfree(p);
+        p = nullptr;
+    }
+    if (init_h) {
+        zfree(init_h);
+        init_h = nullptr;
+    }
+    if (init_c) {
+        zfree(init_c);
+        init_c = nullptr;
+    }
+    if (dst.size() < 2 && c != nullptr) {
+        zfree(c);
+        c = nullptr;
+    }
+
+    return;
+}
+
+bool lstm_test(test_lstm_params &param) {
+    std::vector<Tensor4f*> inputs;
+
+    std::vector<int> seq_offsets;
+    int total_seq_len = 0;
+    int offset = 0;
+    for (int i = 0; i < param.mb; i++) {
+        int seq_len = rand()%50 + 50;
+        total_seq_len += seq_len;
+        seq_offsets.push_back(offset);
+        offset += seq_len;
+    }
+    seq_offsets.push_back(offset);
+
+    Shape inputShape(total_seq_len, param.input_size, 1, 1);
+    if (param.skip_input) {
+        inputShape[1] = 4 * param.layer_size;
+    }
+    Tensor4f *i = new Tensor4f(inputShape);
+    i->set_seq_offset(seq_offsets);
+    inputs.push_back(i);
+    fill_tensor_host_rand<Tensor4f>(*(inputs[0]));
+
+    // weight's layout:
+    // [ Wih Wfh Wch Woh ]
+    Shape weightShape(param.layer_size, 4 * param.layer_size, 1, 1);
+    if (!param.skip_input) {
+        // weight's layout:
+        // [ Wix Wfx Wcx Wox ]
+        // [ Wih Wfh Wch Woh ]
+        // It's a (input_size + layer_size) * (4 * layer_size) matrix
+        weightShape[0] = param.input_size + param.layer_size;
+    }
+    Tensor4f saberWeight(weightShape);
+    fill_tensor_host_rand(saberWeight);
+
+    // bias's layout:
+    // while with peephole: [bi, bf, bc, bo, wic, wfc, woc]
+    // while not: [bi, bf, bc, bo]
+    // It's a 1 * (7 * layer_size or 4 * layer_size) vector
+    int bias_num = 4;
+    if (param.with_peephole) {
+        bias_num = 7;
+    }
+    Shape biasShape(1, bias_num * param.layer_size, 1, 1);
+    Tensor4f saberBias(biasShape);
+    fill_tensor_host_rand(saberBias);
+
+    Shape hiddenShape(param.mb * 2, param.layer_size, 1, 1);
+    Tensor4f saberHidden(hiddenShape);
+    fill_tensor_host_rand(saberHidden);
+
+    LstmParam<Tensor4f> lstm_param(&saberWeight, &saberBias, param.with_init_hidden ? &saberHidden : nullptr,
+                                   param.input_activation, param.gate_activation, param.cell_activation,
+                                   param.candidate_activation, param.with_peephole, param.skip_input);
+
+    Shape outputShape(total_seq_len, param.layer_size, 1, 1);
+    std::vector<Tensor4f*> saber_outputs;
+    Tensor4f saberOutputh(outputShape);
+    Tensor4f saberOutputc(outputShape);
+    saber_outputs.push_back(&saberOutputh);
+    saber_outputs.push_back(&saberOutputc);
+
+    std::vector<Tensor4f*> ref_outputs;
+    Tensor4f refOutputh(outputShape);
+    Tensor4f refOutputc(outputShape);
+    ref_outputs.push_back(&refOutputh);
+    ref_outputs.push_back(&refOutputc);
+
+    // compute reference result
+    compute_ref_lstm_fwd(inputs, ref_outputs, lstm_param);
+
+    // compute saber result
+    Lstm<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> saberLstm;
+    Context<X86> ctx_host;
+    saberLstm.init(inputs, saber_outputs, lstm_param, SPECIFY, SABER_IMPL, ctx_host);
+    saberLstm(inputs, saber_outputs, lstm_param, ctx_host);
+
+    bool flag = compare_tensor(*saber_outputs[0], *ref_outputs[0], 1e-4);
+    flag &= compare_tensor(*saber_outputs[1], *ref_outputs[1], 1e-4);
+    return flag;
+}
+
+TEST(TestSaberFuncX86, test_tensor_lstm) {
+    Env<X86>::env_init();
+
+    test_lstm_params test_param[] = {
+        // batch_size, input_size, layer_size, input_activation, gate_activation, candidate_activation, cell_activation, with_peephole, with_init_hidden, skip_input
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, false, false, false},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, true, false, false},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, false, true, false},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, true, true, false},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, false, false, false},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, true, false, false},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, true, true, false},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, false, true, false},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, false, false, false},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, true, false, false},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, false, true, false},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, true, true, false},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, false, false, true},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, true, false, true},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, false, true, true},
+        test_lstm_params{6, 55, 300, Active_unknow, Active_sigmoid, Active_relu, Active_sigmoid, true, true, true},
+        /*test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, false, false, true},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, true, false, true},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, true, true, true},
+        test_lstm_params{6, 55, 300, Active_tanh, Active_sigmoid, Active_relu, Active_sigmoid, false, true, true},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, false, false, true},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, true, false, true},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, false, true, true},
+        test_lstm_params{6, 55, 300, Active_stanh, Active_sigmoid, Active_relu, Active_sigmoid, true, true, true},*/
+    };
+
+    for (size_t i = 0; i < ARRAY_SIZE(test_param); i++) {
+        LOG(INFO) << "case " << i;
+        bool ret = lstm_test(test_param[i]);
+        if (ret) {
+            LOG(INFO) << "Test Passed";
+        }
+        else {
+            LOG(ERROR) << "Test Failed";
+        }
+    }
+}
+
+int main(int argc, const char** argv) {
+    logger::init(argv[0]);
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
diff --git a/test/saber/x86/test_saber_func_lstm_x86.h b/test/saber/x86/test_saber_func_lstm_x86.h
new file mode 100644
index 0000000..a8bde8f
--- /dev/null
+++ b/test/saber/x86/test_saber_func_lstm_x86.h
@@ -0,0 +1,33 @@
+/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+   http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. */
+
+#ifndef ANAKIN_TEST_SABER_TEST_SABER_LSTM_X86_H
+#define ANAKIN_TEST_SABER_TEST_SABER_LSTM_X86_H
+#include "utils/unit_test/aktest.h"
+#include "utils/logger/logger.h"
+#include "core/tensor.h"
+
+using namespace anakin::test;
+
+class TestSaberLSTMX86 : public Test {
+public:
+    TestSaberLSTMX86() {}
+    ~TestSaberLSTMX86() {}
+
+protected:
+    virtual void setup() {}
+    virtual void teardown() {}
+};
+
+#endif // ANAKIN_TEST_SABER_TEST_SABER_LSTM_X86_H
diff --git a/test/saber/x86/test_saber_func_x86.h b/test/saber/x86/test_saber_func_x86.h
index 0b243f8..82f49ea 100644
--- a/test/saber/x86/test_saber_func_x86.h
+++ b/test/saber/x86/test_saber_func_x86.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/test/saber/x86/test_saber_func_x86_gru.cpp b/test/saber/x86/test_saber_func_x86_gru.cpp
index 2d01ae3..75c0ae5 100644
--- a/test/saber/x86/test_saber_func_x86_gru.cpp
+++ b/test/saber/x86/test_saber_func_x86_gru.cpp
@@ -8,9 +8,12 @@
 #include "saber/funcs/timer.h"
 #include "stdio.h"
 #include "x86_test_common.h"
-#include "test_saber_func_x86_gru.h"
+#include "test_saber_func_x86.h"
 #include "saber/funcs/impl/x86/saber_gru.h"
 
+#include <mkl_service.h>
+#include "omp.h"
+
 //#include "cublas.h"
 
 using namespace anakin::saber;
@@ -28,7 +31,7 @@ LOG(INFO)<<"("<<tensor[0]<<","<<tensor[1]<<","<<tensor[2]<<","<<tensor[3]<<")";\
 
 typedef Tensor<X86, AK_FLOAT, NCHW> TensorDf4;
 typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
-
+#ifdef INNER_TEST
 void compute_compare_correct(TensorDf4 dev_x,TensorDf4 last_dev_out,GruParam<TensorDf4> param){
     Context<X86> ctx_dev(0, 1, 1);
     std::vector<TensorDf4*> input_dev_4d;
@@ -68,14 +71,19 @@ void compute_compare_correct(TensorDf4 dev_x,TensorDf4 last_dev_out,GruParam<Ten
     }
 
 }
-void test_saber_gru_x86(int sequence_size = 2, int batch_size = 1, int word_size = 222,
-                    int hidden_size = 333) {
+#endif
+void test_saber_gru_x86(int sequence_size = 2, int batch_size = 1, int word_size = 52,
+                    int hidden_size = 36) {
 
 
+      omp_set_dynamic(0);
+    omp_set_num_threads(1);
+    mkl_set_num_threads(1);
     Context<X86> ctx_dev(0, 1, 1);
-    std::vector<int> offsets = {0,20,40,50};
-
-    bool is_reverse = true;
+    std::vector<int> offsets = {0,39};
+    ImplEnum test_mode=SABER_IMPL;
+//    ImplEnum test_mode=VENDER_IMPL;
+    bool is_reverse = false;
     batch_size = offsets.size() - 1;
     Shape shape_ux(1, 1, offsets[offsets.size() - 1], hidden_size * 3);
     Shape shape_x(offsets[offsets.size() - 1], word_size, 1, 1);
@@ -150,7 +158,7 @@ void test_saber_gru_x86(int sequence_size = 2, int batch_size = 1, int word_size
 
 
     dev_x.set_seq_offset(offsets);
-    GruParam<TensorDf4> param(&dev_wu, &dev_b, GRU_ORIGIN,Active_sigmoid_fluid,Active_tanh_fluid,is_reverse);
+    GruParam<TensorDf4> param(&dev_wu, &dev_b, GRU_ORIGIN,Active_sigmoid,Active_tanh,is_reverse);
 
 
     Gru<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> dev_gru;
@@ -163,13 +171,13 @@ void test_saber_gru_x86(int sequence_size = 2, int batch_size = 1, int word_size
                       << dev_out.valid_shape().data()[3];
 
     output_dev_4d[0]->re_alloc(output_dev_4d[0]->valid_shape());
-    SABER_CHECK(dev_gru.init(input_dev_4d, output_dev_4d, param, SPECIFY, SABER_IMPL, ctx_dev));
+    SABER_CHECK(dev_gru.init(input_dev_4d, output_dev_4d, param, SPECIFY, test_mode, ctx_dev));
     Shape shape = output_dev_4d[0]->get_stride();
     //    printShape(shape);
 
     dev_gru(input_dev_4d, output_dev_4d, param, ctx_dev);
 
-    int test_iter = 111;
+    int test_iter = 1000;
 
     t1.start(ctx_dev);
 
@@ -202,16 +210,16 @@ void test_saber_gru_x86(int sequence_size = 2, int batch_size = 1, int word_size
     tensor_cmp_host(host_g.data(), compare_g.data(), host_g.valid_size(), maxratio, maxdiff);
 
     if (abs(maxratio) <= 0.001) {
-                LOG(INFO) << "passed  " << maxratio;
+                LOG(INFO) << "passed  " << maxratio<<","<<maxdiff<<",?="<<abs(maxratio);
     } else {
-                LOG(INFO) << "failed : ratio " << maxratio;
+                LOG(INFO) << "failed : ratio " << maxratio<<","<<maxdiff;
     }
     return;
 #endif
     //    return;
 }
 
-TEST(TestSaberGruX86, test_func_saber_gru_x86) {
+TEST(TestSaberFuncX86, test_func_saber_gru_x86) {
 
     test_saber_gru_x86();
 
diff --git a/test/saber/x86/test_saber_func_x86_gru.h b/test/saber/x86/test_saber_func_x86_gru.h
deleted file mode 100644
index c2cc873..0000000
--- a/test/saber/x86/test_saber_func_x86_gru.h
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Copyright (c) 2016 Anakin Authors All Rights Reserve.
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-   http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. */
-#ifndef ANAKIN_TEST_SABER_TEST_SABER_GRU_X86_H
-#define ANAKIN_TEST_SABER_TEST_SABER_GRU_X86_H
-#include "utils/unit_test/aktest.h"
-#include "utils/logger/logger.h"
-#include "core/tensor.h"
-
-
-using namespace anakin::test;
-
-class TestSaberGruX86 : public Test {
-public:
-    TestSaberGruX86() {}
-    ~TestSaberGruX86() {}
-
-protected:
-    virtual void setup() {}
-    virtual void teardown() {}
-};
-
-#endif // ANAKIN_TEST_SABER_TEST_SABER_GRU_X86_H
diff --git a/test/saber/x86/test_saber_func_x86_sequence_conv.cpp b/test/saber/x86/test_saber_func_x86_sequence_conv.cpp
new file mode 100644
index 0000000..76559c8
--- /dev/null
+++ b/test/saber/x86/test_saber_func_x86_sequence_conv.cpp
@@ -0,0 +1,78 @@
+
+#include <vector>
+#include "tensor_op.h"
+#include "funcs/sequence_conv.h"
+#include "saber_types.h"
+#include "saber/funcs/timer.h"
+#include "stdio.h"
+#include "x86_test_common.h"
+#include "test_saber_func_x86.h"
+
+
+
+using namespace anakin::saber;
+
+typedef Tensor<X86, AK_FLOAT, NCHW> TensorHf4;
+void test_func_saber_sequence_conv_x86() {
+
+
+    Context<X86> ctx_dev(0, 1, 1);
+    std::vector<int> offsets = {0, 3, 7};
+
+    int hidden_size = 2;
+    int context_length = 3; //kerner size
+    int feature_size = 5;
+    int word_num = offsets[offsets.size() - 1];
+    Shape shape_in(word_num, hidden_size, 1, 1);
+    Shape shape_filter(1, 1, context_length * hidden_size, feature_size);
+
+    TensorHf4 data_in;
+    TensorHf4 data_out;
+    TensorHf4 data_filter;
+    data_filter.re_alloc(shape_filter);
+    data_in.re_alloc(shape_in);
+    fill_tensor_host_seq(data_filter);
+    fill_tensor_host_seq(data_in);
+    data_in.set_seq_offset(offsets);
+
+    SequenceConvParam<TensorHf4> param(&data_filter, 3, -1);
+    SequenceConv<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW, NCHW> dev_seq_conv;
+    std::vector<TensorHf4*> input_dev_4d;
+    std::vector<TensorHf4*> output_dev_4d;
+    input_dev_4d.push_back(&data_in);
+    output_dev_4d.push_back(&data_out);
+
+    dev_seq_conv.compute_output_shape(input_dev_4d, output_dev_4d, param);
+    LOG(INFO) << "shape of output =" << data_out.valid_shape().data()[0] << ","
+              << data_out.valid_shape().data()[1] << ","
+              << data_out.valid_shape().data()[2] << ","
+              << data_out.valid_shape().data()[3];
+    data_out.re_alloc(data_out.valid_shape());
+    output_dev_4d[0]->re_alloc(output_dev_4d[0]->valid_shape());
+
+    SABER_CHECK(dev_seq_conv.init(input_dev_4d, output_dev_4d, param, SPECIFY, SABER_IMPL, ctx_dev));
+    dev_seq_conv(input_dev_4d, output_dev_4d, param, ctx_dev);
+
+    for (int i = 0; i < word_num * feature_size; i++) {
+        printf("[%d] = %f\n", i, data_out.data()[i]);
+    }
+
+    //    return;
+}
+
+TEST(TestSaberFuncX86, test_func_saber_sequence_conv) {
+
+    test_func_saber_sequence_conv_x86();
+
+}
+
+int main(int argc, const char** argv) {
+    // initial logger
+    //logger::init(argv[0]);
+
+    Env<X86>::env_init();
+
+    InitTest();
+    RUN_ALL_TESTS(argv[0]);
+    return 0;
+}
diff --git a/tools/anakin-lite/CMakeLists.txt b/tools/anakin-lite/CMakeLists.txt
index 5760d7e..74f2fa9 100644
--- a/tools/anakin-lite/CMakeLists.txt
+++ b/tools/anakin-lite/CMakeLists.txt
@@ -16,19 +16,33 @@ anakin_option(USE_IOS "using android place." NO if NOT USE_ANDROID)
 anakin_option(USE_OMP "using openmp for lite." YES)
 anakin_option(USE_LOGGER "using local logger" YES)
 
+anakin_option(ENABLE_DEBUG "Enable DEBUG(default) mode." NO)
+
 configure_file ( 
 	"../../cmake/config/anakin_config.h.in" 
 	"${PROJECT_BINARY_DIR}/anakin_config.h"
 )
 
-
 # add compile flags
 anakin_add_compile_option(-std=c++11)
 anakin_add_compile_option(-fPIC)
 anakin_add_compile_option(-ldl)
+anakin_add_compile_option(-fvisibility=hidden)
+anakin_add_compile_option(-fvisibility-inlines-hidden)
+anakin_add_compile_option(-ffunction-sections)
+anakin_add_compile_option(-fdata-sections)
+anakin_add_compile_option(-s)
+#anakin_add_compile_option(-fstrict-aliasing)
+
+#set(CMAKE_SHARED_LINKER_FLAGS "-Wl,--fix-cortex-a8 -Wl,--no-undefined -Wl,--gc-sections -Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now ${CMAKE_SHARED_LINKER_FLAGS}")
+#set(CMAKE_MODULE_LINKER_FLAGS "-Wl,--fix-cortex-a8 -Wl,--no-undefined -Wl,--gc-sections -Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now ${CMAKE_MODULE_LINKER_FLAGS}")
+#set(CMAKE_EXE_LINKER_FLAGS    "-Wl,--fix-cortex-a8 -Wl,--no-undefined -Wl,--gc-sections -Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now ${CMAKE_EXE_LINKER_FLAGS}")
+
+set(CMAKE_SHARED_LINKER_FLAGS "${CMAKE_SHARED_LINKER_FLAGS} -Wl,--gc-sections -Wl,--icf=safe")
+set(MAKE_STATIC_LINKER_FLAGS "${MAKE_STATIC_LINKER_FLAGS} -Wl,--gc-sections -Wl,--icf=safe")
+
 anakin_add_compile_option(-W)
 anakin_add_compile_option(-Wall)
-anakin_add_compile_option(-pthread)
 anakin_add_compile_option(-Wno-unused-variable) # no unused-variable
 anakin_add_compile_option(-Wformat)
 anakin_add_compile_option(-Wmissing-declarations)
@@ -47,11 +61,17 @@ anakin_add_compile_option(-Wno-sign-compare)
 anakin_add_compile_option(-Wno-ignored-qualifiers) 
 anakin_add_compile_option(-Wno-enum-compare)
 
+if(ENABLE_DEBUG)
+	set(CMAKE_BUILD_TYPE Debug FORCE)
+else()
+	set(CMAKE_BUILD_TYPE Release FORCE)
+endif()
+
 if(CMAKE_BUILD_TYPE MATCHES Debug) 
 	anakin_add_compile_option(-O0) 
 	anakin_add_compile_option(-g) 
 else() 
-	anakin_add_compile_option(-O3) 
+	anakin_add_compile_option(-Os) 
 	anakin_add_compile_option(-DNDEBUG) 
 endif()
 
diff --git a/tools/andrid_build.sh b/tools/andrid_build.sh
index f22c37f..2611f44 100755
--- a/tools/andrid_build.sh
+++ b/tools/andrid_build.sh
@@ -41,20 +41,23 @@ cmake .. \
 	-DUSE_ARM_PLACE=YES \
 	-DUSE_GPU_PLACE=NO \
 	-DUSE_X86_PLACE=NO \
-	-DTARGET_ANDRIOD=YES \
+	-DTARGET_ANDROID=YES \
 	-DBUILD_WITH_UNIT_TEST=YES \
     -DUSE_PYTHON=OFF \
-	-DENABLE_DEBUG=YES \
+	-DENABLE_DEBUG=NO \
 	-DENABLE_VERBOSE_MSG=NO \
 	-DDISABLE_ALL_WARNINGS=YES \
 	-DENABLE_NOISY_WARNINGS=NO \
+	-DUSE_OPENCV=YES\
     -DUSE_OPENMP=YES\
-	-DBUILD_SHARED=NO
+	-DBUILD_SHARED=NO\
+	-DBUILD_WITH_UNIT_TEST=YES\
+	-DBUILD_EXAMPLES=YES
 
 # build target lib or unit test.
 if [ "$(uname)" = 'Darwin' ]; then
-    make "-j$(sysctl -n hw.ncpu)" && make install
+    make -j4 # && make install
 else
-    make "-j$(nproc)" && make install
+    make -j4 # && make install
 fi
 
diff --git a/tools/external_converter_v2/config.py b/tools/external_converter_v2/config.py
index 3a91bbf..1e2b21c 100644
--- a/tools/external_converter_v2/config.py
+++ b/tools/external_converter_v2/config.py
@@ -4,14 +4,11 @@
 
 import os
 import subprocess
-from yaml import load
-from yaml import dump
+from yaml import load, dump
 try:
-    from yaml import CLoader as Loader
-    from yaml import CDumper as Dumper
+    from yaml import CLoader as Loader, CDumper as Dumper
 except ImportError:
-    from yaml import Loader
-    from yaml import Dumper
+    from yaml import Loader, Dumper
 
 ConfigFilePath = './config.yaml'
 
@@ -54,6 +51,9 @@ class Configuration:
             pass
         elif self.framework == "MXNET":
             pass
+        elif self.framework == "FLUID":
+            proto_list = data['TARGET'][self.framework]['ProtoPaths']
+            self.framework_config_dict = data['TARGET'][self.framework]
         else:
             raise NameError('ERROR: Framework not support yet ' % (self.framework))
         try:
diff --git a/tools/external_converter_v2/config.yaml b/tools/external_converter_v2/config.yaml
index 6dc384a..565c808 100644
--- a/tools/external_converter_v2/config.yaml
+++ b/tools/external_converter_v2/config.yaml
@@ -63,19 +63,15 @@ TARGET:
         PrototxtPath: /path/to/your/googlenet.prototxt
         ModelPath: /path/to/your/googlenet.caffemodel
 
-    PADDLE:
-        # path to proto files   
-        ProtoPath:
+    FLUID:
+        # path of fluid inference model   
+        Debug: NULL
+        ProtoPath: 
         PrototxtPath: 
-        ModelPath: 
-    
-    LEGO:
-        # path to proto files   
-        ProtoPath:
-        PrototxtPath:
         ModelPath:
+        NetType:
     
-    PADDLE:
+    LEGO:
         # path to proto files   
         ProtoPath:
         PrototxtPath:
diff --git a/tools/external_converter_v2/parser/frontend/__init__.py b/tools/external_converter_v2/parser/frontend/__init__.py
index 70294b1..f1ee1c5 100644
--- a/tools/external_converter_v2/parser/frontend/__init__.py
+++ b/tools/external_converter_v2/parser/frontend/__init__.py
@@ -14,7 +14,7 @@ def RunServerOnGraph(f_graph_get):
     """
     def warpper(self, *args):
         graph, config = f_graph_get(self, *args)
-        graph_to_json, attrs = GraphToJson(graph)()
+        graph_to_json, attrs, mem_info_hold= GraphToJson(graph)()
         # parser origin graph
         GraphBoard.config['graph_attrs'] = attrs
         GraphBoard.config['graph_option'] = graph_to_json
@@ -24,9 +24,10 @@ def RunServerOnGraph(f_graph_get):
         graph_optimized = GraphProtoIO()
         if config.hasOptimizedGraph:
             graph_optimized.parse_from_string(config.optimizedGraphPath)
-            optimized_graph_to_json, optimized_graph_attrs = GraphToJson(graph_optimized)()
+            optimized_graph_to_json, optimized_graph_attrs, mem_info= GraphToJson(graph_optimized)()
             GraphBoard.config['optimized_graph_attrs'] = optimized_graph_attrs
-            GraphBoard.config['optimized_graph_option'] = optimized_graph_to_json
+            GraphBoard.config['optimized_graph_option'] = optimized_graph_to_json 
+            GraphBoard.config['mem_info'] = mem_info 
             GraphBoard.config['disable_optimization'] = False
         else:
             GraphBoard.config['disable_optimization'] = True
diff --git a/tools/external_converter_v2/parser/frontend/dash_board/__init__.py b/tools/external_converter_v2/parser/frontend/dash_board/__init__.py
index 5caa0f6..4b6c1ef 100644
--- a/tools/external_converter_v2/parser/frontend/dash_board/__init__.py
+++ b/tools/external_converter_v2/parser/frontend/dash_board/__init__.py
@@ -24,6 +24,7 @@ GraphBoard.config['graph_attrs'] = ""
 GraphBoard.config['graph_option'] = ""
 GraphBoard.config['optimized_graph_attrs'] = ""
 GraphBoard.config['optimized_graph_option'] = ""
+GraphBoard.config['mem_info']=""
 GraphBoard.config['disable_optimization'] = bool()
 GraphBoard.config['config'] = dict()
 GraphBoard.config.from_object(__name__)
@@ -66,7 +67,8 @@ def board_optimization():
     return render_template('optimization.html', 
                            parser_config=parser_config, 
                            graph_def=GraphBoard.config['optimized_graph_option'], 
-                           attrs=GraphBoard.config['optimized_graph_attrs'])
+                           attrs=GraphBoard.config['optimized_graph_attrs'],
+						   mem_info=GraphBoard.config['mem_info'])
 
 
 @GraphBoard.route('/<path:filename>', methods=['GET', 'POST'])
diff --git a/tools/external_converter_v2/parser/frontend/dash_board/static/echart/echarts.min.js b/tools/external_converter_v2/parser/frontend/dash_board/static/echart/echarts.min.js
index 4d61727..e028670 100644
--- a/tools/external_converter_v2/parser/frontend/dash_board/static/echart/echarts.min.js
+++ b/tools/external_converter_v2/parser/frontend/dash_board/static/echart/echarts.min.js
@@ -1,19 +1,14 @@
-!function(t,e){"object"==typeof exports&&"undefined"!=typeof module?e(exports):"function"==typeof define&&define.amd?define(["exports"],e):e(t.echarts={})}(this,function(t){"use strict";function e(t){var e={},i={},n=t.match(/Firefox\/([\d.]+)/),a=t.match(/MSIE\s([\d.]+)/)||t.match(/Trident\/.+?rv:(([\d.]+))/),r=t.match(/Edge\/([\d.]+)/),o=/micromessenger/i.test(t);return n&&(i.firefox=!0,i.version=n[1]),a&&(i.ie=!0,i.version=a[1]),r&&(i.edge=!0,i.version=r[1]),o&&(i.weChat=!0),{browser:i,os:e,node:!1,canvasSupported:!!document.createElement("canvas").getContext,svgSupported:"undefined"!=typeof SVGRect,touchEventsSupported:"ontouchstart"in window&&!i.ie&&!i.edge,pointerEventsSupported:"onpointerdown"in window&&(i.edge||i.ie&&i.version>=11)}}function i(t,e){"createCanvas"===t&&(Cy=null),Ty[t]=e}function n(t){if(null==t||"object"!=typeof t)return t;var e=t,i=xy.call(t);if("[object Array]"===i){if(!R(t)){e=[];for(var a=0,r=t.length;r>a;a++)e[a]=n(t[a])}}else if(yy[i]){if(!R(t)){var o=t.constructor;if(t.constructor.from)e=o.from(t);else{e=new o(t.length);for(var a=0,r=t.length;r>a;a++)e[a]=n(t[a])}}}else if(!my[i]&&!R(t)&&!T(t)){e={};for(var s in t)t.hasOwnProperty(s)&&(e[s]=n(t[s]))}return e}function a(t,e,i){if(!M(e)||!M(t))return i?n(e):t;for(var r in e)if(e.hasOwnProperty(r)){var o=t[r],s=e[r];!M(s)||!M(o)||_(s)||_(o)||T(s)||T(o)||S(s)||S(o)||R(s)||R(o)?!i&&r in t||(t[r]=n(e[r],!0)):a(o,s,i)}return t}function r(t,e){for(var i=t[0],n=1,r=t.length;r>n;n++)i=a(i,t[n],e);return i}function o(t,e){for(var i in e)e.hasOwnProperty(i)&&(t[i]=e[i]);return t}function s(t,e,i){for(var n in e)e.hasOwnProperty(n)&&(i?null!=e[n]:null==t[n])&&(t[n]=e[n]);return t}function l(){return Cy||(Cy=Ay().getContext("2d")),Cy}function h(t,e){if(t){if(t.indexOf)return t.indexOf(e);for(var i=0,n=t.length;n>i;i++)if(t[i]===e)return i}return-1}function u(t,e){function i(){}var n=t.prototype;i.prototype=e.prototype,t.prototype=new i;for(var a in n)t.prototype[a]=n[a];t.prototype.constructor=t,t.superClass=e}function c(t,e,i){t="prototype"in t?t.prototype:t,e="prototype"in e?e.prototype:e,s(t,e,i)}function d(t){return t?"string"==typeof t?!1:"number"==typeof t.length:void 0}function f(t,e,i){if(t&&e)if(t.forEach&&t.forEach===wy)t.forEach(e,i);else if(t.length===+t.length)for(var n=0,a=t.length;a>n;n++)e.call(i,t[n],n,t);else for(var r in t)t.hasOwnProperty(r)&&e.call(i,t[r],r,t)}function p(t,e,i){if(t&&e){if(t.map&&t.map===Sy)return t.map(e,i);for(var n=[],a=0,r=t.length;r>a;a++)n.push(e.call(i,t[a],a,t));return n}}function g(t,e,i,n){if(t&&e){if(t.reduce&&t.reduce===Iy)return t.reduce(e,i,n);for(var a=0,r=t.length;r>a;a++)i=e.call(n,i,t[a],a,t);return i}}function v(t,e,i){if(t&&e){if(t.filter&&t.filter===by)return t.filter(e,i);for(var n=[],a=0,r=t.length;r>a;a++)e.call(i,t[a],a,t)&&n.push(t[a]);return n}}function m(t,e,i){if(t&&e)for(var n=0,a=t.length;a>n;n++)if(e.call(i,t[n],n,t))return t[n]}function y(t,e){var i=My.call(arguments,2);return function(){return t.apply(e,i.concat(My.call(arguments)))}}function x(t){var e=My.call(arguments,1);return function(){return t.apply(this,e.concat(My.call(arguments)))}}function _(t){return"[object Array]"===xy.call(t)}function w(t){return"function"==typeof t}function b(t){return"[object String]"===xy.call(t)}function M(t){var e=typeof t;return"function"===e||!!t&&"object"==e}function S(t){return!!my[xy.call(t)]}function I(t){return!!yy[xy.call(t)]}function T(t){return"object"==typeof t&&"number"==typeof t.nodeType&&"object"==typeof t.ownerDocument}function A(t){return t!==t}function C(){for(var t=0,e=arguments.length;e>t;t++)if(null!=arguments[t])return arguments[t]}function D(t,e){return null!=t?t:e}function L(t,e,i){return null!=t?t:null!=e?e:i}function k(){return Function.call.apply(My,arguments)}function P(t){if("number"==typeof t)return[t,t,t,t];var e=t.length;return 2===e?[t[0],t[1],t[0],t[1]]:3===e?[t[0],t[1],t[2],t[1]]:t}function O(t,e){if(!t)throw new Error(e)}function z(t){return null==t?null:"function"==typeof t.trim?t.trim():t.replace(/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,"")}function E(t){t[Dy]=!0}function R(t){return t[Dy]}function N(t){function e(t,e){i?n.set(t,e):n.set(e,t)}var i=_(t),n=this;t instanceof N?t.each(e):t&&f(t,e)}function B(t){return new N(t)}function V(t,e){for(var i=new t.constructor(t.length+e.length),n=0;n<t.length;n++)i[n]=t[n];var a=t.length;for(n=0;n<e.length;n++)i[n+a]=e[n];return i}function G(){}function F(t,e){var i=new ky(2);return null==t&&(t=0),null==e&&(e=0),i[0]=t,i[1]=e,i}function W(t,e){return t[0]=e[0],t[1]=e[1],t}function H(t){var e=new ky(2);return e[0]=t[0],e[1]=t[1],e}function Z(t,e,i){return t[0]=e,t[1]=i,t}function j(t,e,i){return t[0]=e[0]+i[0],t[1]=e[1]+i[1],t}function X(t,e,i,n){return t[0]=e[0]+i[0]*n,t[1]=e[1]+i[1]*n,t}function U(t,e,i){return t[0]=e[0]-i[0],t[1]=e[1]-i[1],t}function Y(t){return Math.sqrt(q(t))}function q(t){return t[0]*t[0]+t[1]*t[1]}function $(t,e,i){return t[0]=e[0]*i[0],t[1]=e[1]*i[1],t}function K(t,e,i){return t[0]=e[0]/i[0],t[1]=e[1]/i[1],t}function J(t,e){return t[0]*e[0]+t[1]*e[1]}function Q(t,e,i){return t[0]=e[0]*i,t[1]=e[1]*i,t}function te(t,e){var i=Y(e);return 0===i?(t[0]=0,t[1]=0):(t[0]=e[0]/i,t[1]=e[1]/i),t}function ee(t,e){return Math.sqrt((t[0]-e[0])*(t[0]-e[0])+(t[1]-e[1])*(t[1]-e[1]))}function ie(t,e){return(t[0]-e[0])*(t[0]-e[0])+(t[1]-e[1])*(t[1]-e[1])}function ne(t,e){return t[0]=-e[0],t[1]=-e[1],t}function ae(t,e,i,n){return t[0]=e[0]+n*(i[0]-e[0]),t[1]=e[1]+n*(i[1]-e[1]),t}function re(t,e,i){var n=e[0],a=e[1];return t[0]=i[0]*n+i[2]*a+i[4],t[1]=i[1]*n+i[3]*a+i[5],t}function oe(t,e,i){return t[0]=Math.min(e[0],i[0]),t[1]=Math.min(e[1],i[1]),t}function se(t,e,i){return t[0]=Math.max(e[0],i[0]),t[1]=Math.max(e[1],i[1]),t}function le(){this.on("mousedown",this._dragStart,this),this.on("mousemove",this._drag,this),this.on("mouseup",this._dragEnd,this),this.on("globalout",this._dragEnd,this)}function he(t,e){return{target:t,topTarget:e&&e.topTarget}}function ue(t,e,i){return{type:t,event:i,target:e.target,topTarget:e.topTarget,cancelBubble:!1,offsetX:i.zrX,offsetY:i.zrY,gestureEvent:i.gestureEvent,pinchX:i.pinchX,pinchY:i.pinchY,pinchScale:i.pinchScale,wheelDelta:i.zrDelta,zrByTouch:i.zrByTouch,which:i.which}}function ce(){}function de(t,e,i){if(t[t.rectHover?"rectContain":"contain"](e,i)){for(var n,a=t;a;){if(a.clipPath&&!a.clipPath.contain(e,i))return!1;a.silent&&(n=!0),a=a.parent}return n?Vy:!0}return!1}function fe(){var t=new Wy(6);return pe(t),t}function pe(t){return t[0]=1,t[1]=0,t[2]=0,t[3]=1,t[4]=0,t[5]=0,t}function ge(t,e){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t[4]=e[4],t[5]=e[5],t}function ve(t,e,i){var n=e[0]*i[0]+e[2]*i[1],a=e[1]*i[0]+e[3]*i[1],r=e[0]*i[2]+e[2]*i[3],o=e[1]*i[2]+e[3]*i[3],s=e[0]*i[4]+e[2]*i[5]+e[4],l=e[1]*i[4]+e[3]*i[5]+e[5];return t[0]=n,t[1]=a,t[2]=r,t[3]=o,t[4]=s,t[5]=l,t}function me(t,e,i){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t[4]=e[4]+i[0],t[5]=e[5]+i[1],t}function ye(t,e,i){var n=e[0],a=e[2],r=e[4],o=e[1],s=e[3],l=e[5],h=Math.sin(i),u=Math.cos(i);return t[0]=n*u+o*h,t[1]=-n*h+o*u,t[2]=a*u+s*h,t[3]=-a*h+u*s,t[4]=u*r+h*l,t[5]=u*l-h*r,t}function xe(t,e,i){var n=i[0],a=i[1];return t[0]=e[0]*n,t[1]=e[1]*a,t[2]=e[2]*n,t[3]=e[3]*a,t[4]=e[4]*n,t[5]=e[5]*a,t}function _e(t,e){var i=e[0],n=e[2],a=e[4],r=e[1],o=e[3],s=e[5],l=i*o-r*n;return l?(l=1/l,t[0]=o*l,t[1]=-r*l,t[2]=-n*l,t[3]=i*l,t[4]=(n*s-o*a)*l,t[5]=(r*a-i*s)*l,t):null}function we(t){var e=fe();return ge(e,t),e}function be(t){return t>jy||-jy>t}function Me(t){this._target=t.target,this._life=t.life||1e3,this._delay=t.delay||0,this._initialized=!1,this.loop=null==t.loop?!1:t.loop,this.gap=t.gap||0,this.easing=t.easing||"Linear",this.onframe=t.onframe,this.ondestroy=t.ondestroy,this.onrestart=t.onrestart,this._pausedTime=0,this._paused=!1}function Se(t){return t=Math.round(t),0>t?0:t>255?255:t}function Ie(t){return t=Math.round(t),0>t?0:t>360?360:t}function Te(t){return 0>t?0:t>1?1:t}function Ae(t){return Se(t.length&&"%"===t.charAt(t.length-1)?parseFloat(t)/100*255:parseInt(t,10))}function Ce(t){return Te(t.length&&"%"===t.charAt(t.length-1)?parseFloat(t)/100:parseFloat(t))}function De(t,e,i){return 0>i?i+=1:i>1&&(i-=1),1>6*i?t+(e-t)*i*6:1>2*i?e:2>3*i?t+(e-t)*(2/3-i)*6:t}function Le(t,e,i){return t+(e-t)*i}function ke(t,e,i,n,a){return t[0]=e,t[1]=i,t[2]=n,t[3]=a,t}function Pe(t,e){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t}function Oe(t,e){nx&&Pe(nx,e),nx=ix.put(t,nx||e.slice())}function ze(t,e){if(t){e=e||[];var i=ix.get(t);if(i)return Pe(e,i);t+="";var n=t.replace(/ /g,"").toLowerCase();if(n in ex)return Pe(e,ex[n]),Oe(t,e),e;if("#"!==n.charAt(0)){var a=n.indexOf("("),r=n.indexOf(")");if(-1!==a&&r+1===n.length){var o=n.substr(0,a),s=n.substr(a+1,r-(a+1)).split(","),l=1;switch(o){case"rgba":if(4!==s.length)return void ke(e,0,0,0,1);l=Ce(s.pop());case"rgb":return 3!==s.length?void ke(e,0,0,0,1):(ke(e,Ae(s[0]),Ae(s[1]),Ae(s[2]),l),Oe(t,e),e);case"hsla":return 4!==s.length?void ke(e,0,0,0,1):(s[3]=Ce(s[3]),Ee(s,e),Oe(t,e),e);case"hsl":return 3!==s.length?void ke(e,0,0,0,1):(Ee(s,e),Oe(t,e),e);default:return}}ke(e,0,0,0,1)}else{if(4===n.length){var h=parseInt(n.substr(1),16);return h>=0&&4095>=h?(ke(e,(3840&h)>>4|(3840&h)>>8,240&h|(240&h)>>4,15&h|(15&h)<<4,1),Oe(t,e),e):void ke(e,0,0,0,1)}if(7===n.length){var h=parseInt(n.substr(1),16);return h>=0&&16777215>=h?(ke(e,(16711680&h)>>16,(65280&h)>>8,255&h,1),Oe(t,e),e):void ke(e,0,0,0,1)}}}}function Ee(t,e){var i=(parseFloat(t[0])%360+360)%360/360,n=Ce(t[1]),a=Ce(t[2]),r=.5>=a?a*(n+1):a+n-a*n,o=2*a-r;return e=e||[],ke(e,Se(255*De(o,r,i+1/3)),Se(255*De(o,r,i)),Se(255*De(o,r,i-1/3)),1),4===t.length&&(e[3]=t[3]),e}function Re(t){if(t){var e,i,n=t[0]/255,a=t[1]/255,r=t[2]/255,o=Math.min(n,a,r),s=Math.max(n,a,r),l=s-o,h=(s+o)/2;if(0===l)e=0,i=0;else{i=.5>h?l/(s+o):l/(2-s-o);var u=((s-n)/6+l/2)/l,c=((s-a)/6+l/2)/l,d=((s-r)/6+l/2)/l;n===s?e=d-c:a===s?e=1/3+u-d:r===s&&(e=2/3+c-u),0>e&&(e+=1),e>1&&(e-=1)}var f=[360*e,i,h];return null!=t[3]&&f.push(t[3]),f}}function Ne(t,e){var i=ze(t);if(i){for(var n=0;3>n;n++)i[n]=0>e?i[n]*(1-e)|0:(255-i[n])*e+i[n]|0;return He(i,4===i.length?"rgba":"rgb")}}function Be(t){var e=ze(t);return e?((1<<24)+(e[0]<<16)+(e[1]<<8)+ +e[2]).toString(16).slice(1):void 0}function Ve(t,e,i){if(e&&e.length&&t>=0&&1>=t){i=i||[];var n=t*(e.length-1),a=Math.floor(n),r=Math.ceil(n),o=e[a],s=e[r],l=n-a;return i[0]=Se(Le(o[0],s[0],l)),i[1]=Se(Le(o[1],s[1],l)),i[2]=Se(Le(o[2],s[2],l)),i[3]=Te(Le(o[3],s[3],l)),i}}function Ge(t,e,i){if(e&&e.length&&t>=0&&1>=t){var n=t*(e.length-1),a=Math.floor(n),r=Math.ceil(n),o=ze(e[a]),s=ze(e[r]),l=n-a,h=He([Se(Le(o[0],s[0],l)),Se(Le(o[1],s[1],l)),Se(Le(o[2],s[2],l)),Te(Le(o[3],s[3],l))],"rgba");return i?{color:h,leftIndex:a,rightIndex:r,value:n}:h}}function Fe(t,e,i,n){return t=ze(t),t?(t=Re(t),null!=e&&(t[0]=Ie(e)),null!=i&&(t[1]=Ce(i)),null!=n&&(t[2]=Ce(n)),He(Ee(t),"rgba")):void 0}function We(t,e){return t=ze(t),t&&null!=e?(t[3]=Te(e),He(t,"rgba")):void 0}function He(t,e){if(t&&t.length){var i=t[0]+","+t[1]+","+t[2];return("rgba"===e||"hsva"===e||"hsla"===e)&&(i+=","+t[3]),e+"("+i+")"}}function Ze(t,e){return t[e]}function je(t,e,i){t[e]=i}function Xe(t,e,i){return(e-t)*i+t}function Ue(t,e,i){return i>.5?e:t}function Ye(t,e,i,n,a){var r=t.length;if(1==a)for(var o=0;r>o;o++)n[o]=Xe(t[o],e[o],i);else for(var s=r&&t[0].length,o=0;r>o;o++)for(var l=0;s>l;l++)n[o][l]=Xe(t[o][l],e[o][l],i)}function qe(t,e,i){var n=t.length,a=e.length;if(n!==a){var r=n>a;if(r)t.length=a;else for(var o=n;a>o;o++)t.push(1===i?e[o]:sx.call(e[o]))}for(var s=t[0]&&t[0].length,o=0;o<t.length;o++)if(1===i)isNaN(t[o])&&(t[o]=e[o]);else for(var l=0;s>l;l++)isNaN(t[o][l])&&(t[o][l]=e[o][l])}function $e(t,e,i){if(t===e)return!0;var n=t.length;if(n!==e.length)return!1;if(1===i){for(var a=0;n>a;a++)if(t[a]!==e[a])return!1}else for(var r=t[0].length,a=0;n>a;a++)for(var o=0;r>o;o++)if(t[a][o]!==e[a][o])return!1;return!0}function Ke(t,e,i,n,a,r,o,s,l){var h=t.length;if(1==l)for(var u=0;h>u;u++)s[u]=Je(t[u],e[u],i[u],n[u],a,r,o);else for(var c=t[0].length,u=0;h>u;u++)for(var d=0;c>d;d++)s[u][d]=Je(t[u][d],e[u][d],i[u][d],n[u][d],a,r,o)}function Je(t,e,i,n,a,r,o){var s=.5*(i-t),l=.5*(n-e);return(2*(e-i)+s+l)*o+(-3*(e-i)-2*s-l)*r+s*a+e}function Qe(t){if(d(t)){var e=t.length;if(d(t[0])){for(var i=[],n=0;e>n;n++)i.push(sx.call(t[n]));return i}return sx.call(t)}return t}function ti(t){return t[0]=Math.floor(t[0]),t[1]=Math.floor(t[1]),t[2]=Math.floor(t[2]),"rgba("+t.join(",")+")"}function ei(t){var e=t[t.length-1].value;return d(e&&e[0])?2:1}function ii(t,e,i,n,a,r){var o=t._getter,s=t._setter,l="spline"===e,h=n.length;if(h){var u,c=n[0].value,f=d(c),p=!1,g=!1,v=f?ei(n):0;n.sort(function(t,e){return t.time-e.time}),u=n[h-1].time;for(var m=[],y=[],x=n[0].value,_=!0,w=0;h>w;w++){m.push(n[w].time/u);var b=n[w].value;if(f&&$e(b,x,v)||!f&&b===x||(_=!1),x=b,"string"==typeof b){var M=ze(b);M?(b=M,p=!0):g=!0}y.push(b)}if(r||!_){for(var S=y[h-1],w=0;h-1>w;w++)f?qe(y[w],S,v):!isNaN(y[w])||isNaN(S)||g||p||(y[w]=S);f&&qe(o(t._target,a),S,v);var I,T,A,C,D,L,k=0,P=0;if(p)var O=[0,0,0,0];var z=function(t,e){var i;if(0>e)i=0;else if(P>e){for(I=Math.min(k+1,h-1),i=I;i>=0&&!(m[i]<=e);i--);i=Math.min(i,h-2)}else{for(i=k;h>i&&!(m[i]>e);i++);i=Math.min(i-1,h-2)}k=i,P=e;var n=m[i+1]-m[i];if(0!==n)if(T=(e-m[i])/n,l)if(C=y[i],A=y[0===i?i:i-1],D=y[i>h-2?h-1:i+1],L=y[i>h-3?h-1:i+2],f)Ke(A,C,D,L,T,T*T,T*T*T,o(t,a),v);else{var r;if(p)r=Ke(A,C,D,L,T,T*T,T*T*T,O,1),r=ti(O);else{if(g)return Ue(C,D,T);r=Je(A,C,D,L,T,T*T,T*T*T)}s(t,a,r)}else if(f)Ye(y[i],y[i+1],T,o(t,a),v);else{var r;if(p)Ye(y[i],y[i+1],T,O,1),r=ti(O);else{if(g)return Ue(y[i],y[i+1],T);r=Xe(y[i],y[i+1],T)}s(t,a,r)}},E=new Me({target:t._target,life:u,loop:t._loop,delay:t._delay,onframe:z,ondestroy:i});return e&&"spline"!==e&&(E.easing=e),E}}}function ni(t,e,i,n){0>i&&(t+=i,i=-i),0>n&&(e+=n,n=-n),this.x=t,this.y=e,this.width=i,this.height=n}function ai(t){for(var e=0;t>=_x;)e|=1&t,t>>=1;return t+e}function ri(t,e,i,n){var a=e+1;if(a===i)return 1;if(n(t[a++],t[e])<0){for(;i>a&&n(t[a],t[a-1])<0;)a++;oi(t,e,a)}else for(;i>a&&n(t[a],t[a-1])>=0;)a++;return a-e}function oi(t,e,i){for(i--;i>e;){var n=t[e];t[e++]=t[i],t[i--]=n}}function si(t,e,i,n,a){for(n===e&&n++;i>n;n++){for(var r,o=t[n],s=e,l=n;l>s;)r=s+l>>>1,a(o,t[r])<0?l=r:s=r+1;var h=n-s;switch(h){case 3:t[s+3]=t[s+2];case 2:t[s+2]=t[s+1];case 1:t[s+1]=t[s];break;default:for(;h>0;)t[s+h]=t[s+h-1],h--}t[s]=o}}function li(t,e,i,n,a,r){var o=0,s=0,l=1;if(r(t,e[i+a])>0){for(s=n-a;s>l&&r(t,e[i+a+l])>0;)o=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s),o+=a,l+=a}else{for(s=a+1;s>l&&r(t,e[i+a-l])<=0;)o=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s);var h=o;o=a-l,l=a-h}for(o++;l>o;){var u=o+(l-o>>>1);r(t,e[i+u])>0?o=u+1:l=u}return l}function hi(t,e,i,n,a,r){var o=0,s=0,l=1;if(r(t,e[i+a])<0){for(s=a+1;s>l&&r(t,e[i+a-l])<0;)o=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s);var h=o;o=a-l,l=a-h}else{for(s=n-a;s>l&&r(t,e[i+a+l])>=0;)o=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s),o+=a,l+=a}for(o++;l>o;){var u=o+(l-o>>>1);r(t,e[i+u])<0?l=u:o=u+1}return l}function ui(t,e){function i(t,e){l[c]=t,h[c]=e,c+=1}function n(){for(;c>1;){var t=c-2;if(t>=1&&h[t-1]<=h[t]+h[t+1]||t>=2&&h[t-2]<=h[t]+h[t-1])h[t-1]<h[t+1]&&t--;else if(h[t]>h[t+1])break;r(t)}}function a(){for(;c>1;){var t=c-2;t>0&&h[t-1]<h[t+1]&&t--,r(t)}}function r(i){var n=l[i],a=h[i],r=l[i+1],u=h[i+1];h[i]=a+u,i===c-3&&(l[i+1]=l[i+2],h[i+1]=h[i+2]),c--;var d=hi(t[r],t,n,a,0,e);n+=d,a-=d,0!==a&&(u=li(t[n+a-1],t,r,u,u-1,e),0!==u&&(u>=a?o(n,a,r,u):s(n,a,r,u)))}function o(i,n,a,r){var o=0;for(o=0;n>o;o++)d[o]=t[i+o];var s=0,l=a,h=i;if(t[h++]=t[l++],0!==--r){if(1===n){for(o=0;r>o;o++)t[h+o]=t[l+o];return void(t[h+r]=d[s])}for(var c,f,p,g=u;;){c=0,f=0,p=!1;do if(e(t[l],d[s])<0){if(t[h++]=t[l++],f++,c=0,0===--r){p=!0;break}}else if(t[h++]=d[s++],c++,f=0,1===--n){p=!0;break}while(g>(c|f));if(p)break;do{if(c=hi(t[l],d,s,n,0,e),0!==c){for(o=0;c>o;o++)t[h+o]=d[s+o];if(h+=c,s+=c,n-=c,1>=n){p=!0;break}}if(t[h++]=t[l++],0===--r){p=!0;break}if(f=li(d[s],t,l,r,0,e),0!==f){for(o=0;f>o;o++)t[h+o]=t[l+o];if(h+=f,l+=f,r-=f,0===r){p=!0;break}}if(t[h++]=d[s++],1===--n){p=!0;break}g--}while(c>=bx||f>=bx);if(p)break;0>g&&(g=0),g+=2}if(u=g,1>u&&(u=1),1===n){for(o=0;r>o;o++)t[h+o]=t[l+o];t[h+r]=d[s]}else{if(0===n)throw new Error;for(o=0;n>o;o++)t[h+o]=d[s+o]}}else for(o=0;n>o;o++)t[h+o]=d[s+o]}function s(i,n,a,r){var o=0;for(o=0;r>o;o++)d[o]=t[a+o];var s=i+n-1,l=r-1,h=a+r-1,c=0,f=0;if(t[h--]=t[s--],0!==--n){if(1===r){for(h-=n,s-=n,f=h+1,c=s+1,o=n-1;o>=0;o--)t[f+o]=t[c+o];return void(t[h]=d[l])}for(var p=u;;){var g=0,v=0,m=!1;do if(e(d[l],t[s])<0){if(t[h--]=t[s--],g++,v=0,0===--n){m=!0;break}}else if(t[h--]=d[l--],v++,g=0,1===--r){m=!0;break}while(p>(g|v));if(m)break;do{if(g=n-hi(d[l],t,i,n,n-1,e),0!==g){for(h-=g,s-=g,n-=g,f=h+1,c=s+1,o=g-1;o>=0;o--)t[f+o]=t[c+o];if(0===n){m=!0;break}}if(t[h--]=d[l--],1===--r){m=!0;break}if(v=r-li(t[s],d,0,r,r-1,e),0!==v){for(h-=v,l-=v,r-=v,f=h+1,c=l+1,o=0;v>o;o++)t[f+o]=d[c+o];if(1>=r){m=!0;break}}if(t[h--]=t[s--],0===--n){m=!0;break}p--}while(g>=bx||v>=bx);if(m)break;0>p&&(p=0),p+=2}if(u=p,1>u&&(u=1),1===r){for(h-=n,s-=n,f=h+1,c=s+1,o=n-1;o>=0;o--)t[f+o]=t[c+o];t[h]=d[l]}else{if(0===r)throw new Error;for(c=h-(r-1),o=0;r>o;o++)t[c+o]=d[o]}}else for(c=h-(r-1),o=0;r>o;o++)t[c+o]=d[o]}var l,h,u=bx,c=0,d=[];l=[],h=[],this.mergeRuns=n,this.forceMergeRuns=a,this.pushRun=i}function ci(t,e,i,n){i||(i=0),n||(n=t.length);var a=n-i;if(!(2>a)){var r=0;if(_x>a)return r=ri(t,i,n,e),void si(t,i,n,i+r,e);var o=new ui(t,e),s=ai(a);do{if(r=ri(t,i,n,e),s>r){var l=a;l>s&&(l=s),si(t,i,i+l,i+r,e),r=l}o.pushRun(i,r),o.mergeRuns(),a-=r,i+=r}while(0!==a);o.forceMergeRuns()}}function di(t,e){return t.zlevel===e.zlevel?t.z===e.z?t.z2-e.z2:t.z-e.z:t.zlevel-e.zlevel}function fi(t,e,i){var n=null==e.x?0:e.x,a=null==e.x2?1:e.x2,r=null==e.y?0:e.y,o=null==e.y2?0:e.y2;e.global||(n=n*i.width+i.x,a=a*i.width+i.x,r=r*i.height+i.y,o=o*i.height+i.y);var s=t.createLinearGradient(n,r,a,o);return s}function pi(t,e,i){var n=i.width,a=i.height,r=Math.min(n,a),o=null==e.x?.5:e.x,s=null==e.y?.5:e.y,l=null==e.r?.5:e.r;e.global||(o=o*n+i.x,s=s*a+i.y,l*=r);var h=t.createRadialGradient(o,s,0,o,s,l);return h}function gi(){return!1}function vi(t,e,i){var n=Ay(),a=e.getWidth(),r=e.getHeight(),o=n.style;return o&&(o.position="absolute",o.left=0,o.top=0,o.width=a+"px",o.height=r+"px",n.setAttribute("data-zr-dom-id",t)),n.width=a*i,n.height=r*i,n}function mi(t){if("string"==typeof t){var e=zx.get(t);return e&&e.image}return t}function yi(t,e,i,n,a){if(t){if("string"==typeof t){if(e&&e.__zrImageSrc===t||!i)return e;var r=zx.get(t),o={hostEl:i,cb:n,cbPayload:a};return r?(e=r.image,!_i(e)&&r.pending.push(o)):(!e&&(e=new Image),e.onload=xi,zx.put(t,e.__cachedImgObj={image:e,pending:[o]}),e.src=e.__zrImageSrc=t),e}return t}return e}function xi(){var t=this.__cachedImgObj;this.onload=this.__cachedImgObj=null;for(var e=0;e<t.pending.length;e++){var i=t.pending[e],n=i.cb;n&&n(this,i.cbPayload),i.hostEl.dirty()}t.pending.length=0}function _i(t){return t&&t.width&&t.height}function wi(t,e){Gx[t]=e}function bi(t,e){e=e||Vx;var i=t+":"+e;if(Ex[i])return Ex[i];for(var n=(t+"").split("\n"),a=0,r=0,o=n.length;o>r;r++)a=Math.max(zi(n[r],e).width,a);return Rx>Nx&&(Rx=0,Ex={}),Rx++,Ex[i]=a,a}function Mi(t,e,i,n,a,r,o){return r?Ii(t,e,i,n,a,r,o):Si(t,e,i,n,a,o)}function Si(t,e,i,n,a,r){var o=Ei(t,e,a,r),s=bi(t,e);a&&(s+=a[1]+a[3]);var l=o.outerHeight,h=Ti(0,s,i),u=Ai(0,l,n),c=new ni(h,u,s,l);return c.lineHeight=o.lineHeight,c}function Ii(t,e,i,n,a,r,o){var s=Ri(t,{rich:r,truncate:o,font:e,textAlign:i,textPadding:a}),l=s.outerWidth,h=s.outerHeight,u=Ti(0,l,i),c=Ai(0,h,n);return new ni(u,c,l,h)}function Ti(t,e,i){return"right"===i?t-=e:"center"===i&&(t-=e/2),t}function Ai(t,e,i){return"middle"===i?t-=e/2:"bottom"===i&&(t-=e),t}function Ci(t,e,i){var n=e.x,a=e.y,r=e.height,o=e.width,s=r/2,l="left",h="top";switch(t){case"left":n-=i,a+=s,l="right",h="middle";break;case"right":n+=i+o,a+=s,h="middle";break;case"top":n+=o/2,a-=i,l="center",h="bottom";break;case"bottom":n+=o/2,a+=r+i,l="center";break;case"inside":n+=o/2,a+=s,l="center",h="middle";break;case"insideLeft":n+=i,a+=s,h="middle";break;case"insideRight":n+=o-i,a+=s,l="right",h="middle";break;case"insideTop":n+=o/2,a+=i,l="center";break;case"insideBottom":n+=o/2,a+=r-i,l="center",h="bottom";break;case"insideTopLeft":n+=i,a+=i;break;case"insideTopRight":n+=o-i,a+=i,l="right";break;case"insideBottomLeft":n+=i,a+=r-i,h="bottom";break;case"insideBottomRight":n+=o-i,a+=r-i,l="right",h="bottom"}return{x:n,y:a,textAlign:l,textVerticalAlign:h}}function Di(t,e,i,n,a){if(!e)return"";var r=(t+"").split("\n");a=Li(e,i,n,a);for(var o=0,s=r.length;s>o;o++)r[o]=ki(r[o],a);return r.join("\n")}function Li(t,e,i,n){n=o({},n),n.font=e;var i=D(i,"...");n.maxIterations=D(n.maxIterations,2);var a=n.minChar=D(n.minChar,0);n.cnCharWidth=bi("国",e);var r=n.ascCharWidth=bi("a",e);n.placeholder=D(n.placeholder,"");for(var s=t=Math.max(0,t-1),l=0;a>l&&s>=r;l++)s-=r;var h=bi(i);return h>s&&(i="",h=0),s=t-h,n.ellipsis=i,n.ellipsisWidth=h,n.contentWidth=s,n.containerWidth=t,n}function ki(t,e){var i=e.containerWidth,n=e.font,a=e.contentWidth;if(!i)return"";var r=bi(t,n);if(i>=r)return t;for(var o=0;;o++){if(a>=r||o>=e.maxIterations){t+=e.ellipsis;break}var s=0===o?Pi(t,a,e.ascCharWidth,e.cnCharWidth):r>0?Math.floor(t.length*a/r):0;t=t.substr(0,s),r=bi(t,n)}return""===t&&(t=e.placeholder),t}function Pi(t,e,i,n){for(var a=0,r=0,o=t.length;o>r&&e>a;r++){var s=t.charCodeAt(r);a+=s>=0&&127>=s?i:n}return r}function Oi(t){return bi("国",t)}function zi(t,e){return Gx.measureText(t,e)}function Ei(t,e,i,n){null!=t&&(t+="");var a=Oi(e),r=t?t.split("\n"):[],o=r.length*a,s=o;if(i&&(s+=i[0]+i[2]),t&&n){var l=n.outerHeight,h=n.outerWidth;if(null!=l&&s>l)t="",r=[];else if(null!=h)for(var u=Li(h-(i?i[1]+i[3]:0),e,n.ellipsis,{minChar:n.minChar,placeholder:n.placeholder}),c=0,d=r.length;d>c;c++)r[c]=ki(r[c],u)}return{lines:r,height:o,outerHeight:s,lineHeight:a}}function Ri(t,e){var i={lines:[],width:0,height:0};if(null!=t&&(t+=""),!t)return i;for(var n,a=Bx.lastIndex=0;null!=(n=Bx.exec(t));){var r=n.index;r>a&&Ni(i,t.substring(a,r)),Ni(i,n[2],n[1]),a=Bx.lastIndex}a<t.length&&Ni(i,t.substring(a,t.length));var o=i.lines,s=0,l=0,h=[],u=e.textPadding,c=e.truncate,d=c&&c.outerWidth,f=c&&c.outerHeight;u&&(null!=d&&(d-=u[1]+u[3]),null!=f&&(f-=u[0]+u[2]));for(var p=0;p<o.length;p++){for(var g=o[p],v=0,m=0,y=0;y<g.tokens.length;y++){var x=g.tokens[y],_=x.styleName&&e.rich[x.styleName]||{},w=x.textPadding=_.textPadding,b=x.font=_.font||e.font,M=x.textHeight=D(_.textHeight,Oi(b));if(w&&(M+=w[0]+w[2]),x.height=M,x.lineHeight=L(_.textLineHeight,e.textLineHeight,M),x.textAlign=_&&_.textAlign||e.textAlign,x.textVerticalAlign=_&&_.textVerticalAlign||"middle",null!=f&&s+x.lineHeight>f)return{lines:[],width:0,height:0};x.textWidth=bi(x.text,b);var S=_.textWidth,I=null==S||"auto"===S;if("string"==typeof S&&"%"===S.charAt(S.length-1))x.percentWidth=S,h.push(x),S=0;else{if(I){S=x.textWidth;var T=_.textBackgroundColor,A=T&&T.image;A&&(A=mi(A),_i(A)&&(S=Math.max(S,A.width*M/A.height)))}var C=w?w[1]+w[3]:0;S+=C;var k=null!=d?d-m:null;null!=k&&S>k&&(!I||C>k?(x.text="",x.textWidth=S=0):(x.text=Di(x.text,k-C,b,c.ellipsis,{minChar:c.minChar}),x.textWidth=bi(x.text,b),S=x.textWidth+C))}m+=x.width=S,_&&(v=Math.max(v,x.lineHeight))}g.width=m,g.lineHeight=v,s+=v,l=Math.max(l,m)}i.outerWidth=i.width=D(e.textWidth,l),i.outerHeight=i.height=D(e.textHeight,s),u&&(i.outerWidth+=u[1]+u[3],i.outerHeight+=u[0]+u[2]);for(var p=0;p<h.length;p++){var x=h[p],P=x.percentWidth;x.width=parseInt(P,10)/100*l}return i}function Ni(t,e,i){for(var n=""===e,a=e.split("\n"),r=t.lines,o=0;o<a.length;o++){var s=a[o],l={styleName:i,text:s,isLineHolder:!s&&!n};if(o)r.push({tokens:[l]});else{var h=(r[r.length-1]||(r[0]={tokens:[]})).tokens,u=h.length;1===u&&h[0].isLineHolder?h[0]=l:(s||!u||n)&&h.push(l)}}}function Bi(t){var e=(t.fontSize||t.fontFamily)&&[t.fontStyle,t.fontWeight,(t.fontSize||12)+"px",t.fontFamily||"sans-serif"].join(" ");return e&&z(e)||t.textFont||t.font}function Vi(t,e){var i,n,a,r,o=e.x,s=e.y,l=e.width,h=e.height,u=e.r;0>l&&(o+=l,l=-l),0>h&&(s+=h,h=-h),"number"==typeof u?i=n=a=r=u:u instanceof Array?1===u.length?i=n=a=r=u[0]:2===u.length?(i=a=u[0],n=r=u[1]):3===u.length?(i=u[0],n=r=u[1],a=u[2]):(i=u[0],n=u[1],a=u[2],r=u[3]):i=n=a=r=0;var c;i+n>l&&(c=i+n,i*=l/c,n*=l/c),a+r>l&&(c=a+r,a*=l/c,r*=l/c),n+a>h&&(c=n+a,n*=h/c,a*=h/c),i+r>h&&(c=i+r,i*=h/c,r*=h/c),t.moveTo(o+i,s),t.lineTo(o+l-n,s),0!==n&&t.quadraticCurveTo(o+l,s,o+l,s+n),t.lineTo(o+l,s+h-a),0!==a&&t.quadraticCurveTo(o+l,s+h,o+l-a,s+h),t.lineTo(o+r,s+h),0!==r&&t.quadraticCurveTo(o,s+h,o,s+h-r),t.lineTo(o,s+i),0!==i&&t.quadraticCurveTo(o,s,o+i,s)}function Gi(t){return Fi(t),f(t.rich,Fi),t}function Fi(t){if(t){t.font=Bi(t);var e=t.textAlign;"middle"===e&&(e="center"),t.textAlign=null==e||Fx[e]?e:"left";var i=t.textVerticalAlign||t.textBaseline;"center"===i&&(i="middle"),t.textVerticalAlign=null==i||Wx[i]?i:"top";var n=t.textPadding;n&&(t.textPadding=P(t.textPadding))}}function Wi(t,e,i,n,a){n.rich?Zi(t,e,i,n,a):Hi(t,e,i,n,a)}function Hi(t,e,i,n,a){var r=Ji(e,"font",n.font||Vx),o=n.textPadding,s=t.__textCotentBlock;(!s||t.__dirty)&&(s=t.__textCotentBlock=Ei(i,r,o,n.truncate));var l=s.outerHeight,h=s.lines,u=s.lineHeight,c=Ki(l,n,a),d=c.baseX,f=c.baseY,p=c.textAlign,g=c.textVerticalAlign;Xi(e,n,a,d,f);var v=Ai(f,l,g),m=d,y=v,x=Yi(n);if(x||o){var _=bi(i,r),w=_;o&&(w+=o[1]+o[3]);var b=Ti(d,w,p);x&&qi(t,e,n,b,v,w,l),o&&(m=nn(d,p,o),y+=o[0])}Ji(e,"textAlign",p||"left"),Ji(e,"textBaseline","middle"),Ji(e,"shadowBlur",n.textShadowBlur||0),Ji(e,"shadowColor",n.textShadowColor||"transparent"),Ji(e,"shadowOffsetX",n.textShadowOffsetX||0),Ji(e,"shadowOffsetY",n.textShadowOffsetY||0),y+=u/2;var M=n.textStrokeWidth,S=Qi(n.textStroke,M),I=tn(n.textFill);S&&(Ji(e,"lineWidth",M),Ji(e,"strokeStyle",S)),I&&Ji(e,"fillStyle",I);for(var T=0;T<h.length;T++)S&&e.strokeText(h[T],m,y),I&&e.fillText(h[T],m,y),y+=u}function Zi(t,e,i,n,a){var r=t.__textCotentBlock;(!r||t.__dirty)&&(r=t.__textCotentBlock=Ri(i,n)),ji(t,e,r,n,a)}function ji(t,e,i,n,a){var r=i.width,o=i.outerWidth,s=i.outerHeight,l=n.textPadding,h=Ki(s,n,a),u=h.baseX,c=h.baseY,d=h.textAlign,f=h.textVerticalAlign;Xi(e,n,a,u,c);var p=Ti(u,o,d),g=Ai(c,s,f),v=p,m=g;l&&(v+=l[3],m+=l[0]);var y=v+r;Yi(n)&&qi(t,e,n,p,g,o,s);for(var x=0;x<i.lines.length;x++){for(var _,w=i.lines[x],b=w.tokens,M=b.length,S=w.lineHeight,I=w.width,T=0,A=v,C=y,D=M-1;M>T&&(_=b[T],!_.textAlign||"left"===_.textAlign);)Ui(t,e,_,n,S,m,A,"left"),I-=_.width,A+=_.width,T++;for(;D>=0&&(_=b[D],"right"===_.textAlign);)Ui(t,e,_,n,S,m,C,"right"),I-=_.width,C-=_.width,D--;for(A+=(r-(A-v)-(y-C)-I)/2;D>=T;)_=b[T],Ui(t,e,_,n,S,m,A+_.width/2,"center"),A+=_.width,T++;m+=S}}function Xi(t,e,i,n,a){if(i&&e.textRotation){var r=e.textOrigin;"center"===r?(n=i.width/2+i.x,a=i.height/2+i.y):r&&(n=r[0]+i.x,a=r[1]+i.y),t.translate(n,a),t.rotate(-e.textRotation),t.translate(-n,-a)}}function Ui(t,e,i,n,a,r,o,s){var l=n.rich[i.styleName]||{},h=i.textVerticalAlign,u=r+a/2;"top"===h?u=r+i.height/2:"bottom"===h&&(u=r+a-i.height/2),!i.isLineHolder&&Yi(l)&&qi(t,e,l,"right"===s?o-i.width:"center"===s?o-i.width/2:o,u-i.height/2,i.width,i.height);var c=i.textPadding;c&&(o=nn(o,s,c),u-=i.height/2-c[2]-i.textHeight/2),Ji(e,"shadowBlur",L(l.textShadowBlur,n.textShadowBlur,0)),Ji(e,"shadowColor",l.textShadowColor||n.textShadowColor||"transparent"),Ji(e,"shadowOffsetX",L(l.textShadowOffsetX,n.textShadowOffsetX,0)),Ji(e,"shadowOffsetY",L(l.textShadowOffsetY,n.textShadowOffsetY,0)),Ji(e,"textAlign",s),Ji(e,"textBaseline","middle"),Ji(e,"font",i.font||Vx);var d=Qi(l.textStroke||n.textStroke,p),f=tn(l.textFill||n.textFill),p=D(l.textStrokeWidth,n.textStrokeWidth);d&&(Ji(e,"lineWidth",p),Ji(e,"strokeStyle",d),e.strokeText(i.text,o,u)),f&&(Ji(e,"fillStyle",f),e.fillText(i.text,o,u))}function Yi(t){return t.textBackgroundColor||t.textBorderWidth&&t.textBorderColor}function qi(t,e,i,n,a,r,o){var s=i.textBackgroundColor,l=i.textBorderWidth,h=i.textBorderColor,u=b(s);if(Ji(e,"shadowBlur",i.textBoxShadowBlur||0),Ji(e,"shadowColor",i.textBoxShadowColor||"transparent"),Ji(e,"shadowOffsetX",i.textBoxShadowOffsetX||0),Ji(e,"shadowOffsetY",i.textBoxShadowOffsetY||0),u||l&&h){e.beginPath();var c=i.textBorderRadius;c?Vi(e,{x:n,y:a,width:r,height:o,r:c}):e.rect(n,a,r,o),e.closePath()}if(u)Ji(e,"fillStyle",s),e.fill();else if(M(s)){var d=s.image;d=yi(d,null,t,$i,s),d&&_i(d)&&e.drawImage(d,n,a,r,o)}l&&h&&(Ji(e,"lineWidth",l),Ji(e,"strokeStyle",h),e.stroke())}function $i(t,e){e.image=t}function Ki(t,e,i){var n=e.x||0,a=e.y||0,r=e.textAlign,o=e.textVerticalAlign;if(i){var s=e.textPosition;if(s instanceof Array)n=i.x+en(s[0],i.width),a=i.y+en(s[1],i.height);else{var l=Ci(s,i,e.textDistance);n=l.x,a=l.y,r=r||l.textAlign,o=o||l.textVerticalAlign}var h=e.textOffset;h&&(n+=h[0],a+=h[1])}return{baseX:n,baseY:a,textAlign:r,textVerticalAlign:o}}function Ji(t,e,i){return t[e]=Ix(t,e,i),t[e]}function Qi(t,e){return null==t||0>=e||"transparent"===t||"none"===t?null:t.image||t.colorStops?"#000":t}function tn(t){return null==t||"none"===t?null:t.image||t.colorStops?"#000":t}function en(t,e){return"string"==typeof t?t.lastIndexOf("%")>=0?parseFloat(t)/100*e:parseFloat(t):t}function nn(t,e,i){return"right"===e?t-i[1]:"center"===e?t+i[3]/2-i[1]/2:t+i[3]}function an(t,e){return null!=t&&(t||e.textBackgroundColor||e.textBorderWidth&&e.textBorderColor||e.textPadding)}function rn(t){t=t||{},gx.call(this,t);for(var e in t)t.hasOwnProperty(e)&&"style"!==e&&(this[e]=t[e]);this.style=new Ax(t.style,this),this._rect=null,this.__clipPaths=[]}function on(t){rn.call(this,t)}function sn(t){return parseInt(t,10)}function ln(t){return t?t.__builtin__?!0:"function"!=typeof t.resize||"function"!=typeof t.refresh?!1:!0:!1}function hn(t,e,i){return qx.copy(t.getBoundingRect()),t.transform&&qx.applyTransform(t.transform),$x.width=e,$x.height=i,!qx.intersect($x)}function un(t,e){if(t==e)return!1;if(!t||!e||t.length!==e.length)return!0;for(var i=0;i<t.length;i++)if(t[i]!==e[i])return!0}function cn(t,e){for(var i=0;i<t.length;i++){var n=t[i];n.setTransform(e),e.beginPath(),n.buildPath(e,n.shape),e.clip(),n.restoreTransform(e)}}function dn(t,e){var i=document.createElement("div");return i.style.cssText=["position:relative","overflow:hidden","width:"+t+"px","height:"+e+"px","padding:0","margin:0","border-width:0"].join(";")+";",i}function fn(t){return t.getBoundingClientRect?t.getBoundingClientRect():{left:0,top:0}}function pn(t,e,i,n){return i=i||{},n||!vy.canvasSupported?gn(t,e,i):vy.browser.firefox&&null!=e.layerX&&e.layerX!==e.offsetX?(i.zrX=e.layerX,i.zrY=e.layerY):null!=e.offsetX?(i.zrX=e.offsetX,i.zrY=e.offsetY):gn(t,e,i),i}function gn(t,e,i){var n=fn(t);i.zrX=e.clientX-n.left,i.zrY=e.clientY-n.top}function vn(t,e,i){if(e=e||window.event,null!=e.zrX)return e;var n=e.type,a=n&&n.indexOf("touch")>=0;if(a){var r="touchend"!=n?e.targetTouches[0]:e.changedTouches[0];r&&pn(t,r,e,i)}else pn(t,e,e,i),e.zrDelta=e.wheelDelta?e.wheelDelta/120:-(e.detail||0)/3;var o=e.button;return null==e.which&&void 0!==o&&Qx.test(e.type)&&(e.which=1&o?1:2&o?3:4&o?2:0),e}function mn(t,e,i){Jx?t.addEventListener(e,i):t.attachEvent("on"+e,i)}function yn(t,e,i){Jx?t.removeEventListener(e,i):t.detachEvent("on"+e,i)}function xn(t){return t.which>1}function _n(t){var e=t[1][0]-t[0][0],i=t[1][1]-t[0][1];return Math.sqrt(e*e+i*i)}function wn(t){return[(t[0][0]+t[1][0])/2,(t[0][1]+t[1][1])/2]}function bn(t){return"mousewheel"===t&&vy.browser.firefox?"DOMMouseScroll":t}function Mn(t,e,i){var n=t._gestureMgr;"start"===i&&n.clear();var a=n.recognize(e,t.handler.findHover(e.zrX,e.zrY,null).target,t.dom);if("end"===i&&n.clear(),a){var r=a.type;e.gestureEvent=r,t.handler.dispatchToElement({target:a.target},r,a.event)}}function Sn(t){t._touching=!0,clearTimeout(t._touchTimer),t._touchTimer=setTimeout(function(){t._touching=!1},700)}function In(t){var e=t.pointerType;return"pen"===e||"touch"===e}function Tn(t){function e(t,e){return function(){return e._touching?void 0:t.apply(e,arguments)
-}}f(o_,function(e){t._handlers[e]=y(h_[e],t)}),f(l_,function(e){t._handlers[e]=y(h_[e],t)}),f(r_,function(i){t._handlers[i]=e(h_[i],t)})}function An(t){function e(e,i){f(e,function(e){mn(t,bn(e),i._handlers[e])},i)}By.call(this),this.dom=t,this._touching=!1,this._touchTimer,this._gestureMgr=new i_,this._handlers={},Tn(this),vy.pointerEventsSupported?e(l_,this):(vy.touchEventsSupported&&e(o_,this),e(r_,this))}function Cn(t,e){var i=new g_(py(),t,e);return f_[i.id]=i,i}function Dn(t){if(t)t.dispose();else{for(var e in f_)f_.hasOwnProperty(e)&&f_[e].dispose();f_={}}return this}function Ln(t){return f_[t]}function kn(t,e){d_[t]=e}function Pn(t){delete f_[t]}function On(t){return t instanceof Array?t:null==t?[]:[t]}function zn(t,e,i){if(t){t[e]=t[e]||{},t.emphasis=t.emphasis||{},t.emphasis[e]=t.emphasis[e]||{};for(var n=0,a=i.length;a>n;n++){var r=i[n];!t.emphasis[e].hasOwnProperty(r)&&t[e].hasOwnProperty(r)&&(t.emphasis[e][r]=t[e][r])}}}function En(t){return!y_(t)||x_(t)||t instanceof Date?t:t.value}function Rn(t){return y_(t)&&!(t instanceof Array)}function Nn(t,e){e=(e||[]).slice();var i=p(t||[],function(t){return{exist:t}});return m_(e,function(t,n){if(y_(t)){for(var a=0;a<i.length;a++)if(!i[a].option&&null!=t.id&&i[a].exist.id===t.id+"")return i[a].option=t,void(e[n]=null);for(var a=0;a<i.length;a++){var r=i[a].exist;if(!(i[a].option||null!=r.id&&null!=t.id||null==t.name||Vn(t)||Vn(r)||r.name!==t.name+""))return i[a].option=t,void(e[n]=null)}}}),m_(e,function(t){if(y_(t)){for(var e=0;e<i.length;e++){var n=i[e].exist;if(!i[e].option&&!Vn(n)&&null==t.id){i[e].option=t;break}}e>=i.length&&i.push({option:t})}}),i}function Bn(t){var e=B();m_(t,function(t){var i=t.exist;i&&e.set(i.id,t)}),m_(t,function(t){var i=t.option;O(!i||null==i.id||!e.get(i.id)||e.get(i.id)===t,"id duplicates: "+(i&&i.id)),i&&null!=i.id&&e.set(i.id,t),!t.keyInfo&&(t.keyInfo={})}),m_(t,function(t){var i=t.exist,n=t.option,a=t.keyInfo;if(y_(n)){if(a.name=null!=n.name?n.name+"":i?i.name:__,i)a.id=i.id;else if(null!=n.id)a.id=n.id+"";else{var r=0;do a.id="\x00"+a.name+"\x00"+r++;while(e.get(a.id))}e.set(a.id,t)}})}function Vn(t){return y_(t)&&t.id&&0===(t.id+"").indexOf("\x00_ec_\x00")}function Gn(t,e){function i(t,e,i){for(var n=0,a=t.length;a>n;n++)for(var r=t[n].seriesId,o=On(t[n].dataIndex),s=i&&i[r],l=0,h=o.length;h>l;l++){var u=o[l];s&&s[u]?s[u]=null:(e[r]||(e[r]={}))[u]=1}}function n(t,e){var i=[];for(var a in t)if(t.hasOwnProperty(a)&&null!=t[a])if(e)i.push(+a);else{var r=n(t[a],!0);r.length&&i.push({seriesId:a,dataIndex:r})}return i}var a={},r={};return i(t||[],a),i(e||[],r,a),[n(a),n(r)]}function Fn(t,e){return null!=e.dataIndexInside?e.dataIndexInside:null!=e.dataIndex?_(e.dataIndex)?p(e.dataIndex,function(e){return t.indexOfRawIndex(e)}):t.indexOfRawIndex(e.dataIndex):null!=e.name?_(e.name)?p(e.name,function(e){return t.indexOfName(e)}):t.indexOfName(e.name):void 0}function Wn(){var t="__\x00ec_inner_"+b_++ +"_"+Math.random().toFixed(5);return function(e){return e[t]||(e[t]={})}}function Hn(t,e,i){if(b(e)){var n={};n[e+"Index"]=0,e=n}var a=i&&i.defaultMainType;!a||Zn(e,a+"Index")||Zn(e,a+"Id")||Zn(e,a+"Name")||(e[a+"Index"]=0);var r={};return m_(e,function(n,a){var n=e[a];if("dataIndex"===a||"dataIndexInside"===a)return void(r[a]=n);var o=a.match(/^(\w+)(Index|Id|Name)$/)||[],s=o[1],l=(o[2]||"").toLowerCase();if(!(!s||!l||null==n||"index"===l&&"none"===n||i&&i.includeMainTypes&&h(i.includeMainTypes,s)<0)){var u={mainType:s};("index"!==l||"all"!==n)&&(u[l]=n);var c=t.queryComponents(u);r[s+"Models"]=c,r[s+"Model"]=c[0]}}),r}function Zn(t,e){return t&&t.hasOwnProperty(e)}function jn(t,e,i){t.setAttribute?t.setAttribute(e,i):t[e]=i}function Xn(t,e){return t.getAttribute?t.getAttribute(e):t[e]}function Un(t){var e={main:"",sub:""};return t&&(t=t.split(M_),e.main=t[0]||"",e.sub=t[1]||""),e}function Yn(t){O(/^[a-zA-Z0-9_]+([.][a-zA-Z0-9_]+)?$/.test(t),'componentType "'+t+'" illegal')}function qn(t){t.$constructor=t,t.extend=function(t){var e=this,i=function(){t.$constructor?t.$constructor.apply(this,arguments):e.apply(this,arguments)};return o(i.prototype,t),i.extend=this.extend,i.superCall=Kn,i.superApply=Jn,u(i,this),i.superClass=e,i}}function $n(t){var e=["__\x00is_clz",I_++,Math.random().toFixed(3)].join("_");t.prototype[e]=!0,t.isInstance=function(t){return!(!t||!t[e])}}function Kn(t,e){var i=k(arguments,2);return this.superClass.prototype[e].apply(t,i)}function Jn(t,e,i){return this.superClass.prototype[e].apply(t,i)}function Qn(t,e){function i(t){var e=n[t.main];return e&&e[S_]||(e=n[t.main]={},e[S_]=!0),e}e=e||{};var n={};if(t.registerClass=function(t,e){if(e)if(Yn(e),e=Un(e),e.sub){if(e.sub!==S_){var a=i(e);a[e.sub]=t}}else n[e.main]=t;return t},t.getClass=function(t,e,i){var a=n[t];if(a&&a[S_]&&(a=e?a[e]:null),i&&!a)throw new Error(e?"Component "+t+"."+(e||"")+" not exists. Load it first.":t+".type should be specified.");return a},t.getClassesByMainType=function(t){t=Un(t);var e=[],i=n[t.main];return i&&i[S_]?f(i,function(t,i){i!==S_&&e.push(t)}):e.push(i),e},t.hasClass=function(t){return t=Un(t),!!n[t.main]},t.getAllClassMainTypes=function(){var t=[];return f(n,function(e,i){t.push(i)}),t},t.hasSubTypes=function(t){t=Un(t);var e=n[t.main];return e&&e[S_]},t.parseClassType=Un,e.registerWhenExtend){var a=t.extend;a&&(t.extend=function(e){var i=a.call(this,e);return t.registerClass(i,e.type)})}return t}function ta(t){return t>-O_&&O_>t}function ea(t){return t>O_||-O_>t}function ia(t,e,i,n,a){var r=1-a;return r*r*(r*t+3*a*e)+a*a*(a*n+3*r*i)}function na(t,e,i,n,a){var r=1-a;return 3*(((e-t)*r+2*(i-e)*a)*r+(n-i)*a*a)}function aa(t,e,i,n,a,r){var o=n+3*(e-i)-t,s=3*(i-2*e+t),l=3*(e-t),h=t-a,u=s*s-3*o*l,c=s*l-9*o*h,d=l*l-3*s*h,f=0;if(ta(u)&&ta(c))if(ta(s))r[0]=0;else{var p=-l/s;p>=0&&1>=p&&(r[f++]=p)}else{var g=c*c-4*u*d;if(ta(g)){var v=c/u,p=-s/o+v,m=-v/2;p>=0&&1>=p&&(r[f++]=p),m>=0&&1>=m&&(r[f++]=m)}else if(g>0){var y=P_(g),x=u*s+1.5*o*(-c+y),_=u*s+1.5*o*(-c-y);x=0>x?-k_(-x,R_):k_(x,R_),_=0>_?-k_(-_,R_):k_(_,R_);var p=(-s-(x+_))/(3*o);p>=0&&1>=p&&(r[f++]=p)}else{var w=(2*u*s-3*o*c)/(2*P_(u*u*u)),b=Math.acos(w)/3,M=P_(u),S=Math.cos(b),p=(-s-2*M*S)/(3*o),m=(-s+M*(S+E_*Math.sin(b)))/(3*o),I=(-s+M*(S-E_*Math.sin(b)))/(3*o);p>=0&&1>=p&&(r[f++]=p),m>=0&&1>=m&&(r[f++]=m),I>=0&&1>=I&&(r[f++]=I)}}return f}function ra(t,e,i,n,a){var r=6*i-12*e+6*t,o=9*e+3*n-3*t-9*i,s=3*e-3*t,l=0;if(ta(o)){if(ea(r)){var h=-s/r;h>=0&&1>=h&&(a[l++]=h)}}else{var u=r*r-4*o*s;if(ta(u))a[0]=-r/(2*o);else if(u>0){var c=P_(u),h=(-r+c)/(2*o),d=(-r-c)/(2*o);h>=0&&1>=h&&(a[l++]=h),d>=0&&1>=d&&(a[l++]=d)}}return l}function oa(t,e,i,n,a,r){var o=(e-t)*a+t,s=(i-e)*a+e,l=(n-i)*a+i,h=(s-o)*a+o,u=(l-s)*a+s,c=(u-h)*a+h;r[0]=t,r[1]=o,r[2]=h,r[3]=c,r[4]=c,r[5]=u,r[6]=l,r[7]=n}function sa(t,e,i,n,a,r,o,s,l,h,u){var c,d,f,p,g,v=.005,m=1/0;N_[0]=l,N_[1]=h;for(var y=0;1>y;y+=.05)B_[0]=ia(t,i,a,o,y),B_[1]=ia(e,n,r,s,y),p=Ey(N_,B_),m>p&&(c=y,m=p);m=1/0;for(var x=0;32>x&&!(z_>v);x++)d=c-v,f=c+v,B_[0]=ia(t,i,a,o,d),B_[1]=ia(e,n,r,s,d),p=Ey(B_,N_),d>=0&&m>p?(c=d,m=p):(V_[0]=ia(t,i,a,o,f),V_[1]=ia(e,n,r,s,f),g=Ey(V_,N_),1>=f&&m>g?(c=f,m=g):v*=.5);return u&&(u[0]=ia(t,i,a,o,c),u[1]=ia(e,n,r,s,c)),P_(m)}function la(t,e,i,n){var a=1-n;return a*(a*t+2*n*e)+n*n*i}function ha(t,e,i,n){return 2*((1-n)*(e-t)+n*(i-e))}function ua(t,e,i,n,a){var r=t-2*e+i,o=2*(e-t),s=t-n,l=0;if(ta(r)){if(ea(o)){var h=-s/o;h>=0&&1>=h&&(a[l++]=h)}}else{var u=o*o-4*r*s;if(ta(u)){var h=-o/(2*r);h>=0&&1>=h&&(a[l++]=h)}else if(u>0){var c=P_(u),h=(-o+c)/(2*r),d=(-o-c)/(2*r);h>=0&&1>=h&&(a[l++]=h),d>=0&&1>=d&&(a[l++]=d)}}return l}function ca(t,e,i){var n=t+i-2*e;return 0===n?.5:(t-e)/n}function da(t,e,i,n,a){var r=(e-t)*n+t,o=(i-e)*n+e,s=(o-r)*n+r;a[0]=t,a[1]=r,a[2]=s,a[3]=s,a[4]=o,a[5]=i}function fa(t,e,i,n,a,r,o,s,l){var h,u=.005,c=1/0;N_[0]=o,N_[1]=s;for(var d=0;1>d;d+=.05){B_[0]=la(t,i,a,d),B_[1]=la(e,n,r,d);var f=Ey(N_,B_);c>f&&(h=d,c=f)}c=1/0;for(var p=0;32>p&&!(z_>u);p++){var g=h-u,v=h+u;B_[0]=la(t,i,a,g),B_[1]=la(e,n,r,g);var f=Ey(B_,N_);if(g>=0&&c>f)h=g,c=f;else{V_[0]=la(t,i,a,v),V_[1]=la(e,n,r,v);var m=Ey(V_,N_);1>=v&&c>m?(h=v,c=m):u*=.5}}return l&&(l[0]=la(t,i,a,h),l[1]=la(e,n,r,h)),P_(c)}function pa(t,e,i){if(0!==t.length){var n,a=t[0],r=a[0],o=a[0],s=a[1],l=a[1];for(n=1;n<t.length;n++)a=t[n],r=G_(r,a[0]),o=F_(o,a[0]),s=G_(s,a[1]),l=F_(l,a[1]);e[0]=r,e[1]=s,i[0]=o,i[1]=l}}function ga(t,e,i,n,a,r){a[0]=G_(t,i),a[1]=G_(e,n),r[0]=F_(t,i),r[1]=F_(e,n)}function va(t,e,i,n,a,r,o,s,l,h){var u,c=ra,d=ia,f=c(t,i,a,o,Y_);for(l[0]=1/0,l[1]=1/0,h[0]=-1/0,h[1]=-1/0,u=0;f>u;u++){var p=d(t,i,a,o,Y_[u]);l[0]=G_(p,l[0]),h[0]=F_(p,h[0])}for(f=c(e,n,r,s,q_),u=0;f>u;u++){var g=d(e,n,r,s,q_[u]);l[1]=G_(g,l[1]),h[1]=F_(g,h[1])}l[0]=G_(t,l[0]),h[0]=F_(t,h[0]),l[0]=G_(o,l[0]),h[0]=F_(o,h[0]),l[1]=G_(e,l[1]),h[1]=F_(e,h[1]),l[1]=G_(s,l[1]),h[1]=F_(s,h[1])}function ma(t,e,i,n,a,r,o,s){var l=ca,h=la,u=F_(G_(l(t,i,a),1),0),c=F_(G_(l(e,n,r),1),0),d=h(t,i,a,u),f=h(e,n,r,c);o[0]=G_(t,a,d),o[1]=G_(e,r,f),s[0]=F_(t,a,d),s[1]=F_(e,r,f)}function ya(t,e,i,n,a,r,o,s,l){var h=oe,u=se,c=Math.abs(a-r);if(1e-4>c%Z_&&c>1e-4)return s[0]=t-i,s[1]=e-n,l[0]=t+i,void(l[1]=e+n);if(j_[0]=H_(a)*i+t,j_[1]=W_(a)*n+e,X_[0]=H_(r)*i+t,X_[1]=W_(r)*n+e,h(s,j_,X_),u(l,j_,X_),a%=Z_,0>a&&(a+=Z_),r%=Z_,0>r&&(r+=Z_),a>r&&!o?r+=Z_:r>a&&o&&(a+=Z_),o){var d=r;r=a,a=d}for(var f=0;r>f;f+=Math.PI/2)f>a&&(U_[0]=H_(f)*i+t,U_[1]=W_(f)*n+e,h(s,U_,s),u(l,U_,l))}function xa(t,e,i,n,a,r,o){if(0===a)return!1;var s=a,l=0,h=t;if(o>e+s&&o>n+s||e-s>o&&n-s>o||r>t+s&&r>i+s||t-s>r&&i-s>r)return!1;if(t===i)return Math.abs(r-t)<=s/2;l=(e-n)/(t-i),h=(t*n-i*e)/(t-i);var u=l*r-o+h,c=u*u/(l*l+1);return s/2*s/2>=c}function _a(t,e,i,n,a,r,o,s,l,h,u){if(0===l)return!1;var c=l;if(u>e+c&&u>n+c&&u>r+c&&u>s+c||e-c>u&&n-c>u&&r-c>u&&s-c>u||h>t+c&&h>i+c&&h>a+c&&h>o+c||t-c>h&&i-c>h&&a-c>h&&o-c>h)return!1;var d=sa(t,e,i,n,a,r,o,s,h,u,null);return c/2>=d}function wa(t,e,i,n,a,r,o,s,l){if(0===o)return!1;var h=o;if(l>e+h&&l>n+h&&l>r+h||e-h>l&&n-h>l&&r-h>l||s>t+h&&s>i+h&&s>a+h||t-h>s&&i-h>s&&a-h>s)return!1;var u=fa(t,e,i,n,a,r,s,l,null);return h/2>=u}function ba(t){return t%=hw,0>t&&(t+=hw),t}function Ma(t,e,i,n,a,r,o,s,l){if(0===o)return!1;var h=o;s-=t,l-=e;var u=Math.sqrt(s*s+l*l);if(u-h>i||i>u+h)return!1;if(Math.abs(n-a)%uw<1e-4)return!0;if(r){var c=n;n=ba(a),a=ba(c)}else n=ba(n),a=ba(a);n>a&&(a+=uw);var d=Math.atan2(l,s);return 0>d&&(d+=uw),d>=n&&a>=d||d+uw>=n&&a>=d+uw}function Sa(t,e,i,n,a,r){if(r>e&&r>n||e>r&&n>r)return 0;if(n===e)return 0;var o=e>n?1:-1,s=(r-e)/(n-e);(1===s||0===s)&&(o=e>n?.5:-.5);var l=s*(i-t)+t;return l>a?o:0}function Ia(t,e){return Math.abs(t-e)<fw}function Ta(){var t=gw[0];gw[0]=gw[1],gw[1]=t}function Aa(t,e,i,n,a,r,o,s,l,h){if(h>e&&h>n&&h>r&&h>s||e>h&&n>h&&r>h&&s>h)return 0;var u=aa(e,n,r,s,h,pw);if(0===u)return 0;for(var c,d,f=0,p=-1,g=0;u>g;g++){var v=pw[g],m=0===v||1===v?.5:1,y=ia(t,i,a,o,v);l>y||(0>p&&(p=ra(e,n,r,s,gw),gw[1]<gw[0]&&p>1&&Ta(),c=ia(e,n,r,s,gw[0]),p>1&&(d=ia(e,n,r,s,gw[1]))),f+=2==p?v<gw[0]?e>c?m:-m:v<gw[1]?c>d?m:-m:d>s?m:-m:v<gw[0]?e>c?m:-m:c>s?m:-m)}return f}function Ca(t,e,i,n,a,r,o,s){if(s>e&&s>n&&s>r||e>s&&n>s&&r>s)return 0;var l=ua(e,n,r,s,pw);if(0===l)return 0;var h=ca(e,n,r);if(h>=0&&1>=h){for(var u=0,c=la(e,n,r,h),d=0;l>d;d++){var f=0===pw[d]||1===pw[d]?.5:1,p=la(t,i,a,pw[d]);o>p||(u+=pw[d]<h?e>c?f:-f:c>r?f:-f)}return u}var f=0===pw[0]||1===pw[0]?.5:1,p=la(t,i,a,pw[0]);return o>p?0:e>r?f:-f}function Da(t,e,i,n,a,r,o,s){if(s-=e,s>i||-i>s)return 0;var l=Math.sqrt(i*i-s*s);pw[0]=-l,pw[1]=l;var h=Math.abs(n-a);if(1e-4>h)return 0;if(1e-4>h%dw){n=0,a=dw;var u=r?1:-1;return o>=pw[0]+t&&o<=pw[1]+t?u:0}if(r){var l=n;n=ba(a),a=ba(l)}else n=ba(n),a=ba(a);n>a&&(a+=dw);for(var c=0,d=0;2>d;d++){var f=pw[d];if(f+t>o){var p=Math.atan2(s,f),u=r?1:-1;0>p&&(p=dw+p),(p>=n&&a>=p||p+dw>=n&&a>=p+dw)&&(p>Math.PI/2&&p<1.5*Math.PI&&(u=-u),c+=u)}}return c}function La(t,e,i,n,a){for(var r=0,o=0,s=0,l=0,h=0,u=0;u<t.length;){var c=t[u++];switch(c===cw.M&&u>1&&(i||(r+=Sa(o,s,l,h,n,a))),1==u&&(o=t[u],s=t[u+1],l=o,h=s),c){case cw.M:l=t[u++],h=t[u++],o=l,s=h;break;case cw.L:if(i){if(xa(o,s,t[u],t[u+1],e,n,a))return!0}else r+=Sa(o,s,t[u],t[u+1],n,a)||0;o=t[u++],s=t[u++];break;case cw.C:if(i){if(_a(o,s,t[u++],t[u++],t[u++],t[u++],t[u],t[u+1],e,n,a))return!0}else r+=Aa(o,s,t[u++],t[u++],t[u++],t[u++],t[u],t[u+1],n,a)||0;o=t[u++],s=t[u++];break;case cw.Q:if(i){if(wa(o,s,t[u++],t[u++],t[u],t[u+1],e,n,a))return!0}else r+=Ca(o,s,t[u++],t[u++],t[u],t[u+1],n,a)||0;o=t[u++],s=t[u++];break;case cw.A:var d=t[u++],f=t[u++],p=t[u++],g=t[u++],v=t[u++],m=t[u++],y=(t[u++],1-t[u++]),x=Math.cos(v)*p+d,_=Math.sin(v)*g+f;u>1?r+=Sa(o,s,x,_,n,a):(l=x,h=_);var w=(n-d)*g/p+d;if(i){if(Ma(d,f,g,v,v+m,y,e,w,a))return!0}else r+=Da(d,f,g,v,v+m,y,w,a);o=Math.cos(v+m)*p+d,s=Math.sin(v+m)*g+f;break;case cw.R:l=o=t[u++],h=s=t[u++];var b=t[u++],M=t[u++],x=l+b,_=h+M;if(i){if(xa(l,h,x,h,e,n,a)||xa(x,h,x,_,e,n,a)||xa(x,_,l,_,e,n,a)||xa(l,_,l,h,e,n,a))return!0}else r+=Sa(x,h,x,_,n,a),r+=Sa(l,_,l,h,n,a);break;case cw.Z:if(i){if(xa(o,s,l,h,e,n,a))return!0}else r+=Sa(o,s,l,h,n,a);o=l,s=h}}return i||Ia(s,h)||(r+=Sa(o,s,l,h,n,a)||0),0!==r}function ka(t,e,i){return La(t,0,!1,e,i)}function Pa(t,e,i,n){return La(t,e,!0,i,n)}function Oa(t){rn.call(this,t),this.path=null}function za(t,e,i,n,a,r,o,s,l,h,u){var c=l*(Cw/180),d=Aw(c)*(t-i)/2+Tw(c)*(e-n)/2,f=-1*Tw(c)*(t-i)/2+Aw(c)*(e-n)/2,p=d*d/(o*o)+f*f/(s*s);p>1&&(o*=Iw(p),s*=Iw(p));var g=(a===r?-1:1)*Iw((o*o*s*s-o*o*f*f-s*s*d*d)/(o*o*f*f+s*s*d*d))||0,v=g*o*f/s,m=g*-s*d/o,y=(t+i)/2+Aw(c)*v-Tw(c)*m,x=(e+n)/2+Tw(c)*v+Aw(c)*m,_=kw([1,0],[(d-v)/o,(f-m)/s]),w=[(d-v)/o,(f-m)/s],b=[(-1*d-v)/o,(-1*f-m)/s],M=kw(w,b);Lw(w,b)<=-1&&(M=Cw),Lw(w,b)>=1&&(M=0),0===r&&M>0&&(M-=2*Cw),1===r&&0>M&&(M+=2*Cw),u.addData(h,y,x,o,s,_,M,c,r)}function Ea(t){if(!t)return[];var e,i=t.replace(/-/g," -").replace(/  /g," ").replace(/ /g,",").replace(/,,/g,",");for(e=0;e<Sw.length;e++)i=i.replace(new RegExp(Sw[e],"g"),"|"+Sw[e]);var n,a=i.split("|"),r=0,o=0,s=new lw,l=lw.CMD;for(e=1;e<a.length;e++){var h,u=a[e],c=u.charAt(0),d=0,f=u.slice(1).replace(/e,-/g,"e-").split(",");f.length>0&&""===f[0]&&f.shift();for(var p=0;p<f.length;p++)f[p]=parseFloat(f[p]);for(;d<f.length&&!isNaN(f[d])&&!isNaN(f[0]);){var g,v,m,y,x,_,w,b=r,M=o;switch(c){case"l":r+=f[d++],o+=f[d++],h=l.L,s.addData(h,r,o);break;case"L":r=f[d++],o=f[d++],h=l.L,s.addData(h,r,o);break;case"m":r+=f[d++],o+=f[d++],h=l.M,s.addData(h,r,o),c="l";break;case"M":r=f[d++],o=f[d++],h=l.M,s.addData(h,r,o),c="L";break;case"h":r+=f[d++],h=l.L,s.addData(h,r,o);break;case"H":r=f[d++],h=l.L,s.addData(h,r,o);break;case"v":o+=f[d++],h=l.L,s.addData(h,r,o);break;case"V":o=f[d++],h=l.L,s.addData(h,r,o);break;case"C":h=l.C,s.addData(h,f[d++],f[d++],f[d++],f[d++],f[d++],f[d++]),r=f[d-2],o=f[d-1];break;case"c":h=l.C,s.addData(h,f[d++]+r,f[d++]+o,f[d++]+r,f[d++]+o,f[d++]+r,f[d++]+o),r+=f[d-2],o+=f[d-1];break;case"S":g=r,v=o;var S=s.len(),I=s.data;n===l.C&&(g+=r-I[S-4],v+=o-I[S-3]),h=l.C,b=f[d++],M=f[d++],r=f[d++],o=f[d++],s.addData(h,g,v,b,M,r,o);break;case"s":g=r,v=o;var S=s.len(),I=s.data;n===l.C&&(g+=r-I[S-4],v+=o-I[S-3]),h=l.C,b=r+f[d++],M=o+f[d++],r+=f[d++],o+=f[d++],s.addData(h,g,v,b,M,r,o);break;case"Q":b=f[d++],M=f[d++],r=f[d++],o=f[d++],h=l.Q,s.addData(h,b,M,r,o);break;case"q":b=f[d++]+r,M=f[d++]+o,r+=f[d++],o+=f[d++],h=l.Q,s.addData(h,b,M,r,o);break;case"T":g=r,v=o;var S=s.len(),I=s.data;n===l.Q&&(g+=r-I[S-4],v+=o-I[S-3]),r=f[d++],o=f[d++],h=l.Q,s.addData(h,g,v,r,o);break;case"t":g=r,v=o;var S=s.len(),I=s.data;n===l.Q&&(g+=r-I[S-4],v+=o-I[S-3]),r+=f[d++],o+=f[d++],h=l.Q,s.addData(h,g,v,r,o);break;case"A":m=f[d++],y=f[d++],x=f[d++],_=f[d++],w=f[d++],b=r,M=o,r=f[d++],o=f[d++],h=l.A,za(b,M,r,o,_,w,m,y,x,h,s);break;case"a":m=f[d++],y=f[d++],x=f[d++],_=f[d++],w=f[d++],b=r,M=o,r+=f[d++],o+=f[d++],h=l.A,za(b,M,r,o,_,w,m,y,x,h,s)}}("z"===c||"Z"===c)&&(h=l.Z,s.addData(h)),n=h}return s.toStatic(),s}function Ra(t,e){var i=Ea(t);return e=e||{},e.buildPath=function(t){if(t.setData){t.setData(i.data);var e=t.getContext();e&&t.rebuildPath(e)}else{var e=t;i.rebuildPath(e)}},e.applyTransform=function(t){Mw(i,t),this.dirty(!0)},e}function Na(t,e){return new Oa(Ra(t,e))}function Ba(t,e){return Oa.extend(Ra(t,e))}function Va(t,e){for(var i=[],n=t.length,a=0;n>a;a++){var r=t[a];r.path||r.createPathProxy(),r.__dirtyPath&&r.buildPath(r.path,r.shape,!0),i.push(r.path)}var o=new Oa(e);return o.createPathProxy(),o.buildPath=function(t){t.appendPath(i);var e=t.getContext();e&&t.rebuildPath(e)},o}function Ga(t,e,i,n,a,r,o){var s=.5*(i-t),l=.5*(n-e);return(2*(e-i)+s+l)*o+(-3*(e-i)-2*s-l)*r+s*a+e}function Fa(t,e,i){var n=e.points,a=e.smooth;if(n&&n.length>=2){if(a&&"spline"!==a){var r=Vw(n,a,i,e.smoothConstraint);t.moveTo(n[0][0],n[0][1]);for(var o=n.length,s=0;(i?o:o-1)>s;s++){var l=r[2*s],h=r[2*s+1],u=n[(s+1)%o];t.bezierCurveTo(l[0],l[1],h[0],h[1],u[0],u[1])}}else{"spline"===a&&(n=Bw(n,i)),t.moveTo(n[0][0],n[0][1]);for(var s=1,c=n.length;c>s;s++)t.lineTo(n[s][0],n[s][1])}i&&t.closePath()}}function Wa(t,e,i){var n=t.cpx2,a=t.cpy2;return null===n||null===a?[(i?na:ia)(t.x1,t.cpx1,t.cpx2,t.x2,e),(i?na:ia)(t.y1,t.cpy1,t.cpy2,t.y2,e)]:[(i?ha:la)(t.x1,t.cpx1,t.x2,e),(i?ha:la)(t.y1,t.cpy1,t.y2,e)]}function Ha(t){rn.call(this,t),this._displayables=[],this._temporaryDisplayables=[],this._cursor=0,this.notClear=!0}function Za(t){return Oa.extend(t)}function ja(t,e){return Ba(t,e)}function Xa(t,e,i,n){var a=Na(t,e),r=a.getBoundingRect();return i&&("center"===n&&(i=Ya(i,r)),qa(a,i)),a}function Ua(t,e,i){var n=new on({style:{image:t,x:e.x,y:e.y,width:e.width,height:e.height},onload:function(t){if("center"===i){var a={width:t.width,height:t.height};n.setStyle(Ya(e,a))}}});return n}function Ya(t,e){var i,n=e.width/e.height,a=t.height*n;a<=t.width?i=t.height:(a=t.width,i=a/n);var r=t.x+t.width/2,o=t.y+t.height/2;return{x:r-a/2,y:o-i/2,width:a,height:i}}function qa(t,e){if(t.applyTransform){var i=t.getBoundingRect(),n=i.calculateTransform(e);t.applyTransform(n)}}function $a(t){var e=t.shape,i=t.style.lineWidth;return Jw(2*e.x1)===Jw(2*e.x2)&&(e.x1=e.x2=Ja(e.x1,i,!0)),Jw(2*e.y1)===Jw(2*e.y2)&&(e.y1=e.y2=Ja(e.y1,i,!0)),t}function Ka(t){var e=t.shape,i=t.style.lineWidth,n=e.x,a=e.y,r=e.width,o=e.height;return e.x=Ja(e.x,i,!0),e.y=Ja(e.y,i,!0),e.width=Math.max(Ja(n+r,i,!1)-e.x,0===r?0:1),e.height=Math.max(Ja(a+o,i,!1)-e.y,0===o?0:1),t}function Ja(t,e,i){var n=Jw(2*t);return(n+Jw(e))%2===0?n/2:(n+(i?1:-1))/2}function Qa(t){return null!=t&&"none"!=t}function tr(t){return"string"==typeof t?Ne(t,-.1):t}function er(t){if(t.__hoverStlDirty){var e=t.style.stroke,i=t.style.fill,n=t.__hoverStl;n.fill=n.fill||(Qa(i)?tr(i):null),n.stroke=n.stroke||(Qa(e)?tr(e):null);var a={};for(var r in n)null!=n[r]&&(a[r]=t.style[r]);t.__normalStl=a,t.__hoverStlDirty=!1}}function ir(t){if(!t.__isHover){if(er(t),t.useHoverLayer)t.__zr&&t.__zr.addHover(t,t.__hoverStl);else{var e=t.style,i=e.insideRollbackOpt;i&&_r(e),e.extendFrom(t.__hoverStl),i&&(xr(e,e.insideOriginalTextPosition,i),null==e.textFill&&(e.textFill=i.autoColor)),t.dirty(!1),t.z2+=1}t.__isHover=!0}}function nr(t){if(t.__isHover){var e=t.__normalStl;t.useHoverLayer?t.__zr&&t.__zr.removeHover(t):(e&&t.setStyle(e),t.z2-=1),t.__isHover=!1}}function ar(t){"group"===t.type?t.traverse(function(t){"group"!==t.type&&ir(t)}):ir(t)}function rr(t){"group"===t.type?t.traverse(function(t){"group"!==t.type&&nr(t)}):nr(t)}function or(t,e){t.__hoverStl=t.hoverStyle||e||{},t.__hoverStlDirty=!0,t.__isHover&&er(t)}function sr(t){this.__hoverSilentOnTouch&&t.zrByTouch||!this.__isEmphasis&&ar(this)}function lr(t){this.__hoverSilentOnTouch&&t.zrByTouch||!this.__isEmphasis&&rr(this)}function hr(){this.__isEmphasis=!0,ar(this)}function ur(){this.__isEmphasis=!1,rr(this)}function cr(t,e,i){t.__hoverSilentOnTouch=i&&i.hoverSilentOnTouch,"group"===t.type?t.traverse(function(t){"group"!==t.type&&or(t,e)}):or(t,e),t.on("mouseover",sr).on("mouseout",lr),t.on("emphasis",hr).on("normal",ur)}function dr(t,e,i,n,a,r,o){a=a||eb;var s,l=a.labelFetcher,h=a.labelDataIndex,u=a.labelDimIndex,c=i.getShallow("show"),d=n.getShallow("show");(c||d)&&(l&&(s=l.getFormattedLabel(h,"normal",null,u)),null==s&&(s=w(a.defaultText)?a.defaultText(h,a):a.defaultText));var f=c?s:null,p=d?D(l?l.getFormattedLabel(h,"emphasis",null,u):null,s):null;(null!=f||null!=p)&&(fr(t,i,r,a),fr(e,n,o,a,!0)),t.text=f,e.text=p}function fr(t,e,i,n,a){return gr(t,e,n,a),i&&o(t,i),t.host&&t.host.dirty&&t.host.dirty(!1),t}function pr(t,e,i){var n,a={isRectText:!0};i===!1?n=!0:a.autoColor=i,gr(t,e,a,n),t.host&&t.host.dirty&&t.host.dirty(!1)}function gr(t,e,i,n){if(i=i||eb,i.isRectText){var a=e.getShallow("position")||(n?null:"inside");"outside"===a&&(a="top"),t.textPosition=a,t.textOffset=e.getShallow("offset");var r=e.getShallow("rotate");null!=r&&(r*=Math.PI/180),t.textRotation=r,t.textDistance=D(e.getShallow("distance"),n?null:5)}var o,s=e.ecModel,l=s&&s.option.textStyle,h=vr(e);if(h){o={};for(var u in h)if(h.hasOwnProperty(u)){var c=e.getModel(["rich",u]);mr(o[u]={},c,l,i,n)}}return t.rich=o,mr(t,e,l,i,n,!0),i.forceRich&&!i.textStyle&&(i.textStyle={}),t}function vr(t){for(var e;t&&t!==t.ecModel;){var i=(t.option||eb).rich;if(i){e=e||{};for(var n in i)i.hasOwnProperty(n)&&(e[n]=1)}t=t.parentModel}return e}function mr(t,e,i,n,a,r){if(i=!a&&i||eb,t.textFill=yr(e.getShallow("color"),n)||i.color,t.textStroke=yr(e.getShallow("textBorderColor"),n)||i.textBorderColor,t.textStrokeWidth=D(e.getShallow("textBorderWidth"),i.textBorderWidth),!a){if(r){var o=t.textPosition;t.insideRollback=xr(t,o,n),t.insideOriginalTextPosition=o,t.insideRollbackOpt=n}null==t.textFill&&(t.textFill=n.autoColor)}t.fontStyle=e.getShallow("fontStyle")||i.fontStyle,t.fontWeight=e.getShallow("fontWeight")||i.fontWeight,t.fontSize=e.getShallow("fontSize")||i.fontSize,t.fontFamily=e.getShallow("fontFamily")||i.fontFamily,t.textAlign=e.getShallow("align"),t.textVerticalAlign=e.getShallow("verticalAlign")||e.getShallow("baseline"),t.textLineHeight=e.getShallow("lineHeight"),t.textWidth=e.getShallow("width"),t.textHeight=e.getShallow("height"),t.textTag=e.getShallow("tag"),r&&n.disableBox||(t.textBackgroundColor=yr(e.getShallow("backgroundColor"),n),t.textPadding=e.getShallow("padding"),t.textBorderColor=yr(e.getShallow("borderColor"),n),t.textBorderWidth=e.getShallow("borderWidth"),t.textBorderRadius=e.getShallow("borderRadius"),t.textBoxShadowColor=e.getShallow("shadowColor"),t.textBoxShadowBlur=e.getShallow("shadowBlur"),t.textBoxShadowOffsetX=e.getShallow("shadowOffsetX"),t.textBoxShadowOffsetY=e.getShallow("shadowOffsetY")),t.textShadowColor=e.getShallow("textShadowColor")||i.textShadowColor,t.textShadowBlur=e.getShallow("textShadowBlur")||i.textShadowBlur,t.textShadowOffsetX=e.getShallow("textShadowOffsetX")||i.textShadowOffsetX,t.textShadowOffsetY=e.getShallow("textShadowOffsetY")||i.textShadowOffsetY}function yr(t,e){return"auto"!==t?t:e&&e.autoColor?e.autoColor:null}function xr(t,e,i){var n,a=i.useInsideStyle;return null==t.textFill&&a!==!1&&(a===!0||i.isRectText&&e&&"string"==typeof e&&e.indexOf("inside")>=0)&&(n={textFill:null,textStroke:t.textStroke,textStrokeWidth:t.textStrokeWidth},t.textFill="#fff",null==t.textStroke&&(t.textStroke=i.autoColor,null==t.textStrokeWidth&&(t.textStrokeWidth=2))),n}function _r(t){var e=t.insideRollback;e&&(t.textFill=e.textFill,t.textStroke=e.textStroke,t.textStrokeWidth=e.textStrokeWidth)}function wr(t,e){var i=e||e.getModel("textStyle");return z([t.fontStyle||i&&i.getShallow("fontStyle")||"",t.fontWeight||i&&i.getShallow("fontWeight")||"",(t.fontSize||i&&i.getShallow("fontSize")||12)+"px",t.fontFamily||i&&i.getShallow("fontFamily")||"sans-serif"].join(" "))}function br(t,e,i,n,a,r){"function"==typeof a&&(r=a,a=null);var o=n&&n.isAnimationEnabled();if(o){var s=t?"Update":"",l=n.getShallow("animationDuration"+s),h=n.getShallow("animationEasing"+s),u=n.getShallow("animationDelay"+s);"function"==typeof u&&(u=u(a,n.getAnimationDelayParams?n.getAnimationDelayParams(e,a):null)),"function"==typeof l&&(l=l(a)),l>0?e.animateTo(i,l,u||0,h,r,!!r):(e.stopAnimation(),e.attr(i),r&&r())}else e.stopAnimation(),e.attr(i),r&&r()}function Mr(t,e,i,n,a){br(!0,t,e,i,n,a)}function Sr(t,e,i,n,a){br(!1,t,e,i,n,a)}function Ir(t,e){for(var i=pe([]);t&&t!==e;)ve(i,t.getLocalTransform(),i),t=t.parent;return i}function Tr(t,e,i){return e&&!d(e)&&(e=Xy.getLocalTransform(e)),i&&(e=_e([],e)),re([],t,e)}function Ar(t,e,i){var n=0===e[4]||0===e[5]||0===e[0]?1:Math.abs(2*e[4]/e[0]),a=0===e[4]||0===e[5]||0===e[2]?1:Math.abs(2*e[4]/e[2]),r=["left"===t?-n:"right"===t?n:0,"top"===t?-a:"bottom"===t?a:0];return r=Tr(r,e,i),Math.abs(r[0])>Math.abs(r[1])?r[0]>0?"right":"left":r[1]>0?"bottom":"top"}function Cr(t,e,i){function n(t){var e={};return t.traverse(function(t){!t.isGroup&&t.anid&&(e[t.anid]=t)}),e}function a(t){var e={position:H(t.position),rotation:t.rotation};return t.shape&&(e.shape=o({},t.shape)),e}if(t&&e){var r=n(t);e.traverse(function(t){if(!t.isGroup&&t.anid){var e=r[t.anid];if(e){var n=a(t);t.attr(a(e)),Mr(t,n,i,t.dataIndex)}}})}}function Dr(t,e){return p(t,function(t){var i=t[0];i=Qw(i,e.x),i=tb(i,e.x+e.width);var n=t[1];return n=Qw(n,e.y),n=tb(n,e.y+e.height),[i,n]})}function Lr(t,e){var i=Qw(t.x,e.x),n=tb(t.x+t.width,e.x+e.width),a=Qw(t.y,e.y),r=tb(t.y+t.height,e.y+e.height);return n>=i&&r>=a?{x:i,y:a,width:n-i,height:r-a}:void 0}function kr(t,e,i){e=o({rectHover:!0},e);var n=e.style={strokeNoScale:!0};return i=i||{x:-1,y:-1,width:2,height:2},t?0===t.indexOf("image://")?(n.image=t.slice(8),s(n,i),new on(e)):Xa(t.replace("path://",""),e,i,"center"):void 0}function Pr(t,e,i){this.parentModel=e,this.ecModel=i,this.option=t}function Or(t,e,i){for(var n=0;n<e.length&&(!e[n]||(t=t&&"object"==typeof t?t[e[n]]:null,null!=t));n++);return null==t&&i&&(t=i.get(e)),t}function zr(t,e){var i=hb(t).getParent;return i?i.call(t,e):t.parentModel}function Er(t){return[t||"",ub++,Math.random().toFixed(5)].join("_")}function Rr(t){var e={};return t.registerSubTypeDefaulter=function(t,i){t=Un(t),e[t.main]=i},t.determineSubType=function(i,n){var a=n.type;if(!a){var r=Un(i).main;t.hasSubTypes(i)&&e[r]&&(a=e[r](n))}return a},t}function Nr(t,e){function i(t){var i={},r=[];return f(t,function(o){var s=n(i,o),l=s.originalDeps=e(o),u=a(l,t);s.entryCount=u.length,0===s.entryCount&&r.push(o),f(u,function(t){h(s.predecessor,t)<0&&s.predecessor.push(t);var e=n(i,t);h(e.successor,t)<0&&e.successor.push(o)})}),{graph:i,noEntryList:r}}function n(t,e){return t[e]||(t[e]={predecessor:[],successor:[]}),t[e]}function a(t,e){var i=[];return f(t,function(t){h(e,t)>=0&&i.push(t)}),i}t.topologicalTravel=function(t,e,n,a){function r(t){l[t].entryCount--,0===l[t].entryCount&&h.push(t)}function o(t){u[t]=!0,r(t)}if(t.length){var s=i(e),l=s.graph,h=s.noEntryList,u={};for(f(t,function(t){u[t]=!0});h.length;){var c=h.pop(),d=l[c],p=!!u[c];p&&(n.call(a,c,d.originalDeps.slice()),delete u[c]),f(d.successor,p?o:r)}f(u,function(){throw new Error("Circle dependency may exists")})}}}function Br(t){return t.replace(/^\s+/,"").replace(/\s+$/,"")}function Vr(t,e,i,n){var a=e[1]-e[0],r=i[1]-i[0];if(0===a)return 0===r?i[0]:(i[0]+i[1])/2;if(n)if(a>0){if(t<=e[0])return i[0];if(t>=e[1])return i[1]}else{if(t>=e[0])return i[0];if(t<=e[1])return i[1]}else{if(t===e[0])return i[0];if(t===e[1])return i[1]}return(t-e[0])/a*r+i[0]}function Gr(t,e){switch(t){case"center":case"middle":t="50%";break;case"left":case"top":t="0%";break;case"right":case"bottom":t="100%"}return"string"==typeof t?Br(t).match(/%$/)?parseFloat(t)/100*e:parseFloat(t):null==t?0/0:+t}function Fr(t,e,i){return null==e&&(e=10),e=Math.min(Math.max(0,e),20),t=(+t).toFixed(e),i?t:+t}function Wr(t){return t.sort(function(t,e){return t-e}),t}function Hr(t){if(t=+t,isNaN(t))return 0;for(var e=1,i=0;Math.round(t*e)/e!==t;)e*=10,i++;return i}function Zr(t){var e=t.toString(),i=e.indexOf("e");if(i>0){var n=+e.slice(i+1);return 0>n?-n:0}var a=e.indexOf(".");return 0>a?0:e.length-1-a}function jr(t,e){var i=Math.log,n=Math.LN10,a=Math.floor(i(t[1]-t[0])/n),r=Math.round(i(Math.abs(e[1]-e[0]))/n),o=Math.min(Math.max(-a+r,0),20);return isFinite(o)?o:20}function Xr(t,e,i){if(!t[e])return 0;var n=g(t,function(t,e){return t+(isNaN(e)?0:e)},0);if(0===n)return 0;for(var a=Math.pow(10,i),r=p(t,function(t){return(isNaN(t)?0:t)/n*a*100}),o=100*a,s=p(r,function(t){return Math.floor(t)}),l=g(s,function(t,e){return t+e},0),h=p(r,function(t,e){return t-s[e]});o>l;){for(var u=Number.NEGATIVE_INFINITY,c=null,d=0,f=h.length;f>d;++d)h[d]>u&&(u=h[d],c=d);++s[c],h[c]=0,++l}return s[e]/a}function Ur(t){var e=2*Math.PI;return(t%e+e)%e}function Yr(t){return t>-cb&&cb>t}function qr(t){if(t instanceof Date)return t;if("string"==typeof t){var e=fb.exec(t);if(!e)return new Date(0/0);if(e[8]){var i=+e[4]||0;return"Z"!==e[8].toUpperCase()&&(i-=e[8].slice(0,3)),new Date(Date.UTC(+e[1],+(e[2]||1)-1,+e[3]||1,i,+(e[5]||0),+e[6]||0,+e[7]||0))}return new Date(+e[1],+(e[2]||1)-1,+e[3]||1,+e[4]||0,+(e[5]||0),+e[6]||0,+e[7]||0)}return new Date(null==t?0/0:Math.round(t))}function $r(t){return Math.pow(10,Kr(t))}function Kr(t){return Math.floor(Math.log(t)/Math.LN10)}function Jr(t,e){var i,n=Kr(t),a=Math.pow(10,n),r=t/a;return i=e?1.5>r?1:2.5>r?2:4>r?3:7>r?5:10:1>r?1:2>r?2:3>r?3:5>r?5:10,t=i*a,n>=-20?+t.toFixed(0>n?-n:0):t}function Qr(t){function e(t,i,n){return t.interval[n]<i.interval[n]||t.interval[n]===i.interval[n]&&(t.close[n]-i.close[n]===(n?-1:1)||!n&&e(t,i,1))}t.sort(function(t,i){return e(t,i,0)?-1:1});for(var i=-1/0,n=1,a=0;a<t.length;){for(var r=t[a].interval,o=t[a].close,s=0;2>s;s++)r[s]<=i&&(r[s]=i,o[s]=s?1:1-n),i=r[s],n=o[s];r[0]===r[1]&&o[0]*o[1]!==1?t.splice(a,1):a++}return t}function to(t){return t-parseFloat(t)>=0}function eo(t){return isNaN(t)?"-":(t=(t+"").split("."),t[0].replace(/(\d{1,3})(?=(?:\d{3})+(?!\d))/g,"$1,")+(t.length>1?"."+t[1]:""))}function io(t,e){return t=(t||"").toLowerCase().replace(/-(.)/g,function(t,e){return e.toUpperCase()}),e&&t&&(t=t.charAt(0).toUpperCase()+t.slice(1)),t}function no(t){return String(t).replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;").replace(/"/g,"&quot;").replace(/'/g,"&#39;")}function ao(t,e,i){_(e)||(e=[e]);var n=e.length;if(!n)return"";for(var a=e[0].$vars||[],r=0;r<a.length;r++){var o=vb[r];t=t.replace(mb(o),mb(o,0))}for(var s=0;n>s;s++)for(var l=0;l<a.length;l++){var h=e[s][a[l]];t=t.replace(mb(vb[l],s),i?no(h):h)}return t}function ro(t,e,i){return f(e,function(e,n){t=t.replace("{"+n+"}",i?no(e):e)}),t}function oo(t,e){t=b(t)?{color:t,extraCssText:e}:t||{};var i=t.color,n=t.type,e=t.extraCssText;return i?"subItem"===n?'<span style="display:inline-block;vertical-align:middle;margin-right:8px;margin-left:3px;border-radius:4px;width:4px;height:4px;background-color:'+no(i)+";"+(e||"")+'"></span>':'<span style="display:inline-block;margin-right:5px;border-radius:10px;width:10px;height:10px;background-color:'+no(i)+";"+(e||"")+'"></span>':""}function so(t,e,i){("week"===t||"month"===t||"quarter"===t||"half-year"===t||"year"===t)&&(t="MM-dd\nyyyy");var n=qr(e),a=i?"UTC":"",r=n["get"+a+"FullYear"](),o=n["get"+a+"Month"]()+1,s=n["get"+a+"Date"](),l=n["get"+a+"Hours"](),h=n["get"+a+"Minutes"](),u=n["get"+a+"Seconds"]();return t=t.replace("MM",yb(o)).replace("M",o).replace("yyyy",r).replace("yy",r%100).replace("dd",yb(s)).replace("d",s).replace("hh",yb(l)).replace("h",l).replace("mm",yb(h)).replace("m",h).replace("ss",yb(u)).replace("s",u)}function lo(t){return t?t.charAt(0).toUpperCase()+t.substr(1):t}function ho(t,e,i,n,a){var r=0,o=0;null==n&&(n=1/0),null==a&&(a=1/0);var s=0;e.eachChild(function(l,h){var u,c,d=l.position,f=l.getBoundingRect(),p=e.childAt(h+1),g=p&&p.getBoundingRect();if("horizontal"===t){var v=f.width+(g?-g.x+f.x:0);u=r+v,u>n||l.newline?(r=0,u=v,o+=s+i,s=f.height):s=Math.max(s,f.height)}else{var m=f.height+(g?-g.y+f.y:0);c=o+m,c>a||l.newline?(r+=s+i,o=0,c=m,s=f.width):s=Math.max(s,f.width)}l.newline||(d[0]=r,d[1]=o,"horizontal"===t?r=u+i:o=c+i)})}function uo(t,e,i){i=gb(i||0);var n=e.width,a=e.height,r=Gr(t.left,n),o=Gr(t.top,a),s=Gr(t.right,n),l=Gr(t.bottom,a),h=Gr(t.width,n),u=Gr(t.height,a),c=i[2]+i[0],d=i[1]+i[3],f=t.aspect;
-switch(isNaN(h)&&(h=n-s-d-r),isNaN(u)&&(u=a-l-c-o),null!=f&&(isNaN(h)&&isNaN(u)&&(f>n/a?h=.8*n:u=.8*a),isNaN(h)&&(h=f*u),isNaN(u)&&(u=h/f)),isNaN(r)&&(r=n-s-h-d),isNaN(o)&&(o=a-l-u-c),t.left||t.right){case"center":r=n/2-h/2-i[3];break;case"right":r=n-h-d}switch(t.top||t.bottom){case"middle":case"center":o=a/2-u/2-i[0];break;case"bottom":o=a-u-c}r=r||0,o=o||0,isNaN(h)&&(h=n-d-r-(s||0)),isNaN(u)&&(u=a-c-o-(l||0));var p=new ni(r+i[3],o+i[0],h,u);return p.margin=i,p}function co(t,e,i,n,a){var r=!a||!a.hv||a.hv[0],o=!a||!a.hv||a.hv[1],l=a&&a.boundingMode||"all";if(r||o){var h;if("raw"===l)h="group"===t.type?new ni(0,0,+e.width||0,+e.height||0):t.getBoundingRect();else if(h=t.getBoundingRect(),t.needLocalTransform()){var u=t.getLocalTransform();h=h.clone(),h.applyTransform(u)}e=uo(s({width:h.width,height:h.height},e),i,n);var c=t.position,d=r?e.x-h.x:0,f=o?e.y-h.y:0;t.attr("position","raw"===l?[d,f]:[c[0]+d,c[1]+f])}}function fo(t,e){return null!=t[Sb[e][0]]||null!=t[Sb[e][1]]&&null!=t[Sb[e][2]]}function po(t,e,i){function n(i,n){var o={},l=0,h={},u=0,c=2;if(bb(i,function(e){h[e]=t[e]}),bb(i,function(t){a(e,t)&&(o[t]=h[t]=e[t]),r(o,t)&&l++,r(h,t)&&u++}),s[n])return r(e,i[1])?h[i[2]]=null:r(e,i[2])&&(h[i[1]]=null),h;if(u!==c&&l){if(l>=c)return o;for(var d=0;d<i.length;d++){var f=i[d];if(!a(o,f)&&a(t,f)){o[f]=t[f];break}}return o}return h}function a(t,e){return t.hasOwnProperty(e)}function r(t,e){return null!=t[e]&&"auto"!==t[e]}function o(t,e,i){bb(t,function(t){e[t]=i[t]})}!M(i)&&(i={});var s=i.ignoreSize;!_(s)&&(s=[s,s]);var l=n(Sb[0],0),h=n(Sb[1],1);o(Sb[0],t,l),o(Sb[1],t,h)}function go(t){return vo({},t)}function vo(t,e){return e&&t&&bb(Mb,function(i){e.hasOwnProperty(i)&&(t[i]=e[i])}),t}function mo(t){var e=[];return f(Cb.getClassesByMainType(t),function(t){e=e.concat(t.prototype.dependencies||[])}),e=p(e,function(t){return Un(t).main}),"dataset"!==t&&h(e,"dataset")<=0&&e.unshift("dataset"),e}function yo(t,e){for(var i=t.length,n=0;i>n;n++)if(t[n].length>e)return t[n];return t[i-1]}function xo(t){var e=t.get("coordinateSystem"),i={coordSysName:e,coordSysDims:[],axisMap:B(),categoryAxisMap:B()},n=Ob[e];return n?(n(t,i,i.axisMap,i.categoryAxisMap),i):void 0}function _o(t){return"category"===t.get("type")}function wo(t){this.fromDataset=t.fromDataset,this.data=t.data||(t.sourceFormat===Nb?{}:[]),this.sourceFormat=t.sourceFormat||Bb,this.seriesLayoutBy=t.seriesLayoutBy||Gb,this.dimensionsDefine=t.dimensionsDefine,this.encodeDefine=t.encodeDefine&&B(t.encodeDefine),this.startIndex=t.startIndex||0,this.dimensionsDetectCount=t.dimensionsDetectCount}function bo(t){return Wb(t).source}function Mo(t){Wb(t).datasetMap=B()}function So(t){var e=t.option,i=e.data,n=I(i)?Vb:zb,a=!1,r=e.seriesLayoutBy,o=e.sourceHeader,s=e.dimensions,l=Lo(t);if(l){var h=l.option;i=h.source,n=Wb(l).sourceFormat,a=!0,r=r||h.seriesLayoutBy,null==o&&(o=h.sourceHeader),s=s||h.dimensions}var u=Io(i,n,r,o,s),c=e.encode;!c&&l&&(c=Do(t,l,i,n,r,u)),Wb(t).source=new wo({data:i,fromDataset:a,seriesLayoutBy:r,sourceFormat:n,dimensionsDefine:u.dimensionsDefine,startIndex:u.startIndex,dimensionsDetectCount:u.dimensionsDetectCount,encodeDefine:c})}function Io(t,e,i,n,a){if(!t)return{dimensionsDefine:To(a)};var r,o,s;if(e===Eb)"auto"===n||null==n?Ao(function(t){null!=t&&"-"!==t&&(b(t)?null==o&&(o=1):o=0)},i,t,10):o=n?1:0,a||1!==o||(a=[],Ao(function(t,e){a[e]=null!=t?t:""},i,t)),r=a?a.length:i===Fb?t.length:t[0]?t[0].length:null;else if(e===Rb)a||(a=Co(t),s=!0);else if(e===Nb)a||(a=[],s=!0,f(t,function(t,e){a.push(e)}));else if(e===zb){var l=En(t[0]);r=_(l)&&l.length||1}var h;return s&&f(a,function(t,e){"name"===(M(t)?t.name:t)&&(h=e)}),{startIndex:o,dimensionsDefine:To(a),dimensionsDetectCount:r,potentialNameDimIndex:h}}function To(t){if(t){var e=B();return p(t,function(t){if(t=o({},M(t)?t:{name:t}),null==t.name)return t;t.name+="",null==t.displayName&&(t.displayName=t.name);var i=e.get(t.name);return i?t.name+="-"+i.count++:e.set(t.name,{count:1}),t})}}function Ao(t,e,i,n){if(null==n&&(n=1/0),e===Fb)for(var a=0;a<i.length&&n>a;a++)t(i[a]?i[a][0]:null,a);else for(var r=i[0]||[],a=0;a<r.length&&n>a;a++)t(r[a],a)}function Co(t){for(var e,i=0;i<t.length&&!(e=t[i++]););if(e){var n=[];return f(e,function(t,e){n.push(e)}),n}}function Do(t,e,i,n,a,r){var o=xo(t),s={},l=[],h=[],u=t.subType,c=B(["pie","map","funnel"]),d=B(["line","bar","pictorialBar","scatter","effectScatter","candlestick","boxplot"]);if(o&&null!=d.get(u)){var p=t.ecModel,g=Wb(p).datasetMap,v=e.uid+"_"+a,m=g.get(v)||g.set(v,{categoryWayDim:1,valueWayDim:0});f(o.coordSysDims,function(t){if(null==o.firstCategoryDimIndex){var e=m.valueWayDim++;s[t]=e,h.push(e)}else if(o.categoryAxisMap.get(t))s[t]=0,l.push(0);else{var e=m.categoryWayDim++;s[t]=e,h.push(e)}})}else if(null!=c.get(u)){for(var y,x=0;5>x&&null==y;x++)Po(i,n,a,r.dimensionsDefine,r.startIndex,x)||(y=x);if(null!=y){s.value=y;var _=r.potentialNameDimIndex||Math.max(y-1,0);h.push(_),l.push(_)}}return l.length&&(s.itemName=l),h.length&&(s.seriesName=h),s}function Lo(t){var e=t.option,i=e.data;return i?void 0:t.ecModel.getComponent("dataset",e.datasetIndex||0)}function ko(t,e){return Po(t.data,t.sourceFormat,t.seriesLayoutBy,t.dimensionsDefine,t.startIndex,e)}function Po(t,e,i,n,a,r){function o(t){return null!=t&&isFinite(t)&&""!==t?!1:b(t)&&"-"!==t?!0:void 0}var s,l=5;if(I(t))return!1;var h;if(n&&(h=n[r],h=M(h)?h.name:h),e===Eb)if(i===Fb){for(var u=t[r],c=0;c<(u||[]).length&&l>c;c++)if(null!=(s=o(u[a+c])))return s}else for(var c=0;c<t.length&&l>c;c++){var d=t[a+c];if(d&&null!=(s=o(d[r])))return s}else if(e===Rb){if(!h)return;for(var c=0;c<t.length&&l>c;c++){var f=t[c];if(f&&null!=(s=o(f[h])))return s}}else if(e===Nb){if(!h)return;var u=t[h];if(!u||I(u))return!1;for(var c=0;c<u.length&&l>c;c++)if(null!=(s=o(u[c])))return s}else if(e===zb)for(var c=0;c<t.length&&l>c;c++){var f=t[c],p=En(f);if(!_(p))return!1;if(null!=(s=o(p[r])))return s}return!1}function Oo(t,e){if(e){var i=e.seiresIndex,n=e.seriesId,a=e.seriesName;return null!=i&&t.componentIndex!==i||null!=n&&t.id!==n||null!=a&&t.name!==a}}function zo(t,e){f(e,function(e,i){Cb.hasClass(i)||("object"==typeof e?t[i]=t[i]?a(t[i],e,!1):n(e):null==t[i]&&(t[i]=e))})}function Eo(t){t=t,this.option={},this.option[Hb]=1,this._componentsMap=B({series:[]}),this._seriesIndices,this._seriesIndicesMap,zo(t,this._theme.option),a(t,Lb,!1),this.mergeOption(t)}function Ro(t,e){_(e)||(e=e?[e]:[]);var i={};return f(e,function(e){i[e]=(t.get(e)||[]).slice()}),i}function No(t,e,i){var n=e.type?e.type:i?i.subType:Cb.determineSubType(t,e);return n}function Bo(t,e){t._seriesIndicesMap=B(t._seriesIndices=p(e,function(t){return t.componentIndex})||[])}function Vo(t,e){return e.hasOwnProperty("subType")?v(t,function(t){return t.subType===e.subType}):t}function Go(t){f(jb,function(e){this[e]=y(t[e],t)},this)}function Fo(){this._coordinateSystems=[]}function Wo(t){this._api=t,this._timelineOptions=[],this._mediaList=[],this._mediaDefault,this._currentMediaIndices=[],this._optionBackup,this._newBaseOption}function Ho(t,e,i){var n,a,r=[],o=[],s=t.timeline;if(t.baseOption&&(a=t.baseOption),(s||t.options)&&(a=a||{},r=(t.options||[]).slice()),t.media){a=a||{};var l=t.media;Ub(l,function(t){t&&t.option&&(t.query?o.push(t):n||(n=t))})}return a||(a=t),a.timeline||(a.timeline=s),Ub([a].concat(r).concat(p(o,function(t){return t.option})),function(t){Ub(e,function(e){e(t,i)})}),{baseOption:a,timelineOptions:r,mediaDefault:n,mediaList:o}}function Zo(t,e,i){var n={width:e,height:i,aspectratio:e/i},a=!0;return f(t,function(t,e){var i=e.match(Kb);if(i&&i[1]&&i[2]){var r=i[1],o=i[2].toLowerCase();jo(n[o],t,r)||(a=!1)}}),a}function jo(t,e,i){return"min"===i?t>=e:"max"===i?e>=t:t===e}function Xo(t,e){return t.join(",")===e.join(",")}function Uo(t,e){e=e||{},Ub(e,function(e,i){if(null!=e){var n=t[i];if(Cb.hasClass(i)){e=On(e),n=On(n);var a=Nn(n,e);t[i]=qb(a,function(t){return t.option&&t.exist?$b(t.exist,t.option,!0):t.exist||t.option})}else t[i]=$b(n,e,!0)}})}function Yo(t){var e=t&&t.itemStyle;if(e)for(var i=0,n=tM.length;n>i;i++){var r=tM[i],o=e.normal,s=e.emphasis;o&&o[r]&&(t[r]=t[r]||{},t[r].normal?a(t[r].normal,o[r]):t[r].normal=o[r],o[r]=null),s&&s[r]&&(t[r]=t[r]||{},t[r].emphasis?a(t[r].emphasis,s[r]):t[r].emphasis=s[r],s[r]=null)}}function qo(t,e){if(t&&t[e]&&(t[e].normal||t[e].emphasis)){var i=t[e].normal,n=t[e].emphasis;i&&(t[e]=i),n&&(t.emphasis=t.emphasis||{},t.emphasis[e]=n)}}function $o(t){qo(t,"itemStyle"),qo(t,"lineStyle"),qo(t,"areaStyle"),qo(t,"label"),qo(t,"labelLine"),qo(t,"upperLabel"),qo(t,"edgeLabel")}function Ko(t){var e=Qb(t)&&t.textStyle;if(e)for(var i=0,n=w_.length;n>i;i++){var a=w_[i];e.hasOwnProperty(a)&&(t[a]=e[a])}}function Jo(t){t&&($o(t),Ko(t.label),t.emphasis&&Ko(t.emphasis.label))}function Qo(t){if(Qb(t)){Yo(t),$o(t),Ko(t.label),Ko(t.upperLabel),Ko(t.edgeLabel),t.emphasis&&(Ko(t.emphasis.label),Ko(t.emphasis.upperLabel),Ko(t.emphasis.edgeLabel));var e=t.markPoint;e&&(Yo(e),Jo(e));var i=t.markLine;i&&(Yo(i),Jo(i));var n=t.markArea;n&&Jo(n);var a=t.data;if("graph"===t.type){a=a||t.nodes;var r=t.links||t.edges;if(r&&!I(r))for(var o=0;o<r.length;o++)Jo(r[o]);f(t.categories,function(t){$o(t)})}if(a&&!I(a))for(var o=0;o<a.length;o++)Jo(a[o]);var e=t.markPoint;if(e&&e.data)for(var s=e.data,o=0;o<s.length;o++)Jo(s[o]);var i=t.markLine;if(i&&i.data)for(var l=i.data,o=0;o<l.length;o++)_(l[o])?(Jo(l[o][0]),Jo(l[o][1])):Jo(l[o]);"gauge"===t.type?(Ko(t,"axisLabel"),Ko(t,"title"),Ko(t,"detail")):"treemap"===t.type&&(qo(t.breadcrumb,"itemStyle"),f(t.levels,function(t){$o(t)}))}}function ts(t){return _(t)?t:t?[t]:[]}function es(t){return(_(t)?t[0]:t)||{}}function is(t,e){e=e.split(",");for(var i=t,n=0;n<e.length&&(i=i&&i[e[n]],null!=i);n++);return i}function ns(t,e,i,n){e=e.split(",");for(var a,r=t,o=0;o<e.length-1;o++)a=e[o],null==r[a]&&(r[a]={}),r=r[a];(n||null==r[e[o]])&&(r[e[o]]=i)}function as(t){f(iM,function(e){e[0]in t&&!(e[1]in t)&&(t[e[1]]=t[e[0]])})}function rs(t,e){wo.isInstance(t)||(t=wo.seriesDataToSource(t)),this._source=t;var i=this._data=t.data,n=t.sourceFormat;n===Vb&&(this._offset=0,this._dimSize=e,this._data=i);var a=oM[n===Eb?n+"_"+t.seriesLayoutBy:n];o(this,a)}function os(){return this._data.length}function ss(t){return this._data[t]}function ls(t){for(var e=0;e<t.length;e++)this._data.push(t[e])}function hs(t,e,i){return null!=i?t[i]:t}function us(t,e,i,n){return cs(t[n],this._dimensionInfos[e])}function cs(t,e){var i=e&&e.type;if("ordinal"===i){var n=e&&e.ordinalMeta;return n?n.parseAndCollect(t):t}return"time"===i&&"number"!=typeof t&&null!=t&&"-"!==t&&(t=+qr(t)),null==t||""===t?0/0:+t}function ds(t,e,i){if(t){var n=t.getRawDataItem(e);if(null!=n){var a,r,o=t.getProvider().getSource().sourceFormat,s=t.getDimensionInfo(i);return s&&(a=s.name,r=s.index),sM[o](n,e,r,a)}}}function fs(t){return new ps(t)}function ps(t){t=t||{},this._reset=t.reset,this._plan=t.plan,this._count=t.count,this._onDirty=t.onDirty,this._dirty=!0,this.context}function gs(t,e){t._dueIndex=t._outputDueEnd=t._dueEnd=0,t._settedOutputEnd=null,t._progress=!e&&t._reset&&t._reset(t.context);var i=t._downstream;i&&i.dirty()}function vs(t){var e=t.name;__===e&&(t.name=ms(t)||e)}function ms(t){var e=t.getRawData(),i=e.mapDimension("seriesName",!0),n=[];return f(i,function(t){var i=e.getDimensionInfo(t);i.displayName&&n.push(i.displayName)}),n.join(" ")}function ys(t){return t.model.getRawData().count()}function xs(t){var e=t.model;return e.setData(e.getRawData().cloneShallow()),_s}function _s(t,e){t.end>e.outputData.count()&&e.model.getRawData().cloneShallow(e.outputData)}function ws(t,e){f(t.CHANGABLE_METHODS,function(i){t.wrapMethod(i,x(bs,e))})}function bs(t){var e=Ms(t);e&&e.setOutputEnd(this.count())}function Ms(t){var e=(t.ecModel||{}).scheduler,i=e&&e.getPipeline(t.uid);if(i){var n=i.currentTask;if(n){var a=n.agentStubMap;a&&(n=a.get(t.uid))}return n}}function Ss(){this.group=new xx,this.uid=Er("viewChart"),this.renderTask=fs({plan:As,reset:Cs}),this.renderTask.context={view:this}}function Is(t,e){if(t&&(t.trigger(e),"group"===t.type))for(var i=0;i<t.childCount();i++)Is(t.childAt(i),e)}function Ts(t,e,i){var n=Fn(t,e);null!=n?f(On(n),function(e){Is(t.getItemGraphicEl(e),i)}):t.eachItemGraphicEl(function(t){Is(t,i)})}function As(t){return yM(t.model)}function Cs(t){var e=t.model,i=t.ecModel,n=t.api,a=t.payload,r=e.pipelineContext.incrementalRender,o=t.view,s=a&&mM(a).updateMethod,l=r&&o.incrementalPrepareRender?"incrementalPrepareRender":s&&o[s]?s:"render";return o[l](e,i,n,a),r?Ds:null}function Ds(t,e){e.view.incrementalRender(t,e.model,e.ecModel,e.api,e.payload)}function Ls(t,e,i){function n(){u=(new Date).getTime(),c=null,t.apply(o,s||[])}var a,r,o,s,l,h=0,u=0,c=null;e=e||0;var d=function(){a=(new Date).getTime(),o=this,s=arguments;var t=l||e,d=l||i;l=null,r=a-(d?h:u)-t,clearTimeout(c),d?c=setTimeout(n,t):r>=0?n():c=setTimeout(n,-r),h=a};return d.clear=function(){c&&(clearTimeout(c),c=null)},d.debounceNextCall=function(t){l=t},d}function ks(t,e,i,n){var a=t[e];if(a){var r=a[_M]||a,o=a[bM],s=a[wM];if(s!==i||o!==n){if(null==i||!n)return t[e]=r;a=t[e]=Ls(r,i,"debounce"===n),a[_M]=r,a[bM]=n,a[wM]=i}return a}}function Ps(t,e){var i=t[e];i&&i[_M]&&(t[e]=i[_M])}function Os(t,e){this.ecInstance=t,this.api=e,this.unfinished,this._stageTaskMap=B()}function zs(t,e,i,n,a){function r(t,e){return t.setDirty&&(!t.dirtyMap||t.dirtyMap.get(e.__pipeline.id))}a=a||{};var o;f(e,function(e){if(!a.visualType||a.visualType===e.visualType){var s=t._stageTaskMap.get(e.uid),l=s.seriesTaskMap,h=s.overallTask;if(h){var u,c=h.agentStubMap;c.each(function(t){r(a,t)&&(t.dirty(),u=!0)}),u&&h.dirty(),DM(h,n);var d=t.getPerformArgs(h,a.block);c.each(function(t){t.perform(d)}),o|=h.perform(d)}else l&&l.each(function(s){r(a,s)&&s.dirty();var l=t.getPerformArgs(s,a.block);l.skip=!e.performRawSeries&&i.isSeriesFiltered(s.context.model),DM(s,n),o|=s.perform(l)})}}),t.unfinished|=o}function Es(t,e,i,n,a){function r(i){var r=i.uid,s=o.get(r)||o.set(r,fs({plan:Fs,reset:Ws,count:Zs}));s.context={model:i,ecModel:n,api:a,useClearVisual:e.isVisual&&!e.isLayout,plan:e.plan,reset:e.reset,scheduler:t},js(t,i,s)}var o=i.seriesTaskMap||(i.seriesTaskMap=B()),s=e.seriesType,l=e.getTargetSeries;e.createOnAllSeries?n.eachRawSeries(r):s?n.eachRawSeriesByType(s,r):l&&l(n,a).each(r);var h=t._pipelineMap;o.each(function(t,e){h.get(e)||(t.dispose(),o.removeKey(e))})}function Rs(t,e,i,n,a){function r(e){var i=e.uid,n=s.get(i)||s.set(i,fs({reset:Bs,onDirty:Gs}));n.context={model:e,overallProgress:u,isOverallFilter:c},n.agent=o,n.__block=u,js(t,e,n)}var o=i.overallTask=i.overallTask||fs({reset:Ns});o.context={ecModel:n,api:a,overallReset:e.overallReset,scheduler:t};var s=o.agentStubMap=o.agentStubMap||B(),l=e.seriesType,h=e.getTargetSeries,u=!0,c=e.isOverallFilter;l?n.eachRawSeriesByType(l,r):h?h(n,a).each(r):(u=!1,f(n.getSeries(),r));var d=t._pipelineMap;s.each(function(t,e){d.get(e)||(t.dispose(),s.removeKey(e))})}function Ns(t){t.overallReset(t.ecModel,t.api,t.payload)}function Bs(t){return t.overallProgress&&Vs}function Vs(){this.agent.dirty(),this.getDownstream().dirty()}function Gs(){this.agent&&this.agent.dirty()}function Fs(t){return t.plan&&t.plan(t.model,t.ecModel,t.api,t.payload)}function Ws(t){t.useClearVisual&&t.data.clearAllVisual();var e=t.resetDefines=On(t.reset(t.model,t.ecModel,t.api,t.payload));return e.length?Hs:void 0}function Hs(t,e){for(var i=e.data,n=e.resetDefines,a=0;a<n.length;a++){var r=n[a];if(r&&r.dataEach)for(var o=t.start;o<t.end;o++)r.dataEach(i,o);else r&&r.progress&&r.progress(t,i)}}function Zs(t){return t.data.count()}function js(t,e,i){var n=e.uid,a=t._pipelineMap.get(n);!a.head&&(a.head=i),a.tail&&a.tail.pipe(i),a.tail=i,i.__idxInPipeline=a.count++,i.__pipeline=a}function Xs(t){LM=null;try{t(kM,PM)}catch(e){}return LM}function Us(t,e){for(var i in e.prototype)t[i]=G}function Ys(t){return function(e,i,n){e=e&&e.toLowerCase(),By.prototype[t].call(this,e,i,n)}}function qs(){By.call(this)}function $s(t,e,i){function a(t,e){return t.__prio-e.__prio}i=i||{},"string"==typeof e&&(e=pS[e]),this.id,this.group,this._dom=t;var r="canvas",o=this._zr=Cn(t,{renderer:i.renderer||r,devicePixelRatio:i.devicePixelRatio,width:i.width,height:i.height});this._throttledZrFlush=Ls(y(o.flush,o),17);var e=n(e);e&&aM(e,!0),this._theme=e,this._chartsViews=[],this._chartsMap={},this._componentsViews=[],this._componentsMap={},this._coordSysMgr=new Fo;var s=this._api=gl(this);this._scheduler=new Os(this,s),By.call(this),this._messageCenter=new qs,this._initEvents(),this.resize=y(this.resize,this),this._pendingActions=[],ci(fS,a),ci(uS,a),o.animation.on("frame",this._onframe,this),E(this)}function Ks(t,e,i){var n,a=this._model,r=this._coordSysMgr.getCoordinateSystems();e=Hn(a,e);for(var o=0;o<r.length;o++){var s=r[o];if(s[t]&&null!=(n=s[t](a,e,i)))return n}}function Js(t){var e=t._model,i=t._scheduler;i.restorePipelines(e),i.prepareStageTasks(uS),i.prepareStageTasks(fS),rl(t,"component",e,i),rl(t,"chart",e,i),i.plan()}function Qs(t,e,i,n,a){function r(n){n&&n.__alive&&n[e]&&n[e](n.__model,o,t._api,i)}var o=t._model;if(!n)return void GM(t._componentsViews.concat(t._chartsViews),r);var s={};s[n+"Id"]=i[n+"Id"],s[n+"Index"]=i[n+"Index"],s[n+"Name"]=i[n+"Name"];var l={mainType:n,query:s};a&&(l.subType=a),o&&o.eachComponent(l,function(e){r(t["series"===n?"_chartsMap":"_componentsMap"][e.__viewId])},t)}function tl(t,e,i){t[eS]=!0,e&&Js(t),oS.update.call(t),t[eS]=!1,nl.call(t,i),al.call(t,i)}function el(t,e){var i=t._chartsMap,n=t._scheduler;e.eachSeries(function(t){n.updateStreamModes(t,i[t.__viewId])})}function il(t,e){var i=t.type,n=t.escapeConnect,a=lS[i],r=a.actionInfo,l=(r.update||"update").split(":"),h=l.pop();l=null!=l[0]&&HM(l[0]),this[eS]=!0;var u=[t],c=!1;t.batch&&(c=!0,u=p(t.batch,function(e){return e=s(o({},e),t),e.batch=null,e}));var d,f=[],g="highlight"===i||"downplay"===i;GM(u,function(t){d=a.action(t,this._model,this._api),d=d||o({},t),d.type=r.event||d.type,f.push(d),g?Qs(this,h,t,"series"):l&&Qs(this,h,t,l.main,l.sub)},this),"none"===h||g||l||(this[nS]?(Js(this),oS.update.call(this,t),this[nS]=!1):oS[h].call(this,t)),d=c?{type:r.event||i,escapeConnect:n,batch:f}:f[0],this[eS]=!1,!e&&this._messageCenter.trigger(d.type,d)}function nl(t){for(var e=this._pendingActions;e.length;){var i=e.shift();il.call(this,i,t)}}function al(t){!t&&this.trigger("updated")}function rl(t,e,i,n){function a(t){var e="_ec_"+t.id+"_"+t.type,a=s[e];if(!a){var u=HM(t.type),c=r?pM.getClass(u.main,u.sub):Ss.getClass(u.sub);a=new c,a.init(i,h),s[e]=a,o.push(a),l.add(a.group)}t.__viewId=a.__id=e,a.__alive=!0,a.__model=t,a.group.__ecComponentInfo={mainType:t.mainType,index:t.componentIndex},!r&&n.prepareView(a,t,i,h)}for(var r="component"===e,o=r?t._componentsViews:t._chartsViews,s=r?t._componentsMap:t._chartsMap,l=t._zr,h=t._api,u=0;u<o.length;u++)o[u].__alive=!1;r?i.eachComponent(function(t,e){"series"!==t&&a(e)}):i.eachSeries(a);for(var u=0;u<o.length;){var c=o[u];c.__alive?u++:(!r&&c.renderTask.dispose(),l.remove(c.group),c.dispose(i,h),o.splice(u,1),delete s[c.__id],c.__id=c.group.__ecComponentInfo=null)}}function ol(t){var e={};t.eachSeries(function(t){var i=t.get("stack"),n=t.getData();if(i&&"list"===n.type){var a=e[i];e.hasOwnProperty(i)&&a&&(n.stackedOn=a),e[i]=n}})}function sl(t){t.clearColorPalette(),t.eachSeries(function(t){t.clearColorPalette()})}function ll(t,e,i,n){hl(t,e,i,n),GM(t._chartsViews,function(t){t.__alive=!1}),ul(t,e,i,n),GM(t._chartsViews,function(t){t.__alive||t.remove(e,i)})}function hl(t,e,i,n,a){GM(a||t._componentsViews,function(t){var a=t.__model;t.render(a,e,i,n),pl(a,t)})}function ul(t,e,i,n,a){var r,o=t._scheduler;e.eachSeries(function(e){var i=t._chartsMap[e.__viewId];i.__alive=!0;var s=i.renderTask;o.updatePayload(s,n),a&&a.get(e.uid)&&s.dirty(),r|=s.perform(o.getPerformArgs(s)),i.group.silent=!!e.get("silent"),pl(e,i),fl(e,i)}),o.unfinished|=r,dl(t._zr,e),IM(t._zr.dom,e)}function cl(t,e){GM(dS,function(i){i(t,e)})}function dl(t,e){var i=t.storage,n=0;i.traverse(function(t){t.isGroup||n++}),n>e.get("hoverLayerThreshold")&&!vy.node&&i.traverse(function(t){t.isGroup||(t.useHoverLayer=!0)})}function fl(t,e){var i=t.get("blendMode")||null;e.group.traverse(function(t){t.isGroup||t.style.blend!==i&&t.setStyle("blend",i),t.eachPendingDisplayable&&t.eachPendingDisplayable(function(t){t.setStyle("blend",i)})})}function pl(t,e){var i=t.get("z"),n=t.get("zlevel");e.group.traverse(function(t){"group"!==t.type&&(null!=i&&(t.z=i),null!=n&&(t.zlevel=n))})}function gl(t){var e=t._coordSysMgr;return o(new Go(t),{getCoordinateSystems:y(e.getCoordinateSystems,e),getComponentByElement:function(e){for(;e;){var i=e.__ecComponentInfo;if(null!=i)return t._model.getComponent(i.mainType,i.index);e=e.parent}}})}function vl(t){function e(t,e){for(var i=0;i<t.length;i++){var n=t[i];n[r]=e}}var i=0,n=1,a=2,r="__connectUpdateStatus";GM(hS,function(o,s){t._messageCenter.on(s,function(o){if(mS[t.group]&&t[r]!==i){if(o&&o.escapeConnect)return;var s=t.makeActionFromEvent(o),l=[];GM(vS,function(e){e!==t&&e.group===t.group&&l.push(e)}),e(l,i),GM(l,function(t){t[r]!==n&&t.dispatchAction(s)}),e(l,a)}})})}function ml(t,e,i){var n=wl(t);if(n)return n;var a=new $s(t,e,i);return a.id="ec_"+yS++,vS[a.id]=a,jn(t,_S,a.id),vl(a),a}function yl(t){if(_(t)){var e=t;t=null,GM(e,function(e){null!=e.group&&(t=e.group)}),t=t||"g_"+xS++,GM(e,function(e){e.group=t})}return mS[t]=!0,t}function xl(t){mS[t]=!1}function _l(t){"string"==typeof t?t=vS[t]:t instanceof $s||(t=wl(t)),t instanceof $s&&!t.isDisposed()&&t.dispose()}function wl(t){return vS[Xn(t,_S)]}function bl(t){return vS[t]}function Ml(t,e){pS[t]=e}function Sl(t){cS.push(t)}function Il(t,e){Pl(uS,t,e,UM)}function Tl(t){dS.push(t)}function Al(t,e,i){"function"==typeof e&&(i=e,e="");var n=WM(t)?t.type:[t,t={event:e}][0];t.event=(t.event||n).toLowerCase(),e=t.event,VM(aS.test(n)&&aS.test(e)),lS[n]||(lS[n]={action:i,actionInfo:t}),hS[e]=n}function Cl(t,e){Fo.register(t,e)}function Dl(t){var e=Fo.get(t);return e?e.getDimensionsInfo?e.getDimensionsInfo():e.dimensions.slice():void 0}function Ll(t,e){Pl(fS,t,e,qM,"layout")}function kl(t,e){Pl(fS,t,e,KM,"visual")}function Pl(t,e,i,n,a){(FM(e)||WM(e))&&(i=e,e=n);var r=Os.wrapStageHandler(i,a);return r.__prio=e,r.__raw=i,t.push(r),r}function Ol(t,e){gS[t]=e}function zl(t){return Cb.extend(t)}function El(t){return pM.extend(t)}function Rl(t){return fM.extend(t)}function Nl(t){return Ss.extend(t)}function Bl(t){i("createCanvas",t)}function Vl(t,e,i){e.geoJson&&!e.features&&(i=e.specialAreas,e=e.geoJson),"string"==typeof e&&(e="undefined"!=typeof JSON&&JSON.parse?JSON.parse(e):new Function("return ("+e+");")()),wS[t]={geoJson:e,specialAreas:i}}function Gl(t){return wS[t]}function Fl(t){return t}function Wl(t,e,i,n,a){this._old=t,this._new=e,this._oldKeyGetter=i||Fl,this._newKeyGetter=n||Fl,this.context=a}function Hl(t,e,i,n,a){for(var r=0;r<t.length;r++){var o="_ec_"+a[n](t[r],r),s=e[o];null==s?(i.push(o),e[o]=r):(s.length||(e[o]=s=[s]),s.push(r))}}function Zl(t){var e={},i=e.encode={},n=e.coordDimMap=B(),a=[];f(t.dimensions,function(e){var r=t.getDimensionInfo(e),o=r.coordDim;if(o){var s=i[o];i.hasOwnProperty(o)||(s=i[o]=[]),s[r.coordDimIndex]=e,r.isSysCoord&&Xl(r.type)&&(a[0]=e),n.set(o,1)}SS.each(function(t,e){var n=i[e];i.hasOwnProperty(e)||(n=i[e]=[]);var a=r.otherDims[e];null!=a&&a!==!1&&(n[a]=r.name)})});var r=[];n.each(function(t,e){r=r.concat(i[e])}),e.dataDimsOnCoord=r;var o=i.label;o&&o.length&&(a=o.slice());var s=a.slice(),l=i.tooltip;return l&&l.length&&(s=l.slice()),i.defaultedLabel=a,i.defaultedTooltip=s,e}function jl(t){return"category"===t?"ordinal":"time"===t?"time":"float"}function Xl(t){return!("ordinal"===t||"time"===t)}function Ul(t){var e=typeof AS.Uint32Array===TS?Array:AS.Uint32Array,i=typeof AS.Uint16Array===TS?Array:AS.Uint16Array;return t._rawCount>65535?e:i}function Yl(t){var e=t.constructor;return e===Array?t.slice():new e(t)}function ql(t,e){f(LS.concat(e.__wrappedMethods||[]),function(i){e.hasOwnProperty(i)&&(t[i]=e[i])}),t.__wrappedMethods=e.__wrappedMethods}function $l(t){return t}function Kl(t){return t<this._count&&t>=0?this._indices[t]:-1}function Jl(t,e){var i=t._idList[e];return null==i&&(i=t._getIdFromStore(e)),null==i&&(i=CS+e),i}function Ql(t){return _(t)||(t=[t]),t}function th(t,e){var i=t.dimensions,n=new kS(p(i,t.getDimensionInfo,t),t.hostModel);ql(n,t);for(var a=n._storage={},r=t._storage,o=0;o<i.length;o++){var s=i[o];r[s]&&(a[s]=h(e,s)>=0?eh(r[s]):r[s])}return n}function eh(t){for(var e=new Array(t.length),i=0;i<t.length;i++)e[i]=Yl(t[i]);return e}function ih(t,e,i){function a(t,e,i){null!=SS.get(e)?t.otherDims[e]=i:(t.coordDim=e,t.coordDimIndex=i,u.set(e,!0))}wo.isInstance(e)||(e=wo.seriesDataToSource(e)),i=i||{},t=(t||[]).slice();for(var r=(i.dimsDef||[]).slice(),l=B(i.encodeDef),h=B(),u=B(),c=[],d=nh(e,t,r,i.dimCount),p=0;d>p;p++){var g=r[p]=o({},M(r[p])?r[p]:{name:r[p]}),v=g.name,m=c[p]={otherDims:{}};null!=v&&null==h.get(v)&&(m.name=m.displayName=v,h.set(v,p)),null!=g.type&&(m.type=g.type),null!=g.displayName&&(m.displayName=g.displayName)}l.each(function(t,e){t=On(t).slice();var i=l.set(e,[]);f(t,function(t,n){b(t)&&(t=h.get(t)),null!=t&&d>t&&(i[n]=t,a(c[t],e,n))})});var y=0;f(t,function(t){var e,t,i,r;if(b(t))e=t,t={};else{e=t.name;var o=t.ordinalMeta;t.ordinalMeta=null,t=n(t),t.ordinalMeta=o,i=t.dimsDef,r=t.otherDims,t.name=t.coordDim=t.coordDimIndex=t.dimsDef=t.otherDims=null}var h=On(l.get(e));if(!h.length)for(var u=0;u<(i&&i.length||1);u++){for(;y<c.length&&null!=c[y].coordDim;)y++;y<c.length&&h.push(y++)}f(h,function(n,o){var l=c[n];a(s(l,t),e,o),null==l.name&&i&&(l.name=l.displayName=i[o]),l.isSysCoord=!0,r&&s(l.otherDims,r)})});for(var x=i.extraPrefix||"value",_=0;d>_;_++){var m=c[_]=c[_]||{},w=m.coordDim;null==w&&(m.coordDim=ah(x,u,i.extraFromZero),m.coordDimIndex=0,m.isExtraCoord=!0),null==m.name&&(m.name=ah(m.coordDim,h)),null==m.type&&ko(e,_,m.name)&&(m.type="ordinal")}return c}function nh(t,e,i,n){return null==n&&(n=Math.max(t.dimensionsDetectCount||1,e.length,i.length),f(e,function(t){var e=t.dimsDef;e&&(n=Math.max(n,e.length))})),n}function ah(t,e,i){if(i||null!=e.get(t)){for(var n=0;null!=e.get(t+n);)n++;t+=n}return e.set(t,!0),t}function rh(t,e){wo.isInstance(t)||(t=wo.seriesDataToSource(t));var i,n=e.get("coordinateSystem"),a=Fo.get(n),r=xo(e);r&&(i=p(r.coordSysDims,function(t){var e={name:t},i=r.axisMap.get(t);if(i){var n=i.get("type");e.type=jl(n),e.stackable=oh(n)}return e})),i||(i=a&&(a.getDimensionsInfo?a.getDimensionsInfo():a.dimensions.slice())||["x","y"]);var o,s,l=zS(t,{coordDimensions:i});r&&f(l,function(t,e){var i=t.coordDim,n=r.categoryAxisMap.get(i);n&&(null==o&&(o=e),t.ordinalMeta=n.getOrdinalMeta()),null!=t.otherDims.itemName&&(s=!0)}),s||null==o||(l[o].otherDims.itemName=0);var h=new kS(l,e),u=null!=o&&sh(t)?function(t,e,i,n){return n===o?i:this.defaultDimValueGetter(t,e,i,n)}:null;return h.hasItemOption=!1,h.initData(t,null,u),h}function oh(t){return"category"!==t&&"time"!==t}function sh(t){if(t.sourceFormat===zb){var e=lh(t.data||[]);return null!=e&&!_(En(e))}}function lh(t){for(var e=0;e<t.length&&null==t[e];)e++;return t[e]}function hh(t){this._setting=t||{},this._extent=[1/0,-1/0],this._interval=0,this.init&&this.init.apply(this,arguments)}function uh(t){this.categories=t.categories||[],this._needCollect=t.needCollect,this._deduplication=t.deduplication,this._map}function ch(t){return t._map||(t._map=B(t.categories))}function dh(t){return M(t)&&null!=t.value?t.value:t+""}function fh(t,e,i,n){var a={},r=t[1]-t[0],o=a.interval=Jr(r/e,!0);null!=i&&i>o&&(o=a.interval=i),null!=n&&o>n&&(o=a.interval=n);var s=a.intervalPrecision=ph(o),l=a.niceTickExtent=[BS(Math.ceil(t[0]/o)*o,s),BS(Math.floor(t[1]/o)*o,s)];return vh(l,t),a}function ph(t){return Zr(t)+2}function gh(t,e,i){t[e]=Math.max(Math.min(t[e],i[1]),i[0])}function vh(t,e){!isFinite(t[0])&&(t[0]=e[0]),!isFinite(t[1])&&(t[1]=e[1]),gh(t,0,e),gh(t,1,e),t[0]>t[1]&&(t[0]=t[1])}function mh(t,e,i,n){var a=[];if(!t)return a;var r=1e4;e[0]<i[0]&&a.push(e[0]);for(var o=i[0];o<=i[1]&&(a.push(o),o=BS(o+t,n),o!==a[a.length-1]);)if(a.length>r)return[];return e[1]>(a.length?a[a.length-1]:i[1])&&a.push(e[1]),a}function yh(t){return t.get("stack")||FS+t.seriesIndex}function xh(t){return t.dim+t.index}function _h(t,e){var i=[],n=t.axis,a="axis0";if("category"===n.type){for(var r=n.getBandWidth(),o=0;o<t.count;o++)i.push(s({bandWidth:r,axisKey:a,stackId:FS+o},t));for(var l=bh(i,e),h=[],o=0;o<t.count;o++){var u=l[a][FS+o];u.offsetCenter=u.offset+u.width/2,h.push(u)}return h}}function wh(t,e){var i=p(t,function(t){var e=t.getData(),i=t.coordinateSystem,n=i.getBaseAxis(),a=n.getExtent(),r="category"===n.type?n.getBandWidth():Math.abs(a[1]-a[0])/e.count(),o=Gr(t.get("barWidth"),r),s=Gr(t.get("barMaxWidth"),r),l=t.get("barGap"),h=t.get("barCategoryGap");return{bandWidth:r,barWidth:o,barMaxWidth:s,barGap:l,barCategoryGap:h,axisKey:xh(n),stackId:yh(t)}});return bh(i,e)}function bh(t){var e={};f(t,function(t){var i=t.axisKey,n=t.bandWidth,a=e[i]||{bandWidth:n,remainedWidth:n,autoWidthCount:0,categoryGap:"20%",gap:"30%",stacks:{}},r=a.stacks;e[i]=a;var o=t.stackId;r[o]||a.autoWidthCount++,r[o]=r[o]||{width:0,maxWidth:0};var s=t.barWidth;s&&!r[o].width&&(r[o].width=s,s=Math.min(a.remainedWidth,s),a.remainedWidth-=s);var l=t.barMaxWidth;l&&(r[o].maxWidth=l);var h=t.barGap;null!=h&&(a.gap=h);var u=t.barCategoryGap;null!=u&&(a.categoryGap=u)});var i={};return f(e,function(t,e){i[e]={};var n=t.stacks,a=t.bandWidth,r=Gr(t.categoryGap,a),o=Gr(t.gap,1),s=t.remainedWidth,l=t.autoWidthCount,h=(s-r)/(l+(l-1)*o);h=Math.max(h,0),f(n,function(t){var e=t.maxWidth;e&&h>e&&(e=Math.min(e,s),t.width&&(e=Math.min(e,t.width)),s-=e,t.width=e,l--)}),h=(s-r)/(l+(l-1)*o),h=Math.max(h,0);var u,c=0;f(n,function(t){t.width||(t.width=h),u=t,c+=t.width*(1+o)}),u&&(c-=u.width*o);var d=-c/2;f(n,function(t,n){i[e][n]=i[e][n]||{offset:d,width:t.width},d+=t.width*(1+o)})}),i}function Mh(t,e){var i=wh(v(e.getSeriesByType(t),function(t){return!e.isSeriesFiltered(t)&&t.coordinateSystem&&"cartesian2d"===t.coordinateSystem.type})),n={},a={};e.eachSeriesByType(t,function(t){if("cartesian2d"===t.coordinateSystem.type){var e=t.getData(),r=t.coordinateSystem,o=r.getBaseAxis(),s=yh(t),l=i[xh(o)][s],h=l.offset,u=l.width,c=r.getOtherAxis(o),d=t.get("barMinHeight")||0,f=o.onZero?c.toGlobalCoord(c.dataToCoord(0)):c.getGlobalExtent()[0],p=[e.mapDimension("x"),e.mapDimension("y")],g=e.mapArray(p,function(t,e){return r.dataToPoint([t,e])},!0);n[s]=n[s]||[],a[s]=a[s]||[],e.setLayout({offset:h,size:u}),e.each(e.mapDimension(c.dim),function(t,i){if(!isNaN(t)){n[s][i]||(n[s][i]={p:f,n:f},a[s][i]={p:f,n:f});var r,o,l,p,v=t>=0?"p":"n",m=g[i],y=n[s][i][v],x=a[s][i][v];c.isHorizontal()?(r=y,o=m[1]+h,l=m[0]-x,p=u,a[s][i][v]+=l,Math.abs(l)<d&&(l=(0>l?-1:1)*d),n[s][i][v]+=l):(r=m[0]+h,o=y,l=u,p=m[1]-x,a[s][i][v]+=p,Math.abs(p)<d&&(p=(0>=p?-1:1)*d),n[s][i][v]+=p),e.setItemLayout(i,{x:r,y:o,width:l,height:p})}},!0)}},this)}function Sh(t,e){return eI(t,tI(e))}function Ih(t,e){var i,n,a,r=t.type,o=e.getMin(),s=e.getMax(),l=null!=o,h=null!=s,u=t.getExtent();"ordinal"===r?i=e.getCategories().length:(n=e.get("boundaryGap"),_(n)||(n=[n||0,n||0]),"boolean"==typeof n[0]&&(n=[0,0]),n[0]=Gr(n[0],1),n[1]=Gr(n[1],1),a=u[1]-u[0]||Math.abs(u[0])),null==o&&(o="ordinal"===r?i?0:0/0:u[0]-n[0]*a),null==s&&(s="ordinal"===r?i?i-1:0/0:u[1]+n[1]*a),"dataMin"===o?o=u[0]:"function"==typeof o&&(o=o({min:u[0],max:u[1]})),"dataMax"===s?s=u[1]:"function"==typeof s&&(s=s({min:u[0],max:u[1]})),(null==o||!isFinite(o))&&(o=0/0),(null==s||!isFinite(s))&&(s=0/0),t.setBlank(A(o)||A(s)),e.getNeedCrossZero()&&(o>0&&s>0&&!l&&(o=0),0>o&&0>s&&!h&&(s=0));var c=e.ecModel;if(c){var d=v(c.getSeriesByType("bar"),function(t){return t.getBaseAxis()===e.axis}).length>0;if(("time"===r||"interval"===r)&&d){var f=Th(o,s,e);o=f.min,s=f.max}}return[o,s]}function Th(t,e,i){var n=i.ecModel,a=i.axis.getExtent(),r=a[1]-a[0],o=wh(v(n.getSeriesByType("bar"),function(t){return!n.isSeriesFiltered(t)&&t.coordinateSystem&&"cartesian2d"===t.coordinateSystem.type
-})),s=i.axis.dim+i.axis.index,l=o[s];if(void 0===l)return{min:t,max:e};var h=1/0;f(l,function(t){h=Math.min(t.offset,h)});var u=-1/0;f(l,function(t){u=Math.max(t.offset+t.width,u)});var c=Math.abs(h)+u,d=e-t,p=1-(h+u)/r,g=d/p-d;return e+=g*(u/c),t-=g*(h/c),{min:t,max:e}}function Ah(t,e){var i=Ih(t,e),n=null!=e.getMin(),a=null!=e.getMax(),r=e.get("splitNumber");"log"===t.type&&(t.base=e.get("logBase"));var o=t.type;t.setExtent(i[0],i[1]),t.niceExtent({splitNumber:r,fixMin:n,fixMax:a,minInterval:"interval"===o||"time"===o?e.get("minInterval"):null,maxInterval:"interval"===o||"time"===o?e.get("maxInterval"):null});var s=e.get("interval");null!=s&&t.setInterval&&t.setInterval(s)}function Ch(t,e){if(e=e||t.get("type"))switch(e){case"category":return new NS(t.getOrdinalMeta?t.getOrdinalMeta():t.getCategories(),[1/0,-1/0]);case"value":return new GS;default:return(hh.getClass(e)||GS).create(t)}}function Dh(t){var e=t.scale.getExtent(),i=e[0],n=e[1];return!(i>0&&n>0||0>i&&0>n)}function Lh(t,e,i,n,a){var r,o=0,s=0,l=(n-a)/180*Math.PI,h=1;e.length>40&&(h=Math.floor(e.length/40));for(var u=0;u<t.length;u+=h){var c=t[u],d=Mi(e[u],i,"center","top");d.x+=c*Math.cos(l),d.y+=c*Math.sin(l),d.width*=1.3,d.height*=1.3,r?r.intersect(d)?(s++,o=Math.max(o,s)):(r.union(d),s=0):r=d.clone()}return 0===o&&h>1?h:(o+1)*h-1}function kh(t,e){var i=t.scale,n=i.getTicksLabels(),a=i.getTicks();return"string"==typeof e?(e=function(t){return function(e){return t.replace("{value}",null!=e?e:"")}}(e),p(n,e)):"function"==typeof e?p(a,function(i,n){return e(Ph(t,i),n)},this):n}function Ph(t,e){return"category"===t.type?t.scale.getLabel(e):e}function Oh(t,e){if("image"!==this.type){var i=this.style,n=this.shape;n&&"line"===n.symbolType?i.stroke=t:this.__isEmptyBrush?(i.stroke=t,i.fill=e||"#fff"):(i.fill&&(i.fill=t),i.stroke&&(i.stroke=t)),this.dirty(!1)}}function zh(t,e,i,n,a,r,o){var s=0===t.indexOf("empty");s&&(t=t.substr(5,1).toLowerCase()+t.substr(6));var l;return l=0===t.indexOf("image://")?Ua(t.slice(8),new ni(e,i,n,a),o?"center":"cover"):0===t.indexOf("path://")?Xa(t.slice(7),{},new ni(e,i,n,a),o?"center":"cover"):new gI({shape:{symbolType:t,x:e,y:i,width:n,height:a}}),l.__isEmptyBrush=s,l.setColor=Oh,l.setColor(r),l}function Eh(t){return rh(t.getSource(),t)}function Rh(t,e){var i=e;Pr.isInstance(e)||(i=new Pr(e),c(i,sI));var n=Ch(i);return n.setExtent(t[0],t[1]),Ah(n,i),n}function Nh(t){c(t,sI)}function Bh(t,e){return Math.abs(t-e)<mI}function Vh(t,e,i){var n=0,a=t[0];if(!a)return!1;for(var r=1;r<t.length;r++){var o=t[r];n+=Sa(a[0],a[1],o[0],o[1],e,i),a=o}var s=t[0];return Bh(a[0],s[0])&&Bh(a[1],s[1])||(n+=Sa(a[0],a[1],s[0],s[1],e,i)),0!==n}function Gh(t,e,i){if(this.name=t,this.geometries=e,i)i=[i[0],i[1]];else{var n=this.getBoundingRect();i=[n.x+n.width/2,n.y+n.height/2]}this.center=i}function Fh(t){if(!t.UTF8Encoding)return t;var e=t.UTF8Scale;null==e&&(e=1024);for(var i=t.features,n=0;n<i.length;n++)for(var a=i[n],r=a.geometry,o=r.coordinates,s=r.encodeOffsets,l=0;l<o.length;l++){var h=o[l];if("Polygon"===r.type)o[l]=Wh(h,s[l],e);else if("MultiPolygon"===r.type)for(var u=0;u<h.length;u++){var c=h[u];h[u]=Wh(c,s[l][u],e)}}return t.UTF8Encoding=!1,t}function Wh(t,e,i){for(var n=[],a=e[0],r=e[1],o=0;o<t.length;o+=2){var s=t.charCodeAt(o)-64,l=t.charCodeAt(o+1)-64;s=s>>1^-(1&s),l=l>>1^-(1&l),s+=a,l+=r,a=s,r=l,n.push([s/i,l/i])}return n}function Hh(t,e){var i=t[1]-t[0],n=e,a=i/n/2;t[0]+=a,t[1]-=a}function Zh(t){return this._axes[t]}function jh(t){SI.call(this,t)}function Xh(t,e){return e.type||(e.data?"category":"value")}function Uh(t,e){return t.getCoordSysModel()===e}function Yh(t,e){var i=e*Math.PI/180,n=t.plain(),a=n.width,r=n.height,o=a*Math.cos(i)+r*Math.sin(i),s=a*Math.sin(i)+r*Math.cos(i),l=new ni(n.x,n.y,o,s);return l}function qh(t){var e,i=t.model,n=i.get("axisLabel.show")?i.getFormattedLabels():[],a=i.getModel("axisLabel"),r=1,o=n.length;o>40&&(r=Math.ceil(o/40));for(var s=0;o>s;s+=r)if(!t.isLabelIgnored(s)){var l=a.getTextRect(n[s]),h=Yh(l,a.get("rotate")||0);e?e.union(h):e=h}return e}function $h(t,e,i){this._coordsMap={},this._coordsList=[],this._axesMap={},this._axesList=[],this._initCartesian(t,e,i),this.model=t}function Kh(t,e,i){var n=t[e];if(i.onZero){var a=i.onZeroAxisIndex;if(null!=a){var r=n[a];return void(r&&Jh(r)&&(i.onZero=!1))}for(var o in n)if(n.hasOwnProperty(o)){var r=n[o];if(r&&!Jh(r)){a=+o;break}}null==a&&(i.onZero=!1),i.onZeroAxisIndex=a}}function Jh(t){return"category"===t.type||"time"===t.type||!OI(t)}function Qh(t,e){var i=t.getExtent(),n=i[0]+i[1];t.toGlobalCoord="x"===t.dim?function(t){return t+e}:function(t){return n-t+e},t.toLocalCoord="x"===t.dim?function(t){return t-e}:function(t){return n-t+e}}function tu(t){return p(RI,function(e){var i=t.getReferringComponents(e)[0];return i})}function eu(t){return"cartesian2d"===t.get("coordinateSystem")}function iu(t,e){var i=t.mapDimension("defaultedLabel",!0),n=i.length;if(1===n)return ds(t,e,i[0]);if(n){for(var a=[],r=0;r<i.length;r++){var o=ds(t,e,i[r]);a.push(o)}return a.join(" ")}}function nu(t,e,i,n,a,r){var o=i.getModel("label"),s=i.getModel("emphasis.label");dr(t,e,o,s,{labelFetcher:a,labelDataIndex:r,defaultText:iu(a.getData(),r),isRectText:!0,autoColor:n}),au(t),au(e)}function au(t,e){"outside"===t.textPosition&&(t.textPosition=e)}function ru(t,e,i){i.style.text=null,Mr(i,{shape:{width:0}},e,t,function(){i.parent&&i.parent.remove(i)})}function ou(t,e,i){i.style.text=null,Mr(i,{shape:{r:i.shape.r0}},e,t,function(){i.parent&&i.parent.remove(i)})}function su(t,e,i,n,a,r,o,l){var h=e.getItemVisual(i,"color"),u=e.getItemVisual(i,"opacity"),c=n.getModel("itemStyle"),d=n.getModel("emphasis.itemStyle").getBarItemStyle();l||t.setShape("r",c.get("barBorderRadius")||0),t.useStyle(s({fill:h,opacity:u},c.getBarItemStyle()));var f=n.getShallow("cursor");f&&t.attr("cursor",f);var p=o?a.height>0?"bottom":"top":a.width>0?"left":"right";l||nu(t.style,d,n,h,r,i,p),cr(t,d)}function lu(t,e){var i=t.get(GI)||0;return Math.min(i,Math.abs(e.width),Math.abs(e.height))}function hu(t){var e={componentType:t.mainType};return e[t.mainType+"Index"]=t.componentIndex,e}function uu(t,e,i,n){var a,r,o=Ur(i-t.rotation),s=n[0]>n[1],l="start"===e&&!s||"start"!==e&&s;return Yr(o-HI/2)?(r=l?"bottom":"top",a="center"):Yr(o-1.5*HI)?(r=l?"top":"bottom",a="center"):(r="middle",a=1.5*HI>o&&o>HI/2?l?"left":"right":l?"right":"left"),{rotation:o,textAlign:a,textVerticalAlign:r}}function cu(t){var e=t.get("tooltip");return t.get("silent")||!(t.get("triggerEvent")||e&&e.show)}function du(t,e,i){var n=t.get("axisLabel.showMinLabel"),a=t.get("axisLabel.showMaxLabel");e=e||[],i=i||[];var r=e[0],o=e[1],s=e[e.length-1],l=e[e.length-2],h=i[0],u=i[1],c=i[i.length-1],d=i[i.length-2];n===!1?(fu(r),fu(h)):pu(r,o)&&(n?(fu(o),fu(u)):(fu(r),fu(h))),a===!1?(fu(s),fu(c)):pu(l,s)&&(a?(fu(l),fu(d)):(fu(s),fu(c)))}function fu(t){t&&(t.ignore=!0)}function pu(t,e){var i=t&&t.getBoundingRect().clone(),n=e&&e.getBoundingRect().clone();if(i&&n){var a=pe([]);return ye(a,a,-t.rotation),i.applyTransform(ve([],a,t.getLocalTransform())),n.applyTransform(ve([],a,e.getLocalTransform())),i.intersect(n)}}function gu(t){return"middle"===t||"center"===t}function vu(t,e,i){var n=e.axis;if(e.get("axisTick.show")&&!n.scale.isBlank()){for(var a=e.getModel("axisTick"),r=a.getModel("lineStyle"),o=a.get("length"),l=YI(a,i.labelInterval),h=n.getTicksCoords(a.get("alignWithLabel")),u=n.scale.getTicks(),c=e.get("axisLabel.showMinLabel"),d=e.get("axisLabel.showMaxLabel"),f=[],p=[],g=t._transform,v=[],m=h.length,y=0;m>y;y++)if(!UI(n,y,l,m,c,d)){var x=h[y];f[0]=x,f[1]=0,p[0]=x,p[1]=i.tickDirection*o,g&&(re(f,f,g),re(p,p,g));var _=new Hw($a({anid:"tick_"+u[y],shape:{x1:f[0],y1:f[1],x2:p[0],y2:p[1]},style:s(r.getLineStyle(),{stroke:e.get("axisLine.lineStyle.color")}),z2:2,silent:!0}));t.group.add(_),v.push(_)}return v}}function mu(t,e,i){var n=e.axis,a=C(i.axisLabelShow,e.get("axisLabel.show"));if(a&&!n.scale.isBlank()){var r=e.getModel("axisLabel"),o=r.get("margin"),s=n.scale.getTicks(),l=e.getFormattedLabels(),h=(C(i.labelRotate,r.get("rotate"))||0)*HI/180,u=XI(i.rotation,h,i.labelDirection),c=e.getCategories(),d=[],p=cu(e),g=e.get("triggerEvent"),v=e.get("axisLabel.showMinLabel"),m=e.get("axisLabel.showMaxLabel");return f(s,function(a,h){if(!UI(n,h,i.labelInterval,s.length,v,m)){var f=r;c&&c[a]&&c[a].textStyle&&(f=new Pr(c[a].textStyle,r,e.ecModel));var y=f.getTextColor()||e.get("axisLine.lineStyle.color"),x=n.dataToCoord(a),_=[x,i.labelOffset+i.labelDirection*o],w=n.scale.getLabel(a),b=new Pw({anid:"label_"+a,position:_,rotation:u.rotation,silent:p,z2:10});fr(b.style,f,{text:l[h],textAlign:f.getShallow("align",!0)||u.textAlign,textVerticalAlign:f.getShallow("verticalAlign",!0)||f.getShallow("baseline",!0)||u.textVerticalAlign,textFill:"function"==typeof y?y("category"===n.type?w:"value"===n.type?a+"":a,h):y}),g&&(b.eventData=hu(e),b.eventData.targetType="axisLabel",b.eventData.value=w),t._dumbGroup.add(b),b.updateTransform(),d.push(b),t.group.add(b),b.decomposeTransform()}}),d}}function yu(t,e){var i={axesInfo:{},seriesInvolved:!1,coordSysAxesInfo:{},coordSysMap:{}};return xu(i,t,e),i.seriesInvolved&&wu(i,t),i}function xu(t,e,i){var n=e.getComponent("tooltip"),a=e.getComponent("axisPointer"),r=a.get("link",!0)||[],o=[];qI(i.getCoordinateSystems(),function(i){function s(n,s,l){var u=l.model.getModel("axisPointer",a),d=u.get("show");if(d&&("auto"!==d||n||Au(u))){null==s&&(s=u.get("triggerTooltip")),u=n?_u(l,c,a,e,n,s):u;var f=u.get("snap"),p=Cu(l.model),g=s||f||"category"===l.type,v=t.axesInfo[p]={key:p,axis:l,coordSys:i,axisPointerModel:u,triggerTooltip:s,involveSeries:g,snap:f,useHandle:Au(u),seriesModels:[]};h[p]=v,t.seriesInvolved|=g;var m=bu(r,l);if(null!=m){var y=o[m]||(o[m]={axesInfo:{}});y.axesInfo[p]=v,y.mapper=r[m].mapper,v.linkGroup=y}}}if(i.axisPointerEnabled){var l=Cu(i.model),h=t.coordSysAxesInfo[l]={};t.coordSysMap[l]=i;var u=i.model,c=u.getModel("tooltip",n);if(qI(i.getAxes(),$I(s,!1,null)),i.getTooltipAxes&&n&&c.get("show")){var d="axis"===c.get("trigger"),f="cross"===c.get("axisPointer.type"),p=i.getTooltipAxes(c.get("axisPointer.axis"));(d||f)&&qI(p.baseAxes,$I(s,f?"cross":!0,d)),f&&qI(p.otherAxes,$I(s,"cross",!1))}}})}function _u(t,e,i,a,r,o){var l=e.getModel("axisPointer"),h={};qI(["type","snap","lineStyle","shadowStyle","label","animation","animationDurationUpdate","animationEasingUpdate","z"],function(t){h[t]=n(l.get(t))}),h.snap="category"!==t.type&&!!o,"cross"===l.get("type")&&(h.type="line");var u=h.label||(h.label={});if(null==u.show&&(u.show=!1),"cross"===r&&(u.show=!0,!o)){var c=h.lineStyle=l.get("crossStyle");c&&s(u,c.textStyle)}return t.model.getModel("axisPointer",new Pr(h,i,a))}function wu(t,e){e.eachSeries(function(e){var i=e.coordinateSystem,n=e.get("tooltip.trigger",!0),a=e.get("tooltip.show",!0);i&&"none"!==n&&n!==!1&&"item"!==n&&a!==!1&&e.get("axisPointer.show",!0)!==!1&&qI(t.coordSysAxesInfo[Cu(i.model)],function(t){var n=t.axis;i.getAxis(n.dim)===n&&(t.seriesModels.push(e),null==t.seriesDataCount&&(t.seriesDataCount=0),t.seriesDataCount+=e.getData().count())})},this)}function bu(t,e){for(var i=e.model,n=e.dim,a=0;a<t.length;a++){var r=t[a]||{};if(Mu(r[n+"AxisId"],i.id)||Mu(r[n+"AxisIndex"],i.componentIndex)||Mu(r[n+"AxisName"],i.name))return a}}function Mu(t,e){return"all"===t||_(t)&&h(t,e)>=0||t===e}function Su(t){var e=Iu(t);if(e){var i=e.axisPointerModel,n=e.axis.scale,a=i.option,r=i.get("status"),o=i.get("value");null!=o&&(o=n.parse(o));var s=Au(i);null==r&&(a.status=s?"show":"hide");var l=n.getExtent().slice();l[0]>l[1]&&l.reverse(),(null==o||o>l[1])&&(o=l[1]),o<l[0]&&(o=l[0]),a.value=o,s&&(a.status=e.axis.scale.isBlank()?"hide":"show")}}function Iu(t){var e=(t.ecModel.getComponent("axisPointer")||{}).coordSysAxesInfo;return e&&e.axesInfo[Cu(t)]}function Tu(t){var e=Iu(t);return e&&e.axisPointerModel}function Au(t){return!!t.get("handle.show")}function Cu(t){return t.type+"||"+t.id}function Du(t,e,i,n,a,r){var o=KI.getAxisPointerClass(t.axisPointerClass);if(o){var s=Tu(e);s?(t._axisPointer||(t._axisPointer=new o)).render(e,s,n,r):Lu(t,n)}}function Lu(t,e,i){var n=t._axisPointer;n&&n.dispose(e,i),t._axisPointer=null}function ku(t,e,i){i=i||{};var n=t.coordinateSystem,a=e.axis,r={},o=a.position,s=a.onZero?"onZero":o,l=a.dim,h=n.getRect(),u=[h.x,h.x+h.width,h.y,h.y+h.height],c={left:0,right:1,top:0,bottom:1,onZero:2},d=e.get("offset")||0,f="x"===l?[u[2]-d,u[3]+d]:[u[0]-d,u[1]+d];if(a.onZero){var p=n.getAxis("x"===l?"y":"x",a.onZeroAxisIndex),g=p.toGlobalCoord(p.dataToCoord(0));f[c.onZero]=Math.max(Math.min(g,f[1]),f[0])}r.position=["y"===l?f[c[s]]:u[0],"x"===l?f[c[s]]:u[3]],r.rotation=Math.PI/2*("x"===l?0:1);var v={top:-1,bottom:1,left:-1,right:1};r.labelDirection=r.tickDirection=r.nameDirection=v[o],r.labelOffset=a.onZero?f[c[o]]-f[c.onZero]:0,e.get("axisTick.inside")&&(r.tickDirection=-r.tickDirection),C(i.labelInside,e.get("axisLabel.inside"))&&(r.labelDirection=-r.labelDirection);var m=e.get("axisLabel.rotate");return r.labelRotate="top"===s?-m:m,r.labelInterval=a.getLabelInterval(),r.z2=1,r}function Pu(t,e){var i=t.getItemVisual(e,"symbolSize");return i instanceof Array?i.slice():[+i,+i]}function Ou(t){return[t[0]/2,t[1]/2]}function zu(t,e,i){xx.call(this),this.updateData(t,e,i)}function Eu(t,e){this.parent.drift(t,e)}function Ru(t){this.group=new xx,this._symbolCtor=t||zu}function Nu(t,e,i,n){return!(!e||isNaN(e[0])||isNaN(e[1])||n&&n(i)||"none"===t.getItemVisual(i,"symbol"))}function Bu(t){var e=t.hostModel;return{itemStyle:e.getModel("itemStyle").getItemStyle(["color"]),hoverItemStyle:e.getModel("emphasis.itemStyle").getItemStyle(),symbolRotate:e.get("symbolRotate"),symbolOffset:e.get("symbolOffset"),hoverAnimation:e.get("hoverAnimation"),labelModel:e.getModel("label"),hoverLabelModel:e.getModel("emphasis.label"),cursorStyle:e.get("cursor")}}function Vu(t){return t>=0?1:-1}function Gu(t,e,i){for(var n,a=t.getBaseAxis(),r=t.getOtherAxis(a),o=a.onZero?0:r.scale.getExtent()[0],s=r.dim,l="x"===s||"radius"===s?1:0,h=e.stackedOn,u=e.get(s,i);h&&Vu(h.get(s,i))===Vu(u);){n=h;break}var c=[];return c[l]=e.get(a.dim,i),c[1-l]=n?n.get(s,i,!0):o,t.dataToPoint(c)}function Fu(t,e){var i=[];return e.diff(t).add(function(t){i.push({cmd:"+",idx:t})}).update(function(t,e){i.push({cmd:"=",idx:e,idx1:t})}).remove(function(t){i.push({cmd:"-",idx:t})}).execute(),i}function Wu(t){return isNaN(t[0])||isNaN(t[1])}function Hu(t,e,i,n,a,r,o,s,l,h,u){for(var c=0,d=i,f=0;n>f;f++){var p=e[d];if(d>=a||0>d)break;if(Wu(p)){if(u){d+=r;continue}break}if(d===i)t[r>0?"moveTo":"lineTo"](p[0],p[1]),pT(vT,p);else if(l>0){var g=d+r,v=e[g];if(u)for(;v&&Wu(e[g]);)g+=r,v=e[g];var m=.5,y=e[c],v=e[g];if(!v||Wu(v))pT(mT,p);else{Wu(v)&&!u&&(v=p),U(gT,v,y);var x,_;if("x"===h||"y"===h){var w="x"===h?0:1;x=Math.abs(p[w]-y[w]),_=Math.abs(p[w]-v[w])}else x=zy(p,y),_=zy(p,v);m=_/(_+x),fT(mT,p,gT,-l*(1-m))}cT(vT,vT,s),dT(vT,vT,o),cT(mT,mT,s),dT(mT,mT,o),t.bezierCurveTo(vT[0],vT[1],mT[0],mT[1],p[0],p[1]),fT(vT,p,gT,l*m)}else t.lineTo(p[0],p[1]);c=d,d+=r}return f}function Zu(t,e){var i=[1/0,1/0],n=[-1/0,-1/0];if(e)for(var a=0;a<t.length;a++){var r=t[a];r[0]<i[0]&&(i[0]=r[0]),r[1]<i[1]&&(i[1]=r[1]),r[0]>n[0]&&(n[0]=r[0]),r[1]>n[1]&&(n[1]=r[1])}return{min:e?i:n,max:e?n:i}}function ju(t,e){if(t.length===e.length){for(var i=0;i<t.length;i++){var n=t[i],a=e[i];if(n[0]!==a[0]||n[1]!==a[1])return}return!0}}function Xu(t){return"number"==typeof t?t:t?.3:0}function Uu(t){var e=t.getGlobalExtent();if(t.onBand){var i=t.getBandWidth()/2-1,n=e[1]>e[0]?1:-1;e[0]+=n*i,e[1]-=n*i}return e}function Yu(t){return t>=0?1:-1}function qu(t,e,i,n){var a=e.getBaseAxis(),r=e.getOtherAxis(a),o=0,s=r.scale.getExtent();if("start"===n)o=s[0];else if("end"===n)o=s[1];else{var s=r.scale.getExtent();s[0]>0?o=s[0]:s[1]<0&&(o=s[1])}var l=r.dim,h="x"===l||"radius"===l?1:0,u=i.mapDimension(l);return i.mapArray(u?[u]:[],function(t,n){for(var r,s=i.stackedOn;s&&Yu(s.get(u,n))===Yu(t);){r=s;break}var l=[];return l[h]=i.get(a.dim,n),l[1-h]=r?r.get(u,n,!0):o,e.dataToPoint(l)},!0)}function $u(t,e,i){var n=Uu(t.getAxis("x")),a=Uu(t.getAxis("y")),r=t.getBaseAxis().isHorizontal(),o=Math.min(n[0],n[1]),s=Math.min(a[0],a[1]),l=Math.max(n[0],n[1])-o,h=Math.max(a[0],a[1])-s,u=i.get("lineStyle.width")||2,c=i.get("clipOverflow")?u/2:Math.max(l,h);r?(s-=c,h+=2*c):(o-=c,l+=2*c);var d=new Ww({shape:{x:o,y:s,width:l,height:h}});return e&&(d.shape[r?"width":"height"]=0,Sr(d,{shape:{width:l,height:h}},i)),d}function Ku(t,e,i){var n=t.getAngleAxis(),a=t.getRadiusAxis(),r=a.getExtent(),o=n.getExtent(),s=Math.PI/180,l=new Rw({shape:{cx:t.cx,cy:t.cy,r0:r[0],r:r[1],startAngle:-o[0]*s,endAngle:-o[1]*s,clockwise:n.inverse}});return e&&(l.shape.endAngle=-o[0]*s,Sr(l,{shape:{endAngle:-o[1]*s}},i)),l}function Ju(t,e,i){return"polar"===t.type?Ku(t,e,i):$u(t,e,i)}function Qu(t,e,i){for(var n=e.getBaseAxis(),a="x"===n.dim||"radius"===n.dim?0:1,r=[],o=0;o<t.length-1;o++){var s=t[o+1],l=t[o];r.push(l);var h=[];switch(i){case"end":h[a]=s[a],h[1-a]=l[1-a],r.push(h);break;case"middle":var u=(l[a]+s[a])/2,c=[];h[a]=c[a]=u,h[1-a]=l[1-a],c[1-a]=s[1-a],r.push(h),r.push(c);break;default:h[a]=l[a],h[1-a]=s[1-a],r.push(h)}}return t[o]&&r.push(t[o]),r}function tc(t,e){var i=t.getVisual("visualMeta");if(i&&i.length&&t.count()){for(var n,a=i.length-1;a>=0;a--)if(i[a].dimension<2){n=i[a];break}if(n&&"cartesian2d"===e.type){var r=n.dimension,o=t.dimensions[r],s=e.getAxis(o),l=p(n.stops,function(t){return{coord:s.toGlobalCoord(s.dataToCoord(t.value)),color:t.color}}),h=l.length,u=n.outerColors.slice();h&&l[0].coord>l[h-1].coord&&(l.reverse(),u.reverse());var c=10,d=l[0].coord-c,g=l[h-1].coord+c,v=g-d;if(.001>v)return"transparent";f(l,function(t){t.offset=(t.coord-d)/v}),l.push({offset:h?l[h-1].offset:.5,color:u[1]||"transparent"}),l.unshift({offset:h?l[0].offset:.5,color:u[0]||"transparent"});var m=new qw(0,0,0,0,l,!0);return m[o]=d,m[o+"2"]=g,m}}}function ec(t,e,i,n){var a=e.getData(),r=this.dataIndex,o=a.getName(r),s=e.get("selectedOffset");n.dispatchAction({type:"pieToggleSelect",from:t,name:o,seriesId:e.id}),a.each(function(t){ic(a.getItemGraphicEl(t),a.getItemLayout(t),e.isSelected(a.getName(t)),s,i)})}function ic(t,e,i,n,a){var r=(e.startAngle+e.endAngle)/2,o=Math.cos(r),s=Math.sin(r),l=i?n:0,h=[o*l,s*l];a?t.animate().when(200,{position:h}).start("bounceOut"):t.attr("position",h)}function nc(t,e){function i(){r.ignore=r.hoverIgnore,o.ignore=o.hoverIgnore}function n(){r.ignore=r.normalIgnore,o.ignore=o.normalIgnore}xx.call(this);var a=new Rw({z2:2}),r=new Fw,o=new Pw;this.add(a),this.add(r),this.add(o),this.updateData(t,e,!0),this.on("emphasis",i).on("normal",n).on("mouseover",i).on("mouseout",n)}function ac(t,e,i,n,a,r,o){function s(e,i,n){for(var a=e;i>a;a++)if(t[a].y+=n,a>e&&i>a+1&&t[a+1].y>t[a].y+t[a].height)return void l(a,n/2);l(i-1,n/2)}function l(e,i){for(var n=e;n>=0&&(t[n].y-=i,!(n>0&&t[n].y>t[n-1].y+t[n-1].height));n--);}function h(t,e,i,n,a,r){for(var o=r>0?e?Number.MAX_VALUE:0:e?Number.MAX_VALUE:0,s=0,l=t.length;l>s;s++)if("center"!==t[s].position){var h=Math.abs(t[s].y-n),u=t[s].len,c=t[s].len2,d=a+u>h?Math.sqrt((a+u+c)*(a+u+c)-h*h):Math.abs(t[s].x-i);e&&d>=o&&(d=o-10),!e&&o>=d&&(d=o+10),t[s].x=i+d*r,o=d}}t.sort(function(t,e){return t.y-e.y});for(var u,c=0,d=t.length,f=[],p=[],g=0;d>g;g++)u=t[g].y-c,0>u&&s(g,d,-u,a),c=t[g].y+t[g].height;0>o-c&&l(d-1,c-o);for(var g=0;d>g;g++)t[g].y>=i?p.push(t[g]):f.push(t[g]);h(f,!1,e,i,n,a),h(p,!0,e,i,n,a)}function rc(t,e,i,n,a,r){for(var o=[],s=[],l=0;l<t.length;l++)t[l].x<e?o.push(t[l]):s.push(t[l]);ac(s,e,i,n,1,a,r),ac(o,e,i,n,-1,a,r);for(var l=0;l<t.length;l++){var h=t[l].linePoints;if(h){var u=h[1][0]-h[2][0];h[2][0]=t[l].x<e?t[l].x+3:t[l].x-3,h[1][1]=h[2][1]=t[l].y,h[1][0]=h[2][0]+u}}}function oc(){var t=Ay();this.canvas=t,this.blurSize=30,this.pointSize=20,this.maxOpacity=1,this.minOpacity=0,this._gradientPixels={}}function sc(t,e,i){var n=t[1]-t[0];e=p(e,function(e){return{interval:[(e.interval[0]-t[0])/n,(e.interval[1]-t[0])/n]}});var a=e.length,r=0;return function(t){for(var n=r;a>n;n++){var o=e[n].interval;if(o[0]<=t&&t<=o[1]){r=n;break}}if(n===a)for(var n=r-1;n>=0;n--){var o=e[n].interval;if(o[0]<=t&&t<=o[1]){r=n;break}}return n>=0&&a>n&&i[n]}}function lc(t,e){var i=t[1]-t[0];return e=[(e[0]-t[0])/i,(e[1]-t[0])/i],function(t){return t>=e[0]&&t<=e[1]}}function hc(t){var e=t.dimensions;return"lng"===e[0]&&"lat"===e[1]}function uc(t){var e=t.mainData,i=t.datas;i||(i={main:e},t.datasAttr={main:"data"}),t.datas=t.mainData=null,vc(e,i,t),NT(i,function(i){NT(e.TRANSFERABLE_METHODS,function(e){i.wrapMethod(e,x(cc,t))})}),e.wrapMethod("cloneShallow",x(fc,t)),NT(e.CHANGABLE_METHODS,function(i){e.wrapMethod(i,x(dc,t))}),O(i[e.dataType]===e)}function cc(t,e){if(gc(this)){var i=o({},this[BT]);i[this.dataType]=e,vc(e,i,t)}else mc(e,this.dataType,this[VT],t);return e}function dc(t,e){return t.struct&&t.struct.update(this),e}function fc(t,e){return NT(e[BT],function(i,n){i!==e&&mc(i.cloneShallow(),n,e,t)}),e}function pc(t){var e=this[VT];return null==t||null==e?e:e[BT][t]}function gc(t){return t[VT]===t}function vc(t,e,i){t[BT]={},NT(e,function(e,n){mc(e,n,t,i)})}function mc(t,e,i,n){i[BT][e]=t,t[VT]=i,t.dataType=e,n.struct&&(t[n.structAttr]=n.struct,n.struct[n.datasAttr[e]]=t),t.getLinkedData=pc}function yc(t,e,i){this.root,this.data,this._nodes=[],this.hostModel=t,this.levelModels=p(e||[],function(e){return new Pr(e,t,t.ecModel)}),this.leavesModel=new Pr(i||{},t,t.ecModel)}function xc(t,e){var i=e.children;t.parentNode!==e&&(i.push(t),t.parentNode=e)}function _c(t){t.hierNode={defaultAncestor:null,ancestor:t,prelim:0,modifier:0,change:0,shift:0,i:0,thread:null};for(var e,i,n=[t];e=n.pop();)if(i=e.children,e.isExpand&&i.length)for(var a=i.length,r=a-1;r>=0;r--){var o=i[r];o.hierNode={defaultAncestor:null,ancestor:o,prelim:0,modifier:0,change:0,shift:0,i:r,thread:null},n.push(o)}}function wc(t,e){var i=t.isExpand?t.children:[],n=t.parentNode.children,a=t.hierNode.i?n[t.hierNode.i-1]:null;if(i.length){Tc(t);var r=(i[0].hierNode.prelim+i[i.length-1].hierNode.prelim)/2;a?(t.hierNode.prelim=a.hierNode.prelim+e(t,a),t.hierNode.modifier=t.hierNode.prelim-r):t.hierNode.prelim=r}else a&&(t.hierNode.prelim=a.hierNode.prelim+e(t,a));t.parentNode.hierNode.defaultAncestor=Ac(t,a,t.parentNode.hierNode.defaultAncestor||n[0],e)}function bc(t){var e=t.hierNode.prelim+t.parentNode.hierNode.modifier;t.setLayout({x:e},!0),t.hierNode.modifier+=t.parentNode.hierNode.modifier}function Mc(t){return arguments.length?t:Pc}function Sc(t,e){var i={};return t-=Math.PI/2,i.x=e*Math.cos(t),i.y=e*Math.sin(t),i}function Ic(t,e){return uo(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()})}function Tc(t){for(var e=t.children,i=e.length,n=0,a=0;--i>=0;){var r=e[i];r.hierNode.prelim+=n,r.hierNode.modifier+=n,a+=r.hierNode.change,n+=r.hierNode.shift+a}}function Ac(t,e,i,n){if(e){for(var a=t,r=t,o=r.parentNode.children[0],s=e,l=a.hierNode.modifier,h=r.hierNode.modifier,u=o.hierNode.modifier,c=s.hierNode.modifier;s=Cc(s),r=Dc(r),s&&r;){a=Cc(a),o=Dc(o),a.hierNode.ancestor=t;var d=s.hierNode.prelim+c-r.hierNode.prelim-h+n(s,r);d>0&&(kc(Lc(s,t,i),t,d),h+=d,l+=d),c+=s.hierNode.modifier,h+=r.hierNode.modifier,l+=a.hierNode.modifier,u+=o.hierNode.modifier}s&&!Cc(a)&&(a.hierNode.thread=s,a.hierNode.modifier+=c-l),r&&!Dc(o)&&(o.hierNode.thread=r,o.hierNode.modifier+=h-u,i=t)}return i}function Cc(t){var e=t.children;return e.length&&t.isExpand?e[e.length-1]:t.hierNode.thread}function Dc(t){var e=t.children;return e.length&&t.isExpand?e[0]:t.hierNode.thread}function Lc(t,e,i){return t.hierNode.ancestor.parentNode===e.parentNode?t.hierNode.ancestor:i}function kc(t,e,i){var n=i/(e.hierNode.i-t.hierNode.i);e.hierNode.change-=n,e.hierNode.shift+=i,e.hierNode.modifier+=i,e.hierNode.prelim+=i,t.hierNode.change+=n}function Pc(t,e){return t.parentNode===e.parentNode?1:2}function Oc(t,e){var i=t.getItemLayout(e);return i&&!isNaN(i.x)&&!isNaN(i.y)&&"none"!==t.getItemVisual(e,"symbol")}function zc(t,e,i){return i.itemModel=e,i.itemStyle=e.getModel("itemStyle").getItemStyle(),i.hoverItemStyle=e.getModel("emphasis.itemStyle").getItemStyle(),i.lineStyle=e.getModel("lineStyle").getLineStyle(),i.labelModel=e.getModel("label"),i.hoverLabelModel=e.getModel("emphasis.label"),i.symbolInnerColor=t.isExpand===!1&&0!==t.children.length?i.itemStyle.fill:"#fff",i}function Ec(t,e,i,n,a,r){var o=!i,l=t.tree.getNodeByDataIndex(e),h=l.getModel(),r=zc(l,h,r),u=t.tree.root,c=l.parentNode===u?l:l.parentNode||l,d=t.getItemGraphicEl(c.dataIndex),f=c.getLayout(),p=d?{x:d.position[0],y:d.position[1],rawX:d.__radialOldRawX,rawY:d.__radialOldRawY}:f,g=l.getLayout();o?(i=new zu(t,e,r),i.attr("position",[p.x,p.y])):i.updateData(t,e,r),i.__radialOldRawX=i.__radialRawX,i.__radialOldRawY=i.__radialRawY,i.__radialRawX=g.rawX,i.__radialRawY=g.rawY,n.add(i),t.setItemGraphicEl(e,i),Mr(i,{position:[g.x,g.y]},a);var v=i.getSymbolPath();if("radial"===r.layout){var m,y,x=u.children[0],_=x.getLayout(),w=x.children.length;if(g.x===_.x&&l.isExpand===!0){var b={};b.x=(x.children[0].getLayout().x+x.children[w-1].getLayout().x)/2,b.y=(x.children[0].getLayout().y+x.children[w-1].getLayout().y)/2,m=Math.atan2(b.y-_.y,b.x-_.x),0>m&&(m=2*Math.PI+m),y=b.x<_.x,y&&(m-=Math.PI)}else m=Math.atan2(g.y-_.y,g.x-_.x),0>m&&(m=2*Math.PI+m),0===l.children.length||0!==l.children.length&&l.isExpand===!1?(y=g.x<_.x,y&&(m-=Math.PI)):(y=g.x>_.x,y||(m-=Math.PI));var M=y?"left":"right";v.setStyle({textPosition:M,textRotation:-m,textOrigin:"center",verticalAlign:"middle"})}if(l.parentNode&&l.parentNode!==u){var S=i.__edge;S||(S=i.__edge=new jw({shape:Nc(r,p,p),style:s({opacity:0},r.lineStyle)})),Mr(S,{shape:Nc(r,f,g),style:{opacity:1}},a),n.add(S)}}function Rc(t,e,i,n,a,r){for(var o,s=t.tree.getNodeByDataIndex(e),l=t.tree.root,h=s.getModel(),r=zc(s,h,r),u=s.parentNode===l?s:s.parentNode||s;o=u.getLayout(),null==o;)u=u.parentNode===l?u:u.parentNode||u;Mr(i,{position:[o.x+1,o.y+1]},a,function(){n.remove(i),t.setItemGraphicEl(e,null)}),i.fadeOut(null,{keepLabel:!0});var c=i.__edge;c&&Mr(c,{shape:Nc(r,o,o),style:{opacity:0}},a,function(){n.remove(c)})}function Nc(t,e,i){var n,a,r,o,s=t.orient;if("radial"===t.layout){var l=e.rawX,h=e.rawY,u=i.rawX,c=i.rawY,d=Sc(l,h),f=Sc(l,h+(c-h)*t.curvature),p=Sc(u,c+(h-c)*t.curvature),g=Sc(u,c);return{x1:d.x,y1:d.y,x2:g.x,y2:g.y,cpx1:f.x,cpy1:f.y,cpx2:p.x,cpy2:p.y}}var l=e.x,h=e.y,u=i.x,c=i.y;return"horizontal"===s&&(n=l+(u-l)*t.curvature,a=h,r=u+(l-u)*t.curvature,o=c),"vertical"===s&&(n=l,a=h+(c-h)*t.curvature,r=u,o=c+(h-c)*t.curvature),{x1:l,y1:h,x2:u,y2:c,cpx1:n,cpy1:a,cpx2:r,cpy2:o}}function Bc(t,e,i){for(var n,a=[t],r=[];n=a.pop();)if(r.push(n),n.isExpand){var o=n.children;if(o.length)for(var s=0;s<o.length;s++)a.push(o[s])}for(;n=r.pop();)e(n,i)}function Vc(t,e){for(var i,n=[t];i=n.pop();)if(e(i),i.isExpand){var a=i.children;if(a.length)for(var r=a.length-1;r>=0;r--)n.push(a[r])}}function Gc(t){return"_EC_"+t}function Fc(t,e){this.id=null==t?"":t,this.inEdges=[],this.outEdges=[],this.edges=[],this.hostGraph,this.dataIndex=null==e?-1:e}function Wc(t,e,i){this.node1=t,this.node2=e,this.dataIndex=null==i?-1:i}function Hc(t){return isNaN(+t.cpx1)||isNaN(+t.cpy1)}function Zc(t){return"_"+t+"Type"}function jc(t,e,i){var n=e.getItemVisual(i,"color"),a=e.getItemVisual(i,t),r=e.getItemVisual(i,t+"Size");if(a&&"none"!==a){_(r)||(r=[r,r]);var o=zh(a,-r[0]/2,-r[1]/2,r[0],r[1],n);return o.name=t,o}}function Xc(t){var e=new KT({name:"line"});return Uc(e.shape,t),e}function Uc(t,e){var i=e[0],n=e[1],a=e[2];t.x1=i[0],t.y1=i[1],t.x2=n[0],t.y2=n[1],t.percent=1,a?(t.cpx1=a[0],t.cpy1=a[1]):(t.cpx1=0/0,t.cpy1=0/0)}function Yc(){var t=this,e=t.childOfName("fromSymbol"),i=t.childOfName("toSymbol"),n=t.childOfName("label");if(e||i||!n.ignore){for(var a=1,r=this.parent;r;)r.scale&&(a/=r.scale[0]),r=r.parent;var o=t.childOfName("line");if(this.__dirty||o.__dirty){var s=o.shape.percent,l=o.pointAt(0),h=o.pointAt(s),u=U([],h,l);if(te(u,u),e){e.attr("position",l);var c=o.tangentAt(0);e.attr("rotation",Math.PI/2-Math.atan2(c[1],c[0])),e.attr("scale",[a*s,a*s])}if(i){i.attr("position",h);var c=o.tangentAt(1);i.attr("rotation",-Math.PI/2-Math.atan2(c[1],c[0])),i.attr("scale",[a*s,a*s])}if(!n.ignore){n.attr("position",h);var d,f,p,g=5*a;if("end"===n.__position)d=[u[0]*g+h[0],u[1]*g+h[1]],f=u[0]>.8?"left":u[0]<-.8?"right":"center",p=u[1]>.8?"top":u[1]<-.8?"bottom":"middle";else if("middle"===n.__position){var v=s/2,c=o.tangentAt(v),m=[c[1],-c[0]],y=o.pointAt(v);m[1]>0&&(m[0]=-m[0],m[1]=-m[1]),d=[y[0]+m[0]*g,y[1]+m[1]*g],f="center",p="bottom";var x=-Math.atan2(c[1],c[0]);h[0]<l[0]&&(x=Math.PI+x),n.attr("rotation",x)}else d=[-u[0]*g+l[0],-u[1]*g+l[1]],f=u[0]>.8?"right":u[0]<-.8?"left":"center",p=u[1]>.8?"bottom":u[1]<-.8?"top":"middle";n.attr({style:{textVerticalAlign:n.__verticalAlign||p,textAlign:n.__textAlign||f},position:d,scale:[a,a]})}}}}function qc(t,e,i){xx.call(this),this._createLine(t,e,i)}function $c(t){this._ctor=t||qc,this.group=new xx}function Kc(t,e,i,n){var a=e.getItemLayout(i);if(ed(a)){var r=new t._ctor(e,i,n);e.setItemGraphicEl(i,r),t.group.add(r)}}function Jc(t,e,i,n,a,r){var o=e.getItemGraphicEl(n);return ed(i.getItemLayout(a))?(o?o.updateData(i,a,r):o=new t._ctor(i,a,r),i.setItemGraphicEl(a,o),void t.group.add(o)):void t.group.remove(o)}function Qc(t){var e=t.hostModel;return{lineStyle:e.getModel("lineStyle").getLineStyle(),hoverLineStyle:e.getModel("emphasis.lineStyle").getLineStyle(),labelModel:e.getModel("label"),hoverLabelModel:e.getModel("emphasis.label")}}function td(t){return isNaN(t[0])||isNaN(t[1])}function ed(t){return!td(t[0])&&!td(t[1])}function id(t,e,i){var n=rd(t);n[e]=i}function nd(t,e,i){var n=rd(t),a=n[e];a===i&&(n[e]=null)}function ad(t,e){return!!rd(t)[e]}function rd(t){return t[eA]||(t[eA]={})}function od(t){this.pointerChecker,this._zr=t,this._opt={};var e=y,i=e(sd,this),a=e(ld,this),r=e(hd,this),o=e(ud,this),l=e(cd,this);By.call(this),this.setPointerChecker=function(t){this.pointerChecker=t},this.enable=function(e,h){this.disable(),this._opt=s(n(h)||{},{zoomOnMouseWheel:!0,moveOnMouseMove:!0,preventDefaultMouseMove:!0}),null==e&&(e=!0),(e===!0||"move"===e||"pan"===e)&&(t.on("mousedown",i),t.on("mousemove",a),t.on("mouseup",r)),(e===!0||"scale"===e||"zoom"===e)&&(t.on("mousewheel",o),t.on("pinch",l))},this.disable=function(){t.off("mousedown",i),t.off("mousemove",a),t.off("mouseup",r),t.off("mousewheel",o),t.off("pinch",l)},this.dispose=this.disable,this.isDragging=function(){return this._dragging},this.isPinching=function(){return this._pinching}}function sd(t){if(!(xn(t)||t.target&&t.target.draggable)){var e=t.offsetX,i=t.offsetY;this.pointerChecker&&this.pointerChecker(t,e,i)&&(this._x=e,this._y=i,this._dragging=!0)}}function ld(t){if(!xn(t)&&fd(this,"moveOnMouseMove",t)&&this._dragging&&"pinch"!==t.gestureEvent&&!ad(this._zr,"globalPan")){var e=t.offsetX,i=t.offsetY,n=this._x,a=this._y,r=e-n,o=i-a;this._x=e,this._y=i,this._opt.preventDefaultMouseMove&&t_(t.event),this.trigger("pan",r,o,n,a,e,i)}}function hd(t){xn(t)||(this._dragging=!1)}function ud(t){if(fd(this,"zoomOnMouseWheel",t)&&0!==t.wheelDelta){var e=t.wheelDelta>0?1.1:1/1.1;dd.call(this,t,e,t.offsetX,t.offsetY)}}function cd(t){if(!ad(this._zr,"globalPan")){var e=t.pinchScale>1?1.1:1/1.1;dd.call(this,t,e,t.pinchX,t.pinchY)}}function dd(t,e,i,n){this.pointerChecker&&this.pointerChecker(t,i,n)&&(t_(t.event),this.trigger("zoom",e,i,n))}function fd(t,e,i){var n=t._opt[e];return n&&(!b(n)||i.event[n+"Key"])}function pd(t,e,i){var n=t.target,a=n.position;a[0]+=e,a[1]+=i,n.dirty()}function gd(t,e,i,n){var a=t.target,r=t.zoomLimit,o=a.position,s=a.scale,l=t.zoom=t.zoom||1;if(l*=e,r){var h=r.min||0,u=r.max||1/0;l=Math.max(Math.min(u,l),h)}var c=l/t.zoom;t.zoom=l,o[0]-=(i-o[0])*(c-1),o[1]-=(n-o[1])*(c-1),s[0]*=c,s[1]*=c,a.dirty()}function vd(t,e,i){var n=e.getComponentByElement(t.topTarget),a=n&&n.coordinateSystem;return n&&n!==i&&!iA[n.mainType]&&a&&a.model!==i}function md(t,e,i){for(var n,a=t[0],r=t[1],o=t[2],s=1/0,l=i*i,h=.1,u=.1;.9>=u;u+=.1){nA[0]=oA(a[0],r[0],o[0],u),nA[1]=oA(a[1],r[1],o[1],u);
-var c=lA(sA(nA,e)-l);s>c&&(s=c,n=u)}for(var d=0;32>d;d++){var f=n+h;aA[0]=oA(a[0],r[0],o[0],n),aA[1]=oA(a[1],r[1],o[1],n),rA[0]=oA(a[0],r[0],o[0],f),rA[1]=oA(a[1],r[1],o[1],f);var c=sA(aA,e)-l;if(lA(c)<.01)break;var p=sA(rA,e)-l;h/=2,0>c?p>=0?n+=h:n-=h:p>=0?n-=h:n+=h}return n}function yd(t,e){return t.getVisual("opacity")||t.getModel().get(e)}function xd(t,e,i){var n=t.getGraphicEl(),a=yd(t,e);null!=i&&(null==a&&(a=1),a*=i),n.downplay&&n.downplay(),n.traverse(function(t){"group"!==t.type&&t.setStyle("opacity",a)})}function _d(t,e){var i=yd(t,e),n=t.getGraphicEl();n.highlight&&n.highlight(),n.traverse(function(t){"group"!==t.type&&t.setStyle("opacity",i)})}function wd(t,e,i){var n=t.getZoom(),a=t.getCenter(),r=e.zoom,o=t.dataToPoint(a);if(null!=e.dx&&null!=e.dy){o[0]-=e.dx,o[1]-=e.dy;var a=t.pointToData(o);t.setCenter(a)}if(null!=r){if(i){var s=i.min||0,l=i.max||1/0;r=Math.max(Math.min(n*r,l),s)/n}t.scale[0]*=r,t.scale[1]*=r;var h=t.position,u=(e.originX-h[0])*(r-1),c=(e.originY-h[1])*(r-1);h[0]-=u,h[1]-=c,t.updateTransform();var a=t.pointToData(o);t.setCenter(a),t.setZoom(r*n)}return{center:t.getCenter(),zoom:t.getZoom()}}function bd(t){return t instanceof Array||(t=[t,t]),t}function Md(t){var e=t.coordinateSystem;if(!e||"view"===e.type){var i=t.getGraph();i.eachNode(function(t){var e=t.getModel();t.setLayout([+e.get("x"),+e.get("y")])}),Sd(i)}}function Sd(t){t.eachEdge(function(t){var e=t.getModel().get("lineStyle.curveness")||0,i=H(t.node1.getLayout()),n=H(t.node2.getLayout()),a=[i,n];+e&&a.push([(i[0]+n[0])/2-(i[1]-n[1])*e,(i[1]+n[1])/2-(n[0]-i[0])*e]),t.setLayout(a)})}function Id(t){var e=t.coordinateSystem;if(!e||"view"===e.type){var i=e.getBoundingRect(),n=t.getData(),a=n.graph,r=0,o=n.getSum("value"),s=2*Math.PI/(o||n.count()),l=i.width/2+i.x,h=i.height/2+i.y,u=Math.min(i.width,i.height)/2;a.eachNode(function(t){var e=t.getValue("value");r+=s*(o?e:1)/2,t.setLayout([u*Math.cos(r)+l,u*Math.sin(r)+h]),r+=s*(o?e:1)/2}),n.setLayout({cx:l,cy:h}),a.eachEdge(function(t){var e,i=t.getModel().get("lineStyle.curveness")||0,n=H(t.node1.getLayout()),a=H(t.node2.getLayout()),r=(n[0]+a[0])/2,o=(n[1]+a[1])/2;+i&&(i*=3,e=[l*i+r*(1-i),h*i+o*(1-i)]),t.setLayout([n,a,e])})}}function Td(t,e,i){for(var n=i.rect,a=n.width,r=n.height,o=[n.x+a/2,n.y+r/2],s=null==i.gravity?.1:i.gravity,l=0;l<t.length;l++){var h=t[l];h.p||(h.p=F(a*(Math.random()-.5)+o[0],r*(Math.random()-.5)+o[1])),h.pp=H(h.p),h.edges=null}var u=.6;return{warmUp:function(){u=.5},setFixed:function(e){t[e].fixed=!0},setUnfixed:function(e){t[e].fixed=!1},step:function(i){for(var n=[],a=t.length,r=0;r<e.length;r++){var l=e[r],h=l.n1,c=l.n2;U(n,c.p,h.p);var d=Y(n)-l.d,f=c.w/(h.w+c.w);isNaN(f)&&(f=0),te(n,n),!h.fixed&&yA(h.p,h.p,n,f*d*u),!c.fixed&&yA(c.p,c.p,n,-(1-f)*d*u)}for(var r=0;a>r;r++){var p=t[r];p.fixed||(U(n,o,p.p),yA(p.p,p.p,n,s*u))}for(var r=0;a>r;r++)for(var h=t[r],g=r+1;a>g;g++){var c=t[g];U(n,c.p,h.p);var d=Y(n);0===d&&(Z(n,Math.random()-.5,Math.random()-.5),d=1);var v=(h.rep+c.rep)/d/d;!h.fixed&&yA(h.pp,h.pp,n,v),!c.fixed&&yA(c.pp,c.pp,n,-v)}for(var m=[],r=0;a>r;r++){var p=t[r];p.fixed||(U(m,p.p,p.pp),yA(p.p,p.p,m,u),W(p.pp,p.p))}u=.992*u,i&&i(t,e,.01>u)}}}function Ad(){Xy.call(this)}function Cd(t){this.name=t,this.zoomLimit,Xy.call(this),this._roamTransformable=new Ad,this._rawTransformable=new Ad,this._center,this._zoom}function Dd(t,e,i,n){var a=i.seriesModel,r=a?a.coordinateSystem:null;return r===this?r[t](n):null}function Ld(t,e,i){var n=t.getBoxLayoutParams();return n.aspect=i,uo(n,{width:e.getWidth(),height:e.getHeight()})}function kd(t){if(!t.parallel){var e=!1;f(t.series,function(t){t&&"parallel"===t.type&&(e=!0)}),e&&(t.parallel=[{}])}}function Pd(t){var e=On(t.parallelAxis);f(e,function(e){if(M(e)){var i=e.parallelIndex||0,n=On(t.parallel)[i];n&&n.parallelAxisDefault&&a(e,n.parallelAxisDefault,!1)}})}function Od(t,e){var i=t[e]-t[1-e];return{span:Math.abs(i),sign:i>0?-1:0>i?1:e?-1:1}}function zd(t,e){return Math.min(e[1],Math.max(e[0],t))}function Ed(t,e,i){this._axesMap=B(),this._axesLayout={},this.dimensions=t.dimensions,this._rect,this._model=t,this._init(t,e,i)}function Rd(t,e){return TA(AA(t,e[0]),e[1])}function Nd(t,e){var i=e.layoutLength/(e.axisCount-1);return{position:i*t,axisNameAvailableWidth:i,axisLabelShow:!0}}function Bd(t,e){var i,n,a=e.layoutLength,r=e.axisExpandWidth,o=e.axisCount,s=e.axisCollapseWidth,l=e.winInnerIndices,h=s,u=!1;return t<l[0]?(i=t*s,n=s):t<=l[1]?(i=e.axisExpandWindow0Pos+t*r-e.axisExpandWindow[0],h=r,u=!0):(i=a-(o-1-t)*s,n=s),{position:i,axisNameAvailableWidth:h,axisLabelShow:u,nameTruncateMaxWidth:n}}function Vd(t,e){var i=[];return t.eachComponent("parallel",function(n,a){var r=new Ed(n,t,e);r.name="parallel_"+a,r.resize(n,e),n.coordinateSystem=r,r.model=n,i.push(r)}),t.eachSeries(function(e){if("parallel"===e.get("coordinateSystem")){var i=t.queryComponents({mainType:"parallel",index:e.get("parallelIndex"),id:e.get("parallelId")})[0];e.coordinateSystem=i.coordinateSystem}}),i}function Gd(t,e){return e.type||(e.data?"category":"value")}function Fd(t){By.call(this),this._zr=t,this.group=new xx,this._brushType,this._brushOption,this._panels,this._track=[],this._dragging,this._covers=[],this._creatingCover,this._creatingPanel,this._enableGlobalPan,this._uid="brushController_"+YA++,this._handlers={},RA(qA,function(t,e){this._handlers[e]=y(t,this)},this)}function Wd(t,e){var i=t._zr;t._enableGlobalPan||id(i,ZA,t._uid),RA(t._handlers,function(t,e){i.on(e,t)}),t._brushType=e.brushType,t._brushOption=a(n(UA),e,!0)}function Hd(t){var e=t._zr;nd(e,ZA,t._uid),RA(t._handlers,function(t,i){e.off(i,t)}),t._brushType=t._brushOption=null}function Zd(t,e){var i=$A[e.brushType].createCover(t,e);return i.__brushOption=e,Ud(i,e),t.group.add(i),i}function jd(t,e){var i=qd(e);return i.endCreating&&(i.endCreating(t,e),Ud(e,e.__brushOption)),e}function Xd(t,e){var i=e.__brushOption;qd(e).updateCoverShape(t,e,i.range,i)}function Ud(t,e){var i=e.z;null==i&&(i=FA),t.traverse(function(t){t.z=i,t.z2=i})}function Yd(t,e){qd(e).updateCommon(t,e),Xd(t,e)}function qd(t){return $A[t.__brushOption.brushType]}function $d(t,e,i){var n=t._panels;if(!n)return!0;var a,r=t._transform;return RA(n,function(t){t.isTargetByCursor(e,i,r)&&(a=t)}),a}function Kd(t,e){var i=t._panels;if(!i)return!0;var n=e.__brushOption.panelId;return null!=n?i[n]:!0}function Jd(t){var e=t._covers,i=e.length;return RA(e,function(e){t.group.remove(e)},t),e.length=0,!!i}function Qd(t,e){var i=NA(t._covers,function(t){var e=t.__brushOption,i=n(e.range);return{brushType:e.brushType,panelId:e.panelId,range:i}});t.trigger("brush",i,{isEnd:!!e.isEnd,removeOnClick:!!e.removeOnClick})}function tf(t){var e=t._track;if(!e.length)return!1;var i=e[e.length-1],n=e[0],a=i[0]-n[0],r=i[1]-n[1],o=GA(a*a+r*r,.5);return o>WA}function ef(t){var e=t.length-1;return 0>e&&(e=0),[t[0],t[e]]}function nf(t,e,i,n){var a=new xx;return a.add(new Ww({name:"main",style:sf(i),silent:!0,draggable:!0,cursor:"move",drift:EA(t,e,a,"nswe"),ondragend:EA(Qd,e,{isEnd:!0})})),RA(n,function(i){a.add(new Ww({name:i,style:{opacity:0},draggable:!0,silent:!0,invisible:!0,drift:EA(t,e,a,i),ondragend:EA(Qd,e,{isEnd:!0})}))}),a}function af(t,e,i,n){var a=n.brushStyle.lineWidth||0,r=VA(a,HA),o=i[0][0],s=i[1][0],l=o-a/2,h=s-a/2,u=i[0][1],c=i[1][1],d=u-r+a/2,f=c-r+a/2,p=u-o,g=c-s,v=p+a,m=g+a;of(t,e,"main",o,s,p,g),n.transformable&&(of(t,e,"w",l,h,r,m),of(t,e,"e",d,h,r,m),of(t,e,"n",l,h,v,r),of(t,e,"s",l,f,v,r),of(t,e,"nw",l,h,r,r),of(t,e,"ne",d,h,r,r),of(t,e,"sw",l,f,r,r),of(t,e,"se",d,f,r,r))}function rf(t,e){var i=e.__brushOption,n=i.transformable,a=e.childAt(0);a.useStyle(sf(i)),a.attr({silent:!n,cursor:n?"move":"default"}),RA(["w","e","n","s","se","sw","ne","nw"],function(i){var a=e.childOfName(i),r=uf(t,i);a&&a.attr({silent:!n,invisible:!n,cursor:n?XA[r]+"-resize":null})})}function of(t,e,i,n,a,r,o){var s=e.childOfName(i);s&&s.setShape(gf(pf(t,e,[[n,a],[n+r,a+o]])))}function sf(t){return s({strokeNoScale:!0},t.brushStyle)}function lf(t,e,i,n){var a=[BA(t,i),BA(e,n)],r=[VA(t,i),VA(e,n)];return[[a[0],r[0]],[a[1],r[1]]]}function hf(t){return Ir(t.group)}function uf(t,e){if(e.length>1){e=e.split("");var i=[uf(t,e[0]),uf(t,e[1])];return("e"===i[0]||"w"===i[0])&&i.reverse(),i.join("")}var n={w:"left",e:"right",n:"top",s:"bottom"},a={left:"w",right:"e",top:"n",bottom:"s"},i=Ar(n[e],hf(t));return a[i]}function cf(t,e,i,n,a,r,o){var s=n.__brushOption,l=t(s.range),h=ff(i,r,o);RA(a.split(""),function(t){var e=jA[t];l[e[0]][e[1]]+=h[e[0]]}),s.range=e(lf(l[0][0],l[1][0],l[0][1],l[1][1])),Yd(i,n),Qd(i,{isEnd:!1})}function df(t,e,i,n){var a=e.__brushOption.range,r=ff(t,i,n);RA(a,function(t){t[0]+=r[0],t[1]+=r[1]}),Yd(t,e),Qd(t,{isEnd:!1})}function ff(t,e,i){var n=t.group,a=n.transformCoordToLocal(e,i),r=n.transformCoordToLocal(0,0);return[a[0]-r[0],a[1]-r[1]]}function pf(t,e,i){var a=Kd(t,e);return a&&a!==!0?a.clipPath(i,t._transform):n(i)}function gf(t){var e=BA(t[0][0],t[1][0]),i=BA(t[0][1],t[1][1]),n=VA(t[0][0],t[1][0]),a=VA(t[0][1],t[1][1]);return{x:e,y:i,width:n-e,height:a-i}}function vf(t,e,i){if(t._brushType){var n=t._zr,a=t._covers,r=$d(t,e,i);if(!t._dragging)for(var o=0;o<a.length;o++){var s=a[o].__brushOption;if(r&&(r===!0||s.panelId===r.panelId)&&$A[s.brushType].contain(a[o],i[0],i[1]))return}r&&n.setCursorStyle("crosshair")}}function mf(t){var e=t.event;e.preventDefault&&e.preventDefault()}function yf(t,e,i){return t.childOfName("main").contain(e,i)}function xf(t,e,i,a){var r,o=t._creatingCover,s=t._creatingPanel,l=t._brushOption;if(t._track.push(i.slice()),tf(t)||o){if(s&&!o){"single"===l.brushMode&&Jd(t);var h=n(l);h.brushType=_f(h.brushType,s),h.panelId=s===!0?null:s.panelId,o=t._creatingCover=Zd(t,h),t._covers.push(o)}if(o){var u=$A[_f(t._brushType,s)],c=o.__brushOption;c.range=u.getCreatingRange(pf(t,o,t._track)),a&&(jd(t,o),u.updateCommon(t,o)),Xd(t,o),r={isEnd:a}}}else a&&"single"===l.brushMode&&l.removeOnClick&&$d(t,e,i)&&Jd(t)&&(r={isEnd:a,removeOnClick:!0});return r}function _f(t,e){return"auto"===t?e.defaultBrushType:t}function wf(t){if(this._dragging){mf(t);var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY),i=xf(this,t,e,!0);this._dragging=!1,this._track=[],this._creatingCover=null,i&&Qd(this,i)}}function bf(t){return{createCover:function(e,i){return nf(EA(cf,function(e){var i=[e,[0,100]];return t&&i.reverse(),i},function(e){return e[t]}),e,i,[["w","e"],["n","s"]][t])},getCreatingRange:function(e){var i=ef(e),n=BA(i[0][t],i[1][t]),a=VA(i[0][t],i[1][t]);return[n,a]},updateCoverShape:function(e,i,n,a){var r,o=Kd(e,i);if(o!==!0&&o.getLinearBrushOtherExtent)r=o.getLinearBrushOtherExtent(t,e._transform);else{var s=e._zr;r=[0,[s.getWidth(),s.getHeight()][1-t]]}var l=[n,r];t&&l.reverse(),af(e,i,l,a)},updateCommon:rf,contain:yf}}function Mf(t){return t=Tf(t),function(e){return Dr(e,t)}}function Sf(t,e){return t=Tf(t),function(i){var n=null!=e?e:i,a=n?t.width:t.height,r=n?t.x:t.y;return[r,r+(a||0)]}}function If(t,e,i){return t=Tf(t),function(n,a){return t.contain(a[0],a[1])&&!vd(n,e,i)}}function Tf(t){return ni.create(t)}function Af(t,e,i){return i&&"axisAreaSelect"===i.type&&e.findComponents({mainType:"parallelAxis",query:i})[0]===t}function Cf(t){var e=t.axis;return p(t.activeIntervals,function(t){return{brushType:"lineX",panelId:"pl",range:[e.dataToCoord(t[0],!0),e.dataToCoord(t[1],!0)]}})}function Df(t,e){return e.getComponent("parallel",t.get("parallelIndex"))}function Lf(t,e){var i=t._model;return i.get("axisExpandable")&&i.get("axisExpandTriggerOn")===e}function kf(t,e){if(!t.encodeDefine){var i=e.ecModel.getComponent("parallel",e.get("parallelIndex"));if(i){var n=t.encodeDefine=B();f(i.dimensions,function(t){var e=Pf(t);n.set(t,e)})}}}function Pf(t){return+t.replace("dim","")}function Of(t,e,i){var n=t.model,a=t.getRect(),r=new Ww({shape:{x:a.x,y:a.y,width:a.width,height:a.height}}),o="horizontal"===n.get("layout")?"width":"height";return r.setShape(o,0),Sr(r,{shape:{width:a.width,height:a.height}},e,i),r}function zf(t,e,i,n){for(var a=[],r=0;r<i.length;r++){var o=i[r],s=t.get(t.mapDimension(o),e);Nf(s,n.getAxis(o).type)||a.push(n.dataToPoint(s,o))}return a}function Ef(t,e,i,n,a){var r=zf(t,i,n,a),o=new Fw({shape:{points:r},silent:!0,z2:10});e.add(o),t.setItemGraphicEl(i,o)}function Rf(t,e){var i=t.hostModel.getModel("lineStyle"),n=i.getLineStyle();t.eachItemGraphicEl(function(a,r){if(t.hasItemOption){var s=t.getItemModel(r),l=s.getModel("lineStyle",i);n=l.getLineStyle(["color","stroke"])}a.useStyle(o(n,{fill:null,stroke:t.getItemVisual(r,"color"),opacity:t.getItemVisual(r,"opacity")})),a.shape.smooth=e})}function Nf(t,e){return"category"===e?null==t:null==t||isNaN(t)}function Bf(t,e){var i=t.get("center"),n=e.getWidth(),a=e.getHeight(),r=Math.min(n,a),o=Gr(i[0],e.getWidth()),s=Gr(i[1],e.getHeight()),l=Gr(t.get("radius"),r/2);return{cx:o,cy:s,r:l}}function Vf(t,e){return e&&("string"==typeof e?t=e.replace("{value}",null!=t?t:""):"function"==typeof e&&(t=e(t))),t}function Gf(t,e){return e=e||[0,0],p(["x","y"],function(i,n){var a=this.getAxis(i),r=e[n],o=t[n]/2;return"category"===a.type?a.getBandWidth():Math.abs(a.dataToCoord(r-o)-a.dataToCoord(r+o))},this)}function Ff(t,e){return e=e||[0,0],p([0,1],function(i){var n=e[i],a=t[i]/2,r=[],o=[];return r[i]=n-a,o[i]=n+a,r[1-i]=o[1-i]=e[1-i],Math.abs(this.dataToPoint(r)[i]-this.dataToPoint(o)[i])},this)}function Wf(t,e){var i=this.getAxis(),n=e instanceof Array?e[0]:e,a=(t instanceof Array?t[0]:t)/2;return"category"===i.type?i.getBandWidth():Math.abs(i.dataToCoord(n-a)-i.dataToCoord(n+a))}function Hf(t,e){return p(["Radius","Angle"],function(i,n){var a=this["get"+i+"Axis"](),r=e[n],o=t[n]/2,s="dataTo"+i,l="category"===a.type?a.getBandWidth():Math.abs(a[s](r-o)-a[s](r+o));return"Angle"===i&&(l=l*Math.PI/180),l},this)}function Zf(t){var e,i=t.type;if("path"===i){var n=t.shape;e=Xa(n.pathData,null,{x:n.x||0,y:n.y||0,width:n.width||0,height:n.height||0},"center"),e.__customPathData=t.pathData}else if("image"===i)e=new on({}),e.__customImagePath=t.style.image;else if("text"===i)e=new Pw({}),e.__customText=t.style.text;else{var a=nb[i.charAt(0).toUpperCase()+i.slice(1)];e=new a}return e.__customGraphicType=i,e.name=t.name,e}function jf(t,e,i,a,r,o){var s={},l=i.style||{};if(i.shape&&(s.shape=n(i.shape)),i.position&&(s.position=i.position.slice()),i.scale&&(s.scale=i.scale.slice()),i.origin&&(s.origin=i.origin.slice()),i.rotation&&(s.rotation=i.rotation),"image"===t.type&&i.style){var h=s.style={};f(["x","y","width","height"],function(e){Xf(e,h,l,t.style,o)})}if("text"===t.type&&i.style){var h=s.style={};f(["x","y"],function(e){Xf(e,h,l,t.style,o)}),!l.hasOwnProperty("textFill")&&l.fill&&(l.textFill=l.fill),!l.hasOwnProperty("textStroke")&&l.stroke&&(l.textStroke=l.stroke)}if("group"!==t.type&&(t.useStyle(l),o)){t.style.opacity=0;var u=l.opacity;null==u&&(u=1),Sr(t,{style:{opacity:u}},a,e)}o?t.attr(s):Mr(t,s,a,e),t.attr({z2:i.z2||0,silent:i.silent}),i.styleEmphasis!==!1&&cr(t,i.styleEmphasis)}function Xf(t,e,i,n,a){null==i[t]||a||(e[t]=i[t],i[t]=n[t])}function Uf(t,e,i,n){function a(t){null==t&&(t=m),S&&(y=e.getItemModel(t),x=y.getModel(fC),_=y.getModel(pC),w=e.getItemVisual(t,"color"),S=!1)}function r(t,i){return null==i&&(i=m),e.get(e.getDimension(t||0),i)}function l(i,n){null==n&&(n=m),a(n);var r=y.getModel(cC).getItemStyle();null!=w&&(r.fill=w);var s=e.getItemVisual(n,"opacity");return null!=s&&(r.opacity=s),fr(r,x,null,{autoColor:w,isRectText:!0}),r.text=x.getShallow("show")?D(t.getFormattedLabel(n,"normal"),iu(e,n)):null,i&&o(r,i),r}function h(i,n){null==n&&(n=m),a(n);var r=y.getModel(dC).getItemStyle();return fr(r,_,null,{isRectText:!0},!0),r.text=_.getShallow("show")?L(t.getFormattedLabel(n,"emphasis"),t.getFormattedLabel(n,"normal"),iu(e,n)):null,i&&o(r,i),r}function u(t,i){return null==i&&(i=m),e.getItemVisual(i,t)}function c(t){if(g.getBaseAxis){var e=g.getBaseAxis();return _h(s({axis:e},t),n)}}function d(){return i.getCurrentSeriesIndices()}function f(t){return wr(t,i)}var p=t.get("renderItem"),g=t.coordinateSystem,v={};g&&(v=g.prepareCustoms?g.prepareCustoms():vC[g.type](g));var m,y,x,_,w,b=s({getWidth:n.getWidth,getHeight:n.getHeight,getZr:n.getZr,getDevicePixelRatio:n.getDevicePixelRatio,value:r,style:l,styleEmphasis:h,visual:u,barLayout:c,currentSeriesIndices:d,font:f},v.api||{}),M={context:{},seriesId:t.id,seriesName:t.name,seriesIndex:t.seriesIndex,coordSys:v.coordSys,dataInsideLength:e.count(),encode:Yf(t.getData())},S=!0;return function(t){return m=t,S=!0,p&&p(s({dataIndexInside:t,dataIndex:e.getRawIndex(t)},M),b)||{}}}function Yf(t){var e={};return f(t.dimensions,function(i,n){var a=t.getDimensionInfo(i);if(!a.isExtraCoord){var r=a.coordDim,o=e[r]=e[r]||[];o[a.coordDimIndex]=n}}),e}function qf(t,e,i,n,a,r){return t=$f(t,e,i,n,a,r),t&&r.setItemGraphicEl(e,t),t}function $f(t,e,i,n,a,r){var o=i.type;if(!t||o===t.__customGraphicType||"path"===o&&i.pathData===t.__customPathData||"image"===o&&i.style.image===t.__customImagePath||"text"===o&&i.style.text===t.__customText||(a.remove(t),t=null),null!=o){var s=!t;if(!t&&(t=Zf(i)),jf(t,e,i,n,r,s),"group"===o){var l=t.children()||[],h=i.children||[];if(i.diffChildrenByName)Kf({oldChildren:l,newChildren:h,dataIndex:e,animatableModel:n,group:t,data:r});else{for(var u=0;u<h.length;u++)$f(t.childAt(u),e,h[u],n,t,r);for(;u<l.length;u++)l[u]&&t.remove(l[u])}}return a.add(t),t}}function Kf(t){new Wl(t.oldChildren,t.newChildren,Jf,Jf,t).add(Qf).update(Qf).remove(tp).execute()}function Jf(t,e){var i=t&&t.name;return null!=i?i:gC+e}function Qf(t,e){var i=this.context,n=null!=t?i.newChildren[t]:null,a=null!=e?i.oldChildren[e]:null;$f(a,i.dataIndex,n,i.animatableModel,i.group,i.data)}function tp(t){var e=this.context,i=e.oldChildren[t];i&&e.group.remove(i)}function ep(t){return t.get("stack")||"__ec_stack_"+t.seriesIndex}function ip(t){return t.dim}function np(t,e,i){var n=i.getWidth(),a=i.getHeight(),r={},o={},s=ap(v(e.getSeriesByType(t),function(t){return!e.isSeriesFiltered(t)&&t.coordinateSystem&&"polar"===t.coordinateSystem.type}));e.eachSeriesByType(t,function(t){if("polar"===t.coordinateSystem.type){var e=t.getData(),i=t.coordinateSystem,l=i.getAngleAxis(),h=i.getBaseAxis(),u=ep(t),c=s[ip(h)][u],d=c.offset,f=c.width,p=i.getOtherAxis(h),g=t.get("center")||["50%","50%"],v=Gr(g[0],n),m=Gr(g[1],a),y=t.get("barMinHeight")||0,x=t.get("barMinAngle")||0,_=p.getExtent()[0],w=p.model.get("max"),b=p.model.get("min"),M=[e.mapDimension("radius"),e.mapDimension("angle")],S=e.mapArray(M,function(t,e){return i.dataToPoint([t,e])},!0);r[u]=r[u]||[],o[u]=o[u]||[],e.each(e.mapDimension(p.dim),function(t,n){if(!isNaN(t)){r[u][n]||(r[u][n]={p:_,n:_},o[u][n]={p:_,n:_});var a,s,h,c,g=t>=0?"p":"n",M=i.pointToCoord(S[n]),I=o[u][n][g];if("radius"===p.dim)a=I,s=M[0],h=(-M[1]+d)*Math.PI/180,c=h+f*Math.PI/180,Math.abs(s)<y&&(s=a+(0>s?-1:1)*y),o[u][n][g]=s;else{a=M[0]+d,s=a+f,null!=w&&(t=Math.min(t,w)),null!=b&&(t=Math.max(t,b));var T=l.dataToAngle(t);Math.abs(T-I)<x&&(T=I-(0>t?-1:1)*x),h=-I*Math.PI/180,c=-T*Math.PI/180;var A=l.getExtent(),C=T;C===A[0]&&t>0?C=A[1]:C===A[1]&&0>t&&(C=A[0]),o[u][n][g]=C}e.setItemLayout(n,{cx:v,cy:m,r0:a,r:s,startAngle:h,endAngle:c})}},!0)}},this)}function ap(t){var e={};f(t,function(t){var i=t.getData(),n=t.coordinateSystem,a=n.getBaseAxis(),r=a.getExtent(),o="category"===a.type?a.getBandWidth():Math.abs(r[1]-r[0])/i.count(),s=e[ip(a)]||{bandWidth:o,remainedWidth:o,autoWidthCount:0,categoryGap:"20%",gap:"30%",stacks:{}},l=s.stacks;e[ip(a)]=s;var h=ep(t);l[h]||s.autoWidthCount++,l[h]=l[h]||{width:0,maxWidth:0};var u=Gr(t.get("barWidth"),o),c=Gr(t.get("barMaxWidth"),o),d=t.get("barGap"),f=t.get("barCategoryGap");u&&!l[h].width&&(u=Math.min(s.remainedWidth,u),l[h].width=u,s.remainedWidth-=u),c&&(l[h].maxWidth=c),null!=d&&(s.gap=d),null!=f&&(s.categoryGap=f)});var i={};return f(e,function(t,e){i[e]={};var n=t.stacks,a=t.bandWidth,r=Gr(t.categoryGap,a),o=Gr(t.gap,1),s=t.remainedWidth,l=t.autoWidthCount,h=(s-r)/(l+(l-1)*o);h=Math.max(h,0),f(n,function(t){var e=t.maxWidth;e&&h>e&&(e=Math.min(e,s),t.width&&(e=Math.min(e,t.width)),s-=e,t.width=e,l--)}),h=(s-r)/(l+(l-1)*o),h=Math.max(h,0);var u,c=0;f(n,function(t){t.width||(t.width=h),u=t,c+=t.width*(1+o)}),u&&(c-=u.width*o);var d=-c/2;f(n,function(t,n){i[e][n]=i[e][n]||{offset:d,width:t.width},d+=t.width*(1+o)})}),i}function rp(t,e){wI.call(this,"radius",t,e),this.type="category"}function op(t,e){e=e||[0,360],wI.call(this,"angle",t,e),this.type="category"}function sp(t,e){return e.type||(e.data?"category":"value")}function lp(t,e,i){var n=e.get("center"),a=i.getWidth(),r=i.getHeight();t.cx=Gr(n[0],a),t.cy=Gr(n[1],r);var o=t.getRadiusAxis(),s=Math.min(a,r)/2,l=Gr(e.get("radius"),s);o.inverse?o.setExtent(l,0):o.setExtent(0,l)}function hp(t){var e=this,i=e.getAngleAxis(),n=e.getRadiusAxis();if(i.scale.setExtent(1/0,-1/0),n.scale.setExtent(1/0,-1/0),t.eachSeries(function(t){if(t.coordinateSystem===e){var a=t.getData();f(a.mapDimension("radius",!0),function(t){n.scale.unionExtentFromData(a,t)}),f(a.mapDimension("angle",!0),function(t){i.scale.unionExtentFromData(a,t)})}}),Ah(i.scale,i.model),Ah(n.scale,n.model),"category"===i.type&&!i.onBand){var a=i.getExtent(),r=360/i.scale.count();i.inverse?a[1]+=r:a[1]-=r,i.setExtent(a[0],a[1])}}function up(t,e){if(t.type=e.get("type"),t.scale=Ch(e),t.onBand=e.get("boundaryGap")&&"category"===t.type,t.inverse=e.get("inverse"),"angleAxis"===e.mainType){t.inverse^=e.get("clockwise");var i=e.get("startAngle");t.setExtent(i,i+(t.inverse?-360:360))}e.axis=t,t.model=e}function cp(t,e,i){e[1]>e[0]&&(e=e.slice().reverse());var n=t.coordToPoint([e[0],i]),a=t.coordToPoint([e[1],i]);return{x1:n[0],y1:n[1],x2:a[0],y2:a[1]}}function dp(t){var e=t.getRadiusAxis();return e.inverse?0:1}function fp(t,e,i){return{position:[t.cx,t.cy],rotation:i/180*Math.PI,labelDirection:-1,tickDirection:-1,nameDirection:1,labelRotate:e.getModel("axisLabel").get("rotate"),z2:1}}function pp(t,e,i,n,a){var r=t.axis;if(!r.scale.isBlank()&&r.containData(e)){if(!t.involveSeries)return void i.showPointer(t,e);var s=gp(e,t),l=s.payloadBatch,h=s.snapToValue;l[0]&&null==a.seriesIndex&&o(a,l[0]),!n&&t.snap&&r.containData(h)&&null!=h&&(e=h),i.showPointer(t,e,l,a),i.showTooltip(t,s,h)}}function gp(t,e){var i=e.axis,n=i.dim,a=t,r=[],o=Number.MAX_VALUE,s=-1;return IC(e.seriesModels,function(e){var l,h,u=e.getData().mapDimension(n,!0);if(e.getAxisTooltipData){var c=e.getAxisTooltipData(u,t,i);h=c.dataIndices,l=c.nestestValue}else{if(h=e.getData().indicesOfNearest(u[0],t,!1,"category"===i.type?.5:null),!h.length)return;l=e.getData().get(u[0],h[0])}if(null!=l&&isFinite(l)){var d=t-l,f=Math.abs(d);o>=f&&((o>f||d>=0&&0>s)&&(o=f,s=d,a=l,r.length=0),IC(h,function(t){r.push({seriesIndex:e.seriesIndex,dataIndexInside:t,dataIndex:e.getData().getRawIndex(t)})}))}}),{payloadBatch:r,snapToValue:a}}function vp(t,e,i,n){t[e.key]={value:i,payloadBatch:n}}function mp(t,e,i,n){var a=i.payloadBatch,r=e.axis,o=r.model,s=e.axisPointerModel;if(e.triggerTooltip&&a.length){var l=e.coordSys.model,h=Cu(l),u=t.map[h];u||(u=t.map[h]={coordSysId:l.id,coordSysIndex:l.componentIndex,coordSysType:l.type,coordSysMainType:l.mainType,dataByAxis:[]},t.list.push(u)),u.dataByAxis.push({axisDim:r.dim,axisIndex:o.componentIndex,axisType:o.type,axisId:o.id,value:n,valueLabelOpt:{precision:s.get("label.precision"),formatter:s.get("label.formatter")},seriesDataIndices:a.slice()})}}function yp(t,e,i){var n=i.axesInfo=[];IC(e,function(e,i){var a=e.axisPointerModel.option,r=t[i];r?(!e.useHandle&&(a.status="show"),a.value=r.value,a.seriesDataIndices=(r.payloadBatch||[]).slice()):!e.useHandle&&(a.status="hide"),"show"===a.status&&n.push({axisDim:e.axis.dim,axisIndex:e.axis.model.componentIndex,value:a.value})})}function xp(t,e,i,n){if(Mp(e)||!t.list.length)return void n({type:"hideTip"});var a=((t.list[0].dataByAxis[0]||{}).seriesDataIndices||[])[0]||{};n({type:"showTip",escapeConnect:!0,x:e[0],y:e[1],tooltipOption:i.tooltipOption,position:i.position,dataIndexInside:a.dataIndexInside,dataIndex:a.dataIndex,seriesIndex:a.seriesIndex,dataByCoordSys:t.list})}function _p(t,e,i){var n=i.getZr(),a="axisPointerLastHighlights",r=AC(n)[a]||{},o=AC(n)[a]={};IC(t,function(t){var e=t.axisPointerModel.option;"show"===e.status&&IC(e.seriesDataIndices,function(t){var e=t.seriesIndex+" | "+t.dataIndex;o[e]=t})});var s=[],l=[];f(r,function(t,e){!o[e]&&l.push(t)}),f(o,function(t,e){!r[e]&&s.push(t)}),l.length&&i.dispatchAction({type:"downplay",escapeConnect:!0,batch:l}),s.length&&i.dispatchAction({type:"highlight",escapeConnect:!0,batch:s})}function wp(t,e){for(var i=0;i<(t||[]).length;i++){var n=t[i];if(e.axis.dim===n.axisDim&&e.axis.model.componentIndex===n.axisIndex)return n}}function bp(t){var e=t.axis.model,i={},n=i.axisDim=t.axis.dim;return i.axisIndex=i[n+"AxisIndex"]=e.componentIndex,i.axisName=i[n+"AxisName"]=e.name,i.axisId=i[n+"AxisId"]=e.id,i}function Mp(t){return!t||null==t[0]||isNaN(t[0])||null==t[1]||isNaN(t[1])}function Sp(t,e,i){if(!vy.node){var n=e.getZr();DC(n).records||(DC(n).records={}),Ip(n,e);var a=DC(n).records[t]||(DC(n).records[t]={});a.handler=i}}function Ip(t,e){function i(i,n){t.on(i,function(i){var a=Dp(e);LC(DC(t).records,function(t){t&&n(t,i,a.dispatchAction)}),Tp(a.pendings,e)})}DC(t).initialized||(DC(t).initialized=!0,i("click",x(Cp,"click")),i("mousemove",x(Cp,"mousemove")),i("globalout",Ap))}function Tp(t,e){var i,n=t.showTip.length,a=t.hideTip.length;n?i=t.showTip[n-1]:a&&(i=t.hideTip[a-1]),i&&(i.dispatchAction=null,e.dispatchAction(i))}function Ap(t,e,i){t.handler("leave",null,i)}function Cp(t,e,i,n){e.handler(t,i,n)}function Dp(t){var e={showTip:[],hideTip:[]},i=function(n){var a=e[n.type];a?a.push(n):(n.dispatchAction=i,t.dispatchAction(n))};return{dispatchAction:i,pendings:e}}function Lp(t,e){if(!vy.node){var i=e.getZr(),n=(DC(i).records||{})[t];n&&(DC(i).records[t]=null)}}function kp(){}function Pp(t,e,i,n){Op(PC(i).lastProp,n)||(PC(i).lastProp=n,e?Mr(i,n,t):(i.stopAnimation(),i.attr(n)))}function Op(t,e){if(M(t)&&M(e)){var i=!0;return f(e,function(e,n){i=i&&Op(t[n],e)}),!!i}return t===e}function zp(t,e){t[e.get("label.show")?"show":"hide"]()}function Ep(t){return{position:t.position.slice(),rotation:t.rotation||0}}function Rp(t,e,i){var n=e.get("z"),a=e.get("zlevel");t&&t.traverse(function(t){"group"!==t.type&&(null!=n&&(t.z=n),null!=a&&(t.zlevel=a),t.silent=i)})}function Np(t){var e,i=t.get("type"),n=t.getModel(i+"Style");return"line"===i?(e=n.getLineStyle(),e.fill=null):"shadow"===i&&(e=n.getAreaStyle(),e.stroke=null),e}function Bp(t,e,i,n,a){var r=i.get("value"),o=Gp(r,e.axis,e.ecModel,i.get("seriesDataIndices"),{precision:i.get("label.precision"),formatter:i.get("label.formatter")}),s=i.getModel("label"),l=gb(s.get("padding")||0),h=s.getFont(),u=Mi(o,h),c=a.position,d=u.width+l[1]+l[3],f=u.height+l[0]+l[2],p=a.align;"right"===p&&(c[0]-=d),"center"===p&&(c[0]-=d/2);var g=a.verticalAlign;"bottom"===g&&(c[1]-=f),"middle"===g&&(c[1]-=f/2),Vp(c,d,f,n);var v=s.get("backgroundColor");v&&"auto"!==v||(v=e.get("axisLine.lineStyle.color")),t.label={shape:{x:0,y:0,width:d,height:f,r:s.get("borderRadius")},position:c.slice(),style:{text:o,textFont:h,textFill:s.getTextColor(),textPosition:"inside",fill:v,stroke:s.get("borderColor")||"transparent",lineWidth:s.get("borderWidth")||0,shadowBlur:s.get("shadowBlur"),shadowColor:s.get("shadowColor"),shadowOffsetX:s.get("shadowOffsetX"),shadowOffsetY:s.get("shadowOffsetY")},z2:10}}function Vp(t,e,i,n){var a=n.getWidth(),r=n.getHeight();t[0]=Math.min(t[0]+e,a)-e,t[1]=Math.min(t[1]+i,r)-i,t[0]=Math.max(t[0],0),t[1]=Math.max(t[1],0)}function Gp(t,e,i,n,a){var r=e.scale.getLabel(t,{precision:a.precision}),o=a.formatter;if(o){var s={value:Ph(e,t),seriesData:[]};f(n,function(t){var e=i.getSeriesByIndex(t.seriesIndex),n=t.dataIndexInside,a=e&&e.getDataParams(n);a&&s.seriesData.push(a)}),b(o)?r=o.replace("{value}",r):w(o)&&(r=o(s))}return r}function Fp(t,e,i){var n=fe();return ye(n,n,i.rotation),me(n,n,i.position),Tr([t.dataToCoord(e),(i.labelOffset||0)+(i.labelDirection||1)*(i.labelMargin||0)],n)}function Wp(t,e,i,n,a,r){var o=ZI.innerTextLayout(i.rotation,0,i.labelDirection);i.labelMargin=a.get("label.margin"),Bp(e,n,a,r,{position:Fp(n.axis,t,i),align:o.textAlign,verticalAlign:o.textVerticalAlign})}function Hp(t,e,i){return i=i||0,{x1:t[i],y1:t[1-i],x2:e[i],y2:e[1-i]}}function Zp(t,e,i){return i=i||0,{x:t[i],y:t[1-i],width:e[i],height:e[1-i]}}function jp(t,e,i,n,a,r){return{cx:t,cy:e,r0:i,r:n,startAngle:a,endAngle:r,clockwise:!0}}function Xp(t,e){var i={};return i[e.dim+"AxisIndex"]=e.index,t.getCartesian(i)}function Up(t){return"x"===t.dim?0:1}function Yp(t,e,i,n,a){var r=e.axis,o=r.dataToCoord(t),s=n.getAngleAxis().getExtent()[0];s=s/180*Math.PI;var l,h,u,c=n.getRadiusAxis().getExtent();if("radius"===r.dim){var d=fe();ye(d,d,s),me(d,d,[n.cx,n.cy]),l=Tr([o,-a],d);var f=e.getModel("axisLabel").get("rotate")||0,p=ZI.innerTextLayout(s,f*Math.PI/180,-1);h=p.textAlign,u=p.textVerticalAlign}else{var g=c[1];l=n.coordToPoint([g+a,o]);var v=n.cx,m=n.cy;h=Math.abs(l[0]-v)/g<.3?"center":l[0]>v?"left":"right",u=Math.abs(l[1]-m)/g<.3?"middle":l[1]>m?"top":"bottom"}return{position:l,align:h,verticalAlign:u}}function qp(t,e,i,n,a){Cd.call(this,t),this.map=e,this._nameCoordMap=B(),this.loadGeoJson(i,n,a)}function $p(t,e,i,n){var a=i.geoModel,r=i.seriesModel,o=a?a.coordinateSystem:r?r.coordinateSystem||(r.getReferringComponents("geo")[0]||{}).coordinateSystem:null;return o===this?o[t](n):null}function Kp(t,e){var i=t.get("boundingCoords");if(null!=i){var n=i[0],a=i[1];isNaN(n[0])||isNaN(n[1])||isNaN(a[0])||isNaN(a[1])||this.setBoundingRect(n[0],n[1],a[0]-n[0],a[1]-n[1])}var r,o=this.getBoundingRect(),s=t.get("layoutCenter"),l=t.get("layoutSize"),h=e.getWidth(),u=e.getHeight(),c=t.get("aspectScale")||.75,d=o.width/o.height*c,f=!1;s&&l&&(s=[Gr(s[0],h),Gr(s[1],u)],l=Gr(l,Math.min(h,u)),isNaN(s[0])||isNaN(s[1])||isNaN(l)||(f=!0));var p;if(f){var p={};d>1?(p.width=l,p.height=l/d):(p.height=l,p.width=l*d),p.y=s[1]-p.height/2,p.x=s[0]-p.width/2}else r=t.getBoxLayoutParams(),r.aspect=d,p=uo(r,{width:h,height:u});this.setViewRect(p.x,p.y,p.width,p.height),this.setCenter(t.get("center")),this.setZoom(t.get("zoom"))}function Jp(t,e){f(e.get("geoCoord"),function(e,i){t.addGeoCoord(i,e)})}function Qp(t){var e=t.getItemStyle(),i=t.get("areaColor");return null!=i&&(e.fill=i),e}function tg(t,e,i,n,a){i.off("click"),i.off("mousedown"),e.get("selectedMode")&&(i.on("mousedown",function(){t._mouseDownFlag=!0}),i.on("click",function(r){if(t._mouseDownFlag){t._mouseDownFlag=!1;for(var o=r.target;!o.__regions;)o=o.parent;if(o){var s={type:("geo"===e.mainType?"geo":"map")+"ToggleSelect",batch:p(o.__regions,function(t){return{name:t.name,from:a.uid}})};s[e.mainType+"Id"]=e.id,n.dispatchAction(s),eg(e,i)}}}))}function eg(t,e){e.eachChild(function(e){f(e.__regions,function(i){e.trigger(t.isSelected(i.name)?"emphasis":"normal")})})}function ig(t,e){var i=new xx;this._controller=new od(t.getZr()),this._controllerHost={target:e?i:null},this.group=i,this._updateGroup=e,this._mouseDownFlag}function ng(t,e){e.update="updateView",Al(e,function(e,i){var n={};return i.eachComponent({mainType:"geo",query:e},function(i){i[t](e.name);var a=i.coordinateSystem;f(a.regions,function(t){n[t.name]=i.isSelected(t.name)||!1})}),{selected:n,name:e.name}})}function ag(t,e,i){this.dimension="single",this.dimensions=["single"],this._axis=null,this._rect,this._init(t,e,i),this.model=t}function rg(t,e){var i=[];return t.eachComponent("singleAxis",function(n,a){var r=new ag(n,t,e);r.name="single_"+a,r.resize(n,e),n.coordinateSystem=r,i.push(r)}),t.eachSeries(function(e){if("singleAxis"===e.get("coordinateSystem")){var i=t.queryComponents({mainType:"singleAxis",index:e.get("singleAxisIndex"),id:e.get("singleAxisId")})[0];e.coordinateSystem=i&&i.coordinateSystem}}),i}function og(t,e){e=e||{};var i=t.coordinateSystem,n=t.axis,a={},r=n.position,o=n.orient,s=i.getRect(),l=[s.x,s.x+s.width,s.y,s.y+s.height],h={horizontal:{top:l[2],bottom:l[3]},vertical:{left:l[0],right:l[1]}};a.position=["vertical"===o?h.vertical[r]:l[0],"horizontal"===o?h.horizontal[r]:l[3]];
-var u={horizontal:0,vertical:1};a.rotation=Math.PI/2*u[o];var c={top:-1,bottom:1,right:1,left:-1};a.labelDirection=a.tickDirection=a.nameDirection=c[r],t.get("axisTick.inside")&&(a.tickDirection=-a.tickDirection),C(e.labelInside,t.get("axisLabel.inside"))&&(a.labelDirection=-a.labelDirection);var d=e.rotate;return null==d&&(d=t.get("axisLabel.rotate")),a.labelRotation="top"===r?-d:d,a.labelInterval=n.getLabelInterval(),a.z2=1,a}function sg(t,e){return e.type||(e.data?"category":"value")}function lg(t){return t.isHorizontal()?0:1}function hg(t,e){var i=t.getRect();return[i[sD[e]],i[sD[e]]+i[lD[e]]]}function ug(t){this._model=t}function cg(t,e,i,n){var a=i.calendarModel,r=i.seriesModel,o=a?a.coordinateSystem:r?r.coordinateSystem:null;return o===this?o[t](n):null}function dg(t,e){var i=t.cellSize;_(i)?1===i.length&&(i[1]=i[0]):i=t.cellSize=[i,i];var n=p([0,1],function(t){return fo(e,t)&&(i[t]="auto"),null!=i[t]&&"auto"!==i[t]});po(t,e,{type:"box",ignoreSize:n})}function fg(t,e,i){var n,a={},r="toggleSelected"===t;return i.eachComponent("legend",function(i){r&&null!=n?i[n?"select":"unSelect"](e.name):(i[t](e.name),n=i.isSelected(e.name));var o=i.getData();f(o,function(t){var e=t.get("name");if("\n"!==e&&""!==e){var n=i.isSelected(e);a[e]=a.hasOwnProperty(e)?a[e]&&n:n}})}),{name:e.name,selected:a}}function pg(t,e,i){var n=e.getBoxLayoutParams(),a=e.get("padding"),r={width:i.getWidth(),height:i.getHeight()},o=uo(n,r,a);Ib(e.get("orient"),t,e.get("itemGap"),o.width,o.height),co(t,n,r,a)}function gg(t,e){var i=gb(e.get("padding")),n=e.getItemStyle(["color","opacity"]);n.fill=e.get("backgroundColor");var t=new Ww({shape:{x:t.x-i[3],y:t.y-i[0],width:t.width+i[1]+i[3],height:t.height+i[0]+i[2],r:e.get("borderRadius")},style:n,silent:!0,z2:-1});return t}function vg(t,e){e.dispatchAction({type:"legendToggleSelect",name:t})}function mg(t,e,i){var n=i.getZr().storage.getDisplayList()[0];n&&n.useHoverLayer||t.get("legendHoverLink")&&i.dispatchAction({type:"highlight",seriesName:t.name,name:e})}function yg(t,e,i){var n=i.getZr().storage.getDisplayList()[0];n&&n.useHoverLayer||t.get("legendHoverLink")&&i.dispatchAction({type:"downplay",seriesName:t.name,name:e})}function xg(t,e,i){var n=t.getOrient(),a=[1,1];a[n.index]=0,po(e,i,{type:"box",ignoreSize:a})}function _g(t){var e="cubic-bezier(0.23, 1, 0.32, 1)",i="left "+t+"s "+e+",top "+t+"s "+e;return p(CD,function(t){return t+"transition:"+i}).join(";")}function wg(t){var e=[],i=t.get("fontSize"),n=t.getTextColor();return n&&e.push("color:"+n),e.push("font:"+t.getFont()),i&&e.push("line-height:"+Math.round(3*i/2)+"px"),TD(["decoration","align"],function(i){var n=t.get(i);n&&e.push("text-"+i+":"+n)}),e.join(";")}function bg(t){var e=[],i=t.get("transitionDuration"),n=t.get("backgroundColor"),a=t.getModel("textStyle"),r=t.get("padding");return i&&e.push(_g(i)),n&&(vy.canvasSupported?e.push("background-Color:"+n):(e.push("background-Color:#"+Be(n)),e.push("filter:alpha(opacity=70)"))),TD(["width","color","radius"],function(i){var n="border-"+i,a=AD(n),r=t.get(a);null!=r&&e.push(n+":"+r+("color"===i?"":"px"))}),e.push(wg(a)),null!=r&&e.push("padding:"+gb(r).join("px ")+"px"),e.join(";")+";"}function Mg(t,e){if(vy.wxa)return null;var i=document.createElement("div"),n=this._zr=e.getZr();this.el=i,this._x=e.getWidth()/2,this._y=e.getHeight()/2,t.appendChild(i),this._container=t,this._show=!1,this._hideTimeout;var a=this;i.onmouseenter=function(){a._enterable&&(clearTimeout(a._hideTimeout),a._show=!0),a._inContent=!0},i.onmousemove=function(e){if(e=e||window.event,!a._enterable){var i=n.handler;vn(t,e,!0),i.dispatch("mousemove",e)}},i.onmouseleave=function(){a._enterable&&a._show&&a.hideLater(a._hideDelay),a._inContent=!1}}function Sg(t){for(var e=t.pop();t.length;){var i=t.pop();i&&(Pr.isInstance(i)&&(i=i.get("tooltip",!0)),"string"==typeof i&&(i={formatter:i}),e=new Pr(i,e,e.ecModel))}return e}function Ig(t,e){return t.dispatchAction||y(e.dispatchAction,e)}function Tg(t,e,i,n,a,r,o){var s=Cg(i),l=s.width,h=s.height;return null!=r&&(t+l+r>n?t-=l+r:t+=r),null!=o&&(e+h+o>a?e-=h+o:e+=o),[t,e]}function Ag(t,e,i,n,a){var r=Cg(i),o=r.width,s=r.height;return t=Math.min(t+o,n)-o,e=Math.min(e+s,a)-s,t=Math.max(t,0),e=Math.max(e,0),[t,e]}function Cg(t){var e=t.clientWidth,i=t.clientHeight;if(document.defaultView&&document.defaultView.getComputedStyle){var n=document.defaultView.getComputedStyle(t);n&&(e+=parseInt(n.paddingLeft,10)+parseInt(n.paddingRight,10)+parseInt(n.borderLeftWidth,10)+parseInt(n.borderRightWidth,10),i+=parseInt(n.paddingTop,10)+parseInt(n.paddingBottom,10)+parseInt(n.borderTopWidth,10)+parseInt(n.borderBottomWidth,10))}return{width:e,height:i}}function Dg(t,e,i){var n=i[0],a=i[1],r=5,o=0,s=0,l=e.width,h=e.height;switch(t){case"inside":o=e.x+l/2-n/2,s=e.y+h/2-a/2;break;case"top":o=e.x+l/2-n/2,s=e.y-a-r;break;case"bottom":o=e.x+l/2-n/2,s=e.y+h+r;break;case"left":o=e.x-n-r,s=e.y+h/2-a/2;break;case"right":o=e.x+l+r,s=e.y+h/2-a/2}return[o,s]}function Lg(t){return"center"===t||"middle"===t}function kg(t){zn(t,"label",["show"])}function Pg(t){return!(isNaN(parseFloat(t.x))&&isNaN(parseFloat(t.y)))}function Og(t){return!isNaN(parseFloat(t.x))&&!isNaN(parseFloat(t.y))}function zg(t,e,i){var n=-1;do n=Math.max(Hr(t.get(e,i)),n),t=t.stackedOn;while(t);return n}function Eg(t,e,i,n,a,r){var o=[],s=Fg(e,n,t),l=e.indicesOfNearest(n,s,!0)[0];o[a]=e.get(i,l,!0),o[r]=e.get(n,l,!0);var h=zg(e,n,l);return h=Math.min(h,20),h>=0&&(o[r]=+o[r].toFixed(h)),o}function Rg(t,e){var i=t.getData(),a=t.coordinateSystem;if(e&&!Og(e)&&!_(e.coord)&&a){var r=a.dimensions,o=Ng(e,i,a,t);if(e=n(e),e.type&&VD[e.type]&&o.baseAxis&&o.valueAxis){var s=ND(r,o.baseAxis.dim),l=ND(r,o.valueAxis.dim);e.coord=VD[e.type](i,o.baseDataDim,o.valueDataDim,s,l),e.value=e.coord[l]}else{for(var h=[null!=e.xAxis?e.xAxis:e.radiusAxis,null!=e.yAxis?e.yAxis:e.angleAxis],u=0;2>u;u++)VD[h[u]]&&(h[u]=Fg(i,i.mapDimension(r[u]),h[u]));e.coord=h}}return e}function Ng(t,e,i,n){var a={};return null!=t.valueIndex||null!=t.valueDim?(a.valueDataDim=null!=t.valueIndex?e.getDimension(t.valueIndex):t.valueDim,a.valueAxis=i.getAxis(Bg(n,a.valueDataDim)),a.baseAxis=i.getOtherAxis(a.valueAxis),a.baseDataDim=e.mapDimension(a.baseAxis.dim)):(a.baseAxis=n.getBaseAxis(),a.valueAxis=i.getOtherAxis(a.baseAxis),a.baseDataDim=e.mapDimension(a.baseAxis.dim),a.valueDataDim=e.mapDimension(a.valueAxis.dim)),a}function Bg(t,e){var i=t.getData(),n=i.dimensions;e=i.getDimension(e);for(var a=0;a<n.length;a++){var r=i.getDimensionInfo(n[a]);if(r.name===e)return r.coordDim}}function Vg(t,e){return t&&t.containData&&e.coord&&!Pg(e)?t.containData(e.coord):!0}function Gg(t,e,i,n){return 2>n?t.coord&&t.coord[n]:t.value}function Fg(t,e,i){if("average"===i){var n=0,a=0;return t.each(e,function(t){isNaN(t)||(n+=t,a++)},!0),n/a}return t.getDataExtent(e,!0)["max"===i?1:0]}function Wg(t,e,i){var n=e.coordinateSystem;t.each(function(a){var r,o=t.getItemModel(a),s=Gr(o.get("x"),i.getWidth()),l=Gr(o.get("y"),i.getHeight());if(isNaN(s)||isNaN(l)){if(e.getMarkerPosition)r=e.getMarkerPosition(t.getValues(t.dimensions,a));else if(n){var h=t.get(n.dimensions[0],a),u=t.get(n.dimensions[1],a);r=n.dataToPoint([h,u])}}else r=[s,l];isNaN(s)||(r[0]=s),isNaN(l)||(r[1]=l),t.setItemLayout(a,r)})}function Hg(t,e,i){var n;n=t?p(t&&t.dimensions,function(t){var i=e.getData().getDimensionInfo(e.getData().mapDimension(t))||{};return s({name:t,isSysCoord:!0},i)}):[{name:"value",type:"float",isSysCoord:!0}];var a=new kS(n,i),r=p(i.get("data"),x(Rg,e));return t&&(r=v(r,x(Vg,t))),a.initData(r,null,t?Gg:function(t){return t.value}),a}function Zg(t){return!isNaN(t)&&!isFinite(t)}function jg(t,e,i,n){var a=1-t,r=n.dimensions[t];return Zg(e[a])&&Zg(i[a])&&e[t]===i[t]&&n.getAxis(r).containData(e[t])}function Xg(t,e){if("cartesian2d"===t.type){var i=e[0].coord,n=e[1].coord;if(i&&n&&(jg(1,i,n,t)||jg(0,i,n,t)))return!0}return Vg(t,e[0])&&Vg(t,e[1])}function Ug(t,e,i,n,a){var r,o=n.coordinateSystem,s=t.getItemModel(e),l=Gr(s.get("x"),a.getWidth()),h=Gr(s.get("y"),a.getHeight());if(isNaN(l)||isNaN(h)){if(n.getMarkerPosition)r=n.getMarkerPosition(t.getValues(t.dimensions,e));else{var u=o.dimensions,c=t.get(u[0],e),d=t.get(u[1],e);r=o.dataToPoint([c,d])}if("cartesian2d"===o.type){var f=o.getAxis("x"),p=o.getAxis("y"),u=o.dimensions;Zg(t.get(u[0],e))?r[0]=f.toGlobalCoord(f.getExtent()[i?0:1]):Zg(t.get(u[1],e))&&(r[1]=p.toGlobalCoord(p.getExtent()[i?0:1]))}isNaN(l)||(r[0]=l),isNaN(h)||(r[1]=h)}else r=[l,h];t.setItemLayout(e,r)}function Yg(t,e,i){var n;n=t?p(t&&t.dimensions,function(t){var i=e.getData().getDimensionInfo(e.getData().mapDimension(t))||{};return s({name:t},i)}):[{name:"value",type:"float"}];var a=new kS(n,i),r=new kS(n,i),o=new kS([],i),l=p(i.get("data"),x(FD,e,t,i));t&&(l=v(l,x(Xg,t)));var h=t?Gg:function(t){return t.value};return a.initData(p(l,function(t){return t[0]}),null,h),r.initData(p(l,function(t){return t[1]}),null,h),o.initData(p(l,function(t){return t[2]})),o.hasItemOption=!0,{from:a,to:r,line:o}}function qg(t){return!isNaN(t)&&!isFinite(t)}function $g(t,e,i){var n=1-t;return qg(e[n])&&qg(i[n])}function Kg(t,e){var i=e.coord[0],n=e.coord[1];return"cartesian2d"===t.type&&i&&n&&($g(1,i,n,t)||$g(0,i,n,t))?!0:Vg(t,{coord:i,x:e.x0,y:e.y0})||Vg(t,{coord:n,x:e.x1,y:e.y1})}function Jg(t,e,i,n,a){var r,o=n.coordinateSystem,s=t.getItemModel(e),l=Gr(s.get(i[0]),a.getWidth()),h=Gr(s.get(i[1]),a.getHeight());if(isNaN(l)||isNaN(h)){if(n.getMarkerPosition)r=n.getMarkerPosition(t.getValues(i,e));else{var u=t.get(i[0],e),c=t.get(i[1],e),d=[u,c];o.clampData&&o.clampData(d,d),r=o.dataToPoint(d,!0)}if("cartesian2d"===o.type){var f=o.getAxis("x"),p=o.getAxis("y"),u=t.get(i[0],e),c=t.get(i[1],e);qg(u)?r[0]=f.toGlobalCoord(f.getExtent()["x0"===i[0]?0:1]):qg(c)&&(r[1]=p.toGlobalCoord(p.getExtent()["y0"===i[1]?0:1]))}isNaN(l)||(r[0]=l),isNaN(h)||(r[1]=h)}else r=[l,h];return r}function Qg(t,e,i){var n,a,r=["x0","y0","x1","y1"];t?(n=p(t&&t.dimensions,function(t){var i=e.getData(),n=i.getDimensionInfo(i.mapDimension(t))||{};return s({name:t},n)}),a=new kS(p(r,function(t,e){return{name:t,type:n[e%2].type}}),i)):(n=[{name:"value",type:"float"}],a=new kS(n,i));var o=p(i.get("data"),x(WD,e,t,i));t&&(o=v(o,x(Kg,t)));var l=t?function(t,e,i,n){return t.coord[Math.floor(n/2)][n%2]}:function(t){return t.value};return a.initData(o,null,l),a.hasItemOption=!0,a}function tv(t){var e=t.type,i={number:"value",time:"time"};if(i[e]&&(t.axisType=i[e],delete t.type),ev(t),iv(t,"controlPosition")){var n=t.controlStyle||(t.controlStyle={});iv(n,"position")||(n.position=t.controlPosition),"none"!==n.position||iv(n,"show")||(n.show=!1,delete n.position),delete t.controlPosition}f(t.data||[],function(t){M(t)&&!_(t)&&(!iv(t,"value")&&iv(t,"name")&&(t.value=t.name),ev(t))})}function ev(t){var e=t.itemStyle||(t.itemStyle={}),i=e.emphasis||(e.emphasis={}),n=t.label||t.label||{},a=n.normal||(n.normal={}),r={normal:1,emphasis:1};f(n,function(t,e){r[e]||iv(a,e)||(a[e]=t)}),i.label&&!iv(n,"emphasis")&&(n.emphasis=i.label,delete i.label)}function iv(t,e){return t.hasOwnProperty(e)}function nv(t,e){return uo(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()},t.get("padding"))}function av(t,e,i,a){var r=Xa(t.get(e).replace(/^path:\/\//,""),n(a||{}),new ni(i[0],i[1],i[2],i[3]),"center");return r}function rv(t,e,i,n,r,o){var s=e.get("color");if(r)r.setColor(s),i.add(r),o&&o.onUpdate(r);else{var l=t.get("symbol");r=zh(l,-1,-1,2,2,s),r.setStyle("strokeNoScale",!0),i.add(r),o&&o.onCreate(r)}var h=e.getItemStyle(["color","symbol","symbolSize"]);r.setStyle(h),n=a({rectHover:!0,z2:100},n,!0);var u=t.get("symbolSize");u=u instanceof Array?u.slice():[+u,+u],u[0]/=2,u[1]/=2,n.scale=u;var c=t.get("symbolOffset");if(c){var d=n.position=n.position||[0,0];d[0]+=Gr(c[0],u[0]),d[1]+=Gr(c[1],u[1])}var f=t.get("symbolRotate");return n.rotation=(f||0)*Math.PI/180||0,r.attr(n),r.updateTransform(),r}function ov(t,e,i,n,a){if(!t.dragging){var r=n.getModel("checkpointStyle"),o=i.dataToCoord(n.getData().get(["value"],e));a||!r.get("animation",!0)?t.attr({position:[o,0]}):(t.stopAnimation(!0),t.animateTo({position:[o,0]},r.get("animationDuration",!0),r.get("animationEasing",!0)))}}function sv(t){return h(QD,t)>=0}function lv(t,e){t=t.slice();var i=p(t,lo);e=(e||[]).slice();var n=p(e,lo);return function(a,r){f(t,function(t,o){for(var s={name:t,capital:i[o]},l=0;l<e.length;l++)s[e[l]]=t+n[l];a.call(r,s)})}}function hv(t,e,i){function n(t,e){return h(e.nodes,t)>=0}function a(t,n){var a=!1;return e(function(e){f(i(t,e)||[],function(t){n.records[e.name][t]&&(a=!0)})}),a}function r(t,n){n.nodes.push(t),e(function(e){f(i(t,e)||[],function(t){n.records[e.name][t]=!0})})}return function(i){function o(t){!n(t,s)&&a(t,s)&&(r(t,s),l=!0)}var s={nodes:[],records:{}};if(e(function(t){s.records[t.name]={}}),!i)return s;r(i,s);var l;do l=!1,t(o);while(l);return s}}function uv(t,e,i){var n=[1/0,-1/0];return eL(i,function(t){var i=t.getData();i&&eL(i.mapDimension(e,!0),function(t){var e=i.getApproximateExtent(t);e[0]<n[0]&&(n[0]=e[0]),e[1]>n[1]&&(n[1]=e[1])})}),n[1]<n[0]&&(n=[0/0,0/0]),cv(t,n),n}function cv(t,e){var i=t.getAxisModel(),n=i.getMin(!0),a="category"===i.get("type"),r=a&&i.getCategories().length;null!=n&&"dataMin"!==n&&"function"!=typeof n?e[0]=n:a&&(e[0]=r>0?0:0/0);var o=i.getMax(!0);return null!=o&&"dataMax"!==o&&"function"!=typeof o?e[1]=o:a&&(e[1]=r>0?r-1:0/0),i.get("scale",!0)||(e[0]>0&&(e[0]=0),e[1]<0&&(e[1]=0)),e}function dv(t,e){var i=t.getAxisModel(),n=t._percentWindow,a=t._valueWindow;if(n){var r=jr(a,[0,500]);r=Math.min(r,20);var o=e||0===n[0]&&100===n[1];i.setRange(o?null:+a[0].toFixed(r),o?null:+a[1].toFixed(r))}}function fv(t){var e=t._minMaxSpan={},i=t._dataZoomModel;eL(["min","max"],function(n){e[n+"Span"]=i.get(n+"Span");var a=i.get(n+"ValueSpan");if(null!=a&&(e[n+"ValueSpan"]=a,a=t.getAxisModel().axis.scale.parse(a),null!=a)){var r=t._dataExtent;e[n+"Span"]=Vr(r[0]+a,r,[0,100],!0)}})}function pv(t){var e={};return aL(["start","end","startValue","endValue","throttle"],function(i){t.hasOwnProperty(i)&&(e[i]=t[i])}),e}function gv(t,e){var i=t._rangePropMode,n=t.get("rangeMode");aL([["start","startValue"],["end","endValue"]],function(t,a){var r=null!=e[t[0]],o=null!=e[t[1]];r&&!o?i[a]="percent":!r&&o?i[a]="value":n?i[a]=n[a]:r&&(i[a]="percent")})}function vv(t){var e={x:"y",y:"x",radius:"angle",angle:"radius"};return e[t]}function mv(t){return"vertical"===t?"ns-resize":"ew-resize"}function yv(t,e){var i=bv(t),n=e.dataZoomId,a=e.coordId;f(i,function(t){var i=t.dataZoomInfos;i[n]&&h(e.allCoordIds,a)<0&&(delete i[n],t.count--)}),Sv(i);var r=i[a];r||(r=i[a]={coordId:a,dataZoomInfos:{},count:0},r.controller=Mv(t,r),r.dispatchAction=x(Cv,t)),!r.dataZoomInfos[n]&&r.count++,r.dataZoomInfos[n]=e;var o=Dv(r.dataZoomInfos);r.controller.enable(o.controlType,o.opt),r.controller.setPointerChecker(e.containsPoint),ks(r,"dispatchAction",e.throttleRate,"fixRate")}function xv(t,e){var i=bv(t);f(i,function(t){t.controller.dispose();var i=t.dataZoomInfos;i[e]&&(delete i[e],t.count--)}),Sv(i)}function _v(t,e){if(t&&"dataZoom"===t.type&&t.batch)for(var i=0,n=t.batch.length;n>i;i++)if(t.batch[i].dataZoomId===e)return!1;return!0}function wv(t){return t.type+"\x00_"+t.id}function bv(t){var e=t.getZr();return e[bL]||(e[bL]={})}function Mv(t,e){var i=new od(t.getZr());return i.on("pan",wL(Iv,e)),i.on("zoom",wL(Tv,e)),i}function Sv(t){f(t,function(e,i){e.count||(e.controller.dispose(),delete t[i])})}function Iv(t,e,i,n,a,r,o){Av(t,function(s){return s.panGetRange(t.controller,e,i,n,a,r,o)})}function Tv(t,e,i,n){Av(t,function(a){return a.zoomGetRange(t.controller,e,i,n)})}function Av(t,e){var i=[];f(t.dataZoomInfos,function(t){var n=e(t);!t.disabled&&n&&i.push({dataZoomId:t.dataZoomId,start:n[0],end:n[1]})}),t.dispatchAction(i)}function Cv(t,e){t.dispatchAction({type:"dataZoom",batch:e})}function Dv(t){var e,i={},n="type_",a={type_true:2,type_move:1,type_false:0,type_undefined:-1};return f(t,function(t){var r=t.disabled?!1:t.zoomLock?"move":!0;a[n+r]>a[n+e]&&(e=r),o(i,t.roamControllerOpt)}),{controlType:e,opt:i}}function Lv(t){var e={};f(t,function(t){e[t]=1}),t.length=0,f(e,function(e,i){t.push(i)})}function kv(t){var e=t.pieceList;t.hasSpecialVisual=!1,f(e,function(e,i){e.originIndex=i,null!=e.visual&&(t.hasSpecialVisual=!0)})}function Pv(t){var e=t.categories,i=t.visual,n=t.categoryMap={};if(CL(e,function(t,e){n[t]=e}),!_(i)){var a=[];M(i)?CL(i,function(t,e){var i=n[e];a[null!=i?i:LL]=t}):a[LL]=i,i=Fv(t,a)}for(var r=e.length-1;r>=0;r--)null==i[r]&&(delete n[e[r]],e.pop())}function Ov(t,e){var i=t.visual,n=[];M(i)?CL(i,function(t){n.push(t)}):null!=i&&n.push(i);var a={color:1,symbol:1};e||1!==n.length||a.hasOwnProperty(t.type)||(n[1]=n[0]),Fv(t,n)}function zv(t){return{applyVisual:function(e,i,n){e=this.mapValueToVisual(e),n("color",t(i("color"),e))},_doMap:Vv([0,1])}}function Ev(t){var e=this.option.visual;return e[Math.round(Vr(t,[0,1],[0,e.length-1],!0))]||{}}function Rv(t){return function(e,i,n){n(t,this.mapValueToVisual(e))}}function Nv(t){var e=this.option.visual;return e[this.option.loop&&t!==LL?t%e.length:t]}function Bv(){return this.option.visual[0]}function Vv(t){return{linear:function(e){return Vr(e,t,this.option.visual,!0)},category:Nv,piecewise:function(e,i){var n=Gv.call(this,i);return null==n&&(n=Vr(e,t,this.option.visual,!0)),n},fixed:Bv}}function Gv(t){var e=this.option,i=e.pieceList;if(e.hasSpecialVisual){var n=kL.findPieceIndex(t,i),a=i[n];if(a&&a.visual)return a.visual[this.type]}}function Fv(t,e){return t.visual=e,"color"===t.type&&(t.parsedVisual=p(e,function(t){return ze(t)})),e}function Wv(t,e,i){return t?i>=e:i>e}function Hv(t){if(t)for(var e in t)if(t.hasOwnProperty(e))return!0}function Zv(t,e,i){function a(){var t=function(){};t.prototype.__hidden=t.prototype;var e=new t;return e}var r={};return zL(e,function(e){var o=r[e]=a();zL(t[e],function(t,a){if(kL.isValidType(a)){var r={type:a,visual:t};i&&i(r,e),o[a]=new kL(r),"opacity"===a&&(r=n(r),r.type="colorAlpha",o.__hidden.__alphaForOpacity=new kL(r))}})}),r}function jv(t,e,i){var a;f(i,function(t){e.hasOwnProperty(t)&&Hv(e[t])&&(a=!0)}),a&&f(i,function(i){e.hasOwnProperty(i)&&Hv(e[i])?t[i]=n(e[i]):delete t[i]})}function Xv(t,e,i,n,a,r){function o(t){return i.getItemVisual(u,t)}function s(t,e){i.setItemVisual(u,t,e)}function l(t,l){u=null==r?t:l;var c=i.getRawDataItem(u);if(!c||c.visualMap!==!1)for(var d=n.call(a,t),f=e[d],p=h[d],g=0,v=p.length;v>g;g++){var m=p[g];f[m]&&f[m].applyVisual(t,o,s)}}var h={};f(t,function(t){var i=kL.prepareVisualTypes(e[t]);h[t]=i});var u;null==r?i.each(l,!0):i.each([r],l,!0)}function Uv(t,e,i,n){function a(t,a){function o(t){return a.getItemVisual(l,t)}function s(t,e){a.setItemVisual(l,t,e)}null!=n&&(n=a.getDimension(n));for(var l=t.start;l<t.end;l++){var h=a.getRawDataItem(l);if(h&&h.visualMap===!1)return;for(var u=null!=n?a.get(n,l,!0):l,c=i(u),d=e[c],f=r[c],p=0,g=f.length;g>p;p++){var v=f[p];d[v]&&d[v].applyVisual(u,o,s)}}}var r={};return f(t,function(t){var i=kL.prepareVisualTypes(e[t]);r[t]=i}),{progress:a}}function Yv(t){var e=["x","y"],i=["width","height"];return{point:function(e,i,n){if(e){var a=n.range,r=e[t];return qv(r,a)}},rect:function(n,a,r){if(n){var o=r.range,s=[n[e[t]],n[e[t]]+n[i[t]]];return s[1]<s[0]&&s.reverse(),qv(s[0],o)||qv(s[1],o)||qv(o[0],s)||qv(o[1],s)}}}}function qv(t,e){return e[0]<=t&&t<=e[1]}function $v(t,e,i,n,a){for(var r=0,o=a[a.length-1];r<a.length;r++){var s=a[r];if(Kv(t,e,i,n,s[0],s[1],o[0],o[1]))return!0;o=s}}function Kv(t,e,i,n,a,r,o,s){var l=Qv(i-t,a-o,n-e,r-s);if(Jv(l))return!1;var h=Qv(a-t,a-o,r-e,r-s)/l;if(0>h||h>1)return!1;var u=Qv(i-t,a-t,n-e,r-e)/l;return 0>u||u>1?!1:!0}function Jv(t){return 1e-6>=t&&t>=-1e-6}function Qv(t,e,i,n){return t*n-e*i}function tm(t,e,i){var n=this._targetInfoList=[],a={},r=im(e,t);RL(WL,function(t,e){(!i||!i.include||NL(i.include,e)>=0)&&t(r,n,a)})}function em(t){return t[0]>t[1]&&t.reverse(),t}function im(t,e){return Hn(t,e,{includeMainTypes:GL})}function nm(t,e,i,n){var a=i.getAxis(["x","y"][t]),r=em(p([0,1],function(t){return e?a.coordToData(a.toLocalCoord(n[t])):a.toGlobalCoord(a.dataToCoord(n[t]))})),o=[];return o[t]=r,o[1-t]=[0/0,0/0],{values:r,xyMinMax:o}}function am(t,e,i,n){return[e[0]-n[t]*i[0],e[1]-n[t]*i[1]]}function rm(t,e){var i=om(t),n=om(e),a=[i[0]/n[0],i[1]/n[1]];return isNaN(a[0])&&(a[0]=1),isNaN(a[1])&&(a[1]=1),a}function om(t){return t?[t[0][1]-t[0][0],t[1][1]-t[1][0]]:[0/0,0/0]}function sm(t,e,i,n,a){if(a){var r=t.getZr();if(!r[qL]){r[YL]||(r[YL]=lm);var o=ks(r,YL,i,e);o(t,n)}}}function lm(t,e){if(!t.isDisposed()){var i=t.getZr();i[qL]=!0,t.dispatchAction({type:"brushSelect",batch:e}),i[qL]=!1}}function hm(t,e,i,n){for(var a=0,r=e.length;r>a;a++){var o=e[a];if(t[o.brushType](n,i,o.selectors,o))return!0}}function um(t){var e=t.brushSelector;if(b(e)){var i=[];return f(EL,function(t,n){i[n]=function(i,n,a,r){var o=n.getItemLayout(i);return t[e](o,a,r)}}),i}if(w(e)){var n={};return f(EL,function(t,i){n[i]=e}),n}return e}function cm(t,e){var i=t.option.seriesIndex;return null!=i&&"all"!==i&&(_(i)?h(i,e)<0:e!==i)}function dm(t){var e=t.selectors={};return f(EL[t.brushType],function(i,n){e[n]=function(n){return i(n,e,t)}}),t}function fm(t){return new ni(t[0][0],t[1][0],t[0][1]-t[0][0],t[1][1]-t[1][0])}function pm(t,e){return a({brushType:t.brushType,brushMode:t.brushMode,transformable:t.transformable,brushStyle:new Pr(t.brushStyle).getItemStyle(),removeOnClick:t.removeOnClick,z:t.z},e,!0)}function gm(t,e,i,n){(!n||n.$from!==t.id)&&this._brushController.setPanels(t.brushTargetManager.makePanelOpts(i)).enableBrush(t.brushOption).updateCovers(t.areas.slice())}function vm(t,e){QL[t]=e}function mm(t){return QL[t]}function ym(t,e,i){this.model=t,this.ecModel=e,this.api=i,this._brushType,this._brushMode}function xm(t,e){return t&&t.hasOwnProperty&&t.hasOwnProperty(e)}function _m(t,e,i,n){function a(t){return l[t]}function r(t,e){l[t]=e}for(var o=e.targetVisuals[n],s=kL.prepareVisualTypes(o),l={color:t.getData().getVisual("color")},h=0,u=s.length;u>h;h++){var c=s[h],d=o["opacity"===c?"__alphaForOpacity":c];d&&d.applyVisual(i,a,r)}return l.color}function wm(t,e,i){if(i[0]===i[1])return i.slice();for(var n=200,a=(i[1]-i[0])/n,r=i[0],o=[],s=0;n>=s&&r<i[1];s++)o.push(r),r+=a;return o.push(i[1]),o}function bm(t,e,i){var n=t.option,a=n.align;if(null!=a&&"auto"!==a)return a;for(var r={width:e.getWidth(),height:e.getHeight()},o="horizontal"===n.orient?1:0,s=[["left","right","width"],["top","bottom","height"]],l=s[o],h=[0,null,10],u={},c=0;3>c;c++)u[s[1-o][c]]=h[c],u[l[c]]=2===c?i[0]:n[l[c]];var d=[["x","width",3],["y","height",0]][o],f=uo(u,r,n.padding);return l[(f.margin[d[2]]||0)+f[d[0]]+.5*f[d[1]]<.5*r[d[1]]?0:1]}function Mm(t){return f(t||[],function(){null!=t.dataIndex&&(t.dataIndexInside=t.dataIndex,t.dataIndex=null)}),t}function Sm(t,e,i,n){return new Gw({shape:{points:t},draggable:!!i,cursor:e,drift:i,onmousemove:function(t){t_(t.event)},ondragend:n})}function Im(t,e){return 0===t?[[0,0],[e,0],[e,-e]]:[[0,0],[e,0],[e,e]]}function Tm(t,e,i,n){return t?[[0,-_k(e,wk(i,0))],[Mk,0],[0,_k(e,wk(n-i,0))]]:[[0,0],[5,-5],[5,5]]}function Am(t,e,i){var n=bk/2,a=t.get("hoverLinkDataSize");return a&&(n=yk(a,e,i,!0)/2),n}function Cm(t){var e=t.get("hoverLinkOnHandle");return!!(null==e?t.get("realtime"):e)}function Dm(t){return"vertical"===t?"ns-resize":"ew-resize"}function Lm(t,e){var i=t.inverse;("vertical"===t.orient?!i:i)&&e.reverse()}function km(t){return 0===t.indexOf("my")}function Pm(t){this.model=t}function Om(t){this.model=t}function zm(t){var e={},i=[],n=[];return t.eachRawSeries(function(t){var a=t.coordinateSystem;if(!a||"cartesian2d"!==a.type&&"polar"!==a.type)i.push(t);else{var r=a.getBaseAxis();if("category"===r.type){var o=r.dim+"_"+r.index;e[o]||(e[o]={categoryAxis:r,valueAxis:a.getOtherAxis(r),series:[]},n.push({axisDim:r.dim,axisIndex:r.index})),e[o].series.push(t)}else i.push(t)}}),{seriesGroupByCategoryAxis:e,other:i,meta:n}}function Em(t){var e=[];return f(t,function(t){var i=t.categoryAxis,n=t.valueAxis,a=n.dim,r=[" "].concat(p(t.series,function(t){return t.name})),o=[i.model.getCategories()];f(t.series,function(t){o.push(t.getRawData().mapArray(a,function(t){return t}))});for(var s=[r.join(Nk)],l=0;l<o[0].length;l++){for(var h=[],u=0;u<o.length;u++)h.push(o[u][l]);s.push(h.join(Nk))}e.push(s.join("\n"))}),e.join("\n\n"+Rk+"\n\n")}function Rm(t){return p(t,function(t){var e=t.getRawData(),i=[t.name],n=[];return e.each(e.dimensions,function(){for(var t=arguments.length,a=arguments[t-1],r=e.getName(a),o=0;t-1>o;o++)n[o]=arguments[o];i.push((r?r+Nk:"")+n.join(Nk))}),i.join("\n")}).join("\n\n"+Rk+"\n\n")}function Nm(t){var e=zm(t);return{value:v([Em(e.seriesGroupByCategoryAxis),Rm(e.other)],function(t){return t.replace(/[\n\t\s]/g,"")}).join("\n\n"+Rk+"\n\n"),meta:e.meta}}function Bm(t){return t.replace(/^\s\s*/,"").replace(/\s\s*$/,"")}function Vm(t){var e=t.slice(0,t.indexOf("\n"));return e.indexOf(Nk)>=0?!0:void 0}function Gm(t){for(var e=t.split(/\n+/g),i=Bm(e.shift()).split(Bk),n=[],a=p(i,function(t){return{name:t,data:[]}}),r=0;r<e.length;r++){var o=Bm(e[r]).split(Bk);n.push(o.shift());for(var s=0;s<o.length;s++)a[s]&&(a[s].data[r]=o[s])}return{series:a,categories:n}}function Fm(t){for(var e=t.split(/\n+/g),i=Bm(e.shift()),n=[],a=0;a<e.length;a++){var r,o=Bm(e[a]).split(Bk),s="",l=!1;isNaN(o[0])?(l=!0,s=o[0],o=o.slice(1),n[a]={name:s,value:[]},r=n[a].value):r=n[a]=[];for(var h=0;h<o.length;h++)r.push(+o[h]);1===r.length&&(l?n[a].value=r[0]:n[a]=r[0])}return{name:i,data:n}}function Wm(t,e){var i=t.split(new RegExp("\n*"+Rk+"\n*","g")),n={series:[]};return f(i,function(t,i){if(Vm(t)){var a=Gm(t),r=e[i],o=r.axisDim+"Axis";r&&(n[o]=n[o]||[],n[o][r.axisIndex]={data:a.categories},n.series=n.series.concat(a.series))}else{var a=Fm(t);n.series.push(a)}}),n}function Hm(t){this._dom=null,this.model=t}function Zm(t,e){return p(t,function(t,i){var n=e&&e[i];return M(n)&&!_(n)?(M(t)&&!_(t)&&(t=t.value),s({value:t},n)):t})}function jm(t,e){var i=qm(t);Vk(e,function(e,n){for(var a=i.length-1;a>=0;a--){var r=i[a];if(r[n])break}if(0>a){var o=t.queryComponents({mainType:"dataZoom",subType:"select",id:n})[0];if(o){var s=o.getPercentRange();i[0][n]={dataZoomId:n,start:s[0],end:s[1]}}}}),i.push(e)}function Xm(t){var e=qm(t),i=e[e.length-1];e.length>1&&e.pop();var n={};return Vk(i,function(t,i){for(var a=e.length-1;a>=0;a--){var t=e[a][i];if(t){n[i]=t;break}}}),n}function Um(t){t[Gk]=null}function Ym(t){return qm(t).length}function qm(t){var e=t[Gk];return e||(e=t[Gk]=[{}]),e}function $m(t,e,i){(this._brushController=new Fd(i.getZr())).on("brush",y(this._onBrush,this)).mount(),this._isZoomActive}function Km(t){var e={};return f(["xAxisIndex","yAxisIndex"],function(i){e[i]=t[i],null==e[i]&&(e[i]="all"),(e[i]===!1||"none"===e[i])&&(e[i]=[])}),e}function Jm(t,e){t.setIconStatus("back",Ym(e)>1?"emphasis":"normal")}function Qm(t,e,i,n,a){var r=i._isZoomActive;n&&"takeGlobalCursor"===n.type&&(r="dataZoomSelect"===n.key?n.dataZoomSelectActive:!1),i._isZoomActive=r,t.setIconStatus("zoom",r?"emphasis":"normal");var o=new tm(Km(t.option),e,{include:["grid"]});i._brushController.setPanels(o.makePanelOpts(a,function(t){return t.xAxisDeclared&&!t.yAxisDeclared?"lineX":!t.xAxisDeclared&&t.yAxisDeclared?"lineY":"rect"})).enableBrush(r?{brushType:"auto",brushStyle:{lineWidth:0,fill:"rgba(0,0,0,0.2)"}}:!1)}function ty(t){this.model=t}function ey(t,e,i,n){var a=i.type,r=nb[a.charAt(0).toUpperCase()+a.slice(1)],o=new r(i);e.add(o),n.set(t,o),o.__ecGraphicId=t}function iy(t,e){var i=t&&t.parent;i&&("group"===t.type&&t.traverse(function(t){iy(t,e)}),e.removeKey(t.__ecGraphicId),i.remove(t))}function ny(t){return t=o({},t),f(["id","parentId","$action","hv","bounding"].concat(Mb),function(e){delete t[e]}),t}function ay(t,e){var i;return f(e,function(e){null!=t[e]&&"auto"!==t[e]&&(i=!0)}),i}function ry(t,e){var i=t.exist;if(e.id=t.keyInfo.id,!e.type&&i&&(e.type=i.type),null==e.parentId){var n=e.parentOption;n?e.parentId=n.id:i&&(e.parentId=i.parentId)}e.parentOption=null}function oy(t,e,i){var n=o({},i),r=t[e],s=i.$action||"merge";"merge"===s?r?(a(r,n,!0),po(r,n,{ignoreSize:!0}),vo(i,r)):t[e]=n:"replace"===s?t[e]=n:"remove"===s&&r&&(t[e]=null)}function sy(t,e){t&&(t.hv=e.hv=[ay(e,["left","right"]),ay(e,["top","bottom"])],"group"===t.type&&(null==t.width&&(t.width=e.width=0),null==t.height&&(t.height=e.height=0)))}function ly(t){return qk(t)}function hy(){if(!Jk&&Qk){Jk=!0;var t=Qk.styleSheets;t.length<31?Qk.createStyleSheet().addRule(".zrvml","behavior:url(#default#VML)"):t[0].addRule(".zrvml","behavior:url(#default#VML)")}}function uy(t){return parseInt(t,10)}function cy(t,e){hy(),this.root=t,this.storage=e;var i=document.createElement("div"),n=document.createElement("div");i.style.cssText="display:inline-block;overflow:hidden;position:relative;width:300px;height:150px;",n.style.cssText="position:absolute;left:0;top:0;",t.appendChild(i),this._vmlRoot=n,this._vmlViewport=i,this.resize();var a=e.delFromStorage,r=e.addToStorage;e.delFromStorage=function(t){a.call(e,t),t&&t.onRemove&&t.onRemove(n)},e.addToStorage=function(t){t.onAdd&&t.onAdd(n),r.call(e,t)},this._firstPaint=!0}function dy(t){return function(){fx('In IE8.0 VML mode painter not support method "'+t+'"')}}var fy=2311,py=function(){return fy++},gy={};gy="undefined"!=typeof wx?{browser:{},os:{},node:!1,wxa:!0,canvasSupported:!0,svgSupported:!1,touchEventsSupported:!0}:"undefined"==typeof document&&"undefined"!=typeof self?{browser:{},os:{},node:!1,worker:!0,canvasSupported:!0}:"undefined"==typeof navigator?{browser:{},os:{},node:!0,worker:!1,canvasSupported:!0,svgSupported:!0}:e(navigator.userAgent);var vy=gy,my={"[object Function]":1,"[object RegExp]":1,"[object Date]":1,"[object Error]":1,"[object CanvasGradient]":1,"[object CanvasPattern]":1,"[object Image]":1,"[object Canvas]":1},yy={"[object Int8Array]":1,"[object Uint8Array]":1,"[object Uint8ClampedArray]":1,"[object Int16Array]":1,"[object Uint16Array]":1,"[object Int32Array]":1,"[object Uint32Array]":1,"[object Float32Array]":1,"[object Float64Array]":1},xy=Object.prototype.toString,_y=Array.prototype,wy=_y.forEach,by=_y.filter,My=_y.slice,Sy=_y.map,Iy=_y.reduce,Ty={},Ay=function(){return Ty.createCanvas()};Ty.createCanvas=function(){return document.createElement("canvas")};var Cy,Dy="__ec_primitive__";N.prototype={constructor:N,get:function(t){return this.hasOwnProperty(t)?this[t]:null},set:function(t,e){return this[t]=e},each:function(t,e){void 0!==e&&(t=y(t,e));for(var i in this)this.hasOwnProperty(i)&&t(this[i],i)},removeKey:function(t){delete this[t]}};var Ly=(Object.freeze||Object)({$override:i,clone:n,merge:a,mergeAll:r,extend:o,defaults:s,createCanvas:Ay,getContext:l,indexOf:h,inherits:u,mixin:c,isArrayLike:d,each:f,map:p,reduce:g,filter:v,find:m,bind:y,curry:x,isArray:_,isFunction:w,isString:b,isObject:M,isBuiltInObject:S,isTypedArray:I,isDom:T,eqNaN:A,retrieve:C,retrieve2:D,retrieve3:L,slice:k,normalizeCssArray:P,assert:O,trim:z,setAsPrimitive:E,isPrimitive:R,createHashMap:B,concatArray:V,noop:G}),ky="undefined"==typeof Float32Array?Array:Float32Array,Py=Y,Oy=q,zy=ee,Ey=ie,Ry=(Object.freeze||Object)({create:F,copy:W,clone:H,set:Z,add:j,scaleAndAdd:X,sub:U,len:Y,length:Py,lenSquare:q,lengthSquare:Oy,mul:$,div:K,dot:J,scale:Q,normalize:te,distance:ee,dist:zy,distanceSquare:ie,distSquare:Ey,negate:ne,lerp:ae,applyTransform:re,min:oe,max:se});le.prototype={constructor:le,_dragStart:function(t){var e=t.target;e&&e.draggable&&(this._draggingTarget=e,e.dragging=!0,this._x=t.offsetX,this._y=t.offsetY,this.dispatchToElement(he(e,t),"dragstart",t.event))},_drag:function(t){var e=this._draggingTarget;if(e){var i=t.offsetX,n=t.offsetY,a=i-this._x,r=n-this._y;this._x=i,this._y=n,e.drift(a,r,t),this.dispatchToElement(he(e,t),"drag",t.event);var o=this.findHover(i,n,e).target,s=this._dropTarget;this._dropTarget=o,e!==o&&(s&&o!==s&&this.dispatchToElement(he(s,t),"dragleave",t.event),o&&o!==s&&this.dispatchToElement(he(o,t),"dragenter",t.event))}},_dragEnd:function(t){var e=this._draggingTarget;e&&(e.dragging=!1),this.dispatchToElement(he(e,t),"dragend",t.event),this._dropTarget&&this.dispatchToElement(he(this._dropTarget,t),"drop",t.event),this._draggingTarget=null,this._dropTarget=null
-}};var Ny=Array.prototype.slice,By=function(){this._$handlers={}};By.prototype={constructor:By,one:function(t,e,i){var n=this._$handlers;if(!e||!t)return this;n[t]||(n[t]=[]);for(var a=0;a<n[t].length;a++)if(n[t][a].h===e)return this;return n[t].push({h:e,one:!0,ctx:i||this}),this},on:function(t,e,i){var n=this._$handlers;if(!e||!t)return this;n[t]||(n[t]=[]);for(var a=0;a<n[t].length;a++)if(n[t][a].h===e)return this;return n[t].push({h:e,one:!1,ctx:i||this}),this},isSilent:function(t){var e=this._$handlers;return e[t]&&e[t].length},off:function(t,e){var i=this._$handlers;if(!t)return this._$handlers={},this;if(e){if(i[t]){for(var n=[],a=0,r=i[t].length;r>a;a++)i[t][a].h!=e&&n.push(i[t][a]);i[t]=n}i[t]&&0===i[t].length&&delete i[t]}else delete i[t];return this},trigger:function(t){if(this._$handlers[t]){var e=arguments,i=e.length;i>3&&(e=Ny.call(e,1));for(var n=this._$handlers[t],a=n.length,r=0;a>r;){switch(i){case 1:n[r].h.call(n[r].ctx);break;case 2:n[r].h.call(n[r].ctx,e[1]);break;case 3:n[r].h.call(n[r].ctx,e[1],e[2]);break;default:n[r].h.apply(n[r].ctx,e)}n[r].one?(n.splice(r,1),a--):r++}}return this},triggerWithContext:function(t){if(this._$handlers[t]){var e=arguments,i=e.length;i>4&&(e=Ny.call(e,1,e.length-1));for(var n=e[e.length-1],a=this._$handlers[t],r=a.length,o=0;r>o;){switch(i){case 1:a[o].h.call(n);break;case 2:a[o].h.call(n,e[1]);break;case 3:a[o].h.call(n,e[1],e[2]);break;default:a[o].h.apply(n,e)}a[o].one?(a.splice(o,1),r--):o++}}return this}};var Vy="silent";ce.prototype.dispose=function(){};var Gy=["click","dblclick","mousewheel","mouseout","mouseup","mousedown","mousemove","contextmenu"],Fy=function(t,e,i,n){By.call(this),this.storage=t,this.painter=e,this.painterRoot=n,i=i||new ce,this.proxy=null,this._hovered={},this._lastTouchMoment,this._lastX,this._lastY,le.call(this),this.setHandlerProxy(i)};Fy.prototype={constructor:Fy,setHandlerProxy:function(t){this.proxy&&this.proxy.dispose(),t&&(f(Gy,function(e){t.on&&t.on(e,this[e],this)},this),t.handler=this),this.proxy=t},mousemove:function(t){var e=t.zrX,i=t.zrY,n=this._hovered,a=n.target;a&&!a.__zr&&(n=this.findHover(n.x,n.y),a=n.target);var r=this._hovered=this.findHover(e,i),o=r.target,s=this.proxy;s.setCursor&&s.setCursor(o?o.cursor:"default"),a&&o!==a&&this.dispatchToElement(n,"mouseout",t),this.dispatchToElement(r,"mousemove",t),o&&o!==a&&this.dispatchToElement(r,"mouseover",t)},mouseout:function(t){this.dispatchToElement(this._hovered,"mouseout",t);var e,i=t.toElement||t.relatedTarget;do i=i&&i.parentNode;while(i&&9!=i.nodeType&&!(e=i===this.painterRoot));!e&&this.trigger("globalout",{event:t})},resize:function(){this._hovered={}},dispatch:function(t,e){var i=this[t];i&&i.call(this,e)},dispose:function(){this.proxy.dispose(),this.storage=this.proxy=this.painter=null},setCursorStyle:function(t){var e=this.proxy;e.setCursor&&e.setCursor(t)},dispatchToElement:function(t,e,i){t=t||{};var n=t.target;if(!n||!n.silent){for(var a="on"+e,r=ue(e,t,i);n&&(n[a]&&(r.cancelBubble=n[a].call(n,r)),n.trigger(e,r),n=n.parent,!r.cancelBubble););r.cancelBubble||(this.trigger(e,r),this.painter&&this.painter.eachOtherLayer(function(t){"function"==typeof t[a]&&t[a].call(t,r),t.trigger&&t.trigger(e,r)}))}},findHover:function(t,e,i){for(var n=this.storage.getDisplayList(),a={x:t,y:e},r=n.length-1;r>=0;r--){var o;if(n[r]!==i&&!n[r].ignore&&(o=de(n[r],t,e))&&(!a.topTarget&&(a.topTarget=n[r]),o!==Vy)){a.target=n[r];break}}return a}},f(["click","mousedown","mouseup","mousewheel","dblclick","contextmenu"],function(t){Fy.prototype[t]=function(e){var i=this.findHover(e.zrX,e.zrY),n=i.target;if("mousedown"===t)this._downEl=n,this._downPoint=[e.zrX,e.zrY],this._upEl=n;else if("mouseup"===t)this._upEl=n;else if("click"===t){if(this._downEl!==this._upEl||!this._downPoint||zy(this._downPoint,[e.zrX,e.zrY])>4)return;this._downPoint=null}this.dispatchToElement(i,t,e)}}),c(Fy,By),c(Fy,le);var Wy="undefined"==typeof Float32Array?Array:Float32Array,Hy=(Object.freeze||Object)({create:fe,identity:pe,copy:ge,mul:ve,translate:me,rotate:ye,scale:xe,invert:_e,clone:we}),Zy=pe,jy=5e-5,Xy=function(t){t=t||{},t.position||(this.position=[0,0]),null==t.rotation&&(this.rotation=0),t.scale||(this.scale=[1,1]),this.origin=this.origin||null},Uy=Xy.prototype;Uy.transform=null,Uy.needLocalTransform=function(){return be(this.rotation)||be(this.position[0])||be(this.position[1])||be(this.scale[0]-1)||be(this.scale[1]-1)},Uy.updateTransform=function(){var t=this.parent,e=t&&t.transform,i=this.needLocalTransform(),n=this.transform;return i||e?(n=n||fe(),i?this.getLocalTransform(n):Zy(n),e&&(i?ve(n,t.transform,n):ge(n,t.transform)),this.transform=n,this.invTransform=this.invTransform||fe(),void _e(this.invTransform,n)):void(n&&Zy(n))},Uy.getLocalTransform=function(t){return Xy.getLocalTransform(this,t)},Uy.setTransform=function(t){var e=this.transform,i=t.dpr||1;e?t.setTransform(i*e[0],i*e[1],i*e[2],i*e[3],i*e[4],i*e[5]):t.setTransform(i,0,0,i,0,0)},Uy.restoreTransform=function(t){var e=t.dpr||1;t.setTransform(e,0,0,e,0,0)};var Yy=[];Uy.decomposeTransform=function(){if(this.transform){var t=this.parent,e=this.transform;t&&t.transform&&(ve(Yy,t.invTransform,e),e=Yy);var i=e[0]*e[0]+e[1]*e[1],n=e[2]*e[2]+e[3]*e[3],a=this.position,r=this.scale;be(i-1)&&(i=Math.sqrt(i)),be(n-1)&&(n=Math.sqrt(n)),e[0]<0&&(i=-i),e[3]<0&&(n=-n),a[0]=e[4],a[1]=e[5],r[0]=i,r[1]=n,this.rotation=Math.atan2(-e[1]/n,e[0]/i)}},Uy.getGlobalScale=function(){var t=this.transform;if(!t)return[1,1];var e=Math.sqrt(t[0]*t[0]+t[1]*t[1]),i=Math.sqrt(t[2]*t[2]+t[3]*t[3]);return t[0]<0&&(e=-e),t[3]<0&&(i=-i),[e,i]},Uy.transformCoordToLocal=function(t,e){var i=[t,e],n=this.invTransform;return n&&re(i,i,n),i},Uy.transformCoordToGlobal=function(t,e){var i=[t,e],n=this.transform;return n&&re(i,i,n),i},Xy.getLocalTransform=function(t,e){e=e||[],Zy(e);var i=t.origin,n=t.scale||[1,1],a=t.rotation||0,r=t.position||[0,0];return i&&(e[4]-=i[0],e[5]-=i[1]),xe(e,e,n),a&&ye(e,e,a),i&&(e[4]+=i[0],e[5]+=i[1]),e[4]+=r[0],e[5]+=r[1],e};var qy={linear:function(t){return t},quadraticIn:function(t){return t*t},quadraticOut:function(t){return t*(2-t)},quadraticInOut:function(t){return(t*=2)<1?.5*t*t:-.5*(--t*(t-2)-1)},cubicIn:function(t){return t*t*t},cubicOut:function(t){return--t*t*t+1},cubicInOut:function(t){return(t*=2)<1?.5*t*t*t:.5*((t-=2)*t*t+2)},quarticIn:function(t){return t*t*t*t},quarticOut:function(t){return 1- --t*t*t*t},quarticInOut:function(t){return(t*=2)<1?.5*t*t*t*t:-.5*((t-=2)*t*t*t-2)},quinticIn:function(t){return t*t*t*t*t},quinticOut:function(t){return--t*t*t*t*t+1},quinticInOut:function(t){return(t*=2)<1?.5*t*t*t*t*t:.5*((t-=2)*t*t*t*t+2)},sinusoidalIn:function(t){return 1-Math.cos(t*Math.PI/2)},sinusoidalOut:function(t){return Math.sin(t*Math.PI/2)},sinusoidalInOut:function(t){return.5*(1-Math.cos(Math.PI*t))},exponentialIn:function(t){return 0===t?0:Math.pow(1024,t-1)},exponentialOut:function(t){return 1===t?1:1-Math.pow(2,-10*t)},exponentialInOut:function(t){return 0===t?0:1===t?1:(t*=2)<1?.5*Math.pow(1024,t-1):.5*(-Math.pow(2,-10*(t-1))+2)},circularIn:function(t){return 1-Math.sqrt(1-t*t)},circularOut:function(t){return Math.sqrt(1- --t*t)},circularInOut:function(t){return(t*=2)<1?-.5*(Math.sqrt(1-t*t)-1):.5*(Math.sqrt(1-(t-=2)*t)+1)},elasticIn:function(t){var e,i=.1,n=.4;return 0===t?0:1===t?1:(!i||1>i?(i=1,e=n/4):e=n*Math.asin(1/i)/(2*Math.PI),-(i*Math.pow(2,10*(t-=1))*Math.sin(2*(t-e)*Math.PI/n)))},elasticOut:function(t){var e,i=.1,n=.4;return 0===t?0:1===t?1:(!i||1>i?(i=1,e=n/4):e=n*Math.asin(1/i)/(2*Math.PI),i*Math.pow(2,-10*t)*Math.sin(2*(t-e)*Math.PI/n)+1)},elasticInOut:function(t){var e,i=.1,n=.4;return 0===t?0:1===t?1:(!i||1>i?(i=1,e=n/4):e=n*Math.asin(1/i)/(2*Math.PI),(t*=2)<1?-.5*i*Math.pow(2,10*(t-=1))*Math.sin(2*(t-e)*Math.PI/n):i*Math.pow(2,-10*(t-=1))*Math.sin(2*(t-e)*Math.PI/n)*.5+1)},backIn:function(t){var e=1.70158;return t*t*((e+1)*t-e)},backOut:function(t){var e=1.70158;return--t*t*((e+1)*t+e)+1},backInOut:function(t){var e=2.5949095;return(t*=2)<1?.5*t*t*((e+1)*t-e):.5*((t-=2)*t*((e+1)*t+e)+2)},bounceIn:function(t){return 1-qy.bounceOut(1-t)},bounceOut:function(t){return 1/2.75>t?7.5625*t*t:2/2.75>t?7.5625*(t-=1.5/2.75)*t+.75:2.5/2.75>t?7.5625*(t-=2.25/2.75)*t+.9375:7.5625*(t-=2.625/2.75)*t+.984375},bounceInOut:function(t){return.5>t?.5*qy.bounceIn(2*t):.5*qy.bounceOut(2*t-1)+.5}};Me.prototype={constructor:Me,step:function(t,e){if(this._initialized||(this._startTime=t+this._delay,this._initialized=!0),this._paused)return void(this._pausedTime+=e);var i=(t-this._startTime-this._pausedTime)/this._life;if(!(0>i)){i=Math.min(i,1);var n=this.easing,a="string"==typeof n?qy[n]:n,r="function"==typeof a?a(i):i;return this.fire("frame",r),1==i?this.loop?(this.restart(t),"restart"):(this._needsRemove=!0,"destroy"):null}},restart:function(t){var e=(t-this._startTime-this._pausedTime)%this._life;this._startTime=t-e+this.gap,this._pausedTime=0,this._needsRemove=!1},fire:function(t,e){t="on"+t,this[t]&&this[t](this._target,e)},pause:function(){this._paused=!0},resume:function(){this._paused=!1}};var $y=function(){this.head=null,this.tail=null,this._len=0},Ky=$y.prototype;Ky.insert=function(t){var e=new Jy(t);return this.insertEntry(e),e},Ky.insertEntry=function(t){this.head?(this.tail.next=t,t.prev=this.tail,t.next=null,this.tail=t):this.head=this.tail=t,this._len++},Ky.remove=function(t){var e=t.prev,i=t.next;e?e.next=i:this.head=i,i?i.prev=e:this.tail=e,t.next=t.prev=null,this._len--},Ky.len=function(){return this._len},Ky.clear=function(){this.head=this.tail=null,this._len=0};var Jy=function(t){this.value=t,this.next,this.prev},Qy=function(t){this._list=new $y,this._map={},this._maxSize=t||10,this._lastRemovedEntry=null},tx=Qy.prototype;tx.put=function(t,e){var i=this._list,n=this._map,a=null;if(null==n[t]){var r=i.len(),o=this._lastRemovedEntry;if(r>=this._maxSize&&r>0){var s=i.head;i.remove(s),delete n[s.key],a=s.value,this._lastRemovedEntry=s}o?o.value=e:o=new Jy(e),o.key=t,i.insertEntry(o),n[t]=o}return a},tx.get=function(t){var e=this._map[t],i=this._list;return null!=e?(e!==i.tail&&(i.remove(e),i.insertEntry(e)),e.value):void 0},tx.clear=function(){this._list.clear(),this._map={}};var ex={transparent:[0,0,0,0],aliceblue:[240,248,255,1],antiquewhite:[250,235,215,1],aqua:[0,255,255,1],aquamarine:[127,255,212,1],azure:[240,255,255,1],beige:[245,245,220,1],bisque:[255,228,196,1],black:[0,0,0,1],blanchedalmond:[255,235,205,1],blue:[0,0,255,1],blueviolet:[138,43,226,1],brown:[165,42,42,1],burlywood:[222,184,135,1],cadetblue:[95,158,160,1],chartreuse:[127,255,0,1],chocolate:[210,105,30,1],coral:[255,127,80,1],cornflowerblue:[100,149,237,1],cornsilk:[255,248,220,1],crimson:[220,20,60,1],cyan:[0,255,255,1],darkblue:[0,0,139,1],darkcyan:[0,139,139,1],darkgoldenrod:[184,134,11,1],darkgray:[169,169,169,1],darkgreen:[0,100,0,1],darkgrey:[169,169,169,1],darkkhaki:[189,183,107,1],darkmagenta:[139,0,139,1],darkolivegreen:[85,107,47,1],darkorange:[255,140,0,1],darkorchid:[153,50,204,1],darkred:[139,0,0,1],darksalmon:[233,150,122,1],darkseagreen:[143,188,143,1],darkslateblue:[72,61,139,1],darkslategray:[47,79,79,1],darkslategrey:[47,79,79,1],darkturquoise:[0,206,209,1],darkviolet:[148,0,211,1],deeppink:[255,20,147,1],deepskyblue:[0,191,255,1],dimgray:[105,105,105,1],dimgrey:[105,105,105,1],dodgerblue:[30,144,255,1],firebrick:[178,34,34,1],floralwhite:[255,250,240,1],forestgreen:[34,139,34,1],fuchsia:[255,0,255,1],gainsboro:[220,220,220,1],ghostwhite:[248,248,255,1],gold:[255,215,0,1],goldenrod:[218,165,32,1],gray:[128,128,128,1],green:[0,128,0,1],greenyellow:[173,255,47,1],grey:[128,128,128,1],honeydew:[240,255,240,1],hotpink:[255,105,180,1],indianred:[205,92,92,1],indigo:[75,0,130,1],ivory:[255,255,240,1],khaki:[240,230,140,1],lavender:[230,230,250,1],lavenderblush:[255,240,245,1],lawngreen:[124,252,0,1],lemonchiffon:[255,250,205,1],lightblue:[173,216,230,1],lightcoral:[240,128,128,1],lightcyan:[224,255,255,1],lightgoldenrodyellow:[250,250,210,1],lightgray:[211,211,211,1],lightgreen:[144,238,144,1],lightgrey:[211,211,211,1],lightpink:[255,182,193,1],lightsalmon:[255,160,122,1],lightseagreen:[32,178,170,1],lightskyblue:[135,206,250,1],lightslategray:[119,136,153,1],lightslategrey:[119,136,153,1],lightsteelblue:[176,196,222,1],lightyellow:[255,255,224,1],lime:[0,255,0,1],limegreen:[50,205,50,1],linen:[250,240,230,1],magenta:[255,0,255,1],maroon:[128,0,0,1],mediumaquamarine:[102,205,170,1],mediumblue:[0,0,205,1],mediumorchid:[186,85,211,1],mediumpurple:[147,112,219,1],mediumseagreen:[60,179,113,1],mediumslateblue:[123,104,238,1],mediumspringgreen:[0,250,154,1],mediumturquoise:[72,209,204,1],mediumvioletred:[199,21,133,1],midnightblue:[25,25,112,1],mintcream:[245,255,250,1],mistyrose:[255,228,225,1],moccasin:[255,228,181,1],navajowhite:[255,222,173,1],navy:[0,0,128,1],oldlace:[253,245,230,1],olive:[128,128,0,1],olivedrab:[107,142,35,1],orange:[255,165,0,1],orangered:[255,69,0,1],orchid:[218,112,214,1],palegoldenrod:[238,232,170,1],palegreen:[152,251,152,1],paleturquoise:[175,238,238,1],palevioletred:[219,112,147,1],papayawhip:[255,239,213,1],peachpuff:[255,218,185,1],peru:[205,133,63,1],pink:[255,192,203,1],plum:[221,160,221,1],powderblue:[176,224,230,1],purple:[128,0,128,1],red:[255,0,0,1],rosybrown:[188,143,143,1],royalblue:[65,105,225,1],saddlebrown:[139,69,19,1],salmon:[250,128,114,1],sandybrown:[244,164,96,1],seagreen:[46,139,87,1],seashell:[255,245,238,1],sienna:[160,82,45,1],silver:[192,192,192,1],skyblue:[135,206,235,1],slateblue:[106,90,205,1],slategray:[112,128,144,1],slategrey:[112,128,144,1],snow:[255,250,250,1],springgreen:[0,255,127,1],steelblue:[70,130,180,1],tan:[210,180,140,1],teal:[0,128,128,1],thistle:[216,191,216,1],tomato:[255,99,71,1],turquoise:[64,224,208,1],violet:[238,130,238,1],wheat:[245,222,179,1],white:[255,255,255,1],whitesmoke:[245,245,245,1],yellow:[255,255,0,1],yellowgreen:[154,205,50,1]},ix=new Qy(20),nx=null,ax=Ve,rx=Ge,ox=(Object.freeze||Object)({parse:ze,lift:Ne,toHex:Be,fastLerp:Ve,fastMapToColor:ax,lerp:Ge,mapToColor:rx,modifyHSL:Fe,modifyAlpha:We,stringify:He}),sx=Array.prototype.slice,lx=function(t,e,i,n){this._tracks={},this._target=t,this._loop=e||!1,this._getter=i||Ze,this._setter=n||je,this._clipCount=0,this._delay=0,this._doneList=[],this._onframeList=[],this._clipList=[]};lx.prototype={when:function(t,e){var i=this._tracks;for(var n in e)if(e.hasOwnProperty(n)){if(!i[n]){i[n]=[];var a=this._getter(this._target,n);if(null==a)continue;0!==t&&i[n].push({time:0,value:Qe(a)})}i[n].push({time:t,value:e[n]})}return this},during:function(t){return this._onframeList.push(t),this},pause:function(){for(var t=0;t<this._clipList.length;t++)this._clipList[t].pause();this._paused=!0},resume:function(){for(var t=0;t<this._clipList.length;t++)this._clipList[t].resume();this._paused=!1},isPaused:function(){return!!this._paused},_doneCallback:function(){this._tracks={},this._clipList.length=0;for(var t=this._doneList,e=t.length,i=0;e>i;i++)t[i].call(this)},start:function(t,e){var i,n=this,a=0,r=function(){a--,a||n._doneCallback()};for(var o in this._tracks)if(this._tracks.hasOwnProperty(o)){var s=ii(this,t,r,this._tracks[o],o,e);s&&(this._clipList.push(s),a++,this.animation&&this.animation.addClip(s),i=s)}if(i){var l=i.onframe;i.onframe=function(t,e){l(t,e);for(var i=0;i<n._onframeList.length;i++)n._onframeList[i](t,e)}}return a||this._doneCallback(),this},stop:function(t){for(var e=this._clipList,i=this.animation,n=0;n<e.length;n++){var a=e[n];t&&a.onframe(this._target,1),i&&i.removeClip(a)}e.length=0},delay:function(t){return this._delay=t,this},done:function(t){return t&&this._doneList.push(t),this},getClips:function(){return this._clipList}};var hx=1;"undefined"!=typeof window&&(hx=Math.max(window.devicePixelRatio||1,1));var ux=0,cx=hx,dx=function(){};1===ux?dx=function(){for(var t in arguments)throw new Error(arguments[t])}:ux>1&&(dx=function(){for(var t in arguments)console.log(arguments[t])});var fx=dx,px=function(){this.animators=[]};px.prototype={constructor:px,animate:function(t,e){var i,n=!1,a=this,r=this.__zr;if(t){var o=t.split("."),s=a;n="shape"===o[0];for(var l=0,u=o.length;u>l;l++)s&&(s=s[o[l]]);s&&(i=s)}else i=a;if(!i)return void fx('Property "'+t+'" is not existed in element '+a.id);var c=a.animators,d=new lx(i,e);return d.during(function(){a.dirty(n)}).done(function(){c.splice(h(c,d),1)}),c.push(d),r&&r.animation.addAnimator(d),d},stopAnimation:function(t){for(var e=this.animators,i=e.length,n=0;i>n;n++)e[n].stop(t);return e.length=0,this},animateTo:function(t,e,i,n,a,r){function o(){l--,l||a&&a()}b(i)?(a=n,n=i,i=0):w(n)?(a=n,n="linear",i=0):w(i)?(a=i,i=0):w(e)?(a=e,e=500):e||(e=500),this.stopAnimation(),this._animateToShallow("",this,t,e,i);var s=this.animators.slice(),l=s.length;l||a&&a();for(var h=0;h<s.length;h++)s[h].done(o).start(n,r)},_animateToShallow:function(t,e,i,n,a){var r={},o=0;for(var s in i)if(i.hasOwnProperty(s))if(null!=e[s])M(i[s])&&!d(i[s])?this._animateToShallow(t?t+"."+s:s,e[s],i[s],n,a):(r[s]=i[s],o++);else if(null!=i[s])if(t){var l={};l[t]={},l[t][s]=i[s],this.attr(l)}else this.attr(s,i[s]);return o>0&&this.animate(t,!1).when(null==n?500:n,r).delay(a||0),this}};var gx=function(t){Xy.call(this,t),By.call(this,t),px.call(this,t),this.id=t.id||py()};gx.prototype={type:"element",name:"",__zr:null,ignore:!1,clipPath:null,isGroup:!1,drift:function(t,e){switch(this.draggable){case"horizontal":e=0;break;case"vertical":t=0}var i=this.transform;i||(i=this.transform=[1,0,0,1,0,0]),i[4]+=t,i[5]+=e,this.decomposeTransform(),this.dirty(!1)},beforeUpdate:function(){},afterUpdate:function(){},update:function(){this.updateTransform()},traverse:function(){},attrKV:function(t,e){if("position"===t||"scale"===t||"origin"===t){if(e){var i=this[t];i||(i=this[t]=[]),i[0]=e[0],i[1]=e[1]}}else this[t]=e},hide:function(){this.ignore=!0,this.__zr&&this.__zr.refresh()},show:function(){this.ignore=!1,this.__zr&&this.__zr.refresh()},attr:function(t,e){if("string"==typeof t)this.attrKV(t,e);else if(M(t))for(var i in t)t.hasOwnProperty(i)&&this.attrKV(i,t[i]);return this.dirty(!1),this},setClipPath:function(t){var e=this.__zr;e&&t.addSelfToZr(e),this.clipPath&&this.clipPath!==t&&this.removeClipPath(),this.clipPath=t,t.__zr=e,t.__clipTarget=this,this.dirty(!1)},removeClipPath:function(){var t=this.clipPath;t&&(t.__zr&&t.removeSelfFromZr(t.__zr),t.__zr=null,t.__clipTarget=null,this.clipPath=null,this.dirty(!1))},addSelfToZr:function(t){this.__zr=t;var e=this.animators;if(e)for(var i=0;i<e.length;i++)t.animation.addAnimator(e[i]);this.clipPath&&this.clipPath.addSelfToZr(t)},removeSelfFromZr:function(t){this.__zr=null;var e=this.animators;if(e)for(var i=0;i<e.length;i++)t.animation.removeAnimator(e[i]);this.clipPath&&this.clipPath.removeSelfFromZr(t)}},c(gx,px),c(gx,Xy),c(gx,By);var vx=re,mx=Math.min,yx=Math.max;ni.prototype={constructor:ni,union:function(t){var e=mx(t.x,this.x),i=mx(t.y,this.y);this.width=yx(t.x+t.width,this.x+this.width)-e,this.height=yx(t.y+t.height,this.y+this.height)-i,this.x=e,this.y=i},applyTransform:function(){var t=[],e=[],i=[],n=[];return function(a){if(a){t[0]=i[0]=this.x,t[1]=n[1]=this.y,e[0]=n[0]=this.x+this.width,e[1]=i[1]=this.y+this.height,vx(t,t,a),vx(e,e,a),vx(i,i,a),vx(n,n,a),this.x=mx(t[0],e[0],i[0],n[0]),this.y=mx(t[1],e[1],i[1],n[1]);var r=yx(t[0],e[0],i[0],n[0]),o=yx(t[1],e[1],i[1],n[1]);this.width=r-this.x,this.height=o-this.y}}}(),calculateTransform:function(t){var e=this,i=t.width/e.width,n=t.height/e.height,a=fe();return me(a,a,[-e.x,-e.y]),xe(a,a,[i,n]),me(a,a,[t.x,t.y]),a},intersect:function(t){if(!t)return!1;t instanceof ni||(t=ni.create(t));var e=this,i=e.x,n=e.x+e.width,a=e.y,r=e.y+e.height,o=t.x,s=t.x+t.width,l=t.y,h=t.y+t.height;return!(o>n||i>s||l>r||a>h)},contain:function(t,e){var i=this;return t>=i.x&&t<=i.x+i.width&&e>=i.y&&e<=i.y+i.height},clone:function(){return new ni(this.x,this.y,this.width,this.height)},copy:function(t){this.x=t.x,this.y=t.y,this.width=t.width,this.height=t.height},plain:function(){return{x:this.x,y:this.y,width:this.width,height:this.height}}},ni.create=function(t){return new ni(t.x,t.y,t.width,t.height)};var xx=function(t){t=t||{},gx.call(this,t);for(var e in t)t.hasOwnProperty(e)&&(this[e]=t[e]);this._children=[],this.__storage=null,this.__dirty=!0};xx.prototype={constructor:xx,isGroup:!0,type:"group",silent:!1,children:function(){return this._children.slice()},childAt:function(t){return this._children[t]},childOfName:function(t){for(var e=this._children,i=0;i<e.length;i++)if(e[i].name===t)return e[i]},childCount:function(){return this._children.length},add:function(t){return t&&t!==this&&t.parent!==this&&(this._children.push(t),this._doAdd(t)),this},addBefore:function(t,e){if(t&&t!==this&&t.parent!==this&&e&&e.parent===this){var i=this._children,n=i.indexOf(e);n>=0&&(i.splice(n,0,t),this._doAdd(t))}return this},_doAdd:function(t){t.parent&&t.parent.remove(t),t.parent=this;var e=this.__storage,i=this.__zr;e&&e!==t.__storage&&(e.addToStorage(t),t instanceof xx&&t.addChildrenToStorage(e)),i&&i.refresh()},remove:function(t){var e=this.__zr,i=this.__storage,n=this._children,a=h(n,t);return 0>a?this:(n.splice(a,1),t.parent=null,i&&(i.delFromStorage(t),t instanceof xx&&t.delChildrenFromStorage(i)),e&&e.refresh(),this)},removeAll:function(){var t,e,i=this._children,n=this.__storage;for(e=0;e<i.length;e++)t=i[e],n&&(n.delFromStorage(t),t instanceof xx&&t.delChildrenFromStorage(n)),t.parent=null;return i.length=0,this},eachChild:function(t,e){for(var i=this._children,n=0;n<i.length;n++){var a=i[n];t.call(e,a,n)}return this},traverse:function(t,e){for(var i=0;i<this._children.length;i++){var n=this._children[i];t.call(e,n),"group"===n.type&&n.traverse(t,e)}return this},addChildrenToStorage:function(t){for(var e=0;e<this._children.length;e++){var i=this._children[e];t.addToStorage(i),i instanceof xx&&i.addChildrenToStorage(t)}},delChildrenFromStorage:function(t){for(var e=0;e<this._children.length;e++){var i=this._children[e];t.delFromStorage(i),i instanceof xx&&i.delChildrenFromStorage(t)}},dirty:function(){return this.__dirty=!0,this.__zr&&this.__zr.refresh(),this},getBoundingRect:function(t){for(var e=null,i=new ni(0,0,0,0),n=t||this._children,a=[],r=0;r<n.length;r++){var o=n[r];if(!o.ignore&&!o.invisible){var s=o.getBoundingRect(),l=o.getLocalTransform(a);l?(i.copy(s),i.applyTransform(l),e=e||i.clone(),e.union(i)):(e=e||s.clone(),e.union(s))}}return e||i}},u(xx,gx);var _x=32,bx=7,Mx=function(){this._roots=[],this._displayList=[],this._displayListLen=0};Mx.prototype={constructor:Mx,traverse:function(t,e){for(var i=0;i<this._roots.length;i++)this._roots[i].traverse(t,e)},getDisplayList:function(t,e){return e=e||!1,t&&this.updateDisplayList(e),this._displayList},updateDisplayList:function(t){this._displayListLen=0;for(var e=this._roots,i=this._displayList,n=0,a=e.length;a>n;n++)this._updateAndAddDisplayable(e[n],null,t);i.length=this._displayListLen,vy.canvasSupported&&ci(i,di)},_updateAndAddDisplayable:function(t,e,i){if(!t.ignore||i){t.beforeUpdate(),t.__dirty&&t.update(),t.afterUpdate();var n=t.clipPath;if(n){e=e?e.slice():[];for(var a=n,r=t;a;)a.parent=r,a.updateTransform(),e.push(a),r=a,a=a.clipPath}if(t.isGroup){for(var o=t._children,s=0;s<o.length;s++){var l=o[s];t.__dirty&&(l.__dirty=!0),this._updateAndAddDisplayable(l,e,i)}t.__dirty=!1}else t.__clipPaths=e,this._displayList[this._displayListLen++]=t}},addRoot:function(t){t.__storage!==this&&(t instanceof xx&&t.addChildrenToStorage(this),this.addToStorage(t),this._roots.push(t))},delRoot:function(t){if(null==t){for(var e=0;e<this._roots.length;e++){var i=this._roots[e];i instanceof xx&&i.delChildrenFromStorage(this)}return this._roots=[],this._displayList=[],void(this._displayListLen=0)}if(t instanceof Array)for(var e=0,n=t.length;n>e;e++)this.delRoot(t[e]);else{var a=h(this._roots,t);a>=0&&(this.delFromStorage(t),this._roots.splice(a,1),t instanceof xx&&t.delChildrenFromStorage(this))}},addToStorage:function(t){return t&&(t.__storage=this,t.dirty(!1)),this},delFromStorage:function(t){return t&&(t.__storage=null),this},dispose:function(){this._renderList=this._roots=null},displayableSortFunc:di};var Sx={shadowBlur:1,shadowOffsetX:1,shadowOffsetY:1,textShadowBlur:1,textShadowOffsetX:1,textShadowOffsetY:1,textBoxShadowBlur:1,textBoxShadowOffsetX:1,textBoxShadowOffsetY:1},Ix=function(t,e,i){return Sx.hasOwnProperty(e)?i*=t.dpr:i},Tx=[["shadowBlur",0],["shadowOffsetX",0],["shadowOffsetY",0],["shadowColor","#000"],["lineCap","butt"],["lineJoin","miter"],["miterLimit",10]],Ax=function(t,e){this.extendFrom(t,!1),this.host=e};Ax.prototype={constructor:Ax,host:null,fill:"#000",stroke:null,opacity:1,lineDash:null,lineDashOffset:0,shadowBlur:0,shadowOffsetX:0,shadowOffsetY:0,lineWidth:1,strokeNoScale:!1,text:null,font:null,textFont:null,fontStyle:null,fontWeight:null,fontSize:null,fontFamily:null,textTag:null,textFill:"#000",textStroke:null,textWidth:null,textHeight:null,textStrokeWidth:0,textLineHeight:null,textPosition:"inside",textRect:null,textOffset:null,textAlign:null,textVerticalAlign:null,textDistance:5,textShadowColor:"transparent",textShadowBlur:0,textShadowOffsetX:0,textShadowOffsetY:0,textBoxShadowColor:"transparent",textBoxShadowBlur:0,textBoxShadowOffsetX:0,textBoxShadowOffsetY:0,transformText:!1,textRotation:0,textOrigin:null,textBackgroundColor:null,textBorderColor:null,textBorderWidth:0,textBorderRadius:0,textPadding:null,rich:null,truncate:null,blend:null,bind:function(t,e,i){for(var n=this,a=i&&i.style,r=!a,o=0;o<Tx.length;o++){var s=Tx[o],l=s[0];(r||n[l]!==a[l])&&(t[l]=Ix(t,l,n[l]||s[1]))}if((r||n.fill!==a.fill)&&(t.fillStyle=n.fill),(r||n.stroke!==a.stroke)&&(t.strokeStyle=n.stroke),(r||n.opacity!==a.opacity)&&(t.globalAlpha=null==n.opacity?1:n.opacity),(r||n.blend!==a.blend)&&(t.globalCompositeOperation=n.blend||"source-over"),this.hasStroke()){var h=n.lineWidth;t.lineWidth=h/(this.strokeNoScale&&e&&e.getLineScale?e.getLineScale():1)}},hasFill:function(){var t=this.fill;return null!=t&&"none"!==t},hasStroke:function(){var t=this.stroke;return null!=t&&"none"!==t&&this.lineWidth>0},extendFrom:function(t,e){if(t)for(var i in t)!t.hasOwnProperty(i)||e!==!0&&(e===!1?this.hasOwnProperty(i):null==t[i])||(this[i]=t[i])},set:function(t,e){"string"==typeof t?this[t]=e:this.extendFrom(t,!0)},clone:function(){var t=new this.constructor;return t.extendFrom(this,!0),t},getGradient:function(t,e,i){for(var n="radial"===e.type?pi:fi,a=n(t,e,i),r=e.colorStops,o=0;o<r.length;o++)a.addColorStop(r[o].offset,r[o].color);return a}};for(var Cx=Ax.prototype,Dx=0;Dx<Tx.length;Dx++){var Lx=Tx[Dx];Lx[0]in Cx||(Cx[Lx[0]]=Lx[1])}Ax.getGradient=Cx.getGradient;var kx=function(t,e){this.image=t,this.repeat=e,this.type="pattern"};kx.prototype.getCanvasPattern=function(t){return t.createPattern(this.image,this.repeat||"repeat")};var Px=function(t,e,i){var n;i=i||cx,"string"==typeof t?n=vi(t,e,i):M(t)&&(n=t,t=n.id),this.id=t,this.dom=n;var a=n.style;a&&(n.onselectstart=gi,a["-webkit-user-select"]="none",a["user-select"]="none",a["-webkit-touch-callout"]="none",a["-webkit-tap-highlight-color"]="rgba(0,0,0,0)",a.padding=0,a.margin=0,a["border-width"]=0),this.domBack=null,this.ctxBack=null,this.painter=e,this.config=null,this.clearColor=0,this.motionBlur=!1,this.lastFrameAlpha=.7,this.dpr=i};Px.prototype={constructor:Px,__dirty:!0,__used:!1,__drawIndex:0,__startIndex:0,__endIndex:0,incremental:!1,getElementCount:function(){return this.__endIndex-this.__startIndex},initContext:function(){this.ctx=this.dom.getContext("2d"),this.ctx.dpr=this.dpr},createBackBuffer:function(){var t=this.dpr;this.domBack=vi("back-"+this.id,this.painter,t),this.ctxBack=this.domBack.getContext("2d"),1!=t&&this.ctxBack.scale(t,t)},resize:function(t,e){var i=this.dpr,n=this.dom,a=n.style,r=this.domBack;a.width=t+"px",a.height=e+"px",n.width=t*i,n.height=e*i,r&&(r.width=t*i,r.height=e*i,1!=i&&this.ctxBack.scale(i,i))},clear:function(t){var e=this.dom,i=this.ctx,n=e.width,a=e.height,r=this.clearColor,o=this.motionBlur&&!t,s=this.lastFrameAlpha,l=this.dpr;if(o&&(this.domBack||this.createBackBuffer(),this.ctxBack.globalCompositeOperation="copy",this.ctxBack.drawImage(e,0,0,n/l,a/l)),i.clearRect(0,0,n,a),r){var h;r.colorStops?(h=r.__canvasGradient||Ax.getGradient(i,r,{x:0,y:0,width:n,height:a}),r.__canvasGradient=h):r.image&&(h=kx.prototype.getCanvasPattern.call(r,i)),i.save(),i.fillStyle=h||r,i.fillRect(0,0,n,a),i.restore()}if(o){var u=this.domBack;i.save(),i.globalAlpha=s,i.drawImage(u,0,0,n,a),i.restore()}}};var Ox="undefined"!=typeof window&&(window.requestAnimationFrame&&window.requestAnimationFrame.bind(window)||window.msRequestAnimationFrame&&window.msRequestAnimationFrame.bind(window)||window.mozRequestAnimationFrame||window.webkitRequestAnimationFrame)||function(t){setTimeout(t,16)},zx=new Qy(50),Ex={},Rx=0,Nx=5e3,Bx=/\{([a-zA-Z0-9_]+)\|([^}]*)\}/g,Vx="12px sans-serif",Gx={};Gx.measureText=function(t,e){var i=l();return i.font=e||Vx,i.measureText(t)};var Fx={left:1,right:1,center:1},Wx={top:1,bottom:1,middle:1},Hx=new ni,Zx=function(){};Zx.prototype={constructor:Zx,drawRectText:function(t,e){var i=this.style;e=i.textRect||e,this.__dirty&&Gi(i,!0);var n=i.text;if(null!=n&&(n+=""),an(n,i)){t.save();var a=this.transform;i.transformText?this.setTransform(t):a&&(Hx.copy(e),Hx.applyTransform(a),e=Hx),Wi(this,t,n,i,e),t.restore()}}},rn.prototype={constructor:rn,type:"displayable",__dirty:!0,invisible:!1,z:0,z2:0,zlevel:0,draggable:!1,dragging:!1,silent:!1,culling:!1,cursor:"pointer",rectHover:!1,progressive:!1,incremental:!1,inplace:!1,beforeBrush:function(){},afterBrush:function(){},brush:function(){},getBoundingRect:function(){},contain:function(t,e){return this.rectContain(t,e)},traverse:function(t,e){t.call(e,this)},rectContain:function(t,e){var i=this.transformCoordToLocal(t,e),n=this.getBoundingRect();return n.contain(i[0],i[1])},dirty:function(){this.__dirty=!0,this._rect=null,this.__zr&&this.__zr.refresh()},animateStyle:function(t){return this.animate("style",t)},attrKV:function(t,e){"style"!==t?gx.prototype.attrKV.call(this,t,e):this.style.set(e)},setStyle:function(t,e){return this.style.set(t,e),this.dirty(!1),this},useStyle:function(t){return this.style=new Ax(t,this),this.dirty(!1),this}},u(rn,gx),c(rn,Zx),on.prototype={constructor:on,type:"image",brush:function(t,e){var i=this.style,n=i.image;i.bind(t,this,e);var a=this._image=yi(n,this._image,this,this.onload);if(a&&_i(a)){var r=i.x||0,o=i.y||0,s=i.width,l=i.height,h=a.width/a.height;if(null==s&&null!=l?s=l*h:null==l&&null!=s?l=s/h:null==s&&null==l&&(s=a.width,l=a.height),this.setTransform(t),i.sWidth&&i.sHeight){var u=i.sx||0,c=i.sy||0;t.drawImage(a,u,c,i.sWidth,i.sHeight,r,o,s,l)}else if(i.sx&&i.sy){var u=i.sx,c=i.sy,d=s-u,f=l-c;t.drawImage(a,u,c,d,f,r,o,s,l)}else t.drawImage(a,r,o,s,l);null!=i.text&&(this.restoreTransform(t),this.drawRectText(t,this.getBoundingRect()))}},getBoundingRect:function(){var t=this.style;return this._rect||(this._rect=new ni(t.x||0,t.y||0,t.width||0,t.height||0)),this._rect}},u(on,rn);var jx=1e5,Xx=314159,Ux=.01,Yx=.001,qx=new ni(0,0,0,0),$x=new ni(0,0,0,0),Kx=function(t,e,i){this.type="canvas";var n=!t.nodeName||"CANVAS"===t.nodeName.toUpperCase();this._opts=i=o({},i||{}),this.dpr=i.devicePixelRatio||cx,this._singleCanvas=n,this.root=t;var a=t.style;a&&(a["-webkit-tap-highlight-color"]="transparent",a["-webkit-user-select"]=a["user-select"]=a["-webkit-touch-callout"]="none",t.innerHTML=""),this.storage=e;var r=this._zlevelList=[],s=this._layers={};if(this._layerConfig={},this._needsManuallyCompositing=!1,n){null!=i.width&&(t.width=i.width),null!=i.height&&(t.height=i.height);var l=t.width,h=t.height;this._width=l,this._height=h;var u=new Px(t,this,1);u.__builtin__=!0,u.initContext(),s[Xx]=u,r.push(Xx),this._domRoot=t}else{this._width=this._getSize(0),this._height=this._getSize(1);var c=this._domRoot=dn(this._width,this._height);t.appendChild(c)}this._hoverlayer=null,this._hoverElements=[]};Kx.prototype={constructor:Kx,getType:function(){return"canvas"},isSingleCanvas:function(){return this._singleCanvas},getViewportRoot:function(){return this._domRoot
-},getViewportRootOffset:function(){var t=this.getViewportRoot();return t?{offsetLeft:t.offsetLeft||0,offsetTop:t.offsetTop||0}:void 0},refresh:function(t){var e=this.storage.getDisplayList(!0),i=this._zlevelList;this._redrawId=Math.random(),this._paintList(e,t,this._redrawId);for(var n=0;n<i.length;n++){var a=i[n],r=this._layers[a];!r.__builtin__&&r.refresh&&r.refresh()}return this.refreshHover(),this},addHover:function(t,e){if(!t.__hoverMir){var i=new t.constructor({style:t.style,shape:t.shape});i.__from=t,t.__hoverMir=i,i.setStyle(e),this._hoverElements.push(i)}},removeHover:function(t){var e=t.__hoverMir,i=this._hoverElements,n=h(i,e);n>=0&&i.splice(n,1),t.__hoverMir=null},clearHover:function(){for(var t=this._hoverElements,e=0;e<t.length;e++){var i=t[e].__from;i&&(i.__hoverMir=null)}t.length=0},refreshHover:function(){var t=this._hoverElements,e=t.length,i=this._hoverlayer;if(i&&i.clear(),e){ci(t,this.storage.displayableSortFunc),i||(i=this._hoverlayer=this.getLayer(jx));var n={};i.ctx.save();for(var a=0;e>a;){var r=t[a],o=r.__from;o&&o.__zr?(a++,o.invisible||(r.transform=o.transform,r.invTransform=o.invTransform,r.__clipPaths=o.__clipPaths,this._doPaintEl(r,i,!0,n))):(t.splice(a,1),o.__hoverMir=null,e--)}i.ctx.restore()}},getHoverLayer:function(){return this.getLayer(jx)},_paintList:function(t,e,i){if(this._redrawId===i){e=e||!1,this._updateLayerStatus(t);var n=this._doPaintList(t,e);if(this._needsManuallyCompositing&&this._compositeManually(),!n){var a=this;Ox(function(){a._paintList(t,e,i)})}}},_compositeManually:function(){var t=this.getLayer(Xx).ctx,e=this._domRoot.width,i=this._domRoot.height;t.clearRect(0,0,e,i),this.eachBuiltinLayer(function(n){n.virtual&&t.drawImage(n.dom,0,0,e,i)})},_doPaintList:function(t,e){for(var i=[],n=0;n<this._zlevelList.length;n++){var a=this._zlevelList[n],r=this._layers[a];r.__builtin__&&r!==this._hoverlayer&&(r.__dirty||e)&&i.push(r)}for(var o=!0,s=0;s<i.length;s++){var r=i[s],l=r.ctx,h={};l.save();var u=e?r.__startIndex:r.__drawIndex,c=!e&&r.incremental&&Date.now,d=c&&Date.now();if(r.__startIndex===r.__endIndex)r.clear();else if(u===r.__startIndex){var p=t[u];p.incremental&&p.notClear&&!e||r.clear()}-1===u&&(console.error("For some unknown reason. drawIndex is -1"),u=r.__startIndex);for(var g=u;g<r.__endIndex;g++){var v=t[g];if(this._doPaintEl(v,r,e,h),v.__dirty=!1,c){var m=Date.now()-d;if(m>15)break}}r.__drawIndex=g,r.__drawIndex<r.__endIndex&&(o=!1),l.restore()}return vy.wxa&&f(this._layers,function(t){t&&t.ctx&&t.ctx.draw&&t.ctx.draw()}),o},_doPaintEl:function(t,e,i,n){var a=e.ctx,r=t.transform;if(!(!e.__dirty&&!i||t.invisible||0===t.style.opacity||r&&!r[0]&&!r[3]||t.culling&&hn(t,this._width,this._height))){var o=t.__clipPaths;(n.prevClipLayer!==e||un(o,n.prevElClipPaths))&&(n.prevElClipPaths&&(n.prevClipLayer.ctx.restore(),n.prevClipLayer=n.prevElClipPaths=null,n.prevEl=null),o&&(a.save(),cn(o,a),n.prevClipLayer=e,n.prevElClipPaths=o)),t.beforeBrush&&t.beforeBrush(a),t.brush(a,n.prevEl||null),n.prevEl=t,t.afterBrush&&t.afterBrush(a)}},getLayer:function(t,e){this._singleCanvas&&!this._needsManuallyCompositing&&(t=Xx);var i=this._layers[t];return i||(i=new Px("zr_"+t,this,this.dpr),i.zlevel=t,i.__builtin__=!0,this._layerConfig[t]&&a(i,this._layerConfig[t],!0),e&&(i.virtual=e),this.insertLayer(t,i),i.initContext()),i},insertLayer:function(t,e){var i=this._layers,n=this._zlevelList,a=n.length,r=null,o=-1,s=this._domRoot;if(i[t])return void fx("ZLevel "+t+" has been used already");if(!ln(e))return void fx("Layer of zlevel "+t+" is not valid");if(a>0&&t>n[0]){for(o=0;a-1>o&&!(n[o]<t&&n[o+1]>t);o++);r=i[n[o]]}if(n.splice(o+1,0,t),i[t]=e,!e.virtual)if(r){var l=r.dom;l.nextSibling?s.insertBefore(e.dom,l.nextSibling):s.appendChild(e.dom)}else s.firstChild?s.insertBefore(e.dom,s.firstChild):s.appendChild(e.dom)},eachLayer:function(t,e){var i,n,a=this._zlevelList;for(n=0;n<a.length;n++)i=a[n],t.call(e,this._layers[i],i)},eachBuiltinLayer:function(t,e){var i,n,a,r=this._zlevelList;for(a=0;a<r.length;a++)n=r[a],i=this._layers[n],i.__builtin__&&t.call(e,i,n)},eachOtherLayer:function(t,e){var i,n,a,r=this._zlevelList;for(a=0;a<r.length;a++)n=r[a],i=this._layers[n],i.__builtin__||t.call(e,i,n)},getLayers:function(){return this._layers},_updateLayerStatus:function(t){function e(t){a&&(a.__endIndex!==t&&(a.__dirty=!0),a.__endIndex=t)}if(this.eachBuiltinLayer(function(t){t.__dirty=t.__used=!1}),this._singleCanvas)for(var i=1;i<t.length;i++){var n=t[i];if(n.zlevel!==t[i-1].zlevel||n.incremental){this._needsManuallyCompositing=!0;break}}for(var a=null,r=0,i=0;i<t.length;i++){var o,n=t[i],s=n.zlevel;n.incremental?(o=this.getLayer(s+Yx,this._needsManuallyCompositing),o.incremental=!0,r=1):o=this.getLayer(s+(r>0?Ux:0),this._needsManuallyCompositing),o.__builtin__||fx("ZLevel "+s+" has been used by unkown layer "+o.id),o!==a&&(o.__used=!0,o.__startIndex!==i&&(o.__dirty=!0),o.__startIndex=i,o.__drawIndex=o.incremental?-1:i,e(i),a=o),n.__dirty&&(o.__dirty=!0,o.incremental&&o.__drawIndex<0&&(o.__drawIndex=i))}e(i),this.eachBuiltinLayer(function(t){!t.__used&&t.getElementCount()>0&&(t.__dirty=!0,t.__startIndex=t.__endIndex=t.__drawIndex=0),t.__dirty&&t.__drawIndex<0&&(t.__drawIndex=t.__startIndex)})},clear:function(){return this.eachBuiltinLayer(this._clearLayer),this},_clearLayer:function(t){t.clear()},configLayer:function(t,e){if(e){var i=this._layerConfig;i[t]?a(i[t],e,!0):i[t]=e;for(var n=0;n<this._zlevelList.length;n++){var r=this._zlevelList[n];if(r===t||r===t+Ux){var o=this._layers[r];a(o,i[t],!0)}}}},delLayer:function(t){var e=this._layers,i=this._zlevelList,n=e[t];n&&(n.dom.parentNode.removeChild(n.dom),delete e[t],i.splice(h(i,t),1))},resize:function(t,e){if(this._domRoot.style){var i=this._domRoot;i.style.display="none";var n=this._opts;if(null!=t&&(n.width=t),null!=e&&(n.height=e),t=this._getSize(0),e=this._getSize(1),i.style.display="",this._width!=t||e!=this._height){i.style.width=t+"px",i.style.height=e+"px";for(var a in this._layers)this._layers.hasOwnProperty(a)&&this._layers[a].resize(t,e);f(this._progressiveLayers,function(i){i.resize(t,e)}),this.refresh(!0)}this._width=t,this._height=e}else{if(null==t||null==e)return;this._width=t,this._height=e,this.getLayer(Xx).resize(t,e)}return this},clearLayer:function(t){var e=this._layers[t];e&&e.clear()},dispose:function(){this.root.innerHTML="",this.root=this.storage=this._domRoot=this._layers=null},getRenderedCanvas:function(t){if(t=t||{},this._singleCanvas&&!this._compositeManually)return this._layers[Xx].dom;var e=new Px("image",this,t.pixelRatio||this.dpr);if(e.initContext(),e.clearColor=t.backgroundColor,e.clear(),t.pixelRatio<=this.dpr){this.refresh();var i=e.dom.width,n=e.dom.height,a=e.ctx;this.eachLayer(function(t){t.__builtin__?a.drawImage(t.dom,0,0,i,n):t.renderToCanvas&&(e.ctx.save(),t.renderToCanvas(e.ctx),e.ctx.restore())})}else for(var r={},o=this.storage.getDisplayList(!0),s=0;s<o.length;s++){var l=o[s];this._doPaintEl(l,e,!0,r)}return e.dom},getWidth:function(){return this._width},getHeight:function(){return this._height},_getSize:function(t){var e=this._opts,i=["width","height"][t],n=["clientWidth","clientHeight"][t],a=["paddingLeft","paddingTop"][t],r=["paddingRight","paddingBottom"][t];if(null!=e[i]&&"auto"!==e[i])return parseFloat(e[i]);var o=this.root,s=document.defaultView.getComputedStyle(o);return(o[n]||sn(s[i])||sn(o.style[i]))-(sn(s[a])||0)-(sn(s[r])||0)|0},pathToImage:function(t,e){e=e||this.dpr;var i=document.createElement("canvas"),n=i.getContext("2d"),a=t.getBoundingRect(),r=t.style,o=r.shadowBlur*e,s=r.shadowOffsetX*e,l=r.shadowOffsetY*e,h=r.hasStroke()?r.lineWidth:0,u=Math.max(h/2,-s+o),c=Math.max(h/2,s+o),d=Math.max(h/2,-l+o),f=Math.max(h/2,l+o),p=a.width+u+c,g=a.height+d+f;i.width=p*e,i.height=g*e,n.scale(e,e),n.clearRect(0,0,p,g),n.dpr=e;var v={position:t.position,rotation:t.rotation,scale:t.scale};t.position=[u-a.x,d-a.y],t.rotation=0,t.scale=[1,1],t.updateTransform(),t&&t.brush(n);var m=on,y=new m({style:{x:0,y:0,image:i}});return null!=v.position&&(y.position=t.position=v.position),null!=v.rotation&&(y.rotation=t.rotation=v.rotation),null!=v.scale&&(y.scale=t.scale=v.scale),y}};var Jx="undefined"!=typeof window&&!!window.addEventListener,Qx=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,t_=Jx?function(t){t.preventDefault(),t.stopPropagation(),t.cancelBubble=!0}:function(t){t.returnValue=!1,t.cancelBubble=!0},e_=function(t){t=t||{},this.stage=t.stage||{},this.onframe=t.onframe||function(){},this._clips=[],this._running=!1,this._time,this._pausedTime,this._pauseStart,this._paused=!1,By.call(this)};e_.prototype={constructor:e_,addClip:function(t){this._clips.push(t)},addAnimator:function(t){t.animation=this;for(var e=t.getClips(),i=0;i<e.length;i++)this.addClip(e[i])},removeClip:function(t){var e=h(this._clips,t);e>=0&&this._clips.splice(e,1)},removeAnimator:function(t){for(var e=t.getClips(),i=0;i<e.length;i++)this.removeClip(e[i]);t.animation=null},_update:function(){for(var t=(new Date).getTime()-this._pausedTime,e=t-this._time,i=this._clips,n=i.length,a=[],r=[],o=0;n>o;o++){var s=i[o],l=s.step(t,e);l&&(a.push(l),r.push(s))}for(var o=0;n>o;)i[o]._needsRemove?(i[o]=i[n-1],i.pop(),n--):o++;n=a.length;for(var o=0;n>o;o++)r[o].fire(a[o]);this._time=t,this.onframe(e),this.trigger("frame",e),this.stage.update&&this.stage.update()},_startLoop:function(){function t(){e._running&&(Ox(t),!e._paused&&e._update())}var e=this;this._running=!0,Ox(t)},start:function(){this._time=(new Date).getTime(),this._pausedTime=0,this._startLoop()},stop:function(){this._running=!1},pause:function(){this._paused||(this._pauseStart=(new Date).getTime(),this._paused=!0)},resume:function(){this._paused&&(this._pausedTime+=(new Date).getTime()-this._pauseStart,this._paused=!1)},clear:function(){this._clips=[]},animate:function(t,e){e=e||{};var i=new lx(t,e.loop,e.getter,e.setter);return this.addAnimator(i),i}},c(e_,By);var i_=function(){this._track=[]};i_.prototype={constructor:i_,recognize:function(t,e,i){return this._doTrack(t,e,i),this._recognize(t)},clear:function(){return this._track.length=0,this},_doTrack:function(t,e,i){var n=t.touches;if(n){for(var a={points:[],touches:[],target:e,event:t},r=0,o=n.length;o>r;r++){var s=n[r],l=pn(i,s,{});a.points.push([l.zrX,l.zrY]),a.touches.push(s)}this._track.push(a)}},_recognize:function(t){for(var e in n_)if(n_.hasOwnProperty(e)){var i=n_[e](this._track,t);if(i)return i}}};var n_={pinch:function(t,e){var i=t.length;if(i){var n=(t[i-1]||{}).points,a=(t[i-2]||{}).points||n;if(a&&a.length>1&&n&&n.length>1){var r=_n(n)/_n(a);!isFinite(r)&&(r=1),e.pinchScale=r;var o=wn(n);return e.pinchX=o[0],e.pinchY=o[1],{type:"pinch",target:t[0].target,event:e}}}}},a_=300,r_=["click","dblclick","mousewheel","mouseout","mouseup","mousedown","mousemove","contextmenu"],o_=["touchstart","touchend","touchmove"],s_={pointerdown:1,pointerup:1,pointermove:1,pointerout:1},l_=p(r_,function(t){var e=t.replace("mouse","pointer");return s_[e]?e:t}),h_={mousemove:function(t){t=vn(this.dom,t),this.trigger("mousemove",t)},mouseout:function(t){t=vn(this.dom,t);var e=t.toElement||t.relatedTarget;if(e!=this.dom)for(;e&&9!=e.nodeType;){if(e===this.dom)return;e=e.parentNode}this.trigger("mouseout",t)},touchstart:function(t){t=vn(this.dom,t),t.zrByTouch=!0,this._lastTouchMoment=new Date,Mn(this,t,"start"),h_.mousemove.call(this,t),h_.mousedown.call(this,t),Sn(this)},touchmove:function(t){t=vn(this.dom,t),t.zrByTouch=!0,Mn(this,t,"change"),h_.mousemove.call(this,t),Sn(this)},touchend:function(t){t=vn(this.dom,t),t.zrByTouch=!0,Mn(this,t,"end"),h_.mouseup.call(this,t),+new Date-this._lastTouchMoment<a_&&h_.click.call(this,t),Sn(this)},pointerdown:function(t){h_.mousedown.call(this,t)},pointermove:function(t){In(t)||h_.mousemove.call(this,t)},pointerup:function(t){h_.mouseup.call(this,t)},pointerout:function(t){In(t)||h_.mouseout.call(this,t)}};f(["click","mousedown","mouseup","mousewheel","dblclick","contextmenu"],function(t){h_[t]=function(e){e=vn(this.dom,e),this.trigger(t,e)}});var u_=An.prototype;u_.dispose=function(){for(var t=r_.concat(o_),e=0;e<t.length;e++){var i=t[e];yn(this.dom,bn(i),this._handlers[i])}},u_.setCursor=function(t){this.dom.style&&(this.dom.style.cursor=t||"default")},c(An,By);var c_=!vy.canvasSupported,d_={canvas:Kx},f_={},p_="4.0.0",g_=function(t,e,i){i=i||{},this.dom=e,this.id=t;var n=this,a=new Mx,r=i.renderer;if(c_){if(!d_.vml)throw new Error("You need to require 'zrender/vml/vml' to support IE8");r="vml"}else r&&d_[r]||(r="canvas");var o=new d_[r](e,a,i,t);this.storage=a,this.painter=o;var s=vy.node||vy.worker?null:new An(o.getViewportRoot());this.handler=new Fy(a,o,s,o.root),this.animation=new e_({stage:{update:y(this.flush,this)}}),this.animation.start(),this._needsRefresh;var l=a.delFromStorage,h=a.addToStorage;a.delFromStorage=function(t){l.call(a,t),t&&t.removeSelfFromZr(n)},a.addToStorage=function(t){h.call(a,t),t.addSelfToZr(n)}};g_.prototype={constructor:g_,getId:function(){return this.id},add:function(t){this.storage.addRoot(t),this._needsRefresh=!0},remove:function(t){this.storage.delRoot(t),this._needsRefresh=!0},configLayer:function(t,e){this.painter.configLayer(t,e),this._needsRefresh=!0},refreshImmediately:function(){this._needsRefresh=!1,this.painter.refresh(),this._needsRefresh=!1},refresh:function(){this._needsRefresh=!0},flush:function(){this._needsRefresh&&this.refreshImmediately(),this._needsRefreshHover&&this.refreshHoverImmediately()},addHover:function(t,e){this.painter.addHover&&(this.painter.addHover(t,e),this.refreshHover())},removeHover:function(t){this.painter.removeHover&&(this.painter.removeHover(t),this.refreshHover())},clearHover:function(){this.painter.clearHover&&(this.painter.clearHover(),this.refreshHover())},refreshHover:function(){this._needsRefreshHover=!0},refreshHoverImmediately:function(){this._needsRefreshHover=!1,this.painter.refreshHover&&this.painter.refreshHover()},resize:function(t){t=t||{},this.painter.resize(t.width,t.height),this.handler.resize()},clearAnimation:function(){this.animation.clear()},getWidth:function(){return this.painter.getWidth()},getHeight:function(){return this.painter.getHeight()},pathToImage:function(t,e){return this.painter.pathToImage(t,e)},setCursorStyle:function(t){this.handler.setCursorStyle(t)},findHover:function(t,e){return this.handler.findHover(t,e)},on:function(t,e,i){this.handler.on(t,e,i)},off:function(t,e){this.handler.off(t,e)},trigger:function(t,e){this.handler.trigger(t,e)},clear:function(){this.storage.delRoot(),this.painter.clear()},dispose:function(){this.animation.stop(),this.clear(),this.storage.dispose(),this.painter.dispose(),this.handler.dispose(),this.animation=this.storage=this.painter=this.handler=null,Pn(this.id)}};var v_=(Object.freeze||Object)({version:p_,init:Cn,dispose:Dn,getInstance:Ln,registerPainter:kn}),m_=f,y_=M,x_=_,__="\x00-",w_=["fontStyle","fontWeight","fontSize","fontFamily","rich","tag","color","textBorderColor","textBorderWidth","width","height","lineHeight","align","verticalAlign","baseline","shadowColor","shadowBlur","shadowOffsetX","shadowOffsetY","textShadowColor","textShadowBlur","textShadowOffsetX","textShadowOffsetY","backgroundColor","borderColor","borderWidth","borderRadius","padding"],b_=0,M_=".",S_="___EC__COMPONENT__CONTAINER___",I_=0,T_=function(t){for(var e=0;e<t.length;e++)t[e][1]||(t[e][1]=t[e][0]);return function(e,i,n){for(var a={},r=0;r<t.length;r++){var o=t[r][1];if(!(i&&h(i,o)>=0||n&&h(n,o)<0)){var s=e.getShallow(o);null!=s&&(a[t[r][0]]=s)}}return a}},A_=T_([["lineWidth","width"],["stroke","color"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"]]),C_={getLineStyle:function(t){var e=A_(this,t),i=this.getLineDash(e.lineWidth);return i&&(e.lineDash=i),e},getLineDash:function(t){null==t&&(t=1);var e=this.get("type"),i=Math.max(t,2),n=4*t;return"solid"===e||null==e?null:"dashed"===e?[n,n]:[i,i]}},D_=T_([["fill","color"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["opacity"],["shadowColor"]]),L_={getAreaStyle:function(t,e){return D_(this,t,e)}},k_=Math.pow,P_=Math.sqrt,O_=1e-8,z_=1e-4,E_=P_(3),R_=1/3,N_=F(),B_=F(),V_=F(),G_=Math.min,F_=Math.max,W_=Math.sin,H_=Math.cos,Z_=2*Math.PI,j_=F(),X_=F(),U_=F(),Y_=[],q_=[],$_={M:1,L:2,C:3,Q:4,A:5,Z:6,R:7},K_=[],J_=[],Q_=[],tw=[],ew=Math.min,iw=Math.max,nw=Math.cos,aw=Math.sin,rw=Math.sqrt,ow=Math.abs,sw="undefined"!=typeof Float32Array,lw=function(t){this._saveData=!t,this._saveData&&(this.data=[]),this._ctx=null};lw.prototype={constructor:lw,_xi:0,_yi:0,_x0:0,_y0:0,_ux:0,_uy:0,_len:0,_lineDash:null,_dashOffset:0,_dashIdx:0,_dashSum:0,setScale:function(t,e){this._ux=ow(1/cx/t)||0,this._uy=ow(1/cx/e)||0},getContext:function(){return this._ctx},beginPath:function(t){return this._ctx=t,t&&t.beginPath(),t&&(this.dpr=t.dpr),this._saveData&&(this._len=0),this._lineDash&&(this._lineDash=null,this._dashOffset=0),this},moveTo:function(t,e){return this.addData($_.M,t,e),this._ctx&&this._ctx.moveTo(t,e),this._x0=t,this._y0=e,this._xi=t,this._yi=e,this},lineTo:function(t,e){var i=ow(t-this._xi)>this._ux||ow(e-this._yi)>this._uy||this._len<5;return this.addData($_.L,t,e),this._ctx&&i&&(this._needsDash()?this._dashedLineTo(t,e):this._ctx.lineTo(t,e)),i&&(this._xi=t,this._yi=e),this},bezierCurveTo:function(t,e,i,n,a,r){return this.addData($_.C,t,e,i,n,a,r),this._ctx&&(this._needsDash()?this._dashedBezierTo(t,e,i,n,a,r):this._ctx.bezierCurveTo(t,e,i,n,a,r)),this._xi=a,this._yi=r,this},quadraticCurveTo:function(t,e,i,n){return this.addData($_.Q,t,e,i,n),this._ctx&&(this._needsDash()?this._dashedQuadraticTo(t,e,i,n):this._ctx.quadraticCurveTo(t,e,i,n)),this._xi=i,this._yi=n,this},arc:function(t,e,i,n,a,r){return this.addData($_.A,t,e,i,i,n,a-n,0,r?0:1),this._ctx&&this._ctx.arc(t,e,i,n,a,r),this._xi=nw(a)*i+t,this._yi=aw(a)*i+t,this},arcTo:function(t,e,i,n,a){return this._ctx&&this._ctx.arcTo(t,e,i,n,a),this},rect:function(t,e,i,n){return this._ctx&&this._ctx.rect(t,e,i,n),this.addData($_.R,t,e,i,n),this},closePath:function(){this.addData($_.Z);var t=this._ctx,e=this._x0,i=this._y0;return t&&(this._needsDash()&&this._dashedLineTo(e,i),t.closePath()),this._xi=e,this._yi=i,this},fill:function(t){t&&t.fill(),this.toStatic()},stroke:function(t){t&&t.stroke(),this.toStatic()},setLineDash:function(t){if(t instanceof Array){this._lineDash=t,this._dashIdx=0;for(var e=0,i=0;i<t.length;i++)e+=t[i];this._dashSum=e}return this},setLineDashOffset:function(t){return this._dashOffset=t,this},len:function(){return this._len},setData:function(t){var e=t.length;this.data&&this.data.length==e||!sw||(this.data=new Float32Array(e));for(var i=0;e>i;i++)this.data[i]=t[i];this._len=e},appendPath:function(t){t instanceof Array||(t=[t]);for(var e=t.length,i=0,n=this._len,a=0;e>a;a++)i+=t[a].len();sw&&this.data instanceof Float32Array&&(this.data=new Float32Array(n+i));for(var a=0;e>a;a++)for(var r=t[a].data,o=0;o<r.length;o++)this.data[n++]=r[o];this._len=n},addData:function(t){if(this._saveData){var e=this.data;this._len+arguments.length>e.length&&(this._expandData(),e=this.data);for(var i=0;i<arguments.length;i++)e[this._len++]=arguments[i];this._prevCmd=t}},_expandData:function(){if(!(this.data instanceof Array)){for(var t=[],e=0;e<this._len;e++)t[e]=this.data[e];this.data=t}},_needsDash:function(){return this._lineDash},_dashedLineTo:function(t,e){var i,n,a=this._dashSum,r=this._dashOffset,o=this._lineDash,s=this._ctx,l=this._xi,h=this._yi,u=t-l,c=e-h,d=rw(u*u+c*c),f=l,p=h,g=o.length;for(u/=d,c/=d,0>r&&(r=a+r),r%=a,f-=r*u,p-=r*c;u>0&&t>=f||0>u&&f>=t||0==u&&(c>0&&e>=p||0>c&&p>=e);)n=this._dashIdx,i=o[n],f+=u*i,p+=c*i,this._dashIdx=(n+1)%g,u>0&&l>f||0>u&&f>l||c>0&&h>p||0>c&&p>h||s[n%2?"moveTo":"lineTo"](u>=0?ew(f,t):iw(f,t),c>=0?ew(p,e):iw(p,e));u=f-t,c=p-e,this._dashOffset=-rw(u*u+c*c)},_dashedBezierTo:function(t,e,i,n,a,r){var o,s,l,h,u,c=this._dashSum,d=this._dashOffset,f=this._lineDash,p=this._ctx,g=this._xi,v=this._yi,m=ia,y=0,x=this._dashIdx,_=f.length,w=0;for(0>d&&(d=c+d),d%=c,o=0;1>o;o+=.1)s=m(g,t,i,a,o+.1)-m(g,t,i,a,o),l=m(v,e,n,r,o+.1)-m(v,e,n,r,o),y+=rw(s*s+l*l);for(;_>x&&(w+=f[x],!(w>d));x++);for(o=(w-d)/y;1>=o;)h=m(g,t,i,a,o),u=m(v,e,n,r,o),x%2?p.moveTo(h,u):p.lineTo(h,u),o+=f[x]/y,x=(x+1)%_;x%2!==0&&p.lineTo(a,r),s=a-h,l=r-u,this._dashOffset=-rw(s*s+l*l)},_dashedQuadraticTo:function(t,e,i,n){var a=i,r=n;i=(i+2*t)/3,n=(n+2*e)/3,t=(this._xi+2*t)/3,e=(this._yi+2*e)/3,this._dashedBezierTo(t,e,i,n,a,r)},toStatic:function(){var t=this.data;t instanceof Array&&(t.length=this._len,sw&&(this.data=new Float32Array(t)))},getBoundingRect:function(){K_[0]=K_[1]=Q_[0]=Q_[1]=Number.MAX_VALUE,J_[0]=J_[1]=tw[0]=tw[1]=-Number.MAX_VALUE;for(var t=this.data,e=0,i=0,n=0,a=0,r=0;r<t.length;){var o=t[r++];switch(1==r&&(e=t[r],i=t[r+1],n=e,a=i),o){case $_.M:n=t[r++],a=t[r++],e=n,i=a,Q_[0]=n,Q_[1]=a,tw[0]=n,tw[1]=a;break;case $_.L:ga(e,i,t[r],t[r+1],Q_,tw),e=t[r++],i=t[r++];break;case $_.C:va(e,i,t[r++],t[r++],t[r++],t[r++],t[r],t[r+1],Q_,tw),e=t[r++],i=t[r++];break;case $_.Q:ma(e,i,t[r++],t[r++],t[r],t[r+1],Q_,tw),e=t[r++],i=t[r++];break;case $_.A:var s=t[r++],l=t[r++],h=t[r++],u=t[r++],c=t[r++],d=t[r++]+c,f=(t[r++],1-t[r++]);1==r&&(n=nw(c)*h+s,a=aw(c)*u+l),ya(s,l,h,u,c,d,f,Q_,tw),e=nw(d)*h+s,i=aw(d)*u+l;break;case $_.R:n=e=t[r++],a=i=t[r++];var p=t[r++],g=t[r++];ga(n,a,n+p,a+g,Q_,tw);break;case $_.Z:e=n,i=a}oe(K_,K_,Q_),se(J_,J_,tw)}return 0===r&&(K_[0]=K_[1]=J_[0]=J_[1]=0),new ni(K_[0],K_[1],J_[0]-K_[0],J_[1]-K_[1])},rebuildPath:function(t){for(var e,i,n,a,r,o,s=this.data,l=this._ux,h=this._uy,u=this._len,c=0;u>c;){var d=s[c++];switch(1==c&&(n=s[c],a=s[c+1],e=n,i=a),d){case $_.M:e=n=s[c++],i=a=s[c++],t.moveTo(n,a);break;case $_.L:r=s[c++],o=s[c++],(ow(r-n)>l||ow(o-a)>h||c===u-1)&&(t.lineTo(r,o),n=r,a=o);break;case $_.C:t.bezierCurveTo(s[c++],s[c++],s[c++],s[c++],s[c++],s[c++]),n=s[c-2],a=s[c-1];break;case $_.Q:t.quadraticCurveTo(s[c++],s[c++],s[c++],s[c++]),n=s[c-2],a=s[c-1];break;case $_.A:var f=s[c++],p=s[c++],g=s[c++],v=s[c++],m=s[c++],y=s[c++],x=s[c++],_=s[c++],w=g>v?g:v,b=g>v?1:g/v,M=g>v?v/g:1,S=Math.abs(g-v)>.001,I=m+y;S?(t.translate(f,p),t.rotate(x),t.scale(b,M),t.arc(0,0,w,m,I,1-_),t.scale(1/b,1/M),t.rotate(-x),t.translate(-f,-p)):t.arc(f,p,w,m,I,1-_),1==c&&(e=nw(m)*g+f,i=aw(m)*v+p),n=nw(I)*g+f,a=aw(I)*v+p;break;case $_.R:e=n=s[c],i=a=s[c+1],t.rect(s[c++],s[c++],s[c++],s[c++]);break;case $_.Z:t.closePath(),n=e,a=i}}}},lw.CMD=$_;var hw=2*Math.PI,uw=2*Math.PI,cw=lw.CMD,dw=2*Math.PI,fw=1e-4,pw=[-1,-1,-1],gw=[-1,-1],vw=kx.prototype.getCanvasPattern,mw=Math.abs,yw=new lw(!0);Oa.prototype={constructor:Oa,type:"path",__dirtyPath:!0,strokeContainThreshold:5,brush:function(t,e){var i=this.style,n=this.path||yw,a=i.hasStroke(),r=i.hasFill(),o=i.fill,s=i.stroke,l=r&&!!o.colorStops,h=a&&!!s.colorStops,u=r&&!!o.image,c=a&&!!s.image;if(i.bind(t,this,e),this.setTransform(t),this.__dirty){var d;l&&(d=d||this.getBoundingRect(),this._fillGradient=i.getGradient(t,o,d)),h&&(d=d||this.getBoundingRect(),this._strokeGradient=i.getGradient(t,s,d))}l?t.fillStyle=this._fillGradient:u&&(t.fillStyle=vw.call(o,t)),h?t.strokeStyle=this._strokeGradient:c&&(t.strokeStyle=vw.call(s,t));var f=i.lineDash,p=i.lineDashOffset,g=!!t.setLineDash,v=this.getGlobalScale();n.setScale(v[0],v[1]),this.__dirtyPath||f&&!g&&a?(n.beginPath(t),f&&!g&&(n.setLineDash(f),n.setLineDashOffset(p)),this.buildPath(n,this.shape,!1),this.path&&(this.__dirtyPath=!1)):(t.beginPath(),this.path.rebuildPath(t)),r&&n.fill(t),f&&g&&(t.setLineDash(f),t.lineDashOffset=p),a&&n.stroke(t),f&&g&&t.setLineDash([]),null!=i.text&&(this.restoreTransform(t),this.drawRectText(t,this.getBoundingRect()))},buildPath:function(){},createPathProxy:function(){this.path=new lw},getBoundingRect:function(){var t=this._rect,e=this.style,i=!t;if(i){var n=this.path;n||(n=this.path=new lw),this.__dirtyPath&&(n.beginPath(),this.buildPath(n,this.shape,!1)),t=n.getBoundingRect()}if(this._rect=t,e.hasStroke()){var a=this._rectWithStroke||(this._rectWithStroke=t.clone());if(this.__dirty||i){a.copy(t);var r=e.lineWidth,o=e.strokeNoScale?this.getLineScale():1;e.hasFill()||(r=Math.max(r,this.strokeContainThreshold||4)),o>1e-10&&(a.width+=r/o,a.height+=r/o,a.x-=r/o/2,a.y-=r/o/2)}return a}return t},contain:function(t,e){var i=this.transformCoordToLocal(t,e),n=this.getBoundingRect(),a=this.style;if(t=i[0],e=i[1],n.contain(t,e)){var r=this.path.data;if(a.hasStroke()){var o=a.lineWidth,s=a.strokeNoScale?this.getLineScale():1;if(s>1e-10&&(a.hasFill()||(o=Math.max(o,this.strokeContainThreshold)),Pa(r,o/s,t,e)))return!0}if(a.hasFill())return ka(r,t,e)}return!1},dirty:function(t){null==t&&(t=!0),t&&(this.__dirtyPath=t,this._rect=null),this.__dirty=!0,this.__zr&&this.__zr.refresh(),this.__clipTarget&&this.__clipTarget.dirty()},animateShape:function(t){return this.animate("shape",t)},attrKV:function(t,e){"shape"===t?(this.setShape(e),this.__dirtyPath=!0,this._rect=null):rn.prototype.attrKV.call(this,t,e)},setShape:function(t,e){var i=this.shape;if(i){if(M(t))for(var n in t)t.hasOwnProperty(n)&&(i[n]=t[n]);else i[t]=e;this.dirty(!0)}return this},getLineScale:function(){var t=this.transform;return t&&mw(t[0]-1)>1e-10&&mw(t[3]-1)>1e-10?Math.sqrt(mw(t[0]*t[3]-t[2]*t[1])):1}},Oa.extend=function(t){var e=function(e){Oa.call(this,e),t.style&&this.style.extendFrom(t.style,!1);var i=t.shape;if(i){this.shape=this.shape||{};var n=this.shape;for(var a in i)!n.hasOwnProperty(a)&&i.hasOwnProperty(a)&&(n[a]=i[a])}t.init&&t.init.call(this,e)};u(e,Oa);for(var i in t)"style"!==i&&"shape"!==i&&(e.prototype[i]=t[i]);return e},u(Oa,rn);var xw=lw.CMD,_w=[[],[],[]],ww=Math.sqrt,bw=Math.atan2,Mw=function(t,e){var i,n,a,r,o,s,l=t.data,h=xw.M,u=xw.C,c=xw.L,d=xw.R,f=xw.A,p=xw.Q;for(a=0,r=0;a<l.length;){switch(i=l[a++],r=a,n=0,i){case h:n=1;break;case c:n=1;break;case u:n=3;break;case p:n=2;break;case f:var g=e[4],v=e[5],m=ww(e[0]*e[0]+e[1]*e[1]),y=ww(e[2]*e[2]+e[3]*e[3]),x=bw(-e[1]/y,e[0]/m);l[a]*=m,l[a++]+=g,l[a]*=y,l[a++]+=v,l[a++]*=m,l[a++]*=y,l[a++]+=x,l[a++]+=x,a+=2,r=a;break;case d:s[0]=l[a++],s[1]=l[a++],re(s,s,e),l[r++]=s[0],l[r++]=s[1],s[0]+=l[a++],s[1]+=l[a++],re(s,s,e),l[r++]=s[0],l[r++]=s[1]}for(o=0;n>o;o++){var s=_w[o];s[0]=l[a++],s[1]=l[a++],re(s,s,e),l[r++]=s[0],l[r++]=s[1]}}},Sw=["m","M","l","L","v","V","h","H","z","Z","c","C","q","Q","t","T","s","S","a","A"],Iw=Math.sqrt,Tw=Math.sin,Aw=Math.cos,Cw=Math.PI,Dw=function(t){return Math.sqrt(t[0]*t[0]+t[1]*t[1])},Lw=function(t,e){return(t[0]*e[0]+t[1]*e[1])/(Dw(t)*Dw(e))},kw=function(t,e){return(t[0]*e[1]<t[1]*e[0]?-1:1)*Math.acos(Lw(t,e))},Pw=function(t){rn.call(this,t)};Pw.prototype={constructor:Pw,type:"text",brush:function(t,e){var i=this.style;this.__dirty&&Gi(i,!0),i.fill=i.stroke=i.shadowBlur=i.shadowColor=i.shadowOffsetX=i.shadowOffsetY=null;var n=i.text;null!=n&&(n+=""),i.bind(t,this,e),an(n,i)&&(this.setTransform(t),Wi(this,t,n,i),this.restoreTransform(t))},getBoundingRect:function(){var t=this.style;if(this.__dirty&&Gi(t,!0),!this._rect){var e=t.text;null!=e?e+="":e="";var i=Mi(t.text+"",t.font,t.textAlign,t.textVerticalAlign,t.textPadding,t.rich);if(i.x+=t.x||0,i.y+=t.y||0,Qi(t.textStroke,t.textStrokeWidth)){var n=t.textStrokeWidth;i.x-=n/2,i.y-=n/2,i.width+=n,i.height+=n}this._rect=i}return this._rect}},u(Pw,rn);var Ow=Oa.extend({type:"circle",shape:{cx:0,cy:0,r:0},buildPath:function(t,e,i){i&&t.moveTo(e.cx+e.r,e.cy),t.arc(e.cx,e.cy,e.r,0,2*Math.PI,!0)}}),zw=[["shadowBlur",0],["shadowColor","#000"],["shadowOffsetX",0],["shadowOffsetY",0]],Ew=function(t){return vy.browser.ie&&vy.browser.version>=11?function(){var e,i=this.__clipPaths,n=this.style;if(i)for(var a=0;a<i.length;a++){var r=i[a],o=r&&r.shape,s=r&&r.type;if(o&&("sector"===s&&o.startAngle===o.endAngle||"rect"===s&&(!o.width||!o.height))){for(var l=0;l<zw.length;l++)zw[l][2]=n[zw[l][0]],n[zw[l][0]]=zw[l][1];e=!0;break}}if(t.apply(this,arguments),e)for(var l=0;l<zw.length;l++)n[zw[l][0]]=zw[l][2]}:t},Rw=Oa.extend({type:"sector",shape:{cx:0,cy:0,r0:0,r:0,startAngle:0,endAngle:2*Math.PI,clockwise:!0},brush:Ew(Oa.prototype.brush),buildPath:function(t,e){var i=e.cx,n=e.cy,a=Math.max(e.r0||0,0),r=Math.max(e.r,0),o=e.startAngle,s=e.endAngle,l=e.clockwise,h=Math.cos(o),u=Math.sin(o);t.moveTo(h*a+i,u*a+n),t.lineTo(h*r+i,u*r+n),t.arc(i,n,r,o,s,!l),t.lineTo(Math.cos(s)*a+i,Math.sin(s)*a+n),0!==a&&t.arc(i,n,a,s,o,l),t.closePath()}}),Nw=Oa.extend({type:"ring",shape:{cx:0,cy:0,r:0,r0:0},buildPath:function(t,e){var i=e.cx,n=e.cy,a=2*Math.PI;t.moveTo(i+e.r,n),t.arc(i,n,e.r,0,a,!1),t.moveTo(i+e.r0,n),t.arc(i,n,e.r0,0,a,!0)}}),Bw=function(t,e){for(var i=t.length,n=[],a=0,r=1;i>r;r++)a+=ee(t[r-1],t[r]);var o=a/2;o=i>o?i:o;for(var r=0;o>r;r++){var s,l,h,u=r/(o-1)*(e?i:i-1),c=Math.floor(u),d=u-c,f=t[c%i];e?(s=t[(c-1+i)%i],l=t[(c+1)%i],h=t[(c+2)%i]):(s=t[0===c?c:c-1],l=t[c>i-2?i-1:c+1],h=t[c>i-3?i-1:c+2]);var p=d*d,g=d*p;n.push([Ga(s[0],f[0],l[0],h[0],d,p,g),Ga(s[1],f[1],l[1],h[1],d,p,g)])}return n},Vw=function(t,e,i,n){var a,r,o,s,l=[],h=[],u=[],c=[];if(n){o=[1/0,1/0],s=[-1/0,-1/0];for(var d=0,f=t.length;f>d;d++)oe(o,o,t[d]),se(s,s,t[d]);oe(o,o,n[0]),se(s,s,n[1])}for(var d=0,f=t.length;f>d;d++){var p=t[d];if(i)a=t[d?d-1:f-1],r=t[(d+1)%f];else{if(0===d||d===f-1){l.push(H(t[d]));continue}a=t[d-1],r=t[d+1]}U(h,r,a),Q(h,h,e);var g=ee(p,a),v=ee(p,r),m=g+v;0!==m&&(g/=m,v/=m),Q(u,h,-g),Q(c,h,v);var y=j([],p,u),x=j([],p,c);n&&(se(y,y,o),oe(y,y,s),se(x,x,o),oe(x,x,s)),l.push(y),l.push(x)}return i&&l.push(l.shift()),l},Gw=Oa.extend({type:"polygon",shape:{points:null,smooth:!1,smoothConstraint:null},buildPath:function(t,e){Fa(t,e,!0)}}),Fw=Oa.extend({type:"polyline",shape:{points:null,smooth:!1,smoothConstraint:null},style:{stroke:"#000",fill:null},buildPath:function(t,e){Fa(t,e,!1)}}),Ww=Oa.extend({type:"rect",shape:{r:0,x:0,y:0,width:0,height:0},buildPath:function(t,e){var i=e.x,n=e.y,a=e.width,r=e.height;e.r?Vi(t,e):t.rect(i,n,a,r),t.closePath()}}),Hw=Oa.extend({type:"line",shape:{x1:0,y1:0,x2:0,y2:0,percent:1},style:{stroke:"#000",fill:null},buildPath:function(t,e){var i=e.x1,n=e.y1,a=e.x2,r=e.y2,o=e.percent;0!==o&&(t.moveTo(i,n),1>o&&(a=i*(1-o)+a*o,r=n*(1-o)+r*o),t.lineTo(a,r))},pointAt:function(t){var e=this.shape;return[e.x1*(1-t)+e.x2*t,e.y1*(1-t)+e.y2*t]}}),Zw=[],jw=Oa.extend({type:"bezier-curve",shape:{x1:0,y1:0,x2:0,y2:0,cpx1:0,cpy1:0,percent:1},style:{stroke:"#000",fill:null},buildPath:function(t,e){var i=e.x1,n=e.y1,a=e.x2,r=e.y2,o=e.cpx1,s=e.cpy1,l=e.cpx2,h=e.cpy2,u=e.percent;0!==u&&(t.moveTo(i,n),null==l||null==h?(1>u&&(da(i,o,a,u,Zw),o=Zw[1],a=Zw[2],da(n,s,r,u,Zw),s=Zw[1],r=Zw[2]),t.quadraticCurveTo(o,s,a,r)):(1>u&&(oa(i,o,l,a,u,Zw),o=Zw[1],l=Zw[2],a=Zw[3],oa(n,s,h,r,u,Zw),s=Zw[1],h=Zw[2],r=Zw[3]),t.bezierCurveTo(o,s,l,h,a,r)))},pointAt:function(t){return Wa(this.shape,t,!1)},tangentAt:function(t){var e=Wa(this.shape,t,!0);return te(e,e)}}),Xw=Oa.extend({type:"arc",shape:{cx:0,cy:0,r:0,startAngle:0,endAngle:2*Math.PI,clockwise:!0},style:{stroke:"#000",fill:null},buildPath:function(t,e){var i=e.cx,n=e.cy,a=Math.max(e.r,0),r=e.startAngle,o=e.endAngle,s=e.clockwise,l=Math.cos(r),h=Math.sin(r);t.moveTo(l*a+i,h*a+n),t.arc(i,n,a,r,o,!s)}}),Uw=Oa.extend({type:"compound",shape:{paths:null},_updatePathDirty:function(){for(var t=this.__dirtyPath,e=this.shape.paths,i=0;i<e.length;i++)t=t||e[i].__dirtyPath;this.__dirtyPath=t,this.__dirty=this.__dirty||t},beforeBrush:function(){this._updatePathDirty();for(var t=this.shape.paths||[],e=this.getGlobalScale(),i=0;i<t.length;i++)t[i].path||t[i].createPathProxy(),t[i].path.setScale(e[0],e[1])},buildPath:function(t,e){for(var i=e.paths||[],n=0;n<i.length;n++)i[n].buildPath(t,i[n].shape,!0)},afterBrush:function(){for(var t=this.shape.paths||[],e=0;e<t.length;e++)t[e].__dirtyPath=!1},getBoundingRect:function(){return this._updatePathDirty(),Oa.prototype.getBoundingRect.call(this)}}),Yw=function(t){this.colorStops=t||[]};Yw.prototype={constructor:Yw,addColorStop:function(t,e){this.colorStops.push({offset:t,color:e})}};var qw=function(t,e,i,n,a,r){this.x=null==t?0:t,this.y=null==e?0:e,this.x2=null==i?1:i,this.y2=null==n?0:n,this.type="linear",this.global=r||!1,Yw.call(this,a)};qw.prototype={constructor:qw},u(qw,Yw);
-var $w=function(t,e,i,n,a){this.x=null==t?.5:t,this.y=null==e?.5:e,this.r=null==i?.5:i,this.type="radial",this.global=a||!1,Yw.call(this,n)};$w.prototype={constructor:$w},u($w,Yw),Ha.prototype.incremental=!0,Ha.prototype.clearDisplaybles=function(){this._displayables=[],this._temporaryDisplayables=[],this._cursor=0,this.dirty(),this.notClear=!1},Ha.prototype.addDisplayable=function(t,e){e?this._temporaryDisplayables.push(t):this._displayables.push(t),this.dirty()},Ha.prototype.addDisplayables=function(t,e){e=e||!1;for(var i=0;i<t.length;i++)this.addDisplayable(t[i],e)},Ha.prototype.eachPendingDisplayable=function(t){for(var e=this._cursor;e<this._displayables.length;e++)t&&t(this._displayables[e]);for(var e=0;e<this._temporaryDisplayables.length;e++)t&&t(this._temporaryDisplayables[e])},Ha.prototype.update=function(){this.updateTransform();for(var t=this._cursor;t<this._displayables.length;t++){var e=this._displayables[t];e.parent=this,e.update(),e.parent=null}for(var t=0;t<this._temporaryDisplayables.length;t++){var e=this._temporaryDisplayables[t];e.parent=this,e.update(),e.parent=null}},Ha.prototype.brush=function(t){for(var e=this._cursor;e<this._displayables.length;e++){var i=this._temporaryDisplayables[e];i.beforeBrush&&i.beforeBrush(t),i.brush(t,e===this._cursor?null:this._displayables[e-1]),i.afterBrush&&i.afterBrush(t)}this._cursor=e;for(var e=0;e<this._temporaryDisplayables.length;e++){var i=this._temporaryDisplayables[e];i.beforeBrush&&i.beforeBrush(t),i.brush(t,0===e?null:this._temporaryDisplayables[e-1]),i.afterBrush&&i.afterBrush(t)}this._temporaryDisplayables=[],this.notClear=!0};var Kw=[];Ha.prototype.getBoundingRect=function(){if(!this._rect){for(var t=new ni(1/0,1/0,-1/0,-1/0),e=0;e<this._displayables.length;e++){var i=this._displayables[e],n=i.getBoundingRect().clone();i.needLocalTransform()&&n.applyTransform(i.getLocalTransform(Kw)),t.union(n)}this._rect=t}return this._rect},Ha.prototype.contain=function(t,e){var i=this.transformCoordToLocal(t,e),n=this.getBoundingRect();if(n.contain(i[0],i[1]))for(var a=0;a<this._displayables.length;a++){var r=this._displayables[a];if(r.contain(t,e))return!0}return!1},u(Ha,rn);var Jw=Math.round,Qw=Math.max,tb=Math.min,eb={},ib=Va,nb=(Object.freeze||Object)({extendShape:Za,extendPath:ja,makePath:Xa,makeImage:Ua,mergePath:ib,resizePath:qa,subPixelOptimizeLine:$a,subPixelOptimizeRect:Ka,subPixelOptimize:Ja,setHoverStyle:cr,setLabelStyle:dr,setTextStyle:fr,setText:pr,getFont:wr,updateProps:Mr,initProps:Sr,getTransform:Ir,applyTransform:Tr,transformDirection:Ar,groupTransition:Cr,clipPointsByRect:Dr,clipRectByRect:Lr,createIcon:kr,Group:xx,Image:on,Text:Pw,Circle:Ow,Sector:Rw,Ring:Nw,Polygon:Gw,Polyline:Fw,Rect:Ww,Line:Hw,BezierCurve:jw,Arc:Xw,IncrementalDisplayable:Ha,CompoundPath:Uw,LinearGradient:qw,RadialGradient:$w,BoundingRect:ni}),ab=["textStyle","color"],rb={getTextColor:function(t){var e=this.ecModel;return this.getShallow("color")||(!t&&e?e.get(ab):null)},getFont:function(){return wr({fontStyle:this.getShallow("fontStyle"),fontWeight:this.getShallow("fontWeight"),fontSize:this.getShallow("fontSize"),fontFamily:this.getShallow("fontFamily")},this.ecModel)},getTextRect:function(t){return Mi(t,this.getFont(),this.getShallow("align"),this.getShallow("verticalAlign")||this.getShallow("baseline"),this.getShallow("padding"),this.getShallow("rich"),this.getShallow("truncateText"))}},ob=T_([["fill","color"],["stroke","borderColor"],["lineWidth","borderWidth"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"],["textPosition"],["textAlign"]]),sb={getItemStyle:function(t,e){var i=ob(this,t,e),n=this.getBorderLineDash();return n&&(i.lineDash=n),i},getBorderLineDash:function(){var t=this.get("borderType");return"solid"===t||null==t?null:"dashed"===t?[5,5]:[1,1]}},lb=c,hb=Wn();Pr.prototype={constructor:Pr,init:null,mergeOption:function(t){a(this.option,t,!0)},get:function(t,e){return null==t?this.option:Or(this.option,this.parsePath(t),!e&&zr(this,t))},getShallow:function(t,e){var i=this.option,n=null==i?i:i[t],a=!e&&zr(this,t);return null==n&&a&&(n=a.getShallow(t)),n},getModel:function(t,e){var i,n=null==t?this.option:Or(this.option,t=this.parsePath(t));return e=e||(i=zr(this,t))&&i.getModel(t),new Pr(n,e,this.ecModel)},isEmpty:function(){return null==this.option},restoreData:function(){},clone:function(){var t=this.constructor;return new t(n(this.option))},setReadOnly:function(){},parsePath:function(t){return"string"==typeof t&&(t=t.split(".")),t},customizeGetParent:function(t){hb(this).getParent=t},isAnimationEnabled:function(){if(!vy.node){if(null!=this.option.animation)return!!this.option.animation;if(this.parentModel)return this.parentModel.isAnimationEnabled()}}},qn(Pr),$n(Pr),lb(Pr,C_),lb(Pr,L_),lb(Pr,rb),lb(Pr,sb);var ub=0,cb=1e-4,db=9007199254740991,fb=/^(?:(\d{4})(?:[-\/](\d{1,2})(?:[-\/](\d{1,2})(?:[T ](\d{1,2})(?::(\d\d)(?::(\d\d)(?:[.,](\d+))?)?)?(Z|[\+\-]\d\d:?\d\d)?)?)?)?)?$/,pb=(Object.freeze||Object)({linearMap:Vr,parsePercent:Gr,round:Fr,asc:Wr,getPrecision:Hr,getPrecisionSafe:Zr,getPixelPrecision:jr,getPercentWithPrecision:Xr,MAX_SAFE_INTEGER:db,remRadian:Ur,isRadianAroundZero:Yr,parseDate:qr,quantity:$r,nice:Jr,reformIntervals:Qr,isNumeric:to}),gb=P,vb=["a","b","c","d","e","f","g"],mb=function(t,e){return"{"+t+(null==e?"":e)+"}"},yb=function(t){return 10>t?"0"+t:t},xb=Di,_b=Mi,wb=(Object.freeze||Object)({addCommas:eo,toCamelCase:io,normalizeCssArray:gb,encodeHTML:no,formatTpl:ao,formatTplSimple:ro,getTooltipMarker:oo,formatTime:so,capitalFirst:lo,truncateText:xb,getTextRect:_b}),bb=f,Mb=["left","right","top","bottom","width","height"],Sb=[["width","left","right"],["height","top","bottom"]],Ib=ho,Tb=(x(ho,"vertical"),x(ho,"horizontal"),{getBoxLayoutParams:function(){return{left:this.get("left"),top:this.get("top"),right:this.get("right"),bottom:this.get("bottom"),width:this.get("width"),height:this.get("height")}}}),Ab=Wn(),Cb=Pr.extend({type:"component",id:"",name:"",mainType:"",subType:"",componentIndex:0,defaultOption:null,ecModel:null,dependentModels:[],uid:null,layoutMode:null,$constructor:function(t,e,i,n){Pr.call(this,t,e,i,n),this.uid=Er("ec_cpt_model")},init:function(t,e,i){this.mergeDefaultAndTheme(t,i)},mergeDefaultAndTheme:function(t,e){var i=this.layoutMode,n=i?go(t):{},r=e.getTheme();a(t,r.get(this.mainType)),a(t,this.getDefaultOption()),i&&po(t,n,i)},mergeOption:function(t){a(this.option,t,!0);var e=this.layoutMode;e&&po(this.option,t,e)},optionUpdated:function(){},getDefaultOption:function(){var t=Ab(this);if(!t.defaultOption){for(var e=[],i=this.constructor;i;){var n=i.prototype.defaultOption;n&&e.push(n),i=i.superClass}for(var r={},o=e.length-1;o>=0;o--)r=a(r,e[o],!0);t.defaultOption=r}return t.defaultOption},getReferringComponents:function(t){return this.ecModel.queryComponents({mainType:t,index:this.get(t+"Index",!0),id:this.get(t+"Id",!0)})}});Qn(Cb,{registerWhenExtend:!0}),Rr(Cb),Nr(Cb,mo),c(Cb,Tb);var Db="";"undefined"!=typeof navigator&&(Db=navigator.platform||"");var Lb={color:["#c23531","#2f4554","#61a0a8","#d48265","#91c7ae","#749f83","#ca8622","#bda29a","#6e7074","#546570","#c4ccd3"],gradientColor:["#f6efa6","#d88273","#bf444c"],textStyle:{fontFamily:Db.match(/^Win/)?"Microsoft YaHei":"sans-serif",fontSize:12,fontStyle:"normal",fontWeight:"normal"},blendMode:null,animation:"auto",animationDuration:1e3,animationDurationUpdate:300,animationEasing:"exponentialOut",animationEasingUpdate:"cubicOut",animationThreshold:2e3,progressiveThreshold:3e3,progressive:400,hoverLayerThreshold:3e3,useUTC:!1},kb=Wn(),Pb={clearColorPalette:function(){kb(this).colorIdx=0,kb(this).colorNameMap={}},getColorFromPalette:function(t,e,i){e=e||this;var n=kb(e),a=n.colorIdx||0,r=n.colorNameMap=n.colorNameMap||{};if(r.hasOwnProperty(t))return r[t];var o=On(this.get("color",!0)),s=this.get("colorLayer",!0),l=null!=i&&s?yo(s,i):o;if(l=l||o,l&&l.length){var h=l[a];return t&&(r[t]=h),n.colorIdx=(a+1)%l.length,h}}},Ob={cartesian2d:function(t,e,i,n){var a=t.getReferringComponents("xAxis")[0],r=t.getReferringComponents("yAxis")[0];e.coordSysDims=["x","y"],i.set("x",a),i.set("y",r),_o(a)&&(n.set("x",a),e.firstCategoryDimIndex=0),_o(r)&&(n.set("y",r),e.firstCategoryDimIndex=1)},singleAxis:function(t,e,i,n){var a=t.getReferringComponents("singleAxis")[0];e.coordSysDims=["single"],i.set("single",a),_o(a)&&(n.set("single",a),e.firstCategoryDimIndex=0)},polar:function(t,e,i,n){var a=t.getReferringComponents("polar")[0],r=a.findAxisModel("radiusAxis"),o=a.findAxisModel("angleAxis");e.coordSysDims=["radius","angle"],i.set("radius",r),i.set("angle",o),_o(r)&&(n.set("radius",r),e.firstCategoryDimIndex=0),_o(o)&&(n.set("angle",o),e.firstCategoryDimIndex=1)},geo:function(t,e){e.coordSysDims=["lng","lat"]},parallel:function(t,e,i,n){var a=t.ecModel,r=a.getComponent("parallel",t.get("parallelIndex")),o=e.coordSysDims=r.dimensions.slice();f(r.parallelAxisIndex,function(t,r){var s=a.getComponent("parallelAxis",t),l=o[r];i.set(l,s),_o(s)&&null==e.firstCategoryDimIndex&&(n.set(l,s),e.firstCategoryDimIndex=r)})}},zb="original",Eb="arrayRows",Rb="objectRows",Nb="keyedColumns",Bb="unknown",Vb="typedArray",Gb="column",Fb="row";wo.seriesDataToSource=function(t){return new wo({data:t,sourceFormat:I(t)?Vb:zb,fromDataset:!1})},$n(wo);var Wb=Wn(),Hb="\x00_ec_inner",Zb=Pr.extend({constructor:Zb,init:function(t,e,i,n){i=i||{},this.option=null,this._theme=new Pr(i),this._optionManager=n},setOption:function(t,e){O(!(Hb in t),"please use chart.getOption()"),this._optionManager.setOption(t,e),this.resetOption(null)},resetOption:function(t){var e=!1,i=this._optionManager;if(!t||"recreate"===t){var n=i.mountOption("recreate"===t);this.option&&"recreate"!==t?(this.restoreData(),this.mergeOption(n)):Eo.call(this,n),e=!0}if(("timeline"===t||"media"===t)&&this.restoreData(),!t||"recreate"===t||"timeline"===t){var a=i.getTimelineOption(this);a&&(this.mergeOption(a),e=!0)}if(!t||"recreate"===t||"media"===t){var r=i.getMediaOption(this,this._api);r.length&&f(r,function(t){this.mergeOption(t,e=!0)},this)}return e},mergeOption:function(t){function e(e,n){var a=On(t[e]),s=Nn(r.get(e),a);Bn(s),f(s,function(t){var i=t.option;M(i)&&(t.keyInfo.mainType=e,t.keyInfo.subType=No(e,i,t.exist))});var l=Ro(r,n);i[e]=[],r.set(e,[]),f(s,function(t,n){var a=t.exist,s=t.option;if(O(M(s)||a,"Empty component definition"),s){var h=Cb.getClass(e,t.keyInfo.subType,!0);if(a&&a instanceof h)a.name=t.keyInfo.name,a.mergeOption(s,this),a.optionUpdated(s,!1);else{var u=o({dependentModels:l,componentIndex:n},t.keyInfo);a=new h(s,this,this,u),o(a,u),a.init(s,this,this,u),a.optionUpdated(null,!0)}}else a.mergeOption({},this),a.optionUpdated({},!1);r.get(e)[n]=a,i[e][n]=a.option},this),"series"===e&&Bo(this,r.get("series"))}var i=this.option,r=this._componentsMap,s=[];Mo(this),f(t,function(t,e){null!=t&&(Cb.hasClass(e)?e&&s.push(e):i[e]=null==i[e]?n(t):a(i[e],t,!0))}),Cb.topologicalTravel(s,Cb.getAllClassMainTypes(),e,this),this._seriesIndicesMap=B(this._seriesIndices=this._seriesIndices||[])},getOption:function(){var t=n(this.option);return f(t,function(e,i){if(Cb.hasClass(i)){for(var e=On(e),n=e.length-1;n>=0;n--)Vn(e[n])&&e.splice(n,1);t[i]=e}}),delete t[Hb],t},getTheme:function(){return this._theme},getComponent:function(t,e){var i=this._componentsMap.get(t);return i?i[e||0]:void 0},queryComponents:function(t){var e=t.mainType;if(!e)return[];var i=t.index,n=t.id,a=t.name,r=this._componentsMap.get(e);if(!r||!r.length)return[];var o;if(null!=i)_(i)||(i=[i]),o=v(p(i,function(t){return r[t]}),function(t){return!!t});else if(null!=n){var s=_(n);o=v(r,function(t){return s&&h(n,t.id)>=0||!s&&t.id===n})}else if(null!=a){var l=_(a);o=v(r,function(t){return l&&h(a,t.name)>=0||!l&&t.name===a})}else o=r.slice();return Vo(o,t)},findComponents:function(t){function e(t){var e=a+"Index",i=a+"Id",n=a+"Name";return!t||null==t[e]&&null==t[i]&&null==t[n]?null:{mainType:a,index:t[e],id:t[i],name:t[n]}}function i(e){return t.filter?v(e,t.filter):e}var n=t.query,a=t.mainType,r=e(n),o=r?this.queryComponents(r):this._componentsMap.get(a);return i(Vo(o,t))},eachComponent:function(t,e,i){var n=this._componentsMap;if("function"==typeof t)i=e,e=t,n.each(function(t,n){f(t,function(t,a){e.call(i,n,t,a)})});else if(b(t))f(n.get(t),e,i);else if(M(t)){var a=this.findComponents(t);f(a,e,i)}},getSeriesByName:function(t){var e=this._componentsMap.get("series");return v(e,function(e){return e.name===t})},getSeriesByIndex:function(t){return this._componentsMap.get("series")[t]},getSeriesByType:function(t){var e=this._componentsMap.get("series");return v(e,function(e){return e.subType===t})},getSeries:function(){return this._componentsMap.get("series").slice()},getSeriesCount:function(){return this._componentsMap.get("series").length},eachSeries:function(t,e){f(this._seriesIndices,function(i){var n=this._componentsMap.get("series")[i];t.call(e,n,i)},this)},eachRawSeries:function(t,e){f(this._componentsMap.get("series"),t,e)},eachSeriesByType:function(t,e,i){f(this._seriesIndices,function(n){var a=this._componentsMap.get("series")[n];a.subType===t&&e.call(i,a,n)},this)},eachRawSeriesByType:function(t,e,i){return f(this.getSeriesByType(t),e,i)},isSeriesFiltered:function(t){return null==this._seriesIndicesMap.get(t.componentIndex)},getCurrentSeriesIndices:function(){return(this._seriesIndices||[]).slice()},filterSeries:function(t,e){var i=v(this._componentsMap.get("series"),t,e);Bo(this,i)},restoreData:function(t){var e=this._componentsMap;Bo(this,e.get("series"));var i=[];e.each(function(t,e){i.push(e)}),Cb.topologicalTravel(i,Cb.getAllClassMainTypes(),function(i){f(e.get(i),function(e){("series"!==i||!Oo(e,t))&&e.restoreData()})})}});c(Zb,Pb);var jb=["getDom","getZr","getWidth","getHeight","getDevicePixelRatio","dispatchAction","isDisposed","on","off","getDataURL","getConnectedDataURL","getModel","getOption","getViewOfComponentModel","getViewOfSeriesModel"],Xb={};Fo.prototype={constructor:Fo,create:function(t,e){var i=[];f(Xb,function(n){var a=n.create(t,e);i=i.concat(a||[])}),this._coordinateSystems=i},update:function(t,e){f(this._coordinateSystems,function(i){i.update&&i.update(t,e)})},getCoordinateSystems:function(){return this._coordinateSystems.slice()}},Fo.register=function(t,e){Xb[t]=e},Fo.get=function(t){return Xb[t]};var Ub=f,Yb=n,qb=p,$b=a,Kb=/^(min|max)?(.+)$/;Wo.prototype={constructor:Wo,setOption:function(t,e){t&&f(On(t.series),function(t){t&&t.data&&I(t.data)&&E(t.data)}),t=Yb(t,!0);var i=this._optionBackup,n=Ho.call(this,t,e,!i);this._newBaseOption=n.baseOption,i?(Uo(i.baseOption,n.baseOption),n.timelineOptions.length&&(i.timelineOptions=n.timelineOptions),n.mediaList.length&&(i.mediaList=n.mediaList),n.mediaDefault&&(i.mediaDefault=n.mediaDefault)):this._optionBackup=n},mountOption:function(t){var e=this._optionBackup;return this._timelineOptions=qb(e.timelineOptions,Yb),this._mediaList=qb(e.mediaList,Yb),this._mediaDefault=Yb(e.mediaDefault),this._currentMediaIndices=[],Yb(t?e.baseOption:this._newBaseOption)},getTimelineOption:function(t){var e,i=this._timelineOptions;if(i.length){var n=t.getComponent("timeline");n&&(e=Yb(i[n.getCurrentIndex()],!0))}return e},getMediaOption:function(){var t=this._api.getWidth(),e=this._api.getHeight(),i=this._mediaList,n=this._mediaDefault,a=[],r=[];if(!i.length&&!n)return r;for(var o=0,s=i.length;s>o;o++)Zo(i[o].query,t,e)&&a.push(o);return!a.length&&n&&(a=[-1]),a.length&&!Xo(a,this._currentMediaIndices)&&(r=qb(a,function(t){return Yb(-1===t?n.option:i[t].option)})),this._currentMediaIndices=a,r}};var Jb=f,Qb=M,tM=["areaStyle","lineStyle","nodeStyle","linkStyle","chordStyle","label","labelLine"],eM=function(t,e){Jb(ts(t.series),function(t){Qb(t)&&Qo(t)});var i=["xAxis","yAxis","radiusAxis","angleAxis","singleAxis","parallelAxis","radar"];e&&i.push("valueAxis","categoryAxis","logAxis","timeAxis"),Jb(i,function(e){Jb(ts(t[e]),function(t){t&&(Ko(t,"axisLabel"),Ko(t.axisPointer,"label"))})}),Jb(ts(t.parallel),function(t){var e=t&&t.parallelAxisDefault;Ko(e,"axisLabel"),Ko(e&&e.axisPointer,"label")}),Jb(ts(t.calendar),function(t){qo(t,"itemStyle"),Ko(t,"dayLabel"),Ko(t,"monthLabel"),Ko(t,"yearLabel")}),Jb(ts(t.radar),function(t){Ko(t,"name")}),Jb(ts(t.geo),function(t){Qb(t)&&(Jo(t),Jb(ts(t.regions),function(t){Jo(t)}))}),Jb(ts(t.timeline),function(t){Jo(t),qo(t,"label"),qo(t,"itemStyle"),qo(t,"controlStyle"),qo(t,"checkpointStyle");var e=t.data;_(e)&&f(e,function(t){M(t)&&(qo(t,"label"),qo(t,"itemStyle"))})}),Jb(ts(t.toolbox),function(t){qo(t,"iconStyle"),Jb(t.feature,function(t){qo(t,"iconStyle")})}),Ko(es(t.axisPointer),"label"),Ko(es(t.tooltip).axisPointer,"label")},iM=[["x","left"],["y","top"],["x2","right"],["y2","bottom"]],nM=["grid","geo","parallel","legend","toolbox","title","visualMap","dataZoom","timeline"],aM=function(t,e){eM(t,e),t.series=On(t.series),f(t.series,function(t){if(M(t)){var e=t.type;if(("pie"===e||"gauge"===e)&&null!=t.clockWise&&(t.clockwise=t.clockWise),"gauge"===e){var i=is(t,"pointer.color");null!=i&&ns(t,"itemStyle.normal.color",i)}as(t)}}),t.dataRange&&(t.visualMap=t.dataRange),f(nM,function(e){var i=t[e];i&&(_(i)||(i=[i]),f(i,function(t){as(t)}))})},rM=rs.prototype;rM.pure=!1,rM.persistent=!0,rM.getSource=function(){return this._source};var oM={arrayRows_column:{pure:!0,count:function(){return Math.max(0,this._data.length-this._source.startIndex)},getItem:function(t){return this._data[t+this._source.startIndex]},appendData:ls},arrayRows_row:{pure:!0,count:function(){var t=this._data[0];return t?Math.max(0,t.length-this._source.startIndex):0},getItem:function(t){t+=this._source.startIndex;for(var e=[],i=this._data,n=0;n<i.length;n++){var a=i[n];e.push(a?a[t]:null)}return e},appendData:function(){throw new Error('Do not support appendData when set seriesLayoutBy: "row".')}},objectRows:{pure:!0,count:os,getItem:ss,appendData:ls},keyedColumns:{pure:!0,count:function(){var t=this._source.dimensionsDefine[0].name,e=this._data[t];return e?e.length:0},getItem:function(t){for(var e=[],i=this._source.dimensionsDefine,n=0;n<i.length;n++){var a=this._data[i[n].name];e.push(a?a[t]:null)}return e},appendData:function(t){var e=this._data;f(t,function(t,i){for(var n=e[i]||(e[i]=[]),a=0;a<(t||[]).length;a++)n.push(t[a])})}},original:{count:os,getItem:ss,appendData:ls},typedArray:{persistent:!1,pure:!0,count:function(){return this._data?this._data.length/this._dimSize:0},getItem:function(t){t-=this._offset;for(var e=[],i=this._dimSize*t,n=0;n<this._dimSize;n++)e[n]=this._data[i+n];return e},appendData:function(t){this._data=t},clean:function(){this._offset+=this.count(),this._data=null}}},sM={arrayRows:hs,objectRows:function(t,e,i,n){return null!=i?t[n]:t},keyedColumns:hs,original:function(t,e,i){var n=En(t);return null!=i&&n instanceof Array?n[i]:n},typedArray:hs},lM={arrayRows:us,objectRows:function(t,e){return cs(t[e],this._dimensionInfos[e])},keyedColumns:us,original:function(t,e,i,n){var a=t&&(null==t.value?t:t.value);return!this._rawData.pure&&Rn(t)&&(this.hasItemOption=!0),cs(a instanceof Array?a[n]:a,this._dimensionInfos[e])},typedArray:function(t,e,i,n){return t[n]}},hM=/\{@(.+?)\}/g,uM={getDataParams:function(t,e){var i=this.getData(e),n=this.getRawValue(t,e),a=i.getRawIndex(t),r=i.getName(t,!0),o=i.getRawDataItem(t),s=i.getItemVisual(t,"color");return{componentType:this.mainType,componentSubType:this.subType,seriesType:"series"===this.mainType?this.subType:null,seriesIndex:this.seriesIndex,seriesId:this.id,seriesName:this.name,name:r,dataIndex:a,data:o,dataType:e,value:n,color:s,marker:oo(s),$vars:["seriesName","name","value"]}},getFormattedLabel:function(t,e,i,n,a){e=e||"normal";var r=this.getData(i),o=r.getItemModel(t),s=this.getDataParams(t,i);null!=n&&s.value instanceof Array&&(s.value=s.value[n]);var l=o.get("normal"===e?[a||"label","formatter"]:[e,a||"label","formatter"]);if("function"==typeof l)return s.status=e,l(s);if("string"==typeof l){var h=ao(l,s);return h.replace(hM,function(e,i){var n=i.length;return"["===i.charAt(0)&&"]"===i.charAt(n-1)&&(i=+i.slice(1,n-1)),ds(r,t,i)})}},getRawValue:function(t,e){return ds(this.getData(e),t)},formatTooltip:function(){}},cM=ps.prototype;cM.perform=function(t){var e=this._upstream,i=t&&t.skip;if(this._dirty&&e){var n=this.context;n.data=n.outputData=e.context.outputData}this.__pipeline&&(this.__pipeline.currentTask=this);var a;this._plan&&!i&&(a=this._plan(this.context)),(this._dirty||"reset"===a)&&(this._dirty=!1,gs(this,i));var r=t&&t.step;if(this._dueEnd=e?e._outputDueEnd:this._count?this._count(this.context):1/0,this._progress){var o=this._dueIndex,s=Math.min(null!=r?this._dueIndex+r:1/0,this._dueEnd);!i&&s>o&&this._progress({start:o,end:s},this.context),this._dueIndex=s;var l=null!=this._settedOutputEnd?this._settedOutputEnd:s;this._outputDueEnd=l}else this._dueIndex=this._outputDueEnd=null!=this._settedOutputEnd?this._settedOutputEnd:this._dueEnd;return this.unfinished()},cM.dirty=function(){this._dirty=!0,this._onDirty&&this._onDirty(this.context)},cM.unfinished=function(){return this._progress&&this._dueIndex<this._dueEnd},cM.pipe=function(t){(this._downstream!==t||this._dirty)&&(this._downstream=t,t._upstream=this,t.dirty())},cM.dispose=function(){this._disposed||(this._upstream&&(this._upstream._downstream=null),this._downstream&&(this._downstream._upstream=null),this._dirty=!1,this._disposed=!0)},cM.getUpstream=function(){return this._upstream},cM.getDownstream=function(){return this._downstream},cM.setOutputEnd=function(t){this._outputDueEnd=this._settedOutputEnd=t};var dM=Wn(),fM=Cb.extend({type:"series.__base__",seriesIndex:0,coordinateSystem:null,defaultOption:null,legendDataProvider:null,visualColorAccessPath:"itemStyle.color",layoutMode:null,init:function(t,e,i){this.seriesIndex=this.componentIndex,this.dataTask=fs({count:ys,reset:xs}),this.dataTask.context={model:this},this.mergeDefaultAndTheme(t,i),So(this);var n=this.getInitialData(t,i);ws(n,this),this.dataTask.context.data=n,dM(this).dataBeforeProcessed=n,vs(this)},mergeDefaultAndTheme:function(t,e){var i=this.layoutMode,n=i?go(t):{},r=this.subType;Cb.hasClass(r)&&(r+="Series"),a(t,e.getTheme().get(this.subType)),a(t,this.getDefaultOption()),zn(t,"label",["show"]),this.fillDataTextStyle(t.data),i&&po(t,n,i)},mergeOption:function(t,e){t=a(this.option,t,!0),this.fillDataTextStyle(t.data);var i=this.layoutMode;i&&po(this.option,t,i),So(this);var n=this.getInitialData(t,e);ws(n,this),this.dataTask.dirty(),this.dataTask.context.data=n,dM(this).dataBeforeProcessed=n,vs(this)},fillDataTextStyle:function(t){if(t)for(var e=["show"],i=0;i<t.length;i++)t[i]&&t[i].label&&zn(t[i],"label",e)},getInitialData:function(){},appendData:function(t){var e=this.getRawData();e.appendData(t.data)},getData:function(t){var e=Ms(this);if(e){var i=e.context.data;return null==t?i:i.getLinkedData(t)}return dM(this).data},setData:function(t){var e=Ms(this);if(e){var i=e.context;i.data!==t&&e.isOverallFilter&&e.setOutputEnd(t.count()),i.outputData=t,e!==this.dataTask&&(i.data=t)}dM(this).data=t},getSource:function(){return bo(this)},getRawData:function(){return dM(this).dataBeforeProcessed},getBaseAxis:function(){var t=this.coordinateSystem;return t&&t.getBaseAxis&&t.getBaseAxis()},formatTooltip:function(t,e){function i(i){function n(t,i){var n=a.getDimensionInfo(i);if(n&&n.otherDims.tooltip!==!1){var r=n.type,l=oo({color:h,type:"subItem"}),u=(o?l+no(n.displayName||"-")+": ":"")+no("ordinal"===r?t+"":"time"===r?e?"":so("yyyy/MM/dd hh:mm:ss",t):eo(t));u&&s.push(u)}}var o=g(i,function(t,e,i){var n=a.getDimensionInfo(i);return t|=n&&n.tooltip!==!1&&null!=n.displayName},0),s=[];return r.length?f(r,function(e){n(ds(a,t,e),e)}):f(i,n),(o?"<br/>":"")+s.join(o?"<br/>":", ")}function n(t){return no(eo(t))}var a=this.getData(),r=a.mapDimension("defaultedTooltip",!0),o=r.length,s=this.getRawValue(t),l=_(s),h=a.getItemVisual(t,"color");M(h)&&h.colorStops&&(h=(h.colorStops[0]||{}).color),h=h||"transparent";var u=o>1||l&&!o?i(s):n(o?ds(a,t,r[0]):l?s[0]:s),c=oo(h),d=a.getName(t),p=this.name;return p===__&&(p=""),p=p?no(p)+(e?": ":"<br/>"):"",e?c+p+u:p+c+(d?no(d)+": "+u:u)},isAnimationEnabled:function(){if(vy.node)return!1;var t=this.getShallow("animation");return t&&this.getData().count()>this.getShallow("animationThreshold")&&(t=!1),t},restoreData:function(){this.dataTask.dirty()},getColorFromPalette:function(t,e,i){var n=this.ecModel,a=Pb.getColorFromPalette.call(this,t,e,i);return a||(a=n.getColorFromPalette(t,e,i)),a},coordDimToDataDim:function(t){return this.getRawData().mapDimension(t,!0)},getProgressive:function(){return this.get("progressive")},getProgressiveThreshold:function(){return this.get("progressiveThreshold")},getAxisTooltipData:null,getTooltipPosition:null,pipeTask:null,preventIncremental:null,pipelineContext:null});c(fM,uM),c(fM,Pb);var pM=function(){this.group=new xx,this.uid=Er("viewComponent")};pM.prototype={constructor:pM,init:function(){},render:function(){},dispose:function(){}};var gM=pM.prototype;gM.updateView=gM.updateLayout=gM.updateVisual=function(){},qn(pM),Qn(pM,{registerWhenExtend:!0});var vM=function(){var t=Wn();return function(e){var i=t(e),n=e.pipelineContext,a=i.large,r=i.incrementalRender,o=i.large=n.large,s=i.incrementalRender=n.incrementalRender;return(a^o||r^s)&&"reset"}},mM=Wn(),yM=vM();Ss.prototype={type:"chart",init:function(){},render:function(){},highlight:function(t,e,i,n){Ts(t.getData(),n,"emphasis")},downplay:function(t,e,i,n){Ts(t.getData(),n,"normal")},remove:function(){this.group.removeAll()},dispose:function(){},incrementalPrepareRender:null,incrementalRender:null,updateTransform:null};var xM=Ss.prototype;xM.updateView=xM.updateLayout=xM.updateVisual=function(t,e,i,n){this.render(t,e,i,n)},qn(Ss,["dispose"]),Qn(Ss,{registerWhenExtend:!0}),Ss.markUpdateMethod=function(t,e){mM(t).updateMethod=e};var _M="\x00__throttleOriginMethod",wM="\x00__throttleRate",bM="\x00__throttleType",MM={createOnAllSeries:!0,performRawSeries:!0,reset:function(t,e){var i=t.getData(),n=(t.visualColorAccessPath||"itemStyle.color").split("."),a=t.get(n)||t.getColorFromPalette(t.get("name"),null,e.getSeriesCount());if(i.setVisual("color",a),!e.isSeriesFiltered(t)){"function"!=typeof a||a instanceof Yw||i.each(function(e){i.setItemVisual(e,"color",a(t.getDataParams(e)))});var r=function(t,e){var i=t.getItemModel(e),a=i.get(n,!0);null!=a&&t.setItemVisual(e,"color",a)};return{dataEach:i.hasItemOption?r:null}}}},SM={toolbox:{brush:{title:{rect:"矩形选择",polygon:"圈选",lineX:"横向选择",lineY:"纵向选择",keep:"保持选择",clear:"清除选择"}},dataView:{title:"数据视图",lang:["数据视图","关闭","刷新"]},dataZoom:{title:{zoom:"区域缩放",back:"区域缩放还原"}},magicType:{title:{line:"切换为折线图",bar:"切换为柱状图",stack:"切换为堆叠",tiled:"切换为平铺"}},restore:{title:"还原"},saveAsImage:{title:"保存为图片",lang:["右键另存为图片"]}},series:{typeNames:{pie:"饼图",bar:"柱状图",line:"折线图",scatter:"散点图",effectScatter:"涟漪散点图",radar:"雷达图",tree:"树图",treemap:"矩形树图",boxplot:"箱型图",candlestick:"K线图",k:"K线图",heatmap:"热力图",map:"地图",parallel:"平行坐标图",lines:"线图",graph:"关系图",sankey:"桑基图",funnel:"漏斗图",gauge:"仪表盘图",pictorialBar:"象形柱图",themeRiver:"主题河流图",sunburst:"旭日图"}},aria:{general:{withTitle:"这是一个关于“{title}”的图表。",withoutTitle:"这是一个图表，"},series:{single:{prefix:"",withName:"图表类型是{seriesType}，表示{seriesName}。",withoutName:"图表类型是{seriesType}。"},multiple:{prefix:"它由{seriesCount}个图表系列组成。",withName:"第{seriesId}个系列是一个表示{seriesName}的{seriesType}，",withoutName:"第{seriesId}个系列是一个{seriesType}，",separator:{middle:"；",end:"。"}}},data:{allData:"其数据是——",partialData:"其中，前{displayCnt}项是——",withName:"{name}的数据是{value}",withoutName:"{value}",separator:{middle:"，",end:""}}}},IM=function(t,e){function i(t,e){if("string"!=typeof t)return t;var i=t;return f(e,function(t,e){i=i.replace(new RegExp("\\{\\s*"+e+"\\s*\\}","g"),t)}),i}function n(t){var e=o.get(t);if(null==e){for(var i=t.split("."),n=SM.aria,a=0;a<i.length;++a)n=n[i[a]];return n}return e}function a(){var t=e.getModel("title").option;return t&&t.length&&(t=t[0]),t&&t.text}function r(t){return SM.series.typeNames[t]||"自定义图"}var o=e.getModel("aria");if(o.get("show")){if(o.get("description"))return void t.setAttribute("aria-label",o.get("description"));var s=0;e.eachSeries(function(){++s},this);var l,h=o.get("data.maxCount")||10,u=o.get("series.maxCount")||10,c=Math.min(s,u);if(!(1>s)){var d=a();l=d?i(n("general.withTitle"),{title:d}):n("general.withoutTitle");var p=[],g=s>1?"series.multiple.prefix":"series.single.prefix";l+=i(n(g),{seriesCount:s}),e.eachSeries(function(t,e){if(c>e){var a,o=t.get("name"),l="series."+(s>1?"multiple":"single")+".";a=n(o?l+"withName":l+"withoutName"),a=i(a,{seriesId:t.seriesIndex,seriesName:t.get("name"),seriesType:r(t.subType)});var u=t.getData();window.data=u,a+=u.count()>h?i(n("data.partialData"),{displayCnt:h}):n("data.allData");for(var d=[],f=0;f<u.count();f++)if(h>f){var g=u.getName(f),v=ds(u,f);d.push(i(n(g?"data.withName":"data.withoutName"),{name:g,value:v}))}a+=d.join(n("data.separator.middle"))+n("data.separator.end"),p.push(a)}}),l+=p.join(n("series.multiple.separator.middle"))+n("series.multiple.separator.end"),t.setAttribute("aria-label",l)}}},TM=Math.PI,AM=function(t,e){e=e||{},s(e,{text:"loading",color:"#c23531",textColor:"#000",maskColor:"rgba(255, 255, 255, 0.8)",zlevel:0});var i=new Ww({style:{fill:e.maskColor},zlevel:e.zlevel,z:1e4}),n=new Xw({shape:{startAngle:-TM/2,endAngle:-TM/2+.1,r:10},style:{stroke:e.color,lineCap:"round",lineWidth:5},zlevel:e.zlevel,z:10001}),a=new Ww({style:{fill:"none",text:e.text,textPosition:"right",textDistance:10,textFill:e.textColor},zlevel:e.zlevel,z:10001});n.animateShape(!0).when(1e3,{endAngle:3*TM/2}).start("circularInOut"),n.animateShape(!0).when(1e3,{startAngle:3*TM/2}).delay(300).start("circularInOut");var r=new xx;return r.add(n),r.add(a),r.add(i),r.resize=function(){var e=t.getWidth()/2,r=t.getHeight()/2;n.setShape({cx:e,cy:r});var o=n.shape.r;a.setShape({x:e-o,y:r-o,width:2*o,height:2*o}),i.setShape({x:0,y:0,width:t.getWidth(),height:t.getHeight()})},r.resize(),r},CM=Os.prototype;CM.getPerformArgs=function(t,e){if(t.__pipeline){var i=this._pipelineMap.get(t.__pipeline.id),n=i.context,a=!e&&i.progressiveEnabled&&(!n||n.incrementalRender)&&t.__idxInPipeline>i.bockIndex;return{step:a?i.step:null}}},CM.getPipeline=function(t){return this._pipelineMap.get(t)},CM.updateStreamModes=function(t,e){var i=this._pipelineMap.get(t.uid),n=t.getData(),a=n.count(),r=i.progressiveEnabled&&e.incrementalPrepareRender&&a>=i.threshold,o=t.get("large")&&a>=t.get("largeThreshold");t.pipelineContext=i.context={incrementalRender:r,large:o}},CM.restorePipelines=function(t){var e=this,i=e._pipelineMap=B();t.eachSeries(function(t){var n=t.getProgressive(),a=t.uid;i.set(a,{id:a,head:null,tail:null,threshold:t.getProgressiveThreshold(),progressiveEnabled:n&&!(t.preventIncremental&&t.preventIncremental()),bockIndex:-1,step:n||700,count:0}),js(e,t,t.dataTask)})},CM.prepareStageTasks=function(t){var e=this._stageTaskMap,i=this.ecInstance.getModel(),n=this.api;f(t,function(t){var a=e.get(t.uid)||e.set(t.uid,[]);t.reset&&Es(this,t,a,i,n),t.overallReset&&Rs(this,t,a,i,n)},this)},CM.prepareView=function(t,e,i,n){var a=t.renderTask,r=a.context;r.model=e,r.ecModel=i,r.api=n,a.__block=!t.incrementalPrepareRender,js(this,e,a)},CM.performDataProcessorTasks=function(t,e,i){zs(this,t,e,i,{block:!0})},CM.performVisualTasks=function(t,e,i,n){zs(this,t,e,i,n)},CM.performSeriesTasks=function(t){var e;t.eachSeries(function(t){e|=t.dataTask.perform()}),this.unfinished|=e},CM.plan=function(){this._pipelineMap.each(function(t){var e=t.tail;do{if(e.__block){t.bockIndex=e.__idxInPipeline;break}e=e.getUpstream()}while(e)})};var DM=CM.updatePayload=function(t,e){"remain"!==e&&(t.context.payload=e)};Os.wrapStageHandler=function(t,e){return w(t)&&(t={overallReset:t,seriesType:Xs(t)}),t.uid=Er("stageHandler"),e&&(t.visualType=e),t};var LM,kM={},PM={};Us(kM,Zb),Us(PM,Go),kM.eachSeriesByType=kM.eachRawSeriesByType=function(t){LM=t},kM.eachComponent=function(t){"series"===t.mainType&&t.subType&&(LM=t.subType)};var OM=["#37A2DA","#32C5E9","#67E0E3","#9FE6B8","#FFDB5C","#ff9f7f","#fb7293","#E062AE","#E690D1","#e7bcf3","#9d96f5","#8378EA","#96BFFF"],zM={color:OM,colorLayer:[["#37A2DA","#ffd85c","#fd7b5f"],["#37A2DA","#67E0E3","#FFDB5C","#ff9f7f","#E062AE","#9d96f5"],["#37A2DA","#32C5E9","#9FE6B8","#FFDB5C","#ff9f7f","#fb7293","#e7bcf3","#8378EA","#96BFFF"],OM]},EM="#eee",RM=function(){return{axisLine:{lineStyle:{color:EM}},axisTick:{lineStyle:{color:EM}},axisLabel:{textStyle:{color:EM}},splitLine:{lineStyle:{type:"dashed",color:"#aaa"}},splitArea:{areaStyle:{color:EM}}}
-},NM=["#dd6b66","#759aa0","#e69d87","#8dc1a9","#ea7e53","#eedd78","#73a373","#73b9bc","#7289ab","#91ca8c","#f49f42"],BM={color:NM,backgroundColor:"#333",tooltip:{axisPointer:{lineStyle:{color:EM},crossStyle:{color:EM}}},legend:{textStyle:{color:EM}},textStyle:{color:EM},title:{textStyle:{color:EM}},toolbox:{iconStyle:{normal:{borderColor:EM}}},dataZoom:{textStyle:{color:EM}},visualMap:{textStyle:{color:EM}},timeline:{lineStyle:{color:EM},itemStyle:{normal:{color:NM[1]}},label:{normal:{textStyle:{color:EM}}},controlStyle:{normal:{color:EM,borderColor:EM}}},timeAxis:RM(),logAxis:RM(),valueAxis:RM(),categoryAxis:RM(),line:{symbol:"circle"},graph:{color:NM},gauge:{title:{textStyle:{color:EM}}},candlestick:{itemStyle:{normal:{color:"#FD1050",color0:"#0CF49B",borderColor:"#FD1050",borderColor0:"#0CF49B"}}}};BM.categoryAxis.splitLine.show=!1;var VM=O,GM=f,FM=w,WM=M,HM=Cb.parseClassType,ZM="4.0.0",jM={zrender:"4.0.0"},XM=1,UM=1e3,YM=5e3,qM=1e3,$M=2e3,KM=3e3,JM=4e3,QM=5e3,tS={PROCESSOR:{FILTER:UM,STATISTIC:YM},VISUAL:{LAYOUT:qM,GLOBAL:$M,CHART:KM,COMPONENT:JM,BRUSH:QM}},eS="__flagInMainProcess",iS="__hasGradientOrPatternBg",nS="__optionUpdated",aS=/^[a-zA-Z0-9_]+$/;qs.prototype.on=Ys("on"),qs.prototype.off=Ys("off"),qs.prototype.one=Ys("one"),c(qs,By);var rS=$s.prototype;rS._onframe=function(){if(!this._disposed){var t=this._scheduler;if(this[nS]){var e=this[nS].silent;this[eS]=!0,Js(this),oS.update.call(this),this[eS]=!1,this[nS]=!1,nl.call(this,e),al.call(this,e)}else if(t.unfinished){var i=XM,n=this._model,a=this._api;t.unfinished=!1;do{var r=+new Date;t.performSeriesTasks(n),t.performDataProcessorTasks(uS,n),el(this,n),t.performVisualTasks(fS,n),ul(this,this._model,a,"remain"),i-=+new Date-r}while(i>0&&t.unfinished);t.unfinished||(this._zr&&this._zr.flush(),this.trigger("finished"))}}},rS.getDom=function(){return this._dom},rS.getZr=function(){return this._zr},rS.setOption=function(t,e,i){var n;if(WM(e)&&(i=e.lazyUpdate,n=e.silent,e=e.notMerge),this[eS]=!0,!this._model||e){var a=new Wo(this._api),r=this._theme,o=this._model=new Zb(null,null,r,a);o.scheduler=this._scheduler,o.init(null,null,r,a)}this._model.setOption(t,cS),i?(this[nS]={silent:n},this[eS]=!1):(Js(this),oS.update.call(this),this._zr.flush(),this[nS]=!1,this[eS]=!1,nl.call(this,n),al.call(this,n))},rS.setTheme=function(){console.log("ECharts#setTheme() is DEPRECATED in ECharts 3.0")},rS.getModel=function(){return this._model},rS.getOption=function(){return this._model&&this._model.getOption()},rS.getWidth=function(){return this._zr.getWidth()},rS.getHeight=function(){return this._zr.getHeight()},rS.getDevicePixelRatio=function(){return this._zr.painter.dpr||window.devicePixelRatio||1},rS.getRenderedCanvas=function(t){if(vy.canvasSupported){t=t||{},t.pixelRatio=t.pixelRatio||1,t.backgroundColor=t.backgroundColor||this._model.get("backgroundColor");var e=this._zr,i=e.storage.getDisplayList();return f(i,function(t){t.stopAnimation(!0)}),e.painter.getRenderedCanvas(t)}},rS.getSvgDataUrl=function(){if(vy.svgSupported){var t=this._zr,e=t.storage.getDisplayList();return f(e,function(t){t.stopAnimation(!0)}),t.painter.pathToSvg()}},rS.getDataURL=function(t){t=t||{};var e=t.excludeComponents,i=this._model,n=[],a=this;GM(e,function(t){i.eachComponent({mainType:t},function(t){var e=a._componentsMap[t.__viewId];e.group.ignore||(n.push(e),e.group.ignore=!0)})});var r="svg"===this._zr.painter.getType()?this.getSvgDataUrl():this.getRenderedCanvas(t).toDataURL("image/"+(t&&t.type||"png"));return GM(n,function(t){t.group.ignore=!1}),r},rS.getConnectedDataURL=function(t){if(vy.canvasSupported){var e=this.group,i=Math.min,a=Math.max,r=1/0;if(mS[e]){var o=r,s=r,l=-r,h=-r,u=[],c=t&&t.pixelRatio||1;f(vS,function(r){if(r.group===e){var c=r.getRenderedCanvas(n(t)),d=r.getDom().getBoundingClientRect();o=i(d.left,o),s=i(d.top,s),l=a(d.right,l),h=a(d.bottom,h),u.push({dom:c,left:d.left,top:d.top})}}),o*=c,s*=c,l*=c,h*=c;var d=l-o,p=h-s,g=Ay();g.width=d,g.height=p;var v=Cn(g);return GM(u,function(t){var e=new on({style:{x:t.left*c-o,y:t.top*c-s,image:t.dom}});v.add(e)}),v.refreshImmediately(),g.toDataURL("image/"+(t&&t.type||"png"))}return this.getDataURL(t)}},rS.convertToPixel=x(Ks,"convertToPixel"),rS.convertFromPixel=x(Ks,"convertFromPixel"),rS.containPixel=function(t,e){var i,n=this._model;return t=Hn(n,t),f(t,function(t,n){n.indexOf("Models")>=0&&f(t,function(t){var a=t.coordinateSystem;if(a&&a.containPoint)i|=!!a.containPoint(e);else if("seriesModels"===n){var r=this._chartsMap[t.__viewId];r&&r.containPoint&&(i|=r.containPoint(e,t))}},this)},this),!!i},rS.getVisual=function(t,e){var i=this._model;t=Hn(i,t,{defaultMainType:"series"});var n=t.seriesModel,a=n.getData(),r=t.hasOwnProperty("dataIndexInside")?t.dataIndexInside:t.hasOwnProperty("dataIndex")?a.indexOfRawIndex(t.dataIndex):null;return null!=r?a.getItemVisual(r,e):a.getVisual(e)},rS.getViewOfComponentModel=function(t){return this._componentsMap[t.__viewId]},rS.getViewOfSeriesModel=function(t){return this._chartsMap[t.__viewId]};var oS={prepareAndUpdate:function(t){Js(this),oS.update.call(this,t)},update:function(t){var e=this._model,i=this._api,n=this._zr,a=this._coordSysMgr,r=this._scheduler;if(e){e.restoreData(t),r.performSeriesTasks(e),a.create(e,i),r.performDataProcessorTasks(uS,e,t),el(this,e),ol(e),a.update(e,i),sl(e),r.performVisualTasks(fS,e,t),ll(this,e,i,t);var o=e.get("backgroundColor")||"transparent",s=n.painter;if(s.isSingleCanvas&&s.isSingleCanvas())n.configLayer(0,{clearColor:o});else{if(!vy.canvasSupported){var l=ze(o);o=He(l,"rgb"),0===l[3]&&(o="transparent")}o.colorStops||o.image?(n.configLayer(0,{clearColor:o}),this[iS]=!0,this._dom.style.background="transparent"):(this[iS]&&n.configLayer(0,{clearColor:null}),this[iS]=!1,this._dom.style.background=o)}cl(e,i)}},updateTransform:function(t){var e=this._model,i=this,n=this._api;if(e){var a=[];e.eachComponent(function(r,o){var s=i.getViewOfComponentModel(o);if(s&&s.__alive)if(s.updateTransform){var l=s.updateTransform(o,e,n,t);l&&l.update&&a.push(s)}else a.push(s)});var r=B();e.eachSeries(function(a){var o=i._chartsMap[a.__viewId];if(o.updateTransform){var s=o.updateTransform(a,e,n,t);s&&s.update&&r.set(a.uid,1)}else r.set(a.uid,1)}),sl(e),this._scheduler.performVisualTasks(fS,e,t,{setDirty:!0,dirtyMap:r}),ul(i,e,n,t,r),cl(e,this._api)}},updateView:function(t){var e=this._model;e&&(Ss.markUpdateMethod(t,"updateView"),sl(e),this._scheduler.performVisualTasks(fS,e,t,{setDirty:!0}),ll(this,this._model,this._api,t),cl(e,this._api))},updateVisual:function(t){oS.update.call(this,t)},updateLayout:function(t){oS.update.call(this,t)}};rS.resize=function(t){this._zr.resize(t);var e=this._model;if(this._loadingFX&&this._loadingFX.resize(),e){var i=e.resetOption("media");tl(this,i,t&&t.silent)}},rS.showLoading=function(t,e){if(WM(t)&&(e=t,t=""),t=t||"default",this.hideLoading(),gS[t]){var i=gS[t](this._api,e),n=this._zr;this._loadingFX=i,n.add(i)}},rS.hideLoading=function(){this._loadingFX&&this._zr.remove(this._loadingFX),this._loadingFX=null},rS.makeActionFromEvent=function(t){var e=o({},t);return e.type=hS[t.type],e},rS.dispatchAction=function(t,e){if(WM(e)||(e={silent:!!e}),lS[t.type]&&this._model){if(this[eS])return void this._pendingActions.push(t);il.call(this,t,e.silent),e.flush?this._zr.flush(!0):e.flush!==!1&&vy.browser.weChat&&this._throttledZrFlush(),nl.call(this,e.silent),al.call(this,e.silent)}},rS.appendData=function(t){var e=t.seriesIndex,i=this.getModel(),n=i.getSeriesByIndex(e);n.appendData(t),this._scheduler.unfinished=!0},rS.on=Ys("on"),rS.off=Ys("off"),rS.one=Ys("one");var sS=["click","dblclick","mouseover","mouseout","mousemove","mousedown","mouseup","globalout","contextmenu"];rS._initEvents=function(){GM(sS,function(t){this._zr.on(t,function(e){var i,n=this.getModel(),a=e.target;if("globalout"===t)i={};else if(a&&null!=a.dataIndex){var r=a.dataModel||n.getSeriesByIndex(a.seriesIndex);i=r&&r.getDataParams(a.dataIndex,a.dataType)||{}}else a&&a.eventData&&(i=o({},a.eventData));i&&(i.event=e,i.type=t,this.trigger(t,i))},this)},this),GM(hS,function(t,e){this._messageCenter.on(e,function(t){this.trigger(e,t)},this)},this)},rS.isDisposed=function(){return this._disposed},rS.clear=function(){this.setOption({series:[]},!0)},rS.dispose=function(){if(!this._disposed){this._disposed=!0,jn(this.getDom(),_S,"");var t=this._api,e=this._model;GM(this._componentsViews,function(i){i.dispose(e,t)}),GM(this._chartsViews,function(i){i.dispose(e,t)}),this._zr.dispose(),delete vS[this.id]}},c($s,By);var lS={},hS={},uS=[],cS=[],dS=[],fS=[],pS={},gS={},vS={},mS={},yS=new Date-0,xS=new Date-0,_S="_echarts_instance_",wS={},bS=xl;kl($M,MM),Sl(aM),Ol("default",AM),Al({type:"highlight",event:"highlight",update:"highlight"},G),Al({type:"downplay",event:"downplay",update:"downplay"},G),Ml("light",zM),Ml("dark",BM);var MS={};Wl.prototype={constructor:Wl,add:function(t){return this._add=t,this},update:function(t){return this._update=t,this},remove:function(t){return this._remove=t,this},execute:function(){var t,e=this._old,i=this._new,n={},a={},r=[],o=[];for(Hl(e,n,r,"_oldKeyGetter",this),Hl(i,a,o,"_newKeyGetter",this),t=0;t<e.length;t++){var s=r[t],l=a[s];if(null!=l){var h=l.length;h?(1===h&&(a[s]=null),l=l.unshift()):a[s]=null,this._update&&this._update(l,t)}else this._remove&&this._remove(t)}for(var t=0;t<o.length;t++){var s=o[t];if(a.hasOwnProperty(s)){var l=a[s];if(null==l)continue;if(l.length)for(var u=0,h=l.length;h>u;u++)this._add&&this._add(l[u]);else this._add&&this._add(l)}}}};var SS=B(["tooltip","label","itemName","itemId","seriesName"]),IS=M,TS="undefined",AS=typeof window===TS?global:window,CS="e\x00\x00",DS={"float":typeof AS.Float64Array===TS?Array:AS.Float64Array,"int":typeof AS.Int32Array===TS?Array:AS.Int32Array,ordinal:Array,number:Array,time:Array},LS=["stackedOn","hasItemOption","_nameList","_idList","_rawData","_rawExtent","_chunkSize","_chunkCount","_dimValueGetter","_count","_rawCount","_nameDimIdx","_idDimIdx"],kS=function(t,e){t=t||["x","y"];for(var i={},n=[],a=0;a<t.length;a++){var r,o={};"string"==typeof t[a]?(r=t[a],o={name:r,coordDim:r,coordDimIndex:0,stackable:!1,type:"float"}):(o=t[a],r=o.name,o.type=o.type||"float",o.coordDim||(o.coordDim=r,o.coordDimIndex=0)),o.otherDims=o.otherDims||{},n.push(r),i[r]=o,o.index=a}this.dimensions=n,this._dimensionInfos=i,this.hostModel=e,this.dataType,this._indices=null,this._count=0,this._rawCount=0,this._storage={},this._nameList=[],this._idList=[],this._optionModels=[],this.stackedOn=null,this._visual={},this._layout={},this._itemVisuals=[],this.hasItemVisual={},this._itemLayouts=[],this._graphicEls=[],this._chunkSize=1e5,this._chunkCount=0,this._rawData,this._rawExtent={},this._extent={},this._approximateExtent={},this._dimensionsSummary=Zl(this)},PS=kS.prototype;PS.type="list",PS.hasItemOption=!0,PS.getDimension=function(t){return isNaN(t)||(t=this.dimensions[t]||t),t},PS.getDimensionInfo=function(t){return this._dimensionInfos[this.getDimension(t)]},PS.getDimensionsOnCoord=function(){return this._dimensionsSummary.dataDimsOnCoord.slice()},PS.mapDimension=function(t,e){var i=this._dimensionsSummary.encode[t];return e===!0?i&&i.slice()||[]:i?i[e||0]:null},PS.initData=function(t,e,i){var n=wo.isInstance(t)||d(t);n&&(t=new rs(t,this.dimensions.length)),this._rawData=t,this._storage={},this._indices=null,this._nameList=e||[],this._idList=[],this._nameRepeatCount={},i||(this.hasItemOption=!1),this.defaultDimValueGetter=lM[this._rawData.getSource().sourceFormat],this._dimValueGetter=i=i||this.defaultDimValueGetter,this._rawExtent={},this._initDataFromProvider(0,t.count()),t.pure&&(this.hasItemOption=!1)},PS.getProvider=function(){return this._rawData},PS.appendData=function(t){var e=this._rawData,i=this.count();e.appendData(t);var n=e.count();e.persistent||(n+=i),this._initDataFromProvider(i,n)},PS._initDataFromProvider=function(t,e){if(!(t>=e)){for(var i,n=this._chunkSize,a=this._rawData,r=this._storage,o=this.dimensions,s=this._dimensionInfos,l=this._nameList,h=this._idList,u=this._rawExtent,c=this._nameRepeatCount={},d=this._chunkCount,f=d-1,p=0;p<o.length;p++){var g=o[p];u[g]||(u[g]=[1/0,-1/0]);var v=s[g];0===v.otherDims.itemName&&(i=this._nameDimIdx=p),0===v.otherDims.itemId&&(this._idDimIdx=p);var m=DS[v.type];r[g]||(r[g]=[]);var y=r[g][f];if(y&&y.length<n){for(var x=new m(Math.min(e-f*n,n)),_=0;_<y.length;_++)x[_]=y[_];r[g][f]=x}for(var w=d*n;e>w;w+=n)r[g].push(new m(Math.min(e-w,n)));this._chunkCount=r[g].length}for(var b=t;e>b;b++){for(var M=a.getItem(b),S=Math.floor(b/n),I=b%n,w=0;w<o.length;w++){var g=o[w],T=r[g][S],A=this._dimValueGetter(M,g,b,w);T[I]=A,A<u[g][0]&&(u[g][0]=A),A>u[g][1]&&(u[g][1]=A)}if(!a.pure){var C=l[b];M&&!C&&(null!=i?C=this._getNameFromStore(b):null!=M.name&&(l[b]=C=M.name));var D=null==M?null:M.id;null==D&&null!=C&&(c[C]=c[C]||0,D=C,c[C]>0&&(D+="__ec__"+c[C]),c[C]++),null!=D&&(h[b]=D)}}!a.persistent&&a.clean&&a.clean(),this._rawCount=this._count=e,this._extent={}}},PS._getNameFromStore=function(t){var e=this._nameDimIdx;if(null!=e){var i=this._chunkSize,n=Math.floor(t/i),a=t%i,r=this.dimensions[e],o=this._dimensionInfos[r].ordinalMeta;if(o)return o.categories[t];var s=this._storage[r][n];return s&&s[a]}},PS._getIdFromStore=function(t){var e=this._idDimIdx;if(null!=e){var i=this._chunkSize,n=Math.floor(t/i),a=t%i,r=this.dimensions[e],o=this._dimensionInfos[r].ordinalMeta;if(o)return o.categories[t];var s=this._storage[r][n];return s&&s[a]}},PS.count=function(){return this._count},PS.getIndices=function(){if(this._indices){var t=this._indices.constructor;return new t(this._indices.buffer,0,this._count)}for(var t=Ul(this),e=new t(this.count()),i=0;i<e.length;i++)e[i]=i;return e},PS.get=function(t,e,i){if(!(e>=0&&e<this._count))return 0/0;var n=this._storage;if(!n[t])return 0/0;e=this.getRawIndex(e);var a=Math.floor(e/this._chunkSize),r=e%this._chunkSize,o=n[t][a],s=o[r];if(i){var l=this._dimensionInfos[t];if(l&&l.stackable)for(var h=this.stackedOn;h;){var u=h.get(t,e);(s>=0&&u>0||0>=s&&0>u)&&(s+=u),h=h.stackedOn}}return s},PS._getFast=function(t,e){var i=Math.floor(e/this._chunkSize),n=e%this._chunkSize,a=this._storage[t][i];return a[n]},PS.getValues=function(t,e,i){var n=[];_(t)||(i=e,e=t,t=this.dimensions);for(var a=0,r=t.length;r>a;a++)n.push(this.get(t[a],e,i));return n},PS.hasValue=function(t){for(var e=this._dimensionsSummary.dataDimsOnCoord,i=this._dimensionInfos,n=0,a=e.length;a>n;n++)if("ordinal"!==i[e[n]].type&&isNaN(this.get(e[n],t)))return!1;return!0},PS.getDataExtent=function(t,e){t=this.getDimension(t);var i=this._storage[t],n=[1/0,-1/0];if(e=(e||!1)&&this.isStacked(t),!i)return n;var a,r=this.count(),o=[t,!!e].join("_"),s=!this._indices&&!e;if(s)return this._rawExtent[t].slice();if(a=this._extent[o])return a.slice();a=n;for(var l=a[0],h=a[1],u=0;r>u;u++){var c=e?this.get(t,u,!0):this._getFast(t,this.getRawIndex(u));l>c&&(l=c),c>h&&(h=c)}return a=[l,h],this._extent[o]=a,a},PS.getApproximateExtent=function(t,e){return t=this.getDimension(t),this._approximateExtent[t]||this.getDataExtent(t,e)},PS.setApproximateExtent=function(t,e){e=this.getDimension(e),this._approximateExtent[e]=t.slice()},PS.isStacked=function(t){var e=this._dimensionInfos[t];return e&&e.stackable&&this.stackedOn},PS.getSum=function(t,e){var i=this._storage[t],n=0;if(i)for(var a=0,r=this.count();r>a;a++){var o=this.get(t,a,e);isNaN(o)||(n+=o)}return n},PS.indexOf=function(t,e){var i=this._storage,n=i[t],a=this._chunkSize;if(n)for(var r=0,o=this.count();o>r;r++){var s=Math.floor(r/a),l=r%a;if(n[s][l]===e)return r}return-1},PS.indexOfName=function(t){for(var e=0,i=this.count();i>e;e++)if(this.getName(e)===t)return e;return-1},PS.indexOfRawIndex=function(t){if(!this._indices)return t;if(t>=this._rawCount||0>t)return-1;var e=this._indices,i=e[t];if(null!=i&&i<this._count&&i===t)return t;for(var n=0,a=this._count-1;a>=n;){var r=(n+a)/2|0;if(e[r]<t)n=r+1;else{if(!(e[r]>t))return r;a=r-1}}return-1},PS.indicesOfNearest=function(t,e,i,n){var a=this._storage,r=a[t],o=[];if(!r)return o;null==n&&(n=1/0);for(var s=Number.MAX_VALUE,l=-1,h=0,u=this.count();u>h;h++){var c=e-this.get(t,h,i),d=Math.abs(c);n>=c&&s>=d&&((s>d||c>=0&&0>l)&&(s=d,l=c,o.length=0),o.push(h))}return o},PS.getRawIndex=$l,PS.getRawDataItem=function(t){if(this._rawData.persistent)return this._rawData.getItem(this.getRawIndex(t));for(var e=[],i=0;i<this.dimensions.length;i++){var n=this.dimensions[i];e.push(this.get(n,t))}return e},PS.getName=function(t){var e=this.getRawIndex(t);return this._nameList[e]||this._getNameFromStore(e)||""},PS.getId=function(t){return Jl(this,this.getRawIndex(t))},PS.each=function(t,e,i,n){if(this._count){"function"==typeof t&&(n=i,i=e,e=t,t=[]),t=p(Ql(t),this.getDimension,this);var a=t.length;n=n||this;for(var r=0;r<this.count();r++)switch(a){case 0:e.call(n,r);break;case 1:e.call(n,this.get(t[0],r,i),r);break;case 2:e.call(n,this.get(t[0],r,i),this.get(t[1],r,i),r);break;default:for(var o=0,s=[];a>o;o++)s[o]=this.get(t[o],r,i);s[o]=r,e.apply(n,s)}}},PS.filterSelf=function(t,e,i,n){if(this._count){"function"==typeof t&&(n=i,i=e,e=t,t=[]),i=i||!1,n=n||this,t=p(Ql(t),this.getDimension,this);for(var a=this.count(),r=Ul(this),o=new r(a),s=[],l=t.length,h=0,u=t[0],c=0;a>c;c++){var d,f=this.getRawIndex(c);if(0===l)d=e.call(n,c);else if(1===l){var g=i?this.get(u,c,!0):this._getFast(u,f);d=e.call(n,g,c)}else{for(var v=0;l>v;v++)s[v]=i?this.get(t[v],c,!0):this._getFast(u,f);s[v]=c,d=e.apply(n,s)}d&&(o[h++]=f)}return a>h&&(this._indices=o),this._count=h,this._extent={},this.getRawIndex=this._indices?Kl:$l,this}},PS.selectRange=function(t,e){if(this._count){e=e||!1;var i=[];for(var n in t)t.hasOwnProperty(n)&&i.push(n);var a=i.length;if(a){var r=this.count(),o=Ul(this),s=new o(r),l=0,h=i[0],u=t[h][0],c=t[h][1],d=!1;if(!this._indices&&!e){var f=0;if(1===a){for(var p=this._storage[i[0]],g=0;g<this._chunkCount;g++)for(var v=p[g],m=Math.min(this._count-g*this._chunkSize,this._chunkSize),y=0;m>y;y++){var x=v[y];x>=u&&c>=x&&(s[l++]=f),f++}d=!0}else if(2===a){for(var p=this._storage[h],_=this._storage[i[1]],w=t[i[1]][0],b=t[i[1]][1],g=0;g<this._chunkCount;g++)for(var v=p[g],M=_[g],m=Math.min(this._count-g*this._chunkSize,this._chunkSize),y=0;m>y;y++){var x=v[y],S=M[y];x>=u&&c>=x&&S>=w&&b>=S&&(s[l++]=f),f++}d=!0}}if(!d)if(1===a){e=e||this.isStacked(h);for(var y=0;r>y;y++){var I=this.getRawIndex(y),x=e?this.get(h,y,!0):this._getFast(h,I);x>=u&&c>=x&&(s[l++]=I)}}else for(var y=0;r>y;y++){for(var T=!0,I=this.getRawIndex(y),g=0;a>g;g++){var A=i[g],x=e?this.get(A,y,!0):this._getFast(n,I);(x<t[A][0]||x>t[A][1])&&(T=!1)}T&&(s[l++]=this.getRawIndex(y))}return r>l&&(this._indices=s),this._count=l,this._extent={},this.getRawIndex=this._indices?Kl:$l,this}}},PS.mapArray=function(t,e,i,n){"function"==typeof t&&(n=i,i=e,e=t,t=[]);var a=[];return this.each(t,function(){a.push(e&&e.apply(this,arguments))},i,n),a},PS.map=function(t,e,i,n){t=p(Ql(t),this.getDimension,this);var a=th(this,t);a._indices=this._indices,a.getRawIndex=a._indices?Kl:$l;for(var r=a._storage,o=[],s=this._chunkSize,l=t.length,h=this.count(),u=[],c=0;h>c;c++){for(var d=0;l>d;d++)u[d]=this.get(t[d],c,i);u[l]=c;var f=e&&e.apply(n,u);if(null!=f){"object"!=typeof f&&(o[0]=f,f=o);for(var g=this.getRawIndex(c),v=Math.floor(g/s),m=g%s,y=0;y<f.length;y++){var x=t[y],_=r[x];_&&(_[v][m]=f[y])}}}return a},PS.downSample=function(t,e,i,n){for(var a=th(this,[t]),r=a._storage,o=[],s=Math.floor(1/e),l=r[t],h=this.count(),u=this._chunkSize,c=new(Ul(this))(h),d=0,f=0;h>f;f+=s){s>h-f&&(s=h-f,o.length=s);for(var p=0;s>p;p++){var g=this.getRawIndex(f+p),v=Math.floor(g/u),m=g%u;o[p]=l[v][m]}var y=i(o),x=this.getRawIndex(Math.min(f+n(o,y)||0,h-1)),_=Math.floor(x/u),w=x%u;l[_][w]=y,c[d++]=x}return a._count=d,a._indices=c,a.getRawIndex=Kl,a},PS.getItemModel=function(t){var e=this.hostModel;return new Pr(this.getRawDataItem(t),e,e&&e.ecModel)},PS.diff=function(t){var e=this;return new Wl(t?t.getIndices():[],this.getIndices(),function(e){return Jl(t,e)},function(t){return Jl(e,t)})},PS.getVisual=function(t){var e=this._visual;return e&&e[t]},PS.setVisual=function(t,e){if(IS(t))for(var i in t)t.hasOwnProperty(i)&&this.setVisual(i,t[i]);else this._visual=this._visual||{},this._visual[t]=e},PS.setLayout=function(t,e){if(IS(t))for(var i in t)t.hasOwnProperty(i)&&this.setLayout(i,t[i]);else this._layout[t]=e},PS.getLayout=function(t){return this._layout[t]},PS.getItemLayout=function(t){return this._itemLayouts[t]},PS.setItemLayout=function(t,e,i){this._itemLayouts[t]=i?o(this._itemLayouts[t]||{},e):e},PS.clearItemLayouts=function(){this._itemLayouts.length=0},PS.getItemVisual=function(t,e,i){var n=this._itemVisuals[t],a=n&&n[e];return null!=a||i?a:this.getVisual(e)},PS.setItemVisual=function(t,e,i){var n=this._itemVisuals[t]||{},a=this.hasItemVisual;if(this._itemVisuals[t]=n,IS(e))for(var r in e)e.hasOwnProperty(r)&&(n[r]=e[r],a[r]=!0);else n[e]=i,a[e]=!0},PS.clearAllVisual=function(){this._visual={},this._itemVisuals=[],this.hasItemVisual={}};var OS=function(t){t.seriesIndex=this.seriesIndex,t.dataIndex=this.dataIndex,t.dataType=this.dataType};PS.setItemGraphicEl=function(t,e){var i=this.hostModel;e&&(e.dataIndex=t,e.dataType=this.dataType,e.seriesIndex=i&&i.seriesIndex,"group"===e.type&&e.traverse(OS,e)),this._graphicEls[t]=e},PS.getItemGraphicEl=function(t){return this._graphicEls[t]},PS.eachItemGraphicEl=function(t,e){f(this._graphicEls,function(i,n){i&&t&&t.call(e,i,n)})},PS.cloneShallow=function(t){if(!t){var e=p(this.dimensions,this.getDimensionInfo,this);t=new kS(e,this.hostModel)}if(t._storage=this._storage,ql(t,this),this._indices){var i=this._indices.constructor;t._indices=new i(this._indices)}else t._indices=null;return t.getRawIndex=t._indices?Kl:$l,t._extent=n(this._extent),t._approximateExtent=n(this._approximateExtent),t},PS.wrapMethod=function(t,e){var i=this[t];"function"==typeof i&&(this.__wrappedMethods=this.__wrappedMethods||[],this.__wrappedMethods.push(t),this[t]=function(){var t=i.apply(this,arguments);return e.apply(this,[t].concat(k(arguments)))})},PS.TRANSFERABLE_METHODS=["cloneShallow","downSample","map"],PS.CHANGABLE_METHODS=["filterSelf","selectRange"];var zS=function(t,e){return e=e||{},ih(e.coordDimensions||[],t,{dimsDef:e.dimensionsDefine||t.dimensionsDefine,encodeDef:e.encodeDefine||t.encodeDefine,dimCount:e.dimensionsCount,extraPrefix:e.extraPrefix,extraFromZero:e.extraFromZero})};hh.prototype.parse=function(t){return t},hh.prototype.getSetting=function(t){return this._setting[t]},hh.prototype.contain=function(t){var e=this._extent;return t>=e[0]&&t<=e[1]},hh.prototype.normalize=function(t){var e=this._extent;return e[1]===e[0]?.5:(t-e[0])/(e[1]-e[0])},hh.prototype.scale=function(t){var e=this._extent;return t*(e[1]-e[0])+e[0]},hh.prototype.unionExtent=function(t){var e=this._extent;t[0]<e[0]&&(e[0]=t[0]),t[1]>e[1]&&(e[1]=t[1])},hh.prototype.unionExtentFromData=function(t,e){this.unionExtent(t.getApproximateExtent(e,!0))},hh.prototype.getExtent=function(){return this._extent.slice()},hh.prototype.setExtent=function(t,e){var i=this._extent;isNaN(t)||(i[0]=t),isNaN(e)||(i[1]=e)},hh.prototype.getTicksLabels=function(){for(var t=[],e=this.getTicks(),i=0;i<e.length;i++)t.push(this.getLabel(e[i]));return t},hh.prototype.isBlank=function(){return this._isBlank},hh.prototype.setBlank=function(t){this._isBlank=t},qn(hh),Qn(hh,{registerWhenExtend:!0}),uh.createByAxisModel=function(t){var e=t.option,i=e.data,n=i&&p(i,dh);return new uh({categories:n,needCollect:!n,deduplication:e.dedplication!==!1})};var ES=uh.prototype;ES.getOrdinal=function(t){return ch(this).get(t)},ES.parseAndCollect=function(t){var e,i=this._needCollect;if("string"!=typeof t&&!i)return t;if(i&&!this._deduplication)return e=this.categories.length,this.categories[e]=t,e;var n=ch(this);return e=n.get(t),null==e&&(i?(e=this.categories.length,this.categories[e]=t,n.set(t,e)):e=0/0),e};var RS=hh.prototype,NS=hh.extend({type:"ordinal",init:function(t,e){(!t||_(t))&&(t=new uh({categories:t})),this._ordinalMeta=t,this._extent=e||[0,t.categories.length-1]},parse:function(t){return"string"==typeof t?this._ordinalMeta.getOrdinal(t):Math.round(t)},contain:function(t){return t=this.parse(t),RS.contain.call(this,t)&&null!=this._ordinalMeta.categories[t]},normalize:function(t){return RS.normalize.call(this,this.parse(t))},scale:function(t){return Math.round(RS.scale.call(this,t))},getTicks:function(){for(var t=[],e=this._extent,i=e[0];i<=e[1];)t.push(i),i++;return t},getLabel:function(t){return this._ordinalMeta.categories[t]},count:function(){return this._extent[1]-this._extent[0]+1},unionExtentFromData:function(t,e){this.unionExtent(t.getApproximateExtent(e,!1))},niceTicks:G,niceExtent:G});NS.create=function(){return new NS};var BS=Fr,VS=Fr,GS=hh.extend({type:"interval",_interval:0,_intervalPrecision:2,setExtent:function(t,e){var i=this._extent;isNaN(t)||(i[0]=parseFloat(t)),isNaN(e)||(i[1]=parseFloat(e))},unionExtent:function(t){var e=this._extent;t[0]<e[0]&&(e[0]=t[0]),t[1]>e[1]&&(e[1]=t[1]),GS.prototype.setExtent.call(this,e[0],e[1])},getInterval:function(){return this._interval},setInterval:function(t){this._interval=t,this._niceExtent=this._extent.slice(),this._intervalPrecision=ph(t)},getTicks:function(){return mh(this._interval,this._extent,this._niceExtent,this._intervalPrecision)},getTicksLabels:function(){for(var t=[],e=this.getTicks(),i=0;i<e.length;i++)t.push(this.getLabel(e[i]));return t},getLabel:function(t,e){if(null==t)return"";var i=e&&e.precision;return null==i?i=Zr(t)||0:"auto"===i&&(i=this._intervalPrecision),t=VS(t,i,!0),eo(t)},niceTicks:function(t,e,i){t=t||5;var n=this._extent,a=n[1]-n[0];if(isFinite(a)){0>a&&(a=-a,n.reverse());var r=fh(n,t,e,i);this._intervalPrecision=r.intervalPrecision,this._interval=r.interval,this._niceExtent=r.niceTickExtent}},niceExtent:function(t){var e=this._extent;if(e[0]===e[1])if(0!==e[0]){var i=e[0];t.fixMax?e[0]-=i/2:(e[1]+=i/2,e[0]-=i/2)}else e[1]=1;var n=e[1]-e[0];isFinite(n)||(e[0]=0,e[1]=1),this.niceTicks(t.splitNumber,t.minInterval,t.maxInterval);var a=this._interval;t.fixMin||(e[0]=VS(Math.floor(e[0]/a)*a)),t.fixMax||(e[1]=VS(Math.ceil(e[1]/a)*a))}});GS.create=function(){return new GS};var FS="__ec_stack_",WS=GS.prototype,HS=Math.ceil,ZS=Math.floor,jS=1e3,XS=60*jS,US=60*XS,YS=24*US,qS=function(t,e,i,n){for(;n>i;){var a=i+n>>>1;t[a][1]<e?i=a+1:n=a}return i},$S=GS.extend({type:"time",getLabel:function(t){var e=this._stepLvl,i=new Date(t);return so(e[0],i,this.getSetting("useUTC"))},niceExtent:function(t){var e=this._extent;if(e[0]===e[1]&&(e[0]-=YS,e[1]+=YS),e[1]===-1/0&&1/0===e[0]){var i=new Date;e[1]=+new Date(i.getFullYear(),i.getMonth(),i.getDate()),e[0]=e[1]-YS}this.niceTicks(t.splitNumber,t.minInterval,t.maxInterval);var n=this._interval;t.fixMin||(e[0]=Fr(ZS(e[0]/n)*n)),t.fixMax||(e[1]=Fr(HS(e[1]/n)*n))},niceTicks:function(t,e,i){t=t||10;var n=this._extent,a=n[1]-n[0],r=a/t;null!=e&&e>r&&(r=e),null!=i&&r>i&&(r=i);var o=KS.length,s=qS(KS,r,0,o),l=KS[Math.min(s,o-1)],h=l[1];if("year"===l[0]){var u=a/h,c=Jr(u/t,!0);h*=c}var d=this.getSetting("useUTC")?0:60*new Date(+n[0]||+n[1]).getTimezoneOffset()*1e3,f=[Math.round(HS((n[0]-d)/h)*h+d),Math.round(ZS((n[1]-d)/h)*h+d)];vh(f,n),this._stepLvl=l,this._interval=h,this._niceExtent=f},parse:function(t){return+qr(t)}});f(["contain","normalize"],function(t){$S.prototype[t]=function(e){return WS[t].call(this,this.parse(e))}});var KS=[["hh:mm:ss",jS],["hh:mm:ss",5*jS],["hh:mm:ss",10*jS],["hh:mm:ss",15*jS],["hh:mm:ss",30*jS],["hh:mm\nMM-dd",XS],["hh:mm\nMM-dd",5*XS],["hh:mm\nMM-dd",10*XS],["hh:mm\nMM-dd",15*XS],["hh:mm\nMM-dd",30*XS],["hh:mm\nMM-dd",US],["hh:mm\nMM-dd",2*US],["hh:mm\nMM-dd",6*US],["hh:mm\nMM-dd",12*US],["MM-dd\nyyyy",YS],["MM-dd\nyyyy",2*YS],["MM-dd\nyyyy",3*YS],["MM-dd\nyyyy",4*YS],["MM-dd\nyyyy",5*YS],["MM-dd\nyyyy",6*YS],["week",7*YS],["MM-dd\nyyyy",10*YS],["week",14*YS],["week",21*YS],["month",31*YS],["week",42*YS],["month",62*YS],["week",42*YS],["quarter",380*YS/4],["month",31*YS*4],["month",31*YS*5],["half-year",380*YS/2],["month",31*YS*8],["month",31*YS*10],["year",380*YS]];$S.create=function(t){return new $S({useUTC:t.ecModel.get("useUTC")})};var JS=hh.prototype,QS=GS.prototype,tI=Zr,eI=Fr,iI=Math.floor,nI=Math.ceil,aI=Math.pow,rI=Math.log,oI=hh.extend({type:"log",base:10,$constructor:function(){hh.apply(this,arguments),this._originalScale=new GS},getTicks:function(){var t=this._originalScale,e=this._extent,i=t.getExtent();return p(QS.getTicks.call(this),function(n){var a=Fr(aI(this.base,n));return a=n===e[0]&&t.__fixMin?Sh(a,i[0]):a,a=n===e[1]&&t.__fixMax?Sh(a,i[1]):a},this)},getLabel:QS.getLabel,scale:function(t){return t=JS.scale.call(this,t),aI(this.base,t)},setExtent:function(t,e){var i=this.base;t=rI(t)/rI(i),e=rI(e)/rI(i),QS.setExtent.call(this,t,e)},getExtent:function(){var t=this.base,e=JS.getExtent.call(this);e[0]=aI(t,e[0]),e[1]=aI(t,e[1]);var i=this._originalScale,n=i.getExtent();return i.__fixMin&&(e[0]=Sh(e[0],n[0])),i.__fixMax&&(e[1]=Sh(e[1],n[1])),e},unionExtent:function(t){this._originalScale.unionExtent(t);var e=this.base;t[0]=rI(t[0])/rI(e),t[1]=rI(t[1])/rI(e),JS.unionExtent.call(this,t)},unionExtentFromData:function(t,e){this.unionExtent(t.getApproximateExtent(e,!0,function(t){return t>0}))},niceTicks:function(t){t=t||10;var e=this._extent,i=e[1]-e[0];if(!(1/0===i||0>=i)){var n=$r(i),a=t/i*n;for(.5>=a&&(n*=10);!isNaN(n)&&Math.abs(n)<1&&Math.abs(n)>0;)n*=10;var r=[Fr(nI(e[0]/n)*n),Fr(iI(e[1]/n)*n)];this._interval=n,this._niceExtent=r}},niceExtent:function(t){QS.niceExtent.call(this,t);var e=this._originalScale;e.__fixMin=t.fixMin,e.__fixMax=t.fixMax}});f(["contain","normalize"],function(t){oI.prototype[t]=function(e){return e=rI(e)/rI(this.base),JS[t].call(this,e)}}),oI.create=function(){return new oI};var sI={getFormattedLabels:function(){return kh(this.axis,this.get("axisLabel.formatter"))},getMin:function(t){var e=this.option,i=t||null==e.rangeStart?e.min:e.rangeStart;return this.axis&&null!=i&&"dataMin"!==i&&"function"!=typeof i&&!A(i)&&(i=this.axis.scale.parse(i)),i},getMax:function(t){var e=this.option,i=t||null==e.rangeEnd?e.max:e.rangeEnd;return this.axis&&null!=i&&"dataMax"!==i&&"function"!=typeof i&&!A(i)&&(i=this.axis.scale.parse(i)),i},getNeedCrossZero:function(){var t=this.option;return null!=t.rangeStart||null!=t.rangeEnd?!1:!t.scale},getCoordSysModel:G,setRange:function(t,e){this.option.rangeStart=t,this.option.rangeEnd=e},resetRange:function(){this.option.rangeStart=this.option.rangeEnd=null}},lI=Za({type:"triangle",shape:{cx:0,cy:0,width:0,height:0},buildPath:function(t,e){var i=e.cx,n=e.cy,a=e.width/2,r=e.height/2;t.moveTo(i,n-r),t.lineTo(i+a,n+r),t.lineTo(i-a,n+r),t.closePath()}}),hI=Za({type:"diamond",shape:{cx:0,cy:0,width:0,height:0},buildPath:function(t,e){var i=e.cx,n=e.cy,a=e.width/2,r=e.height/2;t.moveTo(i,n-r),t.lineTo(i+a,n),t.lineTo(i,n+r),t.lineTo(i-a,n),t.closePath()}}),uI=Za({type:"pin",shape:{x:0,y:0,width:0,height:0},buildPath:function(t,e){var i=e.x,n=e.y,a=e.width/5*3,r=Math.max(a,e.height),o=a/2,s=o*o/(r-o),l=n-r+o+s,h=Math.asin(s/o),u=Math.cos(h)*o,c=Math.sin(h),d=Math.cos(h),f=.6*o,p=.7*o;t.moveTo(i-u,l+s),t.arc(i,l,o,Math.PI-h,2*Math.PI+h),t.bezierCurveTo(i+u-c*f,l+s+d*f,i,n-p,i,n),t.bezierCurveTo(i,n-p,i-u+c*f,l+s+d*f,i-u,l+s),t.closePath()}}),cI=Za({type:"arrow",shape:{x:0,y:0,width:0,height:0},buildPath:function(t,e){var i=e.height,n=e.width,a=e.x,r=e.y,o=n/3*2;t.moveTo(a,r),t.lineTo(a+o,r+i),t.lineTo(a,r+i/4*3),t.lineTo(a-o,r+i),t.lineTo(a,r),t.closePath()}}),dI={line:Hw,rect:Ww,roundRect:Ww,square:Ww,circle:Ow,diamond:hI,pin:uI,arrow:cI,triangle:lI},fI={line:function(t,e,i,n,a){a.x1=t,a.y1=e+n/2,a.x2=t+i,a.y2=e+n/2},rect:function(t,e,i,n,a){a.x=t,a.y=e,a.width=i,a.height=n},roundRect:function(t,e,i,n,a){a.x=t,a.y=e,a.width=i,a.height=n,a.r=Math.min(i,n)/4},square:function(t,e,i,n,a){var r=Math.min(i,n);a.x=t,a.y=e,a.width=r,a.height=r},circle:function(t,e,i,n,a){a.cx=t+i/2,a.cy=e+n/2,a.r=Math.min(i,n)/2},diamond:function(t,e,i,n,a){a.cx=t+i/2,a.cy=e+n/2,a.width=i,a.height=n},pin:function(t,e,i,n,a){a.x=t+i/2,a.y=e+n/2,a.width=i,a.height=n
-},arrow:function(t,e,i,n,a){a.x=t+i/2,a.y=e+n/2,a.width=i,a.height=n},triangle:function(t,e,i,n,a){a.cx=t+i/2,a.cy=e+n/2,a.width=i,a.height=n}},pI={};f(dI,function(t,e){pI[e]=new t});var gI=Za({type:"symbol",shape:{symbolType:"",x:0,y:0,width:0,height:0},beforeBrush:function(){var t=this.style,e=this.shape;"pin"===e.symbolType&&"inside"===t.textPosition&&(t.textPosition=["50%","40%"],t.textAlign="center",t.textVerticalAlign="middle")},buildPath:function(t,e,i){var n=e.symbolType,a=pI[n];"none"!==e.symbolType&&(a||(n="rect",a=pI[n]),fI[n](e.x,e.y,e.width,e.height,a.shape),a.buildPath(t,a.shape,i))}}),vI=(Object.freeze||Object)({createList:Eh,getLayoutRect:uo,createScale:Rh,mixinAxisModelCommonMethods:Nh,completeDimensions:ih,createDimensions:zS,createSymbol:zh}),mI=1e-8;Gh.prototype={constructor:Gh,properties:null,getBoundingRect:function(){var t=this._rect;if(t)return t;for(var e=Number.MAX_VALUE,i=[e,e],n=[-e,-e],a=[],r=[],o=this.geometries,s=0;s<o.length;s++)if("polygon"===o[s].type){var l=o[s].exterior;pa(l,a,r),oe(i,i,a),se(n,n,r)}return 0===s&&(i[0]=i[1]=n[0]=n[1]=0),this._rect=new ni(i[0],i[1],n[0]-i[0],n[1]-i[1])},contain:function(t){var e=this.getBoundingRect(),i=this.geometries;if(!e.contain(t[0],t[1]))return!1;t:for(var n=0,a=i.length;a>n;n++)if("polygon"===i[n].type){var r=i[n].exterior,o=i[n].interiors;if(Vh(r,t[0],t[1])){for(var s=0;s<(o?o.length:0);s++)if(Vh(o[s]))continue t;return!0}}return!1},transformTo:function(t,e,i,n){var a=this.getBoundingRect(),r=a.width/a.height;i?n||(n=i/r):i=r*n;for(var o=new ni(t,e,i,n),s=a.calculateTransform(o),l=this.geometries,h=0;h<l.length;h++)if("polygon"===l[h].type){for(var u=l[h].exterior,c=l[h].interiors,d=0;d<u.length;d++)re(u[d],u[d],s);for(var f=0;f<(c?c.length:0);f++)for(var d=0;d<c[f].length;d++)re(c[f][d],c[f][d],s)}a=this._rect,a.copy(o),this.center=[a.x+a.width/2,a.y+a.height/2]}};var yI=function(t){return Fh(t),p(v(t.features,function(t){return t.geometry&&t.properties&&t.geometry.coordinates.length>0}),function(t){var e=t.properties,i=t.geometry,n=i.coordinates,a=[];"Polygon"===i.type&&a.push({type:"polygon",exterior:n[0],interiors:n.slice(1)}),"MultiPolygon"===i.type&&f(n,function(t){t[0]&&a.push({type:"polygon",exterior:t[0],interiors:t.slice(1)})});var r=new Gh(e.name,a,e.cp);return r.properties=e,r})},xI=Vr,_I=[0,1],wI=function(t,e,i){this.dim=t,this.scale=e,this._extent=i||[0,0],this.inverse=!1,this.onBand=!1,this._labelInterval};wI.prototype={constructor:wI,contain:function(t){var e=this._extent,i=Math.min(e[0],e[1]),n=Math.max(e[0],e[1]);return t>=i&&n>=t},containData:function(t){return this.contain(this.dataToCoord(t))},getExtent:function(){return this._extent.slice()},getPixelPrecision:function(t){return jr(t||this.scale.getExtent(),this._extent)},setExtent:function(t,e){var i=this._extent;i[0]=t,i[1]=e},dataToCoord:function(t,e){var i=this._extent,n=this.scale;return t=n.normalize(t),this.onBand&&"ordinal"===n.type&&(i=i.slice(),Hh(i,n.count())),xI(t,_I,i,e)},coordToData:function(t,e){var i=this._extent,n=this.scale;this.onBand&&"ordinal"===n.type&&(i=i.slice(),Hh(i,n.count()));var a=xI(t,i,_I,e);return this.scale.scale(a)},pointToData:function(){},getTicksCoords:function(t){if(this.onBand&&!t){for(var e=this.getBands(),i=[],n=0;n<e.length;n++)i.push(e[n][0]);return e[n-1]&&i.push(e[n-1][1]),i}return p(this.scale.getTicks(),this.dataToCoord,this)},getLabelsCoords:function(){return p(this.scale.getTicks(),this.dataToCoord,this)},getBands:function(){for(var t=this.getExtent(),e=[],i=this.scale.count(),n=t[0],a=t[1],r=a-n,o=0;i>o;o++)e.push([r*o/i+n,r*(o+1)/i+n]);return e},getBandWidth:function(){var t=this._extent,e=this.scale.getExtent(),i=e[1]-e[0]+(this.onBand?1:0);0===i&&(i=1);var n=Math.abs(t[1]-t[0]);return Math.abs(n)/i},isHorizontal:null,getRotate:null,getLabelInterval:function(){var t=this._labelInterval;if(!t){var e=this.model,i=e.getModel("axisLabel");t=i.get("interval"),"category"!==this.type||null!=t&&"auto"!==t||(t=Lh(p(this.scale.getTicks(),this.dataToCoord,this),e.getFormattedLabels(),i.getFont(),this.getRotate?this.getRotate():this.isHorizontal&&!this.isHorizontal()?90:0,i.get("rotate"))),this._labelInterval=t}return t}};var bI=yI,MI={};f(["map","each","filter","indexOf","inherits","reduce","filter","bind","curry","isArray","isString","isObject","isFunction","extend","defaults","clone","merge"],function(t){MI[t]=Ly[t]});var SI=function(t){this._axes={},this._dimList=[],this.name=t||""};SI.prototype={constructor:SI,type:"cartesian",getAxis:function(t){return this._axes[t]},getAxes:function(){return p(this._dimList,Zh,this)},getAxesByScale:function(t){return t=t.toLowerCase(),v(this.getAxes(),function(e){return e.scale.type===t})},addAxis:function(t){var e=t.dim;this._axes[e]=t,this._dimList.push(e)},dataToCoord:function(t){return this._dataCoordConvert(t,"dataToCoord")},coordToData:function(t){return this._dataCoordConvert(t,"coordToData")},_dataCoordConvert:function(t,e){for(var i=this._dimList,n=t instanceof Array?[]:{},a=0;a<i.length;a++){var r=i[a],o=this._axes[r];n[r]=o[e](t[r])}return n}},jh.prototype={constructor:jh,type:"cartesian2d",dimensions:["x","y"],getBaseAxis:function(){return this.getAxesByScale("ordinal")[0]||this.getAxesByScale("time")[0]||this.getAxis("x")},containPoint:function(t){var e=this.getAxis("x"),i=this.getAxis("y");return e.contain(e.toLocalCoord(t[0]))&&i.contain(i.toLocalCoord(t[1]))},containData:function(t){return this.getAxis("x").containData(t[0])&&this.getAxis("y").containData(t[1])},dataToPoint:function(t,e,i){var n=this.getAxis("x"),a=this.getAxis("y");return i=i||[],i[0]=n.toGlobalCoord(n.dataToCoord(t[0])),i[1]=a.toGlobalCoord(a.dataToCoord(t[1])),i},clampData:function(t,e){var i=this.getAxis("x").scale.getExtent(),n=this.getAxis("y").scale.getExtent();return e=e||[],e[0]=Math.min(Math.max(Math.min(i[0],i[1]),t[0]),Math.max(i[0],i[1])),e[1]=Math.min(Math.max(Math.min(n[0],n[1]),t[1]),Math.max(n[0],n[1])),e},pointToData:function(t,e){var i=this.getAxis("x"),n=this.getAxis("y");return e=e||[],e[0]=i.coordToData(i.toLocalCoord(t[0])),e[1]=n.coordToData(n.toLocalCoord(t[1])),e},getOtherAxis:function(t){return this.getAxis("x"===t.dim?"y":"x")}},u(jh,SI);var II=function(t,e,i,n,a){wI.call(this,t,e,i),this.type=n||"value",this.position=a||"bottom"};II.prototype={constructor:II,index:0,onZero:!1,model:null,isHorizontal:function(){var t=this.position;return"top"===t||"bottom"===t},getGlobalExtent:function(t){var e=this.getExtent();return e[0]=this.toGlobalCoord(e[0]),e[1]=this.toGlobalCoord(e[1]),t&&e[0]>e[1]&&e.reverse(),e},getOtherAxis:function(){this.grid.getOtherAxis()},isLabelIgnored:function(t){if("category"===this.type){var e=this.getLabelInterval();return"function"==typeof e&&!e(t,this.scale.getLabel(t))||t%(e+1)}},pointToData:function(t,e){return this.coordToData(this.toLocalCoord(t["x"===this.dim?0:1]),e)},toLocalCoord:null,toGlobalCoord:null},u(II,wI);var TI={show:!0,zlevel:0,z:0,inverse:!1,name:"",nameLocation:"end",nameRotate:null,nameTruncate:{maxWidth:null,ellipsis:"...",placeholder:"."},nameTextStyle:{},nameGap:15,silent:!1,triggerEvent:!1,tooltip:{show:!1},axisPointer:{},axisLine:{show:!0,onZero:!0,onZeroAxisIndex:null,lineStyle:{color:"#333",width:1,type:"solid"},symbol:["none","none"],symbolSize:[10,15]},axisTick:{show:!0,inside:!1,length:5,lineStyle:{width:1}},axisLabel:{show:!0,inside:!1,rotate:0,showMinLabel:null,showMaxLabel:null,margin:8,fontSize:12},splitLine:{show:!0,lineStyle:{color:["#ccc"],width:1,type:"solid"}},splitArea:{show:!1,areaStyle:{color:["rgba(250,250,250,0.3)","rgba(200,200,200,0.3)"]}}},AI={};AI.categoryAxis=a({boundaryGap:!0,deduplication:null,splitLine:{show:!1},axisTick:{alignWithLabel:!1,interval:"auto"},axisLabel:{interval:"auto"}},TI),AI.valueAxis=a({boundaryGap:[0,0],splitNumber:5},TI),AI.timeAxis=s({scale:!0,min:"dataMin",max:"dataMax"},AI.valueAxis),AI.logAxis=s({scale:!0,logBase:10},AI.valueAxis);var CI=["value","category","time","log"],DI=function(t,e,i,n){f(CI,function(o){e.extend({type:t+"Axis."+o,mergeDefaultAndTheme:function(e,n){var r=this.layoutMode,s=r?go(e):{},l=n.getTheme();a(e,l.get(o+"Axis")),a(e,this.getDefaultOption()),e.type=i(t,e),r&&po(e,s,r)},optionUpdated:function(){var t=this.option;"category"===t.type&&(this.__ordinalMeta=uh.createByAxisModel(this))},getCategories:function(){return"category"===this.option.type?this.__ordinalMeta.categories:void 0},getOrdinalMeta:function(){return this.__ordinalMeta},defaultOption:r([{},AI[o+"Axis"],n],!0)})}),Cb.registerSubTypeDefaulter(t+"Axis",x(i,t))},LI=Cb.extend({type:"cartesian2dAxis",axis:null,init:function(){LI.superApply(this,"init",arguments),this.resetRange()},mergeOption:function(){LI.superApply(this,"mergeOption",arguments),this.resetRange()},restoreData:function(){LI.superApply(this,"restoreData",arguments),this.resetRange()},getCoordSysModel:function(){return this.ecModel.queryComponents({mainType:"grid",index:this.option.gridIndex,id:this.option.gridId})[0]}});a(LI.prototype,sI);var kI={offset:0};DI("x",LI,Xh,kI),DI("y",LI,Xh,kI),Cb.extend({type:"grid",dependencies:["xAxis","yAxis"],layoutMode:"box",coordinateSystem:null,defaultOption:{show:!1,zlevel:0,z:0,left:"10%",top:60,right:"10%",bottom:60,containLabel:!1,backgroundColor:"rgba(0,0,0,0)",borderWidth:1,borderColor:"#ccc"}});var PI=f,OI=Dh,zI=Ah,EI=$h.prototype;EI.type="grid",EI.axisPointerEnabled=!0,EI.getRect=function(){return this._rect},EI.update=function(t,e){var i=this._axesMap;this._updateScale(t,this.model),PI(i.x,function(t){zI(t.scale,t.model)}),PI(i.y,function(t){zI(t.scale,t.model)}),PI(i.x,function(t){Kh(i,"y",t)}),PI(i.y,function(t){Kh(i,"x",t)}),this.resize(this.model,e)},EI.resize=function(t,e,i){function n(){PI(r,function(t){var e=t.isHorizontal(),i=e?[0,a.width]:[0,a.height],n=t.inverse?1:0;t.setExtent(i[n],i[1-n]),Qh(t,e?a.x:a.y)})}var a=uo(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()});this._rect=a;var r=this._axesList;n(),!i&&t.get("containLabel")&&(PI(r,function(t){if(!t.model.get("axisLabel.inside")){var e=qh(t);if(e){var i=t.isHorizontal()?"height":"width",n=t.model.get("axisLabel.margin");a[i]-=e[i]+n,"top"===t.position?a.y+=e.height+n:"left"===t.position&&(a.x+=e.width+n)}}}),n())},EI.getAxis=function(t,e){var i=this._axesMap[t];if(null!=i){if(null==e)for(var n in i)if(i.hasOwnProperty(n))return i[n];return i[e]}},EI.getAxes=function(){return this._axesList.slice()},EI.getCartesian=function(t,e){if(null!=t&&null!=e){var i="x"+t+"y"+e;return this._coordsMap[i]}M(t)&&(e=t.yAxisIndex,t=t.xAxisIndex);for(var n=0,a=this._coordsList;n<a.length;n++)if(a[n].getAxis("x").index===t||a[n].getAxis("y").index===e)return a[n]},EI.getCartesians=function(){return this._coordsList.slice()},EI.convertToPixel=function(t,e,i){var n=this._findConvertTarget(t,e);return n.cartesian?n.cartesian.dataToPoint(i):n.axis?n.axis.toGlobalCoord(n.axis.dataToCoord(i)):null},EI.convertFromPixel=function(t,e,i){var n=this._findConvertTarget(t,e);return n.cartesian?n.cartesian.pointToData(i):n.axis?n.axis.coordToData(n.axis.toLocalCoord(i)):null},EI._findConvertTarget=function(t,e){var i,n,a=e.seriesModel,r=e.xAxisModel||a&&a.getReferringComponents("xAxis")[0],o=e.yAxisModel||a&&a.getReferringComponents("yAxis")[0],s=e.gridModel,l=this._coordsList;if(a)i=a.coordinateSystem,h(l,i)<0&&(i=null);else if(r&&o)i=this.getCartesian(r.componentIndex,o.componentIndex);else if(r)n=this.getAxis("x",r.componentIndex);else if(o)n=this.getAxis("y",o.componentIndex);else if(s){var u=s.coordinateSystem;u===this&&(i=this._coordsList[0])}return{cartesian:i,axis:n}},EI.containPoint=function(t){var e=this._coordsList[0];return e?e.containPoint(t):void 0},EI._initCartesian=function(t,e){function i(i){return function(o,s){if(Uh(o,t,e)){var l=o.get("position");"x"===i?"top"!==l&&"bottom"!==l&&(l="bottom",n[l]&&(l="top"===l?"bottom":"top")):"left"!==l&&"right"!==l&&(l="left",n[l]&&(l="left"===l?"right":"left")),n[l]=!0;var h=new II(i,Ch(o),[0,0],o.get("type"),l),u="category"===h.type;h.onBand=u&&o.get("boundaryGap"),h.inverse=o.get("inverse"),h.onZero=o.get("axisLine.onZero"),h.onZeroAxisIndex=o.get("axisLine.onZeroAxisIndex"),o.axis=h,h.model=o,h.grid=this,h.index=s,this._axesList.push(h),a[i][s]=h,r[i]++}}}var n={left:!1,right:!1,top:!1,bottom:!1},a={x:{},y:{}},r={x:0,y:0};return e.eachComponent("xAxis",i("x"),this),e.eachComponent("yAxis",i("y"),this),r.x&&r.y?(this._axesMap=a,void PI(a.x,function(e,i){PI(a.y,function(n,a){var r="x"+i+"y"+a,o=new jh(r);o.grid=this,o.model=t,this._coordsMap[r]=o,this._coordsList.push(o),o.addAxis(e),o.addAxis(n)},this)},this)):(this._axesMap={},void(this._axesList=[]))},EI._updateScale=function(t,e){function i(t,e){PI(t.mapDimension(e.dim,!0),function(i){e.scale.unionExtentFromData(t,i)})}f(this._axesList,function(t){t.scale.setExtent(1/0,-1/0)}),t.eachSeries(function(n){if(eu(n)){var a=tu(n,t),r=a[0],o=a[1];if(!Uh(r,e,t)||!Uh(o,e,t))return;var s=this.getCartesian(r.componentIndex,o.componentIndex),l=n.getData(),h=s.getAxis("x"),u=s.getAxis("y");"list"===l.type&&(i(l,h,n),i(l,u,n))}},this)},EI.getTooltipAxes=function(t){var e=[],i=[];return PI(this.getCartesians(),function(n){var a=null!=t&&"auto"!==t?n.getAxis(t):n.getBaseAxis(),r=n.getOtherAxis(a);h(e,a)<0&&e.push(a),h(i,r)<0&&i.push(r)}),{baseAxes:e,otherAxes:i}};var RI=["xAxis","yAxis"];$h.create=function(t,e){var i=[];return t.eachComponent("grid",function(n,a){var r=new $h(n,t,e);r.name="grid_"+a,r.resize(n,e,!0),n.coordinateSystem=r,i.push(r)}),t.eachSeries(function(e){if(eu(e)){var i=tu(e,t),n=i[0],a=i[1],r=n.getCoordSysModel(),o=r.coordinateSystem;e.coordinateSystem=o.getCartesian(n.componentIndex,a.componentIndex)}}),i},$h.dimensions=$h.prototype.dimensions=jh.prototype.dimensions,Fo.register("cartesian2d",$h);var NI=fM.extend({type:"series.__base_bar__",getInitialData:function(){return rh(this.getSource(),this)},getMarkerPosition:function(t){var e=this.coordinateSystem;if(e){var i=e.dataToPoint(e.clampData(t)),n=this.getData(),a=n.getLayout("offset"),r=n.getLayout("size"),o=e.getBaseAxis().isHorizontal()?0:1;return i[o]+=a+r/2,i}return[0/0,0/0]},defaultOption:{zlevel:0,z:2,coordinateSystem:"cartesian2d",legendHoverLink:!0,barMinHeight:0,barMinAngle:0,itemStyle:{},emphasis:{}}});NI.extend({type:"series.bar",dependencies:["grid","polar"],brushSelector:"rect"});var BI=T_([["fill","color"],["stroke","borderColor"],["lineWidth","borderWidth"],["stroke","barBorderColor"],["lineWidth","barBorderWidth"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"]]),VI={getBarItemStyle:function(t){var e=BI(this,t);if(this.getBorderLineDash){var i=this.getBorderLineDash();i&&(e.lineDash=i)}return e}},GI=["itemStyle","barBorderWidth"];o(Pr.prototype,VI),Nl({type:"bar",render:function(t,e,i){var n=t.get("coordinateSystem");return("cartesian2d"===n||"polar"===n)&&this._render(t,e,i),this.group},dispose:G,_render:function(t){var e,i=this.group,n=t.getData(),a=this._data,r=t.coordinateSystem,o=r.getBaseAxis();"cartesian2d"===r.type?e=o.isHorizontal():"polar"===r.type&&(e="angle"===o.dim);var s=t.isAnimationEnabled()?t:null;n.diff(a).add(function(a){if(n.hasValue(a)){var o=n.getItemModel(a),l=WI[r.type](n,a,o),h=FI[r.type](n,a,o,l,e,s);n.setItemGraphicEl(a,h),i.add(h),su(h,n,a,o,l,t,e,"polar"===r.type)}}).update(function(o,l){var h=a.getItemGraphicEl(l);if(!n.hasValue(o))return void i.remove(h);var u=n.getItemModel(o),c=WI[r.type](n,o,u);h?Mr(h,{shape:c},s,o):h=FI[r.type](n,o,u,c,e,s,!0),n.setItemGraphicEl(o,h),i.add(h),su(h,n,o,u,c,t,e,"polar"===r.type)}).remove(function(t){var e=a.getItemGraphicEl(t);"cartesian2d"===r.type?e&&ru(t,s,e):e&&ou(t,s,e)}).execute(),this._data=n},remove:function(t){var e=this.group,i=this._data;t.get("animation")?i&&i.eachItemGraphicEl(function(e){"sector"===e.type?ou(e.dataIndex,t,e):ru(e.dataIndex,t,e)}):e.removeAll()}});var FI={cartesian2d:function(t,e,i,n,a,r,s){var l=new Ww({shape:o({},n)});if(r){var h=l.shape,u=a?"height":"width",c={};h[u]=0,c[u]=n[u],nb[s?"updateProps":"initProps"](l,{shape:c},r,e)}return l},polar:function(t,e,i,n,a,r,s){var l=new Rw({shape:o({},n)});if(r){var h=l.shape,u=a?"r":"endAngle",c={};h[u]=a?0:n.startAngle,c[u]=n[u],nb[s?"updateProps":"initProps"](l,{shape:c},r,e)}return l}},WI={cartesian2d:function(t,e,i){var n=t.getItemLayout(e),a=lu(i,n),r=n.width>0?1:-1,o=n.height>0?1:-1;return{x:n.x+r*a/2,y:n.y+o*a/2,width:n.width-r*a,height:n.height-o*a}},polar:function(t,e){var i=t.getItemLayout(e);return{cx:i.cx,cy:i.cy,r0:i.r0,r:i.r,startAngle:i.startAngle,endAngle:i.endAngle}}},HI=Math.PI,ZI=function(t,e){this.opt=e,this.axisModel=t,s(e,{labelOffset:0,nameDirection:1,tickDirection:1,labelDirection:1,silent:!0}),this.group=new xx;var i=new xx({position:e.position.slice(),rotation:e.rotation});i.updateTransform(),this._transform=i.transform,this._dumbGroup=i};ZI.prototype={constructor:ZI,hasBuilder:function(t){return!!jI[t]},add:function(t){jI[t].call(this)},getGroup:function(){return this.group}};var jI={axisLine:function(){var t=this.opt,e=this.axisModel;if(e.get("axisLine.show")){var i=this.axisModel.axis.getExtent(),n=this._transform,a=[i[0],0],r=[i[1],0];n&&(re(a,a,n),re(r,r,n));var s=o({lineCap:"round"},e.getModel("axisLine.lineStyle").getLineStyle());this.group.add(new Hw($a({anid:"line",shape:{x1:a[0],y1:a[1],x2:r[0],y2:r[1]},style:s,strokeContainThreshold:t.strokeContainThreshold||5,silent:!0,z2:1})));var l=e.get("axisLine.symbol"),h=e.get("axisLine.symbolSize");if(null!=l){"string"==typeof l&&(l=[l,l]),("string"==typeof h||"number"==typeof h)&&(h=[h,h]);var u=h[0],c=h[1];f([[t.rotation+Math.PI/2,a],[t.rotation-Math.PI/2,r]],function(t,e){if("none"!==l[e]&&null!=l[e]){var i=zh(l[e],-u/2,-c/2,u,c,s.stroke,!0);i.attr({rotation:t[0],position:t[1],silent:!0}),this.group.add(i)}},this)}}},axisTickLabel:function(){var t=this.axisModel,e=this.opt,i=vu(this,t,e),n=mu(this,t,e);du(t,n,i)},axisName:function(){var t=this.opt,e=this.axisModel,i=C(t.axisName,e.get("name"));if(i){var n,a=e.get("nameLocation"),r=t.nameDirection,s=e.getModel("nameTextStyle"),l=e.get("nameGap")||0,h=this.axisModel.axis.getExtent(),u=h[0]>h[1]?-1:1,c=["start"===a?h[0]-u*l:"end"===a?h[1]+u*l:(h[0]+h[1])/2,gu(a)?t.labelOffset+r*l:0],d=e.get("nameRotate");null!=d&&(d=d*HI/180);var f;gu(a)?n=XI(t.rotation,null!=d?d:t.rotation,r):(n=uu(t,a,d||0,h),f=t.axisNameAvailableWidth,null!=f&&(f=Math.abs(f/Math.sin(n.rotation)),!isFinite(f)&&(f=null)));var p=s.getFont(),g=e.get("nameTruncate",!0)||{},v=g.ellipsis,m=C(t.nameTruncateMaxWidth,g.maxWidth,f),y=null!=v&&null!=m?xb(i,m,p,v,{minChar:2,placeholder:g.placeholder}):i,x=e.get("tooltip",!0),_=e.mainType,w={componentType:_,name:i,$vars:["name"]};w[_+"Index"]=e.componentIndex;var b=new Pw({anid:"name",__fullText:i,__truncatedText:y,position:c,rotation:n.rotation,silent:cu(e),z2:1,tooltip:x&&x.show?o({content:i,formatter:function(){return i},formatterParams:w},x):null});fr(b.style,s,{text:y,textFont:p,textFill:s.getTextColor()||e.get("axisLine.lineStyle.color"),textAlign:n.textAlign,textVerticalAlign:n.textVerticalAlign}),e.get("triggerEvent")&&(b.eventData=hu(e),b.eventData.targetType="axisName",b.eventData.name=i),this._dumbGroup.add(b),b.updateTransform(),this.group.add(b),b.decomposeTransform()}}},XI=ZI.innerTextLayout=function(t,e,i){var n,a,r=Ur(e-t);return Yr(r)?(a=i>0?"top":"bottom",n="center"):Yr(r-HI)?(a=i>0?"bottom":"top",n="center"):(a="middle",n=r>0&&HI>r?i>0?"right":"left":i>0?"left":"right"),{rotation:r,textAlign:n,textVerticalAlign:a}},UI=ZI.ifIgnoreOnTick=function(t,e,i,n,a,r){if(0===e&&a||e===n-1&&r)return!1;var o,s=t.scale;return"ordinal"===s.type&&("function"==typeof i?(o=s.getTicks()[e],!i(o,s.getLabel(o))):e%(i+1))},YI=ZI.getInterval=function(t,e){var i=t.get("interval");return(null==i||"auto"==i)&&(i=e),i},qI=f,$I=x,KI=El({type:"axis",_axisPointer:null,axisPointerClass:null,render:function(t,e,i,n){this.axisPointerClass&&Su(t),KI.superApply(this,"render",arguments),Du(this,t,e,i,n,!0)},updateAxisPointer:function(t,e,i,n){Du(this,t,e,i,n,!1)},remove:function(t,e){var i=this._axisPointer;i&&i.remove(e),KI.superApply(this,"remove",arguments)},dispose:function(t,e){Lu(this,e),KI.superApply(this,"dispose",arguments)}}),JI=[];KI.registerAxisPointerClass=function(t,e){JI[t]=e},KI.getAxisPointerClass=function(t){return t&&JI[t]};var QI=ZI.ifIgnoreOnTick,tT=ZI.getInterval,eT=["axisLine","axisTickLabel","axisName"],iT=["splitArea","splitLine"],nT=KI.extend({type:"cartesianAxis",axisPointerClass:"CartesianAxisPointer",render:function(t,e,i,n){this.group.removeAll();var a=this._axisGroup;if(this._axisGroup=new xx,this.group.add(this._axisGroup),t.get("show")){var r=t.getCoordSysModel(),o=ku(r,t),s=new ZI(t,o);f(eT,s.add,s),this._axisGroup.add(s.getGroup()),f(iT,function(e){t.get(e+".show")&&this["_"+e](t,r,o.labelInterval)},this),Cr(a,this._axisGroup,t),nT.superCall(this,"render",t,e,i,n)}},_splitLine:function(t,e,i){var n=t.axis;if(!n.scale.isBlank()){var a=t.getModel("splitLine"),r=a.getModel("lineStyle"),o=r.get("color"),l=tT(a,i);o=_(o)?o:[o];for(var h=e.coordinateSystem.getRect(),u=n.isHorizontal(),c=0,d=n.getTicksCoords(),f=n.scale.getTicks(),p=t.get("axisLabel.showMinLabel"),g=t.get("axisLabel.showMaxLabel"),v=[],m=[],y=r.getLineStyle(),x=0;x<d.length;x++)if(!QI(n,x,l,d.length,p,g)){var w=n.toGlobalCoord(d[x]);u?(v[0]=w,v[1]=h.y,m[0]=w,m[1]=h.y+h.height):(v[0]=h.x,v[1]=w,m[0]=h.x+h.width,m[1]=w);var b=c++%o.length;this._axisGroup.add(new Hw($a({anid:"line_"+f[x],shape:{x1:v[0],y1:v[1],x2:m[0],y2:m[1]},style:s({stroke:o[b]},y),silent:!0})))}}},_splitArea:function(t,e,i){var n=t.axis;if(!n.scale.isBlank()){var a=t.getModel("splitArea"),r=a.getModel("areaStyle"),o=r.get("color"),l=e.coordinateSystem.getRect(),h=n.getTicksCoords(),u=n.scale.getTicks(),c=n.toGlobalCoord(h[0]),d=n.toGlobalCoord(h[0]),f=0,p=tT(a,i),g=r.getAreaStyle();o=_(o)?o:[o];for(var v=t.get("axisLabel.showMinLabel"),m=t.get("axisLabel.showMaxLabel"),y=1;y<h.length;y++)if(!QI(n,y,p,h.length,v,m)){var x,w,b,M,S=n.toGlobalCoord(h[y]);n.isHorizontal()?(x=c,w=l.y,b=S-x,M=l.height):(x=l.x,w=d,b=l.width,M=S-w);var I=f++%o.length;this._axisGroup.add(new Ww({anid:"area_"+u[y],shape:{x:x,y:w,width:b,height:M},style:s({fill:o[I]},g),silent:!0})),c=x+b,d=w+M}}}});nT.extend({type:"xAxis"}),nT.extend({type:"yAxis"}),El({type:"grid",render:function(t){this.group.removeAll(),t.get("show")&&this.group.add(new Ww({shape:t.coordinateSystem.getRect(),style:s({fill:t.get("backgroundColor")},t.getItemStyle()),silent:!0,z2:-1}))}}),Sl(function(t){t.xAxis&&t.yAxis&&!t.grid&&(t.grid={})}),Ll(x(Mh,"bar")),kl(function(t){t.eachSeriesByType("bar",function(t){var e=t.getData();e.setVisual("legendSymbol","roundRect")})}),fM.extend({type:"series.line",dependencies:["grid","polar"],getInitialData:function(){return rh(this.getSource(),this)},defaultOption:{zlevel:0,z:2,coordinateSystem:"cartesian2d",legendHoverLink:!0,hoverAnimation:!0,clipOverflow:!0,label:{position:"top"},lineStyle:{width:2,type:"solid"},step:!1,smooth:!1,smoothMonotone:null,symbol:"emptyCircle",symbolSize:4,symbolRotate:null,showSymbol:!0,showAllSymbol:!1,connectNulls:!1,sampling:"none",animationEasing:"linear",progressive:0,hoverLayerThreshold:1/0}});var aT=zu.prototype;aT._createSymbol=function(t,e,i,n){this.removeAll();var a=e.getItemVisual(i,"color"),r=zh(t,-1,-1,2,2,a);r.attr({z2:100,culling:!0,scale:Ou(n)}),r.drift=Eu,this._symbolType=t,this.add(r)},aT.stopSymbolAnimation=function(t){this.childAt(0).stopAnimation(t)},aT.getSymbolPath=function(){return this.childAt(0)},aT.getScale=function(){return this.childAt(0).scale},aT.highlight=function(){this.childAt(0).trigger("emphasis")},aT.downplay=function(){this.childAt(0).trigger("normal")},aT.setZ=function(t,e){var i=this.childAt(0);i.zlevel=t,i.z=e},aT.setDraggable=function(t){var e=this.childAt(0);e.draggable=t,e.cursor=t?"move":"pointer"},aT.updateData=function(t,e,i){this.silent=!1;var n=t.getItemVisual(e,"symbol")||"circle",a=t.hostModel,r=Pu(t,e),o=n!==this._symbolType;if(o)this._createSymbol(n,t,e,r);else{var s=this.childAt(0);s.silent=!1,Mr(s,{scale:Ou(r)},a,e)}if(this._updateCommon(t,e,r,i),o){var s=this.childAt(0),l=i&&i.fadeIn,h={scale:s.scale.slice()};l&&(h.style={opacity:s.style.opacity}),s.scale=[0,0],l&&(s.style.opacity=0),Sr(s,h,a,e)}this._seriesModel=a};var rT=["itemStyle"],oT=["emphasis","itemStyle"],sT=["label"],lT=["emphasis","label"];aT._updateCommon=function(t,e,i,n){function a(e){return _?t.getName(e):iu(t,e)}var r=this.childAt(0),s=t.hostModel,l=t.getItemVisual(e,"color");"image"!==r.type&&r.useStyle({strokeNoScale:!0});var h=n&&n.itemStyle,u=n&&n.hoverItemStyle,c=n&&n.symbolRotate,d=n&&n.symbolOffset,f=n&&n.labelModel,p=n&&n.hoverLabelModel,g=n&&n.hoverAnimation,v=n&&n.cursorStyle;if(!n||t.hasItemOption){var m=n&&n.itemModel?n.itemModel:t.getItemModel(e);h=m.getModel(rT).getItemStyle(["color"]),u=m.getModel(oT).getItemStyle(),c=m.getShallow("symbolRotate"),d=m.getShallow("symbolOffset"),f=m.getModel(sT),p=m.getModel(lT),g=m.getShallow("hoverAnimation"),v=m.getShallow("cursor")}else u=o({},u);var y=r.style;r.attr("rotation",(c||0)*Math.PI/180||0),d&&r.attr("position",[Gr(d[0],i[0]),Gr(d[1],i[1])]),v&&r.attr("cursor",v),r.setColor(l,n&&n.symbolInnerColor),r.setStyle(h);var x=t.getItemVisual(e,"opacity");null!=x&&(y.opacity=x);var _=n&&n.useNameLabel;dr(y,u,f,p,{labelFetcher:s,labelDataIndex:e,defaultText:a,isRectText:!0,autoColor:l}),r.off("mouseover").off("mouseout").off("emphasis").off("normal"),r.hoverStyle=u,cr(r);var w=Ou(i);if(g&&s.isAnimationEnabled()){var b=function(){var t=w[1]/w[0];this.animateTo({scale:[Math.max(1.1*w[0],w[0]+3),Math.max(1.1*w[1],w[1]+3*t)]},400,"elasticOut")},M=function(){this.animateTo({scale:w},400,"elasticOut")};r.on("mouseover",b).on("mouseout",M).on("emphasis",b).on("normal",M)}},aT.fadeOut=function(t,e){var i=this.childAt(0);this.silent=i.silent=!0,!(e&&e.keepLabel)&&(i.style.text=null),Mr(i,{style:{opacity:0},scale:[0,0]},this._seriesModel,this.dataIndex,t)},u(zu,xx);var hT=Ru.prototype;hT.updateData=function(t,e){var i=this.group,n=t.hostModel,a=this._data,r=this._symbolCtor,o=Bu(t);a||i.removeAll(),t.diff(a).add(function(n){var a=t.getItemLayout(n);if(Nu(t,a,n,e)){var s=new r(t,n,o);s.attr("position",a),t.setItemGraphicEl(n,s),i.add(s)}}).update(function(s,l){var h=a.getItemGraphicEl(l),u=t.getItemLayout(s);return Nu(t,u,s,e)?(h?(h.updateData(t,s,o),Mr(h,{position:u},n)):(h=new r(t,s),h.attr("position",u)),i.add(h),void t.setItemGraphicEl(s,h)):void i.remove(h)}).remove(function(t){var e=a.getItemGraphicEl(t);e&&e.fadeOut(function(){i.remove(e)})}).execute(),this._data=t},hT.isPersistent=function(){return!0},hT.updateLayout=function(){var t=this._data;t&&t.eachItemGraphicEl(function(e,i){var n=t.getItemLayout(i);e.attr("position",n)})},hT.incrementalPrepareUpdate=function(t){this._seriesScope=Bu(t),this._data=null,this.group.removeAll()},hT.incrementalUpdate=function(t,e,i){function n(t){t.isGroup||(t.incremental=t.useHoverLayer=!0)}for(var a=t.start;a<t.end;a++){var r=e.getItemLayout(a);if(Nu(e,r,a,i)){var o=new this._symbolCtor(e,a,this._seriesScope);o.traverse(n),o.attr("position",r),this.group.add(o),e.setItemGraphicEl(a,o)}}},hT.remove=function(t){var e=this.group,i=this._data;i&&(t?i.eachItemGraphicEl(function(t){t.fadeOut(function(){e.remove(t)})}):e.removeAll())};var uT=function(t,e,i,n,a,r){for(var o=Fu(t,e),s=[],l=[],h=[],u=[],c=[],d=[],f=[],p=r.dimensions,g=0;g<o.length;g++){var v=o[g],m=!0;switch(v.cmd){case"=":var y=t.getItemLayout(v.idx),x=e.getItemLayout(v.idx1);(isNaN(y[0])||isNaN(y[1]))&&(y=x.slice()),s.push(y),l.push(x),h.push(i[v.idx]),u.push(n[v.idx1]),f.push(e.getRawIndex(v.idx1));break;case"+":var _=v.idx;s.push(a.dataToPoint([e.get(p[0],_,!0),e.get(p[1],_,!0)])),l.push(e.getItemLayout(_).slice()),h.push(Gu(a,e,_)),u.push(n[_]),f.push(e.getRawIndex(_));break;case"-":var _=v.idx,w=t.getRawIndex(_);w!==_?(s.push(t.getItemLayout(_)),l.push(r.dataToPoint([t.get(p[0],_,!0),t.get(p[1],_,!0)])),h.push(i[_]),u.push(Gu(r,t,_)),f.push(w)):m=!1}m&&(c.push(v),d.push(d.length))}d.sort(function(t,e){return f[t]-f[e]});for(var b=[],M=[],S=[],I=[],T=[],g=0;g<d.length;g++){var _=d[g];b[g]=s[_],M[g]=l[_],S[g]=h[_],I[g]=u[_],T[g]=c[_]}return{current:b,next:M,stackedOnCurrent:S,stackedOnNext:I,status:T}},cT=oe,dT=se,fT=X,pT=W,gT=[],vT=[],mT=[],yT=Oa.extend({type:"ec-polyline",shape:{points:[],smooth:0,smoothConstraint:!0,smoothMonotone:null,connectNulls:!1},style:{fill:null,stroke:"#000"},brush:Ew(Oa.prototype.brush),buildPath:function(t,e){var i=e.points,n=0,a=i.length,r=Zu(i,e.smoothConstraint);if(e.connectNulls){for(;a>0&&Wu(i[a-1]);a--);for(;a>n&&Wu(i[n]);n++);}for(;a>n;)n+=Hu(t,i,n,a,a,1,r.min,r.max,e.smooth,e.smoothMonotone,e.connectNulls)+1}}),xT=Oa.extend({type:"ec-polygon",shape:{points:[],stackedOnPoints:[],smooth:0,stackedOnSmooth:0,smoothConstraint:!0,smoothMonotone:null,connectNulls:!1},brush:Ew(Oa.prototype.brush),buildPath:function(t,e){var i=e.points,n=e.stackedOnPoints,a=0,r=i.length,o=e.smoothMonotone,s=Zu(i,e.smoothConstraint),l=Zu(n,e.smoothConstraint);if(e.connectNulls){for(;r>0&&Wu(i[r-1]);r--);for(;r>a&&Wu(i[a]);a++);}for(;r>a;){var h=Hu(t,i,a,r,r,1,s.min,s.max,e.smooth,o,e.connectNulls);Hu(t,n,a+h-1,h,r,-1,l.min,l.max,e.stackedOnSmooth,o,e.connectNulls),a+=h+1,t.closePath()}}});Ss.extend({type:"line",init:function(){var t=new xx,e=new Ru;this.group.add(e.group),this._symbolDraw=e,this._lineGroup=t},render:function(t,e,i){var n=t.coordinateSystem,a=this.group,r=t.getData(),o=t.getModel("lineStyle"),l=t.getModel("areaStyle"),h=r.mapArray(r.getItemLayout,!0),u="polar"===n.type,c=this._coordSys,d=this._symbolDraw,f=this._polyline,p=this._polygon,g=this._lineGroup,v=t.get("animation"),m=!l.isEmpty(),y=l.get("origin"),x=qu(t,n,r,y),_=t.get("showSymbol"),w=_&&!u&&!t.get("showAllSymbol")&&this._getSymbolIgnoreFunc(r,n),b=this._data;b&&b.eachItemGraphicEl(function(t,e){t.__temp&&(a.remove(t),b.setItemGraphicEl(e,null))}),_||d.remove(),a.add(g);var M=!u&&t.get("step");f&&c.type===n.type&&M===this._step?(m&&!p?p=this._newPolygon(h,x,n,v):p&&!m&&(g.remove(p),p=this._polygon=null),g.setClipPath(Ju(n,!1,t)),_&&d.updateData(r,w),r.eachItemGraphicEl(function(t){t.stopAnimation(!0)}),ju(this._stackedOnPoints,x)&&ju(this._points,h)||(v?this._updateAnimation(r,x,n,i,M):(M&&(h=Qu(h,n,M),x=Qu(x,n,M)),f.setShape({points:h}),p&&p.setShape({points:h,stackedOnPoints:x})))):(_&&d.updateData(r,w),M&&(h=Qu(h,n,M),x=Qu(x,n,M)),f=this._newPolyline(h,n,v),m&&(p=this._newPolygon(h,x,n,v)),g.setClipPath(Ju(n,!0,t)));var S=tc(r,n)||r.getVisual("color");f.useStyle(s(o.getLineStyle(),{fill:"none",stroke:S,lineJoin:"bevel"}));var I=t.get("smooth");if(I=Xu(t.get("smooth")),f.setShape({smooth:I,smoothMonotone:t.get("smoothMonotone"),connectNulls:t.get("connectNulls")}),p){var T=r.stackedOn,A=0;if(p.useStyle(s(l.getAreaStyle(),{fill:S,opacity:.7,lineJoin:"bevel"})),T){var C=T.hostModel;A=Xu(C.get("smooth"))}p.setShape({smooth:I,stackedOnSmooth:A,smoothMonotone:t.get("smoothMonotone"),connectNulls:t.get("connectNulls")})}this._data=r,this._coordSys=n,this._stackedOnPoints=x,this._points=h,this._step=M},dispose:function(){},highlight:function(t,e,i,n){var a=t.getData(),r=Fn(a,n);if(!(r instanceof Array)&&null!=r&&r>=0){var o=a.getItemGraphicEl(r);if(!o){var s=a.getItemLayout(r);if(!s)return;o=new zu(a,r),o.position=s,o.setZ(t.get("zlevel"),t.get("z")),o.ignore=isNaN(s[0])||isNaN(s[1]),o.__temp=!0,a.setItemGraphicEl(r,o),o.stopSymbolAnimation(!0),this.group.add(o)}o.highlight()}else Ss.prototype.highlight.call(this,t,e,i,n)},downplay:function(t,e,i,n){var a=t.getData(),r=Fn(a,n);if(null!=r&&r>=0){var o=a.getItemGraphicEl(r);o&&(o.__temp?(a.setItemGraphicEl(r,null),this.group.remove(o)):o.downplay())}else Ss.prototype.downplay.call(this,t,e,i,n)},_newPolyline:function(t){var e=this._polyline;return e&&this._lineGroup.remove(e),e=new yT({shape:{points:t},silent:!0,z2:10}),this._lineGroup.add(e),this._polyline=e,e},_newPolygon:function(t,e){var i=this._polygon;return i&&this._lineGroup.remove(i),i=new xT({shape:{points:t,stackedOnPoints:e},silent:!0}),this._lineGroup.add(i),this._polygon=i,i
-},_getSymbolIgnoreFunc:function(t,e){var i=e.getAxesByScale("ordinal")[0];return i&&i.isLabelIgnored?y(i.isLabelIgnored,i):void 0},_updateAnimation:function(t,e,i,n,a){var r=this._polyline,o=this._polygon,s=t.hostModel,l=uT(this._data,t,this._stackedOnPoints,e,this._coordSys,i),h=l.current,u=l.stackedOnCurrent,c=l.next,d=l.stackedOnNext;a&&(h=Qu(l.current,i,a),u=Qu(l.stackedOnCurrent,i,a),c=Qu(l.next,i,a),d=Qu(l.stackedOnNext,i,a)),r.shape.__points=l.current,r.shape.points=h,Mr(r,{shape:{points:c}},s),o&&(o.setShape({points:h,stackedOnPoints:u}),Mr(o,{shape:{points:c,stackedOnPoints:d}},s));for(var f=[],p=l.status,g=0;g<p.length;g++){var v=p[g].cmd;if("="===v){var m=t.getItemGraphicEl(p[g].idx1);m&&f.push({el:m,ptIdx:g})}}r.animators&&r.animators.length&&r.animators[0].during(function(){for(var t=0;t<f.length;t++){var e=f[t].el;e.attr("position",r.shape.__points[f[t].ptIdx])}})},remove:function(){var t=this.group,e=this._data;this._lineGroup.removeAll(),this._symbolDraw.remove(!0),e&&e.eachItemGraphicEl(function(i,n){i.__temp&&(t.remove(i),e.setItemGraphicEl(n,null))}),this._polyline=this._polygon=this._coordSys=this._points=this._stackedOnPoints=this._data=null}});var _T=function(t,e,i){return{seriesType:t,performRawSeries:!0,reset:function(t,n){function a(e,i){if("function"==typeof s){var n=t.getRawValue(i),a=t.getDataParams(i);e.setItemVisual(i,"symbolSize",s(n,a))}if(e.hasItemOption){var r=e.getItemModel(i),o=r.getShallow("symbol",!0),l=r.getShallow("symbolSize",!0);null!=o&&e.setItemVisual(i,"symbol",o),null!=l&&e.setItemVisual(i,"symbolSize",l)}}var r=t.getData(),o=t.get("symbol")||e,s=t.get("symbolSize");if(r.setVisual({legendSymbol:i||o,symbol:o,symbolSize:s}),!n.isSeriesFiltered(t)){var l="function"==typeof s;return{dataEach:r.hasItemOption||l?a:null}}}}},wT=function(t){return{seriesType:t,plan:vM(),reset:function(t){function e(t,e){for(var i=t.end-t.start,a=r&&new Float32Array(i*s),l=t.start,h=0,u=[],c=[];l<t.end;l++){var d;if(1===s){var f=e.get(o[0],l,!0);d=!isNaN(f)&&n.dataToPoint(f,null,c)}else{var f=u[0]=e.get(o[0],l,!0),p=u[1]=e.get(o[1],l,!0);d=!isNaN(f)&&!isNaN(p)&&n.dataToPoint(u,null,c)}r?(a[h++]=d?d[0]:0/0,a[h++]=d?d[1]:0/0):e.setItemLayout(l,d&&d.slice()||[0/0,0/0])}r&&e.setLayout("symbolPoints",a)}var i=t.getData(),n=t.coordinateSystem,a=t.pipelineContext,r=a.large;if(n){var o=p(n.dimensions,function(t){return i.getDimension(i.mapDimension(t))}).slice(0,2),s=o.length;return s&&{progress:e}}}}},bT={average:function(t){for(var e=0,i=0,n=0;n<t.length;n++)isNaN(t[n])||(e+=t[n],i++);return 0===i?0/0:e/i},sum:function(t){for(var e=0,i=0;i<t.length;i++)e+=t[i]||0;return e},max:function(t){for(var e=-1/0,i=0;i<t.length;i++)t[i]>e&&(e=t[i]);return e},min:function(t){for(var e=1/0,i=0;i<t.length;i++)t[i]<e&&(e=t[i]);return e},nearest:function(t){return t[0]}},MT=function(t){return Math.round(t.length/2)},ST=function(t){return{seriesType:t,reset:function(t){var e=t.getData(),i=t.get("sampling"),n=t.coordinateSystem;if("cartesian2d"===n.type&&i){var a=n.getBaseAxis(),r=n.getOtherAxis(a),o=a.getExtent(),s=o[1]-o[0],l=Math.round(e.count()/s);if(l>1){var h;"string"==typeof i?h=bT[i]:"function"==typeof i&&(h=i),h&&t.setData(e.downSample(r.dim,1/l,h,MT))}}}}};kl(_T("line","circle","line")),Ll(wT("line")),Il(tS.PROCESSOR.STATISTIC,ST("line"));var IT=function(t,e,i){e=_(e)&&{coordDimensions:e}||o({},e);var n=t.getSource(),a=zS(n,e),r=new kS(a,t);return r.initData(n,i),r},TT={updateSelectedMap:function(t){if(_(t))this._targetList=t.slice();else for(var e=t,i=e.mapDimension("value"),t=this._targetList=[],n=0,a=e.count();a>n;n++)t.push({name:e.getName(n),value:e.get(i,n)});this._selectTargetMap=g(t||[],function(t,e){return t.set(e.name,e),t},B())},select:function(t,e){var i=null!=e?this._targetList[e]:this._selectTargetMap.get(t),n=this.get("selectedMode");"single"===n&&this._selectTargetMap.each(function(t){t.selected=!1}),i&&(i.selected=!0)},unSelect:function(t,e){var i=null!=e?this._targetList[e]:this._selectTargetMap.get(t);i&&(i.selected=!1)},toggleSelected:function(t,e){var i=null!=e?this._targetList[e]:this._selectTargetMap.get(t);return null!=i?(this[i.selected?"unSelect":"select"](t,e),i.selected):void 0},isSelected:function(t,e){var i=null!=e?this._targetList[e]:this._selectTargetMap.get(t);return i&&i.selected}},AT=Rl({type:"series.pie",init:function(t){AT.superApply(this,"init",arguments),this.legendDataProvider=function(){return this.getRawData()},this.updateSelectedMap(this.getRawData()),this._defaultLabelLine(t)},mergeOption:function(t){AT.superCall(this,"mergeOption",t),this.updateSelectedMap(this.getRawData())},getInitialData:function(){return IT(this,["value"])},getDataParams:function(t){var e=this.getData(),i=AT.superCall(this,"getDataParams",t),n=[];return e.each(e.mapDimension("value"),function(t){n.push(t)}),i.percent=Xr(n,t,e.hostModel.get("percentPrecision")),i.$vars.push("percent"),i},_defaultLabelLine:function(t){zn(t,"labelLine",["show"]);var e=t.labelLine,i=t.emphasis.labelLine;e.show=e.show&&t.label.show,i.show=i.show&&t.emphasis.label.show},defaultOption:{zlevel:0,z:2,legendHoverLink:!0,hoverAnimation:!0,center:["50%","50%"],radius:[0,"75%"],clockwise:!0,startAngle:90,minAngle:0,selectedOffset:10,hoverOffset:10,avoidLabelOverlap:!0,percentPrecision:2,stillShowZeroSum:!0,label:{rotate:!1,show:!0,position:"outer"},labelLine:{show:!0,length:15,length2:15,smooth:!1,lineStyle:{width:1,type:"solid"}},itemStyle:{borderWidth:1},animationType:"expansion",animationEasing:"cubicOut"}});c(AT,TT);var CT=nc.prototype;CT.updateData=function(t,e,i){function n(){r.stopAnimation(!0),r.animateTo({shape:{r:u.r+l.get("hoverOffset")}},300,"elasticOut")}function a(){r.stopAnimation(!0),r.animateTo({shape:{r:u.r}},300,"elasticOut")}var r=this.childAt(0),l=t.hostModel,h=t.getItemModel(e),u=t.getItemLayout(e),c=o({},u);if(c.label=null,i){r.setShape(c);var d=l.getShallow("animationType");"scale"===d?(r.shape.r=u.r0,Sr(r,{shape:{r:u.r}},l,e)):(r.shape.endAngle=u.startAngle,Mr(r,{shape:{endAngle:u.endAngle}},l,e))}else Mr(r,{shape:c},l,e);var f=t.getItemVisual(e,"color");r.useStyle(s({lineJoin:"bevel",fill:f},h.getModel("itemStyle").getItemStyle())),r.hoverStyle=h.getModel("emphasis.itemStyle").getItemStyle();var p=h.getShallow("cursor");p&&r.attr("cursor",p),ic(this,t.getItemLayout(e),l.isSelected(null,e),l.get("selectedOffset"),l.get("animation")),r.off("mouseover").off("mouseout").off("emphasis").off("normal"),h.get("hoverAnimation")&&l.isAnimationEnabled()&&r.on("mouseover",n).on("mouseout",a).on("emphasis",n).on("normal",a),this._updateLabel(t,e),cr(this)},CT._updateLabel=function(t,e){var i=this.childAt(1),n=this.childAt(2),a=t.hostModel,r=t.getItemModel(e),o=t.getItemLayout(e),s=o.label,l=t.getItemVisual(e,"color");Mr(i,{shape:{points:s.linePoints||[[s.x,s.y],[s.x,s.y],[s.x,s.y]]}},a,e),Mr(n,{style:{x:s.x,y:s.y}},a,e),n.attr({rotation:s.rotation,origin:[s.x,s.y],z2:10});var h=r.getModel("label"),u=r.getModel("emphasis.label"),c=r.getModel("labelLine"),d=r.getModel("emphasis.labelLine"),l=t.getItemVisual(e,"color");dr(n.style,n.hoverStyle={},h,u,{labelFetcher:t.hostModel,labelDataIndex:e,defaultText:t.getName(e),autoColor:l,useInsideStyle:!!s.inside},{textAlign:s.textAlign,textVerticalAlign:s.verticalAlign,opacity:t.getItemVisual(e,"opacity")}),n.ignore=n.normalIgnore=!h.get("show"),n.hoverIgnore=!u.get("show"),i.ignore=i.normalIgnore=!c.get("show"),i.hoverIgnore=!d.get("show"),i.setStyle({stroke:l,opacity:t.getItemVisual(e,"opacity")}),i.setStyle(c.getModel("lineStyle").getLineStyle()),i.hoverStyle=d.getModel("lineStyle").getLineStyle();var f=c.get("smooth");f&&f===!0&&(f=.4),i.setShape({smooth:f})},u(nc,xx);var DT=(Ss.extend({type:"pie",init:function(){var t=new xx;this._sectorGroup=t},render:function(t,e,i,n){if(!n||n.from!==this.uid){var a=t.getData(),r=this._data,o=this.group,s=e.get("animation"),l=!r,h=t.get("animationType"),u=x(ec,this.uid,t,s,i),c=t.get("selectedMode");if(a.diff(r).add(function(t){var e=new nc(a,t);l&&"scale"!==h&&e.eachChild(function(t){t.stopAnimation(!0)}),c&&e.on("click",u),a.setItemGraphicEl(t,e),o.add(e)}).update(function(t,e){var i=r.getItemGraphicEl(e);i.updateData(a,t),i.off("click"),c&&i.on("click",u),o.add(i),a.setItemGraphicEl(t,i)}).remove(function(t){var e=r.getItemGraphicEl(t);o.remove(e)}).execute(),s&&l&&a.count()>0&&"scale"!==h){var d=a.getItemLayout(0),f=Math.max(i.getWidth(),i.getHeight())/2,p=y(o.removeClipPath,o);o.setClipPath(this._createClipPath(d.cx,d.cy,f,d.startAngle,d.clockwise,p,t))}this._data=a}},dispose:function(){},_createClipPath:function(t,e,i,n,a,r,o){var s=new Rw({shape:{cx:t,cy:e,r0:0,r:i,startAngle:n,endAngle:n,clockwise:a}});return Sr(s,{shape:{endAngle:n+(a?1:-1)*Math.PI*2}},o,r),s},containPoint:function(t,e){var i=e.getData(),n=i.getItemLayout(0);if(n){var a=t[0]-n.cx,r=t[1]-n.cy,o=Math.sqrt(a*a+r*r);return o<=n.r&&o>=n.r0}}}),function(t,e){f(e,function(e){e.update="updateView",Al(e,function(i,n){var a={};return n.eachComponent({mainType:"series",subType:t,query:i},function(t){t[e.method]&&t[e.method](i.name,i.dataIndex);var n=t.getData();n.each(function(e){var i=n.getName(e);a[i]=t.isSelected(i)||!1})}),{name:i.name,selected:a}})})}),LT=function(t){return{getTargetSeries:function(e){var i={},n=B();return e.eachSeriesByType(t,function(t){t.__paletteScope=i,n.set(t.uid,t)}),n},reset:function(t){var e=t.getRawData(),i={},n=t.getData();n.each(function(t){var e=n.getRawIndex(t);i[e]=t}),e.each(function(a){var r=i[a],o=null!=r&&n.getItemVisual(r,"color",!0);if(o)e.setItemVisual(a,"color",o);else{var s=e.getItemModel(a),l=s.get("itemStyle.color")||t.getColorFromPalette(e.getName(a),t.__paletteScope,e.count());e.setItemVisual(a,"color",l),null!=r&&n.setItemVisual(r,"color",l)}})}}},kT=function(t,e,i,n){var a,r,o=t.getData(),s=[],l=!1;o.each(function(i){var n,h,u,c,d=o.getItemLayout(i),f=o.getItemModel(i),p=f.getModel("label"),g=p.get("position")||f.get("emphasis.label.position"),v=f.getModel("labelLine"),m=v.get("length"),y=v.get("length2"),x=(d.startAngle+d.endAngle)/2,_=Math.cos(x),w=Math.sin(x);a=d.cx,r=d.cy;var b="inside"===g||"inner"===g;if("center"===g)n=d.cx,h=d.cy,c="center";else{var M=(b?(d.r+d.r0)/2*_:d.r*_)+a,S=(b?(d.r+d.r0)/2*w:d.r*w)+r;if(n=M+3*_,h=S+3*w,!b){var I=M+_*(m+e-d.r),T=S+w*(m+e-d.r),A=I+(0>_?-1:1)*y,C=T;n=A+(0>_?-5:5),h=C,u=[[M,S],[I,T],[A,C]]}c=b?"center":_>0?"left":"right"}var D=p.getFont(),L=p.get("rotate")?0>_?-x+Math.PI:-x:0,k=t.getFormattedLabel(i,"normal")||o.getName(i),P=Mi(k,D,c,"top");l=!!L,d.label={x:n,y:h,position:g,height:P.height,len:m,len2:y,linePoints:u,textAlign:c,verticalAlign:"middle",rotation:L,inside:b},b||s.push(d.label)}),!l&&t.get("avoidLabelOverlap")&&rc(s,a,r,e,i,n)},PT=2*Math.PI,OT=Math.PI/180,zT=function(t,e,i){e.eachSeriesByType(t,function(t){var e=t.getData(),n=e.mapDimension("value"),a=t.get("center"),r=t.get("radius");_(r)||(r=[0,r]),_(a)||(a=[a,a]);var o=i.getWidth(),s=i.getHeight(),l=Math.min(o,s),h=Gr(a[0],o),u=Gr(a[1],s),c=Gr(r[0],l/2),d=Gr(r[1],l/2),f=-t.get("startAngle")*OT,p=t.get("minAngle")*OT,g=0;e.each(n,function(t){!isNaN(t)&&g++});var v=e.getSum(n),m=Math.PI/(v||g)*2,y=t.get("clockwise"),x=t.get("roseType"),w=t.get("stillShowZeroSum"),b=e.getDataExtent(n);b[0]=0;var M=PT,S=0,I=f,T=y?1:-1;if(e.each(n,function(t,i){var n;if(isNaN(t))return void e.setItemLayout(i,{angle:0/0,startAngle:0/0,endAngle:0/0,clockwise:y,cx:h,cy:u,r0:c,r:x?0/0:d});n="area"!==x?0===v&&w?m:t*m:PT/g,p>n?(n=p,M-=p):S+=t;var a=I+T*n;e.setItemLayout(i,{angle:n,startAngle:I,endAngle:a,clockwise:y,cx:h,cy:u,r0:c,r:x?Vr(t,b,[c,d]):d}),I=a},!0),PT>M&&g)if(.001>=M){var A=PT/g;e.each(n,function(t,i){if(!isNaN(t)){var n=e.getItemLayout(i);n.angle=A,n.startAngle=f+T*i*A,n.endAngle=f+T*(i+1)*A}})}else m=M/S,I=f,e.each(n,function(t,i){if(!isNaN(t)){var n=e.getItemLayout(i),a=n.angle===p?p:t*m;n.startAngle=I,n.endAngle=I+T*a,I+=T*a}});kT(t,d,o,s)})},ET=function(t){return{seriesType:t,reset:function(t,e){var i=e.findComponents({mainType:"legend"});if(i&&i.length){var n=t.getData();n.filterSelf(function(t){for(var e=n.getName(t),a=0;a<i.length;a++)if(!i[a].isSelected(e))return!1;return!0},this)}}}};DT("pie",[{type:"pieToggleSelect",event:"pieselectchanged",method:"toggleSelected"},{type:"pieSelect",event:"pieselected",method:"select"},{type:"pieUnSelect",event:"pieunselected",method:"unSelect"}]),kl(LT("pie")),Ll(x(zT,"pie")),Il(ET("pie")),fM.extend({type:"series.heatmap",getInitialData:function(){return rh(this.getSource(),this)},preventIncremental:function(){var t=Fo.get(this.get("coordinateSystem"));return t&&t.dimensions?"lng"===t.dimensions[0]&&"lat"===t.dimensions[1]:void 0},defaultOption:{coordinateSystem:"cartesian2d",zlevel:0,z:2,geoIndex:0,blurSize:30,pointSize:20,maxOpacity:1,minOpacity:0}});var RT=256;oc.prototype={update:function(t,e,i,n,a,r){var o=this._getBrush(),s=this._getGradient(t,a,"inRange"),l=this._getGradient(t,a,"outOfRange"),h=this.pointSize+this.blurSize,u=this.canvas,c=u.getContext("2d"),d=t.length;u.width=e,u.height=i;for(var f=0;d>f;++f){var p=t[f],g=p[0],v=p[1],m=p[2],y=n(m);c.globalAlpha=y,c.drawImage(o,g-h,v-h)}if(!u.width||!u.height)return u;for(var x=c.getImageData(0,0,u.width,u.height),_=x.data,w=0,b=_.length,M=this.minOpacity,S=this.maxOpacity,I=S-M;b>w;){var y=_[w+3]/256,T=4*Math.floor(y*(RT-1));if(y>0){var A=r(y)?s:l;y>0&&(y=y*I+M),_[w++]=A[T],_[w++]=A[T+1],_[w++]=A[T+2],_[w++]=A[T+3]*y*256}else w+=4}return c.putImageData(x,0,0),u},_getBrush:function(){var t=this._brushCanvas||(this._brushCanvas=Ay()),e=this.pointSize+this.blurSize,i=2*e;t.width=i,t.height=i;var n=t.getContext("2d");return n.clearRect(0,0,i,i),n.shadowOffsetX=i,n.shadowBlur=this.blurSize,n.shadowColor="#000",n.beginPath(),n.arc(-e,e,this.pointSize,0,2*Math.PI,!0),n.closePath(),n.fill(),t},_getGradient:function(t,e,i){for(var n=this._gradientPixels,a=n[i]||(n[i]=new Uint8ClampedArray(1024)),r=[0,0,0,0],o=0,s=0;256>s;s++)e[i](s/255,!0,r),a[o++]=r[0],a[o++]=r[1],a[o++]=r[2],a[o++]=r[3];return a}},Nl({type:"heatmap",render:function(t,e,i){var n;e.eachComponent("visualMap",function(e){e.eachTargetSeries(function(i){i===t&&(n=e)})}),this.group.removeAll(),this._incrementalDisplayable=null;var a=t.coordinateSystem;"cartesian2d"===a.type||"calendar"===a.type?this._renderOnCartesianAndCalendar(t,i,0,t.getData().count()):hc(a)&&this._renderOnGeo(a,t,n,i)},incrementalPrepareRender:function(){this.group.removeAll()},incrementalRender:function(t,e,i,n){var a=e.coordinateSystem;a&&this._renderOnCartesianAndCalendar(e,n,t.start,t.end,!0)},_renderOnCartesianAndCalendar:function(t,e,i,n,a){var r,s,l=t.coordinateSystem;if("cartesian2d"===l.type){var h=l.getAxis("x"),u=l.getAxis("y");r=h.getBandWidth(),s=u.getBandWidth()}for(var c=this.group,d=t.getData(),f="itemStyle",p="emphasis.itemStyle",g="label",v="emphasis.label",m=t.getModel(f).getItemStyle(["color"]),y=t.getModel(p).getItemStyle(),x=t.getModel(g),_=t.getModel(v),w=l.type,b="cartesian2d"===w?[d.mapDimension("x"),d.mapDimension("y"),d.mapDimension("value")]:[d.mapDimension("time"),d.mapDimension("value")],M=i;n>M;M++){var S;if("cartesian2d"===w){if(isNaN(d.get(b[2],M)))continue;var I=l.dataToPoint([d.get(b[0],M),d.get(b[1],M)]);S=new Ww({shape:{x:I[0]-r/2,y:I[1]-s/2,width:r,height:s},style:{fill:d.getItemVisual(M,"color"),opacity:d.getItemVisual(M,"opacity")}})}else{if(isNaN(d.get(b[1],M)))continue;S=new Ww({z2:1,shape:l.dataToRect([d.get(b[0],M)]).contentShape,style:{fill:d.getItemVisual(M,"color"),opacity:d.getItemVisual(M,"opacity")}})}var T=d.getItemModel(M);d.hasItemOption&&(m=T.getModel(f).getItemStyle(["color"]),y=T.getModel(p).getItemStyle(),x=T.getModel(g),_=T.getModel(v));var A=t.getRawValue(M),C="-";A&&null!=A[2]&&(C=A[2]),dr(m,y,x,_,{labelFetcher:t,labelDataIndex:M,defaultText:C,isRectText:!0}),S.setStyle(m),cr(S,d.hasItemOption?y:o({},y)),S.incremental=a,a&&(S.useHoverLayer=!0),c.add(S),d.setItemGraphicEl(M,S)}},_renderOnGeo:function(t,e,i,n){var a=i.targetVisuals.inRange,r=i.targetVisuals.outOfRange,o=e.getData(),s=this._hmLayer||this._hmLayer||new oc;s.blurSize=e.get("blurSize"),s.pointSize=e.get("pointSize"),s.minOpacity=e.get("minOpacity"),s.maxOpacity=e.get("maxOpacity");var l=t.getViewRect().clone(),h=t.getRoamTransform();l.applyTransform(h);var u=Math.max(l.x,0),c=Math.max(l.y,0),d=Math.min(l.width+l.x,n.getWidth()),f=Math.min(l.height+l.y,n.getHeight()),p=d-u,g=f-c,v=[o.mapDimension("lng"),o.mapDimension("lat"),o.mapDimension("value")],m=o.mapArray(v,function(e,i,n){var a=t.dataToPoint([e,i]);return a[0]-=u,a[1]-=c,a.push(n),a}),y=i.getExtent(),x="visualMap.continuous"===i.type?lc(y,i.option.range):sc(y,i.getPieceList(),i.option.selected);s.update(m,p,g,a.color.getNormalizer(),{inRange:a.color.getColorMapper(),outOfRange:r.color.getColorMapper()},x);var _=new on({style:{width:p,height:g,x:u,y:c,image:s.canvas},silent:!0});this.group.add(_)},dispose:function(){}});var NT=f,BT="\x00__link_datas",VT="\x00__link_mainData",GT=function(t,e){this.name=t||"",this.depth=0,this.height=0,this.parentNode=null,this.dataIndex=-1,this.children=[],this.viewChildren=[],this.hostTree=e};GT.prototype={constructor:GT,isRemoved:function(){return this.dataIndex<0},eachNode:function(t,e,i){"function"==typeof t&&(i=e,e=t,t=null),t=t||{},b(t)&&(t={order:t});var n,a=t.order||"preorder",r=this[t.attr||"children"];"preorder"===a&&(n=e.call(i,this));for(var o=0;!n&&o<r.length;o++)r[o].eachNode(t,e,i);"postorder"===a&&e.call(i,this)},updateDepthAndHeight:function(t){var e=0;this.depth=t;for(var i=0;i<this.children.length;i++){var n=this.children[i];n.updateDepthAndHeight(t+1),n.height>e&&(e=n.height)}this.height=e+1},getNodeById:function(t){if(this.getId()===t)return this;for(var e=0,i=this.children,n=i.length;n>e;e++){var a=i[e].getNodeById(t);if(a)return a}},contains:function(t){if(t===this)return!0;for(var e=0,i=this.children,n=i.length;n>e;e++){var a=i[e].contains(t);if(a)return a}},getAncestors:function(t){for(var e=[],i=t?this:this.parentNode;i;)e.push(i),i=i.parentNode;return e.reverse(),e},getValue:function(t){var e=this.hostTree.data;return e.get(e.getDimension(t||"value"),this.dataIndex)},setLayout:function(t,e){this.dataIndex>=0&&this.hostTree.data.setItemLayout(this.dataIndex,t,e)},getLayout:function(){return this.hostTree.data.getItemLayout(this.dataIndex)},getModel:function(t){if(!(this.dataIndex<0)){var e,i=this.hostTree,n=i.data.getItemModel(this.dataIndex),a=this.getLevelModel();return a||0!==this.children.length&&(0===this.children.length||this.isExpand!==!1)||(e=this.getLeavesModel()),n.getModel(t,(a||e||i.hostModel).getModel(t))}},getLevelModel:function(){return(this.hostTree.levelModels||[])[this.depth]},getLeavesModel:function(){return this.hostTree.leavesModel},setVisual:function(t,e){this.dataIndex>=0&&this.hostTree.data.setItemVisual(this.dataIndex,t,e)},getVisual:function(t,e){return this.hostTree.data.getItemVisual(this.dataIndex,t,e)},getRawIndex:function(){return this.hostTree.data.getRawIndex(this.dataIndex)},getId:function(){return this.hostTree.data.getId(this.dataIndex)},isAncestorOf:function(t){for(var e=t.parentNode;e;){if(e===this)return!0;e=e.parentNode}return!1},isDescendantOf:function(t){return t!==this&&t.isAncestorOf(this)}},yc.prototype={constructor:yc,type:"tree",eachNode:function(t,e,i){this.root.eachNode(t,e,i)},getNodeByDataIndex:function(t){var e=this.data.getRawIndex(t);return this._nodes[e]},getNodeByName:function(t){return this.root.getNodeByName(t)},update:function(){for(var t=this.data,e=this._nodes,i=0,n=e.length;n>i;i++)e[i].dataIndex=-1;for(var i=0,n=t.count();n>i;i++)e[t.getRawIndex(i)].dataIndex=i},clearLayouts:function(){this.data.clearItemLayouts()}},yc.createTree=function(t,e,i){function n(t,e){var i=t.value;o=Math.max(o,_(i)?i.length:1),r.push(t);var s=new GT(t.name,a);e?xc(s,e):a.root=s,a._nodes.push(s);var l=t.children;if(l)for(var h=0;h<l.length;h++)n(l[h],s)}var a=new yc(e,i.levels,i.leaves),r=[],o=1;n(t),a.root.updateDepthAndHeight(0);var s=zS(r,{coordDimensions:["value"],dimensionsCount:o}),l=new kS(s,e);return l.initData(r),uc({mainData:l,struct:a,structAttr:"tree"}),a.update(),a},fM.extend({type:"series.tree",layoutInfo:null,layoutMode:"box",getInitialData:function(t){var e={name:t.name,children:t.data},i=t.leaves||{},n={};n.leaves=i;var a=yc.createTree(e,this,n),r=0;a.eachNode("preorder",function(t){t.depth>r&&(r=t.depth)});var o=t.expandAndCollapse,s=o&&t.initialTreeDepth>=0?t.initialTreeDepth:r;return a.root.eachNode("preorder",function(t){var e=t.hostTree.data.getRawDataItem(t.dataIndex);t.isExpand=e&&null!=e.collapsed?!e.collapsed:t.depth<=s}),a.data},formatTooltip:function(t){for(var e=this.getData().tree,i=e.root.children[0],n=e.getNodeByDataIndex(t),a=n.getValue(),r=n.name;n&&n!==i;)r=n.parentNode.name+"."+r,n=n.parentNode;return no(r+(isNaN(a)||null==a?"":" : "+a))},defaultOption:{zlevel:0,z:2,left:"12%",top:"12%",right:"12%",bottom:"12%",layout:"orthogonal",orient:"horizontal",symbol:"emptyCircle",symbolSize:7,expandAndCollapse:!0,initialTreeDepth:2,lineStyle:{color:"#ccc",width:1.5,curveness:.5},itemStyle:{color:"lightsteelblue",borderColor:"#c23531",borderWidth:1.5},label:{show:!0,color:"#555"},leaves:{label:{show:!0}},animationEasing:"linear",animationDuration:700,animationDurationUpdate:1e3}}),Nl({type:"tree",init:function(){this._oldTree,this._mainGroup=new xx,this.group.add(this._mainGroup)},render:function(t,e,i){var n=t.getData(),a=t.layoutInfo,r=this._mainGroup,o=t.get("layout");"radial"===o?r.attr("position",[a.x+a.width/2,a.y+a.height/2]):r.attr("position",[a.x,a.y]);var s=this._data,l={expandAndCollapse:t.get("expandAndCollapse"),layout:o,orient:t.get("orient"),curvature:t.get("lineStyle.curveness"),symbolRotate:t.get("symbolRotate"),symbolOffset:t.get("symbolOffset"),hoverAnimation:t.get("hoverAnimation"),useNameLabel:!0,fadeIn:!0};n.diff(s).add(function(e){Oc(n,e)&&Ec(n,e,null,r,t,l)}).update(function(e,i){var a=s.getItemGraphicEl(i);return Oc(n,e)?void Ec(n,e,a,r,t,l):void(a&&Rc(n,e,a,r,t,l))}).remove(function(e){var i=s.getItemGraphicEl(e);Rc(n,e,i,r,t,l)}).execute(),l.expandAndCollapse===!0&&n.eachItemGraphicEl(function(e,n){e.off("click").on("click",function(){i.dispatchAction({type:"treeExpandAndCollapse",seriesId:t.id,dataIndex:n})})}),this._data=n},dispose:function(){},remove:function(){this._mainGroup.removeAll(),this._data=null}}),Al({type:"treeExpandAndCollapse",event:"treeExpandAndCollapse",update:"update"},function(t,e){e.eachComponent({mainType:"series",subType:"tree",query:t},function(e){var i=t.dataIndex,n=e.getData().tree,a=n.getNodeByDataIndex(i);a.isExpand=!a.isExpand})});var FT=function(t,e){var i=Ic(t,e);t.layoutInfo=i;var n=t.get("layout"),a=0,r=0,o=null;"radial"===n?(a=2*Math.PI,r=Math.min(i.height,i.width)/2,o=Mc(function(t,e){return(t.parentNode===e.parentNode?1:2)/t.depth})):(a=i.width,r=i.height,o=Mc());var s=t.getData().tree.root,l=s.children[0];_c(s),Bc(l,wc,o),s.hierNode.modifier=-l.hierNode.prelim,Vc(l,bc);var h=l,u=l,c=l;Vc(l,function(t){var e=t.getLayout().x;e<h.getLayout().x&&(h=t),e>u.getLayout().x&&(u=t),t.depth>c.depth&&(c=t)});var d=h===u?1:o(h,u)/2,f=d-h.getLayout().x,p=0,g=0,v=0,m=0;"radial"===n?(p=a/(u.getLayout().x+d+f),g=r/(c.depth-1||1),Vc(l,function(t){v=(t.getLayout().x+f)*p,m=(t.depth-1)*g;var e=Sc(v,m);t.setLayout({x:e.x,y:e.y,rawX:v,rawY:m},!0)})):"horizontal"===t.get("orient")?(g=r/(u.getLayout().x+d+f),p=a/(c.depth-1||1),Vc(l,function(t){m=(t.getLayout().x+f)*g,v=(t.depth-1)*p,t.setLayout({x:v,y:m},!0)})):(p=a/(u.getLayout().x+d+f),g=r/(c.depth-1||1),Vc(l,function(t){v=(t.getLayout().x+f)*p,m=(t.depth-1)*g,t.setLayout({x:v,y:m},!0)}))},WT=function(t,e){t.eachSeriesByType("tree",function(t){FT(t,e)})},HT=function(t,e){t.eachSeriesByType("tree",function(t){FT(t,e)})};kl(_T("tree","circle")),Ll(WT),Ll(HT);var ZT=function(t){this._directed=t||!1,this.nodes=[],this.edges=[],this._nodesMap={},this._edgesMap={},this.data,this.edgeData},jT=ZT.prototype;jT.type="graph",jT.isDirected=function(){return this._directed},jT.addNode=function(t,e){t=t||""+e;var i=this._nodesMap;if(!i[Gc(t)]){var n=new Fc(t,e);return n.hostGraph=this,this.nodes.push(n),i[Gc(t)]=n,n}},jT.getNodeByIndex=function(t){var e=this.data.getRawIndex(t);return this.nodes[e]},jT.getNodeById=function(t){return this._nodesMap[Gc(t)]},jT.addEdge=function(t,e,i){var n=this._nodesMap,a=this._edgesMap;if("number"==typeof t&&(t=this.nodes[t]),"number"==typeof e&&(e=this.nodes[e]),Fc.isInstance(t)||(t=n[Gc(t)]),Fc.isInstance(e)||(e=n[Gc(e)]),t&&e){var r=t.id+"-"+e.id;if(!a[r]){var o=new Wc(t,e,i);return o.hostGraph=this,this._directed&&(t.outEdges.push(o),e.inEdges.push(o)),t.edges.push(o),t!==e&&e.edges.push(o),this.edges.push(o),a[r]=o,o}}},jT.getEdgeByIndex=function(t){var e=this.edgeData.getRawIndex(t);return this.edges[e]},jT.getEdge=function(t,e){Fc.isInstance(t)&&(t=t.id),Fc.isInstance(e)&&(e=e.id);var i=this._edgesMap;return this._directed?i[t+"-"+e]:i[t+"-"+e]||i[e+"-"+t]},jT.eachNode=function(t,e){for(var i=this.nodes,n=i.length,a=0;n>a;a++)i[a].dataIndex>=0&&t.call(e,i[a],a)},jT.eachEdge=function(t,e){for(var i=this.edges,n=i.length,a=0;n>a;a++)i[a].dataIndex>=0&&i[a].node1.dataIndex>=0&&i[a].node2.dataIndex>=0&&t.call(e,i[a],a)},jT.breadthFirstTraverse=function(t,e,i,n){if(Fc.isInstance(e)||(e=this._nodesMap[Gc(e)]),e){for(var a="out"===i?"outEdges":"in"===i?"inEdges":"edges",r=0;r<this.nodes.length;r++)this.nodes[r].__visited=!1;if(!t.call(n,e,null))for(var o=[e];o.length;)for(var s=o.shift(),l=s[a],r=0;r<l.length;r++){var h=l[r],u=h.node1===s?h.node2:h.node1;if(!u.__visited){if(t.call(n,u,s))return;o.push(u),u.__visited=!0}}}},jT.update=function(){for(var t=this.data,e=this.edgeData,i=this.nodes,n=this.edges,a=0,r=i.length;r>a;a++)i[a].dataIndex=-1;for(var a=0,r=t.count();r>a;a++)i[t.getRawIndex(a)].dataIndex=a;e.filterSelf(function(t){var i=n[e.getRawIndex(t)];return i.node1.dataIndex>=0&&i.node2.dataIndex>=0});for(var a=0,r=n.length;r>a;a++)n[a].dataIndex=-1;for(var a=0,r=e.count();r>a;a++)n[e.getRawIndex(a)].dataIndex=a},jT.clone=function(){for(var t=new ZT(this._directed),e=this.nodes,i=this.edges,n=0;n<e.length;n++)t.addNode(e[n].id,e[n].dataIndex);for(var n=0;n<i.length;n++){var a=i[n];t.addEdge(a.node1.id,a.node2.id,a.dataIndex)}return t},Fc.prototype={constructor:Fc,degree:function(){return this.edges.length},inDegree:function(){return this.inEdges.length},outDegree:function(){return this.outEdges.length},getModel:function(t){if(!(this.dataIndex<0)){var e=this.hostGraph,i=e.data.getItemModel(this.dataIndex);return i.getModel(t)}}},Wc.prototype.getModel=function(t){if(!(this.dataIndex<0)){var e=this.hostGraph,i=e.edgeData.getItemModel(this.dataIndex);return i.getModel(t)}};var XT=function(t,e){return{getValue:function(i){var n=this[t][e];return n.get(n.getDimension(i||"value"),this.dataIndex)},setVisual:function(i,n){this.dataIndex>=0&&this[t][e].setItemVisual(this.dataIndex,i,n)},getVisual:function(i,n){return this[t][e].getItemVisual(this.dataIndex,i,n)},setLayout:function(i,n){this.dataIndex>=0&&this[t][e].setItemLayout(this.dataIndex,i,n)},getLayout:function(){return this[t][e].getItemLayout(this.dataIndex)},getGraphicEl:function(){return this[t][e].getItemGraphicEl(this.dataIndex)},getRawIndex:function(){return this[t][e].getRawIndex(this.dataIndex)}}};c(Fc,XT("hostGraph","data")),c(Wc,XT("hostGraph","edgeData")),ZT.Node=Fc,ZT.Edge=Wc,$n(Fc),$n(Wc);var UT=function(t,e,i,n,a){for(var r=new ZT(n),o=0;o<t.length;o++)r.addNode(C(t[o].id,t[o].name,o),o);for(var s=[],l=[],h=0,o=0;o<e.length;o++){var u=e[o],c=u.source,d=u.target;r.addEdge(c,d,h)&&(l.push(u),s.push(C(u.id,c+" > "+d)),h++)}var f,p=i.get("coordinateSystem");if("cartesian2d"===p||"polar"===p)f=rh(t,i);else{var g=Fo.get(p),v=zS(t,{coordDimensions:(g&&"view"!==g.type?g.dimensions||[]:[]).concat(["value"])});f=new kS(v,i),f.initData(t)}var m=new kS(["value"],i);return m.initData(l,s),a&&a(f,m),uc({mainData:f,struct:r,structAttr:"graph",datas:{node:f,edge:m},datasAttr:{node:"data",edge:"edgeData"}}),r.update(),r},YT=Rl({type:"series.graph",init:function(t){YT.superApply(this,"init",arguments),this.legendDataProvider=function(){return this._categoriesData},this.fillDataTextStyle(t.edges||t.links),this._updateCategoriesData()},mergeOption:function(t){YT.superApply(this,"mergeOption",arguments),this.fillDataTextStyle(t.edges||t.links),this._updateCategoriesData()},mergeDefaultAndTheme:function(t){YT.superApply(this,"mergeDefaultAndTheme",arguments),zn(t,["edgeLabel"],["show"])},getInitialData:function(t,e){function i(t,i){function n(t){return t=this.parsePath(t),t&&"label"===t[0]?o:this.parentModel}t.wrapMethod("getItemModel",function(t){var e=r._categoriesModels,i=t.getShallow("category"),n=e[i];return n&&(n.parentModel=t.parentModel,t.parentModel=n),t});var a=r.getModel("edgeLabel"),o=new Pr({label:a.option},a.parentModel,e);i.wrapMethod("getItemModel",function(t){return t.customizeGetParent(n),t})}var n=t.edges||t.links||[],a=t.data||t.nodes||[],r=this;return a&&n?UT(a,n,this,!0,i).data:void 0},getGraph:function(){return this.getData().graph},getEdgeData:function(){return this.getGraph().edgeData},getCategoriesData:function(){return this._categoriesData},formatTooltip:function(t,e,i){if("edge"===i){var n=this.getData(),a=this.getDataParams(t,i),r=n.graph.getEdgeByIndex(t),o=n.getName(r.node1.dataIndex),s=n.getName(r.node2.dataIndex),l=[];return null!=o&&l.push(o),null!=s&&l.push(s),l=no(l.join(" > ")),a.value&&(l+=" : "+no(a.value)),l}return YT.superApply(this,"formatTooltip",arguments)},_updateCategoriesData:function(){var t=p(this.option.categories||[],function(t){return null!=t.value?t:o({value:0},t)}),e=new kS(["value"],this);e.initData(t),this._categoriesData=e,this._categoriesModels=e.mapArray(function(t){return e.getItemModel(t,!0)})},setZoom:function(t){this.option.zoom=t},setCenter:function(t){this.option.center=t},isAnimationEnabled:function(){return YT.superCall(this,"isAnimationEnabled")&&!("force"===this.get("layout")&&this.get("force.layoutAnimation"))},defaultOption:{zlevel:0,z:2,coordinateSystem:"view",legendHoverLink:!0,hoverAnimation:!0,layout:null,focusNodeAdjacency:!1,circular:{rotateLabel:!1},force:{initLayout:null,repulsion:[0,50],gravity:.1,edgeLength:30,layoutAnimation:!0},left:"center",top:"center",symbol:"circle",symbolSize:10,edgeSymbol:["none","none"],edgeSymbolSize:10,edgeLabel:{position:"middle"},draggable:!1,roam:!1,center:null,zoom:1,nodeScaleRatio:.6,label:{show:!1,formatter:"{b}"},itemStyle:{},lineStyle:{color:"#aaa",width:1,curveness:0,opacity:.5},emphasis:{label:{show:!0}}}}),qT=Hw.prototype,$T=jw.prototype,KT=Za({type:"ec-line",style:{stroke:"#000",fill:null},shape:{x1:0,y1:0,x2:0,y2:0,percent:1,cpx1:null,cpy1:null},buildPath:function(t,e){(Hc(e)?qT:$T).buildPath(t,e)},pointAt:function(t){return Hc(this.shape)?qT.pointAt.call(this,t):$T.pointAt.call(this,t)},tangentAt:function(t){var e=this.shape,i=Hc(e)?[e.x2-e.x1,e.y2-e.y1]:$T.tangentAt.call(this,t);return te(i,i)}}),JT=["fromSymbol","toSymbol"],QT=qc.prototype;QT.beforeUpdate=Yc,QT._createLine=function(t,e,i){var n=t.hostModel,a=t.getItemLayout(e),r=Xc(a);r.shape.percent=0,Sr(r,{shape:{percent:1}},n,e),this.add(r);var o=new Pw({name:"label"});this.add(o),f(JT,function(i){var n=jc(i,t,e);this.add(n),this[Zc(i)]=t.getItemVisual(e,i)},this),this._updateCommonStl(t,e,i)},QT.updateData=function(t,e,i){var n=t.hostModel,a=this.childOfName("line"),r=t.getItemLayout(e),o={shape:{}};Uc(o.shape,r),Mr(a,o,n,e),f(JT,function(i){var n=t.getItemVisual(e,i),a=Zc(i);if(this[a]!==n){this.remove(this.childOfName(i));var r=jc(i,t,e);this.add(r)}this[a]=n},this),this._updateCommonStl(t,e,i)},QT._updateCommonStl=function(t,e,i){var n=t.hostModel,a=this.childOfName("line"),r=i&&i.lineStyle,o=i&&i.hoverLineStyle,l=i&&i.labelModel,h=i&&i.hoverLabelModel;if(!i||t.hasItemOption){var u=t.getItemModel(e);r=u.getModel("lineStyle").getLineStyle(),o=u.getModel("emphasis.lineStyle").getLineStyle(),l=u.getModel("label"),h=u.getModel("emphasis.label")}var c=t.getItemVisual(e,"color"),d=L(t.getItemVisual(e,"opacity"),r.opacity,1);a.useStyle(s({strokeNoScale:!0,fill:"none",stroke:c,opacity:d},r)),a.hoverStyle=o,f(JT,function(t){var e=this.childOfName(t);
-e&&(e.setColor(c),e.setStyle({opacity:d}))},this);var p,g,v,m=l.getShallow("show"),y=h.getShallow("show"),x=this.childOfName("label");if(m||y){if(p=c||"#000",g=n.getFormattedLabel(e,"normal",t.dataType),null==g){var _=n.getRawValue(e);g=null==_?t.getName(e):isFinite(_)?Fr(_):_}v=D(n.getFormattedLabel(e,"emphasis",t.dataType),g)}if(m){var w=fr(x.style,l,{text:g},{autoColor:p});x.__textAlign=w.textAlign,x.__verticalAlign=w.textVerticalAlign,x.__position=l.get("position")||"middle"}else x.setStyle("text",null);x.hoverStyle=y?{text:v,textFill:h.getTextColor(!0),fontStyle:h.getShallow("fontStyle"),fontWeight:h.getShallow("fontWeight"),fontSize:h.getShallow("fontSize"),fontFamily:h.getShallow("fontFamily")}:{text:null},x.ignore=!m&&!y,cr(this)},QT.highlight=function(){this.trigger("emphasis")},QT.downplay=function(){this.trigger("normal")},QT.updateLayout=function(t,e){this.setLinePoints(t.getItemLayout(e))},QT.setLinePoints=function(t){var e=this.childOfName("line");Uc(e.shape,t),e.dirty()},u(qc,xx);var tA=$c.prototype;tA.isPersistent=function(){return!0},tA.updateData=function(t){var e=this,i=e.group,n=e._lineData;e._lineData=t,n||i.removeAll();var a=Qc(t);t.diff(n).add(function(i){Kc(e,t,i,a)}).update(function(i,r){Jc(e,n,t,r,i,a)}).remove(function(t){i.remove(n.getItemGraphicEl(t))}).execute()},tA.updateLayout=function(){var t=this._lineData;t.eachItemGraphicEl(function(e,i){e.updateLayout(t,i)},this)},tA.incrementalPrepareUpdate=function(t){this._seriesScope=Qc(t),this._lineData=null,this.group.removeAll()},tA.incrementalUpdate=function(t,e){function i(t){t.isGroup||(t.incremental=t.useHoverLayer=!0)}for(var n=t.start;n<t.end;n++){var a=e.getItemLayout(n);if(ed(a)){var r=new this._ctor(e,n,this._seriesScope);r.traverse(i),this.group.add(r)}}},tA.remove=function(){this._clearIncremental(),this._incremental=null,this.group.removeAll()},tA._clearIncremental=function(){var t=this._incremental;t&&t.clearDisplaybles()};var eA="\x00_ec_interaction_mutex";Al({type:"takeGlobalCursor",event:"globalCursorTaken",update:"update"},function(){}),c(od,By);var iA={axisPointer:1,tooltip:1,brush:1},nA=[],aA=[],rA=[],oA=la,sA=Ey,lA=Math.abs,hA=function(t,e){function i(t){var e=t.getVisual("symbolSize");return e instanceof Array&&(e=(e[0]+e[1])/2),e}var n=[],a=da,r=[[],[],[]],o=[[],[]],s=[];e/=2,t.eachEdge(function(t){var l=t.getLayout(),h=t.getVisual("fromSymbol"),u=t.getVisual("toSymbol");l.__original||(l.__original=[H(l[0]),H(l[1])],l[2]&&l.__original.push(H(l[2])));var c=l.__original;if(null!=l[2]){if(W(r[0],c[0]),W(r[1],c[2]),W(r[2],c[1]),h&&"none"!=h){var d=i(t.node1),f=md(r,c[0],d*e);a(r[0][0],r[1][0],r[2][0],f,n),r[0][0]=n[3],r[1][0]=n[4],a(r[0][1],r[1][1],r[2][1],f,n),r[0][1]=n[3],r[1][1]=n[4]}if(u&&"none"!=u){var d=i(t.node2),f=md(r,c[1],d*e);a(r[0][0],r[1][0],r[2][0],f,n),r[1][0]=n[1],r[2][0]=n[2],a(r[0][1],r[1][1],r[2][1],f,n),r[1][1]=n[1],r[2][1]=n[2]}W(l[0],r[0]),W(l[1],r[2]),W(l[2],r[1])}else{if(W(o[0],c[0]),W(o[1],c[1]),U(s,o[1],o[0]),te(s,s),h&&"none"!=h){var d=i(t.node1);X(o[0],o[0],s,d*e)}if(u&&"none"!=u){var d=i(t.node2);X(o[1],o[1],s,-d*e)}W(l[0],o[0]),W(l[1],o[1])}})},uA=["itemStyle","opacity"],cA=["lineStyle","opacity"];Nl({type:"graph",init:function(t,e){var i=new Ru,n=new $c,a=this.group;this._controller=new od(e.getZr()),this._controllerHost={target:a},a.add(i.group),a.add(n.group),this._symbolDraw=i,this._lineDraw=n,this._firstRender=!0},render:function(t,e,i){var n=t.coordinateSystem;this._model=t,this._nodeScaleRatio=t.get("nodeScaleRatio");var a=this._symbolDraw,r=this._lineDraw,o=this.group;if("view"===n.type){var s={position:n.position,scale:n.scale};this._firstRender?o.attr(s):Mr(o,s,t)}hA(t.getGraph(),this._getNodeGlobalScale(t));var l=t.getData();a.updateData(l);var h=t.getEdgeData();r.updateData(h),this._updateNodeAndLinkScale(),this._updateController(t,e,i),clearTimeout(this._layoutTimeout);var u=t.forceLayout,c=t.get("force.layoutAnimation");u&&this._startForceLayoutIteration(u,c),l.eachItemGraphicEl(function(e,n){var a=l.getItemModel(n);e.off("drag").off("dragend");var r=l.getItemModel(n).get("draggable");r&&e.on("drag",function(){u&&(u.warmUp(),!this._layouting&&this._startForceLayoutIteration(u,c),u.setFixed(n),l.setItemLayout(n,e.position))},this).on("dragend",function(){u&&u.setUnfixed(n)},this),e.setDraggable(r&&u),e.off("mouseover",e.__focusNodeAdjacency),e.off("mouseout",e.__unfocusNodeAdjacency),a.get("focusNodeAdjacency")&&(e.on("mouseover",e.__focusNodeAdjacency=function(){i.dispatchAction({type:"focusNodeAdjacency",seriesId:t.id,dataIndex:e.dataIndex})}),e.on("mouseout",e.__unfocusNodeAdjacency=function(){i.dispatchAction({type:"unfocusNodeAdjacency",seriesId:t.id})}))},this),l.graph.eachEdge(function(e){var n=e.getGraphicEl();n.off("mouseover",n.__focusNodeAdjacency),n.off("mouseout",n.__unfocusNodeAdjacency),e.getModel().get("focusNodeAdjacency")&&(n.on("mouseover",n.__focusNodeAdjacency=function(){i.dispatchAction({type:"focusNodeAdjacency",seriesId:t.id,edgeDataIndex:e.dataIndex})}),n.on("mouseout",n.__unfocusNodeAdjacency=function(){i.dispatchAction({type:"unfocusNodeAdjacency",seriesId:t.id})}))});var d="circular"===t.get("layout")&&t.get("circular.rotateLabel"),f=l.getLayout("cx"),p=l.getLayout("cy");l.eachItemGraphicEl(function(t,e){var i=t.getSymbolPath();if(d){var n=l.getItemLayout(e),a=Math.atan2(n[1]-p,n[0]-f);0>a&&(a=2*Math.PI+a);var r=n[0]<f;r&&(a-=Math.PI);var o=r?"left":"right";i.setStyle({textRotation:-a,textPosition:o,textOrigin:"center"}),i.hoverStyle&&(i.hoverStyle.textPosition=o)}else i.setStyle({textRotation:0})}),this._firstRender=!1},dispose:function(){this._controller&&this._controller.dispose(),this._controllerHost={}},focusNodeAdjacency:function(t,e,i,n){var a=this._model.getData(),r=a.graph,o=n.dataIndex,s=n.edgeDataIndex,l=r.getNodeByIndex(o),h=r.getEdgeByIndex(s);(l||h)&&(r.eachNode(function(t){xd(t,uA,.1)}),r.eachEdge(function(t){xd(t,cA,.1)}),l&&(_d(l,uA),f(l.edges,function(t){t.dataIndex<0||(_d(t,cA),_d(t.node1,uA),_d(t.node2,uA))})),h&&(_d(h,cA),_d(h.node1,uA),_d(h.node2,uA)))},unfocusNodeAdjacency:function(){var t=this._model.getData().graph;t.eachNode(function(t){xd(t,uA)}),t.eachEdge(function(t){xd(t,cA)})},_startForceLayoutIteration:function(t,e){var i=this;!function n(){t.step(function(t){i.updateLayout(i._model),(i._layouting=!t)&&(e?i._layoutTimeout=setTimeout(n,16):n())})}()},_updateController:function(t,e,i){var n=this._controller,a=this._controllerHost,r=this.group;return n.setPointerChecker(function(e,n,a){var o=r.getBoundingRect();return o.applyTransform(r.transform),o.contain(n,a)&&!vd(e,i,t)}),"view"!==t.coordinateSystem.type?void n.disable():(n.enable(t.get("roam")),a.zoomLimit=t.get("scaleLimit"),a.zoom=t.coordinateSystem.getZoom(),void n.off("pan").off("zoom").on("pan",function(e,n){pd(a,e,n),i.dispatchAction({seriesId:t.id,type:"graphRoam",dx:e,dy:n})}).on("zoom",function(e,n,r){gd(a,e,n,r),i.dispatchAction({seriesId:t.id,type:"graphRoam",zoom:e,originX:n,originY:r}),this._updateNodeAndLinkScale(),hA(t.getGraph(),this._getNodeGlobalScale(t)),this._lineDraw.updateLayout()},this))},_updateNodeAndLinkScale:function(){var t=this._model,e=t.getData(),i=this._getNodeGlobalScale(t),n=[i,i];e.eachItemGraphicEl(function(t){t.attr("scale",n)})},_getNodeGlobalScale:function(t){var e=t.coordinateSystem;if("view"!==e.type)return 1;var i=this._nodeScaleRatio,n=e.scale,a=n&&n[0]||1,r=e.getZoom(),o=(r-1)*i+1;return o/a},updateLayout:function(t){hA(t.getGraph(),this._getNodeGlobalScale(t)),this._symbolDraw.updateLayout(),this._lineDraw.updateLayout()},remove:function(){this._symbolDraw&&this._symbolDraw.remove(),this._lineDraw&&this._lineDraw.remove()}});var dA={type:"graphRoam",event:"graphRoam",update:"none"};Al(dA,function(t,e){e.eachComponent({mainType:"series",query:t},function(e){var i=e.coordinateSystem,n=wd(i,t);e.setCenter&&e.setCenter(n.center),e.setZoom&&e.setZoom(n.zoom)})}),Al({type:"focusNodeAdjacency",event:"focusNodeAdjacency",update:"series.graph:focusNodeAdjacency"},function(){}),Al({type:"unfocusNodeAdjacency",event:"unfocusNodeAdjacency",update:"series.graph:unfocusNodeAdjacency"},function(){});var fA=function(t){var e=t.findComponents({mainType:"legend"});e&&e.length&&t.eachSeriesByType("graph",function(t){var i=t.getCategoriesData(),n=t.getGraph(),a=n.data,r=i.mapArray(i.getName);a.filterSelf(function(t){var i=a.getItemModel(t),n=i.getShallow("category");if(null!=n){"number"==typeof n&&(n=r[n]);for(var o=0;o<e.length;o++)if(!e[o].isSelected(n))return!1}return!0})},this)},pA=function(t){var e={};t.eachSeriesByType("graph",function(t){var i=t.getCategoriesData(),n=t.getData(),a={};i.each(function(n){var r=i.getName(n);a["ec-"+r]=n;var o=i.getItemModel(n),s=o.get("itemStyle.color")||t.getColorFromPalette(r,e);i.setItemVisual(n,"color",s)}),i.count()&&n.each(function(t){var e=n.getItemModel(t),r=e.getShallow("category");null!=r&&("string"==typeof r&&(r=a["ec-"+r]),n.getItemVisual(t,"color",!0)||n.setItemVisual(t,"color",i.getItemVisual(r,"color")))})})},gA=function(t){t.eachSeriesByType("graph",function(t){var e=t.getGraph(),i=t.getEdgeData(),n=bd(t.get("edgeSymbol")),a=bd(t.get("edgeSymbolSize")),r="lineStyle.color".split("."),o="lineStyle.opacity".split(".");i.setVisual("fromSymbol",n&&n[0]),i.setVisual("toSymbol",n&&n[1]),i.setVisual("fromSymbolSize",a&&a[0]),i.setVisual("toSymbolSize",a&&a[1]),i.setVisual("color",t.get(r)),i.setVisual("opacity",t.get(o)),i.each(function(t){var n=i.getItemModel(t),a=e.getEdgeByIndex(t),s=bd(n.getShallow("symbol",!0)),l=bd(n.getShallow("symbolSize",!0)),h=n.get(r),u=n.get(o);switch(h){case"source":h=a.node1.getVisual("color");break;case"target":h=a.node2.getVisual("color")}s[0]&&a.setVisual("fromSymbol",s[0]),s[1]&&a.setVisual("toSymbol",s[1]),l[0]&&a.setVisual("fromSymbolSize",l[0]),l[1]&&a.setVisual("toSymbolSize",l[1]),a.setVisual("color",h),a.setVisual("opacity",u)})})},vA=function(t){t.eachSeriesByType("graph",function(t){var e=t.get("layout"),i=t.coordinateSystem;if(i&&"view"!==i.type){var n=t.getData(),a=[];f(i.dimensions,function(t){a=a.concat(n.mapDimension(t,!0))});for(var r=0;r<n.count();r++){for(var o=[],s=!1,l=0;l<a.length;l++){var h=n.get(a[l],r);isNaN(h)||(s=!0),o.push(h)}s?n.setItemLayout(r,i.dataToPoint(o)):n.setItemLayout(r,[0/0,0/0])}Sd(n.graph)}else e&&"none"!==e||Md(t)})},mA=function(t){t.eachSeriesByType("graph",function(t){"circular"===t.get("layout")&&Id(t)})},yA=X,xA=function(t){t.eachSeriesByType("graph",function(t){var e=t.coordinateSystem;if(!e||"view"===e.type)if("force"===t.get("layout")){var i=t.preservedPoints||{},n=t.getGraph(),a=n.data,r=n.edgeData,o=t.getModel("force"),s=o.get("initLayout");t.preservedPoints?a.each(function(t){var e=a.getId(t);a.setItemLayout(t,i[e]||[0/0,0/0])}):s&&"none"!==s?"circular"===s&&Id(t):Md(t);var l=a.getDataExtent("value"),h=r.getDataExtent("value"),u=o.get("repulsion"),c=o.get("edgeLength");_(u)||(u=[u,u]),_(c)||(c=[c,c]),c=[c[1],c[0]];var d=a.mapArray("value",function(t,e){var i=a.getItemLayout(e),n=Vr(t,l,u);return isNaN(n)&&(n=(u[0]+u[1])/2),{w:n,rep:n,fixed:a.getItemModel(e).get("fixed"),p:!i||isNaN(i[0])||isNaN(i[1])?null:i}}),f=r.mapArray("value",function(t,e){var i=n.getEdgeByIndex(e),a=Vr(t,h,c);return isNaN(a)&&(a=(c[0]+c[1])/2),{n1:d[i.node1.dataIndex],n2:d[i.node2.dataIndex],d:a,curveness:i.getModel().get("lineStyle.curveness")||0}}),e=t.coordinateSystem,p=e.getBoundingRect(),g=Td(d,f,{rect:p,gravity:o.get("gravity")}),v=g.step;g.step=function(t){for(var e=0,r=d.length;r>e;e++)d[e].fixed&&W(d[e].p,n.getNodeByIndex(e).getLayout());v(function(e,r,o){for(var s=0,l=e.length;l>s;s++)e[s].fixed||n.getNodeByIndex(s).setLayout(e[s].p),i[a.getId(s)]=e[s].p;for(var s=0,l=r.length;l>s;s++){var h=r[s],u=n.getEdgeByIndex(s),c=h.n1.p,d=h.n2.p,f=u.getLayout();f=f?f.slice():[],f[0]=f[0]||[],f[1]=f[1]||[],W(f[0],c),W(f[1],d),+h.curveness&&(f[2]=[(c[0]+d[0])/2-(c[1]-d[1])*h.curveness,(c[1]+d[1])/2-(d[0]-c[0])*h.curveness]),u.setLayout(f)}t&&t(o)})},t.forceLayout=g,t.preservedPoints=i,g.step()}else t.forceLayout=null})},_A=re;c(Ad,Xy),Cd.prototype={constructor:Cd,type:"view",dimensions:["x","y"],setBoundingRect:function(t,e,i,n){return this._rect=new ni(t,e,i,n),this._rect},getBoundingRect:function(){return this._rect},setViewRect:function(t,e,i,n){this.transformTo(t,e,i,n),this._viewRect=new ni(t,e,i,n)},transformTo:function(t,e,i,n){var a=this.getBoundingRect(),r=this._rawTransformable;r.transform=a.calculateTransform(new ni(t,e,i,n)),r.decomposeTransform(),this._updateTransform()},setCenter:function(t){t&&(this._center=t,this._updateCenterAndZoom())},setZoom:function(t){t=t||1;var e=this.zoomLimit;e&&(null!=e.max&&(t=Math.min(e.max,t)),null!=e.min&&(t=Math.max(e.min,t))),this._zoom=t,this._updateCenterAndZoom()},getDefaultCenter:function(){var t=this.getBoundingRect(),e=t.x+t.width/2,i=t.y+t.height/2;return[e,i]},getCenter:function(){return this._center||this.getDefaultCenter()},getZoom:function(){return this._zoom||1},getRoamTransform:function(){return this._roamTransformable.getLocalTransform()},_updateCenterAndZoom:function(){var t=this._rawTransformable.getLocalTransform(),e=this._roamTransformable,i=this.getDefaultCenter(),n=this.getCenter(),a=this.getZoom();n=re([],n,t),i=re([],i,t),e.origin=n,e.position=[i[0]-n[0],i[1]-n[1]],e.scale=[a,a],this._updateTransform()},_updateTransform:function(){var t=this._roamTransformable,e=this._rawTransformable;e.parent=t,t.updateTransform(),e.updateTransform(),ge(this.transform||(this.transform=[]),e.transform||fe()),this._rawTransform=e.getLocalTransform(),this.invTransform=this.invTransform||[],_e(this.invTransform,this.transform),this.decomposeTransform()},getViewRect:function(){return this._viewRect},getViewRectAfterRoam:function(){var t=this.getBoundingRect().clone();return t.applyTransform(this.transform),t},dataToPoint:function(t,e,i){var n=e?this._rawTransform:this.transform;return i=i||[],n?_A(i,t,n):W(i,t)},pointToData:function(t){var e=this.invTransform;return e?_A([],t,e):[t[0],t[1]]},convertToPixel:x(Dd,"dataToPoint"),convertFromPixel:x(Dd,"pointToData"),containPoint:function(t){return this.getViewRectAfterRoam().contain(t[0],t[1])}},c(Cd,Xy);var wA=function(t,e){var i=[];return t.eachSeriesByType("graph",function(t){var n=t.get("coordinateSystem");if(!n||"view"===n){var a=t.getData(),r=a.mapArray(function(t){var e=a.getItemModel(t);return[+e.get("x"),+e.get("y")]}),o=[],s=[];pa(r,o,s),s[0]-o[0]===0&&(s[0]+=1,o[0]-=1),s[1]-o[1]===0&&(s[1]+=1,o[1]-=1);var l=(s[0]-o[0])/(s[1]-o[1]),h=Ld(t,e,l);isNaN(l)&&(o=[h.x,h.y],s=[h.x+h.width,h.y+h.height]);var u=s[0]-o[0],c=s[1]-o[1],d=h.width,f=h.height,p=t.coordinateSystem=new Cd;p.zoomLimit=t.get("scaleLimit"),p.setBoundingRect(o[0],o[1],u,c),p.setViewRect(h.x,h.y,d,f),p.setCenter(t.get("center")),p.setZoom(t.get("zoom")),i.push(p)}}),i};Il(fA),kl(_T("graph","circle",null)),kl(pA),kl(gA),Ll(vA),Ll(mA),Ll(xA),Cl("graphView",{create:wA});var bA=function(t){kd(t),Pd(t)},MA=function(t,e,i,n,a){wI.call(this,t,e,i),this.type=n||"value",this.axisIndex=a};MA.prototype={constructor:MA,model:null,isHorizontal:function(){return"horizontal"!==this.coordinateSystem.getModel().get("layout")}},u(MA,wI);var SA=function(t,e,i,n,a,r){e[0]=zd(e[0],i),e[1]=zd(e[1],i),t=t||0;var o=i[1]-i[0];null!=a&&(a=zd(a,[0,o])),null!=r&&(r=Math.max(r,null!=a?a:0)),"all"===n&&(a=r=Math.abs(e[1]-e[0]),n=0);var s=Od(e,n);e[n]+=t;var l=a||0,h=i.slice();s.sign<0?h[0]+=l:h[1]-=l,e[n]=zd(e[n],h);var u=Od(e,n);null!=a&&(u.sign!==s.sign||u.span<a)&&(e[1-n]=e[n]+s.sign*a);var u=Od(e,n);return null!=r&&u.span>r&&(e[1-n]=e[n]+u.sign*r),e},IA=f,TA=Math.min,AA=Math.max,CA=Math.floor,DA=Math.ceil,LA=Fr,kA=Math.PI;Ed.prototype={type:"parallel",constructor:Ed,_init:function(t,e){var i=t.dimensions,n=t.parallelAxisIndex;IA(i,function(t,i){var a=n[i],r=e.getComponent("parallelAxis",a),o=this._axesMap.set(t,new MA(t,Ch(r),[0,0],r.get("type"),a)),s="category"===o.type;o.onBand=s&&r.get("boundaryGap"),o.inverse=r.get("inverse"),r.axis=o,o.model=r,o.coordinateSystem=r.coordinateSystem=this},this)},update:function(t){this._updateAxesFromSeries(this._model,t)},containPoint:function(t){var e=this._makeLayoutInfo(),i=e.axisBase,n=e.layoutBase,a=e.pixelDimIndex,r=t[1-a],o=t[a];return r>=i&&r<=i+e.axisLength&&o>=n&&o<=n+e.layoutLength},getModel:function(){return this._model},_updateAxesFromSeries:function(t,e){e.eachSeries(function(i){if(t.contains(i,e)){var n=i.getData();IA(this.dimensions,function(t){var e=this._axesMap.get(t);e.scale.unionExtentFromData(n,n.mapDimension(t)),Ah(e.scale,e.model)},this)}},this)},resize:function(t,e){this._rect=uo(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()}),this._layoutAxes()},getRect:function(){return this._rect},_makeLayoutInfo:function(){var t,e=this._model,i=this._rect,n=["x","y"],a=["width","height"],r=e.get("layout"),o="horizontal"===r?0:1,s=i[a[o]],l=[0,s],h=this.dimensions.length,u=Rd(e.get("axisExpandWidth"),l),c=Rd(e.get("axisExpandCount")||0,[0,h]),d=e.get("axisExpandable")&&h>3&&h>c&&c>1&&u>0&&s>0,f=e.get("axisExpandWindow");if(f)t=Rd(f[1]-f[0],l),f[1]=f[0]+t;else{t=Rd(u*(c-1),l);var p=e.get("axisExpandCenter")||CA(h/2);f=[u*p-t/2],f[1]=f[0]+t}var g=(s-t)/(h-c);3>g&&(g=0);var v=[CA(LA(f[0]/u,1))+1,DA(LA(f[1]/u,1))-1],m=g/u*f[0];return{layout:r,pixelDimIndex:o,layoutBase:i[n[o]],layoutLength:s,axisBase:i[n[1-o]],axisLength:i[a[1-o]],axisExpandable:d,axisExpandWidth:u,axisCollapseWidth:g,axisExpandWindow:f,axisCount:h,winInnerIndices:v,axisExpandWindow0Pos:m}},_layoutAxes:function(){var t=this._rect,e=this._axesMap,i=this.dimensions,n=this._makeLayoutInfo(),a=n.layout;e.each(function(t){var e=[0,n.axisLength],i=t.inverse?1:0;t.setExtent(e[i],e[1-i])}),IA(i,function(i,r){var o=(n.axisExpandable?Bd:Nd)(r,n),s={horizontal:{x:o.position,y:n.axisLength},vertical:{x:0,y:o.position}},l={horizontal:kA/2,vertical:0},h=[s[a].x+t.x,s[a].y+t.y],u=l[a],c=fe();ye(c,c,u),me(c,c,h),this._axesLayout[i]={position:h,rotation:u,transform:c,axisNameAvailableWidth:o.axisNameAvailableWidth,axisLabelShow:o.axisLabelShow,nameTruncateMaxWidth:o.nameTruncateMaxWidth,tickDirection:1,labelDirection:1,labelInterval:e.get(i).getLabelInterval()}},this)},getAxis:function(t){return this._axesMap.get(t)},dataToPoint:function(t,e){return this.axisCoordToPoint(this._axesMap.get(e).dataToCoord(t),e)},eachActiveState:function(t,e,i){for(var n=this.dimensions,a=p(n,function(e){return t.mapDimension(e)}),r=this._axesMap,o=this.hasAxisBrushed(),s=0,l=t.count();l>s;s++){var h,u=t.getValues(a,s);if(o){h="active";for(var c=0,d=n.length;d>c;c++){var f=n[c],g=r.get(f).model.getActiveState(u[c],c);if("inactive"===g){h="inactive";break}}}else h="normal";e.call(i,h,s)}},hasAxisBrushed:function(){for(var t=this.dimensions,e=this._axesMap,i=!1,n=0,a=t.length;a>n;n++)"normal"!==e.get(t[n]).model.getActiveState()&&(i=!0);return i},axisCoordToPoint:function(t,e){var i=this._axesLayout[e];return Tr([t,0],i.transform)},getAxisLayout:function(t){return n(this._axesLayout[t])},getSlidedAxisExpandWindow:function(t){var e=this._makeLayoutInfo(),i=e.pixelDimIndex,n=e.axisExpandWindow.slice(),a=n[1]-n[0],r=[0,e.axisExpandWidth*(e.axisCount-1)];if(!this.containPoint(t))return{behavior:"none",axisExpandWindow:n};var o,s=t[i]-e.layoutBase-e.axisExpandWindow0Pos,l="slide",h=e.axisCollapseWidth,u=this._model.get("axisExpandSlideTriggerArea"),c=null!=u[0];if(h)c&&h&&s<a*u[0]?(l="jump",o=s-a*u[2]):c&&h&&s>a*(1-u[0])?(l="jump",o=s-a*(1-u[2])):(o=s-a*u[1])>=0&&(o=s-a*(1-u[1]))<=0&&(o=0),o*=e.axisExpandWidth/h,o?SA(o,n,r,"all"):l="none";else{var a=n[1]-n[0],d=r[1]*s/a;n=[AA(0,d-a/2)],n[1]=TA(r[1],n[0]+a),n[0]=n[1]-a}return{axisExpandWindow:n,behavior:l}}},Fo.register("parallel",{create:Vd});var PA=Cb.extend({type:"baseParallelAxis",axis:null,activeIntervals:[],getAreaSelectStyle:function(){return T_([["fill","color"],["lineWidth","borderWidth"],["stroke","borderColor"],["width","width"],["opacity","opacity"]])(this.getModel("areaSelectStyle"))},setActiveIntervals:function(t){var e=this.activeIntervals=n(t);if(e)for(var i=e.length-1;i>=0;i--)Wr(e[i])},getActiveState:function(t){var e=this.activeIntervals;if(!e.length)return"normal";if(null==t)return"inactive";for(var i=0,n=e.length;n>i;i++)if(e[i][0]<=t&&t<=e[i][1])return"active";return"inactive"}}),OA={type:"value",dim:null,areaSelectStyle:{width:20,borderWidth:1,borderColor:"rgba(160,197,232)",color:"rgba(160,197,232)",opacity:.3},realtime:!0,z:10};a(PA.prototype,sI),DI("parallel",PA,Gd,OA),Cb.extend({type:"parallel",dependencies:["parallelAxis"],coordinateSystem:null,dimensions:null,parallelAxisIndex:null,layoutMode:"box",defaultOption:{zlevel:0,z:0,left:80,top:60,right:80,bottom:60,layout:"horizontal",axisExpandable:!1,axisExpandCenter:null,axisExpandCount:0,axisExpandWidth:50,axisExpandRate:17,axisExpandDebounce:50,axisExpandSlideTriggerArea:[-.15,.05,.4],axisExpandTriggerOn:"click",parallelAxisDefault:null},init:function(){Cb.prototype.init.apply(this,arguments),this.mergeOption({})},mergeOption:function(t){var e=this.option;t&&a(e,t,!0),this._initDimensions()},contains:function(t,e){var i=t.get("parallelIndex");return null!=i&&e.getComponent("parallel",i)===this},setAxisExpand:function(t){f(["axisExpandable","axisExpandCenter","axisExpandCount","axisExpandWidth","axisExpandWindow"],function(e){t.hasOwnProperty(e)&&(this.option[e]=t[e])},this)},_initDimensions:function(){var t=this.dimensions=[],e=this.parallelAxisIndex=[],i=v(this.dependentModels.parallelAxis,function(t){return(t.get("parallelIndex")||0)===this.componentIndex},this);f(i,function(i){t.push("dim"+i.get("dim")),e.push(i.componentIndex)})}});var zA={type:"axisAreaSelect",event:"axisAreaSelected"};Al(zA,function(t,e){e.eachComponent({mainType:"parallelAxis",query:t},function(e){e.axis.model.setActiveIntervals(t.intervals)})}),Al("parallelAxisExpand",function(t,e){e.eachComponent({mainType:"parallel",query:t},function(e){e.setAxisExpand(t)})});var EA=x,RA=f,NA=p,BA=Math.min,VA=Math.max,GA=Math.pow,FA=1e4,WA=6,HA=6,ZA="globalPan",jA={w:[0,0],e:[0,1],n:[1,0],s:[1,1]},XA={w:"ew",e:"ew",n:"ns",s:"ns",ne:"nesw",sw:"nesw",nw:"nwse",se:"nwse"},UA={brushStyle:{lineWidth:2,stroke:"rgba(0,0,0,0.3)",fill:"rgba(0,0,0,0.1)"},transformable:!0,brushMode:"single",removeOnClick:!1},YA=0;Fd.prototype={constructor:Fd,enableBrush:function(t){return this._brushType&&Hd(this),t.brushType&&Wd(this,t),this},setPanels:function(t){if(t&&t.length){var e=this._panels={};f(t,function(t){e[t.panelId]=n(t)})}else this._panels=null;return this},mount:function(t){t=t||{},this._enableGlobalPan=t.enableGlobalPan;var e=this.group;return this._zr.add(e),e.attr({position:t.position||[0,0],rotation:t.rotation||0,scale:t.scale||[1,1]}),this._transform=e.getLocalTransform(),this},eachCover:function(t,e){RA(this._covers,t,e)},updateCovers:function(t){function e(t,e){return(null!=t.id?t.id:s+e)+"-"+t.brushType}function i(t,i){return e(t.__brushOption,i)}function r(e,i){var n=t[e];if(null!=i&&l[i]===c)h[e]=l[i];else{var a=h[e]=null!=i?(l[i].__brushOption=n,l[i]):jd(u,Zd(u,n));Yd(u,a)}}function o(t){l[t]!==c&&u.group.remove(l[t])}t=p(t,function(t){return a(n(UA),t,!0)});var s="\x00-brush-index-",l=this._covers,h=this._covers=[],u=this,c=this._creatingCover;return new Wl(l,t,i,e).add(r).update(r).remove(o).execute(),this},unmount:function(){return this.enableBrush(!1),Jd(this),this._zr.remove(this.group),this},dispose:function(){this.unmount(),this.off()}},c(Fd,By);var qA={mousedown:function(t){if(this._dragging)wf.call(this,t);else if(!t.target||!t.target.draggable){mf(t);var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY);this._creatingCover=null;var i=this._creatingPanel=$d(this,t,e);i&&(this._dragging=!0,this._track=[e.slice()])}},mousemove:function(t){var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY);if(vf(this,t,e),this._dragging){mf(t);var i=xf(this,t,e,!1);i&&Qd(this,i)}},mouseup:wf},$A={lineX:bf(0),lineY:bf(1),rect:{createCover:function(t,e){return nf(EA(cf,function(t){return t},function(t){return t}),t,e,["w","e","n","s","se","sw","ne","nw"])},getCreatingRange:function(t){var e=ef(t);return lf(e[1][0],e[1][1],e[0][0],e[0][1])},updateCoverShape:function(t,e,i,n){af(t,e,i,n)},updateCommon:rf,contain:yf},polygon:{createCover:function(t,e){var i=new xx;return i.add(new Fw({name:"main",style:sf(e),silent:!0})),i},getCreatingRange:function(t){return t},endCreating:function(t,e){e.remove(e.childAt(0)),e.add(new Gw({name:"main",draggable:!0,drift:EA(df,t,e),ondragend:EA(Qd,t,{isEnd:!0})}))},updateCoverShape:function(t,e,i){e.childAt(0).setShape({points:pf(t,e,i)})},updateCommon:rf,contain:yf}},KA=["axisLine","axisTickLabel","axisName"],JA=El({type:"parallelAxis",init:function(t,e){JA.superApply(this,"init",arguments),(this._brushController=new Fd(e.getZr())).on("brush",y(this._onBrush,this))},render:function(t,e,i,n){if(!Af(t,e,n)){this.axisModel=t,this.api=i,this.group.removeAll();var a=this._axisGroup;if(this._axisGroup=new xx,this.group.add(this._axisGroup),t.get("show")){var r=Df(t,e),s=r.coordinateSystem,l=t.getAreaSelectStyle(),h=l.width,u=t.axis.dim,c=s.getAxisLayout(u),d=o({strokeContainThreshold:h},c),p=new ZI(t,d);f(KA,p.add,p),this._axisGroup.add(p.getGroup()),this._refreshBrushController(d,l,t,r,h,i);var g=n&&n.animation===!1?null:t;Cr(a,this._axisGroup,g)}}},_refreshBrushController:function(t,e,i,n,a,r){var o=i.axis.getExtent(),s=o[1]-o[0],l=Math.min(30,.1*Math.abs(s)),h=ni.create({x:o[0],y:-a/2,width:s,height:a});h.x-=l,h.width+=2*l,this._brushController.mount({enableGlobalPan:!0,rotation:t.rotation,position:t.position}).setPanels([{panelId:"pl",clipPath:Mf(h),isTargetByCursor:If(h,r,n),getLinearBrushOtherExtent:Sf(h,0)}]).enableBrush({brushType:"lineX",brushStyle:e,removeOnClick:!0}).updateCovers(Cf(i))},_onBrush:function(t,e){var i=this.axisModel,n=i.axis,a=p(t,function(t){return[n.coordToData(t.range[0],!0),n.coordToData(t.range[1],!0)]});(!i.option.realtime===e.isEnd||e.removeOnClick)&&this.api.dispatchAction({type:"axisAreaSelect",parallelAxisId:i.id,intervals:a})},dispose:function(){this._brushController.dispose()}}),QA=5;El({type:"parallel",render:function(t,e,i){this._model=t,this._api=i,this._handlers||(this._handlers={},f(tC,function(t,e){i.getZr().on(e,this._handlers[e]=y(t,this))},this)),ks(this,"_throttledDispatchExpand",t.get("axisExpandRate"),"fixRate")},dispose:function(t,e){f(this._handlers,function(t,i){e.getZr().off(i,t)}),this._handlers=null},_throttledDispatchExpand:function(t){this._dispatchExpand(t)},_dispatchExpand:function(t){t&&this._api.dispatchAction(o({type:"parallelAxisExpand"},t))}});var tC={mousedown:function(t){Lf(this,"click")&&(this._mouseDownPoint=[t.offsetX,t.offsetY])},mouseup:function(t){var e=this._mouseDownPoint;if(Lf(this,"click")&&e){var i=[t.offsetX,t.offsetY],n=Math.pow(e[0]-i[0],2)+Math.pow(e[1]-i[1],2);if(n>QA)return;var a=this._model.coordinateSystem.getSlidedAxisExpandWindow([t.offsetX,t.offsetY]);"none"!==a.behavior&&this._dispatchExpand({axisExpandWindow:a.axisExpandWindow})}this._mouseDownPoint=null},mousemove:function(t){if(!this._mouseDownPoint&&Lf(this,"mousemove")){var e=this._model,i=e.coordinateSystem.getSlidedAxisExpandWindow([t.offsetX,t.offsetY]),n=i.behavior;"jump"===n&&this._throttledDispatchExpand.debounceNextCall(e.get("axisExpandDebounce")),this._throttledDispatchExpand("none"===n?null:{axisExpandWindow:i.axisExpandWindow,animation:"jump"===n?null:!1})}}};Sl(bA),fM.extend({type:"series.parallel",dependencies:["parallel"],visualColorAccessPath:"lineStyle.color",getInitialData:function(){this.option.progressive&&(this.option.animation=!1);var t=this.getSource();return kf(t,this),rh(t,this)},getRawIndicesByActiveState:function(t){var e=this.coordinateSystem,i=this.getData(),n=[];return e.eachActiveState(i,function(e,a){t===e&&n.push(i.getRawIndex(a))}),n},defaultOption:{zlevel:0,z:2,coordinateSystem:"parallel",parallelIndex:0,label:{show:!1},inactiveOpacity:.05,activeOpacity:1,lineStyle:{width:1,opacity:.45,type:"solid"},emphasis:{label:{show:!1}},progressive:!1,smooth:!1,animationEasing:"linear"}});var eC=.3,iC=(Ss.extend({type:"parallel",init:function(){this._dataGroup=new xx,this.group.add(this._dataGroup),this._data},render:function(t,e,i,n){this._renderForNormal(t,n)},dispose:function(){},_renderForNormal:function(t,e){function i(t){Ef(o,r,t,h,l,null,c)}function n(i,n){var a=s.getItemGraphicEl(n),r=zf(o,i,h,l);o.setItemGraphicEl(i,a);var u=e&&e.animation===!1?null:t;Mr(a,{shape:{points:r}},u,i)}function a(t){var e=s.getItemGraphicEl(t);r.remove(e)}var r=this._dataGroup,o=t.getData(),s=this._data,l=t.coordinateSystem,h=l.dimensions,u=t.option,c=u.smooth?eC:null;if(o.diff(s).add(i).update(n).remove(a).execute(),Rf(o,c),!this._data){var d=Of(l,t,function(){setTimeout(function(){r.removeClipPath()})});r.setClipPath(d)}this._data=o},remove:function(){this._dataGroup&&this._dataGroup.removeAll(),this._data=null}}),["lineStyle","normal","opacity"]),nC=function(t){t.eachSeriesByType("parallel",function(e){var i=e.getModel("itemStyle"),n=e.getModel("lineStyle"),a=t.get("color"),r=n.get("color")||i.get("color")||a[e.seriesIndex%a.length],o=e.get("inactiveOpacity"),s=e.get("activeOpacity"),l=e.getModel("lineStyle").getLineStyle(),h=e.coordinateSystem,u=e.getData(),c={normal:l.opacity,active:s,inactive:o};h.eachActiveState(u,function(t,e){var i=u.getItemModel(e),n=c[t];if("normal"===t){var a=i.get(iC,!0);null!=a&&(n=a)}u.setItemVisual(e,"opacity",n)}),u.setVisual("color",r)})};kl(nC);var aC=(fM.extend({type:"series.gauge",getInitialData:function(t){var e=t.data||[];return _(e)||(e=[e]),t.data=e,IT(this,["value"])},defaultOption:{zlevel:0,z:2,center:["50%","50%"],legendHoverLink:!0,radius:"75%",startAngle:225,endAngle:-45,clockwise:!0,min:0,max:100,splitNumber:10,axisLine:{show:!0,lineStyle:{color:[[.2,"#91c7ae"],[.8,"#63869e"],[1,"#c23531"]],width:30}},splitLine:{show:!0,length:30,lineStyle:{color:"#eee",width:2,type:"solid"}},axisTick:{show:!0,splitNumber:5,length:8,lineStyle:{color:"#eee",width:1,type:"solid"}},axisLabel:{show:!0,distance:5,color:"auto"},pointer:{show:!0,length:"80%",width:8},itemStyle:{color:"auto"},title:{show:!0,offsetCenter:[0,"-40%"],color:"#333",fontSize:15},detail:{show:!0,backgroundColor:"rgba(0,0,0,0)",borderWidth:0,borderColor:"#ccc",width:100,height:null,padding:[5,10],offsetCenter:[0,"40%"],color:"auto",fontSize:30}}}),Oa.extend({type:"echartsGaugePointer",shape:{angle:0,width:10,r:10,x:0,y:0},buildPath:function(t,e){var i=Math.cos,n=Math.sin,a=e.r,r=e.width,o=e.angle,s=e.x-i(o)*r*(r>=a/3?1:2),l=e.y-n(o)*r*(r>=a/3?1:2);o=e.angle-Math.PI/2,t.moveTo(s,l),t.lineTo(e.x+i(o)*r,e.y+n(o)*r),t.lineTo(e.x+i(e.angle)*a,e.y+n(e.angle)*a),t.lineTo(e.x-i(o)*r,e.y-n(o)*r),t.lineTo(s,l)}})),rC=2*Math.PI,oC=(Ss.extend({type:"gauge",render:function(t,e,i){this.group.removeAll();var n=t.get("axisLine.lineStyle.color"),a=Bf(t,i);this._renderMain(t,e,i,n,a)},dispose:function(){},_renderMain:function(t,e,i,n,a){for(var r=this.group,o=t.getModel("axisLine"),s=o.getModel("lineStyle"),l=t.get("clockwise"),h=-t.get("startAngle")/180*Math.PI,u=-t.get("endAngle")/180*Math.PI,c=(u-h)%rC,d=h,f=s.get("width"),p=0;p<n.length;p++){var g=Math.min(Math.max(n[p][0],0),1),u=h+c*g,v=new Rw({shape:{startAngle:d,endAngle:u,cx:a.cx,cy:a.cy,clockwise:l,r0:a.r-f,r:a.r},silent:!0});v.setStyle({fill:n[p][1]}),v.setStyle(s.getLineStyle(["color","borderWidth","borderColor"])),r.add(v),d=u}var m=function(t){if(0>=t)return n[0][1];for(var e=0;e<n.length;e++)if(n[e][0]>=t&&(0===e?0:n[e-1][0])<t)return n[e][1];return n[e-1][1]};if(!l){var y=h;h=u,u=y}this._renderTicks(t,e,i,m,a,h,u,l),this._renderPointer(t,e,i,m,a,h,u,l),this._renderTitle(t,e,i,m,a),this._renderDetail(t,e,i,m,a)},_renderTicks:function(t,e,i,n,a,r,o){for(var s=this.group,l=a.cx,h=a.cy,u=a.r,c=+t.get("min"),d=+t.get("max"),f=t.getModel("splitLine"),p=t.getModel("axisTick"),g=t.getModel("axisLabel"),v=t.get("splitNumber"),m=p.get("splitNumber"),y=Gr(f.get("length"),u),x=Gr(p.get("length"),u),_=r,w=(o-r)/v,b=w/m,M=f.getModel("lineStyle").getLineStyle(),S=p.getModel("lineStyle").getLineStyle(),I=0;v>=I;I++){var T=Math.cos(_),A=Math.sin(_);
-if(f.get("show")){var C=new Hw({shape:{x1:T*u+l,y1:A*u+h,x2:T*(u-y)+l,y2:A*(u-y)+h},style:M,silent:!0});"auto"===M.stroke&&C.setStyle({stroke:n(I/v)}),s.add(C)}if(g.get("show")){var D=Vf(Fr(I/v*(d-c)+c),g.get("formatter")),L=g.get("distance"),k=n(I/v);s.add(new Pw({style:fr({},g,{text:D,x:T*(u-y-L)+l,y:A*(u-y-L)+h,textVerticalAlign:-.4>A?"top":A>.4?"bottom":"middle",textAlign:-.4>T?"left":T>.4?"right":"center"},{autoColor:k}),silent:!0}))}if(p.get("show")&&I!==v){for(var P=0;m>=P;P++){var T=Math.cos(_),A=Math.sin(_),O=new Hw({shape:{x1:T*u+l,y1:A*u+h,x2:T*(u-x)+l,y2:A*(u-x)+h},silent:!0,style:S});"auto"===S.stroke&&O.setStyle({stroke:n((I+P/m)/v)}),s.add(O),_+=b}_-=b}else _+=w}},_renderPointer:function(t,e,i,n,a,r,o){var s=this.group,l=this._data;if(!t.get("pointer.show"))return void(l&&l.eachItemGraphicEl(function(t){s.remove(t)}));var h=[+t.get("min"),+t.get("max")],u=[r,o],c=t.getData(),d=c.mapDimension("value");c.diff(l).add(function(e){var i=new aC({shape:{angle:r}});Sr(i,{shape:{angle:Vr(c.get(d,e),h,u,!0)}},t),s.add(i),c.setItemGraphicEl(e,i)}).update(function(e,i){var n=l.getItemGraphicEl(i);Mr(n,{shape:{angle:Vr(c.get(d,e),h,u,!0)}},t),s.add(n),c.setItemGraphicEl(e,n)}).remove(function(t){var e=l.getItemGraphicEl(t);s.remove(e)}).execute(),c.eachItemGraphicEl(function(t,e){var i=c.getItemModel(e),r=i.getModel("pointer");t.setShape({x:a.cx,y:a.cy,width:Gr(r.get("width"),a.r),r:Gr(r.get("length"),a.r)}),t.useStyle(i.getModel("itemStyle").getItemStyle()),"auto"===t.style.fill&&t.setStyle("fill",n(Vr(c.get(d,e),h,[0,1],!0))),cr(t,i.getModel("emphasis.itemStyle").getItemStyle())}),this._data=c},_renderTitle:function(t,e,i,n,a){var r=t.getData(),o=r.mapDimension("value"),s=t.getModel("title");if(s.get("show")){var l=s.get("offsetCenter"),h=a.cx+Gr(l[0],a.r),u=a.cy+Gr(l[1],a.r),c=+t.get("min"),d=+t.get("max"),f=t.getData().get(o,0),p=n(Vr(f,[c,d],[0,1],!0));this.group.add(new Pw({silent:!0,style:fr({},s,{x:h,y:u,text:r.getName(0),textAlign:"center",textVerticalAlign:"middle"},{autoColor:p,forceRich:!0})}))}},_renderDetail:function(t,e,i,n,a){var r=t.getModel("detail"),o=+t.get("min"),s=+t.get("max");if(r.get("show")){var l=r.get("offsetCenter"),h=a.cx+Gr(l[0],a.r),u=a.cy+Gr(l[1],a.r),c=Gr(r.get("width"),a.r),d=Gr(r.get("height"),a.r),f=t.getData(),p=f.get(f.mapDimension("value"),0),g=n(Vr(p,[o,s],[0,1],!0));this.group.add(new Pw({silent:!0,style:fr({},r,{x:h,y:u,text:Vf(p,r.get("formatter")),textWidth:isNaN(c)?null:c,textHeight:isNaN(d)?null:d,textAlign:"center",textVerticalAlign:"middle"},{autoColor:g,forceRich:!0})}))}}}),function(t){var e=t.grid.getRect();return{coordSys:{type:"cartesian2d",x:e.x,y:e.y,width:e.width,height:e.height},api:{coord:function(e){return t.dataToPoint(e)},size:y(Gf,t)}}}),sC=function(t){var e=t.getBoundingRect();return{coordSys:{type:"geo",x:e.x,y:e.y,width:e.width,height:e.height},api:{coord:function(e,i){return t.dataToPoint(e,i)},size:y(Ff,t)}}},lC=function(t){var e=t.getRect();return{coordSys:{type:"singleAxis",x:e.x,y:e.y,width:e.width,height:e.height},api:{coord:function(e){return t.dataToPoint(e)},size:y(Wf,t)}}},hC=function(t){var e=t.getRadiusAxis(),i=t.getAngleAxis(),n=e.getExtent();return n[0]>n[1]&&n.reverse(),{coordSys:{type:"polar",cx:t.cx,cy:t.cy,r:n[1],r0:n[0]},api:{coord:y(function(n){var a=e.dataToRadius(n[0]),r=i.dataToAngle(n[1]),o=t.coordToPoint([a,r]);return o.push(a,r*Math.PI/180),o}),size:y(Hf,t)}}},uC=function(t){var e=t.getRect(),i=t.getRangeInfo();return{coordSys:{type:"calendar",x:e.x,y:e.y,width:e.width,height:e.height,cellWidth:t.getCellWidth(),cellHeight:t.getCellHeight(),rangeInfo:{start:i.start,end:i.end,weeks:i.weeks,dayCount:i.allDay}},api:{coord:function(e,i){return t.dataToPoint(e,i)}}}},cC=["itemStyle"],dC=["emphasis","itemStyle"],fC=["label"],pC=["emphasis","label"],gC="e\x00\x00",vC={cartesian2d:oC,geo:sC,singleAxis:lC,polar:hC,calendar:uC};Rl({type:"series.custom",dependencies:["grid","polar","geo","singleAxis","calendar"],defaultOption:{coordinateSystem:"cartesian2d",zlevel:0,z:2,legendHoverLink:!0},getInitialData:function(){return rh(this.getSource(),this)}}),Nl({type:"custom",_data:null,render:function(t,e,i){var n=this._data,a=t.getData(),r=this.group,o=Uf(t,a,e,i);this.group.removeAll(),a.diff(n).add(function(e){a.hasValue(e)&&qf(null,e,o(e),t,r,a)}).update(function(e,i){var s=n.getItemGraphicEl(i);a.hasValue(e)?qf(s,e,o(e),t,r,a):s&&r.remove(s)}).remove(function(t){var e=n.getItemGraphicEl(t);e&&r.remove(e)}).execute(),this._data=a},incrementalPrepareRender:function(){this.group.removeAll(),this._data=null},incrementalRender:function(t,e,i,n){function a(t){t.isGroup||(t.incremental=!0,t.useHoverLayer=!0)}for(var r=e.getData(),o=Uf(e,r,i,n),s=t.start;s<t.end;s++){var l=qf(null,s,o(s),e,this.group,r);l.traverse(a)}},dispose:G}),rp.prototype={constructor:rp,pointToData:function(t,e){return this.polar.pointToData(t,e)["radius"===this.dim?0:1]},dataToRadius:wI.prototype.dataToCoord,radiusToData:wI.prototype.coordToData},u(rp,wI),op.prototype={constructor:op,pointToData:function(t,e){return this.polar.pointToData(t,e)["radius"===this.dim?0:1]},dataToAngle:wI.prototype.dataToCoord,angleToData:wI.prototype.coordToData},u(op,wI);var mC=function(t){this.name=t||"",this.cx=0,this.cy=0,this._radiusAxis=new rp,this._angleAxis=new op,this._radiusAxis.polar=this._angleAxis.polar=this};mC.prototype={type:"polar",axisPointerEnabled:!0,constructor:mC,dimensions:["radius","angle"],model:null,containPoint:function(t){var e=this.pointToCoord(t);return this._radiusAxis.contain(e[0])&&this._angleAxis.contain(e[1])},containData:function(t){return this._radiusAxis.containData(t[0])&&this._angleAxis.containData(t[1])},getAxis:function(t){return this["_"+t+"Axis"]},getAxes:function(){return[this._radiusAxis,this._angleAxis]},getAxesByScale:function(t){var e=[],i=this._angleAxis,n=this._radiusAxis;return i.scale.type===t&&e.push(i),n.scale.type===t&&e.push(n),e},getAngleAxis:function(){return this._angleAxis},getRadiusAxis:function(){return this._radiusAxis},getOtherAxis:function(t){var e=this._angleAxis;return t===e?this._radiusAxis:e},getBaseAxis:function(){return this.getAxesByScale("ordinal")[0]||this.getAxesByScale("time")[0]||this.getAngleAxis()},getTooltipAxes:function(t){var e=null!=t&&"auto"!==t?this.getAxis(t):this.getBaseAxis();return{baseAxes:[e],otherAxes:[this.getOtherAxis(e)]}},dataToPoint:function(t,e){return this.coordToPoint([this._radiusAxis.dataToRadius(t[0],e),this._angleAxis.dataToAngle(t[1],e)])},pointToData:function(t,e){var i=this.pointToCoord(t);return[this._radiusAxis.radiusToData(i[0],e),this._angleAxis.angleToData(i[1],e)]},pointToCoord:function(t){var e=t[0]-this.cx,i=t[1]-this.cy,n=this.getAngleAxis(),a=n.getExtent(),r=Math.min(a[0],a[1]),o=Math.max(a[0],a[1]);n.inverse?r=o-360:o=r+360;var s=Math.sqrt(e*e+i*i);e/=s,i/=s;for(var l=Math.atan2(-i,e)/Math.PI*180,h=r>l?1:-1;r>l||l>o;)l+=360*h;return[s,l]},coordToPoint:function(t){var e=t[0],i=t[1]/180*Math.PI,n=Math.cos(i)*e+this.cx,a=-Math.sin(i)*e+this.cy;return[n,a]}};var yC=Cb.extend({type:"polarAxis",axis:null,getCoordSysModel:function(){return this.ecModel.queryComponents({mainType:"polar",index:this.option.polarIndex,id:this.option.polarId})[0]}});a(yC.prototype,sI);var xC={angle:{startAngle:90,clockwise:!0,splitNumber:12,axisLabel:{rotate:!1}},radius:{splitNumber:5}};DI("angle",yC,sp,xC.angle),DI("radius",yC,sp,xC.radius),zl({type:"polar",dependencies:["polarAxis","angleAxis"],coordinateSystem:null,findAxisModel:function(t){var e,i=this.ecModel;return i.eachComponent(t,function(t){t.getCoordSysModel()===this&&(e=t)},this),e},defaultOption:{zlevel:0,z:0,center:["50%","50%"],radius:"80%"}});var _C={dimensions:mC.prototype.dimensions,create:function(t,e){var i=[];return t.eachComponent("polar",function(t,n){var a=new mC(n);a.update=hp;var r=a.getRadiusAxis(),o=a.getAngleAxis(),s=t.findAxisModel("radiusAxis"),l=t.findAxisModel("angleAxis");up(r,s),up(o,l),lp(a,t,e),i.push(a),t.coordinateSystem=a,a.model=t}),t.eachSeries(function(e){if("polar"===e.get("coordinateSystem")){var i=t.queryComponents({mainType:"polar",index:e.get("polarIndex"),id:e.get("polarId")})[0];e.coordinateSystem=i.coordinateSystem}}),i}};Fo.register("polar",_C);var wC=["axisLine","axisLabel","axisTick","splitLine","splitArea"];KI.extend({type:"angleAxis",axisPointerClass:"PolarAxisPointer",render:function(t){if(this.group.removeAll(),t.get("show")){var e=t.axis,i=e.polar,n=i.getRadiusAxis().getExtent(),a=e.getTicksCoords();"category"!==e.type&&a.pop(),f(wC,function(r){!t.get(r+".show")||e.scale.isBlank()&&"axisLine"!==r||this["_"+r](t,i,a,n)},this)}},_axisLine:function(t,e,i,n){var a=t.getModel("axisLine.lineStyle"),r=new Ow({shape:{cx:e.cx,cy:e.cy,r:n[dp(e)]},style:a.getLineStyle(),z2:1,silent:!0});r.style.fill=null,this.group.add(r)},_axisTick:function(t,e,i,n){var a=t.getModel("axisTick"),r=(a.get("inside")?-1:1)*a.get("length"),o=n[dp(e)],l=p(i,function(t){return new Hw({shape:cp(e,[o,o+r],t)})});this.group.add(ib(l,{style:s(a.getModel("lineStyle").getLineStyle(),{stroke:t.get("axisLine.lineStyle.color")})}))},_axisLabel:function(t,e,i,n){for(var a=t.axis,r=t.getCategories(),o=t.getModel("axisLabel"),s=t.getFormattedLabels(),l=o.get("margin"),h=a.getLabelsCoords(),u=0;u<i.length;u++){var c=n[dp(e)],d=e.coordToPoint([c+l,h[u]]),f=e.cx,p=e.cy,g=Math.abs(d[0]-f)/c<.3?"center":d[0]>f?"left":"right",v=Math.abs(d[1]-p)/c<.3?"middle":d[1]>p?"top":"bottom";r&&r[u]&&r[u].textStyle&&(o=new Pr(r[u].textStyle,o,o.ecModel));var m=new Pw({silent:!0});this.group.add(m),fr(m.style,o,{x:d[0],y:d[1],textFill:o.getTextColor()||t.get("axisLine.lineStyle.color"),text:s[u],textAlign:g,textVerticalAlign:v})}},_splitLine:function(t,e,i,n){var a=t.getModel("splitLine"),r=a.getModel("lineStyle"),o=r.get("color"),l=0;o=o instanceof Array?o:[o];for(var h=[],u=0;u<i.length;u++){var c=l++%o.length;h[c]=h[c]||[],h[c].push(new Hw({shape:cp(e,n,i[u])}))}for(var u=0;u<h.length;u++)this.group.add(ib(h[u],{style:s({stroke:o[u%o.length]},r.getLineStyle()),silent:!0,z:t.get("z")}))},_splitArea:function(t,e,i,n){var a=t.getModel("splitArea"),r=a.getModel("areaStyle"),o=r.get("color"),l=0;o=o instanceof Array?o:[o];for(var h=[],u=Math.PI/180,c=-i[0]*u,d=Math.min(n[0],n[1]),f=Math.max(n[0],n[1]),p=t.get("clockwise"),g=1;g<i.length;g++){var v=l++%o.length;h[v]=h[v]||[],h[v].push(new Rw({shape:{cx:e.cx,cy:e.cy,r0:d,r:f,startAngle:c,endAngle:-i[g]*u,clockwise:p},silent:!0})),c=-i[g]*u}for(var g=0;g<h.length;g++)this.group.add(ib(h[g],{style:s({fill:o[g%o.length]},r.getAreaStyle()),silent:!0}))}});var bC=["axisLine","axisTickLabel","axisName"],MC=["splitLine","splitArea"];KI.extend({type:"radiusAxis",axisPointerClass:"PolarAxisPointer",render:function(t){if(this.group.removeAll(),t.get("show")){var e=t.axis,i=e.polar,n=i.getAngleAxis(),a=e.getTicksCoords(),r=n.getExtent()[0],o=e.getExtent(),s=fp(i,t,r),l=new ZI(t,s);f(bC,l.add,l),this.group.add(l.getGroup()),f(MC,function(n){t.get(n+".show")&&!e.scale.isBlank()&&this["_"+n](t,i,r,o,a)},this)}},_splitLine:function(t,e,i,n,a){var r=t.getModel("splitLine"),o=r.getModel("lineStyle"),l=o.get("color"),h=0;l=l instanceof Array?l:[l];for(var u=[],c=0;c<a.length;c++){var d=h++%l.length;u[d]=u[d]||[],u[d].push(new Ow({shape:{cx:e.cx,cy:e.cy,r:a[c]},silent:!0}))}for(var c=0;c<u.length;c++)this.group.add(ib(u[c],{style:s({stroke:l[c%l.length],fill:null},o.getLineStyle()),silent:!0}))},_splitArea:function(t,e,i,n,a){var r=t.getModel("splitArea"),o=r.getModel("areaStyle"),l=o.get("color"),h=0;l=l instanceof Array?l:[l];for(var u=[],c=a[0],d=1;d<a.length;d++){var f=h++%l.length;u[f]=u[f]||[],u[f].push(new Rw({shape:{cx:e.cx,cy:e.cy,r0:c,r:a[d],startAngle:0,endAngle:2*Math.PI},silent:!0})),c=a[d]}for(var d=0;d<u.length;d++)this.group.add(ib(u[d],{style:s({fill:l[d%l.length]},o.getAreaStyle()),silent:!0}))}});var SC=function(t,e){var i,n=[],a=t.seriesIndex;if(null==a||!(i=e.getSeriesByIndex(a)))return{point:[]};var r=i.getData(),o=Fn(r,t);if(null==o||0>o||_(o))return{point:[]};var s=r.getItemGraphicEl(o),l=i.coordinateSystem;if(i.getTooltipPosition)n=i.getTooltipPosition(o)||[];else if(l&&l.dataToPoint)n=l.dataToPoint(r.getValues(p(l.dimensions,function(t){return r.mapDimension(t)}),o,!0))||[];else if(s){var h=s.getBoundingRect().clone();h.applyTransform(s.transform),n=[h.x+h.width/2,h.y+h.height/2]}return{point:n,el:s}},IC=f,TC=x,AC=Wn(),CC=function(t,e,i){var n=t.currTrigger,a=[t.x,t.y],r=t,o=t.dispatchAction||y(i.dispatchAction,i),s=e.getComponent("axisPointer").coordSysAxesInfo;if(s){Mp(a)&&(a=SC({seriesIndex:r.seriesIndex,dataIndex:r.dataIndex},e).point);var l=Mp(a),h=r.axesInfo,u=s.axesInfo,c="leave"===n||Mp(a),d={},f={},p={list:[],map:{}},g={showPointer:TC(vp,f),showTooltip:TC(mp,p)};IC(s.coordSysMap,function(t,e){var i=l||t.containPoint(a);IC(s.coordSysAxesInfo[e],function(t){var e=t.axis,n=wp(h,t);if(!c&&i&&(!h||n)){var r=n&&n.value;null!=r||l||(r=e.pointToData(a)),null!=r&&pp(t,r,g,!1,d)}})});var v={};return IC(u,function(t,e){var i=t.linkGroup;i&&!f[e]&&IC(i.axesInfo,function(e,n){var a=f[n];if(e!==t&&a){var r=a.value;i.mapper&&(r=t.axis.scale.parse(i.mapper(r,bp(e),bp(t)))),v[t.key]=r}})}),IC(v,function(t,e){pp(u[e],t,g,!0,d)}),yp(f,u,d),xp(p,a,t,o),_p(u,o,i),d}},DC=(zl({type:"axisPointer",coordSysAxesInfo:null,defaultOption:{show:"auto",triggerOn:null,zlevel:0,z:50,type:"line",snap:!1,triggerTooltip:!0,value:null,status:null,link:[],animation:null,animationDurationUpdate:200,lineStyle:{color:"#aaa",width:1,type:"solid"},shadowStyle:{color:"rgba(150,150,150,0.3)"},label:{show:!0,formatter:null,precision:"auto",margin:3,color:"#fff",padding:[5,7,5,7],backgroundColor:"auto",borderColor:null,borderWidth:0,shadowBlur:3,shadowColor:"#aaa"},handle:{show:!1,icon:"M10.7,11.9v-1.3H9.3v1.3c-4.9,0.3-8.8,4.4-8.8,9.4c0,5,3.9,9.1,8.8,9.4h1.3c4.9-0.3,8.8-4.4,8.8-9.4C19.5,16.3,15.6,12.2,10.7,11.9z M13.3,24.4H6.7v-1.2h6.6z M13.3,22H6.7v-1.2h6.6z M13.3,19.6H6.7v-1.2h6.6z",size:45,margin:50,color:"#333",shadowBlur:3,shadowColor:"#aaa",shadowOffsetX:0,shadowOffsetY:2,throttle:40}}}),Wn()),LC=f,kC=El({type:"axisPointer",render:function(t,e,i){var n=e.getComponent("tooltip"),a=t.get("triggerOn")||n&&n.get("triggerOn")||"mousemove|click";Sp("axisPointer",i,function(t,e,i){"none"!==a&&("leave"===t||a.indexOf(t)>=0)&&i({type:"updateAxisPointer",currTrigger:t,x:e&&e.offsetX,y:e&&e.offsetY})})},remove:function(t,e){Lp(e.getZr(),"axisPointer"),kC.superApply(this._model,"remove",arguments)},dispose:function(t,e){Lp("axisPointer",e),kC.superApply(this._model,"dispose",arguments)}}),PC=Wn(),OC=n,zC=y;kp.prototype={_group:null,_lastGraphicKey:null,_handle:null,_dragging:!1,_lastValue:null,_lastStatus:null,_payloadInfo:null,animationThreshold:15,render:function(t,e,i,n){var a=e.get("value"),r=e.get("status");if(this._axisModel=t,this._axisPointerModel=e,this._api=i,n||this._lastValue!==a||this._lastStatus!==r){this._lastValue=a,this._lastStatus=r;var o=this._group,s=this._handle;if(!r||"hide"===r)return o&&o.hide(),void(s&&s.hide());o&&o.show(),s&&s.show();var l={};this.makeElOption(l,a,t,e,i);var h=l.graphicKey;h!==this._lastGraphicKey&&this.clear(i),this._lastGraphicKey=h;var u=this._moveAnimation=this.determineAnimation(t,e);if(o){var c=x(Pp,e,u);this.updatePointerEl(o,l,c,e),this.updateLabelEl(o,l,c,e)}else o=this._group=new xx,this.createPointerEl(o,l,t,e),this.createLabelEl(o,l,t,e),i.getZr().add(o);Rp(o,e,!0),this._renderHandle(a)}},remove:function(t){this.clear(t)},dispose:function(t){this.clear(t)},determineAnimation:function(t,e){var i=e.get("animation"),n=t.axis,a="category"===n.type,r=e.get("snap");if(!r&&!a)return!1;if("auto"===i||null==i){var o=this.animationThreshold;if(a&&n.getBandWidth()>o)return!0;if(r){var s=Iu(t).seriesDataCount,l=n.getExtent();return Math.abs(l[0]-l[1])/s>o}return!1}return i===!0},makeElOption:function(){},createPointerEl:function(t,e){var i=e.pointer;if(i){var n=PC(t).pointerEl=new nb[i.type](OC(e.pointer));t.add(n)}},createLabelEl:function(t,e,i,n){if(e.label){var a=PC(t).labelEl=new Ww(OC(e.label));t.add(a),zp(a,n)}},updatePointerEl:function(t,e,i){var n=PC(t).pointerEl;n&&(n.setStyle(e.pointer.style),i(n,{shape:e.pointer.shape}))},updateLabelEl:function(t,e,i,n){var a=PC(t).labelEl;a&&(a.setStyle(e.label.style),i(a,{shape:e.label.shape,position:e.label.position}),zp(a,n))},_renderHandle:function(t){if(!this._dragging&&this.updateHandleTransform){var e=this._axisPointerModel,i=this._api.getZr(),n=this._handle,a=e.getModel("handle"),r=e.get("status");if(!a.get("show")||!r||"hide"===r)return n&&i.remove(n),void(this._handle=null);var o;this._handle||(o=!0,n=this._handle=kr(a.get("icon"),{cursor:"move",draggable:!0,onmousemove:function(t){t_(t.event)},onmousedown:zC(this._onHandleDragMove,this,0,0),drift:zC(this._onHandleDragMove,this),ondragend:zC(this._onHandleDragEnd,this)}),i.add(n)),Rp(n,e,!1);var s=["color","borderColor","borderWidth","opacity","shadowColor","shadowBlur","shadowOffsetX","shadowOffsetY"];n.setStyle(a.getItemStyle(null,s));var l=a.get("size");_(l)||(l=[l,l]),n.attr("scale",[l[0]/2,l[1]/2]),ks(this,"_doDispatchAxisPointer",a.get("throttle")||0,"fixRate"),this._moveHandleToValue(t,o)}},_moveHandleToValue:function(t,e){Pp(this._axisPointerModel,!e&&this._moveAnimation,this._handle,Ep(this.getHandleTransform(t,this._axisModel,this._axisPointerModel)))},_onHandleDragMove:function(t,e){var i=this._handle;if(i){this._dragging=!0;var n=this.updateHandleTransform(Ep(i),[t,e],this._axisModel,this._axisPointerModel);this._payloadInfo=n,i.stopAnimation(),i.attr(Ep(n)),PC(i).lastProp=null,this._doDispatchAxisPointer()}},_doDispatchAxisPointer:function(){var t=this._handle;if(t){var e=this._payloadInfo,i=this._axisModel;this._api.dispatchAction({type:"updateAxisPointer",x:e.cursorPoint[0],y:e.cursorPoint[1],tooltipOption:e.tooltipOption,axesInfo:[{axisDim:i.axis.dim,axisIndex:i.componentIndex}]})}},_onHandleDragEnd:function(){this._dragging=!1;var t=this._handle;if(t){var e=this._axisPointerModel.get("value");this._moveHandleToValue(e),this._api.dispatchAction({type:"hideTip"})}},getHandleTransform:null,updateHandleTransform:null,clear:function(t){this._lastValue=null,this._lastStatus=null;var e=t.getZr(),i=this._group,n=this._handle;e&&i&&(this._lastGraphicKey=null,i&&e.remove(i),n&&e.remove(n),this._group=null,this._handle=null,this._payloadInfo=null)},doClear:function(){},buildLabel:function(t,e,i){return i=i||0,{x:t[i],y:t[1-i],width:e[i],height:e[1-i]}}},kp.prototype.constructor=kp,qn(kp);var EC=kp.extend({makeElOption:function(t,e,i,n,a){var r=i.axis,o=r.grid,s=n.get("type"),l=Xp(o,r).getOtherAxis(r).getGlobalExtent(),h=r.toGlobalCoord(r.dataToCoord(e,!0));if(s&&"none"!==s){var u=Np(n),c=RC[s](r,h,l,u);c.style=u,t.graphicKey=c.type,t.pointer=c}var d=ku(o.model,i);Wp(e,t,d,i,n,a)},getHandleTransform:function(t,e,i){var n=ku(e.axis.grid.model,e,{labelInside:!1});return n.labelMargin=i.get("handle.margin"),{position:Fp(e.axis,t,n),rotation:n.rotation+(n.labelDirection<0?Math.PI:0)}},updateHandleTransform:function(t,e,i){var n=i.axis,a=n.grid,r=n.getGlobalExtent(!0),o=Xp(a,n).getOtherAxis(n).getGlobalExtent(),s="x"===n.dim?0:1,l=t.position;l[s]+=e[s],l[s]=Math.min(r[1],l[s]),l[s]=Math.max(r[0],l[s]);var h=(o[1]+o[0])/2,u=[h,h];u[s]=l[s];var c=[{verticalAlign:"middle"},{align:"center"}];return{position:l,rotation:t.rotation,cursorPoint:u,tooltipOption:c[s]}}}),RC={line:function(t,e,i,n){var a=Hp([e,i[0]],[e,i[1]],Up(t));return $a({shape:a,style:n}),{type:"Line",shape:a}},shadow:function(t,e,i){var n=t.getBandWidth(),a=i[1]-i[0];return{type:"Rect",shape:Zp([e-n/2,i[0]],[n,a],Up(t))}}};KI.registerAxisPointerClass("CartesianAxisPointer",EC),Sl(function(t){if(t){(!t.axisPointer||0===t.axisPointer.length)&&(t.axisPointer={});var e=t.axisPointer.link;e&&!_(e)&&(t.axisPointer.link=[e])}}),Il(tS.PROCESSOR.STATISTIC,function(t,e){t.getComponent("axisPointer").coordSysAxesInfo=yu(t,e)}),Al({type:"updateAxisPointer",event:"updateAxisPointer",update:":updateAxisPointer"},CC);var NC=kp.extend({makeElOption:function(t,e,i,n,a){var r=i.axis;"angle"===r.dim&&(this.animationThreshold=Math.PI/18);var o,s=r.polar,l=s.getOtherAxis(r),h=l.getExtent();o=r["dataTo"+lo(r.dim)](e);var u=n.get("type");if(u&&"none"!==u){var c=Np(n),d=BC[u](r,s,o,h,c);d.style=c,t.graphicKey=d.type,t.pointer=d}var f=n.get("label.margin"),p=Yp(e,i,n,s,f);Bp(t,i,n,a,p)}}),BC={line:function(t,e,i,n){return"angle"===t.dim?{type:"Line",shape:Hp(e.coordToPoint([n[0],i]),e.coordToPoint([n[1],i]))}:{type:"Circle",shape:{cx:e.cx,cy:e.cy,r:i}}},shadow:function(t,e,i,n){var a=t.getBandWidth(),r=Math.PI/180;return"angle"===t.dim?{type:"Sector",shape:jp(e.cx,e.cy,n[0],n[1],(-i-a/2)*r,(-i+a/2)*r)}:{type:"Sector",shape:jp(e.cx,e.cy,i-a/2,i+a/2,0,2*Math.PI)}}};KI.registerAxisPointerClass("PolarAxisPointer",NC),Ll(x(np,"bar")),El({type:"polar"});for(var VC=[126,25],GC=[[[0,3.5],[7,11.2],[15,11.9],[30,7],[42,.7],[52,.7],[56,7.7],[59,.7],[64,.7],[64,0],[5,0],[0,3.5]],[[13,16.1],[19,14.7],[16,21.7],[11,23.1],[13,16.1]],[[12,32.2],[14,38.5],[15,38.5],[13,32.2],[12,32.2]],[[16,47.6],[12,53.2],[13,53.2],[18,47.6],[16,47.6]],[[6,64.4],[8,70],[9,70],[8,64.4],[6,64.4]],[[23,82.6],[29,79.8],[30,79.8],[25,82.6],[23,82.6]],[[37,70.7],[43,62.3],[44,62.3],[39,70.7],[37,70.7]],[[48,51.1],[51,45.5],[53,45.5],[50,51.1],[48,51.1]],[[51,35],[51,28.7],[53,28.7],[53,35],[51,35]],[[52,22.4],[55,17.5],[56,17.5],[53,22.4],[52,22.4]],[[58,12.6],[62,7],[63,7],[60,12.6],[58,12.6]],[[0,3.5],[0,93.1],[64,93.1],[64,0],[63,0],[63,92.4],[1,92.4],[1,3.5],[0,3.5]]],FC=0;FC<GC.length;FC++)for(var WC=0;WC<GC[FC].length;WC++)GC[FC][WC][0]/=10.5,GC[FC][WC][1]/=-14,GC[FC][WC][0]+=VC[0],GC[FC][WC][1]+=VC[1];var HC=function(t){"china"===t.map&&t.regions.push(new Gh("南海诸岛",p(GC,function(t){return{type:"polygon",exterior:t}}),VC))},ZC={"南海诸岛":[32,80],"广东":[0,-10],"香港":[10,5],"澳门":[-10,10],"天津":[5,5]},jC=function(t){f(t.regions,function(t){var e=ZC[t.name];if(e){var i=t.center;i[0]+=e[0]/10.5,i[1]+=-e[1]/14}})},XC={Russia:[100,60],"United States":[-99,38],"United States of America":[-99,38]},UC=function(t){f(t.regions,function(t){var e=XC[t.name];if(e){var i=t.center;i[0]=e[0],i[1]=e[1]}})},YC=[[[123.45165252685547,25.73527164402261],[123.49731445312499,25.73527164402261],[123.49731445312499,25.750734064600884],[123.45165252685547,25.750734064600884],[123.45165252685547,25.73527164402261]]],qC=function(t){if("china"===t.map)for(var e=0,i=t.regions.length;i>e;++e)"台湾"===t.regions[e].name&&t.regions[e].geometries.push({type:"polygon",exterior:YC[0]})},$C=[HC,jC,UC,qC];qp.prototype={constructor:qp,type:"geo",dimensions:["lng","lat"],containCoord:function(t){for(var e=this.regions,i=0;i<e.length;i++)if(e[i].contain(t))return!0;return!1},loadGeoJson:function(t,e,i){try{this.regions=t?yI(t):[]}catch(n){throw"Invalid geoJson format\n"+n.message}e=e||{},i=i||{};for(var a=this.regions,r=B(),o=0;o<a.length;o++){var s=a[o].name;s=i.hasOwnProperty(s)?i[s]:s,a[o].name=s,r.set(s,a[o]),this.addGeoCoord(s,a[o].center);var l=e[s];l&&a[o].transformTo(l.left,l.top,l.width,l.height)}this._regionsMap=r,this._rect=null,f($C,function(t){t(this)},this)},transformTo:function(t,e,i,n){var a=this.getBoundingRect();a=a.clone(),a.y=-a.y-a.height;var r=this._rawTransformable;r.transform=a.calculateTransform(new ni(t,e,i,n)),r.decomposeTransform();var o=r.scale;o[1]=-o[1],r.updateTransform(),this._updateTransform()},getRegion:function(t){return this._regionsMap.get(t)},getRegionByCoord:function(t){for(var e=this.regions,i=0;i<e.length;i++)if(e[i].contain(t))return e[i]},addGeoCoord:function(t,e){this._nameCoordMap.set(t,e)},getGeoCoord:function(t){return this._nameCoordMap.get(t)},getBoundingRect:function(){if(this._rect)return this._rect;for(var t,e=this.regions,i=0;i<e.length;i++){var n=e[i].getBoundingRect();t=t||n.clone(),t.union(n)}return this._rect=t||new ni(0,0,0,0)},dataToPoint:function(t,e,i){return"string"==typeof t&&(t=this.getGeoCoord(t)),t?Cd.prototype.dataToPoint.call(this,t,e,i):void 0},convertToPixel:x($p,"dataToPoint"),convertFromPixel:x($p,"pointToData")},c(qp,Cd);var KC={dimensions:qp.prototype.dimensions,create:function(t,e){var i=[];t.eachComponent("geo",function(t,n){var a=t.get("map"),r=Gl(a),o=new qp(a+n,a,r&&r.geoJson,r&&r.specialAreas,t.get("nameMap"));o.zoomLimit=t.get("scaleLimit"),i.push(o),Jp(o,t),t.coordinateSystem=o,o.model=t,o.resize=Kp,o.resize(t,e)}),t.eachSeries(function(t){var e=t.get("coordinateSystem");if("geo"===e){var n=t.get("geoIndex")||0;t.coordinateSystem=i[n]}});var n={};return t.eachSeriesByType("map",function(t){if(!t.getHostGeoModel()){var e=t.getMapType();n[e]=n[e]||[],n[e].push(t)}}),f(n,function(t,n){var a=Gl(n),o=p(t,function(t){return t.get("nameMap")}),s=new qp(n,n,a&&a.geoJson,a&&a.specialAreas,r(o));s.zoomLimit=C.apply(null,p(t,function(t){return t.get("scaleLimit")})),i.push(s),s.resize=Kp,s.resize(t[0],e),f(t,function(t){t.coordinateSystem=s,Jp(s,t)})}),i},getFilledRegions:function(t,e,i){var n=(t||[]).slice();i=i||{};var a=Gl(e),r=a&&a.geoJson;if(!r)return t;for(var o=B(),s=r.features,l=0;l<n.length;l++)o.set(n[l].name,n[l]);for(var l=0;l<s.length;l++){var h=s[l].properties.name;o.get(h)||(i.hasOwnProperty(h)&&(h=i[h]),n.push({name:h}))}return n}};Cl("geo",KC);var JC=Cb.extend({type:"geo",coordinateSystem:null,layoutMode:"box",init:function(t){Cb.prototype.init.apply(this,arguments),zn(t,"label",["show"])},optionUpdated:function(){var t=this.option,e=this;t.regions=KC.getFilledRegions(t.regions,t.map,t.nameMap),this._optionModelMap=g(t.regions||[],function(t,i){return i.name&&t.set(i.name,new Pr(i,e)),t},B()),this.updateSelectedMap(t.regions)},defaultOption:{zlevel:0,z:0,show:!0,left:"center",top:"center",aspectScale:.75,silent:!1,map:"",boundingCoords:null,center:null,zoom:1,scaleLimit:null,label:{show:!1,color:"#000"},itemStyle:{borderWidth:.5,borderColor:"#444",color:"#eee"},emphasis:{label:{show:!0,color:"rgb(100,0,0)"},itemStyle:{color:"rgba(255,215,0,0.8)"}},regions:[]},getRegionModel:function(t){return this._optionModelMap.get(t)||new Pr(null,this,this.ecModel)},getFormattedLabel:function(t,e){var i=this.getRegionModel(t),n=i.get("label."+e+".formatter"),a={name:t};return"function"==typeof n?(a.status=e,n(a)):"string"==typeof n?n.replace("{a}",null!=t?t:""):void 0},setZoom:function(t){this.option.zoom=t},setCenter:function(t){this.option.center=t}});c(JC,TT),ig.prototype={constructor:ig,draw:function(t,e,i,n,a){var r="geo"===t.mainType,o=t.getData&&t.getData();r&&e.eachComponent({mainType:"series",subType:"map"},function(e){o||e.getHostGeoModel()!==t||(o=e.getData())});var s=t.coordinateSystem,l=this.group,h=s.scale,u={position:s.position,scale:h};!l.childAt(0)||a?l.attr(u):Mr(l,u,t),l.removeAll();var c=["itemStyle"],d=["emphasis","itemStyle"],p=["label"],g=["emphasis","label"],v=B();f(s.regions,function(e){var i=v.get(e.name)||v.set(e.name,new xx),n=new Uw({shape:{paths:[]}});i.add(n);var a,s=t.getRegionModel(e.name)||t,u=s.getModel(c),m=s.getModel(d),y=Qp(u,h),x=Qp(m,h),_=s.getModel(p),w=s.getModel(g);if(o){a=o.indexOfName(e.name);var b=o.getItemVisual(a,"color",!0);b&&(y.fill=b)}f(e.geometries,function(t){if("polygon"===t.type){n.shape.paths.push(new Gw({shape:{points:t.exterior}}));for(var e=0;e<(t.interiors?t.interiors.length:0);e++)n.shape.paths.push(new Gw({shape:{points:t.interiors[e]}}))}}),n.setStyle(y),n.style.strokeNoScale=!0,n.culling=!0;var M=_.get("show"),S=w.get("show"),I=o&&isNaN(o.get(o.mapDimension("value"),a)),T=o&&o.getItemLayout(a);if(r||I&&(M||S)||T&&T.showLabel){var A,C=r?e.name:a;(!o||a>=0)&&(A=t);var D=new Pw({position:e.center.slice(),scale:[1/h[0],1/h[1]],z2:10,silent:!0});dr(D.style,D.hoverStyle={},_,w,{labelFetcher:A,labelDataIndex:C,defaultText:e.name,useInsideStyle:!1},{textAlign:"center",textVerticalAlign:"middle"}),i.add(D)}if(o)o.setItemGraphicEl(a,i);else{var s=t.getRegionModel(e.name);n.eventData={componentType:"geo",geoIndex:t.componentIndex,name:e.name,region:s&&s.option||{}}}var L=i.__regions||(i.__regions=[]);L.push(e),cr(i,x,{hoverSilentOnTouch:!!t.get("selectedMode")}),l.add(i)}),this._updateController(t,e,i),tg(this,t,l,i,n),eg(t,l)},remove:function(){this.group.removeAll(),this._controller.dispose(),this._controllerHost={}},_updateController:function(t,e,i){function n(){var e={type:"geoRoam",componentType:l};return e[l+"Id"]=t.id,e}var a=t.coordinateSystem,r=this._controller,s=this._controllerHost;s.zoomLimit=t.get("scaleLimit"),s.zoom=a.getZoom(),r.enable(t.get("roam")||!1);var l=t.mainType;r.off("pan").on("pan",function(t,e){this._mouseDownFlag=!1,pd(s,t,e),i.dispatchAction(o(n(),{dx:t,dy:e}))},this),r.off("zoom").on("zoom",function(t,e,a){if(this._mouseDownFlag=!1,gd(s,t,e,a),i.dispatchAction(o(n(),{zoom:t,originX:e,originY:a})),this._updateGroup){var r=this.group,l=r.scale;r.traverse(function(t){"text"===t.type&&t.attr("scale",[1/l[0],1/l[1]])})}},this),r.setPointerChecker(function(e,n,r){return a.getViewRectAfterRoam().contain(n,r)&&!vd(e,i,t)})}},El({type:"geo",init:function(t,e){var i=new ig(e,!0);this._mapDraw=i,this.group.add(i.group)},render:function(t,e,i,n){if(!n||"geoToggleSelect"!==n.type||n.from!==this.uid){var a=this._mapDraw;t.get("show")?a.draw(t,e,i,this,n):this._mapDraw.group.removeAll(),this.group.silent=t.get("silent")}},dispose:function(){this._mapDraw&&this._mapDraw.remove()}}),Al({type:"geoRoam",event:"geoRoam",update:"updateTransform"},function(t,e){var i=t.componentType||"series";e.eachComponent({mainType:i,query:t},function(e){var n=e.coordinateSystem;if("geo"===n.type){var a=wd(n,t,e.get("scaleLimit"));e.setCenter&&e.setCenter(a.center),e.setZoom&&e.setZoom(a.zoom),"series"===i&&f(e.seriesGroup,function(t){t.setCenter(a.center),t.setZoom(a.zoom)})}})}),ng("toggleSelected",{type:"geoToggleSelect",event:"geoselectchanged"}),ng("select",{type:"geoSelect",event:"geoselected"}),ng("unSelect",{type:"geoUnSelect",event:"geounselected"});var QC=function(t,e,i,n,a){wI.call(this,t,e,i),this.type=n||"value",this.position=a||"bottom",this.orient=null,this._labelInterval=null};QC.prototype={constructor:QC,model:null,isHorizontal:function(){var t=this.position;return"top"===t||"bottom"===t},pointToData:function(t,e){return this.coordinateSystem.pointToData(t,e)[0]},toGlobalCoord:null,toLocalCoord:null},u(QC,wI),ag.prototype={type:"singleAxis",axisPointerEnabled:!0,constructor:ag,_init:function(t){var e=this.dimension,i=new QC(e,Ch(t),[0,0],t.get("type"),t.get("position")),n="category"===i.type;i.onBand=n&&t.get("boundaryGap"),i.inverse=t.get("inverse"),i.orient=t.get("orient"),t.axis=i,i.model=t,i.coordinateSystem=this,this._axis=i},update:function(t){t.eachSeries(function(t){if(t.coordinateSystem===this){var e=t.getData();f(e.mapDimension(this.dimension,!0),function(t){this._axis.scale.unionExtentFromData(e,t)},this),Ah(this._axis.scale,this._axis.model)}},this)},resize:function(t,e){this._rect=uo({left:t.get("left"),top:t.get("top"),right:t.get("right"),bottom:t.get("bottom"),width:t.get("width"),height:t.get("height")},{width:e.getWidth(),height:e.getHeight()}),this._adjustAxis()},getRect:function(){return this._rect},_adjustAxis:function(){var t=this._rect,e=this._axis,i=e.isHorizontal(),n=i?[0,t.width]:[0,t.height],a=e.reverse?1:0;e.setExtent(n[a],n[1-a]),this._updateAxisTransform(e,i?t.x:t.y)},_updateAxisTransform:function(t,e){var i=t.getExtent(),n=i[0]+i[1],a=t.isHorizontal();t.toGlobalCoord=a?function(t){return t+e}:function(t){return n-t+e},t.toLocalCoord=a?function(t){return t-e}:function(t){return n-t+e}},getAxis:function(){return this._axis},getBaseAxis:function(){return this._axis},getAxes:function(){return[this._axis]},getTooltipAxes:function(){return{baseAxes:[this.getAxis()]}},containPoint:function(t){var e=this.getRect(),i=this.getAxis(),n=i.orient;return"horizontal"===n?i.contain(i.toLocalCoord(t[0]))&&t[1]>=e.y&&t[1]<=e.y+e.height:i.contain(i.toLocalCoord(t[1]))&&t[0]>=e.y&&t[0]<=e.y+e.height},pointToData:function(t){var e=this.getAxis();return[e.coordToData(e.toLocalCoord(t["horizontal"===e.orient?0:1]))]},dataToPoint:function(t){var e=this.getAxis(),i=this.getRect(),n=[],a="horizontal"===e.orient?0:1;
-return t instanceof Array&&(t=t[0]),n[a]=e.toGlobalCoord(e.dataToCoord(+t)),n[1-a]=0===a?i.y+i.height/2:i.x+i.width/2,n}},Fo.register("single",{create:rg,dimensions:ag.prototype.dimensions});var tD=ZI.getInterval,eD=ZI.ifIgnoreOnTick,iD=["axisLine","axisTickLabel","axisName"],nD="splitLine",aD=KI.extend({type:"singleAxis",axisPointerClass:"SingleAxisPointer",render:function(t,e,i,n){var a=this.group;a.removeAll();var r=og(t),o=new ZI(t,r);f(iD,o.add,o),a.add(o.getGroup()),t.get(nD+".show")&&this["_"+nD](t,r.labelInterval),aD.superCall(this,"render",t,e,i,n)},_splitLine:function(t,e){var i=t.axis;if(!i.scale.isBlank()){var n=t.getModel("splitLine"),a=n.getModel("lineStyle"),r=a.get("width"),o=a.get("color"),s=tD(n,e);o=o instanceof Array?o:[o];for(var l=t.coordinateSystem.getRect(),h=i.isHorizontal(),u=[],c=0,d=i.getTicksCoords(),f=[],p=[],g=t.get("axisLabel.showMinLabel"),v=t.get("axisLabel.showMaxLabel"),m=0;m<d.length;++m)if(!eD(i,m,s,d.length,g,v)){var y=i.toGlobalCoord(d[m]);h?(f[0]=y,f[1]=l.y,p[0]=y,p[1]=l.y+l.height):(f[0]=l.x,f[1]=y,p[0]=l.x+l.width,p[1]=y);var x=c++%o.length;u[x]=u[x]||[],u[x].push(new Hw($a({shape:{x1:f[0],y1:f[1],x2:p[0],y2:p[1]},style:{lineWidth:r},silent:!0})))}for(var m=0;m<u.length;++m)this.group.add(ib(u[m],{style:{stroke:o[m%o.length],lineDash:a.getLineDash(r),lineWidth:r},silent:!0}))}}}),rD=Cb.extend({type:"singleAxis",layoutMode:"box",axis:null,coordinateSystem:null,getCoordSysModel:function(){return this}}),oD={left:"5%",top:"5%",right:"5%",bottom:"5%",type:"value",position:"bottom",orient:"horizontal",axisLine:{show:!0,lineStyle:{width:2,type:"solid"}},tooltip:{show:!0},axisTick:{show:!0,length:6,lineStyle:{width:2}},axisLabel:{show:!0,interval:"auto"},splitLine:{show:!0,lineStyle:{type:"dashed",opacity:.2}}};a(rD.prototype,sI),DI("single",rD,sg,oD);var sD=["x","y"],lD=["width","height"],hD=kp.extend({makeElOption:function(t,e,i,n,a){var r=i.axis,o=r.coordinateSystem,s=hg(o,1-lg(r)),l=o.dataToPoint(e)[0],h=n.get("type");if(h&&"none"!==h){var u=Np(n),c=uD[h](r,l,s,u);c.style=u,t.graphicKey=c.type,t.pointer=c}var d=og(i);Wp(e,t,d,i,n,a)},getHandleTransform:function(t,e,i){var n=og(e,{labelInside:!1});return n.labelMargin=i.get("handle.margin"),{position:Fp(e.axis,t,n),rotation:n.rotation+(n.labelDirection<0?Math.PI:0)}},updateHandleTransform:function(t,e,i){var n=i.axis,a=n.coordinateSystem,r=lg(n),o=hg(a,r),s=t.position;s[r]+=e[r],s[r]=Math.min(o[1],s[r]),s[r]=Math.max(o[0],s[r]);var l=hg(a,1-r),h=(l[1]+l[0])/2,u=[h,h];return u[r]=s[r],{position:s,rotation:t.rotation,cursorPoint:u,tooltipOption:{verticalAlign:"middle"}}}}),uD={line:function(t,e,i,n){var a=Hp([e,i[0]],[e,i[1]],lg(t));return $a({shape:a,style:n}),{type:"Line",shape:a}},shadow:function(t,e,i){var n=t.getBandWidth(),a=i[1]-i[0];return{type:"Rect",shape:Zp([e-n/2,i[0]],[n,a],lg(t))}}};KI.registerAxisPointerClass("SingleAxisPointer",hD),El({type:"single"});var cD=864e5;ug.prototype={constructor:ug,type:"calendar",dimensions:["time","value"],getDimensionsInfo:function(){return[{name:"time",type:"time"}]},getRangeInfo:function(){return this._rangeInfo},getModel:function(){return this._model},getRect:function(){return this._rect},getCellWidth:function(){return this._sw},getCellHeight:function(){return this._sh},getOrient:function(){return this._orient},getFirstDayOfWeek:function(){return this._firstDayOfWeek},getDateInfo:function(t){t=qr(t);var e=t.getFullYear(),i=t.getMonth()+1;i=10>i?"0"+i:i;var n=t.getDate();n=10>n?"0"+n:n;var a=t.getDay();return a=Math.abs((a+7-this.getFirstDayOfWeek())%7),{y:e,m:i,d:n,day:a,time:t.getTime(),formatedDate:e+"-"+i+"-"+n,date:t}},getNextNDay:function(t,e){return e=e||0,0===e?this.getDateInfo(t):(t=new Date(this.getDateInfo(t).time),t.setDate(t.getDate()+e),this.getDateInfo(t))},update:function(t,e){function i(t,e){return null!=t[e]&&"auto"!==t[e]}this._firstDayOfWeek=+this._model.getModel("dayLabel").get("firstDay"),this._orient=this._model.get("orient"),this._lineWidth=this._model.getModel("itemStyle").getItemStyle().lineWidth||0,this._rangeInfo=this._getRangeInfo(this._initRangeOption());var n=this._rangeInfo.weeks||1,a=["width","height"],r=this._model.get("cellSize").slice(),o=this._model.getBoxLayoutParams(),s="horizontal"===this._orient?[n,7]:[7,n];f([0,1],function(t){i(r,t)&&(o[a[t]]=r[t]*s[t])});var l={width:e.getWidth(),height:e.getHeight()},h=this._rect=uo(o,l);f([0,1],function(t){i(r,t)||(r[t]=h[a[t]]/s[t])}),this._sw=r[0],this._sh=r[1]},dataToPoint:function(t,e){_(t)&&(t=t[0]),null==e&&(e=!0);var i=this.getDateInfo(t),n=this._rangeInfo,a=i.formatedDate;if(e&&!(i.time>=n.start.time&&i.time<=n.end.time))return[0/0,0/0];var r=i.day,o=this._getRangeInfo([n.start.time,a]).nthWeek;return"vertical"===this._orient?[this._rect.x+r*this._sw+this._sw/2,this._rect.y+o*this._sh+this._sh/2]:[this._rect.x+o*this._sw+this._sw/2,this._rect.y+r*this._sh+this._sh/2]},pointToData:function(t){var e=this.pointToDate(t);return e&&e.time},dataToRect:function(t,e){var i=this.dataToPoint(t,e);return{contentShape:{x:i[0]-(this._sw-this._lineWidth)/2,y:i[1]-(this._sh-this._lineWidth)/2,width:this._sw-this._lineWidth,height:this._sh-this._lineWidth},center:i,tl:[i[0]-this._sw/2,i[1]-this._sh/2],tr:[i[0]+this._sw/2,i[1]-this._sh/2],br:[i[0]+this._sw/2,i[1]+this._sh/2],bl:[i[0]-this._sw/2,i[1]+this._sh/2]}},pointToDate:function(t){var e=Math.floor((t[0]-this._rect.x)/this._sw)+1,i=Math.floor((t[1]-this._rect.y)/this._sh)+1,n=this._rangeInfo.range;return"vertical"===this._orient?this._getDateByWeeksAndDay(i,e-1,n):this._getDateByWeeksAndDay(e,i-1,n)},convertToPixel:x(cg,"dataToPoint"),convertFromPixel:x(cg,"pointToData"),_initRangeOption:function(){var t=this._model.get("range"),e=t;if(_(e)&&1===e.length&&(e=e[0]),/^\d{4}$/.test(e)&&(t=[e+"-01-01",e+"-12-31"]),/^\d{4}[\/|-]\d{1,2}$/.test(e)){var i=this.getDateInfo(e),n=i.date;n.setMonth(n.getMonth()+1);var a=this.getNextNDay(n,-1);t=[i.formatedDate,a.formatedDate]}/^\d{4}[\/|-]\d{1,2}[\/|-]\d{1,2}$/.test(e)&&(t=[e,e]);var r=this._getRangeInfo(t);return r.start.time>r.end.time&&t.reverse(),t},_getRangeInfo:function(t){t=[this.getDateInfo(t[0]),this.getDateInfo(t[1])];var e;t[0].time>t[1].time&&(e=!0,t.reverse());var i=Math.floor(t[1].time/cD)-Math.floor(t[0].time/cD)+1,n=new Date(t[0].time),a=n.getDate(),r=t[1].date.getDate();if(n.setDate(a+i-1),n.getDate()!==r)for(var o=n.getTime()-t[1].time>0?1:-1;n.getDate()!==r&&(n.getTime()-t[1].time)*o>0;)i-=o,n.setDate(a+i-1);var s=Math.floor((i+t[0].day+6)/7),l=e?-s+1:s-1;return e&&t.reverse(),{range:[t[0].formatedDate,t[1].formatedDate],start:t[0],end:t[1],allDay:i,weeks:s,nthWeek:l,fweek:t[0].day,lweek:t[1].day}},_getDateByWeeksAndDay:function(t,e,i){var n=this._getRangeInfo(i);if(t>n.weeks||0===t&&e<n.fweek||t===n.weeks&&e>n.lweek)return!1;var a=7*(t-1)-n.fweek+e,r=new Date(n.start.time);return r.setDate(n.start.d+a),this.getDateInfo(r)}},ug.dimensions=ug.prototype.dimensions,ug.getDimensionsInfo=ug.prototype.getDimensionsInfo,ug.create=function(t,e){var i=[];return t.eachComponent("calendar",function(n){var a=new ug(n,t,e);i.push(a),n.coordinateSystem=a}),t.eachSeries(function(t){"calendar"===t.get("coordinateSystem")&&(t.coordinateSystem=i[t.get("calendarIndex")||0])}),i},Fo.register("calendar",ug);var dD=Cb.extend({type:"calendar",coordinateSystem:null,defaultOption:{zlevel:0,z:2,left:80,top:60,cellSize:20,orient:"horizontal",splitLine:{show:!0,lineStyle:{color:"#000",width:1,type:"solid"}},itemStyle:{color:"#fff",borderWidth:1,borderColor:"#ccc"},dayLabel:{show:!0,firstDay:0,position:"start",margin:"50%",nameMap:"en",color:"#000"},monthLabel:{show:!0,position:"start",margin:5,align:"center",nameMap:"en",formatter:null,color:"#000"},yearLabel:{show:!0,position:null,margin:30,formatter:null,color:"#ccc",fontFamily:"sans-serif",fontWeight:"bolder",fontSize:20}},init:function(t){var e=go(t);dD.superApply(this,"init",arguments),dg(t,e)},mergeOption:function(t){dD.superApply(this,"mergeOption",arguments),dg(this.option,t)}}),fD={EN:["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],CN:["一月","二月","三月","四月","五月","六月","七月","八月","九月","十月","十一月","十二月"]},pD={EN:["S","M","T","W","T","F","S"],CN:["日","一","二","三","四","五","六"]};El({type:"calendar",_tlpoints:null,_blpoints:null,_firstDayOfMonth:null,_firstDayPoints:null,render:function(t){var e=this.group;e.removeAll();var i=t.coordinateSystem,n=i.getRangeInfo(),a=i.getOrient();this._renderDayRect(t,n,e),this._renderLines(t,n,a,e),this._renderYearText(t,n,a,e),this._renderMonthText(t,a,e),this._renderWeekText(t,n,a,e)},_renderDayRect:function(t,e,i){for(var n=t.coordinateSystem,a=t.getModel("itemStyle").getItemStyle(),r=n.getCellWidth(),o=n.getCellHeight(),s=e.start.time;s<=e.end.time;s=n.getNextNDay(s,1).time){var l=n.dataToRect([s],!1).tl,h=new Ww({shape:{x:l[0],y:l[1],width:r,height:o},cursor:"default",style:a});i.add(h)}},_renderLines:function(t,e,i,n){function a(e){r._firstDayOfMonth.push(o.getDateInfo(e)),r._firstDayPoints.push(o.dataToRect([e],!1).tl);var a=r._getLinePointsOfOneWeek(t,e,i);r._tlpoints.push(a[0]),r._blpoints.push(a[a.length-1]),l&&r._drawSplitline(a,s,n)}var r=this,o=t.coordinateSystem,s=t.getModel("splitLine.lineStyle").getLineStyle(),l=t.get("splitLine.show"),h=s.lineWidth;this._tlpoints=[],this._blpoints=[],this._firstDayOfMonth=[],this._firstDayPoints=[];for(var u=e.start,c=0;u.time<=e.end.time;c++){a(u.formatedDate),0===c&&(u=o.getDateInfo(e.start.y+"-"+e.start.m));var d=u.date;d.setMonth(d.getMonth()+1),u=o.getDateInfo(d)}a(o.getNextNDay(e.end.time,1).formatedDate),l&&this._drawSplitline(r._getEdgesPoints(r._tlpoints,h,i),s,n),l&&this._drawSplitline(r._getEdgesPoints(r._blpoints,h,i),s,n)},_getEdgesPoints:function(t,e,i){var n=[t[0].slice(),t[t.length-1].slice()],a="horizontal"===i?0:1;return n[0][a]=n[0][a]-e/2,n[1][a]=n[1][a]+e/2,n},_drawSplitline:function(t,e,i){var n=new Fw({z2:20,shape:{points:t},style:e});i.add(n)},_getLinePointsOfOneWeek:function(t,e,i){var n=t.coordinateSystem;e=n.getDateInfo(e);for(var a=[],r=0;7>r;r++){var o=n.getNextNDay(e.time,r),s=n.dataToRect([o.time],!1);a[2*o.day]=s.tl,a[2*o.day+1]=s["horizontal"===i?"bl":"tr"]}return a},_formatterLabel:function(t,e){return"string"==typeof t&&t?ro(t,e):"function"==typeof t?t(e):e.nameMap},_yearTextPositionControl:function(t,e,i,n,a){e=e.slice();var r=["center","bottom"];"bottom"===n?(e[1]+=a,r=["center","top"]):"left"===n?e[0]-=a:"right"===n?(e[0]+=a,r=["center","top"]):e[1]-=a;var o=0;return("left"===n||"right"===n)&&(o=Math.PI/2),{rotation:o,position:e,style:{textAlign:r[0],textVerticalAlign:r[1]}}},_renderYearText:function(t,e,i,n){var a=t.getModel("yearLabel");if(a.get("show")){var r=a.get("margin"),o=a.get("position");o||(o="horizontal"!==i?"top":"left");var s=[this._tlpoints[this._tlpoints.length-1],this._blpoints[0]],l=(s[0][0]+s[1][0])/2,h=(s[0][1]+s[1][1])/2,u="horizontal"===i?0:1,c={top:[l,s[u][1]],bottom:[l,s[1-u][1]],left:[s[1-u][0],h],right:[s[u][0],h]},d=e.start.y;+e.end.y>+e.start.y&&(d=d+"-"+e.end.y);var f=a.get("formatter"),p={start:e.start.y,end:e.end.y,nameMap:d},g=this._formatterLabel(f,p),v=new Pw({z2:30});fr(v.style,a,{text:g}),v.attr(this._yearTextPositionControl(v,c[o],i,o,r)),n.add(v)}},_monthTextPositionControl:function(t,e,i,n,a){var r="left",o="top",s=t[0],l=t[1];return"horizontal"===i?(l+=a,e&&(r="center"),"start"===n&&(o="bottom")):(s+=a,e&&(o="middle"),"start"===n&&(r="right")),{x:s,y:l,textAlign:r,textVerticalAlign:o}},_renderMonthText:function(t,e,i){var n=t.getModel("monthLabel");if(n.get("show")){var a=n.get("nameMap"),r=n.get("margin"),s=n.get("position"),l=n.get("align"),h=[this._tlpoints,this._blpoints];b(a)&&(a=fD[a.toUpperCase()]||[]);var u="start"===s?0:1,c="horizontal"===e?0:1;r="start"===s?-r:r;for(var d="center"===l,f=0;f<h[u].length-1;f++){var p=h[u][f].slice(),g=this._firstDayOfMonth[f];if(d){var v=this._firstDayPoints[f];p[c]=(v[c]+h[0][f+1][c])/2}var m=n.get("formatter"),y=a[+g.m-1],x={yyyy:g.y,yy:(g.y+"").slice(2),MM:g.m,M:+g.m,nameMap:y},_=this._formatterLabel(m,x),w=new Pw({z2:30});o(fr(w.style,n,{text:_}),this._monthTextPositionControl(p,d,e,s,r)),i.add(w)}}},_weekTextPositionControl:function(t,e,i,n,a){var r="center",o="middle",s=t[0],l=t[1],h="start"===i;return"horizontal"===e?(s=s+n+(h?1:-1)*a[0]/2,r=h?"right":"left"):(l=l+n+(h?1:-1)*a[1]/2,o=h?"bottom":"top"),{x:s,y:l,textAlign:r,textVerticalAlign:o}},_renderWeekText:function(t,e,i,n){var a=t.getModel("dayLabel");if(a.get("show")){var r=t.coordinateSystem,s=a.get("position"),l=a.get("nameMap"),h=a.get("margin"),u=r.getFirstDayOfWeek();b(l)&&(l=pD[l.toUpperCase()]||[]);var c=r.getNextNDay(e.end.time,7-e.lweek).time,d=[r.getCellWidth(),r.getCellHeight()];h=Gr(h,d["horizontal"===i?0:1]),"start"===s&&(c=r.getNextNDay(e.start.time,-(7+e.fweek)).time,h=-h);for(var f=0;7>f;f++){var p=r.getNextNDay(c,f),g=r.dataToRect([p.time],!1).center,v=f;v=Math.abs((f+u)%7);var m=new Pw({z2:30});o(fr(m.style,a,{text:l[v]}),this._weekTextPositionControl(g,i,s,h,d)),n.add(m)}}}}),zl({type:"title",layoutMode:{type:"box",ignoreSize:!0},defaultOption:{zlevel:0,z:6,show:!0,text:"",target:"blank",subtext:"",subtarget:"blank",left:0,top:0,backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",borderWidth:0,padding:5,itemGap:10,textStyle:{fontSize:18,fontWeight:"bolder",color:"#333"},subtextStyle:{color:"#aaa"}}}),El({type:"title",render:function(t,e,i){if(this.group.removeAll(),t.get("show")){var n=this.group,a=t.getModel("textStyle"),r=t.getModel("subtextStyle"),o=t.get("textAlign"),s=t.get("textBaseline"),l=new Pw({style:fr({},a,{text:t.get("text"),textFill:a.getTextColor()},{disableBox:!0}),z2:10}),h=l.getBoundingRect(),u=t.get("subtext"),c=new Pw({style:fr({},r,{text:u,textFill:r.getTextColor(),y:h.height+t.get("itemGap"),textVerticalAlign:"top"},{disableBox:!0}),z2:10}),d=t.get("link"),f=t.get("sublink");l.silent=!d,c.silent=!f,d&&l.on("click",function(){window.open(d,"_"+t.get("target"))}),f&&c.on("click",function(){window.open(f,"_"+t.get("subtarget"))}),n.add(l),u&&n.add(c);var p=n.getBoundingRect(),g=t.getBoxLayoutParams();g.width=p.width,g.height=p.height;var v=uo(g,{width:i.getWidth(),height:i.getHeight()},t.get("padding"));o||(o=t.get("left")||t.get("right"),"middle"===o&&(o="center"),"right"===o?v.x+=v.width:"center"===o&&(v.x+=v.width/2)),s||(s=t.get("top")||t.get("bottom"),"center"===s&&(s="middle"),"bottom"===s?v.y+=v.height:"middle"===s&&(v.y+=v.height/2),s=s||"top"),n.attr("position",[v.x,v.y]);var m={textAlign:o,textVerticalAlign:s};l.setStyle(m),c.setStyle(m),p=n.getBoundingRect();var y=v.margin,x=t.getItemStyle(["color","opacity"]);x.fill=t.get("backgroundColor");var _=new Ww({shape:{x:p.x-y[3],y:p.y-y[0],width:p.width+y[1]+y[3],height:p.height+y[0]+y[2],r:t.get("borderRadius")},style:x,silent:!0});Ka(_),n.add(_)}}});var gD=zl({type:"legend.plain",dependencies:["series"],layoutMode:{type:"box",ignoreSize:!0},init:function(t,e,i){this.mergeDefaultAndTheme(t,i),t.selected=t.selected||{}},mergeOption:function(t){gD.superCall(this,"mergeOption",t)},optionUpdated:function(){this._updateData(this.ecModel);var t=this._data;if(t[0]&&"single"===this.get("selectedMode")){for(var e=!1,i=0;i<t.length;i++){var n=t[i].get("name");if(this.isSelected(n)){this.select(n),e=!0;break}}!e&&this.select(t[0].get("name"))}},_updateData:function(t){var e=[],i=[];t.eachRawSeries(function(n){var a=n.name;i.push(a);var r;if(n.legendDataProvider){var o=n.legendDataProvider(),s=o.mapArray(o.getName);t.isSeriesFiltered(n)||(i=i.concat(s)),s.length?e=e.concat(s):r=a}else r=a;r&&r!==__&&e.push(r)}),this._availableNames=i;var n=this.get("data")||e,a=p(n,function(t){return("string"==typeof t||"number"==typeof t)&&(t={name:t}),new Pr(t,this,this.ecModel)},this);this._data=a},getData:function(){return this._data},select:function(t){var e=this.option.selected,i=this.get("selectedMode");if("single"===i){var n=this._data;f(n,function(t){e[t.get("name")]=!1})}e[t]=!0},unSelect:function(t){"single"!==this.get("selectedMode")&&(this.option.selected[t]=!1)},toggleSelected:function(t){var e=this.option.selected;e.hasOwnProperty(t)||(e[t]=!0),this[e[t]?"unSelect":"select"](t)},isSelected:function(t){var e=this.option.selected;return!(e.hasOwnProperty(t)&&!e[t])&&h(this._availableNames,t)>=0},defaultOption:{zlevel:0,z:4,show:!0,orient:"horizontal",left:"center",top:0,align:"auto",backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",borderRadius:0,borderWidth:0,padding:5,itemGap:10,itemWidth:25,itemHeight:14,inactiveColor:"#ccc",textStyle:{color:"#333"},selectedMode:!0,tooltip:{show:!1}}});Al("legendToggleSelect","legendselectchanged",x(fg,"toggleSelected")),Al("legendSelect","legendselected",x(fg,"select")),Al("legendUnSelect","legendunselected",x(fg,"unSelect"));var vD=x,mD=f,yD=xx,xD=El({type:"legend.plain",newlineDisabled:!1,init:function(){this.group.add(this._contentGroup=new yD),this._backgroundEl},getContentGroup:function(){return this._contentGroup},render:function(t,e,i){if(this.resetInner(),t.get("show",!0)){var n=t.get("align");n&&"auto"!==n||(n="right"===t.get("left")&&"vertical"===t.get("orient")?"right":"left"),this.renderInner(n,t,e,i);var a=t.getBoxLayoutParams(),r={width:i.getWidth(),height:i.getHeight()},o=t.get("padding"),l=uo(a,r,o),h=this.layoutInner(t,n,l),u=uo(s({width:h.width,height:h.height},a),r,o);this.group.attr("position",[u.x-h.x,u.y-h.y]),this.group.add(this._backgroundEl=gg(h,t))}},resetInner:function(){this.getContentGroup().removeAll(),this._backgroundEl&&this.group.remove(this._backgroundEl)},renderInner:function(t,e,i,n){var a=this.getContentGroup(),r=B(),o=e.get("selectedMode");mD(e.getData(),function(s,l){var h=s.get("name");if(!this.newlineDisabled&&(""===h||"\n"===h))return void a.add(new yD({newline:!0}));var u=i.getSeriesByName(h)[0];if(!r.get(h))if(u){var c=u.getData(),d=c.getVisual("color");"function"==typeof d&&(d=d(u.getDataParams(0)));var f=c.getVisual("legendSymbol")||"roundRect",p=c.getVisual("symbol"),g=this._createItem(h,l,s,e,f,p,t,d,o);g.on("click",vD(vg,h,n)).on("mouseover",vD(mg,u,null,n)).on("mouseout",vD(yg,u,null,n)),r.set(h,!0)}else i.eachRawSeries(function(i){if(!r.get(h)&&i.legendDataProvider){var a=i.legendDataProvider(),u=a.indexOfName(h);if(0>u)return;var c=a.getItemVisual(u,"color"),d="roundRect",f=this._createItem(h,l,s,e,d,null,t,c,o);f.on("click",vD(vg,h,n)).on("mouseover",vD(mg,i,h,n)).on("mouseout",vD(yg,i,h,n)),r.set(h,!0)}},this)},this)},_createItem:function(t,e,i,n,a,r,s,l,h){var u=n.get("itemWidth"),c=n.get("itemHeight"),d=n.get("inactiveColor"),f=n.isSelected(t),p=new yD,g=i.getModel("textStyle"),v=i.get("icon"),m=i.getModel("tooltip"),y=m.parentModel;if(a=v||a,p.add(zh(a,0,0,u,c,f?l:d,!0)),!v&&r&&(r!==a||"none"==r)){var x=.8*c;"none"===r&&(r="circle"),p.add(zh(r,(u-x)/2,(c-x)/2,x,x,f?l:d))}var _="left"===s?u+5:-5,w=s,b=n.get("formatter"),M=t;"string"==typeof b&&b?M=b.replace("{name}",null!=t?t:""):"function"==typeof b&&(M=b(t)),p.add(new Pw({style:fr({},g,{text:M,x:_,y:c/2,textFill:f?g.getTextColor():d,textAlign:w,textVerticalAlign:"middle"})}));var S=new Ww({shape:p.getBoundingRect(),invisible:!0,tooltip:m.get("show")?o({content:t,formatter:y.get("formatter",!0)||function(){return t},formatterParams:{componentType:"legend",legendIndex:n.componentIndex,name:t,$vars:["name"]}},m.option):null});return p.add(S),p.eachChild(function(t){t.silent=!0}),S.silent=!h,this.getContentGroup().add(p),cr(p),p.__legendDataIndex=e,p},layoutInner:function(t,e,i){var n=this.getContentGroup();Ib(t.get("orient"),n,t.get("itemGap"),i.width,i.height);var a=n.getBoundingRect();return n.attr("position",[-a.x,-a.y]),this.group.getBoundingRect()}}),_D=function(t){var e=t.findComponents({mainType:"legend"});e&&e.length&&t.filterSeries(function(t){for(var i=0;i<e.length;i++)if(!e[i].isSelected(t.name))return!1;return!0})};Il(_D),Cb.registerSubTypeDefaulter("legend",function(){return"plain"});var wD=gD.extend({type:"legend.scroll",setScrollDataIndex:function(t){this.option.scrollDataIndex=t},defaultOption:{scrollDataIndex:0,pageButtonItemGap:5,pageButtonGap:null,pageButtonPosition:"end",pageFormatter:"{current}/{total}",pageIcons:{horizontal:["M0,0L12,-10L12,10z","M0,0L-12,-10L-12,10z"],vertical:["M0,0L20,0L10,-20z","M0,0L20,0L10,20z"]},pageIconColor:"#2f4554",pageIconInactiveColor:"#aaa",pageIconSize:15,pageTextStyle:{color:"#333"},animationDurationUpdate:800},init:function(t,e,i,n){var a=go(t);wD.superCall(this,"init",t,e,i,n),xg(this,t,a)},mergeOption:function(t,e){wD.superCall(this,"mergeOption",t,e),xg(this,this.option,t)},getOrient:function(){return"vertical"===this.get("orient")?{index:1,name:"vertical"}:{index:0,name:"horizontal"}}}),bD=xx,MD=["width","height"],SD=["x","y"],ID=xD.extend({type:"legend.scroll",newlineDisabled:!0,init:function(){ID.superCall(this,"init"),this._currentIndex=0,this.group.add(this._containerGroup=new bD),this._containerGroup.add(this.getContentGroup()),this.group.add(this._controllerGroup=new bD),this._showController},resetInner:function(){ID.superCall(this,"resetInner"),this._controllerGroup.removeAll(),this._containerGroup.removeClipPath(),this._containerGroup.__rectSize=null},renderInner:function(t,e,i,n){function a(t,i){var a=t+"DataIndex",l=kr(e.get("pageIcons",!0)[e.getOrient().name][i],{onclick:y(r._pageGo,r,a,e,n)},{x:-s[0]/2,y:-s[1]/2,width:s[0],height:s[1]});l.name=t,o.add(l)}var r=this;ID.superCall(this,"renderInner",t,e,i,n);var o=this._controllerGroup,s=e.get("pageIconSize",!0);_(s)||(s=[s,s]),a("pagePrev",0);var l=e.getModel("pageTextStyle");o.add(new Pw({name:"pageText",style:{textFill:l.getTextColor(),font:l.getFont(),textVerticalAlign:"middle",textAlign:"center"},silent:!0})),a("pageNext",1)},layoutInner:function(t,e,i){var n=this.getContentGroup(),a=this._containerGroup,r=this._controllerGroup,o=t.getOrient().index,s=MD[o],l=MD[1-o],h=SD[1-o];Ib(t.get("orient"),n,t.get("itemGap"),o?i.width:null,o?null:i.height),Ib("horizontal",r,t.get("pageButtonItemGap",!0));var u=n.getBoundingRect(),c=r.getBoundingRect(),d=this._showController=u[s]>i[s],f=[-u.x,-u.y];f[o]=n.position[o];var p=[0,0],g=[-c.x,-c.y],v=D(t.get("pageButtonGap",!0),t.get("itemGap",!0));if(d){var m=t.get("pageButtonPosition",!0);"end"===m?g[o]+=i[s]-c[s]:p[o]+=c[s]+v}g[1-o]+=u[l]/2-c[l]/2,n.attr("position",f),a.attr("position",p),r.attr("position",g);var y=this.group.getBoundingRect(),y={x:0,y:0};if(y[s]=d?i[s]:u[s],y[l]=Math.max(u[l],c[l]),y[h]=Math.min(0,c[h]+g[1-o]),a.__rectSize=i[s],d){var x={x:0,y:0};x[s]=Math.max(i[s]-c[s]-v,0),x[l]=y[l],a.setClipPath(new Ww({shape:x})),a.__rectSize=x[s]}else r.eachChild(function(t){t.attr({invisible:!0,silent:!0})});var _=this._getPageInfo(t);return null!=_.pageIndex&&Mr(n,{position:_.contentPosition},d?t:!1),this._updatePageInfoView(t,_),y},_pageGo:function(t,e,i){var n=this._getPageInfo(e)[t];null!=n&&i.dispatchAction({type:"legendScroll",scrollDataIndex:n,legendId:e.id})},_updatePageInfoView:function(t,e){var i=this._controllerGroup;f(["pagePrev","pageNext"],function(n){var a=null!=e[n+"DataIndex"],r=i.childOfName(n);r&&(r.setStyle("fill",a?t.get("pageIconColor",!0):t.get("pageIconInactiveColor",!0)),r.cursor=a?"pointer":"default")});var n=i.childOfName("pageText"),a=t.get("pageFormatter"),r=e.pageIndex,o=null!=r?r+1:0,s=e.pageCount;n&&a&&n.setStyle("text",b(a)?a.replace("{current}",o).replace("{total}",s):a({current:o,total:s}))},_getPageInfo:function(t){function e(t){var e=t.getBoundingRect().clone();return e[f]+=t.position[u],e}var i,n,a,r,o=t.get("scrollDataIndex",!0),s=this.getContentGroup(),l=s.getBoundingRect(),h=this._containerGroup.__rectSize,u=t.getOrient().index,c=MD[u],d=MD[1-u],f=SD[u],p=s.position.slice();this._showController?s.eachChild(function(t){t.__legendDataIndex===o&&(r=t)}):r=s.childAt(0);var g=h?Math.ceil(l[c]/h):0;if(r){var v=r.getBoundingRect(),m=r.position[u]+v[f];p[u]=-m-l[f],i=Math.floor(g*(m+v[f]+h/2)/l[c]),i=l[c]&&g?Math.max(0,Math.min(g-1,i)):-1;var y={x:0,y:0};y[c]=h,y[d]=l[d],y[f]=-p[u]-l[f];var x,_=s.children();if(s.eachChild(function(t,i){var n=e(t);n.intersect(y)&&(null==x&&(x=i),a=t.__legendDataIndex),i===_.length-1&&n[f]+n[c]<=y[f]+y[c]&&(a=null)}),null!=x){var w=_[x],b=e(w);if(y[f]=b[f]+b[c]-y[c],0>=x&&b[f]>=y[f])n=null;else{for(;x>0&&e(_[x-1]).intersect(y);)x--;n=_[x].__legendDataIndex}}}return{contentPosition:p,pageIndex:i,pageCount:g,pagePrevDataIndex:n,pageNextDataIndex:a}}});Al("legendScroll","legendscroll",function(t,e){var i=t.scrollDataIndex;null!=i&&e.eachComponent({mainType:"legend",subType:"scroll",query:t},function(t){t.setScrollDataIndex(i)})}),zl({type:"tooltip",dependencies:["axisPointer"],defaultOption:{zlevel:0,z:8,show:!0,showContent:!0,trigger:"item",triggerOn:"mousemove|click",alwaysShowContent:!1,displayMode:"single",confine:!1,showDelay:0,hideDelay:100,transitionDuration:.4,enterable:!1,backgroundColor:"rgba(50,50,50,0.7)",borderColor:"#333",borderRadius:4,borderWidth:0,padding:5,extraCssText:"",axisPointer:{type:"line",axis:"auto",animation:"auto",animationDurationUpdate:200,animationEasingUpdate:"exponentialOut",crossStyle:{color:"#999",width:1,type:"dashed",textStyle:{}}},textStyle:{color:"#fff",fontSize:14}}});var TD=f,AD=io,CD=["","-webkit-","-moz-","-o-"],DD="position:absolute;display:block;border-style:solid;white-space:nowrap;z-index:9999999;";Mg.prototype={constructor:Mg,_enterable:!0,update:function(){var t=this._container,e=t.currentStyle||document.defaultView.getComputedStyle(t),i=t.style;"absolute"!==i.position&&"absolute"!==e.position&&(i.position="relative")},show:function(t){clearTimeout(this._hideTimeout);var e=this.el;e.style.cssText=DD+bg(t)+";left:"+this._x+"px;top:"+this._y+"px;"+(t.get("extraCssText")||""),e.style.display=e.innerHTML?"block":"none",this._show=!0},setContent:function(t){this.el.innerHTML=null==t?"":t},setEnterable:function(t){this._enterable=t},getSize:function(){var t=this.el;return[t.clientWidth,t.clientHeight]},moveTo:function(t,e){var i,n=this._zr;n&&n.painter&&(i=n.painter.getViewportRootOffset())&&(t+=i.offsetLeft,e+=i.offsetTop);var a=this.el.style;a.left=t+"px",a.top=e+"px",this._x=t,this._y=e},hide:function(){this.el.style.display="none",this._show=!1},hideLater:function(t){!this._show||this._inContent&&this._enterable||(t?(this._hideDelay=t,this._show=!1,this._hideTimeout=setTimeout(y(this.hide,this),t)):this.hide())},isShow:function(){return this._show}};var LD=y,kD=f,PD=Gr,OD=new Ww({shape:{x:-1,y:-1,width:2,height:2}});El({type:"tooltip",init:function(t,e){if(!vy.node){var i=new Mg(e.getDom(),e);this._tooltipContent=i}},render:function(t,e,i){if(!vy.node&&!vy.wxa){this.group.removeAll(),this._tooltipModel=t,this._ecModel=e,this._api=i,this._lastDataByCoordSys=null,this._alwaysShowContent=t.get("alwaysShowContent");var n=this._tooltipContent;n.update(),n.setEnterable(t.get("enterable")),this._initGlobalListener(),this._keepShow()}},_initGlobalListener:function(){var t=this._tooltipModel,e=t.get("triggerOn");Sp("itemTooltip",this._api,LD(function(t,i,n){"none"!==e&&(e.indexOf(t)>=0?this._tryShow(i,n):"leave"===t&&this._hide(n))},this))},_keepShow:function(){var t=this._tooltipModel,e=this._ecModel,i=this._api;if(null!=this._lastX&&null!=this._lastY&&"none"!==t.get("triggerOn")){var n=this;clearTimeout(this._refreshUpdateTimeout),this._refreshUpdateTimeout=setTimeout(function(){n.manuallyShowTip(t,e,i,{x:n._lastX,y:n._lastY})})}},manuallyShowTip:function(t,e,i,n){if(n.from!==this.uid&&!vy.node){var a=Ig(n,i);this._ticket="";var r=n.dataByCoordSys;if(n.tooltip&&null!=n.x&&null!=n.y){var o=OD;o.position=[n.x,n.y],o.update(),o.tooltip=n.tooltip,this._tryShow({offsetX:n.x,offsetY:n.y,target:o},a)}else if(r)this._tryShow({offsetX:n.x,offsetY:n.y,position:n.position,event:{},dataByCoordSys:n.dataByCoordSys,tooltipOption:n.tooltipOption},a);else if(null!=n.seriesIndex){if(this._manuallyAxisShowTip(t,e,i,n))return;var s=SC(n,e),l=s.point[0],h=s.point[1];null!=l&&null!=h&&this._tryShow({offsetX:l,offsetY:h,position:n.position,target:s.el,event:{}},a)}else null!=n.x&&null!=n.y&&(i.dispatchAction({type:"updateAxisPointer",x:n.x,y:n.y}),this._tryShow({offsetX:n.x,offsetY:n.y,position:n.position,target:i.getZr().findHover(n.x,n.y).target,event:{}},a))}},manuallyHideTip:function(t,e,i,n){var a=this._tooltipContent;!this._alwaysShowContent&&this._tooltipModel&&a.hideLater(this._tooltipModel.get("hideDelay")),this._lastX=this._lastY=null,n.from!==this.uid&&this._hide(Ig(n,i))},_manuallyAxisShowTip:function(t,e,i,n){var a=n.seriesIndex,r=n.dataIndex,o=e.getComponent("axisPointer").coordSysAxesInfo;if(null!=a&&null!=r&&null!=o){var s=e.getSeriesByIndex(a);if(s){var l=s.getData(),t=Sg([l.getItemModel(r),s,(s.coordinateSystem||{}).model,t]);if("axis"===t.get("trigger"))return i.dispatchAction({type:"updateAxisPointer",seriesIndex:a,dataIndex:r,position:n.position}),!0}}},_tryShow:function(t,e){var i=t.target,n=this._tooltipModel;if(n){this._lastX=t.offsetX,this._lastY=t.offsetY;var a=t.dataByCoordSys;a&&a.length?this._showAxisTooltip(a,t):i&&null!=i.dataIndex?(this._lastDataByCoordSys=null,this._showSeriesItemTooltip(t,i,e)):i&&i.tooltip?(this._lastDataByCoordSys=null,this._showComponentItemTooltip(t,i,e)):(this._lastDataByCoordSys=null,this._hide(e))}},_showOrMove:function(t,e){var i=t.get("showDelay");e=y(e,this),clearTimeout(this._showTimout),i>0?this._showTimout=setTimeout(e,i):e()},_showAxisTooltip:function(t,e){var i=this._ecModel,n=this._tooltipModel,a=[e.offsetX,e.offsetY],r=[],o=[],s=Sg([e.tooltipOption,n]);kD(t,function(t){kD(t.dataByAxis,function(t){var e=i.getComponent(t.axisDim+"Axis",t.axisIndex),n=t.value,a=[];if(e&&null!=n){var s=Gp(n,e.axis,i,t.seriesDataIndices,t.valueLabelOpt);f(t.seriesDataIndices,function(r){var l=i.getSeriesByIndex(r.seriesIndex),h=r.dataIndexInside,u=l&&l.getDataParams(h);u.axisDim=t.axisDim,u.axisIndex=t.axisIndex,u.axisType=t.axisType,u.axisId=t.axisId,u.axisValue=Ph(e.axis,n),u.axisValueLabel=s,u&&(o.push(u),a.push(l.formatTooltip(h,!0)))});var l=s;r.push((l?no(l)+"<br />":"")+a.join("<br />"))}})},this),r.reverse(),r=r.join("<br /><br />");var l=e.position;this._showOrMove(s,function(){this._updateContentNotChangedOnAxis(t)?this._updatePosition(s,l,a[0],a[1],this._tooltipContent,o):this._showTooltipContent(s,r,o,Math.random(),a[0],a[1],l)})},_showSeriesItemTooltip:function(t,e,i){var n=this._ecModel,a=e.seriesIndex,r=n.getSeriesByIndex(a),o=e.dataModel||r,s=e.dataIndex,l=e.dataType,h=o.getData(),u=Sg([h.getItemModel(s),o,r&&(r.coordinateSystem||{}).model,this._tooltipModel]),c=u.get("trigger");if(null==c||"item"===c){var d=o.getDataParams(s,l),f=o.formatTooltip(s,!1,l),p="item_"+o.name+"_"+s;this._showOrMove(u,function(){this._showTooltipContent(u,f,d,p,t.offsetX,t.offsetY,t.position,t.target)}),i({type:"showTip",dataIndexInside:s,dataIndex:h.getRawIndex(s),seriesIndex:a,from:this.uid})}},_showComponentItemTooltip:function(t,e,i){var n=e.tooltip;if("string"==typeof n){var a=n;n={content:a,formatter:a}}var r=new Pr(n,this._tooltipModel,this._ecModel),o=r.get("content"),s=Math.random();this._showOrMove(r,function(){this._showTooltipContent(r,o,r.get("formatterParams")||{},s,t.offsetX,t.offsetY,t.position,e)}),i({type:"showTip",from:this.uid})},_showTooltipContent:function(t,e,i,n,a,r,o,s){if(this._ticket="",t.get("showContent")&&t.get("show")){var l=this._tooltipContent,h=t.get("formatter");o=o||t.get("position");var u=e;if(h&&"string"==typeof h)u=ao(h,i,!0);else if("function"==typeof h){var c=LD(function(e,n){e===this._ticket&&(l.setContent(n),this._updatePosition(t,o,a,r,l,i,s))},this);this._ticket=n,u=h(i,n,c)}l.setContent(u),l.show(t),this._updatePosition(t,o,a,r,l,i,s)}},_updatePosition:function(t,e,i,n,a,r,o){var s=this._api.getWidth(),l=this._api.getHeight();e=e||t.get("position");var h=a.getSize(),u=t.get("align"),c=t.get("verticalAlign"),d=o&&o.getBoundingRect().clone();if(o&&d.applyTransform(o.transform),"function"==typeof e&&(e=e([i,n],r,a.el,d,{viewSize:[s,l],contentSize:h.slice()})),_(e))i=PD(e[0],s),n=PD(e[1],l);else if(M(e)){e.width=h[0],e.height=h[1];var f=uo(e,{width:s,height:l});i=f.x,n=f.y,u=null,c=null}else if("string"==typeof e&&o){var p=Dg(e,d,h);
-i=p[0],n=p[1]}else{var p=Tg(i,n,a.el,s,l,u?null:20,c?null:20);i=p[0],n=p[1]}if(u&&(i-=Lg(u)?h[0]/2:"right"===u?h[0]:0),c&&(n-=Lg(c)?h[1]/2:"bottom"===c?h[1]:0),t.get("confine")){var p=Ag(i,n,a.el,s,l);i=p[0],n=p[1]}a.moveTo(i,n)},_updateContentNotChangedOnAxis:function(t){var e=this._lastDataByCoordSys,i=!!e&&e.length===t.length;return i&&kD(e,function(e,n){var a=e.dataByAxis||{},r=t[n]||{},o=r.dataByAxis||[];i&=a.length===o.length,i&&kD(a,function(t,e){var n=o[e]||{},a=t.seriesDataIndices||[],r=n.seriesDataIndices||[];i&=t.value===n.value&&t.axisType===n.axisType&&t.axisId===n.axisId&&a.length===r.length,i&&kD(a,function(t,e){var n=r[e];i&=t.seriesIndex===n.seriesIndex&&t.dataIndex===n.dataIndex})})}),this._lastDataByCoordSys=t,!!i},_hide:function(t){this._lastDataByCoordSys=null,t({type:"hideTip",from:this.uid})},dispose:function(t,e){vy.node||(this._tooltipContent.hide(),Lp("itemTooltip",e))}}),Al({type:"showTip",event:"showTip",update:"tooltip:manuallyShowTip"},function(){}),Al({type:"hideTip",event:"hideTip",update:"tooltip:manuallyHideTip"},function(){});var zD=eo,ED=no,RD=zl({type:"marker",dependencies:["series","grid","polar","geo"],init:function(t,e,i,n){this.mergeDefaultAndTheme(t,i),this.mergeOption(t,i,n.createdBySelf,!0)},isAnimationEnabled:function(){if(vy.node)return!1;var t=this.__hostSeries;return this.getShallow("animation")&&t&&t.isAnimationEnabled()},mergeOption:function(t,e,i,n){var a=this.constructor,r=this.mainType+"Model";i||e.eachSeries(function(t){var i=t.get(this.mainType),s=t[r];return i&&i.data?(s?s.mergeOption(i,e,!0):(n&&kg(i),f(i.data,function(t){t instanceof Array?(kg(t[0]),kg(t[1])):kg(t)}),s=new a(i,this,e),o(s,{mainType:this.mainType,seriesIndex:t.seriesIndex,name:t.name,createdBySelf:!0}),s.__hostSeries=t),void(t[r]=s)):void(t[r]=null)},this)},formatTooltip:function(t){var e=this.getData(),i=this.getRawValue(t),n=_(i)?p(i,zD).join(", "):zD(i),a=e.getName(t),r=ED(this.name);return(null!=i||a)&&(r+="<br />"),a&&(r+=ED(a),null!=i&&(r+=" : ")),null!=i&&(r+=ED(n)),r},getData:function(){return this._data},setData:function(t){this._data=t}});c(RD,uM),RD.extend({type:"markPoint",defaultOption:{zlevel:0,z:5,symbol:"pin",symbolSize:50,tooltip:{trigger:"item"},label:{show:!0,position:"inside"},itemStyle:{borderWidth:2},emphasis:{label:{show:!0}}}});var ND=h,BD=x,VD={min:BD(Eg,"min"),max:BD(Eg,"max"),average:BD(Eg,"average")},GD=El({type:"marker",init:function(){this.markerGroupMap=B()},render:function(t,e,i){var n=this.markerGroupMap;n.each(function(t){t.__keep=!1});var a=this.type+"Model";e.eachSeries(function(t){var n=t[a];n&&this.renderSeries(t,n,e,i)},this),n.each(function(t){!t.__keep&&this.group.remove(t.group)},this)},renderSeries:function(){}});GD.extend({type:"markPoint",updateTransform:function(t,e,i){e.eachSeries(function(t){var e=t.markPointModel;e&&(Wg(e.getData(),t,i),this.markerGroupMap.get(t.id).updateLayout(e))},this)},renderSeries:function(t,e,i,n){var a=t.coordinateSystem,r=t.id,o=t.getData(),s=this.markerGroupMap,l=s.get(r)||s.set(r,new Ru),h=Hg(a,t,e);e.setData(h),Wg(e.getData(),t,n),h.each(function(t){var i=h.getItemModel(t),n=i.getShallow("symbolSize");"function"==typeof n&&(n=n(e.getRawValue(t),e.getDataParams(t))),h.setItemVisual(t,{symbolSize:n,color:i.get("itemStyle.color")||o.getVisual("color"),symbol:i.getShallow("symbol")})}),l.updateData(h),this.group.add(l.group),h.eachItemGraphicEl(function(t){t.traverse(function(t){t.dataModel=e})}),l.__keep=!0,l.group.silent=e.get("silent")||t.get("silent")}}),Sl(function(t){t.markPoint=t.markPoint||{}}),RD.extend({type:"markLine",defaultOption:{zlevel:0,z:5,symbol:["circle","arrow"],symbolSize:[8,16],precision:2,tooltip:{trigger:"item"},label:{show:!0,position:"end"},lineStyle:{type:"dashed"},emphasis:{label:{show:!0},lineStyle:{width:3}},animationEasing:"linear"}});var FD=function(t,e,i,r){var s=t.getData(),l=r.type;if(!_(r)&&("min"===l||"max"===l||"average"===l||null!=r.xAxis||null!=r.yAxis)){var h,u,c;if(null!=r.yAxis||null!=r.xAxis)u=null!=r.yAxis?"y":"x",h=e.getAxis(u),c=C(r.yAxis,r.xAxis);else{var d=Ng(r,s,e,t);u=d.valueDataDim,h=d.valueAxis,c=Fg(s,u,l)}var f="x"===u?0:1,p=1-f,g=n(r),v={};g.type=null,g.coord=[],v.coord=[],g.coord[p]=-1/0,v.coord[p]=1/0;var m=i.get("precision");m>=0&&"number"==typeof c&&(c=+c.toFixed(Math.min(m,20))),g.coord[f]=v.coord[f]=c,r=[g,v,{type:l,valueIndex:r.valueIndex,value:c}]}return r=[Rg(t,r[0]),Rg(t,r[1]),o({},r[2])],r[2].type=r[2].type||"",a(r[2],r[0]),a(r[2],r[1]),r};GD.extend({type:"markLine",updateTransform:function(t,e,i){e.eachSeries(function(t){var e=t.markLineModel;if(e){var n=e.getData(),a=e.__from,r=e.__to;a.each(function(e){Ug(a,e,!0,t,i),Ug(r,e,!1,t,i)}),n.each(function(t){n.setItemLayout(t,[a.getItemLayout(t),r.getItemLayout(t)])}),this.markerGroupMap.get(t.id).updateLayout()}},this)},renderSeries:function(t,e,i,n){function a(e,i,a){var r=e.getItemModel(i);Ug(e,i,a,t,n),e.setItemVisual(i,{symbolSize:r.get("symbolSize")||g[a?0:1],symbol:r.get("symbol",!0)||p[a?0:1],color:r.get("itemStyle.color")||s.getVisual("color")})}var r=t.coordinateSystem,o=t.id,s=t.getData(),l=this.markerGroupMap,h=l.get(o)||l.set(o,new $c);this.group.add(h.group);var u=Yg(r,t,e),c=u.from,d=u.to,f=u.line;e.__from=c,e.__to=d,e.setData(f);var p=e.get("symbol"),g=e.get("symbolSize");_(p)||(p=[p,p]),"number"==typeof g&&(g=[g,g]),u.from.each(function(t){a(c,t,!0),a(d,t,!1)}),f.each(function(t){var e=f.getItemModel(t).get("lineStyle.color");f.setItemVisual(t,{color:e||c.getItemVisual(t,"color")}),f.setItemLayout(t,[c.getItemLayout(t),d.getItemLayout(t)]),f.setItemVisual(t,{fromSymbolSize:c.getItemVisual(t,"symbolSize"),fromSymbol:c.getItemVisual(t,"symbol"),toSymbolSize:d.getItemVisual(t,"symbolSize"),toSymbol:d.getItemVisual(t,"symbol")})}),h.updateData(f),u.line.eachItemGraphicEl(function(t){t.traverse(function(t){t.dataModel=e})}),h.__keep=!0,h.group.silent=e.get("silent")||t.get("silent")}}),Sl(function(t){t.markLine=t.markLine||{}}),RD.extend({type:"markArea",defaultOption:{zlevel:0,z:1,tooltip:{trigger:"item"},animation:!1,label:{show:!0,position:"top"},itemStyle:{borderWidth:0},emphasis:{label:{show:!0,position:"top"}}}});var WD=function(t,e,i,n){var a=Rg(t,n[0]),o=Rg(t,n[1]),s=C,l=a.coord,h=o.coord;l[0]=s(l[0],-1/0),l[1]=s(l[1],-1/0),h[0]=s(h[0],1/0),h[1]=s(h[1],1/0);var u=r([{},a,o]);return u.coord=[a.coord,o.coord],u.x0=a.x,u.y0=a.y,u.x1=o.x,u.y1=o.y,u},HD=[["x0","y0"],["x1","y0"],["x1","y1"],["x0","y1"]];GD.extend({type:"markArea",updateTransform:function(t,e,i){e.eachSeries(function(t){var e=t.markAreaModel;if(e){var n=e.getData();n.each(function(e){var a=p(HD,function(a){return Jg(n,e,a,t,i)});n.setItemLayout(e,a);var r=n.getItemGraphicEl(e);r.setShape("points",a)})}},this)},renderSeries:function(t,e,i,n){var a=t.coordinateSystem,r=t.name,o=t.getData(),l=this.markerGroupMap,h=l.get(r)||l.set(r,{group:new xx});this.group.add(h.group),h.__keep=!0;var u=Qg(a,t,e);e.setData(u),u.each(function(e){u.setItemLayout(e,p(HD,function(i){return Jg(u,e,i,t,n)})),u.setItemVisual(e,{color:o.getVisual("color")})}),u.diff(h.__data).add(function(t){var e=new Gw({shape:{points:u.getItemLayout(t)}});u.setItemGraphicEl(t,e),h.group.add(e)}).update(function(t,i){var n=h.__data.getItemGraphicEl(i);Mr(n,{shape:{points:u.getItemLayout(t)}},e,t),h.group.add(n),u.setItemGraphicEl(t,n)}).remove(function(t){var e=h.__data.getItemGraphicEl(t);h.group.remove(e)}).execute(),u.eachItemGraphicEl(function(t,i){var n=u.getItemModel(i),a=n.getModel("label"),r=n.getModel("emphasis.label"),o=u.getItemVisual(i,"color");t.useStyle(s(n.getModel("itemStyle").getItemStyle(),{fill:We(o,.4),stroke:o})),t.hoverStyle=n.getModel("emphasis.itemStyle").getItemStyle(),dr(t.style,t.hoverStyle,a,r,{labelFetcher:e,labelDataIndex:i,defaultText:u.getName(i)||"",isRectText:!0,autoColor:o}),cr(t,{}),t.dataModel=e}),h.__data=u,h.group.silent=e.get("silent")||t.get("silent")}}),Sl(function(t){t.markArea=t.markArea||{}});var ZD=function(t){var e=t&&t.timeline;_(e)||(e=e?[e]:[]),f(e,function(t){t&&tv(t)})};Cb.registerSubTypeDefaulter("timeline",function(){return"slider"}),Al({type:"timelineChange",event:"timelineChanged",update:"prepareAndUpdate"},function(t,e){var i=e.getComponent("timeline");return i&&null!=t.currentIndex&&(i.setCurrentIndex(t.currentIndex),!i.get("loop",!0)&&i.isIndexMax()&&i.setPlayState(!1)),e.resetOption("timeline"),s({currentIndex:i.option.currentIndex},t)}),Al({type:"timelinePlayChange",event:"timelinePlayChanged",update:"update"},function(t,e){var i=e.getComponent("timeline");i&&null!=t.playState&&i.setPlayState(t.playState)});var jD=Cb.extend({type:"timeline",layoutMode:"box",defaultOption:{zlevel:0,z:4,show:!0,axisType:"time",realtime:!0,left:"20%",top:null,right:"20%",bottom:0,width:null,height:40,padding:5,controlPosition:"left",autoPlay:!1,rewind:!1,loop:!0,playInterval:2e3,currentIndex:0,itemStyle:{},label:{color:"#000"},data:[]},init:function(t,e,i){this._data,this._names,this.mergeDefaultAndTheme(t,i),this._initData()},mergeOption:function(){jD.superApply(this,"mergeOption",arguments),this._initData()},setCurrentIndex:function(t){null==t&&(t=this.option.currentIndex);var e=this._data.count();this.option.loop?t=(t%e+e)%e:(t>=e&&(t=e-1),0>t&&(t=0)),this.option.currentIndex=t},getCurrentIndex:function(){return this.option.currentIndex},isIndexMax:function(){return this.getCurrentIndex()>=this._data.count()-1},setPlayState:function(t){this.option.autoPlay=!!t},getPlayState:function(){return!!this.option.autoPlay},_initData:function(){var t=this.option,e=t.data||[],i=t.axisType,a=this._names=[];if("category"===i){var r=[];f(e,function(t,e){var i,o=En(t);M(t)?(i=n(t),i.value=e):i=e,r.push(i),b(o)||null!=o&&!isNaN(o)||(o=""),a.push(o+"")}),e=r}var o={category:"ordinal",time:"time"}[i]||"number",s=this._data=new kS([{name:"value",type:o}],this);s.initData(e,a)},getData:function(){return this._data},getCategories:function(){return"category"===this.get("axisType")?this._names.slice():void 0}}),XD=jD.extend({type:"timeline.slider",defaultOption:{backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",borderWidth:0,orient:"horizontal",inverse:!1,tooltip:{trigger:"item"},symbol:"emptyCircle",symbolSize:10,lineStyle:{show:!0,width:2,color:"#304654"},label:{position:"auto",show:!0,interval:"auto",rotate:0,color:"#304654"},itemStyle:{color:"#304654",borderWidth:1},checkpointStyle:{symbol:"circle",symbolSize:13,color:"#c23531",borderWidth:5,borderColor:"rgba(194,53,49, 0.5)",animation:!0,animationDuration:300,animationEasing:"quinticInOut"},controlStyle:{show:!0,showPlayBtn:!0,showPrevBtn:!0,showNextBtn:!0,itemSize:22,itemGap:12,position:"left",playIcon:"path://M31.6,53C17.5,53,6,41.5,6,27.4S17.5,1.8,31.6,1.8C45.7,1.8,57.2,13.3,57.2,27.4S45.7,53,31.6,53z M31.6,3.3 C18.4,3.3,7.5,14.1,7.5,27.4c0,13.3,10.8,24.1,24.1,24.1C44.9,51.5,55.7,40.7,55.7,27.4C55.7,14.1,44.9,3.3,31.6,3.3z M24.9,21.3 c0-2.2,1.6-3.1,3.5-2l10.5,6.1c1.899,1.1,1.899,2.9,0,4l-10.5,6.1c-1.9,1.1-3.5,0.2-3.5-2V21.3z",stopIcon:"path://M30.9,53.2C16.8,53.2,5.3,41.7,5.3,27.6S16.8,2,30.9,2C45,2,56.4,13.5,56.4,27.6S45,53.2,30.9,53.2z M30.9,3.5C17.6,3.5,6.8,14.4,6.8,27.6c0,13.3,10.8,24.1,24.101,24.1C44.2,51.7,55,40.9,55,27.6C54.9,14.4,44.1,3.5,30.9,3.5z M36.9,35.8c0,0.601-0.4,1-0.9,1h-1.3c-0.5,0-0.9-0.399-0.9-1V19.5c0-0.6,0.4-1,0.9-1H36c0.5,0,0.9,0.4,0.9,1V35.8z M27.8,35.8 c0,0.601-0.4,1-0.9,1h-1.3c-0.5,0-0.9-0.399-0.9-1V19.5c0-0.6,0.4-1,0.9-1H27c0.5,0,0.9,0.4,0.9,1L27.8,35.8L27.8,35.8z",nextIcon:"path://M18.6,50.8l22.5-22.5c0.2-0.2,0.3-0.4,0.3-0.7c0-0.3-0.1-0.5-0.3-0.7L18.7,4.4c-0.1-0.1-0.2-0.3-0.2-0.5 c0-0.4,0.3-0.8,0.8-0.8c0.2,0,0.5,0.1,0.6,0.3l23.5,23.5l0,0c0.2,0.2,0.3,0.4,0.3,0.7c0,0.3-0.1,0.5-0.3,0.7l-0.1,0.1L19.7,52 c-0.1,0.1-0.3,0.2-0.5,0.2c-0.4,0-0.8-0.3-0.8-0.8C18.4,51.2,18.5,51,18.6,50.8z",prevIcon:"path://M43,52.8L20.4,30.3c-0.2-0.2-0.3-0.4-0.3-0.7c0-0.3,0.1-0.5,0.3-0.7L42.9,6.4c0.1-0.1,0.2-0.3,0.2-0.5 c0-0.4-0.3-0.8-0.8-0.8c-0.2,0-0.5,0.1-0.6,0.3L18.3,28.8l0,0c-0.2,0.2-0.3,0.4-0.3,0.7c0,0.3,0.1,0.5,0.3,0.7l0.1,0.1L41.9,54 c0.1,0.1,0.3,0.2,0.5,0.2c0.4,0,0.8-0.3,0.8-0.8C43.2,53.2,43.1,53,43,52.8z",color:"#304654",borderColor:"#304654",borderWidth:1},emphasis:{label:{show:!0,color:"#c23531"},itemStyle:{color:"#c23531"},controlStyle:{color:"#c23531",borderColor:"#c23531",borderWidth:2}},data:[]}});c(XD,uM);var UD=pM.extend({type:"timeline"}),YD=function(t,e,i,n){wI.call(this,t,e,i),this.type=n||"value",this._autoLabelInterval,this.model=null};YD.prototype={constructor:YD,getLabelInterval:function(){var t=this.model,e=t.getModel("label"),i=e.get("interval");if(null!=i&&"auto"!=i)return i;var i=this._autoLabelInterval;return i||(i=this._autoLabelInterval=Lh(p(this.scale.getTicks(),this.dataToCoord,this),kh(this,e.get("formatter")),e.getFont(),"horizontal"===t.get("orient")?0:90,e.get("rotate"))),i},isLabelIgnored:function(t){if("category"===this.type){var e=this.getLabelInterval();return"function"==typeof e&&!e(t,this.scale.getLabel(t))||t%(e+1)}}},u(YD,wI);var qD=y,$D=f,KD=Math.PI;UD.extend({type:"timeline.slider",init:function(t,e){this.api=e,this._axis,this._viewRect,this._timer,this._currentPointer,this._mainGroup,this._labelGroup},render:function(t,e,i){if(this.model=t,this.api=i,this.ecModel=e,this.group.removeAll(),t.get("show",!0)){var n=this._layout(t,i),a=this._createGroup("mainGroup"),r=this._createGroup("labelGroup"),o=this._axis=this._createAxis(n,t);t.formatTooltip=function(t){return no(o.scale.getLabel(t))},$D(["AxisLine","AxisTick","Control","CurrentPointer"],function(e){this["_render"+e](n,a,o,t)},this),this._renderAxisLabel(n,r,o,t),this._position(n,t)}this._doPlayStop()},remove:function(){this._clearTimer(),this.group.removeAll()},dispose:function(){this._clearTimer()},_layout:function(t,e){var i=t.get("label.position"),n=t.get("orient"),a=nv(t,e);null==i||"auto"===i?i="horizontal"===n?a.y+a.height/2<e.getHeight()/2?"-":"+":a.x+a.width/2<e.getWidth()/2?"+":"-":isNaN(i)&&(i={horizontal:{top:"-",bottom:"+"},vertical:{left:"-",right:"+"}}[n][i]);var r={horizontal:"center",vertical:i>=0||"+"===i?"left":"right"},o={horizontal:i>=0||"+"===i?"top":"bottom",vertical:"middle"},s={horizontal:0,vertical:KD/2},l="vertical"===n?a.height:a.width,h=t.getModel("controlStyle"),u=h.get("show"),c=u?h.get("itemSize"):0,d=u?h.get("itemGap"):0,f=c+d,p=t.get("label.rotate")||0;p=p*KD/180;var g,v,m,y,x=h.get("position",!0),u=h.get("show",!0),_=u&&h.get("showPlayBtn",!0),w=u&&h.get("showPrevBtn",!0),b=u&&h.get("showNextBtn",!0),M=0,S=l;return"left"===x||"bottom"===x?(_&&(g=[0,0],M+=f),w&&(v=[M,0],M+=f),b&&(m=[S-c,0],S-=f)):(_&&(g=[S-c,0],S-=f),w&&(v=[0,0],M+=f),b&&(m=[S-c,0],S-=f)),y=[M,S],t.get("inverse")&&y.reverse(),{viewRect:a,mainLength:l,orient:n,rotation:s[n],labelRotation:p,labelPosOpt:i,labelAlign:t.get("label.align")||r[n],labelBaseline:t.get("label.verticalAlign")||t.get("label.baseline")||o[n],playPosition:g,prevBtnPosition:v,nextBtnPosition:m,axisExtent:y,controlSize:c,controlGap:d}},_position:function(t){function e(t){var e=t.position;t.origin=[u[0][0]-e[0],u[1][0]-e[1]]}function i(t){return[[t.x,t.x+t.width],[t.y,t.y+t.height]]}function n(t,e,i,n,a){t[n]+=i[n][a]-e[n][a]}var a=this._mainGroup,r=this._labelGroup,o=t.viewRect;if("vertical"===t.orient){var s=fe(),l=o.x,h=o.y+o.height;me(s,s,[-l,-h]),ye(s,s,-KD/2),me(s,s,[l,h]),o=o.clone(),o.applyTransform(s)}var u=i(o),c=i(a.getBoundingRect()),d=i(r.getBoundingRect()),f=a.position,p=r.position;p[0]=f[0]=u[0][0];var g=t.labelPosOpt;if(isNaN(g)){var v="+"===g?0:1;n(f,c,u,1,v),n(p,d,u,1,1-v)}else{var v=g>=0?0:1;n(f,c,u,1,v),p[1]=f[1]+g}a.attr("position",f),r.attr("position",p),a.rotation=r.rotation=t.rotation,e(a),e(r)},_createAxis:function(t,e){var i=e.getData(),n=e.get("axisType"),a=Ch(e,n),r=i.getDataExtent("value");a.setExtent(r[0],r[1]),this._customizeScale(a,i),a.niceTicks();var o=new YD("value",a,t.axisExtent,n);return o.model=e,o},_customizeScale:function(t,e){t.getTicks=function(){return e.mapArray(["value"],function(t){return t})},t.getTicksLabels=function(){return p(this.getTicks(),t.getLabel,t)}},_createGroup:function(t){var e=this["_"+t]=new xx;return this.group.add(e),e},_renderAxisLine:function(t,e,i,n){var a=i.getExtent();n.get("lineStyle.show")&&e.add(new Hw({shape:{x1:a[0],y1:0,x2:a[1],y2:0},style:o({lineCap:"round"},n.getModel("lineStyle").getLineStyle()),silent:!0,z2:1}))},_renderAxisTick:function(t,e,i,n){var a=n.getData(),r=i.scale.getTicks();$D(r,function(t,r){var o=i.dataToCoord(t),s=a.getItemModel(r),l=s.getModel("itemStyle"),h=s.getModel("emphasis.itemStyle"),u={position:[o,0],onclick:qD(this._changeTimeline,this,r)},c=rv(s,l,e,u);cr(c,h.getItemStyle()),s.get("tooltip")?(c.dataIndex=r,c.dataModel=n):c.dataIndex=c.dataModel=null},this)},_renderAxisLabel:function(t,e,i,n){var a=n.getModel("label");if(a.get("show")){var r=n.getData(),o=i.scale.getTicks(),s=kh(i,a.get("formatter")),l=i.getLabelInterval();$D(o,function(n,a){if(!i.isLabelIgnored(a,l)){var o=r.getItemModel(a),h=o.getModel("label"),u=o.getModel("emphasis.label"),c=i.dataToCoord(n),d=new Pw({position:[c,0],rotation:t.labelRotation-t.rotation,onclick:qD(this._changeTimeline,this,a),silent:!1});fr(d.style,h,{text:s[a],textAlign:t.labelAlign,textVerticalAlign:t.labelBaseline}),e.add(d),cr(d,fr({},u))}},this)}},_renderControl:function(t,e,i,n){function a(t,i,a,u){if(t){var c={position:t,origin:[r/2,0],rotation:u?-o:0,rectHover:!0,style:s,onclick:a},d=av(n,i,h,c);e.add(d),cr(d,l)}}var r=t.controlSize,o=t.rotation,s=n.getModel("controlStyle").getItemStyle(),l=n.getModel("emphasis.controlStyle").getItemStyle(),h=[0,-r/2,r,r],u=n.getPlayState(),c=n.get("inverse",!0);a(t.nextBtnPosition,"controlStyle.nextIcon",qD(this._changeTimeline,this,c?"-":"+")),a(t.prevBtnPosition,"controlStyle.prevIcon",qD(this._changeTimeline,this,c?"+":"-")),a(t.playPosition,"controlStyle."+(u?"stopIcon":"playIcon"),qD(this._handlePlayClick,this,!u),!0)},_renderCurrentPointer:function(t,e,i,n){var a=n.getData(),r=n.getCurrentIndex(),o=a.getItemModel(r).getModel("checkpointStyle"),s=this,l={onCreate:function(t){t.draggable=!0,t.drift=qD(s._handlePointerDrag,s),t.ondragend=qD(s._handlePointerDragend,s),ov(t,r,i,n,!0)},onUpdate:function(t){ov(t,r,i,n)}};this._currentPointer=rv(o,o,this._mainGroup,{},this._currentPointer,l)},_handlePlayClick:function(t){this._clearTimer(),this.api.dispatchAction({type:"timelinePlayChange",playState:t,from:this.uid})},_handlePointerDrag:function(t,e,i){this._clearTimer(),this._pointerChangeTimeline([i.offsetX,i.offsetY])},_handlePointerDragend:function(t){this._pointerChangeTimeline([t.offsetX,t.offsetY],!0)},_pointerChangeTimeline:function(t,e){var i=this._toAxisCoord(t)[0],n=this._axis,a=Wr(n.getExtent().slice());i>a[1]&&(i=a[1]),i<a[0]&&(i=a[0]),this._currentPointer.position[0]=i,this._currentPointer.dirty();var r=this._findNearestTick(i),o=this.model;(e||r!==o.getCurrentIndex()&&o.get("realtime"))&&this._changeTimeline(r)},_doPlayStop:function(){function t(){var t=this.model;this._changeTimeline(t.getCurrentIndex()+(t.get("rewind",!0)?-1:1))}this._clearTimer(),this.model.getPlayState()&&(this._timer=setTimeout(qD(t,this),this.model.get("playInterval")))},_toAxisCoord:function(t){var e=this._mainGroup.getLocalTransform();return Tr(t,e,!0)},_findNearestTick:function(t){var e,i=this.model.getData(),n=1/0,a=this._axis;return i.each(["value"],function(i,r){var o=a.dataToCoord(i),s=Math.abs(o-t);n>s&&(n=s,e=r)}),e},_clearTimer:function(){this._timer&&(clearTimeout(this._timer),this._timer=null)},_changeTimeline:function(t){var e=this.model.getCurrentIndex();"+"===t?t=e+1:"-"===t&&(t=e-1),this.api.dispatchAction({type:"timelineChange",currentIndex:t,from:this.uid})}}),Sl(ZD),Cb.registerSubTypeDefaulter("dataZoom",function(){return"slider"});var JD=["x","y","z","radius","angle","single"],QD=["cartesian2d","polar","singleAxis"],tL=lv(JD,["axisIndex","axis","index","id"]),eL=f,iL=Wr,nL=function(t,e,i,n){this._dimName=t,this._axisIndex=e,this._valueWindow,this._percentWindow,this._dataExtent,this._minMaxSpan,this.ecModel=n,this._dataZoomModel=i,this.hasSeriesStacked};nL.prototype={constructor:nL,hostedBy:function(t){return this._dataZoomModel===t},getDataValueWindow:function(){return this._valueWindow.slice()},getDataPercentWindow:function(){return this._percentWindow.slice()},getTargetSeriesModels:function(){var t=[],e=this.ecModel;return e.eachSeries(function(i){if(sv(i.get("coordinateSystem"))){var n=this._dimName,a=e.queryComponents({mainType:n+"Axis",index:i.get(n+"AxisIndex"),id:i.get(n+"AxisId")})[0];this._axisIndex===(a&&a.componentIndex)&&t.push(i)}},this),t},getAxisModel:function(){return this.ecModel.getComponent(this._dimName+"Axis",this._axisIndex)},getOtherAxisModel:function(){var t,e,i=this._dimName,n=this.ecModel,a=this.getAxisModel(),r="x"===i||"y"===i;r?(e="gridIndex",t="x"===i?"y":"x"):(e="polarIndex",t="angle"===i?"radius":"angle");var o;return n.eachComponent(t+"Axis",function(t){(t.get(e)||0)===(a.get(e)||0)&&(o=t)}),o},getMinMaxSpan:function(){return n(this._minMaxSpan)},calculateDataWindow:function(t){var e=this._dataExtent,i=this.getAxisModel(),n=i.axis.scale,a=this._dataZoomModel.getRangePropMode(),r=[0,100],o=[t.start,t.end],s=[];return eL(["startValue","endValue"],function(e){s.push(null!=t[e]?n.parse(t[e]):null)}),eL([0,1],function(t){var i=s[t],l=o[t];"percent"===a[t]?(null==l&&(l=r[t]),i=n.parse(Vr(l,r,e,!0))):l=Vr(i,e,r,!0),s[t]=i,o[t]=l}),{valueWindow:iL(s),percentWindow:iL(o)}},reset:function(t){if(t===this._dataZoomModel){var e=this.getTargetSeriesModels();this._dataExtent=uv(this,this._dimName,e),this.hasSeriesStacked=!1,eL(e,function(t){var e=t.getData(),i=e.mapDimension(this._dimName);e.isStacked(i)&&(this.hasSeriesStacked=!0)},this);var i=this.calculateDataWindow(t.option);this._valueWindow=i.valueWindow,this._percentWindow=i.percentWindow,fv(this),dv(this)}},restore:function(t){t===this._dataZoomModel&&(this._valueWindow=this._percentWindow=null,dv(this,!0))},filterData:function(t){function e(t){return t>=r[0]&&t<=r[1]}if(t===this._dataZoomModel){var i=this._dimName,n=this.getTargetSeriesModels(),a=t.get("filterMode"),r=this._valueWindow;if("none"!==a){var o=this.getOtherAxisModel();t.get("$fromToolbox")&&o&&o.hasSeriesStacked&&(a="empty"),eL(n,function(t){var n=t.getData(),o=n.mapDimension(i,!0);"weakFilter"===a?n.filterSelf(function(t){for(var e,i,a,s=0;s<o.length;s++){var l=n.get(o[s],t),h=!isNaN(l),u=l<r[0],c=l>r[1];if(h&&!u&&!c)return!0;h&&(a=!0),u&&(e=!0),c&&(i=!0)}return a&&e&&i}):eL(o,function(i){if("empty"===a)t.setData(n.map(i,function(t){return e(t)?t:0/0}));else{var o={};o[i]=r,n.selectRange(o)}}),eL(o,function(t){n.setApproximateExtent(r,t)})})}}}};var aL=f,rL=tL,oL=zl({type:"dataZoom",dependencies:["xAxis","yAxis","zAxis","radiusAxis","angleAxis","singleAxis","series"],defaultOption:{zlevel:0,z:4,orient:null,xAxisIndex:null,yAxisIndex:null,filterMode:"filter",throttle:null,start:0,end:100,startValue:null,endValue:null,minSpan:null,maxSpan:null,minValueSpan:null,maxValueSpan:null,rangeMode:null},init:function(t,e,i){this._dataIntervalByAxis={},this._dataInfo={},this._axisProxies={},this.textStyleModel,this._autoThrottle=!0,this._rangePropMode=["percent","percent"];var n=pv(t);this.mergeDefaultAndTheme(t,i),this.doInit(n)},mergeOption:function(t){var e=pv(t);a(this.option,t,!0),this.doInit(e)},doInit:function(t){var e=this.option;vy.canvasSupported||(e.realtime=!1),this._setDefaultThrottle(t),gv(this,t),aL([["start","startValue"],["end","endValue"]],function(t,i){"value"===this._rangePropMode[i]&&(e[t[0]]=null)},this),this.textStyleModel=this.getModel("textStyle"),this._resetTarget(),this._giveAxisProxies()},_giveAxisProxies:function(){var t=this._axisProxies;this.eachTargetAxis(function(e,i,n,a){var r=this.dependentModels[e.axis][i],o=r.__dzAxisProxy||(r.__dzAxisProxy=new nL(e.name,i,this,a));t[e.name+"_"+i]=o},this)},_resetTarget:function(){var t=this.option,e=this._judgeAutoMode();rL(function(e){var i=e.axisIndex;t[i]=On(t[i])},this),"axisIndex"===e?this._autoSetAxisIndex():"orient"===e&&this._autoSetOrient()},_judgeAutoMode:function(){var t=this.option,e=!1;rL(function(i){null!=t[i.axisIndex]&&(e=!0)},this);var i=t.orient;return null==i&&e?"orient":e?void 0:(null==i&&(t.orient="horizontal"),"axisIndex")},_autoSetAxisIndex:function(){var t=!0,e=this.get("orient",!0),i=this.option,n=this.dependentModels;if(t){var a="vertical"===e?"y":"x";n[a+"Axis"].length?(i[a+"AxisIndex"]=[0],t=!1):aL(n.singleAxis,function(n){t&&n.get("orient",!0)===e&&(i.singleAxisIndex=[n.componentIndex],t=!1)})}t&&rL(function(e){if(t){var n=[],a=this.dependentModels[e.axis];if(a.length&&!n.length)for(var r=0,o=a.length;o>r;r++)"category"===a[r].get("type")&&n.push(r);i[e.axisIndex]=n,n.length&&(t=!1)}},this),t&&this.ecModel.eachSeries(function(t){this._isSeriesHasAllAxesTypeOf(t,"value")&&rL(function(e){var n=i[e.axisIndex],a=t.get(e.axisIndex),r=t.get(e.axisId),o=t.ecModel.queryComponents({mainType:e.axis,index:a,id:r})[0];a=o.componentIndex,h(n,a)<0&&n.push(a)})},this)},_autoSetOrient:function(){var t;this.eachTargetAxis(function(e){!t&&(t=e.name)},this),this.option.orient="y"===t?"vertical":"horizontal"},_isSeriesHasAllAxesTypeOf:function(t,e){var i=!0;return rL(function(n){var a=t.get(n.axisIndex),r=this.dependentModels[n.axis][a];r&&r.get("type")===e||(i=!1)},this),i},_setDefaultThrottle:function(t){if(t.hasOwnProperty("throttle")&&(this._autoThrottle=!1),this._autoThrottle){var e=this.ecModel.option;this.option.throttle=e.animation&&e.animationDurationUpdate>0?100:20}},getFirstTargetAxisModel:function(){var t;return rL(function(e){if(null==t){var i=this.get(e.axisIndex);i.length&&(t=this.dependentModels[e.axis][i[0]])}},this),t},eachTargetAxis:function(t,e){var i=this.ecModel;rL(function(n){aL(this.get(n.axisIndex),function(a){t.call(e,n,a,this,i)},this)},this)},getAxisProxy:function(t,e){return this._axisProxies[t+"_"+e]},getAxisModel:function(t,e){var i=this.getAxisProxy(t,e);return i&&i.getAxisModel()},setRawRange:function(t,e){var i=this.option;aL([["start","startValue"],["end","endValue"]],function(e){(null!=t[e[0]]||null!=t[e[1]])&&(i[e[0]]=t[e[0]],i[e[1]]=t[e[1]])},this),!e&&gv(this,t)},getPercentRange:function(){var t=this.findRepresentativeAxisProxy();return t?t.getDataPercentWindow():void 0},getValueRange:function(t,e){if(null!=t||null!=e)return this.getAxisProxy(t,e).getDataValueWindow();var i=this.findRepresentativeAxisProxy();return i?i.getDataValueWindow():void 0},findRepresentativeAxisProxy:function(t){if(t)return t.__dzAxisProxy;var e=this._axisProxies;for(var i in e)if(e.hasOwnProperty(i)&&e[i].hostedBy(this))return e[i];for(var i in e)if(e.hasOwnProperty(i)&&!e[i].hostedBy(this))return e[i]},getRangePropMode:function(){return this._rangePropMode.slice()}}),sL=pM.extend({type:"dataZoom",render:function(t,e,i){this.dataZoomModel=t,this.ecModel=e,this.api=i},getTargetCoordInfo:function(){function t(t,e,i,n){for(var a,r=0;r<i.length;r++)if(i[r].model===t){a=i[r];break}a||i.push(a={model:t,axisModels:[],coordIndex:n}),a.axisModels.push(e)}var e=this.dataZoomModel,i=this.ecModel,n={};return e.eachTargetAxis(function(e,a){var r=i.getComponent(e.axis,a);if(r){var o=r.getCoordSysModel();o&&t(o,r,n[o.mainType]||(n[o.mainType]=[]),o.componentIndex)}},this),n}}),lL=(oL.extend({type:"dataZoom.slider",layoutMode:"box",defaultOption:{show:!0,right:"ph",top:"ph",width:"ph",height:"ph",left:null,bottom:null,backgroundColor:"rgba(47,69,84,0)",dataBackground:{lineStyle:{color:"#2f4554",width:.5,opacity:.3},areaStyle:{color:"rgba(47,69,84,0.3)",opacity:.3}},borderColor:"#ddd",fillerColor:"rgba(167,183,204,0.4)",handleIcon:"M8.2,13.6V3.9H6.3v9.7H3.1v14.9h3.3v9.7h1.8v-9.7h3.3V13.6H8.2z M9.7,24.4H4.8v-1.4h4.9V24.4z M9.7,19.1H4.8v-1.4h4.9V19.1z",handleSize:"100%",handleStyle:{color:"#a7b7cc"},labelPrecision:null,labelFormatter:null,showDetail:!0,showDataShadow:"auto",realtime:!0,zoomLock:!1,textStyle:{color:"#333"}}}),Ww),hL=Vr,uL=Wr,cL=y,dL=f,fL=7,pL=1,gL=30,vL="horizontal",mL="vertical",yL=5,xL=["line","bar","candlestick","scatter"],_L=sL.extend({type:"dataZoom.slider",init:function(t,e){this._displayables={},this._orient,this._range,this._handleEnds,this._size,this._handleWidth,this._handleHeight,this._location,this._dragging,this._dataShadowInfo,this.api=e},render:function(t,e,i,n){return _L.superApply(this,"render",arguments),ks(this,"_dispatchZoomAction",this.dataZoomModel.get("throttle"),"fixRate"),this._orient=t.get("orient"),this.dataZoomModel.get("show")===!1?void this.group.removeAll():(n&&"dataZoom"===n.type&&n.from===this.uid||this._buildView(),void this._updateView())},remove:function(){_L.superApply(this,"remove",arguments),Ps(this,"_dispatchZoomAction")},dispose:function(){_L.superApply(this,"dispose",arguments),Ps(this,"_dispatchZoomAction")},_buildView:function(){var t=this.group;t.removeAll(),this._resetLocation(),this._resetInterval();var e=this._displayables.barGroup=new xx;this._renderBackground(),this._renderHandle(),this._renderDataShadow(),t.add(e),this._positionGroup()},_resetLocation:function(){var t=this.dataZoomModel,e=this.api,i=this._findCoordRect(),n={width:e.getWidth(),height:e.getHeight()},a=this._orient===vL?{right:n.width-i.x-i.width,top:n.height-gL-fL,width:i.width,height:gL}:{right:fL,top:i.y,width:gL,height:i.height},r=go(t.option);f(["right","top","width","height"],function(t){"ph"===r[t]&&(r[t]=a[t])});var o=uo(r,n,t.padding);this._location={x:o.x,y:o.y},this._size=[o.width,o.height],this._orient===mL&&this._size.reverse()},_positionGroup:function(){var t=this.group,e=this._location,i=this._orient,n=this.dataZoomModel.getFirstTargetAxisModel(),a=n&&n.get("inverse"),r=this._displayables.barGroup,o=(this._dataShadowInfo||{}).otherAxisInverse;r.attr(i!==vL||a?i===vL&&a?{scale:o?[-1,1]:[-1,-1]}:i!==mL||a?{scale:o?[-1,-1]:[-1,1],rotation:Math.PI/2}:{scale:o?[1,-1]:[1,1],rotation:Math.PI/2}:{scale:o?[1,1]:[1,-1]});var s=t.getBoundingRect([r]);t.attr("position",[e.x-s.x,e.y-s.y])},_getViewExtent:function(){return[0,this._size[0]]},_renderBackground:function(){var t=this.dataZoomModel,e=this._size,i=this._displayables.barGroup;i.add(new lL({silent:!0,shape:{x:0,y:0,width:e[0],height:e[1]},style:{fill:t.get("backgroundColor")},z2:-40})),i.add(new lL({shape:{x:0,y:0,width:e[0],height:e[1]},style:{fill:"transparent"},z2:0,onclick:y(this._onClickPanelClick,this)}))},_renderDataShadow:function(){var t=this._dataShadowInfo=this._prepareDataShadowInfo();if(t){var e=this._size,i=t.series,n=i.getRawData(),a=i.getShadowDim?i.getShadowDim():t.otherDim;if(null!=a){var r=n.getDataExtent(a),o=.3*(r[1]-r[0]);r=[r[0]-o,r[1]+o];var l,h=[0,e[1]],u=[0,e[0]],c=[[e[0],0],[0,0]],d=[],f=u[1]/(n.count()-1),p=0,g=Math.round(n.count()/e[0]);n.each([a],function(t,e){if(g>0&&e%g)return void(p+=f);var i=null==t||isNaN(t)||""===t,n=i?0:hL(t,r,h,!0);i&&!l&&e?(c.push([c[c.length-1][0],0]),d.push([d[d.length-1][0],0])):!i&&l&&(c.push([p,0]),d.push([p,0])),c.push([p,n]),d.push([p,n]),p+=f,l=i});var v=this.dataZoomModel;this._displayables.barGroup.add(new Gw({shape:{points:c},style:s({fill:v.get("dataBackgroundColor")},v.getModel("dataBackground.areaStyle").getAreaStyle()),silent:!0,z2:-20})),this._displayables.barGroup.add(new Fw({shape:{points:d},style:v.getModel("dataBackground.lineStyle").getLineStyle(),silent:!0,z2:-19}))}}},_prepareDataShadowInfo:function(){var t=this.dataZoomModel,e=t.get("showDataShadow");if(e!==!1){var i,n=this.ecModel;return t.eachTargetAxis(function(a,r){var o=t.getAxisProxy(a.name,r).getTargetSeriesModels();f(o,function(t){if(!(i||e!==!0&&h(xL,t.get("type"))<0)){var o,s=n.getComponent(a.axis,r).axis,l=vv(a.name),u=t.coordinateSystem;null!=l&&u.getOtherAxis&&(o=u.getOtherAxis(s).inverse),l=t.getData().mapDimension(l),i={thisAxis:s,series:t,thisDim:a.name,otherDim:l,otherAxisInverse:o}}},this)},this),i}},_renderHandle:function(){var t=this._displayables,e=t.handles=[],i=t.handleLabels=[],n=this._displayables.barGroup,a=this._size,r=this.dataZoomModel;n.add(t.filler=new lL({draggable:!0,cursor:mv(this._orient),drift:cL(this._onDragMove,this,"all"),onmousemove:function(t){t_(t.event)
-},ondragstart:cL(this._showDataInfo,this,!0),ondragend:cL(this._onDragEnd,this),onmouseover:cL(this._showDataInfo,this,!0),onmouseout:cL(this._showDataInfo,this,!1),style:{fill:r.get("fillerColor"),textPosition:"inside"}})),n.add(new lL(Ka({silent:!0,shape:{x:0,y:0,width:a[0],height:a[1]},style:{stroke:r.get("dataBackgroundColor")||r.get("borderColor"),lineWidth:pL,fill:"rgba(0,0,0,0)"}}))),dL([0,1],function(t){var a=kr(r.get("handleIcon"),{cursor:mv(this._orient),draggable:!0,drift:cL(this._onDragMove,this,t),onmousemove:function(t){t_(t.event)},ondragend:cL(this._onDragEnd,this),onmouseover:cL(this._showDataInfo,this,!0),onmouseout:cL(this._showDataInfo,this,!1)},{x:-1,y:0,width:2,height:2}),o=a.getBoundingRect();this._handleHeight=Gr(r.get("handleSize"),this._size[1]),this._handleWidth=o.width/o.height*this._handleHeight,a.setStyle(r.getModel("handleStyle").getItemStyle());var s=r.get("handleColor");null!=s&&(a.style.fill=s),n.add(e[t]=a);var l=r.textStyleModel;this.group.add(i[t]=new Pw({silent:!0,invisible:!0,style:{x:0,y:0,text:"",textVerticalAlign:"middle",textAlign:"center",textFill:l.getTextColor(),textFont:l.getFont()},z2:10}))},this)},_resetInterval:function(){var t=this._range=this.dataZoomModel.getPercentRange(),e=this._getViewExtent();this._handleEnds=[hL(t[0],[0,100],e,!0),hL(t[1],[0,100],e,!0)]},_updateInterval:function(t,e){var i=this.dataZoomModel,n=this._handleEnds,a=this._getViewExtent(),r=i.findRepresentativeAxisProxy().getMinMaxSpan(),o=[0,100];SA(e,n,a,i.get("zoomLock")?"all":t,null!=r.minSpan?hL(r.minSpan,o,a,!0):null,null!=r.maxSpan?hL(r.maxSpan,o,a,!0):null),this._range=uL([hL(n[0],a,o,!0),hL(n[1],a,o,!0)])},_updateView:function(t){var e=this._displayables,i=this._handleEnds,n=uL(i.slice()),a=this._size;dL([0,1],function(t){var n=e.handles[t],r=this._handleHeight;n.attr({scale:[r/2,r/2],position:[i[t],a[1]/2-r/2]})},this),e.filler.setShape({x:n[0],y:0,width:n[1]-n[0],height:a[1]}),this._updateDataInfo(t)},_updateDataInfo:function(t){function e(t){var e=Ir(n.handles[t].parent,this.group),i=Ar(0===t?"right":"left",e),s=this._handleWidth/2+yL,l=Tr([c[t]+(0===t?-s:s),this._size[1]/2],e);a[t].setStyle({x:l[0],y:l[1],textVerticalAlign:r===vL?"middle":i,textAlign:r===vL?i:"center",text:o[t]})}var i=this.dataZoomModel,n=this._displayables,a=n.handleLabels,r=this._orient,o=["",""];if(i.get("showDetail")){var s=i.findRepresentativeAxisProxy();if(s){var l=s.getAxisModel().axis,h=this._range,u=t?s.calculateDataWindow({start:h[0],end:h[1]}).valueWindow:s.getDataValueWindow();o=[this._formatLabel(u[0],l),this._formatLabel(u[1],l)]}}var c=uL(this._handleEnds.slice());e.call(this,0),e.call(this,1)},_formatLabel:function(t,e){var i=this.dataZoomModel,n=i.get("labelFormatter"),a=i.get("labelPrecision");(null==a||"auto"===a)&&(a=e.getPixelPrecision());var r=null==t||isNaN(t)?"":"category"===e.type||"time"===e.type?e.scale.getLabel(Math.round(t)):t.toFixed(Math.min(a,20));return w(n)?n(t,r):b(n)?n.replace("{value}",r):r},_showDataInfo:function(t){t=this._dragging||t;var e=this._displayables.handleLabels;e[0].attr("invisible",!t),e[1].attr("invisible",!t)},_onDragMove:function(t,e,i){this._dragging=!0;var n=this._displayables.barGroup.getLocalTransform(),a=Tr([e,i],n,!0);this._updateInterval(t,a[0]);var r=this.dataZoomModel.get("realtime");this._updateView(!r),r&&this._dispatchZoomAction()},_onDragEnd:function(){this._dragging=!1,this._showDataInfo(!1);var t=this.dataZoomModel.get("realtime");!t&&this._dispatchZoomAction()},_onClickPanelClick:function(t){var e=this._size,i=this._displayables.barGroup.transformCoordToLocal(t.offsetX,t.offsetY);if(!(i[0]<0||i[0]>e[0]||i[1]<0||i[1]>e[1])){var n=this._handleEnds,a=(n[0]+n[1])/2;this._updateInterval("all",i[0]-a),this._updateView(),this._dispatchZoomAction()}},_dispatchZoomAction:function(){var t=this._range;this.api.dispatchAction({type:"dataZoom",from:this.uid,dataZoomId:this.dataZoomModel.id,start:t[0],end:t[1]})},_findCoordRect:function(){var t;if(dL(this.getTargetCoordInfo(),function(e){if(!t&&e.length){var i=e[0].model.coordinateSystem;t=i.getRect&&i.getRect()}}),!t){var e=this.api.getWidth(),i=this.api.getHeight();t={x:.2*e,y:.2*i,width:.6*e,height:.6*i}}return t}});oL.extend({type:"dataZoom.inside",defaultOption:{disabled:!1,zoomLock:!1,zoomOnMouseWheel:!0,moveOnMouseMove:!0,preventDefaultMouseMove:!0}});var wL=x,bL="\x00_ec_dataZoom_roams",ML=y,SL=sL.extend({type:"dataZoom.inside",init:function(){this._range},render:function(t,e,i,n){SL.superApply(this,"render",arguments),_v(n,t.id)&&(this._range=t.getPercentRange()),f(this.getTargetCoordInfo(),function(e,n){var a=p(e,function(t){return wv(t.model)});f(e,function(e){var r=e.model,o=t.option;yv(i,{coordId:wv(r),allCoordIds:a,containsPoint:function(t,e,i){return r.coordinateSystem.containPoint([e,i])},dataZoomId:t.id,throttleRate:t.get("throttle",!0),panGetRange:ML(this._onPan,this,e,n),zoomGetRange:ML(this._onZoom,this,e,n),zoomLock:o.zoomLock,disabled:o.disabled,roamControllerOpt:{zoomOnMouseWheel:o.zoomOnMouseWheel,moveOnMouseMove:o.moveOnMouseMove,preventDefaultMouseMove:o.preventDefaultMouseMove}})},this)},this)},dispose:function(){xv(this.api,this.dataZoomModel.id),SL.superApply(this,"dispose",arguments),this._range=null},_onPan:function(t,e,i,n,a,r,o,s,l){var h=this._range.slice(),u=t.axisModels[0];if(u){var c=IL[e]([r,o],[s,l],u,i,t),d=c.signal*(h[1]-h[0])*c.pixel/c.pixelLength;return SA(d,h,[0,100],"all"),this._range=h}},_onZoom:function(t,e,i,n,a,r){var o=this._range.slice(),s=t.axisModels[0];if(s){var l=IL[e](null,[a,r],s,i,t),h=(l.signal>0?l.pixelStart+l.pixelLength-l.pixel:l.pixel-l.pixelStart)/l.pixelLength*(o[1]-o[0])+o[0];n=Math.max(1/n,0),o[0]=(o[0]-h)*n+h,o[1]=(o[1]-h)*n+h;var u=this.dataZoomModel.findRepresentativeAxisProxy().getMinMaxSpan();return SA(0,o,[0,100],0,u.minSpan,u.maxSpan),this._range=o}}}),IL={grid:function(t,e,i,n,a){var r=i.axis,o={},s=a.model.coordinateSystem.getRect();return t=t||[0,0],"x"===r.dim?(o.pixel=e[0]-t[0],o.pixelLength=s.width,o.pixelStart=s.x,o.signal=r.inverse?1:-1):(o.pixel=e[1]-t[1],o.pixelLength=s.height,o.pixelStart=s.y,o.signal=r.inverse?-1:1),o},polar:function(t,e,i,n,a){var r=i.axis,o={},s=a.model.coordinateSystem,l=s.getRadiusAxis().getExtent(),h=s.getAngleAxis().getExtent();return t=t?s.pointToCoord(t):[0,0],e=s.pointToCoord(e),"radiusAxis"===i.mainType?(o.pixel=e[0]-t[0],o.pixelLength=l[1]-l[0],o.pixelStart=l[0],o.signal=r.inverse?1:-1):(o.pixel=e[1]-t[1],o.pixelLength=h[1]-h[0],o.pixelStart=h[0],o.signal=r.inverse?-1:1),o},singleAxis:function(t,e,i,n,a){var r=i.axis,o=a.model.coordinateSystem.getRect(),s={};return t=t||[0,0],"horizontal"===r.orient?(s.pixel=e[0]-t[0],s.pixelLength=o.width,s.pixelStart=o.x,s.signal=r.inverse?1:-1):(s.pixel=e[1]-t[1],s.pixelLength=o.height,s.pixelStart=o.y,s.signal=r.inverse?-1:1),s}};Il({getTargetSeries:function(t){var e=B();return t.eachComponent("dataZoom",function(t){t.eachTargetAxis(function(t,i,n){var a=n.getAxisProxy(t.name,i);f(a.getTargetSeriesModels(),function(t){e.set(t.uid,t)})})}),e},isOverallFilter:!0,overallReset:function(t,e){t.eachComponent("dataZoom",function(t){t.eachTargetAxis(function(t,i,n){n.getAxisProxy(t.name,i).reset(n,e)}),t.eachTargetAxis(function(t,i,n){n.getAxisProxy(t.name,i).filterData(n,e)})}),t.eachComponent("dataZoom",function(t){var e=t.findRepresentativeAxisProxy(),i=e.getDataPercentWindow(),n=e.getDataValueWindow();t.setRawRange({start:i[0],end:i[1],startValue:n[0],endValue:n[1]},!0)})}}),Al("dataZoom",function(t,e){var i=hv(y(e.eachComponent,e,"dataZoom"),tL,function(t,e){return t.get(e.axisIndex)}),n=[];e.eachComponent({mainType:"dataZoom",query:t},function(t){n.push.apply(n,i(t).nodes)}),f(n,function(e){e.setRawRange({start:t.start,end:t.end,startValue:t.startValue,endValue:t.endValue})})});var TL=["rect","polygon","keep","clear"],AL=function(t,e){var i=t&&t.brush;if(_(i)||(i=i?[i]:[]),i.length){var n=[];f(i,function(t){var e=t.hasOwnProperty("toolbox")?t.toolbox:[];e instanceof Array&&(n=n.concat(e))});var a=t&&t.toolbox;_(a)&&(a=a[0]),a||(a={feature:{}},t.toolbox=[a]);var r=a.feature||(a.feature={}),o=r.brush||(r.brush={}),s=o.type||(o.type=[]);s.push.apply(s,n),Lv(s),e&&!s.length&&s.push.apply(s,TL)}},CL=f,DL=M,LL=-1,kL=function(t){var e=t.mappingMethod,i=t.type,a=this.option=n(t);this.type=i,this.mappingMethod=e,this._normalizeData=OL[e];var r=PL[i];this.applyVisual=r.applyVisual,this.getColorMapper=r.getColorMapper,this._doMap=r._doMap[e],"piecewise"===e?(Ov(a),kv(a)):"category"===e?a.categories?Pv(a):Ov(a,!0):(O("linear"!==e||a.dataExtent),Ov(a))};kL.prototype={constructor:kL,mapValueToVisual:function(t){var e=this._normalizeData(t);return this._doMap(e,t)},getNormalizer:function(){return y(this._normalizeData,this)}};var PL=kL.visualHandlers={color:{applyVisual:Rv("color"),getColorMapper:function(){var t=this.option;return y("category"===t.mappingMethod?function(t,e){return!e&&(t=this._normalizeData(t)),Nv.call(this,t)}:function(e,i,n){var a=!!n;return!i&&(e=this._normalizeData(e)),n=Ve(e,t.parsedVisual,n),a?n:He(n,"rgba")},this)},_doMap:{linear:function(t){return He(Ve(t,this.option.parsedVisual),"rgba")},category:Nv,piecewise:function(t,e){var i=Gv.call(this,e);return null==i&&(i=He(Ve(t,this.option.parsedVisual),"rgba")),i},fixed:Bv}},colorHue:zv(function(t,e){return Fe(t,e)}),colorSaturation:zv(function(t,e){return Fe(t,null,e)}),colorLightness:zv(function(t,e){return Fe(t,null,null,e)}),colorAlpha:zv(function(t,e){return We(t,e)}),opacity:{applyVisual:Rv("opacity"),_doMap:Vv([0,1])},symbol:{applyVisual:function(t,e,i){var n=this.mapValueToVisual(t);if(b(n))i("symbol",n);else if(DL(n))for(var a in n)n.hasOwnProperty(a)&&i(a,n[a])},_doMap:{linear:Ev,category:Nv,piecewise:function(t,e){var i=Gv.call(this,e);return null==i&&(i=Ev.call(this,t)),i},fixed:Bv}},symbolSize:{applyVisual:Rv("symbolSize"),_doMap:Vv([0,1])}},OL={linear:function(t){return Vr(t,this.option.dataExtent,[0,1],!0)},piecewise:function(t){var e=this.option.pieceList,i=kL.findPieceIndex(t,e,!0);return null!=i?Vr(i,[0,e.length-1],[0,1],!0):void 0},category:function(t){var e=this.option.categories?this.option.categoryMap[t]:t;return null==e?LL:e},fixed:G};kL.listVisualTypes=function(){var t=[];return f(PL,function(e,i){t.push(i)}),t},kL.addVisualHandler=function(t,e){PL[t]=e},kL.isValidType=function(t){return PL.hasOwnProperty(t)},kL.eachVisual=function(t,e,i){M(t)?f(t,e,i):e.call(i,t)},kL.mapVisual=function(t,e,i){var n,a=_(t)?[]:M(t)?{}:(n=!0,null);return kL.eachVisual(t,function(t,r){var o=e.call(i,t,r);n?a=o:a[r]=o}),a},kL.retrieveVisuals=function(t){var e,i={};return t&&CL(PL,function(n,a){t.hasOwnProperty(a)&&(i[a]=t[a],e=!0)}),e?i:null},kL.prepareVisualTypes=function(t){if(DL(t)){var e=[];CL(t,function(t,i){e.push(i)}),t=e}else{if(!_(t))return[];t=t.slice()}return t.sort(function(t,e){return"color"===e&&"color"!==t&&0===t.indexOf("color")?1:-1}),t},kL.dependsOn=function(t,e){return"color"===e?!(!t||0!==t.indexOf(e)):t===e},kL.findPieceIndex=function(t,e,i){function n(e,i){var n=Math.abs(e-t);r>n&&(r=n,a=i)}for(var a,r=1/0,o=0,s=e.length;s>o;o++){var l=e[o].value;if(null!=l){if(l===t||"string"==typeof l&&l===t+"")return o;i&&n(l,o)}}for(var o=0,s=e.length;s>o;o++){var h=e[o],u=h.interval,c=h.close;if(u){if(u[0]===-1/0){if(Wv(c[1],t,u[1]))return o}else if(1/0===u[1]){if(Wv(c[0],u[0],t))return o}else if(Wv(c[0],u[0],t)&&Wv(c[1],t,u[1]))return o;i&&n(u[0],o),i&&n(u[1],o)}}return i?1/0===t?e.length-1:t===-1/0?0:a:void 0};var zL=f,EL={lineX:Yv(0),lineY:Yv(1),rect:{point:function(t,e,i){return t&&i.boundingRect.contain(t[0],t[1])},rect:function(t,e,i){return t&&i.boundingRect.intersect(t)}},polygon:{point:function(t,e,i){return t&&i.boundingRect.contain(t[0],t[1])&&Vh(i.range,t[0],t[1])},rect:function(t,e,i){var n=i.range;if(!t||n.length<=1)return!1;var a=t.x,r=t.y,o=t.width,s=t.height,l=n[0];return Vh(n,a,r)||Vh(n,a+o,r)||Vh(n,a,r+s)||Vh(n,a+o,r+s)||ni.create(t).contain(l[0],l[1])||$v(a,r,a+o,r,n)||$v(a,r,a,r+s,n)||$v(a+o,r,a+o,r+s,n)||$v(a,r+s,a+o,r+s,n)?!0:void 0}}},RL=f,NL=h,BL=x,VL=["dataToPoint","pointToData"],GL=["grid","xAxis","yAxis","geo","graph","polar","radiusAxis","angleAxis","bmap"],FL=tm.prototype;FL.setOutputRanges=function(t,e){this.matchOutputRanges(t,e,function(t,e,i){if((t.coordRanges||(t.coordRanges=[])).push(e),!t.coordRange){t.coordRange=e;var n=jL[t.brushType](0,i,e);t.__rangeOffset={offset:XL[t.brushType](n.values,t.range,[1,1]),xyMinMax:n.xyMinMax}}})},FL.matchOutputRanges=function(t,e,i){RL(t,function(t){var n=this.findTargetInfo(t,e);n&&n!==!0&&f(n.coordSyses,function(n){var a=jL[t.brushType](1,n,t.range);i(t,a.values,n,e)})},this)},FL.setInputRanges=function(t,e){RL(t,function(t){var i=this.findTargetInfo(t,e);if(t.range=t.range||[],i&&i!==!0){t.panelId=i.panelId;var n=jL[t.brushType](0,i.coordSys,t.coordRange),a=t.__rangeOffset;t.range=a?XL[t.brushType](n.values,a.offset,rm(n.xyMinMax,a.xyMinMax)):n.values}},this)},FL.makePanelOpts=function(t,e){return p(this._targetInfoList,function(i){var n=i.getPanelRect();return{panelId:i.panelId,defaultBrushType:e&&e(i),clipPath:Mf(n),isTargetByCursor:If(n,t,i.coordSysModel),getLinearBrushOtherExtent:Sf(n)}})},FL.controlSeries=function(t,e,i){var n=this.findTargetInfo(t,i);return n===!0||n&&NL(n.coordSyses,e.coordinateSystem)>=0},FL.findTargetInfo=function(t,e){for(var i=this._targetInfoList,n=im(e,t),a=0;a<i.length;a++){var r=i[a],o=t.panelId;if(o){if(r.panelId===o)return r}else for(var a=0;a<HL.length;a++)if(HL[a](n,r))return r}return!0};var WL={grid:function(t,e){var i=t.xAxisModels,n=t.yAxisModels,a=t.gridModels,r=B(),o={},s={};(i||n||a)&&(RL(i,function(t){var e=t.axis.grid.model;r.set(e.id,e),o[e.id]=!0}),RL(n,function(t){var e=t.axis.grid.model;r.set(e.id,e),s[e.id]=!0}),RL(a,function(t){r.set(t.id,t),o[t.id]=!0,s[t.id]=!0}),r.each(function(t){var a=t.coordinateSystem,r=[];RL(a.getCartesians(),function(t){(NL(i,t.getAxis("x").model)>=0||NL(n,t.getAxis("y").model)>=0)&&r.push(t)}),e.push({panelId:"grid--"+t.id,gridModel:t,coordSysModel:t,coordSys:r[0],coordSyses:r,getPanelRect:ZL.grid,xAxisDeclared:o[t.id],yAxisDeclared:s[t.id]})}))},geo:function(t,e){RL(t.geoModels,function(t){var i=t.coordinateSystem;e.push({panelId:"geo--"+t.id,geoModel:t,coordSysModel:t,coordSys:i,coordSyses:[i],getPanelRect:ZL.geo})})}},HL=[function(t,e){var i=t.xAxisModel,n=t.yAxisModel,a=t.gridModel;return!a&&i&&(a=i.axis.grid.model),!a&&n&&(a=n.axis.grid.model),a&&a===e.gridModel},function(t,e){var i=t.geoModel;return i&&i===e.geoModel}],ZL={grid:function(){return this.coordSys.grid.getRect().clone()},geo:function(){var t=this.coordSys,e=t.getBoundingRect().clone();return e.applyTransform(Ir(t)),e}},jL={lineX:BL(nm,0),lineY:BL(nm,1),rect:function(t,e,i){var n=e[VL[t]]([i[0][0],i[1][0]]),a=e[VL[t]]([i[0][1],i[1][1]]),r=[em([n[0],a[0]]),em([n[1],a[1]])];return{values:r,xyMinMax:r}},polygon:function(t,e,i){var n=[[1/0,-1/0],[1/0,-1/0]],a=p(i,function(i){var a=e[VL[t]](i);return n[0][0]=Math.min(n[0][0],a[0]),n[1][0]=Math.min(n[1][0],a[1]),n[0][1]=Math.max(n[0][1],a[0]),n[1][1]=Math.max(n[1][1],a[1]),a});return{values:a,xyMinMax:n}}},XL={lineX:BL(am,0),lineY:BL(am,1),rect:function(t,e,i){return[[t[0][0]-i[0]*e[0][0],t[0][1]-i[0]*e[0][1]],[t[1][0]-i[1]*e[1][0],t[1][1]-i[1]*e[1][1]]]},polygon:function(t,e,i){return p(t,function(t,n){return[t[0]-i[0]*e[n][0],t[1]-i[1]*e[n][1]]})}},UL=["inBrush","outOfBrush"],YL="__ecBrushSelect",qL="__ecInBrushSelectEvent",$L=tS.VISUAL.BRUSH;Ll($L,function(t,e,i){t.eachComponent({mainType:"brush"},function(e){i&&"takeGlobalCursor"===i.type&&e.setBrushOption("brush"===i.key?i.brushOption:{brushType:!1});var n=e.brushTargetManager=new tm(e.option,t);n.setInputRanges(e.areas,t)})}),kl($L,function(t,e,i){var a,r,o=[];t.eachComponent({mainType:"brush"},function(e,i){function l(t){return"all"===v||m[t]}function h(t){return!!t.length}function u(t,e){var i=t.coordinateSystem;w|=i.hasAxisBrushed(),l(e)&&i.eachActiveState(t.getData(),function(t,e){"active"===t&&(y[e]=1)})}function c(i,n,a){var r=um(i);if(r&&!cm(e,n)&&(f(b,function(n){r[n.brushType]&&e.brushTargetManager.controlSeries(n,i,t)&&a.push(n),w|=h(a)}),l(n)&&h(a))){var o=i.getData();o.each(function(t){hm(r,a,o,t)&&(y[t]=1)})}}var d={brushId:e.id,brushIndex:i,brushName:e.name,areas:n(e.areas),selected:[]};o.push(d);var g=e.option,v=g.brushLink,m=[],y=[],x=[],w=0;i||(a=g.throttleType,r=g.throttleDelay);var b=p(e.areas,function(t){return dm(s({boundingRect:KL[t.brushType](t)},t))}),M=Zv(e.option,UL,function(t){t.mappingMethod="fixed"});_(v)&&f(v,function(t){m[t]=1}),t.eachSeries(function(t,e){var i=x[e]=[];"parallel"===t.subType?u(t,e,i):c(t,e,i)}),t.eachSeries(function(t,e){var i={seriesId:t.id,seriesIndex:e,seriesName:t.name,dataIndex:[]};d.selected.push(i);var n=um(t),a=x[e],r=t.getData(),o=l(e)?function(t){return y[t]?(i.dataIndex.push(r.getRawIndex(t)),"inBrush"):"outOfBrush"}:function(t){return hm(n,a,r,t)?(i.dataIndex.push(r.getRawIndex(t)),"inBrush"):"outOfBrush"};(l(e)?w:h(a))&&Xv(UL,M,r,o)})}),sm(e,a,r,o,i)});{var KL={lineX:G,lineY:G,rect:function(t){return fm(t.range)},polygon:function(t){for(var e,i=t.range,n=0,a=i.length;a>n;n++){e=e||[[1/0,-1/0],[1/0,-1/0]];var r=i[n];r[0]<e[0][0]&&(e[0][0]=r[0]),r[0]>e[0][1]&&(e[0][1]=r[0]),r[1]<e[1][0]&&(e[1][0]=r[1]),r[1]>e[1][1]&&(e[1][1]=r[1])}return e&&fm(e)}},JL=["#ddd"];zl({type:"brush",dependencies:["geo","grid","xAxis","yAxis","parallel","series"],defaultOption:{toolbox:null,brushLink:null,seriesIndex:"all",geoIndex:null,xAxisIndex:null,yAxisIndex:null,brushType:"rect",brushMode:"single",transformable:!0,brushStyle:{borderWidth:1,color:"rgba(120,140,180,0.3)",borderColor:"rgba(120,140,180,0.8)"},throttleType:"fixRate",throttleDelay:0,removeOnClick:!0,z:1e4},areas:[],brushType:null,brushOption:{},coordInfoList:[],optionUpdated:function(t,e){var i=this.option;!e&&jv(i,t,["inBrush","outOfBrush"]),i.inBrush=i.inBrush||{},i.outOfBrush=i.outOfBrush||{color:JL}},setAreas:function(t){t&&(this.areas=p(t,function(t){return pm(this.option,t)},this))},setBrushOption:function(t){this.brushOption=pm(this.option,t),this.brushType=this.brushOption.brushType}})}El({type:"brush",init:function(t,e){this.ecModel=t,this.api=e,this.model,(this._brushController=new Fd(e.getZr())).on("brush",y(this._onBrush,this)).mount()},render:function(t){return this.model=t,gm.apply(this,arguments)},updateView:gm,dispose:function(){this._brushController.dispose()},_onBrush:function(t,e){var i=this.model.id;this.model.brushTargetManager.setOutputRanges(t,this.ecModel),(!e.isEnd||e.removeOnClick)&&this.api.dispatchAction({type:"brush",brushId:i,areas:n(t),$from:i})}}),Al({type:"brush",event:"brush"},function(t,e){e.eachComponent({mainType:"brush",query:t},function(e){e.setAreas(t.areas)})}),Al({type:"brushSelect",event:"brushSelected",update:"none"},function(){});var QL={},tk=SM.toolbox.brush;ym.defaultOption={show:!0,type:["rect","polygon","lineX","lineY","keep","clear"],icon:{rect:"M7.3,34.7 M0.4,10V-0.2h9.8 M89.6,10V-0.2h-9.8 M0.4,60v10.2h9.8 M89.6,60v10.2h-9.8 M12.3,22.4V10.5h13.1 M33.6,10.5h7.8 M49.1,10.5h7.8 M77.5,22.4V10.5h-13 M12.3,31.1v8.2 M77.7,31.1v8.2 M12.3,47.6v11.9h13.1 M33.6,59.5h7.6 M49.1,59.5 h7.7 M77.5,47.6v11.9h-13",polygon:"M55.2,34.9c1.7,0,3.1,1.4,3.1,3.1s-1.4,3.1-3.1,3.1 s-3.1-1.4-3.1-3.1S53.5,34.9,55.2,34.9z M50.4,51c1.7,0,3.1,1.4,3.1,3.1c0,1.7-1.4,3.1-3.1,3.1c-1.7,0-3.1-1.4-3.1-3.1 C47.3,52.4,48.7,51,50.4,51z M55.6,37.1l1.5-7.8 M60.1,13.5l1.6-8.7l-7.8,4 M59,19l-1,5.3 M24,16.1l6.4,4.9l6.4-3.3 M48.5,11.6 l-5.9,3.1 M19.1,12.8L9.7,5.1l1.1,7.7 M13.4,29.8l1,7.3l6.6,1.6 M11.6,18.4l1,6.1 M32.8,41.9 M26.6,40.4 M27.3,40.2l6.1,1.6 M49.9,52.1l-5.6-7.6l-4.9-1.2",lineX:"M15.2,30 M19.7,15.6V1.9H29 M34.8,1.9H40.4 M55.3,15.6V1.9H45.9 M19.7,44.4V58.1H29 M34.8,58.1H40.4 M55.3,44.4 V58.1H45.9 M12.5,20.3l-9.4,9.6l9.6,9.8 M3.1,29.9h16.5 M62.5,20.3l9.4,9.6L62.3,39.7 M71.9,29.9H55.4",lineY:"M38.8,7.7 M52.7,12h13.2v9 M65.9,26.6V32 M52.7,46.3h13.2v-9 M24.9,12H11.8v9 M11.8,26.6V32 M24.9,46.3H11.8v-9 M48.2,5.1l-9.3-9l-9.4,9.2 M38.9-3.9V12 M48.2,53.3l-9.3,9l-9.4-9.2 M38.9,62.3V46.4",keep:"M4,10.5V1h10.3 M20.7,1h6.1 M33,1h6.1 M55.4,10.5V1H45.2 M4,17.3v6.6 M55.6,17.3v6.6 M4,30.5V40h10.3 M20.7,40 h6.1 M33,40h6.1 M55.4,30.5V40H45.2 M21,18.9h62.9v48.6H21V18.9z",clear:"M22,14.7l30.9,31 M52.9,14.7L22,45.7 M4.7,16.8V4.2h13.1 M26,4.2h7.8 M41.6,4.2h7.8 M70.3,16.8V4.2H57.2 M4.7,25.9v8.6 M70.3,25.9v8.6 M4.7,43.2v12.6h13.1 M26,55.8h7.8 M41.6,55.8h7.8 M70.3,43.2v12.6H57.2"},title:n(tk.title)};var ek=ym.prototype;ek.render=ek.updateView=function(t,e){var i,n,a;e.eachComponent({mainType:"brush"},function(t){i=t.brushType,n=t.brushOption.brushMode||"single",a|=t.areas.length}),this._brushType=i,this._brushMode=n,f(t.get("type",!0),function(e){t.setIconStatus(e,("keep"===e?"multiple"===n:"clear"===e?a:e===i)?"emphasis":"normal")})},ek.getIcons=function(){var t=this.model,e=t.get("icon",!0),i={};return f(t.get("type",!0),function(t){e[t]&&(i[t]=e[t])}),i},ek.onclick=function(t,e,i){var n=this._brushType,a=this._brushMode;"clear"===i?(e.dispatchAction({type:"axisAreaSelect",intervals:[]}),e.dispatchAction({type:"brush",command:"clear",areas:[]})):e.dispatchAction({type:"takeGlobalCursor",key:"brush",brushOption:{brushType:"keep"===i?n:n===i?!1:i,brushMode:"keep"===i?"multiple"===a?"single":"multiple":a}})},vm("brush",ym),Sl(AL);var ik=f,nk=function(t){var e=t&&t.visualMap;_(e)||(e=e?[e]:[]),ik(e,function(t){if(t){xm(t,"splitList")&&!xm(t,"pieces")&&(t.pieces=t.splitList,delete t.splitList);var e=t.pieces;e&&_(e)&&ik(e,function(t){M(t)&&(xm(t,"start")&&!xm(t,"min")&&(t.min=t.start),xm(t,"end")&&!xm(t,"max")&&(t.max=t.end))})}})};Cb.registerSubTypeDefaulter("visualMap",function(t){return t.categories||(t.pieces?t.pieces.length>0:t.splitNumber>0)&&!t.calculable?"piecewise":"continuous"});var ak=tS.VISUAL.COMPONENT;kl(ak,{createOnAllSeries:!0,reset:function(t,e){var i=[];return e.eachComponent("visualMap",function(e){e.isTargetSeries(t)&&i.push(Uv(e.stateList,e.targetVisuals,y(e.getValueState,e),e.getDataDimension(t.getData())))}),i}}),kl(ak,{createOnAllSeries:!0,reset:function(t,e){var i=t.getData(),n=[];e.eachComponent("visualMap",function(e){if(e.isTargetSeries(t)){var a=e.getVisualMeta(y(_m,null,t,e))||{stops:[],outerColors:[]},r=e.getDataDimension(i),o=i.getDimensionInfo(r);null!=o&&(a.dimension=o.index,n.push(a))}}),t.getData().setVisual("visualMeta",n)}});var rk={get:function(t,e,i){var a=n((ok[t]||{})[e]);return i&&_(a)?a[a.length-1]:a}},ok={color:{active:["#006edd","#e0ffff"],inactive:["rgba(0,0,0,0)"]},colorHue:{active:[0,360],inactive:[0,0]},colorSaturation:{active:[.3,1],inactive:[0,0]},colorLightness:{active:[.9,.5],inactive:[0,0]},colorAlpha:{active:[.3,1],inactive:[0,0]},opacity:{active:[.3,1],inactive:[0,0]},symbol:{active:["circle","roundRect","diamond"],inactive:["none"]},symbolSize:{active:[10,50],inactive:[0,0]}},sk=kL.mapVisual,lk=kL.eachVisual,hk=_,uk=f,ck=Wr,dk=Vr,fk=G,pk=zl({type:"visualMap",dependencies:["series"],stateList:["inRange","outOfRange"],replacableOptionKeys:["inRange","outOfRange","target","controller","color"],dataBound:[-1/0,1/0],layoutMode:{type:"box",ignoreSize:!0},defaultOption:{show:!0,zlevel:0,z:4,seriesIndex:"all",min:0,max:200,dimension:null,inRange:null,outOfRange:null,left:0,right:null,top:null,bottom:0,itemWidth:null,itemHeight:null,inverse:!1,orient:"vertical",backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",contentColor:"#5793f3",inactiveColor:"#aaa",borderWidth:0,padding:5,textGap:10,precision:0,color:null,formatter:null,text:null,textStyle:{color:"#333"}},init:function(t,e,i){this._dataExtent,this.targetVisuals={},this.controllerVisuals={},this.textStyleModel,this.itemSize,this.mergeDefaultAndTheme(t,i)},optionUpdated:function(t,e){var i=this.option;vy.canvasSupported||(i.realtime=!1),!e&&jv(i,t,this.replacableOptionKeys),this.textStyleModel=this.getModel("textStyle"),this.resetItemSize(),this.completeVisualOption()},resetVisual:function(t){var e=this.stateList;t=y(t,this),this.controllerVisuals=Zv(this.option.controller,e,t),this.targetVisuals=Zv(this.option.target,e,t)},getTargetSeriesIndices:function(){var t=this.option.seriesIndex,e=[];return null==t||"all"===t?this.ecModel.eachSeries(function(t,i){e.push(i)}):e=On(t),e},eachTargetSeries:function(t,e){f(this.getTargetSeriesIndices(),function(i){t.call(e,this.ecModel.getSeriesByIndex(i))},this)},isTargetSeries:function(t){var e=!1;return this.eachTargetSeries(function(i){i===t&&(e=!0)}),e},formatValueText:function(t,e,i){function n(t){return t===l[0]?"min":t===l[1]?"max":(+t).toFixed(Math.min(s,20))}var a,r,o=this.option,s=o.precision,l=this.dataBound,h=o.formatter;return i=i||["<",">"],_(t)&&(t=t.slice(),a=!0),r=e?t:a?[n(t[0]),n(t[1])]:n(t),b(h)?h.replace("{value}",a?r[0]:r).replace("{value2}",a?r[1]:r):w(h)?a?h(t[0],t[1]):h(t):a?t[0]===l[0]?i[0]+" "+r[1]:t[1]===l[1]?i[1]+" "+r[0]:r[0]+" - "+r[1]:r},resetExtent:function(){var t=this.option,e=ck([t.min,t.max]);this._dataExtent=e},getDataDimension:function(t){var e=this.option.dimension,i=t.dimensions;return null!=e||i.length?t.getDimension(null!=e?e:i.length-1):void 0},getExtent:function(){return this._dataExtent.slice()},completeVisualOption:function(){function t(t){hk(o.color)&&!t.inRange&&(t.inRange={color:o.color.slice().reverse()}),t.inRange=t.inRange||{color:r.get("gradientColor")},uk(this.stateList,function(e){var i=t[e];if(b(i)){var n=rk.get(i,"active",u);n?(t[e]={},t[e][i]=n):delete t[e]}},this)}function e(t,e,i){var n=t[e],a=t[i];n&&!a&&(a=t[i]={},uk(n,function(t,e){if(kL.isValidType(e)){var i=rk.get(e,"inactive",u);null!=i&&(a[e]=i,"color"!==e||a.hasOwnProperty("opacity")||a.hasOwnProperty("colorAlpha")||(a.opacity=[0,0]))}}))}function i(t){var e=(t.inRange||{}).symbol||(t.outOfRange||{}).symbol,i=(t.inRange||{}).symbolSize||(t.outOfRange||{}).symbolSize,a=this.get("inactiveColor");uk(this.stateList,function(r){var o=this.itemSize,s=t[r];s||(s=t[r]={color:u?a:[a]}),null==s.symbol&&(s.symbol=e&&n(e)||(u?"roundRect":["roundRect"])),null==s.symbolSize&&(s.symbolSize=i&&n(i)||(u?o[0]:[o[0],o[0]])),s.symbol=sk(s.symbol,function(t){return"none"===t||"square"===t?"roundRect":t});var l=s.symbolSize;if(null!=l){var h=-1/0;lk(l,function(t){t>h&&(h=t)}),s.symbolSize=sk(l,function(t){return dk(t,[0,h],[0,o[0]],!0)})}},this)}var r=this.ecModel,o=this.option,s={inRange:o.inRange,outOfRange:o.outOfRange},l=o.target||(o.target={}),h=o.controller||(o.controller={});a(l,s),a(h,s);var u=this.isCategory();t.call(this,l),t.call(this,h),e.call(this,l,"inRange","outOfRange"),i.call(this,h)},resetItemSize:function(){this.itemSize=[parseFloat(this.get("itemWidth")),parseFloat(this.get("itemHeight"))]},isCategory:function(){return!!this.option.categories},setSelected:fk,getValueState:fk,getVisualMeta:fk}),gk=[20,140],vk=pk.extend({type:"visualMap.continuous",defaultOption:{align:"auto",calculable:!1,range:null,realtime:!0,itemHeight:null,itemWidth:null,hoverLink:!0,hoverLinkDataSize:null,hoverLinkOnHandle:null},optionUpdated:function(){vk.superApply(this,"optionUpdated",arguments),this.resetExtent(),this.resetVisual(function(t){t.mappingMethod="linear",t.dataExtent=this.getExtent()}),this._resetRange()},resetItemSize:function(){vk.superApply(this,"resetItemSize",arguments);var t=this.itemSize;"horizontal"===this._orient&&t.reverse(),(null==t[0]||isNaN(t[0]))&&(t[0]=gk[0]),(null==t[1]||isNaN(t[1]))&&(t[1]=gk[1])},_resetRange:function(){var t=this.getExtent(),e=this.option.range;!e||e.auto?(t.auto=1,this.option.range=t):_(e)&&(e[0]>e[1]&&e.reverse(),e[0]=Math.max(e[0],t[0]),e[1]=Math.min(e[1],t[1]))},completeVisualOption:function(){pk.prototype.completeVisualOption.apply(this,arguments),f(this.stateList,function(t){var e=this.option.controller[t].symbolSize;e&&e[0]!==e[1]&&(e[0]=0)},this)},setSelected:function(t){this.option.range=t.slice(),this._resetRange()},getSelected:function(){var t=this.getExtent(),e=Wr((this.get("range")||[]).slice());return e[0]>t[1]&&(e[0]=t[1]),e[1]>t[1]&&(e[1]=t[1]),e[0]<t[0]&&(e[0]=t[0]),e[1]<t[0]&&(e[1]=t[0]),e},getValueState:function(t){var e=this.option.range,i=this.getExtent();return(e[0]<=i[0]||e[0]<=t)&&(e[1]>=i[1]||t<=e[1])?"inRange":"outOfRange"},findTargetDataIndices:function(t){var e=[];return this.eachTargetSeries(function(i){var n=[],a=i.getData();a.each(this.getDataDimension(a),function(e,i){t[0]<=e&&e<=t[1]&&n.push(i)},!0,this),e.push({seriesId:i.id,dataIndex:n})},this),e},getVisualMeta:function(t){function e(e,i){a.push({value:e,color:t(e,i)})}for(var i=wm(this,"outOfRange",this.getExtent()),n=wm(this,"inRange",this.option.range.slice()),a=[],r=0,o=0,s=n.length,l=i.length;l>o&&(!n.length||i[o]<=n[0]);o++)i[o]<n[r]&&e(i[o],"outOfRange");for(var h=1;s>r;r++,h=0)h&&a.length&&e(n[r],"outOfRange"),e(n[r],"inRange");for(var h=1;l>o;o++)(!n.length||n[n.length-1]<i[o])&&(h&&(a.length&&e(a[a.length-1].value,"outOfRange"),h=0),e(i[o],"outOfRange"));var u=a.length;return{stops:a,outerColors:[u?a[0].color:"transparent",u?a[u-1].color:"transparent"]}}}),mk=El({type:"visualMap",autoPositionValues:{left:1,right:1,top:1,bottom:1},init:function(t,e){this.ecModel=t,this.api=e,this.visualMapModel},render:function(t){return this.visualMapModel=t,t.get("show")===!1?void this.group.removeAll():void this.doRender.apply(this,arguments)},renderBackground:function(t){var e=this.visualMapModel,i=gb(e.get("padding")||0),n=t.getBoundingRect();t.add(new Ww({z2:-1,silent:!0,shape:{x:n.x-i[3],y:n.y-i[0],width:n.width+i[3]+i[1],height:n.height+i[0]+i[2]},style:{fill:e.get("backgroundColor"),stroke:e.get("borderColor"),lineWidth:e.get("borderWidth")}}))},getControllerVisual:function(t,e,i){function n(t){return s[t]}function a(t,e){s[t]=e}i=i||{};var r=i.forceState,o=this.visualMapModel,s={};if("symbol"===e&&(s.symbol=o.get("itemSymbol")),"color"===e){var l=o.get("contentColor");s.color=l}var h=o.controllerVisuals[r||o.getValueState(t)],u=kL.prepareVisualTypes(h);return f(u,function(r){var o=h[r];i.convertOpacityToAlpha&&"opacity"===r&&(r="colorAlpha",o=h.__alphaForOpacity),kL.dependsOn(r,e)&&o&&o.applyVisual(t,n,a)}),s[e]},positionGroup:function(t){var e=this.visualMapModel,i=this.api;co(t,e.getBoxLayoutParams(),{width:i.getWidth(),height:i.getHeight()})},doRender:G}),yk=Vr,xk=f,_k=Math.min,wk=Math.max,bk=12,Mk=6,Sk=mk.extend({type:"visualMap.continuous",init:function(){Sk.superApply(this,"init",arguments),this._shapes={},this._dataInterval=[],this._handleEnds=[],this._orient,this._useHandle,this._hoverLinkDataIndices=[],this._dragging,this._hovering},doRender:function(t,e,i,n){n&&"selectDataRange"===n.type&&n.from===this.uid||this._buildView()},_buildView:function(){this.group.removeAll();var t=this.visualMapModel,e=this.group;this._orient=t.get("orient"),this._useHandle=t.get("calculable"),this._resetInterval(),this._renderBar(e);var i=t.get("text");this._renderEndsText(e,i,0),this._renderEndsText(e,i,1),this._updateView(!0),this.renderBackground(e),this._updateView(),this._enableHoverLinkToSeries(),this._enableHoverLinkFromSeries(),this.positionGroup(e)},_renderEndsText:function(t,e,i){if(e){var n=e[1-i];n=null!=n?n+"":"";var a=this.visualMapModel,r=a.get("textGap"),o=a.itemSize,s=this._shapes.barGroup,l=this._applyTransform([o[0]/2,0===i?-r:o[1]+r],s),h=this._applyTransform(0===i?"bottom":"top",s),u=this._orient,c=this.visualMapModel.textStyleModel;this.group.add(new Pw({style:{x:l[0],y:l[1],textVerticalAlign:"horizontal"===u?"middle":h,textAlign:"horizontal"===u?h:"center",text:n,textFont:c.getFont(),textFill:c.getTextColor()}}))}},_renderBar:function(t){var e=this.visualMapModel,i=this._shapes,n=e.itemSize,a=this._orient,r=this._useHandle,o=bm(e,this.api,n),s=i.barGroup=this._createBarGroup(o);s.add(i.outOfRange=Sm()),s.add(i.inRange=Sm(null,r?Dm(this._orient):null,y(this._dragHandle,this,"all",!1),y(this._dragHandle,this,"all",!0)));var l=e.textStyleModel.getTextRect("国"),h=wk(l.width,l.height);r&&(i.handleThumbs=[],i.handleLabels=[],i.handleLabelPoints=[],this._createHandle(s,0,n,h,a,o),this._createHandle(s,1,n,h,a,o)),this._createIndicator(s,n,h,a),t.add(s)},_createHandle:function(t,e,i,n,a){var r=y(this._dragHandle,this,e,!1),o=y(this._dragHandle,this,e,!0),s=Sm(Im(e,n),Dm(this._orient),r,o);
-s.position[0]=i[0],t.add(s);var l=this.visualMapModel.textStyleModel,h=new Pw({draggable:!0,drift:r,onmousemove:function(t){t_(t.event)},ondragend:o,style:{x:0,y:0,text:"",textFont:l.getFont(),textFill:l.getTextColor()}});this.group.add(h);var u=["horizontal"===a?n/2:1.5*n,"horizontal"===a?0===e?-(1.5*n):1.5*n:0===e?-n/2:n/2],c=this._shapes;c.handleThumbs[e]=s,c.handleLabelPoints[e]=u,c.handleLabels[e]=h},_createIndicator:function(t,e,i,n){var a=Sm([[0,0]],"move");a.position[0]=e[0],a.attr({invisible:!0,silent:!0}),t.add(a);var r=this.visualMapModel.textStyleModel,o=new Pw({silent:!0,invisible:!0,style:{x:0,y:0,text:"",textFont:r.getFont(),textFill:r.getTextColor()}});this.group.add(o);var s=["horizontal"===n?i/2:Mk+3,0],l=this._shapes;l.indicator=a,l.indicatorLabel=o,l.indicatorLabelPoint=s},_dragHandle:function(t,e,i,n){if(this._useHandle){if(this._dragging=!e,!e){var a=this._applyTransform([i,n],this._shapes.barGroup,!0);this._updateInterval(t,a[1]),this._updateView()}e===!this.visualMapModel.get("realtime")&&this.api.dispatchAction({type:"selectDataRange",from:this.uid,visualMapId:this.visualMapModel.id,selected:this._dataInterval.slice()}),e?!this._hovering&&this._clearHoverLinkToSeries():Cm(this.visualMapModel)&&this._doHoverLinkToSeries(this._handleEnds[t],!1)}},_resetInterval:function(){var t=this.visualMapModel,e=this._dataInterval=t.getSelected(),i=t.getExtent(),n=[0,t.itemSize[1]];this._handleEnds=[yk(e[0],i,n,!0),yk(e[1],i,n,!0)]},_updateInterval:function(t,e){e=e||0;var i=this.visualMapModel,n=this._handleEnds,a=[0,i.itemSize[1]];SA(e,n,a,t,0);var r=i.getExtent();this._dataInterval=[yk(n[0],a,r,!0),yk(n[1],a,r,!0)]},_updateView:function(t){var e=this.visualMapModel,i=e.getExtent(),n=this._shapes,a=[0,e.itemSize[1]],r=t?a:this._handleEnds,o=this._createBarVisual(this._dataInterval,i,r,"inRange"),s=this._createBarVisual(i,i,a,"outOfRange");n.inRange.setStyle({fill:o.barColor,opacity:o.opacity}).setShape("points",o.barPoints),n.outOfRange.setStyle({fill:s.barColor,opacity:s.opacity}).setShape("points",s.barPoints),this._updateHandle(r,o)},_createBarVisual:function(t,e,i,n){var a={forceState:n,convertOpacityToAlpha:!0},r=this._makeColorGradient(t,a),o=[this.getControllerVisual(t[0],"symbolSize",a),this.getControllerVisual(t[1],"symbolSize",a)],s=this._createBarPoints(i,o);return{barColor:new qw(0,0,0,1,r),barPoints:s,handlesColor:[r[0].color,r[r.length-1].color]}},_makeColorGradient:function(t,e){var i=100,n=[],a=(t[1]-t[0])/i;n.push({color:this.getControllerVisual(t[0],"color",e),offset:0});for(var r=1;i>r;r++){var o=t[0]+a*r;if(o>t[1])break;n.push({color:this.getControllerVisual(o,"color",e),offset:r/i})}return n.push({color:this.getControllerVisual(t[1],"color",e),offset:1}),n},_createBarPoints:function(t,e){var i=this.visualMapModel.itemSize;return[[i[0]-e[0],t[0]],[i[0],t[0]],[i[0],t[1]],[i[0]-e[1],t[1]]]},_createBarGroup:function(t){var e=this._orient,i=this.visualMapModel.get("inverse");return new xx("horizontal"!==e||i?"horizontal"===e&&i?{scale:"bottom"===t?[-1,1]:[1,1],rotation:-Math.PI/2}:"vertical"!==e||i?{scale:"left"===t?[1,1]:[-1,1]}:{scale:"left"===t?[1,-1]:[-1,-1]}:{scale:"bottom"===t?[1,1]:[-1,1],rotation:Math.PI/2})},_updateHandle:function(t,e){if(this._useHandle){var i=this._shapes,n=this.visualMapModel,a=i.handleThumbs,r=i.handleLabels;xk([0,1],function(o){var s=a[o];s.setStyle("fill",e.handlesColor[o]),s.position[1]=t[o];var l=Tr(i.handleLabelPoints[o],Ir(s,this.group));r[o].setStyle({x:l[0],y:l[1],text:n.formatValueText(this._dataInterval[o]),textVerticalAlign:"middle",textAlign:this._applyTransform("horizontal"===this._orient?0===o?"bottom":"top":"left",i.barGroup)})},this)}},_showIndicator:function(t,e,i,n){var a=this.visualMapModel,r=a.getExtent(),o=a.itemSize,s=[0,o[1]],l=yk(t,r,s,!0),h=this._shapes,u=h.indicator;if(u){u.position[1]=l,u.attr("invisible",!1),u.setShape("points",Tm(!!i,n,l,o[1]));var c={convertOpacityToAlpha:!0},d=this.getControllerVisual(t,"color",c);u.setStyle("fill",d);var f=Tr(h.indicatorLabelPoint,Ir(u,this.group)),p=h.indicatorLabel;p.attr("invisible",!1);var g=this._applyTransform("left",h.barGroup),v=this._orient;p.setStyle({text:(i?i:"")+a.formatValueText(e),textVerticalAlign:"horizontal"===v?g:"middle",textAlign:"horizontal"===v?"center":g,x:f[0],y:f[1]})}},_enableHoverLinkToSeries:function(){var t=this;this._shapes.barGroup.on("mousemove",function(e){if(t._hovering=!0,!t._dragging){var i=t.visualMapModel.itemSize,n=t._applyTransform([e.offsetX,e.offsetY],t._shapes.barGroup,!0,!0);n[1]=_k(wk(0,n[1]),i[1]),t._doHoverLinkToSeries(n[1],0<=n[0]&&n[0]<=i[0])}}).on("mouseout",function(){t._hovering=!1,!t._dragging&&t._clearHoverLinkToSeries()})},_enableHoverLinkFromSeries:function(){var t=this.api.getZr();this.visualMapModel.option.hoverLink?(t.on("mouseover",this._hoverLinkFromSeriesMouseOver,this),t.on("mouseout",this._hideIndicator,this)):this._clearHoverLinkFromSeries()},_doHoverLinkToSeries:function(t,e){var i=this.visualMapModel,n=i.itemSize;if(i.option.hoverLink){var a=[0,n[1]],r=i.getExtent();t=_k(wk(a[0],t),a[1]);var o=Am(i,r,a),s=[t-o,t+o],l=yk(t,a,r,!0),h=[yk(s[0],a,r,!0),yk(s[1],a,r,!0)];s[0]<a[0]&&(h[0]=-1/0),s[1]>a[1]&&(h[1]=1/0),e&&(h[0]===-1/0?this._showIndicator(l,h[1],"< ",o):1/0===h[1]?this._showIndicator(l,h[0],"> ",o):this._showIndicator(l,l,"≈ ",o));var u=this._hoverLinkDataIndices,c=[];(e||Cm(i))&&(c=this._hoverLinkDataIndices=i.findTargetDataIndices(h));var d=Gn(u,c);this._dispatchHighDown("downplay",Mm(d[0])),this._dispatchHighDown("highlight",Mm(d[1]))}},_hoverLinkFromSeriesMouseOver:function(t){var e=t.target,i=this.visualMapModel;if(e&&null!=e.dataIndex){var n=this.ecModel.getSeriesByIndex(e.seriesIndex);if(i.isTargetSeries(n)){var a=n.getData(e.dataType),r=a.get(i.getDataDimension(a),e.dataIndex,!0);isNaN(r)||this._showIndicator(r,r)}}},_hideIndicator:function(){var t=this._shapes;t.indicator&&t.indicator.attr("invisible",!0),t.indicatorLabel&&t.indicatorLabel.attr("invisible",!0)},_clearHoverLinkToSeries:function(){this._hideIndicator();var t=this._hoverLinkDataIndices;this._dispatchHighDown("downplay",Mm(t)),t.length=0},_clearHoverLinkFromSeries:function(){this._hideIndicator();var t=this.api.getZr();t.off("mouseover",this._hoverLinkFromSeriesMouseOver),t.off("mouseout",this._hideIndicator)},_applyTransform:function(t,e,i,n){var a=Ir(e,n?null:this.group);return nb[_(t)?"applyTransform":"transformDirection"](t,a,i)},_dispatchHighDown:function(t,e){e&&e.length&&this.api.dispatchAction({type:t,batch:e})},dispose:function(){this._clearHoverLinkFromSeries(),this._clearHoverLinkToSeries()},remove:function(){this._clearHoverLinkFromSeries(),this._clearHoverLinkToSeries()}}),Ik={type:"selectDataRange",event:"dataRangeSelected",update:"update"};Al(Ik,function(t,e){e.eachComponent({mainType:"visualMap",query:t},function(e){e.setSelected(t.selected)})}),Sl(nk);{var Tk=pk.extend({type:"visualMap.piecewise",defaultOption:{selected:null,minOpen:!1,maxOpen:!1,align:"auto",itemWidth:20,itemHeight:14,itemSymbol:"roundRect",pieceList:null,categories:null,splitNumber:5,selectedMode:"multiple",itemGap:10,hoverLink:!0,showLabel:null},optionUpdated:function(t,e){Tk.superApply(this,"optionUpdated",arguments),this._pieceList=[],this.resetExtent();var i=this._mode=this._determineMode();Ak[this._mode].call(this),this._resetSelected(t,e);var a=this.option.categories;this.resetVisual(function(t,e){"categories"===i?(t.mappingMethod="category",t.categories=n(a)):(t.dataExtent=this.getExtent(),t.mappingMethod="piecewise",t.pieceList=p(this._pieceList,function(t){var t=n(t);return"inRange"!==e&&(t.visual=null),t}))})},completeVisualOption:function(){function t(t,e,i){return t&&t[e]&&(M(t[e])?t[e].hasOwnProperty(i):t[e]===i)}var e=this.option,i={},n=kL.listVisualTypes(),a=this.isCategory();f(e.pieces,function(t){f(n,function(e){t.hasOwnProperty(e)&&(i[e]=1)})}),f(i,function(i,n){var r=0;f(this.stateList,function(i){r|=t(e,i,n)||t(e.target,i,n)},this),!r&&f(this.stateList,function(t){(e[t]||(e[t]={}))[n]=rk.get(n,"inRange"===t?"active":"inactive",a)})},this),pk.prototype.completeVisualOption.apply(this,arguments)},_resetSelected:function(t,e){var i=this.option,n=this._pieceList,a=(e?i:t).selected||{};if(i.selected=a,f(n,function(t){var e=this.getSelectedMapKey(t);a.hasOwnProperty(e)||(a[e]=!0)},this),"single"===i.selectedMode){var r=!1;f(n,function(t){var e=this.getSelectedMapKey(t);a[e]&&(r?a[e]=!1:r=!0)},this)}},getSelectedMapKey:function(t){return"categories"===this._mode?t.value+"":t.index+""},getPieceList:function(){return this._pieceList},_determineMode:function(){var t=this.option;return t.pieces&&t.pieces.length>0?"pieces":this.option.categories?"categories":"splitNumber"},setSelected:function(t){this.option.selected=n(t)},getValueState:function(t){var e=kL.findPieceIndex(t,this._pieceList);return null!=e&&this.option.selected[this.getSelectedMapKey(this._pieceList[e])]?"inRange":"outOfRange"},findTargetDataIndices:function(t){var e=[];return this.eachTargetSeries(function(i){var n=[],a=i.getData();a.each(this.getDataDimension(a),function(e,i){var a=kL.findPieceIndex(e,this._pieceList);a===t&&n.push(i)},!0,this),e.push({seriesId:i.id,dataIndex:n})},this),e},getRepresentValue:function(t){var e;if(this.isCategory())e=t.value;else if(null!=t.value)e=t.value;else{var i=t.interval||[];e=i[0]===-1/0&&1/0===i[1]?0:(i[0]+i[1])/2}return e},getVisualMeta:function(t){function e(e,r){var o=a.getRepresentValue({interval:e});r||(r=a.getValueState(o));var s=t(o,r);e[0]===-1/0?n[0]=s:1/0===e[1]?n[1]=s:i.push({value:e[0],color:s},{value:e[1],color:s})}if(!this.isCategory()){var i=[],n=[],a=this,r=this._pieceList.slice();if(r.length){var o=r[0].interval[0];o!==-1/0&&r.unshift({interval:[-1/0,o]}),o=r[r.length-1].interval[1],1/0!==o&&r.push({interval:[o,1/0]})}else r.push({interval:[-1/0,1/0]});var s=-1/0;return f(r,function(t){var i=t.interval;i&&(i[0]>s&&e([s,i[0]],"outOfRange"),e(i.slice()),s=i[1])},this),{stops:i,outerColors:n}}}}),Ak={splitNumber:function(){var t=this.option,e=this._pieceList,i=Math.min(t.precision,20),n=this.getExtent(),a=t.splitNumber;a=Math.max(parseInt(a,10),1),t.splitNumber=a;for(var r=(n[1]-n[0])/a;+r.toFixed(i)!==r&&5>i;)i++;t.precision=i,r=+r.toFixed(i);var o=0;t.minOpen&&e.push({index:o++,interval:[-1/0,n[0]],close:[0,0]});for(var s=n[0],l=o+a;l>o;s+=r){var h=o===a-1?n[1]:s+r;e.push({index:o++,interval:[s,h],close:[1,1]})}t.maxOpen&&e.push({index:o++,interval:[n[1],1/0],close:[0,0]}),Qr(e),f(e,function(t){t.text=this.formatValueText(t.interval)},this)},categories:function(){var t=this.option;f(t.categories,function(t){this._pieceList.push({text:this.formatValueText(t,!0),value:t})},this),Lm(t,this._pieceList)},pieces:function(){var t=this.option,e=this._pieceList;f(t.pieces,function(t,i){M(t)||(t={value:t});var n={text:"",index:i};if(null!=t.label&&(n.text=t.label),t.hasOwnProperty("value")){var a=n.value=t.value;n.interval=[a,a],n.close=[1,1]}else{for(var r=n.interval=[],o=n.close=[0,0],s=[1,0,1],l=[-1/0,1/0],h=[],u=0;2>u;u++){for(var c=[["gte","gt","min"],["lte","lt","max"]][u],d=0;3>d&&null==r[u];d++)r[u]=t[c[d]],o[u]=s[d],h[u]=2===d;null==r[u]&&(r[u]=l[u])}h[0]&&1/0===r[1]&&(o[0]=0),h[1]&&r[0]===-1/0&&(o[1]=0),r[0]===r[1]&&o[0]&&o[1]&&(n.value=r[0])}n.visual=kL.retrieveVisuals(t),e.push(n)},this),Lm(t,e),Qr(e),f(e,function(t){var e=t.close,i=[["<","≤"][e[1]],[">","≥"][e[0]]];t.text=t.text||this.formatValueText(null!=t.value?t.value:t.interval,!1,i)},this)}};mk.extend({type:"visualMap.piecewise",doRender:function(){function t(t){var a=t.piece,h=new xx;h.onclick=y(this._onItemClick,this,a),this._enableHoverLink(h,t.indexInModelPieceList);var u=i.getRepresentValue(a);if(this._createItemSymbol(h,u,[0,0,l[0],l[1]]),c){var d=this.visualMapModel.getValueState(u);h.add(new Pw({style:{x:"right"===s?-n:l[0]+n,y:l[1]/2,text:a.text,textVerticalAlign:"middle",textAlign:s,textFont:r,textFill:o,opacity:"outOfRange"===d?.5:1}}))}e.add(h)}var e=this.group;e.removeAll();var i=this.visualMapModel,n=i.get("textGap"),a=i.textStyleModel,r=a.getFont(),o=a.getTextColor(),s=this._getItemAlign(),l=i.itemSize,h=this._getViewData(),u=h.endsText,c=C(i.get("showLabel",!0),!u);u&&this._renderEndsText(e,u[0],l,c,s),f(h.viewPieceList,t,this),u&&this._renderEndsText(e,u[1],l,c,s),Ib(i.get("orient"),e,i.get("itemGap")),this.renderBackground(e),this.positionGroup(e)},_enableHoverLink:function(t,e){function i(t){var i=this.visualMapModel;i.option.hoverLink&&this.api.dispatchAction({type:t,batch:Mm(i.findTargetDataIndices(e))})}t.on("mouseover",y(i,this,"highlight")).on("mouseout",y(i,this,"downplay"))},_getItemAlign:function(){var t=this.visualMapModel,e=t.option;if("vertical"===e.orient)return bm(t,this.api,t.itemSize);var i=e.align;return i&&"auto"!==i||(i="left"),i},_renderEndsText:function(t,e,i,n,a){if(e){var r=new xx,o=this.visualMapModel.textStyleModel;r.add(new Pw({style:{x:n?"right"===a?i[0]:0:i[0]/2,y:i[1]/2,textVerticalAlign:"middle",textAlign:n?a:"center",text:e,textFont:o.getFont(),textFill:o.getTextColor()}})),t.add(r)}},_getViewData:function(){var t=this.visualMapModel,e=p(t.getPieceList(),function(t,e){return{piece:t,indexInModelPieceList:e}}),i=t.get("text"),n=t.get("orient"),a=t.get("inverse");return("horizontal"===n?a:!a)?e.reverse():i&&(i=i.slice().reverse()),{viewPieceList:e,endsText:i}},_createItemSymbol:function(t,e,i){t.add(zh(this.getControllerVisual(e,"symbol"),i[0],i[1],i[2],i[3],this.getControllerVisual(e,"color")))},_onItemClick:function(t){var e=this.visualMapModel,i=e.option,a=n(i.selected),r=e.getSelectedMapKey(t);"single"===i.selectedMode?(a[r]=!0,f(a,function(t,e){a[e]=e===r})):a[r]=!a[r],this.api.dispatchAction({type:"selectDataRange",from:this.uid,visualMapId:this.visualMapModel.id,selected:a})}})}Sl(nk);var Ck=zl({type:"toolbox",layoutMode:{type:"box",ignoreSize:!0},mergeDefaultAndTheme:function(){Ck.superApply(this,"mergeDefaultAndTheme",arguments),f(this.option.feature,function(t,e){var i=mm(e);i&&a(t,i.defaultOption)})},defaultOption:{show:!0,z:6,zlevel:0,orient:"horizontal",left:"right",top:"top",backgroundColor:"transparent",borderColor:"#ccc",borderRadius:0,borderWidth:0,padding:5,itemSize:15,itemGap:8,showTitle:!0,iconStyle:{borderColor:"#666",color:"none"},emphasis:{iconStyle:{borderColor:"#3E98C5"}}}});El({type:"toolbox",render:function(t,e,i,n){function a(a,o){var s,c=u[a],d=u[o],f=l[c],p=new Pr(f,t,t.ecModel);if(c&&!d){if(km(c))s={model:p,onclick:p.option.onclick,featureName:c};else{var g=mm(c);if(!g)return;s=new g(p,e,i)}h[c]=s}else{if(s=h[d],!s)return;s.model=p,s.ecModel=e,s.api=i}return!c&&d?void(s.dispose&&s.dispose(e,i)):!p.get("show")||s.unusable?void(s.remove&&s.remove(e,i)):(r(p,s,c),p.setIconStatus=function(t,e){var i=this.option,n=this.iconPaths;i.iconStatus=i.iconStatus||{},i.iconStatus[t]=e,n[t]&&n[t].trigger(e)},void(s.render&&s.render(p,e,i,n)))}function r(n,a,r){var l=n.getModel("iconStyle"),h=n.getModel("emphasis.iconStyle"),u=a.getIcons?a.getIcons():n.get("icon"),c=n.get("title")||{};if("string"==typeof u){var d=u,p=c;u={},c={},u[r]=d,c[r]=p}var g=n.iconPaths={};f(u,function(r,u){var d=kr(r,{},{x:-s/2,y:-s/2,width:s,height:s});d.setStyle(l.getItemStyle()),d.hoverStyle=h.getItemStyle(),cr(d),t.get("showTitle")&&(d.__title=c[u],d.on("mouseover",function(){var t=h.getItemStyle();d.setStyle({text:c[u],textPosition:t.textPosition||"bottom",textFill:t.fill||t.stroke||"#000",textAlign:t.textAlign||"center"})}).on("mouseout",function(){d.setStyle({textFill:null})})),d.trigger(n.get("iconStatus."+u)||"normal"),o.add(d),d.on("click",y(a.onclick,a,e,i,u)),g[u]=d})}var o=this.group;if(o.removeAll(),t.get("show")){var s=+t.get("itemSize"),l=t.get("feature")||{},h=this._features||(this._features={}),u=[];f(l,function(t,e){u.push(e)}),new Wl(this._featureNames||[],u).add(a).update(a).remove(x(a,null)).execute(),this._featureNames=u,pg(o,t,i),o.add(gg(o.getBoundingRect(),t)),o.eachChild(function(t){var e=t.__title,n=t.hoverStyle;if(n&&e){var a=Mi(e,Bi(n)),r=t.position[0]+o.position[0],l=t.position[1]+o.position[1]+s,h=!1;l+a.height>i.getHeight()&&(n.textPosition="top",h=!0);var u=h?-5-a.height:s+8;r+a.width/2>i.getWidth()?(n.textPosition=["100%",u],n.textAlign="right"):r-a.width/2<0&&(n.textPosition=[0,u],n.textAlign="left")}})}},updateView:function(t,e,i,n){f(this._features,function(t){t.updateView&&t.updateView(t.model,e,i,n)})},remove:function(t,e){f(this._features,function(i){i.remove&&i.remove(t,e)}),this.group.removeAll()},dispose:function(t,e){f(this._features,function(i){i.dispose&&i.dispose(t,e)})}});var Dk=SM.toolbox.saveAsImage;Pm.defaultOption={show:!0,icon:"M4.7,22.9L29.3,45.5L54.7,23.4M4.6,43.6L4.6,58L53.8,58L53.8,43.6M29.2,45.1L29.2,0",title:Dk.title,type:"png",name:"",excludeComponents:["toolbox"],pixelRatio:1,lang:Dk.lang.slice()},Pm.prototype.unusable=!vy.canvasSupported;var Lk=Pm.prototype;Lk.onclick=function(t,e){var i=this.model,n=i.get("name")||t.get("title.0.text")||"echarts",a=document.createElement("a"),r=i.get("type",!0)||"png";a.download=n+"."+r,a.target="_blank";var o=e.getConnectedDataURL({type:r,backgroundColor:i.get("backgroundColor",!0)||t.get("backgroundColor")||"#fff",excludeComponents:i.get("excludeComponents"),pixelRatio:i.get("pixelRatio")});if(a.href=o,"function"!=typeof MouseEvent||vy.browser.ie||vy.browser.edge)if(window.navigator.msSaveOrOpenBlob){for(var s=atob(o.split(",")[1]),l=s.length,h=new Uint8Array(l);l--;)h[l]=s.charCodeAt(l);var u=new Blob([h]);window.navigator.msSaveOrOpenBlob(u,n+"."+r)}else{var c=i.get("lang"),d='<body style="margin:0;"><img src="'+o+'" style="max-width:100%;" title="'+(c&&c[0]||"")+'" /></body>',f=window.open();f.document.write(d)}else{var p=new MouseEvent("click",{view:window,bubbles:!0,cancelable:!1});a.dispatchEvent(p)}},vm("saveAsImage",Pm);var kk=SM.toolbox.magicType;Om.defaultOption={show:!0,type:[],icon:{line:"M4.1,28.9h7.1l9.3-22l7.4,38l9.7-19.7l3,12.8h14.9M4.1,58h51.4",bar:"M6.7,22.9h10V48h-10V22.9zM24.9,13h10v35h-10V13zM43.2,2h10v46h-10V2zM3.1,58h53.7",stack:"M8.2,38.4l-8.4,4.1l30.6,15.3L60,42.5l-8.1-4.1l-21.5,11L8.2,38.4z M51.9,30l-8.1,4.2l-13.4,6.9l-13.9-6.9L8.2,30l-8.4,4.2l8.4,4.2l22.2,11l21.5-11l8.1-4.2L51.9,30z M51.9,21.7l-8.1,4.2L35.7,30l-5.3,2.8L24.9,30l-8.4-4.1l-8.3-4.2l-8.4,4.2L8.2,30l8.3,4.2l13.9,6.9l13.4-6.9l8.1-4.2l8.1-4.1L51.9,21.7zM30.4,2.2L-0.2,17.5l8.4,4.1l8.3,4.2l8.4,4.2l5.5,2.7l5.3-2.7l8.1-4.2l8.1-4.2l8.1-4.1L30.4,2.2z",tiled:"M2.3,2.2h22.8V25H2.3V2.2z M35,2.2h22.8V25H35V2.2zM2.3,35h22.8v22.8H2.3V35z M35,35h22.8v22.8H35V35z"},title:n(kk.title),option:{},seriesIndex:{}};var Pk=Om.prototype;Pk.getIcons=function(){var t=this.model,e=t.get("icon"),i={};return f(t.get("type"),function(t){e[t]&&(i[t]=e[t])}),i};var Ok={line:function(t,e,i,n){return"bar"===t?a({id:e,type:"line",data:i.get("data"),stack:i.get("stack"),markPoint:i.get("markPoint"),markLine:i.get("markLine")},n.get("option.line")||{},!0):void 0},bar:function(t,e,i,n){return"line"===t?a({id:e,type:"bar",data:i.get("data"),stack:i.get("stack"),markPoint:i.get("markPoint"),markLine:i.get("markLine")},n.get("option.bar")||{},!0):void 0},stack:function(t,e,i,n){return"line"===t||"bar"===t?a({id:e,stack:"__ec_magicType_stack__"},n.get("option.stack")||{},!0):void 0},tiled:function(t,e,i,n){return"line"===t||"bar"===t?a({id:e,stack:""},n.get("option.tiled")||{},!0):void 0}},zk=[["line","bar"],["stack","tiled"]];Pk.onclick=function(t,e,i){var n=this.model,a=n.get("seriesIndex."+i);if(Ok[i]){var r={series:[]},o=function(e){var a=e.subType,o=e.id,l=Ok[i](a,o,e,n);l&&(s(l,e.option),r.series.push(l));var h=e.coordinateSystem;if(h&&"cartesian2d"===h.type&&("line"===i||"bar"===i)){var u=h.getAxesByScale("ordinal")[0];if(u){var c=u.dim,d=c+"Axis",f=t.queryComponents({mainType:d,index:e.get(name+"Index"),id:e.get(name+"Id")})[0],p=f.componentIndex;r[d]=r[d]||[];for(var g=0;p>=g;g++)r[d][p]=r[d][p]||{};r[d][p].boundaryGap="bar"===i?!0:!1}}};f(zk,function(t){h(t,i)>=0&&f(t,function(t){n.setIconStatus(t,"normal")})}),n.setIconStatus(i,"emphasis"),t.eachComponent({mainType:"series",query:null==a?null:{seriesIndex:a}},o),e.dispatchAction({type:"changeMagicType",currentType:i,newOption:r})}},Al({type:"changeMagicType",event:"magicTypeChanged",update:"prepareAndUpdate"},function(t,e){e.mergeOption(t.newOption)}),vm("magicType",Om);var Ek=SM.toolbox.dataView,Rk=new Array(60).join("-"),Nk="    ",Bk=new RegExp("["+Nk+"]+","g");Hm.defaultOption={show:!0,readOnly:!1,optionToContent:null,contentToOption:null,icon:"M17.5,17.3H33 M17.5,17.3H33 M45.4,29.5h-28 M11.5,2v56H51V14.8L38.4,2H11.5z M38.4,2.2v12.7H51 M45.4,41.7h-28",title:n(Ek.title),lang:n(Ek.lang),backgroundColor:"#fff",textColor:"#000",textareaColor:"#fff",textareaBorderColor:"#333",buttonColor:"#c23531",buttonTextColor:"#fff"},Hm.prototype.onclick=function(t,e){function i(){n.removeChild(r),x._dom=null}var n=e.getDom(),a=this.model;this._dom&&n.removeChild(this._dom);var r=document.createElement("div");r.style.cssText="position:absolute;left:5px;top:5px;bottom:5px;right:5px;",r.style.backgroundColor=a.get("backgroundColor")||"#fff";var o=document.createElement("h4"),s=a.get("lang")||[];o.innerHTML=s[0]||a.get("title"),o.style.cssText="margin: 10px 20px;",o.style.color=a.get("textColor");var l=document.createElement("div"),h=document.createElement("textarea");l.style.cssText="display:block;width:100%;overflow:auto;";var u=a.get("optionToContent"),c=a.get("contentToOption"),d=Nm(t);if("function"==typeof u){var f=u(e.getOption());"string"==typeof f?l.innerHTML=f:T(f)&&l.appendChild(f)}else l.appendChild(h),h.readOnly=a.get("readOnly"),h.style.cssText="width:100%;height:100%;font-family:monospace;font-size:14px;line-height:1.6rem;",h.style.color=a.get("textColor"),h.style.borderColor=a.get("textareaBorderColor"),h.style.backgroundColor=a.get("textareaColor"),h.value=d.value;var p=d.meta,g=document.createElement("div");g.style.cssText="position:absolute;bottom:0;left:0;right:0;";var v="float:right;margin-right:20px;border:none;cursor:pointer;padding:2px 5px;font-size:12px;border-radius:3px",m=document.createElement("div"),y=document.createElement("div");v+=";background-color:"+a.get("buttonColor"),v+=";color:"+a.get("buttonTextColor");var x=this;mn(m,"click",i),mn(y,"click",function(){var t;try{t="function"==typeof c?c(l,e.getOption()):Wm(h.value,p)}catch(n){throw i(),new Error("Data view format error "+n)}t&&e.dispatchAction({type:"changeDataView",newOption:t}),i()}),m.innerHTML=s[1],y.innerHTML=s[2],y.style.cssText=v,m.style.cssText=v,!a.get("readOnly")&&g.appendChild(y),g.appendChild(m),mn(h,"keydown",function(t){if(9===(t.keyCode||t.which)){var e=this.value,i=this.selectionStart,n=this.selectionEnd;this.value=e.substring(0,i)+Nk+e.substring(n),this.selectionStart=this.selectionEnd=i+1,t_(t)}}),r.appendChild(o),r.appendChild(l),r.appendChild(g),l.style.height=n.clientHeight-80+"px",n.appendChild(r),this._dom=r},Hm.prototype.remove=function(t,e){this._dom&&e.getDom().removeChild(this._dom)},Hm.prototype.dispose=function(t,e){this.remove(t,e)},vm("dataView",Hm),Al({type:"changeDataView",event:"dataViewChanged",update:"prepareAndUpdate"},function(t,e){var i=[];f(t.newOption.series,function(t){var n=e.getSeriesByName(t.name)[0];if(n){var a=n.get("data");i.push({name:t.name,data:Zm(t.data,a)})}else i.push(o({type:"scatter"},t))}),e.mergeOption(s({series:i},t.newOption))});var Vk=f,Gk="\x00_ec_hist_store";oL.extend({type:"dataZoom.select"}),sL.extend({type:"dataZoom.select"});var Fk=SM.toolbox.dataZoom,Wk=f,Hk="\x00_ec_\x00toolbox-dataZoom_";$m.defaultOption={show:!0,icon:{zoom:"M0,13.5h26.9 M13.5,26.9V0 M32.1,13.5H58V58H13.5 V32.1",back:"M22,1.4L9.9,13.5l12.3,12.3 M10.3,13.5H54.9v44.6 H10.3v-26"},title:n(Fk.title)};var Zk=$m.prototype;Zk.render=function(t,e,i,n){this.model=t,this.ecModel=e,this.api=i,Qm(t,e,this,n,i),Jm(t,e)},Zk.onclick=function(t,e,i){jk[i].call(this)},Zk.remove=function(){this._brushController.unmount()},Zk.dispose=function(){this._brushController.dispose()};var jk={zoom:function(){var t=!this._isZoomActive;this.api.dispatchAction({type:"takeGlobalCursor",key:"dataZoomSelect",dataZoomSelectActive:t})},back:function(){this._dispatchZoomAction(Xm(this.ecModel))}};Zk._onBrush=function(t,e){function i(t,e,i){var o=e.getAxis(t),s=o.model,l=n(t,s,r),h=l.findRepresentativeAxisProxy(s).getMinMaxSpan();(null!=h.minValueSpan||null!=h.maxValueSpan)&&(i=SA(0,i.slice(),o.scale.getExtent(),0,h.minValueSpan,h.maxValueSpan)),l&&(a[l.id]={dataZoomId:l.id,startValue:i[0],endValue:i[1]})}function n(t,e,i){var n;return i.eachComponent({mainType:"dataZoom",subType:"select"},function(i){var a=i.getAxisModel(t,e.componentIndex);a&&(n=i)}),n}if(e.isEnd&&t.length){var a={},r=this.ecModel;this._brushController.updateCovers([]);var o=new tm(Km(this.model.option),r,{include:["grid"]});o.matchOutputRanges(t,r,function(t,e,n){if("cartesian2d"===n.type){var a=t.brushType;"rect"===a?(i("x",n,e[0]),i("y",n,e[1])):i({lineX:"x",lineY:"y"}[a],n,e)}}),jm(r,a),this._dispatchZoomAction(a)}},Zk._dispatchZoomAction=function(t){var e=[];Wk(t,function(t){e.push(n(t))}),e.length&&this.api.dispatchAction({type:"dataZoom",from:this.uid,batch:e})},vm("dataZoom",$m),Sl(function(t){function e(t,e){if(e){var a=t+"Index",r=e[a];null==r||"all"==r||_(r)||(r=r===!1||"none"===r?[]:[r]),i(t,function(e,i){if(null==r||"all"==r||-1!==h(r,i)){var o={type:"select",$fromToolbox:!0,id:Hk+t+i};o[a]=i,n.push(o)}})}}function i(e,i){var n=t[e];_(n)||(n=n?[n]:[]),Wk(n,i)}if(t){var n=t.dataZoom||(t.dataZoom=[]);_(n)||(t.dataZoom=n=[n]);var a=t.toolbox;if(a&&(_(a)&&(a=a[0]),a&&a.feature)){var r=a.feature.dataZoom;e("xAxis",r),e("yAxis",r)}}});var Xk=SM.toolbox.restore;ty.defaultOption={show:!0,icon:"M3.8,33.4 M47,18.9h9.8V8.7 M56.3,20.1 C52.1,9,40.5,0.6,26.8,2.1C12.6,3.7,1.6,16.2,2.1,30.6 M13,41.1H3.1v10.2 M3.7,39.9c4.2,11.1,15.8,19.5,29.5,18 c14.2-1.6,25.2-14.1,24.7-28.5",title:Xk.title};var Uk=ty.prototype;Uk.onclick=function(t,e){Um(t),e.dispatchAction({type:"restore",from:this.uid})},vm("restore",ty),Al({type:"restore",event:"restore",update:"prepareAndUpdate"},function(t,e){e.resetOption("recreate")}),Sl(function(t){var e=t.graphic;_(e)?t.graphic=e[0]&&e[0].elements?[t.graphic[0]]:[{elements:e}]:e&&!e.elements&&(t.graphic=[{elements:[e]}])});var Yk=zl({type:"graphic",defaultOption:{elements:[],parentId:null},_elOptionsToUpdate:null,mergeOption:function(){var t=this.option.elements;this.option.elements=null,Yk.superApply(this,"mergeOption",arguments),this.option.elements=t},optionUpdated:function(t,e){var i=this.option,n=(e?i:t).elements,a=i.elements=e?[]:i.elements,r=[];this._flatten(n,r);var o=Nn(a,r);Bn(o);var s=this._elOptionsToUpdate=[];f(o,function(t,e){var i=t.option;i&&(s.push(i),ry(t,i),oy(a,e,i),sy(a[e],i))},this);for(var l=a.length-1;l>=0;l--)null==a[l]?a.splice(l,1):delete a[l].$action},_flatten:function(t,e,i){f(t,function(t){if(t){i&&(t.parentOption=i),e.push(t);var n=t.children;"group"===t.type&&n&&this._flatten(n,e,t),delete t.children}},this)},useElOptionsToUpdate:function(){var t=this._elOptionsToUpdate;return this._elOptionsToUpdate=null,t}});El({type:"graphic",init:function(){this._elMap=B(),this._lastGraphicModel},render:function(t,e,i){t!==this._lastGraphicModel&&this._clear(),this._lastGraphicModel=t,this._updateElements(t,i),this._relocate(t,i)},_updateElements:function(t){var e=t.useElOptionsToUpdate();if(e){var i=this._elMap,n=this.group;f(e,function(t){var e=t.$action,a=t.id,r=i.get(a),o=t.parentId,s=null!=o?i.get(o):n;if("text"===t.type){var l=t.style;t.hv&&t.hv[1]&&(l.textVerticalAlign=l.textBaseline=null),!l.hasOwnProperty("textFill")&&l.fill&&(l.textFill=l.fill),!l.hasOwnProperty("textStroke")&&l.stroke&&(l.textStroke=l.stroke)}var h=ny(t);e&&"merge"!==e?"replace"===e?(iy(r,i),ey(a,s,h,i)):"remove"===e&&iy(r,i):r?r.attr(h):ey(a,s,h,i);var u=i.get(a);u&&(u.__ecGraphicWidth=t.width,u.__ecGraphicHeight=t.height)})}},_relocate:function(t,e){for(var i=t.option.elements,n=this.group,a=this._elMap,r=i.length-1;r>=0;r--){var o=i[r],s=a.get(o.id);if(s){var l=s.parent,h=l===n?{width:e.getWidth(),height:e.getHeight()}:{width:l.__ecGraphicWidth||0,height:l.__ecGraphicHeight||0};co(s,o,h,null,{hv:o.hv,boundingMode:o.bounding})}}},_clear:function(){var t=this._elMap;t.each(function(e){iy(e,t)}),this._elMap=B()},dispose:function(){this._clear()}});var qk,$k="urn:schemas-microsoft-com:vml",Kk="undefined"==typeof window?null:window,Jk=!1,Qk=Kk&&Kk.document;if(Qk&&!vy.canvasSupported)try{!Qk.namespaces.zrvml&&Qk.namespaces.add("zrvml",$k),qk=function(t){return Qk.createElement("<zrvml:"+t+' class="zrvml">')}}catch(tP){qk=function(t){return Qk.createElement("<"+t+' xmlns="'+$k+'" class="zrvml">')}}var eP=lw.CMD,iP=Math.round,nP=Math.sqrt,aP=Math.abs,rP=Math.cos,oP=Math.sin,sP=Math.max;if(!vy.canvasSupported){var lP=",",hP="progid:DXImageTransform.Microsoft",uP=21600,cP=uP/2,dP=1e5,fP=1e3,pP=function(t){t.style.cssText="position:absolute;left:0;top:0;width:1px;height:1px;",t.coordsize=uP+","+uP,t.coordorigin="0,0"},gP=function(t){return String(t).replace(/&/g,"&amp;").replace(/"/g,"&quot;")},vP=function(t,e,i){return"rgb("+[t,e,i].join(",")+")"},mP=function(t,e){e&&t&&e.parentNode!==t&&t.appendChild(e)},yP=function(t,e){e&&t&&e.parentNode===t&&t.removeChild(e)},xP=function(t,e,i){return(parseFloat(t)||0)*dP+(parseFloat(e)||0)*fP+i},_P=function(t,e){return"string"==typeof t?t.lastIndexOf("%")>=0?parseFloat(t)/100*e:parseFloat(t):t},wP=function(t,e,i){var n=ze(e);i=+i,isNaN(i)&&(i=1),n&&(t.color=vP(n[0],n[1],n[2]),t.opacity=i*n[3])},bP=function(t){var e=ze(t);return[vP(e[0],e[1],e[2]),e[3]]},MP=function(t,e,i){var n=e.fill;if(null!=n)if(n instanceof Yw){var a,r=0,o=[0,0],s=0,l=1,h=i.getBoundingRect(),u=h.width,c=h.height;if("linear"===n.type){a="gradient";var d=i.transform,f=[n.x*u,n.y*c],p=[n.x2*u,n.y2*c];d&&(re(f,f,d),re(p,p,d));var g=p[0]-f[0],v=p[1]-f[1];r=180*Math.atan2(g,v)/Math.PI,0>r&&(r+=360),1e-6>r&&(r=0)}else{a="gradientradial";var f=[n.x*u,n.y*c],d=i.transform,m=i.scale,y=u,x=c;o=[(f[0]-h.x)/y,(f[1]-h.y)/x],d&&re(f,f,d),y/=m[0]*uP,x/=m[1]*uP;var _=sP(y,x);s=0/_,l=2*n.r/_-s}var w=n.colorStops.slice();w.sort(function(t,e){return t.offset-e.offset});for(var b=w.length,M=[],S=[],I=0;b>I;I++){var T=w[I],A=bP(T.color);S.push(T.offset*l+s+" "+A[0]),(0===I||I===b-1)&&M.push(A)}if(b>=2){var C=M[0][0],D=M[1][0],L=M[0][1]*e.opacity,k=M[1][1]*e.opacity;t.type=a,t.method="none",t.focus="100%",t.angle=r,t.color=C,t.color2=D,t.colors=S.join(","),t.opacity=k,t.opacity2=L}"radial"===a&&(t.focusposition=o.join(","))}else wP(t,n,e.opacity)},SP=function(t,e){null!=e.lineDash&&(t.dashstyle=e.lineDash.join(" ")),null==e.stroke||e.stroke instanceof Yw||wP(t,e.stroke,e.opacity)},IP=function(t,e,i,n){var a="fill"==e,r=t.getElementsByTagName(e)[0];null!=i[e]&&"none"!==i[e]&&(a||!a&&i.lineWidth)?(t[a?"filled":"stroked"]="true",i[e]instanceof Yw&&yP(t,r),r||(r=ly(e)),a?MP(r,i,n):SP(r,i),mP(t,r)):(t[a?"filled":"stroked"]="false",yP(t,r))},TP=[[],[],[]],AP=function(t,e){var i,n,a,r,o,s,l=eP.M,h=eP.C,u=eP.L,c=eP.A,d=eP.Q,f=[],p=t.data,g=t.len();for(r=0;g>r;){switch(a=p[r++],n="",i=0,a){case l:n=" m ",i=1,o=p[r++],s=p[r++],TP[0][0]=o,TP[0][1]=s;break;case u:n=" l ",i=1,o=p[r++],s=p[r++],TP[0][0]=o,TP[0][1]=s;break;case d:case h:n=" c ",i=3;var v,m,y=p[r++],x=p[r++],_=p[r++],w=p[r++];a===d?(v=_,m=w,_=(_+2*y)/3,w=(w+2*x)/3,y=(o+2*y)/3,x=(s+2*x)/3):(v=p[r++],m=p[r++]),TP[0][0]=y,TP[0][1]=x,TP[1][0]=_,TP[1][1]=w,TP[2][0]=v,TP[2][1]=m,o=v,s=m;break;case c:var b=0,M=0,S=1,I=1,T=0;e&&(b=e[4],M=e[5],S=nP(e[0]*e[0]+e[1]*e[1]),I=nP(e[2]*e[2]+e[3]*e[3]),T=Math.atan2(-e[1]/I,e[0]/S));var A=p[r++],C=p[r++],D=p[r++],L=p[r++],k=p[r++]+T,P=p[r++]+k+T;r++;var O=p[r++],z=A+rP(k)*D,E=C+oP(k)*L,y=A+rP(P)*D,x=C+oP(P)*L,R=O?" wa ":" at ";Math.abs(z-y)<1e-4&&(Math.abs(P-k)>.01?O&&(z+=270/uP):Math.abs(E-C)<1e-4?O&&A>z||!O&&z>A?x-=270/uP:x+=270/uP:O&&C>E||!O&&E>C?y+=270/uP:y-=270/uP),f.push(R,iP(((A-D)*S+b)*uP-cP),lP,iP(((C-L)*I+M)*uP-cP),lP,iP(((A+D)*S+b)*uP-cP),lP,iP(((C+L)*I+M)*uP-cP),lP,iP((z*S+b)*uP-cP),lP,iP((E*I+M)*uP-cP),lP,iP((y*S+b)*uP-cP),lP,iP((x*I+M)*uP-cP)),o=y,s=x;break;case eP.R:var N=TP[0],B=TP[1];
-N[0]=p[r++],N[1]=p[r++],B[0]=N[0]+p[r++],B[1]=N[1]+p[r++],e&&(re(N,N,e),re(B,B,e)),N[0]=iP(N[0]*uP-cP),B[0]=iP(B[0]*uP-cP),N[1]=iP(N[1]*uP-cP),B[1]=iP(B[1]*uP-cP),f.push(" m ",N[0],lP,N[1]," l ",B[0],lP,N[1]," l ",B[0],lP,B[1]," l ",N[0],lP,B[1]);break;case eP.Z:f.push(" x ")}if(i>0){f.push(n);for(var V=0;i>V;V++){var G=TP[V];e&&re(G,G,e),f.push(iP(G[0]*uP-cP),lP,iP(G[1]*uP-cP),i-1>V?lP:"")}}}return f.join("")};Oa.prototype.brushVML=function(t){var e=this.style,i=this._vmlEl;i||(i=ly("shape"),pP(i),this._vmlEl=i),IP(i,"fill",e,this),IP(i,"stroke",e,this);var n=this.transform,a=null!=n,r=i.getElementsByTagName("stroke")[0];if(r){var o=e.lineWidth;if(a&&!e.strokeNoScale){var s=n[0]*n[3]-n[1]*n[2];o*=nP(aP(s))}r.weight=o+"px"}var l=this.path||(this.path=new lw);this.__dirtyPath&&(l.beginPath(),this.buildPath(l,this.shape),l.toStatic(),this.__dirtyPath=!1),i.path=AP(l,this.transform),i.style.zIndex=xP(this.zlevel,this.z,this.z2),mP(t,i),null!=e.text?this.drawRectText(t,this.getBoundingRect()):this.removeRectText(t)},Oa.prototype.onRemove=function(t){yP(t,this._vmlEl),this.removeRectText(t)},Oa.prototype.onAdd=function(t){mP(t,this._vmlEl),this.appendRectText(t)};var CP=function(t){return"object"==typeof t&&t.tagName&&"IMG"===t.tagName.toUpperCase()};on.prototype.brushVML=function(t){var e,i,n=this.style,a=n.image;if(CP(a)){var r=a.src;if(r===this._imageSrc)e=this._imageWidth,i=this._imageHeight;else{var o=a.runtimeStyle,s=o.width,l=o.height;o.width="auto",o.height="auto",e=a.width,i=a.height,o.width=s,o.height=l,this._imageSrc=r,this._imageWidth=e,this._imageHeight=i}a=r}else a===this._imageSrc&&(e=this._imageWidth,i=this._imageHeight);if(a){var h=n.x||0,u=n.y||0,c=n.width,d=n.height,f=n.sWidth,p=n.sHeight,g=n.sx||0,v=n.sy||0,m=f&&p,y=this._vmlEl;y||(y=Qk.createElement("div"),pP(y),this._vmlEl=y);var x,_=y.style,w=!1,b=1,M=1;if(this.transform&&(x=this.transform,b=nP(x[0]*x[0]+x[1]*x[1]),M=nP(x[2]*x[2]+x[3]*x[3]),w=x[1]||x[2]),w){var S=[h,u],I=[h+c,u],T=[h,u+d],A=[h+c,u+d];re(S,S,x),re(I,I,x),re(T,T,x),re(A,A,x);var C=sP(S[0],I[0],T[0],A[0]),D=sP(S[1],I[1],T[1],A[1]),L=[];L.push("M11=",x[0]/b,lP,"M12=",x[2]/M,lP,"M21=",x[1]/b,lP,"M22=",x[3]/M,lP,"Dx=",iP(h*b+x[4]),lP,"Dy=",iP(u*M+x[5])),_.padding="0 "+iP(C)+"px "+iP(D)+"px 0",_.filter=hP+".Matrix("+L.join("")+", SizingMethod=clip)"}else x&&(h=h*b+x[4],u=u*M+x[5]),_.filter="",_.left=iP(h)+"px",_.top=iP(u)+"px";var k=this._imageEl,P=this._cropEl;k||(k=Qk.createElement("div"),this._imageEl=k);var O=k.style;if(m){if(e&&i)O.width=iP(b*e*c/f)+"px",O.height=iP(M*i*d/p)+"px";else{var z=new Image,E=this;z.onload=function(){z.onload=null,e=z.width,i=z.height,O.width=iP(b*e*c/f)+"px",O.height=iP(M*i*d/p)+"px",E._imageWidth=e,E._imageHeight=i,E._imageSrc=a},z.src=a}P||(P=Qk.createElement("div"),P.style.overflow="hidden",this._cropEl=P);var R=P.style;R.width=iP((c+g*c/f)*b),R.height=iP((d+v*d/p)*M),R.filter=hP+".Matrix(Dx="+-g*c/f*b+",Dy="+-v*d/p*M+")",P.parentNode||y.appendChild(P),k.parentNode!=P&&P.appendChild(k)}else O.width=iP(b*c)+"px",O.height=iP(M*d)+"px",y.appendChild(k),P&&P.parentNode&&(y.removeChild(P),this._cropEl=null);var N="",B=n.opacity;1>B&&(N+=".Alpha(opacity="+iP(100*B)+") "),N+=hP+".AlphaImageLoader(src="+a+", SizingMethod=scale)",O.filter=N,y.style.zIndex=xP(this.zlevel,this.z,this.z2),mP(t,y),null!=n.text&&this.drawRectText(t,this.getBoundingRect())}},on.prototype.onRemove=function(t){yP(t,this._vmlEl),this._vmlEl=null,this._cropEl=null,this._imageEl=null,this.removeRectText(t)},on.prototype.onAdd=function(t){mP(t,this._vmlEl),this.appendRectText(t)};var DP,LP="normal",kP={},PP=0,OP=100,zP=document.createElement("div"),EP=function(t){var e=kP[t];if(!e){PP>OP&&(PP=0,kP={});var i,n=zP.style;try{n.font=t,i=n.fontFamily.split(",")[0]}catch(a){}e={style:n.fontStyle||LP,variant:n.fontVariant||LP,weight:n.fontWeight||LP,size:0|parseFloat(n.fontSize||12),family:i||"Microsoft YaHei"},kP[t]=e,PP++}return e};wi("measureText",function(t,e){var i=Qk;DP||(DP=i.createElement("div"),DP.style.cssText="position:absolute;top:-20000px;left:0;padding:0;margin:0;border:none;white-space:pre;",Qk.body.appendChild(DP));try{DP.style.font=e}catch(n){}return DP.innerHTML="",DP.appendChild(i.createTextNode(t)),{width:DP.offsetWidth}});for(var RP=new ni,NP=function(t,e,i,n){var a=this.style;this.__dirty&&Gi(a,!0);var r=a.text;if(null!=r&&(r+=""),r){if(a.rich){var o=Ri(r,a);r=[];for(var s=0;s<o.lines.length;s++){for(var l=o.lines[s].tokens,h=[],u=0;u<l.length;u++)h.push(l[u].text);r.push(h.join(""))}r=r.join("\n")}var c,d,f=a.textAlign,p=a.textVerticalAlign,g=EP(a.font),v=g.style+" "+g.variant+" "+g.weight+" "+g.size+'px "'+g.family+'"';i=i||Mi(r,v,f,p);var m=this.transform;if(m&&!n&&(RP.copy(e),RP.applyTransform(m),e=RP),n)c=e.x,d=e.y;else{var y=a.textPosition,x=a.textDistance;if(y instanceof Array)c=e.x+_P(y[0],e.width),d=e.y+_P(y[1],e.height),f=f||"left";else{var _=Ci(y,e,x);c=_.x,d=_.y,f=f||_.textAlign,p=p||_.textVerticalAlign}}c=Ti(c,i.width,f),d=Ai(d,i.height,p),d+=i.height/2;var w,b,M,S=ly,I=this._textVmlEl;I?(M=I.firstChild,w=M.nextSibling,b=w.nextSibling):(I=S("line"),w=S("path"),b=S("textpath"),M=S("skew"),b.style["v-text-align"]="left",pP(I),w.textpathok=!0,b.on=!0,I.from="0 0",I.to="1000 0.05",mP(I,M),mP(I,w),mP(I,b),this._textVmlEl=I);var T=[c,d],A=I.style;m&&n?(re(T,T,m),M.on=!0,M.matrix=m[0].toFixed(3)+lP+m[2].toFixed(3)+lP+m[1].toFixed(3)+lP+m[3].toFixed(3)+",0,0",M.offset=(iP(T[0])||0)+","+(iP(T[1])||0),M.origin="0 0",A.left="0px",A.top="0px"):(M.on=!1,A.left=iP(c)+"px",A.top=iP(d)+"px"),b.string=gP(r);try{b.style.font=v}catch(C){}IP(I,"fill",{fill:a.textFill,opacity:a.opacity},this),IP(I,"stroke",{stroke:a.textStroke,opacity:a.opacity,lineDash:a.lineDash},this),I.style.zIndex=xP(this.zlevel,this.z,this.z2),mP(t,I)}},BP=function(t){yP(t,this._textVmlEl),this._textVmlEl=null},VP=function(t){mP(t,this._textVmlEl)},GP=[Zx,rn,on,Oa,Pw],FP=0;FP<GP.length;FP++){var WP=GP[FP].prototype;WP.drawRectText=NP,WP.removeRectText=BP,WP.appendRectText=VP}Pw.prototype.brushVML=function(t){var e=this.style;null!=e.text?this.drawRectText(t,{x:e.x||0,y:e.y||0,width:0,height:0},this.getBoundingRect(),!0):this.removeRectText(t)},Pw.prototype.onRemove=function(t){this.removeRectText(t)},Pw.prototype.onAdd=function(t){this.appendRectText(t)}}cy.prototype={constructor:cy,getType:function(){return"vml"},getViewportRoot:function(){return this._vmlViewport},getViewportRootOffset:function(){var t=this.getViewportRoot();return t?{offsetLeft:t.offsetLeft||0,offsetTop:t.offsetTop||0}:void 0},refresh:function(){var t=this.storage.getDisplayList(!0,!0);this._paintList(t)},_paintList:function(t){for(var e=this._vmlRoot,i=0;i<t.length;i++){var n=t[i];n.invisible||n.ignore?(n.__alreadyNotVisible||n.onRemove(e),n.__alreadyNotVisible=!0):(n.__alreadyNotVisible&&n.onAdd(e),n.__alreadyNotVisible=!1,n.__dirty&&(n.beforeBrush&&n.beforeBrush(),(n.brushVML||n.brush).call(n,e),n.afterBrush&&n.afterBrush())),n.__dirty=!1}this._firstPaint&&(this._vmlViewport.appendChild(e),this._firstPaint=!1)},resize:function(t,e){var t=null==t?this._getWidth():t,e=null==e?this._getHeight():e;if(this._width!=t||this._height!=e){this._width=t,this._height=e;var i=this._vmlViewport.style;i.width=t+"px",i.height=e+"px"}},dispose:function(){this.root.innerHTML="",this._vmlRoot=this._vmlViewport=this.storage=null},getWidth:function(){return this._width},getHeight:function(){return this._height},clear:function(){this._vmlViewport&&this.root.removeChild(this._vmlViewport)},_getWidth:function(){var t=this.root,e=t.currentStyle;return(t.clientWidth||uy(e.width))-uy(e.paddingLeft)-uy(e.paddingRight)|0},_getHeight:function(){var t=this.root,e=t.currentStyle;return(t.clientHeight||uy(e.height))-uy(e.paddingTop)-uy(e.paddingBottom)|0}},f(["getLayer","insertLayer","eachLayer","eachBuiltinLayer","eachOtherLayer","getLayers","modLayer","delLayer","clearLayer","toDataURL","pathToImage"],function(t){cy.prototype[t]=dy(t)}),kn("vml",cy),t.version=ZM,t.dependencies=jM,t.PRIORITY=tS,t.init=ml,t.connect=yl,t.disConnect=xl,t.disconnect=bS,t.dispose=_l,t.getInstanceByDom=wl,t.getInstanceById=bl,t.registerTheme=Ml,t.registerPreprocessor=Sl,t.registerProcessor=Il,t.registerPostUpdate=Tl,t.registerAction=Al,t.registerCoordinateSystem=Cl,t.getCoordinateSystemDimensions=Dl,t.registerLayout=Ll,t.registerVisual=kl,t.registerLoading=Ol,t.extendComponentModel=zl,t.extendComponentView=El,t.extendSeriesModel=Rl,t.extendChartView=Nl,t.setCanvasCreator=Bl,t.registerMap=Vl,t.getMap=Gl,t.dataTool=MS,t.zrender=v_,t.graphic=nb,t.number=pb,t.format=wb,t.throttle=Ls,t.helper=vI,t.matrix=Hy,t.vector=Ry,t.color=ox,t.parseGeoJSON=yI,t.parseGeoJson=bI,t.util=MI,t.List=kS,t.Model=Pr,t.Axis=wI,t.env=vy});
\ No newline at end of file
+!function(t,e){"object"==typeof exports&&"undefined"!=typeof module?e(exports):"function"==typeof define&&define.amd?define(["exports"],e):e(t.echarts={})}(this,function(t){"use strict";function e(t){var e={},n={},i=t.match(/Firefox\/([\d.]+)/),r=t.match(/MSIE\s([\d.]+)/)||t.match(/Trident\/.+?rv:(([\d.]+))/),o=t.match(/Edge\/([\d.]+)/),a=/micromessenger/i.test(t);return i&&(n.firefox=!0,n.version=i[1]),r&&(n.ie=!0,n.version=r[1]),o&&(n.edge=!0,n.version=o[1]),a&&(n.weChat=!0),{browser:n,os:e,node:!1,canvasSupported:!!document.createElement("canvas").getContext,svgSupported:"undefined"!=typeof SVGRect,touchEventsSupported:"ontouchstart"in window&&!n.ie&&!n.edge,pointerEventsSupported:"onpointerdown"in window&&(n.edge||n.ie&&n.version>=11)}}function n(t,e){"createCanvas"===t&&(cg=null),ug[t]=e}function i(t){if(null==t||"object"!=typeof t)return t;var e=t,n=ng.call(t);if("[object Array]"===n){if(!z(t)){e=[];for(var r=0,o=t.length;o>r;r++)e[r]=i(t[r])}}else if(eg[n]){if(!z(t)){var a=t.constructor;if(t.constructor.from)e=a.from(t);else{e=new a(t.length);for(var r=0,o=t.length;o>r;r++)e[r]=i(t[r])}}}else if(!tg[n]&&!z(t)&&!C(t)){e={};for(var s in t)t.hasOwnProperty(s)&&(e[s]=i(t[s]))}return e}function r(t,e,n){if(!M(e)||!M(t))return n?i(e):t;for(var o in e)if(e.hasOwnProperty(o)){var a=t[o],s=e[o];!M(s)||!M(a)||_(s)||_(a)||C(s)||C(a)||S(s)||S(a)||z(s)||z(a)?!n&&o in t||(t[o]=i(e[o],!0)):r(a,s,n)}return t}function o(t,e){for(var n=t[0],i=1,o=t.length;o>i;i++)n=r(n,t[i],e);return n}function a(t,e){for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}function s(t,e,n){for(var i in e)e.hasOwnProperty(i)&&(n?null!=e[i]:null==t[i])&&(t[i]=e[i]);return t}function l(){return cg||(cg=hg().getContext("2d")),cg}function u(t,e){if(t){if(t.indexOf)return t.indexOf(e);for(var n=0,i=t.length;i>n;n++)if(t[n]===e)return n}return-1}function h(t,e){function n(){}var i=t.prototype;n.prototype=e.prototype,t.prototype=new n;for(var r in i)t.prototype[r]=i[r];t.prototype.constructor=t,t.superClass=e}function c(t,e,n){t="prototype"in t?t.prototype:t,e="prototype"in e?e.prototype:e,s(t,e,n)}function d(t){return t?"string"==typeof t?!1:"number"==typeof t.length:void 0}function f(t,e,n){if(t&&e)if(t.forEach&&t.forEach===rg)t.forEach(e,n);else if(t.length===+t.length)for(var i=0,r=t.length;r>i;i++)e.call(n,t[i],i,t);else for(var o in t)t.hasOwnProperty(o)&&e.call(n,t[o],o,t)}function p(t,e,n){if(t&&e){if(t.map&&t.map===sg)return t.map(e,n);for(var i=[],r=0,o=t.length;o>r;r++)i.push(e.call(n,t[r],r,t));return i}}function g(t,e,n,i){if(t&&e){if(t.reduce&&t.reduce===lg)return t.reduce(e,n,i);for(var r=0,o=t.length;o>r;r++)n=e.call(i,n,t[r],r,t);return n}}function v(t,e,n){if(t&&e){if(t.filter&&t.filter===og)return t.filter(e,n);for(var i=[],r=0,o=t.length;o>r;r++)e.call(n,t[r],r,t)&&i.push(t[r]);return i}}function m(t,e,n){if(t&&e)for(var i=0,r=t.length;r>i;i++)if(e.call(n,t[i],i,t))return t[i]}function y(t,e){var n=ag.call(arguments,2);return function(){return t.apply(e,n.concat(ag.call(arguments)))}}function x(t){var e=ag.call(arguments,1);return function(){return t.apply(this,e.concat(ag.call(arguments)))}}function _(t){return"[object Array]"===ng.call(t)}function w(t){return"function"==typeof t}function b(t){return"[object String]"===ng.call(t)}function M(t){var e=typeof t;return"function"===e||!!t&&"object"==e}function S(t){return!!tg[ng.call(t)]}function I(t){return!!eg[ng.call(t)]}function C(t){return"object"==typeof t&&"number"==typeof t.nodeType&&"object"==typeof t.ownerDocument}function T(t){return t!==t}function A(){for(var t=0,e=arguments.length;e>t;t++)if(null!=arguments[t])return arguments[t]}function D(t,e){return null!=t?t:e}function k(t,e,n){return null!=t?t:null!=e?e:n}function P(){return Function.call.apply(ag,arguments)}function L(t){if("number"==typeof t)return[t,t,t,t];var e=t.length;return 2===e?[t[0],t[1],t[0],t[1]]:3===e?[t[0],t[1],t[2],t[1]]:t}function O(t,e){if(!t)throw new Error(e)}function E(t){return null==t?null:"function"==typeof t.trim?t.trim():t.replace(/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,"")}function R(t){t[dg]=!0}function z(t){return t[dg]}function B(t){function e(t,e){n?i.set(t,e):i.set(e,t)}var n=_(t),i=this;t instanceof B?t.each(e):t&&f(t,e)}function N(t){return new B(t)}function V(t,e){for(var n=new t.constructor(t.length+e.length),i=0;i<t.length;i++)n[i]=t[i];var r=t.length;for(i=0;i<e.length;i++)n[i+r]=e[i];return n}function F(){}function H(t,e){var n=new pg(2);return null==t&&(t=0),null==e&&(e=0),n[0]=t,n[1]=e,n}function W(t,e){return t[0]=e[0],t[1]=e[1],t}function G(t){var e=new pg(2);return e[0]=t[0],e[1]=t[1],e}function U(t,e,n){return t[0]=e,t[1]=n,t}function Z(t,e,n){return t[0]=e[0]+n[0],t[1]=e[1]+n[1],t}function j(t,e,n,i){return t[0]=e[0]+n[0]*i,t[1]=e[1]+n[1]*i,t}function X(t,e,n){return t[0]=e[0]-n[0],t[1]=e[1]-n[1],t}function Y(t){return Math.sqrt(q(t))}function q(t){return t[0]*t[0]+t[1]*t[1]}function $(t,e,n){return t[0]=e[0]*n[0],t[1]=e[1]*n[1],t}function K(t,e,n){return t[0]=e[0]/n[0],t[1]=e[1]/n[1],t}function Q(t,e){return t[0]*e[0]+t[1]*e[1]}function J(t,e,n){return t[0]=e[0]*n,t[1]=e[1]*n,t}function te(t,e){var n=Y(e);return 0===n?(t[0]=0,t[1]=0):(t[0]=e[0]/n,t[1]=e[1]/n),t}function ee(t,e){return Math.sqrt((t[0]-e[0])*(t[0]-e[0])+(t[1]-e[1])*(t[1]-e[1]))}function ne(t,e){return(t[0]-e[0])*(t[0]-e[0])+(t[1]-e[1])*(t[1]-e[1])}function ie(t,e){return t[0]=-e[0],t[1]=-e[1],t}function re(t,e,n,i){return t[0]=e[0]+i*(n[0]-e[0]),t[1]=e[1]+i*(n[1]-e[1]),t}function oe(t,e,n){var i=e[0],r=e[1];return t[0]=n[0]*i+n[2]*r+n[4],t[1]=n[1]*i+n[3]*r+n[5],t}function ae(t,e,n){return t[0]=Math.min(e[0],n[0]),t[1]=Math.min(e[1],n[1]),t}function se(t,e,n){return t[0]=Math.max(e[0],n[0]),t[1]=Math.max(e[1],n[1]),t}function le(){this.on("mousedown",this._dragStart,this),this.on("mousemove",this._drag,this),this.on("mouseup",this._dragEnd,this),this.on("globalout",this._dragEnd,this)}function ue(t,e){return{target:t,topTarget:e&&e.topTarget}}function he(t,e,n){return{type:t,event:n,target:e.target,topTarget:e.topTarget,cancelBubble:!1,offsetX:n.zrX,offsetY:n.zrY,gestureEvent:n.gestureEvent,pinchX:n.pinchX,pinchY:n.pinchY,pinchScale:n.pinchScale,wheelDelta:n.zrDelta,zrByTouch:n.zrByTouch,which:n.which}}function ce(){}function de(t,e,n){if(t[t.rectHover?"rectContain":"contain"](e,n)){for(var i,r=t;r;){if(r.clipPath&&!r.clipPath.contain(e,n))return!1;r.silent&&(i=!0),r=r.parent}return i?bg:!0}return!1}function fe(){var t=new Ig(6);return pe(t),t}function pe(t){return t[0]=1,t[1]=0,t[2]=0,t[3]=1,t[4]=0,t[5]=0,t}function ge(t,e){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t[4]=e[4],t[5]=e[5],t}function ve(t,e,n){var i=e[0]*n[0]+e[2]*n[1],r=e[1]*n[0]+e[3]*n[1],o=e[0]*n[2]+e[2]*n[3],a=e[1]*n[2]+e[3]*n[3],s=e[0]*n[4]+e[2]*n[5]+e[4],l=e[1]*n[4]+e[3]*n[5]+e[5];return t[0]=i,t[1]=r,t[2]=o,t[3]=a,t[4]=s,t[5]=l,t}function me(t,e,n){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t[4]=e[4]+n[0],t[5]=e[5]+n[1],t}function ye(t,e,n){var i=e[0],r=e[2],o=e[4],a=e[1],s=e[3],l=e[5],u=Math.sin(n),h=Math.cos(n);return t[0]=i*h+a*u,t[1]=-i*u+a*h,t[2]=r*h+s*u,t[3]=-r*u+h*s,t[4]=h*o+u*l,t[5]=h*l-u*o,t}function xe(t,e,n){var i=n[0],r=n[1];return t[0]=e[0]*i,t[1]=e[1]*r,t[2]=e[2]*i,t[3]=e[3]*r,t[4]=e[4]*i,t[5]=e[5]*r,t}function _e(t,e){var n=e[0],i=e[2],r=e[4],o=e[1],a=e[3],s=e[5],l=n*a-o*i;return l?(l=1/l,t[0]=a*l,t[1]=-o*l,t[2]=-i*l,t[3]=n*l,t[4]=(i*s-a*r)*l,t[5]=(o*r-n*s)*l,t):null}function we(t){var e=fe();return ge(e,t),e}function be(t){return t>Ag||-Ag>t}function Me(t){this._target=t.target,this._life=t.life||1e3,this._delay=t.delay||0,this._initialized=!1,this.loop=null==t.loop?!1:t.loop,this.gap=t.gap||0,this.easing=t.easing||"Linear",this.onframe=t.onframe,this.ondestroy=t.ondestroy,this.onrestart=t.onrestart,this._pausedTime=0,this._paused=!1}function Se(t){return t=Math.round(t),0>t?0:t>255?255:t}function Ie(t){return t=Math.round(t),0>t?0:t>360?360:t}function Ce(t){return 0>t?0:t>1?1:t}function Te(t){return Se(t.length&&"%"===t.charAt(t.length-1)?parseFloat(t)/100*255:parseInt(t,10))}function Ae(t){return Ce(t.length&&"%"===t.charAt(t.length-1)?parseFloat(t)/100:parseFloat(t))}function De(t,e,n){return 0>n?n+=1:n>1&&(n-=1),1>6*n?t+(e-t)*n*6:1>2*n?e:2>3*n?t+(e-t)*(2/3-n)*6:t}function ke(t,e,n){return t+(e-t)*n}function Pe(t,e,n,i,r){return t[0]=e,t[1]=n,t[2]=i,t[3]=r,t}function Le(t,e){return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t}function Oe(t,e){Fg&&Le(Fg,e),Fg=Vg.put(t,Fg||e.slice())}function Ee(t,e){if(t){e=e||[];var n=Vg.get(t);if(n)return Le(e,n);t+="";var i=t.replace(/ /g,"").toLowerCase();if(i in Ng)return Le(e,Ng[i]),Oe(t,e),e;if("#"!==i.charAt(0)){var r=i.indexOf("("),o=i.indexOf(")");if(-1!==r&&o+1===i.length){var a=i.substr(0,r),s=i.substr(r+1,o-(r+1)).split(","),l=1;switch(a){case"rgba":if(4!==s.length)return void Pe(e,0,0,0,1);l=Ae(s.pop());case"rgb":return 3!==s.length?void Pe(e,0,0,0,1):(Pe(e,Te(s[0]),Te(s[1]),Te(s[2]),l),Oe(t,e),e);case"hsla":return 4!==s.length?void Pe(e,0,0,0,1):(s[3]=Ae(s[3]),Re(s,e),Oe(t,e),e);case"hsl":return 3!==s.length?void Pe(e,0,0,0,1):(Re(s,e),Oe(t,e),e);default:return}}Pe(e,0,0,0,1)}else{if(4===i.length){var u=parseInt(i.substr(1),16);return u>=0&&4095>=u?(Pe(e,(3840&u)>>4|(3840&u)>>8,240&u|(240&u)>>4,15&u|(15&u)<<4,1),Oe(t,e),e):void Pe(e,0,0,0,1)}if(7===i.length){var u=parseInt(i.substr(1),16);return u>=0&&16777215>=u?(Pe(e,(16711680&u)>>16,(65280&u)>>8,255&u,1),Oe(t,e),e):void Pe(e,0,0,0,1)}}}}function Re(t,e){var n=(parseFloat(t[0])%360+360)%360/360,i=Ae(t[1]),r=Ae(t[2]),o=.5>=r?r*(i+1):r+i-r*i,a=2*r-o;return e=e||[],Pe(e,Se(255*De(a,o,n+1/3)),Se(255*De(a,o,n)),Se(255*De(a,o,n-1/3)),1),4===t.length&&(e[3]=t[3]),e}function ze(t){if(t){var e,n,i=t[0]/255,r=t[1]/255,o=t[2]/255,a=Math.min(i,r,o),s=Math.max(i,r,o),l=s-a,u=(s+a)/2;if(0===l)e=0,n=0;else{n=.5>u?l/(s+a):l/(2-s-a);var h=((s-i)/6+l/2)/l,c=((s-r)/6+l/2)/l,d=((s-o)/6+l/2)/l;i===s?e=d-c:r===s?e=1/3+h-d:o===s&&(e=2/3+c-h),0>e&&(e+=1),e>1&&(e-=1)}var f=[360*e,n,u];return null!=t[3]&&f.push(t[3]),f}}function Be(t,e){var n=Ee(t);if(n){for(var i=0;3>i;i++)n[i]=0>e?n[i]*(1-e)|0:(255-n[i])*e+n[i]|0,n[i]>255?n[i]=255:t[i]<0&&(n[i]=0);return Ge(n,4===n.length?"rgba":"rgb")}}function Ne(t){var e=Ee(t);return e?((1<<24)+(e[0]<<16)+(e[1]<<8)+ +e[2]).toString(16).slice(1):void 0}function Ve(t,e,n){if(e&&e.length&&t>=0&&1>=t){n=n||[];var i=t*(e.length-1),r=Math.floor(i),o=Math.ceil(i),a=e[r],s=e[o],l=i-r;return n[0]=Se(ke(a[0],s[0],l)),n[1]=Se(ke(a[1],s[1],l)),n[2]=Se(ke(a[2],s[2],l)),n[3]=Ce(ke(a[3],s[3],l)),n}}function Fe(t,e,n){if(e&&e.length&&t>=0&&1>=t){var i=t*(e.length-1),r=Math.floor(i),o=Math.ceil(i),a=Ee(e[r]),s=Ee(e[o]),l=i-r,u=Ge([Se(ke(a[0],s[0],l)),Se(ke(a[1],s[1],l)),Se(ke(a[2],s[2],l)),Ce(ke(a[3],s[3],l))],"rgba");return n?{color:u,leftIndex:r,rightIndex:o,value:i}:u}}function He(t,e,n,i){return t=Ee(t),t?(t=ze(t),null!=e&&(t[0]=Ie(e)),null!=n&&(t[1]=Ae(n)),null!=i&&(t[2]=Ae(i)),Ge(Re(t),"rgba")):void 0}function We(t,e){return t=Ee(t),t&&null!=e?(t[3]=Ce(e),Ge(t,"rgba")):void 0}function Ge(t,e){if(t&&t.length){var n=t[0]+","+t[1]+","+t[2];return("rgba"===e||"hsva"===e||"hsla"===e)&&(n+=","+t[3]),e+"("+n+")"}}function Ue(t,e){return t[e]}function Ze(t,e,n){t[e]=n}function je(t,e,n){return(e-t)*n+t}function Xe(t,e,n){return n>.5?e:t}function Ye(t,e,n,i,r){var o=t.length;if(1==r)for(var a=0;o>a;a++)i[a]=je(t[a],e[a],n);else for(var s=o&&t[0].length,a=0;o>a;a++)for(var l=0;s>l;l++)i[a][l]=je(t[a][l],e[a][l],n)}function qe(t,e,n){var i=t.length,r=e.length;if(i!==r){var o=i>r;if(o)t.length=r;else for(var a=i;r>a;a++)t.push(1===n?e[a]:Ug.call(e[a]))}for(var s=t[0]&&t[0].length,a=0;a<t.length;a++)if(1===n)isNaN(t[a])&&(t[a]=e[a]);else for(var l=0;s>l;l++)isNaN(t[a][l])&&(t[a][l]=e[a][l])}function $e(t,e,n){if(t===e)return!0;var i=t.length;if(i!==e.length)return!1;if(1===n){for(var r=0;i>r;r++)if(t[r]!==e[r])return!1}else for(var o=t[0].length,r=0;i>r;r++)for(var a=0;o>a;a++)if(t[r][a]!==e[r][a])return!1;return!0}function Ke(t,e,n,i,r,o,a,s,l){var u=t.length;if(1==l)for(var h=0;u>h;h++)s[h]=Qe(t[h],e[h],n[h],i[h],r,o,a);else for(var c=t[0].length,h=0;u>h;h++)for(var d=0;c>d;d++)s[h][d]=Qe(t[h][d],e[h][d],n[h][d],i[h][d],r,o,a)}function Qe(t,e,n,i,r,o,a){var s=.5*(n-t),l=.5*(i-e);return(2*(e-n)+s+l)*a+(-3*(e-n)-2*s-l)*o+s*r+e}function Je(t){if(d(t)){var e=t.length;if(d(t[0])){for(var n=[],i=0;e>i;i++)n.push(Ug.call(t[i]));return n}return Ug.call(t)}return t}function tn(t){return t[0]=Math.floor(t[0]),t[1]=Math.floor(t[1]),t[2]=Math.floor(t[2]),"rgba("+t.join(",")+")"}function en(t){var e=t[t.length-1].value;return d(e&&e[0])?2:1}function nn(t,e,n,i,r,o){var a=t._getter,s=t._setter,l="spline"===e,u=i.length;if(u){var h,c=i[0].value,f=d(c),p=!1,g=!1,v=f?en(i):0;i.sort(function(t,e){return t.time-e.time}),h=i[u-1].time;for(var m=[],y=[],x=i[0].value,_=!0,w=0;u>w;w++){m.push(i[w].time/h);var b=i[w].value;if(f&&$e(b,x,v)||!f&&b===x||(_=!1),x=b,"string"==typeof b){var M=Ee(b);M?(b=M,p=!0):g=!0}y.push(b)}if(o||!_){for(var S=y[u-1],w=0;u-1>w;w++)f?qe(y[w],S,v):!isNaN(y[w])||isNaN(S)||g||p||(y[w]=S);f&&qe(a(t._target,r),S,v);var I,C,T,A,D,k,P=0,L=0;if(p)var O=[0,0,0,0];var E=function(t,e){var n;if(0>e)n=0;else if(L>e){for(I=Math.min(P+1,u-1),n=I;n>=0&&!(m[n]<=e);n--);n=Math.min(n,u-2)}else{for(n=P;u>n&&!(m[n]>e);n++);n=Math.min(n-1,u-2)}P=n,L=e;var i=m[n+1]-m[n];if(0!==i)if(C=(e-m[n])/i,l)if(A=y[n],T=y[0===n?n:n-1],D=y[n>u-2?u-1:n+1],k=y[n>u-3?u-1:n+2],f)Ke(T,A,D,k,C,C*C,C*C*C,a(t,r),v);else{var o;if(p)o=Ke(T,A,D,k,C,C*C,C*C*C,O,1),o=tn(O);else{if(g)return Xe(A,D,C);o=Qe(T,A,D,k,C,C*C,C*C*C)}s(t,r,o)}else if(f)Ye(y[n],y[n+1],C,a(t,r),v);else{var o;if(p)Ye(y[n],y[n+1],C,O,1),o=tn(O);else{if(g)return Xe(y[n],y[n+1],C);o=je(y[n],y[n+1],C)}s(t,r,o)}},R=new Me({target:t._target,life:h,loop:t._loop,delay:t._delay,onframe:E,ondestroy:n});return e&&"spline"!==e&&(R.easing=e),R}}}function rn(t,e,n,i){0>n&&(t+=n,n=-n),0>i&&(e+=i,i=-i),this.x=t,this.y=e,this.width=n,this.height=i}function on(t){for(var e=0;t>=iv;)e|=1&t,t>>=1;return t+e}function an(t,e,n,i){var r=e+1;if(r===n)return 1;if(i(t[r++],t[e])<0){for(;n>r&&i(t[r],t[r-1])<0;)r++;sn(t,e,r)}else for(;n>r&&i(t[r],t[r-1])>=0;)r++;return r-e}function sn(t,e,n){for(n--;n>e;){var i=t[e];t[e++]=t[n],t[n--]=i}}function ln(t,e,n,i,r){for(i===e&&i++;n>i;i++){for(var o,a=t[i],s=e,l=i;l>s;)o=s+l>>>1,r(a,t[o])<0?l=o:s=o+1;var u=i-s;switch(u){case 3:t[s+3]=t[s+2];case 2:t[s+2]=t[s+1];case 1:t[s+1]=t[s];break;default:for(;u>0;)t[s+u]=t[s+u-1],u--}t[s]=a}}function un(t,e,n,i,r,o){var a=0,s=0,l=1;if(o(t,e[n+r])>0){for(s=i-r;s>l&&o(t,e[n+r+l])>0;)a=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s),a+=r,l+=r}else{for(s=r+1;s>l&&o(t,e[n+r-l])<=0;)a=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s);var u=a;a=r-l,l=r-u}for(a++;l>a;){var h=a+(l-a>>>1);o(t,e[n+h])>0?a=h+1:l=h}return l}function hn(t,e,n,i,r,o){var a=0,s=0,l=1;if(o(t,e[n+r])<0){for(s=r+1;s>l&&o(t,e[n+r-l])<0;)a=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s);var u=a;a=r-l,l=r-u}else{for(s=i-r;s>l&&o(t,e[n+r+l])>=0;)a=l,l=(l<<1)+1,0>=l&&(l=s);l>s&&(l=s),a+=r,l+=r}for(a++;l>a;){var h=a+(l-a>>>1);o(t,e[n+h])<0?l=h:a=h+1}return l}function cn(t,e){function n(t,e){l[c]=t,u[c]=e,c+=1}function i(){for(;c>1;){var t=c-2;if(t>=1&&u[t-1]<=u[t]+u[t+1]||t>=2&&u[t-2]<=u[t]+u[t-1])u[t-1]<u[t+1]&&t--;else if(u[t]>u[t+1])break;o(t)}}function r(){for(;c>1;){var t=c-2;t>0&&u[t-1]<u[t+1]&&t--,o(t)}}function o(n){var i=l[n],r=u[n],o=l[n+1],h=u[n+1];u[n]=r+h,n===c-3&&(l[n+1]=l[n+2],u[n+1]=u[n+2]),c--;var d=hn(t[o],t,i,r,0,e);i+=d,r-=d,0!==r&&(h=un(t[i+r-1],t,o,h,h-1,e),0!==h&&(h>=r?a(i,r,o,h):s(i,r,o,h)))}function a(n,i,r,o){var a=0;for(a=0;i>a;a++)d[a]=t[n+a];var s=0,l=r,u=n;if(t[u++]=t[l++],0!==--o){if(1===i){for(a=0;o>a;a++)t[u+a]=t[l+a];return void(t[u+o]=d[s])}for(var c,f,p,g=h;;){c=0,f=0,p=!1;do if(e(t[l],d[s])<0){if(t[u++]=t[l++],f++,c=0,0===--o){p=!0;break}}else if(t[u++]=d[s++],c++,f=0,1===--i){p=!0;break}while(g>(c|f));if(p)break;do{if(c=hn(t[l],d,s,i,0,e),0!==c){for(a=0;c>a;a++)t[u+a]=d[s+a];if(u+=c,s+=c,i-=c,1>=i){p=!0;break}}if(t[u++]=t[l++],0===--o){p=!0;break}if(f=un(d[s],t,l,o,0,e),0!==f){for(a=0;f>a;a++)t[u+a]=t[l+a];if(u+=f,l+=f,o-=f,0===o){p=!0;break}}if(t[u++]=d[s++],1===--i){p=!0;break}g--}while(c>=rv||f>=rv);if(p)break;0>g&&(g=0),g+=2}if(h=g,1>h&&(h=1),1===i){for(a=0;o>a;a++)t[u+a]=t[l+a];t[u+o]=d[s]}else{if(0===i)throw new Error;for(a=0;i>a;a++)t[u+a]=d[s+a]}}else for(a=0;i>a;a++)t[u+a]=d[s+a]}function s(n,i,r,o){var a=0;for(a=0;o>a;a++)d[a]=t[r+a];var s=n+i-1,l=o-1,u=r+o-1,c=0,f=0;if(t[u--]=t[s--],0!==--i){if(1===o){for(u-=i,s-=i,f=u+1,c=s+1,a=i-1;a>=0;a--)t[f+a]=t[c+a];return void(t[u]=d[l])}for(var p=h;;){var g=0,v=0,m=!1;do if(e(d[l],t[s])<0){if(t[u--]=t[s--],g++,v=0,0===--i){m=!0;break}}else if(t[u--]=d[l--],v++,g=0,1===--o){m=!0;break}while(p>(g|v));if(m)break;do{if(g=i-hn(d[l],t,n,i,i-1,e),0!==g){for(u-=g,s-=g,i-=g,f=u+1,c=s+1,a=g-1;a>=0;a--)t[f+a]=t[c+a];if(0===i){m=!0;break}}if(t[u--]=d[l--],1===--o){m=!0;break}if(v=o-un(t[s],d,0,o,o-1,e),0!==v){for(u-=v,l-=v,o-=v,f=u+1,c=l+1,a=0;v>a;a++)t[f+a]=d[c+a];if(1>=o){m=!0;break}}if(t[u--]=t[s--],0===--i){m=!0;break}p--}while(g>=rv||v>=rv);if(m)break;0>p&&(p=0),p+=2}if(h=p,1>h&&(h=1),1===o){for(u-=i,s-=i,f=u+1,c=s+1,a=i-1;a>=0;a--)t[f+a]=t[c+a];t[u]=d[l]}else{if(0===o)throw new Error;for(c=u-(o-1),a=0;o>a;a++)t[c+a]=d[a]}}else for(c=u-(o-1),a=0;o>a;a++)t[c+a]=d[a]}var l,u,h=rv,c=0,d=[];l=[],u=[],this.mergeRuns=i,this.forceMergeRuns=r,this.pushRun=n}function dn(t,e,n,i){n||(n=0),i||(i=t.length);var r=i-n;if(!(2>r)){var o=0;if(iv>r)return o=an(t,n,i,e),void ln(t,n,i,n+o,e);var a=new cn(t,e),s=on(r);do{if(o=an(t,n,i,e),s>o){var l=r;l>s&&(l=s),ln(t,n,n+l,n+o,e),o=l}a.pushRun(n,o),a.mergeRuns(),r-=o,n+=o}while(0!==r);a.forceMergeRuns()}}function fn(t,e){return t.zlevel===e.zlevel?t.z===e.z?t.z2-e.z2:t.z-e.z:t.zlevel-e.zlevel}function pn(t,e,n){var i=null==e.x?0:e.x,r=null==e.x2?1:e.x2,o=null==e.y?0:e.y,a=null==e.y2?0:e.y2;e.global||(i=i*n.width+n.x,r=r*n.width+n.x,o=o*n.height+n.y,a=a*n.height+n.y),i=isNaN(i)?0:i,r=isNaN(r)?1:r,o=isNaN(o)?0:o,a=isNaN(a)?0:a;var s=t.createLinearGradient(i,o,r,a);return s}function gn(t,e,n){var i=n.width,r=n.height,o=Math.min(i,r),a=null==e.x?.5:e.x,s=null==e.y?.5:e.y,l=null==e.r?.5:e.r;e.global||(a=a*i+n.x,s=s*r+n.y,l*=o);var u=t.createRadialGradient(a,s,0,a,s,l);return u}function vn(){return!1}function mn(t,e,n){var i=hg(),r=e.getWidth(),o=e.getHeight(),a=i.style;return a&&(a.position="absolute",a.left=0,a.top=0,a.width=r+"px",a.height=o+"px",i.setAttribute("data-zr-dom-id",t)),i.width=r*n,i.height=o*n,i}function yn(t){if("string"==typeof t){var e=vv.get(t);return e&&e.image}return t}function xn(t,e,n,i,r){if(t){if("string"==typeof t){if(e&&e.__zrImageSrc===t||!n)return e;var o=vv.get(t),a={hostEl:n,cb:i,cbPayload:r};return o?(e=o.image,!wn(e)&&o.pending.push(a)):(!e&&(e=new Image),e.onload=_n,vv.put(t,e.__cachedImgObj={image:e,pending:[a]}),e.src=e.__zrImageSrc=t),e}return t}return e}function _n(){var t=this.__cachedImgObj;this.onload=this.__cachedImgObj=null;for(var e=0;e<t.pending.length;e++){var n=t.pending[e],i=n.cb;i&&i(this,n.cbPayload),n.hostEl.dirty()}t.pending.length=0}function wn(t){return t&&t.width&&t.height}function bn(t,e){bv[t]=e}function Mn(t,e){e=e||wv;var n=t+":"+e;if(mv[n])return mv[n];for(var i=(t+"").split("\n"),r=0,o=0,a=i.length;a>o;o++)r=Math.max(Rn(i[o],e).width,r);return yv>xv&&(yv=0,mv={}),yv++,mv[n]=r,r}function Sn(t,e,n,i,r,o,a){return o?Cn(t,e,n,i,r,o,a):In(t,e,n,i,r,a)}function In(t,e,n,i,r,o){var a=zn(t,e,r,o),s=Mn(t,e);r&&(s+=r[1]+r[3]);var l=a.outerHeight,u=Tn(0,s,n),h=An(0,l,i),c=new rn(u,h,s,l);return c.lineHeight=a.lineHeight,c}function Cn(t,e,n,i,r,o,a){var s=Bn(t,{rich:o,truncate:a,font:e,textAlign:n,textPadding:r}),l=s.outerWidth,u=s.outerHeight,h=Tn(0,l,n),c=An(0,u,i);return new rn(h,c,l,u)}function Tn(t,e,n){return"right"===n?t-=e:"center"===n&&(t-=e/2),t}function An(t,e,n){return"middle"===n?t-=e/2:"bottom"===n&&(t-=e),t}function Dn(t,e,n){var i=e.x,r=e.y,o=e.height,a=e.width,s=o/2,l="left",u="top";switch(t){case"left":i-=n,r+=s,l="right",u="middle";break;case"right":i+=n+a,r+=s,u="middle";break;case"top":i+=a/2,r-=n,l="center",u="bottom";break;case"bottom":i+=a/2,r+=o+n,l="center";break;case"inside":i+=a/2,r+=s,l="center",u="middle";break;case"insideLeft":i+=n,r+=s,u="middle";break;case"insideRight":i+=a-n,r+=s,l="right",u="middle";break;case"insideTop":i+=a/2,r+=n,l="center";break;case"insideBottom":i+=a/2,r+=o-n,l="center",u="bottom";break;case"insideTopLeft":i+=n,r+=n;break;case"insideTopRight":i+=a-n,r+=n,l="right";break;case"insideBottomLeft":i+=n,r+=o-n,u="bottom";break;case"insideBottomRight":i+=a-n,r+=o-n,l="right",u="bottom"}return{x:i,y:r,textAlign:l,textVerticalAlign:u}}function kn(t,e,n,i,r){if(!e)return"";var o=(t+"").split("\n");r=Pn(e,n,i,r);for(var a=0,s=o.length;s>a;a++)o[a]=Ln(o[a],r);return o.join("\n")}function Pn(t,e,n,i){i=a({},i),i.font=e;var n=D(n,"...");i.maxIterations=D(i.maxIterations,2);var r=i.minChar=D(i.minChar,0);i.cnCharWidth=Mn("国",e);var o=i.ascCharWidth=Mn("a",e);i.placeholder=D(i.placeholder,"");for(var s=t=Math.max(0,t-1),l=0;r>l&&s>=o;l++)s-=o;var u=Mn(n);return u>s&&(n="",u=0),s=t-u,i.ellipsis=n,i.ellipsisWidth=u,i.contentWidth=s,i.containerWidth=t,i}function Ln(t,e){var n=e.containerWidth,i=e.font,r=e.contentWidth;if(!n)return"";var o=Mn(t,i);if(n>=o)return t;for(var a=0;;a++){if(r>=o||a>=e.maxIterations){t+=e.ellipsis;break}var s=0===a?On(t,r,e.ascCharWidth,e.cnCharWidth):o>0?Math.floor(t.length*r/o):0;t=t.substr(0,s),o=Mn(t,i)}return""===t&&(t=e.placeholder),t}function On(t,e,n,i){for(var r=0,o=0,a=t.length;a>o&&e>r;o++){var s=t.charCodeAt(o);r+=s>=0&&127>=s?n:i}return o}function En(t){return Mn("国",t)}function Rn(t,e){return bv.measureText(t,e)}function zn(t,e,n,i){null!=t&&(t+="");var r=En(e),o=t?t.split("\n"):[],a=o.length*r,s=a;if(n&&(s+=n[0]+n[2]),t&&i){var l=i.outerHeight,u=i.outerWidth;if(null!=l&&s>l)t="",o=[];else if(null!=u)for(var h=Pn(u-(n?n[1]+n[3]:0),e,i.ellipsis,{minChar:i.minChar,placeholder:i.placeholder}),c=0,d=o.length;d>c;c++)o[c]=Ln(o[c],h)}return{lines:o,height:a,outerHeight:s,lineHeight:r}}function Bn(t,e){var n={lines:[],width:0,height:0};if(null!=t&&(t+=""),!t)return n;for(var i,r=_v.lastIndex=0;null!=(i=_v.exec(t));){var o=i.index;o>r&&Nn(n,t.substring(r,o)),Nn(n,i[2],i[1]),r=_v.lastIndex}r<t.length&&Nn(n,t.substring(r,t.length));var a=n.lines,s=0,l=0,u=[],h=e.textPadding,c=e.truncate,d=c&&c.outerWidth,f=c&&c.outerHeight;h&&(null!=d&&(d-=h[1]+h[3]),null!=f&&(f-=h[0]+h[2]));for(var p=0;p<a.length;p++){for(var g=a[p],v=0,m=0,y=0;y<g.tokens.length;y++){var x=g.tokens[y],_=x.styleName&&e.rich[x.styleName]||{},w=x.textPadding=_.textPadding,b=x.font=_.font||e.font,M=x.textHeight=D(_.textHeight,En(b));if(w&&(M+=w[0]+w[2]),x.height=M,x.lineHeight=k(_.textLineHeight,e.textLineHeight,M),x.textAlign=_&&_.textAlign||e.textAlign,x.textVerticalAlign=_&&_.textVerticalAlign||"middle",null!=f&&s+x.lineHeight>f)return{lines:[],width:0,height:0};x.textWidth=Mn(x.text,b);var S=_.textWidth,I=null==S||"auto"===S;if("string"==typeof S&&"%"===S.charAt(S.length-1))x.percentWidth=S,u.push(x),S=0;else{if(I){S=x.textWidth;var C=_.textBackgroundColor,T=C&&C.image;T&&(T=yn(T),wn(T)&&(S=Math.max(S,T.width*M/T.height)))}var A=w?w[1]+w[3]:0;S+=A;var P=null!=d?d-m:null;null!=P&&S>P&&(!I||A>P?(x.text="",x.textWidth=S=0):(x.text=kn(x.text,P-A,b,c.ellipsis,{minChar:c.minChar}),x.textWidth=Mn(x.text,b),S=x.textWidth+A))}m+=x.width=S,_&&(v=Math.max(v,x.lineHeight))}g.width=m,g.lineHeight=v,s+=v,l=Math.max(l,m)}n.outerWidth=n.width=D(e.textWidth,l),n.outerHeight=n.height=D(e.textHeight,s),h&&(n.outerWidth+=h[1]+h[3],n.outerHeight+=h[0]+h[2]);for(var p=0;p<u.length;p++){var x=u[p],L=x.percentWidth;x.width=parseInt(L,10)/100*l}return n}function Nn(t,e,n){for(var i=""===e,r=e.split("\n"),o=t.lines,a=0;a<r.length;a++){var s=r[a],l={styleName:n,text:s,isLineHolder:!s&&!i};if(a)o.push({tokens:[l]});else{var u=(o[o.length-1]||(o[0]={tokens:[]})).tokens,h=u.length;1===h&&u[0].isLineHolder?u[0]=l:(s||!h||i)&&u.push(l)}}}function Vn(t){var e=(t.fontSize||t.fontFamily)&&[t.fontStyle,t.fontWeight,(t.fontSize||12)+"px",t.fontFamily||"sans-serif"].join(" ");return e&&E(e)||t.textFont||t.font}function Fn(t,e){var n,i,r,o,a=e.x,s=e.y,l=e.width,u=e.height,h=e.r;0>l&&(a+=l,l=-l),0>u&&(s+=u,u=-u),"number"==typeof h?n=i=r=o=h:h instanceof Array?1===h.length?n=i=r=o=h[0]:2===h.length?(n=r=h[0],i=o=h[1]):3===h.length?(n=h[0],i=o=h[1],r=h[2]):(n=h[0],i=h[1],r=h[2],o=h[3]):n=i=r=o=0;var c;n+i>l&&(c=n+i,n*=l/c,i*=l/c),r+o>l&&(c=r+o,r*=l/c,o*=l/c),i+r>u&&(c=i+r,i*=u/c,r*=u/c),n+o>u&&(c=n+o,n*=u/c,o*=u/c),t.moveTo(a+n,s),t.lineTo(a+l-i,s),0!==i&&t.arc(a+l-i,s+i,i,-Math.PI/2,0),t.lineTo(a+l,s+u-r),0!==r&&t.arc(a+l-r,s+u-r,r,0,Math.PI/2),t.lineTo(a+o,s+u),0!==o&&t.arc(a+o,s+u-o,o,Math.PI/2,Math.PI),t.lineTo(a,s+n),0!==n&&t.arc(a+n,s+n,n,Math.PI,1.5*Math.PI)}function Hn(t){return Wn(t),f(t.rich,Wn),t}function Wn(t){if(t){t.font=Vn(t);var e=t.textAlign;"middle"===e&&(e="center"),t.textAlign=null==e||Mv[e]?e:"left";var n=t.textVerticalAlign||t.textBaseline;"center"===n&&(n="middle"),t.textVerticalAlign=null==n||Sv[n]?n:"top";var i=t.textPadding;i&&(t.textPadding=L(t.textPadding))}}function Gn(t,e,n,i,r){i.rich?Zn(t,e,n,i,r):Un(t,e,n,i,r)}function Un(t,e,n,i,r){var o=Jn(e,"font",i.font||wv),a=i.textPadding,s=t.__textCotentBlock;(!s||t.__dirty)&&(s=t.__textCotentBlock=zn(n,o,a,i.truncate));var l=s.outerHeight,u=s.lines,h=s.lineHeight,c=Qn(l,i,r),d=c.baseX,f=c.baseY,p=c.textAlign,g=c.textVerticalAlign;Xn(e,i,r,d,f);var v=An(f,l,g),m=d,y=v,x=qn(i);if(x||a){var _=Mn(n,o),w=_;a&&(w+=a[1]+a[3]);var b=Tn(d,w,p);x&&$n(t,e,i,b,v,w,l),a&&(m=ii(d,p,a),y+=a[0])}Jn(e,"textAlign",p||"left"),Jn(e,"textBaseline","middle"),Jn(e,"shadowBlur",i.textShadowBlur||0),Jn(e,"shadowColor",i.textShadowColor||"transparent"),Jn(e,"shadowOffsetX",i.textShadowOffsetX||0),Jn(e,"shadowOffsetY",i.textShadowOffsetY||0),y+=h/2;var M=i.textStrokeWidth,S=ti(i.textStroke,M),I=ei(i.textFill);S&&(Jn(e,"lineWidth",M),Jn(e,"strokeStyle",S)),I&&Jn(e,"fillStyle",I);for(var C=0;C<u.length;C++)S&&e.strokeText(u[C],m,y),I&&e.fillText(u[C],m,y),y+=h}function Zn(t,e,n,i,r){var o=t.__textCotentBlock;(!o||t.__dirty)&&(o=t.__textCotentBlock=Bn(n,i)),jn(t,e,o,i,r)}function jn(t,e,n,i,r){var o=n.width,a=n.outerWidth,s=n.outerHeight,l=i.textPadding,u=Qn(s,i,r),h=u.baseX,c=u.baseY,d=u.textAlign,f=u.textVerticalAlign;Xn(e,i,r,h,c);var p=Tn(h,a,d),g=An(c,s,f),v=p,m=g;l&&(v+=l[3],m+=l[0]);var y=v+o;qn(i)&&$n(t,e,i,p,g,a,s);for(var x=0;x<n.lines.length;x++){for(var _,w=n.lines[x],b=w.tokens,M=b.length,S=w.lineHeight,I=w.width,C=0,T=v,A=y,D=M-1;M>C&&(_=b[C],!_.textAlign||"left"===_.textAlign);)Yn(t,e,_,i,S,m,T,"left"),I-=_.width,T+=_.width,C++;for(;D>=0&&(_=b[D],"right"===_.textAlign);)Yn(t,e,_,i,S,m,A,"right"),I-=_.width,A-=_.width,D--;for(T+=(o-(T-v)-(y-A)-I)/2;D>=C;)_=b[C],Yn(t,e,_,i,S,m,T+_.width/2,"center"),T+=_.width,C++;m+=S}}function Xn(t,e,n,i,r){if(n&&e.textRotation){var o=e.textOrigin;"center"===o?(i=n.width/2+n.x,r=n.height/2+n.y):o&&(i=o[0]+n.x,r=o[1]+n.y),t.translate(i,r),t.rotate(-e.textRotation),t.translate(-i,-r)}}function Yn(t,e,n,i,r,o,a,s){var l=i.rich[n.styleName]||{},u=n.textVerticalAlign,h=o+r/2;"top"===u?h=o+n.height/2:"bottom"===u&&(h=o+r-n.height/2),!n.isLineHolder&&qn(l)&&$n(t,e,l,"right"===s?a-n.width:"center"===s?a-n.width/2:a,h-n.height/2,n.width,n.height);var c=n.textPadding;c&&(a=ii(a,s,c),h-=n.height/2-c[2]-n.textHeight/2),Jn(e,"shadowBlur",k(l.textShadowBlur,i.textShadowBlur,0)),Jn(e,"shadowColor",l.textShadowColor||i.textShadowColor||"transparent"),Jn(e,"shadowOffsetX",k(l.textShadowOffsetX,i.textShadowOffsetX,0)),Jn(e,"shadowOffsetY",k(l.textShadowOffsetY,i.textShadowOffsetY,0)),Jn(e,"textAlign",s),Jn(e,"textBaseline","middle"),Jn(e,"font",n.font||wv);var d=ti(l.textStroke||i.textStroke,p),f=ei(l.textFill||i.textFill),p=D(l.textStrokeWidth,i.textStrokeWidth);d&&(Jn(e,"lineWidth",p),Jn(e,"strokeStyle",d),e.strokeText(n.text,a,h)),f&&(Jn(e,"fillStyle",f),e.fillText(n.text,a,h))}function qn(t){return t.textBackgroundColor||t.textBorderWidth&&t.textBorderColor}function $n(t,e,n,i,r,o,a){var s=n.textBackgroundColor,l=n.textBorderWidth,u=n.textBorderColor,h=b(s);if(Jn(e,"shadowBlur",n.textBoxShadowBlur||0),Jn(e,"shadowColor",n.textBoxShadowColor||"transparent"),Jn(e,"shadowOffsetX",n.textBoxShadowOffsetX||0),Jn(e,"shadowOffsetY",n.textBoxShadowOffsetY||0),h||l&&u){e.beginPath();var c=n.textBorderRadius;c?Fn(e,{x:i,y:r,width:o,height:a,r:c}):e.rect(i,r,o,a),e.closePath()}if(h)Jn(e,"fillStyle",s),e.fill();else if(M(s)){var d=s.image;d=xn(d,null,t,Kn,s),d&&wn(d)&&e.drawImage(d,i,r,o,a)}l&&u&&(Jn(e,"lineWidth",l),Jn(e,"strokeStyle",u),e.stroke())}function Kn(t,e){e.image=t}function Qn(t,e,n){var i=e.x||0,r=e.y||0,o=e.textAlign,a=e.textVerticalAlign;if(n){var s=e.textPosition;if(s instanceof Array)i=n.x+ni(s[0],n.width),r=n.y+ni(s[1],n.height);else{var l=Dn(s,n,e.textDistance);i=l.x,r=l.y,o=o||l.textAlign,a=a||l.textVerticalAlign}var u=e.textOffset;u&&(i+=u[0],r+=u[1])}return{baseX:i,baseY:r,textAlign:o,textVerticalAlign:a}}function Jn(t,e,n){return t[e]=sv(t,e,n),t[e]}function ti(t,e){return null==t||0>=e||"transparent"===t||"none"===t?null:t.image||t.colorStops?"#000":t}function ei(t){return null==t||"none"===t?null:t.image||t.colorStops?"#000":t}function ni(t,e){return"string"==typeof t?t.lastIndexOf("%")>=0?parseFloat(t)/100*e:parseFloat(t):t}function ii(t,e,n){return"right"===e?t-n[1]:"center"===e?t+n[3]/2-n[1]/2:t+n[3]}function ri(t,e){return null!=t&&(t||e.textBackgroundColor||e.textBorderWidth&&e.textBorderColor||e.textPadding)}function oi(t){t=t||{},Qg.call(this,t);for(var e in t)t.hasOwnProperty(e)&&"style"!==e&&(this[e]=t[e]);this.style=new uv(t.style,this),this._rect=null,this.__clipPaths=[]}function ai(t){oi.call(this,t)}function si(t){return parseInt(t,10)}function li(t){return t?t.__builtin__?!0:"function"!=typeof t.resize||"function"!=typeof t.refresh?!1:!0:!1}function ui(t,e,n){return Pv.copy(t.getBoundingRect()),t.transform&&Pv.applyTransform(t.transform),Lv.width=e,Lv.height=n,!Pv.intersect(Lv)}function hi(t,e){if(t==e)return!1;if(!t||!e||t.length!==e.length)return!0;for(var n=0;n<t.length;n++)if(t[n]!==e[n])return!0}function ci(t,e){for(var n=0;n<t.length;n++){var i=t[n];i.setTransform(e),e.beginPath(),i.buildPath(e,i.shape),e.clip(),i.restoreTransform(e)}}function di(t,e){var n=document.createElement("div");return n.style.cssText=["position:relative","overflow:hidden","width:"+t+"px","height:"+e+"px","padding:0","margin:0","border-width:0"].join(";")+";",n}function fi(t){return t.getBoundingClientRect?t.getBoundingClientRect():{left:0,top:0}}function pi(t,e,n,i){return n=n||{},i||!Jp.canvasSupported?gi(t,e,n):Jp.browser.firefox&&null!=e.layerX&&e.layerX!==e.offsetX?(n.zrX=e.layerX,n.zrY=e.layerY):null!=e.offsetX?(n.zrX=e.offsetX,n.zrY=e.offsetY):gi(t,e,n),n}function gi(t,e,n){var i=fi(t);n.zrX=e.clientX-i.left,n.zrY=e.clientY-i.top}function vi(t,e,n){if(e=e||window.event,null!=e.zrX)return e;var i=e.type,r=i&&i.indexOf("touch")>=0;if(r){var o="touchend"!=i?e.targetTouches[0]:e.changedTouches[0];o&&pi(t,o,e,n)}else pi(t,e,e,n),e.zrDelta=e.wheelDelta?e.wheelDelta/120:-(e.detail||0)/3;var a=e.button;return null==e.which&&void 0!==a&&Rv.test(e.type)&&(e.which=1&a?1:2&a?3:4&a?2:0),e}function mi(t,e,n){Ev?t.addEventListener(e,n):t.attachEvent("on"+e,n)}function yi(t,e,n){Ev?t.removeEventListener(e,n):t.detachEvent("on"+e,n)}function xi(t){var e=t[1][0]-t[0][0],n=t[1][1]-t[0][1];return Math.sqrt(e*e+n*n)}function _i(t){return[(t[0][0]+t[1][0])/2,(t[0][1]+t[1][1])/2]}function wi(t){return"mousewheel"===t&&Jp.browser.firefox?"DOMMouseScroll":t}function bi(t,e,n){var i=t._gestureMgr;"start"===n&&i.clear();var r=i.recognize(e,t.handler.findHover(e.zrX,e.zrY,null).target,t.dom);if("end"===n&&i.clear(),r){var o=r.type;e.gestureEvent=o,t.handler.dispatchToElement({target:r.target},o,r.event)}}function Mi(t){t._touching=!0,clearTimeout(t._touchTimer),t._touchTimer=setTimeout(function(){t._touching=!1},700)}function Si(t){var e=t.pointerType;return"pen"===e||"touch"===e
+}function Ii(t){function e(t,e){return function(){return e._touching?void 0:t.apply(e,arguments)}}f(Wv,function(e){t._handlers[e]=y(Zv[e],t)}),f(Uv,function(e){t._handlers[e]=y(Zv[e],t)}),f(Hv,function(n){t._handlers[n]=e(Zv[n],t)})}function Ci(t){function e(e,n){f(e,function(e){mi(t,wi(e),n._handlers[e])},n)}wg.call(this),this.dom=t,this._touching=!1,this._touchTimer,this._gestureMgr=new Nv,this._handlers={},Ii(this),Jp.pointerEventsSupported?e(Uv,this):(Jp.touchEventsSupported&&e(Wv,this),e(Hv,this))}function Ti(t,e){var n=new Kv(Kp(),t,e);return qv[n.id]=n,n}function Ai(t){if(t)t.dispose();else{for(var e in qv)qv.hasOwnProperty(e)&&qv[e].dispose();qv={}}return this}function Di(t){return qv[t]}function ki(t,e){Yv[t]=e}function Pi(t){delete qv[t]}function Li(t){return t instanceof Array?t:null==t?[]:[t]}function Oi(t,e,n){if(t){t[e]=t[e]||{},t.emphasis=t.emphasis||{},t.emphasis[e]=t.emphasis[e]||{};for(var i=0,r=n.length;r>i;i++){var o=n[i];!t.emphasis[e].hasOwnProperty(o)&&t[e].hasOwnProperty(o)&&(t.emphasis[e][o]=t[e][o])}}}function Ei(t){return!tm(t)||em(t)||t instanceof Date?t:t.value}function Ri(t){return tm(t)&&!(t instanceof Array)}function zi(t,e){e=(e||[]).slice();var n=p(t||[],function(t){return{exist:t}});return Jv(e,function(t,i){if(tm(t)){for(var r=0;r<n.length;r++)if(!n[r].option&&null!=t.id&&n[r].exist.id===t.id+"")return n[r].option=t,void(e[i]=null);for(var r=0;r<n.length;r++){var o=n[r].exist;if(!(n[r].option||null!=o.id&&null!=t.id||null==t.name||Vi(t)||Vi(o)||o.name!==t.name+""))return n[r].option=t,void(e[i]=null)}}}),Jv(e,function(t){if(tm(t)){for(var e=0;e<n.length;e++){var i=n[e].exist;if(!n[e].option&&!Vi(i)&&null==t.id){n[e].option=t;break}}e>=n.length&&n.push({option:t})}}),n}function Bi(t){var e=N();Jv(t,function(t){var n=t.exist;n&&e.set(n.id,t)}),Jv(t,function(t){var n=t.option;O(!n||null==n.id||!e.get(n.id)||e.get(n.id)===t,"id duplicates: "+(n&&n.id)),n&&null!=n.id&&e.set(n.id,t),!t.keyInfo&&(t.keyInfo={})}),Jv(t,function(t,n){var i=t.exist,r=t.option,o=t.keyInfo;if(tm(r)){if(o.name=null!=r.name?r.name+"":i?i.name:nm+n,i)o.id=i.id;else if(null!=r.id)o.id=r.id+"";else{var a=0;do o.id="\x00"+o.name+"\x00"+a++;while(e.get(o.id))}e.set(o.id,t)}})}function Ni(t){var e=t.name;return!(!e||!e.indexOf(nm))}function Vi(t){return tm(t)&&t.id&&0===(t.id+"").indexOf("\x00_ec_\x00")}function Fi(t,e){return null!=e.dataIndexInside?e.dataIndexInside:null!=e.dataIndex?_(e.dataIndex)?p(e.dataIndex,function(e){return t.indexOfRawIndex(e)}):t.indexOfRawIndex(e.dataIndex):null!=e.name?_(e.name)?p(e.name,function(e){return t.indexOfName(e)}):t.indexOfName(e.name):void 0}function Hi(){var t="__\x00ec_inner_"+rm++ +"_"+Math.random().toFixed(5);return function(e){return e[t]||(e[t]={})}}function Wi(t,e,n){if(b(e)){var i={};i[e+"Index"]=0,e=i}var r=n&&n.defaultMainType;!r||Gi(e,r+"Index")||Gi(e,r+"Id")||Gi(e,r+"Name")||(e[r+"Index"]=0);var o={};return Jv(e,function(i,r){var i=e[r];if("dataIndex"===r||"dataIndexInside"===r)return void(o[r]=i);var a=r.match(/^(\w+)(Index|Id|Name)$/)||[],s=a[1],l=(a[2]||"").toLowerCase();if(!(!s||!l||null==i||"index"===l&&"none"===i||n&&n.includeMainTypes&&u(n.includeMainTypes,s)<0)){var h={mainType:s};("index"!==l||"all"!==i)&&(h[l]=i);var c=t.queryComponents(h);o[s+"Models"]=c,o[s+"Model"]=c[0]}}),o}function Gi(t,e){return t&&t.hasOwnProperty(e)}function Ui(t,e,n){t.setAttribute?t.setAttribute(e,n):t[e]=n}function Zi(t,e){return t.getAttribute?t.getAttribute(e):t[e]}function ji(t){var e={main:"",sub:""};return t&&(t=t.split(om),e.main=t[0]||"",e.sub=t[1]||""),e}function Xi(t){O(/^[a-zA-Z0-9_]+([.][a-zA-Z0-9_]+)?$/.test(t),'componentType "'+t+'" illegal')}function Yi(t){t.$constructor=t,t.extend=function(t){var e=this,n=function(){t.$constructor?t.$constructor.apply(this,arguments):e.apply(this,arguments)};return a(n.prototype,t),n.extend=this.extend,n.superCall=$i,n.superApply=Ki,h(n,this),n.superClass=e,n}}function qi(t){var e=["__\x00is_clz",sm++,Math.random().toFixed(3)].join("_");t.prototype[e]=!0,t.isInstance=function(t){return!(!t||!t[e])}}function $i(t,e){var n=P(arguments,2);return this.superClass.prototype[e].apply(t,n)}function Ki(t,e,n){return this.superClass.prototype[e].apply(t,n)}function Qi(t,e){function n(t){var e=i[t.main];return e&&e[am]||(e=i[t.main]={},e[am]=!0),e}e=e||{};var i={};if(t.registerClass=function(t,e){if(e)if(Xi(e),e=ji(e),e.sub){if(e.sub!==am){var r=n(e);r[e.sub]=t}}else i[e.main]=t;return t},t.getClass=function(t,e,n){var r=i[t];if(r&&r[am]&&(r=e?r[e]:null),n&&!r)throw new Error(e?"Component "+t+"."+(e||"")+" not exists. Load it first.":t+".type should be specified.");return r},t.getClassesByMainType=function(t){t=ji(t);var e=[],n=i[t.main];return n&&n[am]?f(n,function(t,n){n!==am&&e.push(t)}):e.push(n),e},t.hasClass=function(t){return t=ji(t),!!i[t.main]},t.getAllClassMainTypes=function(){var t=[];return f(i,function(e,n){t.push(n)}),t},t.hasSubTypes=function(t){t=ji(t);var e=i[t.main];return e&&e[am]},t.parseClassType=ji,e.registerWhenExtend){var r=t.extend;r&&(t.extend=function(e){var n=r.call(this,e);return t.registerClass(n,e.type)})}return t}function Ji(t){return t>-gm&&gm>t}function tr(t){return t>gm||-gm>t}function er(t,e,n,i,r){var o=1-r;return o*o*(o*t+3*r*e)+r*r*(r*i+3*o*n)}function nr(t,e,n,i,r){var o=1-r;return 3*(((e-t)*o+2*(n-e)*r)*o+(i-n)*r*r)}function ir(t,e,n,i,r,o){var a=i+3*(e-n)-t,s=3*(n-2*e+t),l=3*(e-t),u=t-r,h=s*s-3*a*l,c=s*l-9*a*u,d=l*l-3*s*u,f=0;if(Ji(h)&&Ji(c))if(Ji(s))o[0]=0;else{var p=-l/s;p>=0&&1>=p&&(o[f++]=p)}else{var g=c*c-4*h*d;if(Ji(g)){var v=c/h,p=-s/a+v,m=-v/2;p>=0&&1>=p&&(o[f++]=p),m>=0&&1>=m&&(o[f++]=m)}else if(g>0){var y=pm(g),x=h*s+1.5*a*(-c+y),_=h*s+1.5*a*(-c-y);x=0>x?-fm(-x,ym):fm(x,ym),_=0>_?-fm(-_,ym):fm(_,ym);var p=(-s-(x+_))/(3*a);p>=0&&1>=p&&(o[f++]=p)}else{var w=(2*h*s-3*a*c)/(2*pm(h*h*h)),b=Math.acos(w)/3,M=pm(h),S=Math.cos(b),p=(-s-2*M*S)/(3*a),m=(-s+M*(S+mm*Math.sin(b)))/(3*a),I=(-s+M*(S-mm*Math.sin(b)))/(3*a);p>=0&&1>=p&&(o[f++]=p),m>=0&&1>=m&&(o[f++]=m),I>=0&&1>=I&&(o[f++]=I)}}return f}function rr(t,e,n,i,r){var o=6*n-12*e+6*t,a=9*e+3*i-3*t-9*n,s=3*e-3*t,l=0;if(Ji(a)){if(tr(o)){var u=-s/o;u>=0&&1>=u&&(r[l++]=u)}}else{var h=o*o-4*a*s;if(Ji(h))r[0]=-o/(2*a);else if(h>0){var c=pm(h),u=(-o+c)/(2*a),d=(-o-c)/(2*a);u>=0&&1>=u&&(r[l++]=u),d>=0&&1>=d&&(r[l++]=d)}}return l}function or(t,e,n,i,r,o){var a=(e-t)*r+t,s=(n-e)*r+e,l=(i-n)*r+n,u=(s-a)*r+a,h=(l-s)*r+s,c=(h-u)*r+u;o[0]=t,o[1]=a,o[2]=u,o[3]=c,o[4]=c,o[5]=h,o[6]=l,o[7]=i}function ar(t,e,n,i,r,o,a,s,l,u,h){var c,d,f,p,g,v=.005,m=1/0;xm[0]=l,xm[1]=u;for(var y=0;1>y;y+=.05)_m[0]=er(t,n,r,a,y),_m[1]=er(e,i,o,s,y),p=yg(xm,_m),m>p&&(c=y,m=p);m=1/0;for(var x=0;32>x&&!(vm>v);x++)d=c-v,f=c+v,_m[0]=er(t,n,r,a,d),_m[1]=er(e,i,o,s,d),p=yg(_m,xm),d>=0&&m>p?(c=d,m=p):(wm[0]=er(t,n,r,a,f),wm[1]=er(e,i,o,s,f),g=yg(wm,xm),1>=f&&m>g?(c=f,m=g):v*=.5);return h&&(h[0]=er(t,n,r,a,c),h[1]=er(e,i,o,s,c)),pm(m)}function sr(t,e,n,i){var r=1-i;return r*(r*t+2*i*e)+i*i*n}function lr(t,e,n,i){return 2*((1-i)*(e-t)+i*(n-e))}function ur(t,e,n,i,r){var o=t-2*e+n,a=2*(e-t),s=t-i,l=0;if(Ji(o)){if(tr(a)){var u=-s/a;u>=0&&1>=u&&(r[l++]=u)}}else{var h=a*a-4*o*s;if(Ji(h)){var u=-a/(2*o);u>=0&&1>=u&&(r[l++]=u)}else if(h>0){var c=pm(h),u=(-a+c)/(2*o),d=(-a-c)/(2*o);u>=0&&1>=u&&(r[l++]=u),d>=0&&1>=d&&(r[l++]=d)}}return l}function hr(t,e,n){var i=t+n-2*e;return 0===i?.5:(t-e)/i}function cr(t,e,n,i,r){var o=(e-t)*i+t,a=(n-e)*i+e,s=(a-o)*i+o;r[0]=t,r[1]=o,r[2]=s,r[3]=s,r[4]=a,r[5]=n}function dr(t,e,n,i,r,o,a,s,l){var u,h=.005,c=1/0;xm[0]=a,xm[1]=s;for(var d=0;1>d;d+=.05){_m[0]=sr(t,n,r,d),_m[1]=sr(e,i,o,d);var f=yg(xm,_m);c>f&&(u=d,c=f)}c=1/0;for(var p=0;32>p&&!(vm>h);p++){var g=u-h,v=u+h;_m[0]=sr(t,n,r,g),_m[1]=sr(e,i,o,g);var f=yg(_m,xm);if(g>=0&&c>f)u=g,c=f;else{wm[0]=sr(t,n,r,v),wm[1]=sr(e,i,o,v);var m=yg(wm,xm);1>=v&&c>m?(u=v,c=m):h*=.5}}return l&&(l[0]=sr(t,n,r,u),l[1]=sr(e,i,o,u)),pm(c)}function fr(t,e,n){if(0!==t.length){var i,r=t[0],o=r[0],a=r[0],s=r[1],l=r[1];for(i=1;i<t.length;i++)r=t[i],o=bm(o,r[0]),a=Mm(a,r[0]),s=bm(s,r[1]),l=Mm(l,r[1]);e[0]=o,e[1]=s,n[0]=a,n[1]=l}}function pr(t,e,n,i,r,o){r[0]=bm(t,n),r[1]=bm(e,i),o[0]=Mm(t,n),o[1]=Mm(e,i)}function gr(t,e,n,i,r,o,a,s,l,u){var h,c=rr,d=er,f=c(t,n,r,a,km);for(l[0]=1/0,l[1]=1/0,u[0]=-1/0,u[1]=-1/0,h=0;f>h;h++){var p=d(t,n,r,a,km[h]);l[0]=bm(p,l[0]),u[0]=Mm(p,u[0])}for(f=c(e,i,o,s,Pm),h=0;f>h;h++){var g=d(e,i,o,s,Pm[h]);l[1]=bm(g,l[1]),u[1]=Mm(g,u[1])}l[0]=bm(t,l[0]),u[0]=Mm(t,u[0]),l[0]=bm(a,l[0]),u[0]=Mm(a,u[0]),l[1]=bm(e,l[1]),u[1]=Mm(e,u[1]),l[1]=bm(s,l[1]),u[1]=Mm(s,u[1])}function vr(t,e,n,i,r,o,a,s){var l=hr,u=sr,h=Mm(bm(l(t,n,r),1),0),c=Mm(bm(l(e,i,o),1),0),d=u(t,n,r,h),f=u(e,i,o,c);a[0]=bm(t,r,d),a[1]=bm(e,o,f),s[0]=Mm(t,r,d),s[1]=Mm(e,o,f)}function mr(t,e,n,i,r,o,a,s,l){var u=ae,h=se,c=Math.abs(r-o);if(1e-4>c%Cm&&c>1e-4)return s[0]=t-n,s[1]=e-i,l[0]=t+n,void(l[1]=e+i);if(Tm[0]=Im(r)*n+t,Tm[1]=Sm(r)*i+e,Am[0]=Im(o)*n+t,Am[1]=Sm(o)*i+e,u(s,Tm,Am),h(l,Tm,Am),r%=Cm,0>r&&(r+=Cm),o%=Cm,0>o&&(o+=Cm),r>o&&!a?o+=Cm:o>r&&a&&(r+=Cm),a){var d=o;o=r,r=d}for(var f=0;o>f;f+=Math.PI/2)f>r&&(Dm[0]=Im(f)*n+t,Dm[1]=Sm(f)*i+e,u(s,Dm,s),h(l,Dm,l))}function yr(t,e,n,i,r,o,a){if(0===r)return!1;var s=r,l=0,u=t;if(a>e+s&&a>i+s||e-s>a&&i-s>a||o>t+s&&o>n+s||t-s>o&&n-s>o)return!1;if(t===n)return Math.abs(o-t)<=s/2;l=(e-i)/(t-n),u=(t*i-n*e)/(t-n);var h=l*o-a+u,c=h*h/(l*l+1);return s/2*s/2>=c}function xr(t,e,n,i,r,o,a,s,l,u,h){if(0===l)return!1;var c=l;if(h>e+c&&h>i+c&&h>o+c&&h>s+c||e-c>h&&i-c>h&&o-c>h&&s-c>h||u>t+c&&u>n+c&&u>r+c&&u>a+c||t-c>u&&n-c>u&&r-c>u&&a-c>u)return!1;var d=ar(t,e,n,i,r,o,a,s,u,h,null);return c/2>=d}function _r(t,e,n,i,r,o,a,s,l){if(0===a)return!1;var u=a;if(l>e+u&&l>i+u&&l>o+u||e-u>l&&i-u>l&&o-u>l||s>t+u&&s>n+u&&s>r+u||t-u>s&&n-u>s&&r-u>s)return!1;var h=dr(t,e,n,i,r,o,s,l,null);return u/2>=h}function wr(t){return t%=Zm,0>t&&(t+=Zm),t}function br(t,e,n,i,r,o,a,s,l){if(0===a)return!1;var u=a;s-=t,l-=e;var h=Math.sqrt(s*s+l*l);if(h-u>n||n>h+u)return!1;if(Math.abs(i-r)%jm<1e-4)return!0;if(o){var c=i;i=wr(r),r=wr(c)}else i=wr(i),r=wr(r);i>r&&(r+=jm);var d=Math.atan2(l,s);return 0>d&&(d+=jm),d>=i&&r>=d||d+jm>=i&&r>=d+jm}function Mr(t,e,n,i,r,o){if(o>e&&o>i||e>o&&i>o)return 0;if(i===e)return 0;var a=e>i?1:-1,s=(o-e)/(i-e);(1===s||0===s)&&(a=e>i?.5:-.5);var l=s*(n-t)+t;return l===r?1/0:l>r?a:0}function Sr(t,e){return Math.abs(t-e)<qm}function Ir(){var t=Km[0];Km[0]=Km[1],Km[1]=t}function Cr(t,e,n,i,r,o,a,s,l,u){if(u>e&&u>i&&u>o&&u>s||e>u&&i>u&&o>u&&s>u)return 0;var h=ir(e,i,o,s,u,$m);if(0===h)return 0;for(var c,d,f=0,p=-1,g=0;h>g;g++){var v=$m[g],m=0===v||1===v?.5:1,y=er(t,n,r,a,v);l>y||(0>p&&(p=rr(e,i,o,s,Km),Km[1]<Km[0]&&p>1&&Ir(),c=er(e,i,o,s,Km[0]),p>1&&(d=er(e,i,o,s,Km[1]))),f+=2==p?v<Km[0]?e>c?m:-m:v<Km[1]?c>d?m:-m:d>s?m:-m:v<Km[0]?e>c?m:-m:c>s?m:-m)}return f}function Tr(t,e,n,i,r,o,a,s){if(s>e&&s>i&&s>o||e>s&&i>s&&o>s)return 0;var l=ur(e,i,o,s,$m);if(0===l)return 0;var u=hr(e,i,o);if(u>=0&&1>=u){for(var h=0,c=sr(e,i,o,u),d=0;l>d;d++){var f=0===$m[d]||1===$m[d]?.5:1,p=sr(t,n,r,$m[d]);a>p||(h+=$m[d]<u?e>c?f:-f:c>o?f:-f)}return h}var f=0===$m[0]||1===$m[0]?.5:1,p=sr(t,n,r,$m[0]);return a>p?0:e>o?f:-f}function Ar(t,e,n,i,r,o,a,s){if(s-=e,s>n||-n>s)return 0;var l=Math.sqrt(n*n-s*s);$m[0]=-l,$m[1]=l;var u=Math.abs(i-r);if(1e-4>u)return 0;if(1e-4>u%Ym){i=0,r=Ym;var h=o?1:-1;return a>=$m[0]+t&&a<=$m[1]+t?h:0}if(o){var l=i;i=wr(r),r=wr(l)}else i=wr(i),r=wr(r);i>r&&(r+=Ym);for(var c=0,d=0;2>d;d++){var f=$m[d];if(f+t>a){var p=Math.atan2(s,f),h=o?1:-1;0>p&&(p=Ym+p),(p>=i&&r>=p||p+Ym>=i&&r>=p+Ym)&&(p>Math.PI/2&&p<1.5*Math.PI&&(h=-h),c+=h)}}return c}function Dr(t,e,n,i,r){for(var o=0,a=0,s=0,l=0,u=0,h=0;h<t.length;){var c=t[h++];switch(c===Xm.M&&h>1&&(n||(o+=Mr(a,s,l,u,i,r))),1==h&&(a=t[h],s=t[h+1],l=a,u=s),c){case Xm.M:l=t[h++],u=t[h++],a=l,s=u;break;case Xm.L:if(n){if(yr(a,s,t[h],t[h+1],e,i,r))return!0}else o+=Mr(a,s,t[h],t[h+1],i,r)||0;a=t[h++],s=t[h++];break;case Xm.C:if(n){if(xr(a,s,t[h++],t[h++],t[h++],t[h++],t[h],t[h+1],e,i,r))return!0}else o+=Cr(a,s,t[h++],t[h++],t[h++],t[h++],t[h],t[h+1],i,r)||0;a=t[h++],s=t[h++];break;case Xm.Q:if(n){if(_r(a,s,t[h++],t[h++],t[h],t[h+1],e,i,r))return!0}else o+=Tr(a,s,t[h++],t[h++],t[h],t[h+1],i,r)||0;a=t[h++],s=t[h++];break;case Xm.A:var d=t[h++],f=t[h++],p=t[h++],g=t[h++],v=t[h++],m=t[h++],y=(t[h++],1-t[h++]),x=Math.cos(v)*p+d,_=Math.sin(v)*g+f;h>1?o+=Mr(a,s,x,_,i,r):(l=x,u=_);var w=(i-d)*g/p+d;if(n){if(br(d,f,g,v,v+m,y,e,w,r))return!0}else o+=Ar(d,f,g,v,v+m,y,w,r);a=Math.cos(v+m)*p+d,s=Math.sin(v+m)*g+f;break;case Xm.R:l=a=t[h++],u=s=t[h++];var b=t[h++],M=t[h++],x=l+b,_=u+M;if(n){if(yr(l,u,x,u,e,i,r)||yr(x,u,x,_,e,i,r)||yr(x,_,l,_,e,i,r)||yr(l,_,l,u,e,i,r))return!0}else o+=Mr(x,u,x,_,i,r),o+=Mr(l,_,l,u,i,r);break;case Xm.Z:if(n){if(yr(a,s,l,u,e,i,r))return!0}else o+=Mr(a,s,l,u,i,r);a=l,s=u}}return n||Sr(s,u)||(o+=Mr(a,s,l,u,i,r)||0),0!==o}function kr(t,e,n){return Dr(t,0,!1,e,n)}function Pr(t,e,n,i){return Dr(t,e,!0,n,i)}function Lr(t){oi.call(this,t),this.path=null}function Or(t,e,n,i,r,o,a,s,l,u,h){var c=l*(hy/180),d=uy(c)*(t-n)/2+ly(c)*(e-i)/2,f=-1*ly(c)*(t-n)/2+uy(c)*(e-i)/2,p=d*d/(a*a)+f*f/(s*s);p>1&&(a*=sy(p),s*=sy(p));var g=(r===o?-1:1)*sy((a*a*s*s-a*a*f*f-s*s*d*d)/(a*a*f*f+s*s*d*d))||0,v=g*a*f/s,m=g*-s*d/a,y=(t+n)/2+uy(c)*v-ly(c)*m,x=(e+i)/2+ly(c)*v+uy(c)*m,_=fy([1,0],[(d-v)/a,(f-m)/s]),w=[(d-v)/a,(f-m)/s],b=[(-1*d-v)/a,(-1*f-m)/s],M=fy(w,b);dy(w,b)<=-1&&(M=hy),dy(w,b)>=1&&(M=0),0===o&&M>0&&(M-=2*hy),1===o&&0>M&&(M+=2*hy),h.addData(u,y,x,a,s,_,M,c,o)}function Er(t){if(!t)return[];var e,n=t.replace(/-/g," -").replace(/  /g," ").replace(/ /g,",").replace(/,,/g,",");for(e=0;e<ay.length;e++)n=n.replace(new RegExp(ay[e],"g"),"|"+ay[e]);var i,r=n.split("|"),o=0,a=0,s=new Um,l=Um.CMD;for(e=1;e<r.length;e++){var u,h=r[e],c=h.charAt(0),d=0,f=h.slice(1).replace(/e,-/g,"e-").split(",");f.length>0&&""===f[0]&&f.shift();for(var p=0;p<f.length;p++)f[p]=parseFloat(f[p]);for(;d<f.length&&!isNaN(f[d])&&!isNaN(f[0]);){var g,v,m,y,x,_,w,b=o,M=a;switch(c){case"l":o+=f[d++],a+=f[d++],u=l.L,s.addData(u,o,a);break;case"L":o=f[d++],a=f[d++],u=l.L,s.addData(u,o,a);break;case"m":o+=f[d++],a+=f[d++],u=l.M,s.addData(u,o,a),c="l";break;case"M":o=f[d++],a=f[d++],u=l.M,s.addData(u,o,a),c="L";break;case"h":o+=f[d++],u=l.L,s.addData(u,o,a);break;case"H":o=f[d++],u=l.L,s.addData(u,o,a);break;case"v":a+=f[d++],u=l.L,s.addData(u,o,a);break;case"V":a=f[d++],u=l.L,s.addData(u,o,a);break;case"C":u=l.C,s.addData(u,f[d++],f[d++],f[d++],f[d++],f[d++],f[d++]),o=f[d-2],a=f[d-1];break;case"c":u=l.C,s.addData(u,f[d++]+o,f[d++]+a,f[d++]+o,f[d++]+a,f[d++]+o,f[d++]+a),o+=f[d-2],a+=f[d-1];break;case"S":g=o,v=a;var S=s.len(),I=s.data;i===l.C&&(g+=o-I[S-4],v+=a-I[S-3]),u=l.C,b=f[d++],M=f[d++],o=f[d++],a=f[d++],s.addData(u,g,v,b,M,o,a);break;case"s":g=o,v=a;var S=s.len(),I=s.data;i===l.C&&(g+=o-I[S-4],v+=a-I[S-3]),u=l.C,b=o+f[d++],M=a+f[d++],o+=f[d++],a+=f[d++],s.addData(u,g,v,b,M,o,a);break;case"Q":b=f[d++],M=f[d++],o=f[d++],a=f[d++],u=l.Q,s.addData(u,b,M,o,a);break;case"q":b=f[d++]+o,M=f[d++]+a,o+=f[d++],a+=f[d++],u=l.Q,s.addData(u,b,M,o,a);break;case"T":g=o,v=a;var S=s.len(),I=s.data;i===l.Q&&(g+=o-I[S-4],v+=a-I[S-3]),o=f[d++],a=f[d++],u=l.Q,s.addData(u,g,v,o,a);break;case"t":g=o,v=a;var S=s.len(),I=s.data;i===l.Q&&(g+=o-I[S-4],v+=a-I[S-3]),o+=f[d++],a+=f[d++],u=l.Q,s.addData(u,g,v,o,a);break;case"A":m=f[d++],y=f[d++],x=f[d++],_=f[d++],w=f[d++],b=o,M=a,o=f[d++],a=f[d++],u=l.A,Or(b,M,o,a,_,w,m,y,x,u,s);break;case"a":m=f[d++],y=f[d++],x=f[d++],_=f[d++],w=f[d++],b=o,M=a,o+=f[d++],a+=f[d++],u=l.A,Or(b,M,o,a,_,w,m,y,x,u,s)}}("z"===c||"Z"===c)&&(u=l.Z,s.addData(u)),i=u}return s.toStatic(),s}function Rr(t,e){var n=Er(t);return e=e||{},e.buildPath=function(t){if(t.setData){t.setData(n.data);var e=t.getContext();e&&t.rebuildPath(e)}else{var e=t;n.rebuildPath(e)}},e.applyTransform=function(t){oy(n,t),this.dirty(!0)},e}function zr(t,e){return new Lr(Rr(t,e))}function Br(t,e){return Lr.extend(Rr(t,e))}function Nr(t,e){for(var n=[],i=t.length,r=0;i>r;r++){var o=t[r];o.path||o.createPathProxy(),o.__dirtyPath&&o.buildPath(o.path,o.shape,!0),n.push(o.path)}var a=new Lr(e);return a.createPathProxy(),a.buildPath=function(t){t.appendPath(n);var e=t.getContext();e&&t.rebuildPath(e)},a}function Vr(t,e,n,i,r,o,a){var s=.5*(n-t),l=.5*(i-e);return(2*(e-n)+s+l)*a+(-3*(e-n)-2*s-l)*o+s*r+e}function Fr(t,e,n){var i=e.points,r=e.smooth;if(i&&i.length>=2){if(r&&"spline"!==r){var o=wy(i,r,n,e.smoothConstraint);t.moveTo(i[0][0],i[0][1]);for(var a=i.length,s=0;(n?a:a-1)>s;s++){var l=o[2*s],u=o[2*s+1],h=i[(s+1)%a];t.bezierCurveTo(l[0],l[1],u[0],u[1],h[0],h[1])}}else{"spline"===r&&(i=_y(i,n)),t.moveTo(i[0][0],i[0][1]);for(var s=1,c=i.length;c>s;s++)t.lineTo(i[s][0],i[s][1])}n&&t.closePath()}}function Hr(t,e,n){var i=t.cpx2,r=t.cpy2;return null===i||null===r?[(n?nr:er)(t.x1,t.cpx1,t.cpx2,t.x2,e),(n?nr:er)(t.y1,t.cpy1,t.cpy2,t.y2,e)]:[(n?lr:sr)(t.x1,t.cpx1,t.x2,e),(n?lr:sr)(t.y1,t.cpy1,t.y2,e)]}function Wr(t){oi.call(this,t),this._displayables=[],this._temporaryDisplayables=[],this._cursor=0,this.notClear=!0}function Gr(t){return Lr.extend(t)}function Ur(t,e){return Br(t,e)}function Zr(t,e,n,i){var r=zr(t,e),o=r.getBoundingRect();return n&&("center"===i&&(n=Xr(n,o)),Yr(r,n)),r}function jr(t,e,n){var i=new ai({style:{image:t,x:e.x,y:e.y,width:e.width,height:e.height},onload:function(t){if("center"===n){var r={width:t.width,height:t.height};i.setStyle(Xr(e,r))}}});return i}function Xr(t,e){var n,i=e.width/e.height,r=t.height*i;r<=t.width?n=t.height:(r=t.width,n=r/i);var o=t.x+t.width/2,a=t.y+t.height/2;return{x:o-r/2,y:a-n/2,width:r,height:n}}function Yr(t,e){if(t.applyTransform){var n=t.getBoundingRect(),i=n.calculateTransform(e);t.applyTransform(i)}}function qr(t){var e=t.shape,n=t.style.lineWidth;return Ey(2*e.x1)===Ey(2*e.x2)&&(e.x1=e.x2=Kr(e.x1,n,!0)),Ey(2*e.y1)===Ey(2*e.y2)&&(e.y1=e.y2=Kr(e.y1,n,!0)),t}function $r(t){var e=t.shape,n=t.style.lineWidth,i=e.x,r=e.y,o=e.width,a=e.height;return e.x=Kr(e.x,n,!0),e.y=Kr(e.y,n,!0),e.width=Math.max(Kr(i+o,n,!1)-e.x,0===o?0:1),e.height=Math.max(Kr(r+a,n,!1)-e.y,0===a?0:1),t}function Kr(t,e,n){var i=Ey(2*t);return(i+Ey(e))%2===0?i/2:(i+(n?1:-1))/2}function Qr(t){return null!=t&&"none"!=t}function Jr(t){return"string"==typeof t?Be(t,-.1):t}function to(t){if(t.__hoverStlDirty){var e=t.style.stroke,n=t.style.fill,i=t.__hoverStl;i.fill=i.fill||(Qr(n)?Jr(n):null),i.stroke=i.stroke||(Qr(e)?Jr(e):null);var r={};for(var o in i)null!=i[o]&&(r[o]=t.style[o]);t.__normalStl=r,t.__hoverStlDirty=!1}}function eo(t){if(!t.__isHover){if(to(t),t.useHoverLayer)t.__zr&&t.__zr.addHover(t,t.__hoverStl);else{var e=t.style,n=e.insideRollbackOpt;n&&_o(e),e.extendFrom(t.__hoverStl),n&&(xo(e,e.insideOriginalTextPosition,n),null==e.textFill&&(e.textFill=n.autoColor)),t.dirty(!1),t.z2+=1}t.__isHover=!0}}function no(t){if(t.__isHover){var e=t.__normalStl;t.useHoverLayer?t.__zr&&t.__zr.removeHover(t):(e&&t.setStyle(e),t.z2-=1),t.__isHover=!1}}function io(t){"group"===t.type?t.traverse(function(t){"group"!==t.type&&eo(t)}):eo(t)}function ro(t){"group"===t.type?t.traverse(function(t){"group"!==t.type&&no(t)}):no(t)}function oo(t,e){t.__hoverStl=t.hoverStyle||e||{},t.__hoverStlDirty=!0,t.__isHover&&to(t)}function ao(t){this.__hoverSilentOnTouch&&t.zrByTouch||!this.__isEmphasis&&io(this)}function so(t){this.__hoverSilentOnTouch&&t.zrByTouch||!this.__isEmphasis&&ro(this)}function lo(){this.__isEmphasis=!0,io(this)}function uo(){this.__isEmphasis=!1,ro(this)}function ho(t,e,n){t.__hoverSilentOnTouch=n&&n.hoverSilentOnTouch,"group"===t.type?t.traverse(function(t){"group"!==t.type&&oo(t,e)}):oo(t,e),t.on("mouseover",ao).on("mouseout",so),t.on("emphasis",lo).on("normal",uo)}function co(t,e,n,i,r,o,a){r=r||By;var s,l=r.labelFetcher,u=r.labelDataIndex,h=r.labelDimIndex,c=n.getShallow("show"),d=i.getShallow("show");(c||d)&&(l&&(s=l.getFormattedLabel(u,"normal",null,h)),null==s&&(s=w(r.defaultText)?r.defaultText(u,r):r.defaultText));var f=c?s:null,p=d?D(l?l.getFormattedLabel(u,"emphasis",null,h):null,s):null;(null!=f||null!=p)&&(fo(t,n,o,r),fo(e,i,a,r,!0)),t.text=f,e.text=p}function fo(t,e,n,i,r){return go(t,e,i,r),n&&a(t,n),t.host&&t.host.dirty&&t.host.dirty(!1),t}function po(t,e,n){var i,r={isRectText:!0};n===!1?i=!0:r.autoColor=n,go(t,e,r,i),t.host&&t.host.dirty&&t.host.dirty(!1)}function go(t,e,n,i){if(n=n||By,n.isRectText){var r=e.getShallow("position")||(i?null:"inside");"outside"===r&&(r="top"),t.textPosition=r,t.textOffset=e.getShallow("offset");var o=e.getShallow("rotate");null!=o&&(o*=Math.PI/180),t.textRotation=o,t.textDistance=D(e.getShallow("distance"),i?null:5)}var a,s=e.ecModel,l=s&&s.option.textStyle,u=vo(e);if(u){a={};for(var h in u)if(u.hasOwnProperty(h)){var c=e.getModel(["rich",h]);mo(a[h]={},c,l,n,i)}}return t.rich=a,mo(t,e,l,n,i,!0),n.forceRich&&!n.textStyle&&(n.textStyle={}),t}function vo(t){for(var e;t&&t!==t.ecModel;){var n=(t.option||By).rich;if(n){e=e||{};for(var i in n)n.hasOwnProperty(i)&&(e[i]=1)}t=t.parentModel}return e}function mo(t,e,n,i,r,o){if(n=!r&&n||By,t.textFill=yo(e.getShallow("color"),i)||n.color,t.textStroke=yo(e.getShallow("textBorderColor"),i)||n.textBorderColor,t.textStrokeWidth=D(e.getShallow("textBorderWidth"),n.textBorderWidth),!r){if(o){var a=t.textPosition;t.insideRollback=xo(t,a,i),t.insideOriginalTextPosition=a,t.insideRollbackOpt=i}null==t.textFill&&(t.textFill=i.autoColor)}t.fontStyle=e.getShallow("fontStyle")||n.fontStyle,t.fontWeight=e.getShallow("fontWeight")||n.fontWeight,t.fontSize=e.getShallow("fontSize")||n.fontSize,t.fontFamily=e.getShallow("fontFamily")||n.fontFamily,t.textAlign=e.getShallow("align"),t.textVerticalAlign=e.getShallow("verticalAlign")||e.getShallow("baseline"),t.textLineHeight=e.getShallow("lineHeight"),t.textWidth=e.getShallow("width"),t.textHeight=e.getShallow("height"),t.textTag=e.getShallow("tag"),o&&i.disableBox||(t.textBackgroundColor=yo(e.getShallow("backgroundColor"),i),t.textPadding=e.getShallow("padding"),t.textBorderColor=yo(e.getShallow("borderColor"),i),t.textBorderWidth=e.getShallow("borderWidth"),t.textBorderRadius=e.getShallow("borderRadius"),t.textBoxShadowColor=e.getShallow("shadowColor"),t.textBoxShadowBlur=e.getShallow("shadowBlur"),t.textBoxShadowOffsetX=e.getShallow("shadowOffsetX"),t.textBoxShadowOffsetY=e.getShallow("shadowOffsetY")),t.textShadowColor=e.getShallow("textShadowColor")||n.textShadowColor,t.textShadowBlur=e.getShallow("textShadowBlur")||n.textShadowBlur,t.textShadowOffsetX=e.getShallow("textShadowOffsetX")||n.textShadowOffsetX,t.textShadowOffsetY=e.getShallow("textShadowOffsetY")||n.textShadowOffsetY}function yo(t,e){return"auto"!==t?t:e&&e.autoColor?e.autoColor:null}function xo(t,e,n){var i,r=n.useInsideStyle;return null==t.textFill&&r!==!1&&(r===!0||n.isRectText&&e&&"string"==typeof e&&e.indexOf("inside")>=0)&&(i={textFill:null,textStroke:t.textStroke,textStrokeWidth:t.textStrokeWidth},t.textFill="#fff",null==t.textStroke&&(t.textStroke=n.autoColor,null==t.textStrokeWidth&&(t.textStrokeWidth=2))),i}function _o(t){var e=t.insideRollback;e&&(t.textFill=e.textFill,t.textStroke=e.textStroke,t.textStrokeWidth=e.textStrokeWidth)}function wo(t,e){var n=e||e.getModel("textStyle");return E([t.fontStyle||n&&n.getShallow("fontStyle")||"",t.fontWeight||n&&n.getShallow("fontWeight")||"",(t.fontSize||n&&n.getShallow("fontSize")||12)+"px",t.fontFamily||n&&n.getShallow("fontFamily")||"sans-serif"].join(" "))}function bo(t,e,n,i,r,o){"function"==typeof r&&(o=r,r=null);var a=i&&i.isAnimationEnabled();if(a){var s=t?"Update":"",l=i.getShallow("animationDuration"+s),u=i.getShallow("animationEasing"+s),h=i.getShallow("animationDelay"+s);"function"==typeof h&&(h=h(r,i.getAnimationDelayParams?i.getAnimationDelayParams(e,r):null)),"function"==typeof l&&(l=l(r)),l>0?e.animateTo(n,l,h||0,u,o,!!o):(e.stopAnimation(),e.attr(n),o&&o())}else e.stopAnimation(),e.attr(n),o&&o()}function Mo(t,e,n,i,r){bo(!0,t,e,n,i,r)}function So(t,e,n,i,r){bo(!1,t,e,n,i,r)}function Io(t,e){for(var n=pe([]);t&&t!==e;)ve(n,t.getLocalTransform(),n),t=t.parent;return n}function Co(t,e,n){return e&&!d(e)&&(e=Dg.getLocalTransform(e)),n&&(e=_e([],e)),oe([],t,e)}function To(t,e,n){var i=0===e[4]||0===e[5]||0===e[0]?1:Math.abs(2*e[4]/e[0]),r=0===e[4]||0===e[5]||0===e[2]?1:Math.abs(2*e[4]/e[2]),o=["left"===t?-i:"right"===t?i:0,"top"===t?-r:"bottom"===t?r:0];return o=Co(o,e,n),Math.abs(o[0])>Math.abs(o[1])?o[0]>0?"right":"left":o[1]>0?"bottom":"top"}function Ao(t,e,n){function i(t){var e={};return t.traverse(function(t){!t.isGroup&&t.anid&&(e[t.anid]=t)}),e}function r(t){var e={position:G(t.position),rotation:t.rotation};return t.shape&&(e.shape=a({},t.shape)),e}if(t&&e){var o=i(t);e.traverse(function(t){if(!t.isGroup&&t.anid){var e=o[t.anid];if(e){var i=r(t);t.attr(r(e)),Mo(t,i,n,t.dataIndex)}}})}}function Do(t,e){return p(t,function(t){var n=t[0];n=Ry(n,e.x),n=zy(n,e.x+e.width);var i=t[1];return i=Ry(i,e.y),i=zy(i,e.y+e.height),[n,i]})}function ko(t,e){var n=Ry(t.x,e.x),i=zy(t.x+t.width,e.x+e.width),r=Ry(t.y,e.y),o=zy(t.y+t.height,e.y+e.height);return i>=n&&o>=r?{x:n,y:r,width:i-n,height:o-r}:void 0}function Po(t,e,n){e=a({rectHover:!0},e);var i=e.style={strokeNoScale:!0};return n=n||{x:-1,y:-1,width:2,height:2},t?0===t.indexOf("image://")?(i.image=t.slice(8),s(i,n),new ai(e)):Zr(t.replace("path://",""),e,n,"center"):void 0}function Lo(t,e,n){this.parentModel=e,this.ecModel=n,this.option=t}function Oo(t,e,n){for(var i=0;i<e.length&&(!e[i]||(t=t&&"object"==typeof t?t[e[i]]:null,null!=t));i++);return null==t&&n&&(t=n.get(e)),t}function Eo(t,e){var n=Zy(t).getParent;return n?n.call(t,e):t.parentModel}function Ro(t){return[t||"",jy++,Math.random().toFixed(5)].join("_")}function zo(t){var e={};return t.registerSubTypeDefaulter=function(t,n){t=ji(t),e[t.main]=n},t.determineSubType=function(n,i){var r=i.type;if(!r){var o=ji(n).main;t.hasSubTypes(n)&&e[o]&&(r=e[o](i))}return r},t}function Bo(t,e){function n(t){var n={},o=[];return f(t,function(a){var s=i(n,a),l=s.originalDeps=e(a),h=r(l,t);s.entryCount=h.length,0===s.entryCount&&o.push(a),f(h,function(t){u(s.predecessor,t)<0&&s.predecessor.push(t);var e=i(n,t);u(e.successor,t)<0&&e.successor.push(a)})}),{graph:n,noEntryList:o}}function i(t,e){return t[e]||(t[e]={predecessor:[],successor:[]}),t[e]}function r(t,e){var n=[];return f(t,function(t){u(e,t)>=0&&n.push(t)}),n}t.topologicalTravel=function(t,e,i,r){function o(t){l[t].entryCount--,0===l[t].entryCount&&u.push(t)}function a(t){h[t]=!0,o(t)}if(t.length){var s=n(e),l=s.graph,u=s.noEntryList,h={};for(f(t,function(t){h[t]=!0});u.length;){var c=u.pop(),d=l[c],p=!!h[c];p&&(i.call(r,c,d.originalDeps.slice()),delete h[c]),f(d.successor,p?a:o)}f(h,function(){throw new Error("Circle dependency may exists")})}}}function No(t){return t.replace(/^\s+/,"").replace(/\s+$/,"")}function Vo(t,e,n,i){var r=e[1]-e[0],o=n[1]-n[0];if(0===r)return 0===o?n[0]:(n[0]+n[1])/2;if(i)if(r>0){if(t<=e[0])return n[0];if(t>=e[1])return n[1]}else{if(t>=e[0])return n[0];if(t<=e[1])return n[1]}else{if(t===e[0])return n[0];if(t===e[1])return n[1]}return(t-e[0])/r*o+n[0]}function Fo(t,e){switch(t){case"center":case"middle":t="50%";break;case"left":case"top":t="0%";break;case"right":case"bottom":t="100%"}return"string"==typeof t?No(t).match(/%$/)?parseFloat(t)/100*e:parseFloat(t):null==t?0/0:+t}function Ho(t,e,n){return null==e&&(e=10),e=Math.min(Math.max(0,e),20),t=(+t).toFixed(e),n?t:+t}function Wo(t){return t.sort(function(t,e){return t-e}),t}function Go(t){if(t=+t,isNaN(t))return 0;for(var e=1,n=0;Math.round(t*e)/e!==t;)e*=10,n++;return n}function Uo(t){var e=t.toString(),n=e.indexOf("e");if(n>0){var i=+e.slice(n+1);return 0>i?-i:0}var r=e.indexOf(".");return 0>r?0:e.length-1-r}function Zo(t,e){var n=Math.log,i=Math.LN10,r=Math.floor(n(t[1]-t[0])/i),o=Math.round(n(Math.abs(e[1]-e[0]))/i),a=Math.min(Math.max(-r+o,0),20);return isFinite(a)?a:20}function jo(t,e,n){if(!t[e])return 0;var i=g(t,function(t,e){return t+(isNaN(e)?0:e)},0);if(0===i)return 0;for(var r=Math.pow(10,n),o=p(t,function(t){return(isNaN(t)?0:t)/i*r*100}),a=100*r,s=p(o,function(t){return Math.floor(t)}),l=g(s,function(t,e){return t+e},0),u=p(o,function(t,e){return t-s[e]});a>l;){for(var h=Number.NEGATIVE_INFINITY,c=null,d=0,f=u.length;f>d;++d)u[d]>h&&(h=u[d],c=d);++s[c],u[c]=0,++l}return s[e]/r}function Xo(t){var e=2*Math.PI;return(t%e+e)%e}function Yo(t){return t>-Xy&&Xy>t}function qo(t){if(t instanceof Date)return t;if("string"==typeof t){var e=qy.exec(t);if(!e)return new Date(0/0);if(e[8]){var n=+e[4]||0;return"Z"!==e[8].toUpperCase()&&(n-=e[8].slice(0,3)),new Date(Date.UTC(+e[1],+(e[2]||1)-1,+e[3]||1,n,+(e[5]||0),+e[6]||0,+e[7]||0))}return new Date(+e[1],+(e[2]||1)-1,+e[3]||1,+e[4]||0,+(e[5]||0),+e[6]||0,+e[7]||0)}return new Date(null==t?0/0:Math.round(t))}function $o(t){return Math.pow(10,Ko(t))}function Ko(t){return Math.floor(Math.log(t)/Math.LN10)}function Qo(t,e){var n,i=Ko(t),r=Math.pow(10,i),o=t/r;return n=e?1.5>o?1:2.5>o?2:4>o?3:7>o?5:10:1>o?1:2>o?2:3>o?3:5>o?5:10,t=n*r,i>=-20?+t.toFixed(0>i?-i:0):t}function Jo(t){function e(t,n,i){return t.interval[i]<n.interval[i]||t.interval[i]===n.interval[i]&&(t.close[i]-n.close[i]===(i?-1:1)||!i&&e(t,n,1))}t.sort(function(t,n){return e(t,n,0)?-1:1});for(var n=-1/0,i=1,r=0;r<t.length;){for(var o=t[r].interval,a=t[r].close,s=0;2>s;s++)o[s]<=n&&(o[s]=n,a[s]=s?1:1-i),n=o[s],i=a[s];o[0]===o[1]&&a[0]*a[1]!==1?t.splice(r,1):r++}return t}function ta(t){return t-parseFloat(t)>=0}function ea(t){return isNaN(t)?"-":(t=(t+"").split("."),t[0].replace(/(\d{1,3})(?=(?:\d{3})+(?!\d))/g,"$1,")+(t.length>1?"."+t[1]:""))}function na(t,e){return t=(t||"").toLowerCase().replace(/-(.)/g,function(t,e){return e.toUpperCase()}),e&&t&&(t=t.charAt(0).toUpperCase()+t.slice(1)),t}function ia(t){return null==t?"":(t+"").replace(Qy,function(t,e){return Jy[e]})}function ra(t,e,n){_(e)||(e=[e]);var i=e.length;if(!i)return"";for(var r=e[0].$vars||[],o=0;o<r.length;o++){var a=tx[o];t=t.replace(ex(a),ex(a,0))}for(var s=0;i>s;s++)for(var l=0;l<r.length;l++){var u=e[s][r[l]];t=t.replace(ex(tx[l],s),n?ia(u):u)}return t}function oa(t,e,n){return f(e,function(e,i){t=t.replace("{"+i+"}",n?ia(e):e)}),t}function aa(t,e){t=b(t)?{color:t,extraCssText:e}:t||{};var n=t.color,i=t.type,e=t.extraCssText;return n?"subItem"===i?'<span style="display:inline-block;vertical-align:middle;margin-right:8px;margin-left:3px;border-radius:4px;width:4px;height:4px;background-color:'+ia(n)+";"+(e||"")+'"></span>':'<span style="display:inline-block;margin-right:5px;border-radius:10px;width:10px;height:10px;background-color:'+ia(n)+";"+(e||"")+'"></span>':""}function sa(t,e){return t+="","0000".substr(0,e-t.length)+t}function la(t,e,n){("week"===t||"month"===t||"quarter"===t||"half-year"===t||"year"===t)&&(t="MM-dd\nyyyy");var i=qo(e),r=n?"UTC":"",o=i["get"+r+"FullYear"](),a=i["get"+r+"Month"]()+1,s=i["get"+r+"Date"](),l=i["get"+r+"Hours"](),u=i["get"+r+"Minutes"](),h=i["get"+r+"Seconds"](),c=i["get"+r+"Milliseconds"]();return t=t.replace("MM",sa(a,2)).replace("M",a).replace("yyyy",o).replace("yy",o%100).replace("dd",sa(s,2)).replace("d",s).replace("hh",sa(l,2)).replace("h",l).replace("mm",sa(u,2)).replace("m",u).replace("ss",sa(h,2)).replace("s",h).replace("SSS",sa(c,3))}function ua(t){return t?t.charAt(0).toUpperCase()+t.substr(1):t}function ha(t,e,n,i,r){var o=0,a=0;null==i&&(i=1/0),null==r&&(r=1/0);var s=0;e.eachChild(function(l,u){var h,c,d=l.position,f=l.getBoundingRect(),p=e.childAt(u+1),g=p&&p.getBoundingRect();if("horizontal"===t){var v=f.width+(g?-g.x+f.x:0);h=o+v,h>i||l.newline?(o=0,h=v,a+=s+n,s=f.height):s=Math.max(s,f.height)}else{var m=f.height+(g?-g.y+f.y:0);c=a+m,c>r||l.newline?(o+=s+n,a=0,c=m,s=f.width):s=Math.max(s,f.width)}l.newline||(d[0]=o,d[1]=a,"horizontal"===t?o=h+n:a=c+n)})}function ca(t,e,n){n=Ky(n||0);var i=e.width,r=e.height,o=Fo(t.left,i),a=Fo(t.top,r),s=Fo(t.right,i),l=Fo(t.bottom,r),u=Fo(t.width,i),h=Fo(t.height,r),c=n[2]+n[0],d=n[1]+n[3],f=t.aspect;switch(isNaN(u)&&(u=i-s-d-o),isNaN(h)&&(h=r-l-c-a),null!=f&&(isNaN(u)&&isNaN(h)&&(f>i/r?u=.8*i:h=.8*r),isNaN(u)&&(u=f*h),isNaN(h)&&(h=u/f)),isNaN(o)&&(o=i-s-u-d),isNaN(a)&&(a=r-l-h-c),t.left||t.right){case"center":o=i/2-u/2-n[3];
+break;case"right":o=i-u-d}switch(t.top||t.bottom){case"middle":case"center":a=r/2-h/2-n[0];break;case"bottom":a=r-h-c}o=o||0,a=a||0,isNaN(u)&&(u=i-d-o-(s||0)),isNaN(h)&&(h=r-c-a-(l||0));var p=new rn(o+n[3],a+n[0],u,h);return p.margin=n,p}function da(t,e,n,i,r){var o=!r||!r.hv||r.hv[0],a=!r||!r.hv||r.hv[1],l=r&&r.boundingMode||"all";if(o||a){var u;if("raw"===l)u="group"===t.type?new rn(0,0,+e.width||0,+e.height||0):t.getBoundingRect();else if(u=t.getBoundingRect(),t.needLocalTransform()){var h=t.getLocalTransform();u=u.clone(),u.applyTransform(h)}e=ca(s({width:u.width,height:u.height},e),n,i);var c=t.position,d=o?e.x-u.x:0,f=a?e.y-u.y:0;t.attr("position","raw"===l?[d,f]:[c[0]+d,c[1]+f])}}function fa(t,e,n){function i(n,i){var a={},l=0,u={},h=0,c=2;if(ox(n,function(e){u[e]=t[e]}),ox(n,function(t){r(e,t)&&(a[t]=u[t]=e[t]),o(a,t)&&l++,o(u,t)&&h++}),s[i])return o(e,n[1])?u[n[2]]=null:o(e,n[2])&&(u[n[1]]=null),u;if(h!==c&&l){if(l>=c)return a;for(var d=0;d<n.length;d++){var f=n[d];if(!r(a,f)&&r(t,f)){a[f]=t[f];break}}return a}return u}function r(t,e){return t.hasOwnProperty(e)}function o(t,e){return null!=t[e]&&"auto"!==t[e]}function a(t,e,n){ox(t,function(t){e[t]=n[t]})}!M(n)&&(n={});var s=n.ignoreSize;!_(s)&&(s=[s,s]);var l=i(sx[0],0),u=i(sx[1],1);a(sx[0],t,l),a(sx[1],t,u)}function pa(t){return ga({},t)}function ga(t,e){return e&&t&&ox(ax,function(n){e.hasOwnProperty(n)&&(t[n]=e[n])}),t}function va(t){var e=[];return f(cx.getClassesByMainType(t),function(t){e=e.concat(t.prototype.dependencies||[])}),e=p(e,function(t){return ji(t).main}),"dataset"!==t&&u(e,"dataset")<=0&&e.unshift("dataset"),e}function ma(t,e){for(var n=t.length,i=0;n>i;i++)if(t[i].length>e)return t[i];return t[n-1]}function ya(t){var e=t.get("coordinateSystem"),n={coordSysName:e,coordSysDims:[],axisMap:N(),categoryAxisMap:N()},i=vx[e];return i?(i(t,n,n.axisMap,n.categoryAxisMap),n):void 0}function xa(t){return"category"===t.get("type")}function _a(t){this.fromDataset=t.fromDataset,this.data=t.data||(t.sourceFormat===_x?{}:[]),this.sourceFormat=t.sourceFormat||bx,this.seriesLayoutBy=t.seriesLayoutBy||Sx,this.dimensionsDefine=t.dimensionsDefine,this.encodeDefine=t.encodeDefine&&N(t.encodeDefine),this.startIndex=t.startIndex||0,this.dimensionsDetectCount=t.dimensionsDetectCount}function wa(t){var e=t.option.source,n=bx;if(I(e))n=Mx;else if(_(e))for(var i=0,r=e.length;r>i;i++){var o=e[i];if(null!=o){if(_(o)){n=yx;break}if(M(o)){n=xx;break}}}else if(M(e)){for(var a in e)if(e.hasOwnProperty(a)&&d(e[a])){n=_x;break}}else if(null!=e)throw new Error("Invalid data");Cx(t).sourceFormat=n}function ba(t){return Cx(t).source}function Ma(t){Cx(t).datasetMap=N()}function Sa(t){var e=t.option,n=e.data,i=I(n)?Mx:mx,r=!1,o=e.seriesLayoutBy,a=e.sourceHeader,s=e.dimensions,l=ka(t);if(l){var u=l.option;n=u.source,i=Cx(l).sourceFormat,r=!0,o=o||u.seriesLayoutBy,null==a&&(a=u.sourceHeader),s=s||u.dimensions}var h=Ia(n,i,o,a,s),c=e.encode;!c&&l&&(c=Da(t,l,n,i,o,h)),Cx(t).source=new _a({data:n,fromDataset:r,seriesLayoutBy:o,sourceFormat:i,dimensionsDefine:h.dimensionsDefine,startIndex:h.startIndex,dimensionsDetectCount:h.dimensionsDetectCount,encodeDefine:c})}function Ia(t,e,n,i,r){if(!t)return{dimensionsDefine:Ca(r)};var o,a,s;if(e===yx)"auto"===i||null==i?Ta(function(t){null!=t&&"-"!==t&&(b(t)?null==a&&(a=1):a=0)},n,t,10):a=i?1:0,r||1!==a||(r=[],Ta(function(t,e){r[e]=null!=t?t:""},n,t)),o=r?r.length:n===Ix?t.length:t[0]?t[0].length:null;else if(e===xx)r||(r=Aa(t),s=!0);else if(e===_x)r||(r=[],s=!0,f(t,function(t,e){r.push(e)}));else if(e===mx){var l=Ei(t[0]);o=_(l)&&l.length||1}var u;return s&&f(r,function(t,e){"name"===(M(t)?t.name:t)&&(u=e)}),{startIndex:a,dimensionsDefine:Ca(r),dimensionsDetectCount:o,potentialNameDimIndex:u}}function Ca(t){if(t){var e=N();return p(t,function(t){if(t=a({},M(t)?t:{name:t}),null==t.name)return t;t.name+="",null==t.displayName&&(t.displayName=t.name);var n=e.get(t.name);return n?t.name+="-"+n.count++:e.set(t.name,{count:1}),t})}}function Ta(t,e,n,i){if(null==i&&(i=1/0),e===Ix)for(var r=0;r<n.length&&i>r;r++)t(n[r]?n[r][0]:null,r);else for(var o=n[0]||[],r=0;r<o.length&&i>r;r++)t(o[r],r)}function Aa(t){for(var e,n=0;n<t.length&&!(e=t[n++]););if(e){var i=[];return f(e,function(t,e){i.push(e)}),i}}function Da(t,e,n,i,r,o){var a=ya(t),s={},l=[],u=[],h=t.subType,c=N(["pie","map","funnel"]),d=N(["line","bar","pictorialBar","scatter","effectScatter","candlestick","boxplot"]);if(a&&null!=d.get(h)){var p=t.ecModel,g=Cx(p).datasetMap,v=e.uid+"_"+r,m=g.get(v)||g.set(v,{categoryWayDim:1,valueWayDim:0});f(a.coordSysDims,function(t){if(null==a.firstCategoryDimIndex){var e=m.valueWayDim++;s[t]=e,u.push(e)}else if(a.categoryAxisMap.get(t))s[t]=0,l.push(0);else{var e=m.categoryWayDim++;s[t]=e,u.push(e)}})}else if(null!=c.get(h)){for(var y,x=0;5>x&&null==y;x++)La(n,i,r,o.dimensionsDefine,o.startIndex,x)||(y=x);if(null!=y){s.value=y;var _=o.potentialNameDimIndex||Math.max(y-1,0);u.push(_),l.push(_)}}return l.length&&(s.itemName=l),u.length&&(s.seriesName=u),s}function ka(t){var e=t.option,n=e.data;return n?void 0:t.ecModel.getComponent("dataset",e.datasetIndex||0)}function Pa(t,e){return La(t.data,t.sourceFormat,t.seriesLayoutBy,t.dimensionsDefine,t.startIndex,e)}function La(t,e,n,i,r,o){function a(t){return null!=t&&isFinite(t)&&""!==t?!1:b(t)&&"-"!==t?!0:void 0}var s,l=5;if(I(t))return!1;var u;if(i&&(u=i[o],u=M(u)?u.name:u),e===yx)if(n===Ix){for(var h=t[o],c=0;c<(h||[]).length&&l>c;c++)if(null!=(s=a(h[r+c])))return s}else for(var c=0;c<t.length&&l>c;c++){var d=t[r+c];if(d&&null!=(s=a(d[o])))return s}else if(e===xx){if(!u)return;for(var c=0;c<t.length&&l>c;c++){var f=t[c];if(f&&null!=(s=a(f[u])))return s}}else if(e===_x){if(!u)return;var h=t[u];if(!h||I(h))return!1;for(var c=0;c<h.length&&l>c;c++)if(null!=(s=a(h[c])))return s}else if(e===mx)for(var c=0;c<t.length&&l>c;c++){var f=t[c],p=Ei(f);if(!_(p))return!1;if(null!=(s=a(p[o])))return s}return!1}function Oa(t,e){if(e){var n=e.seiresIndex,i=e.seriesId,r=e.seriesName;return null!=n&&t.componentIndex!==n||null!=i&&t.id!==i||null!=r&&t.name!==r}}function Ea(t,e){var n=t.color&&!t.colorLayer;f(e,function(e,o){"colorLayer"===o&&n||cx.hasClass(o)||("object"==typeof e?t[o]=t[o]?r(t[o],e,!1):i(e):null==t[o]&&(t[o]=e))})}function Ra(t){t=t,this.option={},this.option[Tx]=1,this._componentsMap=N({series:[]}),this._seriesIndices,this._seriesIndicesMap,Ea(t,this._theme.option),r(t,fx,!1),this.mergeOption(t)}function za(t,e){_(e)||(e=e?[e]:[]);var n={};return f(e,function(e){n[e]=(t.get(e)||[]).slice()}),n}function Ba(t,e,n){var i=e.type?e.type:n?n.subType:cx.determineSubType(t,e);return i}function Na(t,e){t._seriesIndicesMap=N(t._seriesIndices=p(e,function(t){return t.componentIndex})||[])}function Va(t,e){return e.hasOwnProperty("subType")?v(t,function(t){return t.subType===e.subType}):t}function Fa(t){f(Dx,function(e){this[e]=y(t[e],t)},this)}function Ha(){this._coordinateSystems=[]}function Wa(t){this._api=t,this._timelineOptions=[],this._mediaList=[],this._mediaDefault,this._currentMediaIndices=[],this._optionBackup,this._newBaseOption}function Ga(t,e,n){var i,r,o=[],a=[],s=t.timeline;if(t.baseOption&&(r=t.baseOption),(s||t.options)&&(r=r||{},o=(t.options||[]).slice()),t.media){r=r||{};var l=t.media;Px(l,function(t){t&&t.option&&(t.query?a.push(t):i||(i=t))})}return r||(r=t),r.timeline||(r.timeline=s),Px([r].concat(o).concat(p(a,function(t){return t.option})),function(t){Px(e,function(e){e(t,n)})}),{baseOption:r,timelineOptions:o,mediaDefault:i,mediaList:a}}function Ua(t,e,n){var i={width:e,height:n,aspectratio:e/n},r=!0;return f(t,function(t,e){var n=e.match(Rx);if(n&&n[1]&&n[2]){var o=n[1],a=n[2].toLowerCase();Za(i[a],t,o)||(r=!1)}}),r}function Za(t,e,n){return"min"===n?t>=e:"max"===n?e>=t:t===e}function ja(t,e){return t.join(",")===e.join(",")}function Xa(t,e){e=e||{},Px(e,function(e,n){if(null!=e){var i=t[n];if(cx.hasClass(n)){e=Li(e),i=Li(i);var r=zi(i,e);t[n]=Ox(r,function(t){return t.option&&t.exist?Ex(t.exist,t.option,!0):t.exist||t.option})}else t[n]=Ex(i,e,!0)}})}function Ya(t){var e=t&&t.itemStyle;if(e)for(var n=0,i=Nx.length;i>n;n++){var o=Nx[n],a=e.normal,s=e.emphasis;a&&a[o]&&(t[o]=t[o]||{},t[o].normal?r(t[o].normal,a[o]):t[o].normal=a[o],a[o]=null),s&&s[o]&&(t[o]=t[o]||{},t[o].emphasis?r(t[o].emphasis,s[o]):t[o].emphasis=s[o],s[o]=null)}}function qa(t,e,n){if(t&&t[e]&&(t[e].normal||t[e].emphasis)){var i=t[e].normal,r=t[e].emphasis;i&&(n?(t[e].normal=t[e].emphasis=null,s(t[e],i)):t[e]=i),r&&(t.emphasis=t.emphasis||{},t.emphasis[e]=r)}}function $a(t){qa(t,"itemStyle"),qa(t,"lineStyle"),qa(t,"areaStyle"),qa(t,"label"),qa(t,"labelLine"),qa(t,"upperLabel"),qa(t,"edgeLabel")}function Ka(t,e){var n=Bx(t)&&t[e],i=Bx(n)&&n.textStyle;if(i)for(var r=0,o=im.length;o>r;r++){var e=im[r];i.hasOwnProperty(e)&&(n[e]=i[e])}}function Qa(t){t&&($a(t),Ka(t,"label"),t.emphasis&&Ka(t.emphasis,"label"))}function Ja(t){if(Bx(t)){Ya(t),$a(t),Ka(t,"label"),Ka(t,"upperLabel"),Ka(t,"edgeLabel"),t.emphasis&&(Ka(t.emphasis,"label"),Ka(t.emphasis,"upperLabel"),Ka(t.emphasis,"edgeLabel"));var e=t.markPoint;e&&(Ya(e),Qa(e));var n=t.markLine;n&&(Ya(n),Qa(n));var i=t.markArea;i&&Qa(i);var r=t.data;if("graph"===t.type){r=r||t.nodes;var o=t.links||t.edges;if(o&&!I(o))for(var a=0;a<o.length;a++)Qa(o[a]);f(t.categories,function(t){$a(t)})}if(r&&!I(r))for(var a=0;a<r.length;a++)Qa(r[a]);var e=t.markPoint;if(e&&e.data)for(var s=e.data,a=0;a<s.length;a++)Qa(s[a]);var n=t.markLine;if(n&&n.data)for(var l=n.data,a=0;a<l.length;a++)_(l[a])?(Qa(l[a][0]),Qa(l[a][1])):Qa(l[a]);"gauge"===t.type?(Ka(t,"axisLabel"),Ka(t,"title"),Ka(t,"detail")):"treemap"===t.type?(qa(t.breadcrumb,"itemStyle"),f(t.levels,function(t){$a(t)})):"tree"===t.type&&$a(t.leaves)}}function ts(t){return _(t)?t:t?[t]:[]}function es(t){return(_(t)?t[0]:t)||{}}function ns(t,e){e=e.split(",");for(var n=t,i=0;i<e.length&&(n=n&&n[e[i]],null!=n);i++);return n}function is(t,e,n,i){e=e.split(",");for(var r,o=t,a=0;a<e.length-1;a++)r=e[a],null==o[r]&&(o[r]={}),o=o[r];(i||null==o[e[a]])&&(o[e[a]]=n)}function rs(t){f(Fx,function(e){e[0]in t&&!(e[1]in t)&&(t[e[1]]=t[e[0]])})}function os(t){f(t,function(e,n){var i=[],r=[0/0,0/0],o=[e.stackResultDimension,e.stackedOverDimension],a=e.data,s=e.isStackedByIndex,l=a.map(o,function(o,l,u){var h=a.get(e.stackedDimension,u);if(isNaN(h))return r;var c,d;s?d=a.getRawIndex(u):c=a.get(e.stackedByDimension,u);for(var f=0/0,p=n-1;p>=0;p--){var g=t[p];if(s||(d=g.data.rawIndexOf(g.stackedByDimension,c)),d>=0){var v=g.data.getByRawIndex(g.stackResultDimension,d);if(h>=0&&v>0||0>=h&&0>v){h+=v,f=v;break}}}return i[0]=h,i[1]=f,i});a.hostModel.setData(l),e.data=l})}function as(t,e){_a.isInstance(t)||(t=_a.seriesDataToSource(t)),this._source=t;var n=this._data=t.data,i=t.sourceFormat;i===Mx&&(this._offset=0,this._dimSize=e,this._data=n);var r=Zx[i===yx?i+"_"+t.seriesLayoutBy:i];a(this,r)}function ss(){return this._data.length}function ls(t){return this._data[t]}function us(t){for(var e=0;e<t.length;e++)this._data.push(t[e])}function hs(t,e,n){return null!=n?t[n]:t}function cs(t,e,n,i){return ds(t[i],this._dimensionInfos[e])}function ds(t,e){var n=e&&e.type;if("ordinal"===n){var i=e&&e.ordinalMeta;return i?i.parseAndCollect(t):t}return"time"===n&&"number"!=typeof t&&null!=t&&"-"!==t&&(t=+qo(t)),null==t||""===t?0/0:+t}function fs(t,e,n){if(t){var i=t.getRawDataItem(e);if(null!=i){var r,o,a=t.getProvider().getSource().sourceFormat,s=t.getDimensionInfo(n);return s&&(r=s.name,o=s.index),jx[a](i,e,o,r)}}}function ps(t,e,n){if(t){var i=t.getProvider().getSource().sourceFormat;if(i===mx||i===xx){var r=t.getRawDataItem(e);return i!==mx||M(r)||(r=null),r?r[n]:void 0}}}function gs(t){return new vs(t)}function vs(t){t=t||{},this._reset=t.reset,this._plan=t.plan,this._count=t.count,this._onDirty=t.onDirty,this._dirty=!0,this.context}function ms(t,e,n,i,r,o){Kx.reset(n,i,r,o),t._callingProgress=e,t._callingProgress({start:n,end:i,count:i-n,next:Kx.next},t.context)}function ys(t,e){t._dueIndex=t._outputDueEnd=t._dueEnd=0,t._settedOutputEnd=null;var n,i;!e&&t._reset&&(n=t._reset(t.context),n&&n.progress&&(i=n.forceFirstProgress,n=n.progress),_(n)&&!n.length&&(n=null)),t._progress=n,t._modBy=t._modDataCount=null;var r=t._downstream;return r&&r.dirty(),i}function xs(t){var e=t.name;Ni(t)||(t.name=_s(t)||e)}function _s(t){var e=t.getRawData(),n=e.mapDimension("seriesName",!0),i=[];return f(n,function(t){var n=e.getDimensionInfo(t);n.displayName&&i.push(n.displayName)}),i.join(" ")}function ws(t){return t.model.getRawData().count()}function bs(t){var e=t.model;return e.setData(e.getRawData().cloneShallow()),Ms}function Ms(t,e){t.end>e.outputData.count()&&e.model.getRawData().cloneShallow(e.outputData)}function Ss(t,e){f(t.CHANGABLE_METHODS,function(n){t.wrapMethod(n,x(Is,e))})}function Is(t){var e=Cs(t);e&&e.setOutputEnd(this.count())}function Cs(t){var e=(t.ecModel||{}).scheduler,n=e&&e.getPipeline(t.uid);if(n){var i=n.currentTask;if(i){var r=i.agentStubMap;r&&(i=r.get(t.uid))}return i}}function Ts(){this.group=new nv,this.uid=Ro("viewChart"),this.renderTask=gs({plan:ks,reset:Ps}),this.renderTask.context={view:this}}function As(t,e){if(t&&(t.trigger(e),"group"===t.type))for(var n=0;n<t.childCount();n++)As(t.childAt(n),e)}function Ds(t,e,n){var i=Fi(t,e);null!=i?f(Li(i),function(e){As(t.getItemGraphicEl(e),n)}):t.eachItemGraphicEl(function(t){As(t,n)})}function ks(t){return r_(t.model)}function Ps(t){var e=t.model,n=t.ecModel,i=t.api,r=t.payload,o=e.pipelineContext.progressiveRender,a=t.view,s=r&&i_(r).updateMethod,l=o?"incrementalPrepareRender":s&&a[s]?s:"render";return"render"!==l&&a[l](e,n,i,r),a_[l]}function Ls(t,e,n){function i(){h=(new Date).getTime(),c=null,t.apply(a,s||[])}var r,o,a,s,l,u=0,h=0,c=null;e=e||0;var d=function(){r=(new Date).getTime(),a=this,s=arguments;var t=l||e,d=l||n;l=null,o=r-(d?u:h)-t,clearTimeout(c),d?c=setTimeout(i,t):o>=0?i():c=setTimeout(i,-o),u=r};return d.clear=function(){c&&(clearTimeout(c),c=null)},d.debounceNextCall=function(t){l=t},d}function Os(t,e,n,i){var r=t[e];if(r){var o=r[s_]||r,a=r[u_],s=r[l_];if(s!==n||a!==i){if(null==n||!i)return t[e]=o;r=t[e]=Ls(o,n,"debounce"===i),r[s_]=o,r[u_]=i,r[l_]=n}return r}}function Es(t,e,n,i){this.ecInstance=t,this.api=e,this.unfinished;var n=this._dataProcessorHandlers=n.slice(),i=this._visualHandlers=i.slice();this._allHandlers=n.concat(i),this._stageTaskMap=N()}function Rs(t,e,n,i,r){function o(t,e){return t.setDirty&&(!t.dirtyMap||t.dirtyMap.get(e.__pipeline.id))}r=r||{};var a;f(e,function(e){if(!r.visualType||r.visualType===e.visualType){var s=t._stageTaskMap.get(e.uid),l=s.seriesTaskMap,u=s.overallTask;if(u){var h,c=u.agentStubMap;c.each(function(t){o(r,t)&&(t.dirty(),h=!0)}),h&&u.dirty(),v_(u,i);var d=t.getPerformArgs(u,r.block);c.each(function(t){t.perform(d)}),a|=u.perform(d)}else l&&l.each(function(s){o(r,s)&&s.dirty();var l=t.getPerformArgs(s,r.block);l.skip=!e.performRawSeries&&n.isSeriesFiltered(s.context.model),v_(s,i),a|=s.perform(l)})}}),t.unfinished|=a}function zs(t,e,n,i,r){function o(n){var o=n.uid,s=a.get(o)||a.set(o,gs({plan:Ws,reset:Gs,count:Zs}));s.context={model:n,ecModel:i,api:r,useClearVisual:e.isVisual&&!e.isLayout,plan:e.plan,reset:e.reset,scheduler:t},js(t,n,s)}var a=n.seriesTaskMap||(n.seriesTaskMap=N()),s=e.seriesType,l=e.getTargetSeries;e.createOnAllSeries?i.eachRawSeries(o):s?i.eachRawSeriesByType(s,o):l&&l(i,r).each(o);var u=t._pipelineMap;a.each(function(t,e){u.get(e)||(t.dispose(),a.removeKey(e))})}function Bs(t,e,n,i,r){function o(e){var n=e.uid,i=s.get(n);i||(i=s.set(n,gs({reset:Vs,onDirty:Hs})),a.dirty()),i.context={model:e,overallProgress:h,modifyOutputEnd:c},i.agent=a,i.__block=h,js(t,e,i)}var a=n.overallTask=n.overallTask||gs({reset:Ns});a.context={ecModel:i,api:r,overallReset:e.overallReset,scheduler:t};var s=a.agentStubMap=a.agentStubMap||N(),l=e.seriesType,u=e.getTargetSeries,h=!0,c=e.modifyOutputEnd;l?i.eachRawSeriesByType(l,o):u?u(i,r).each(o):(h=!1,f(i.getSeries(),o));var d=t._pipelineMap;s.each(function(t,e){d.get(e)||(t.dispose(),a.dirty(),s.removeKey(e))})}function Ns(t){t.overallReset(t.ecModel,t.api,t.payload)}function Vs(t){return t.overallProgress&&Fs}function Fs(){this.agent.dirty(),this.getDownstream().dirty()}function Hs(){this.agent&&this.agent.dirty()}function Ws(t){return t.plan&&t.plan(t.model,t.ecModel,t.api,t.payload)}function Gs(t){t.useClearVisual&&t.data.clearAllVisual();var e=t.resetDefines=Li(t.reset(t.model,t.ecModel,t.api,t.payload));return e.length>1?p(e,function(t,e){return Us(e)}):m_}function Us(t){return function(e,n){var i=n.data,r=n.resetDefines[t];if(r&&r.dataEach)for(var o=e.start;o<e.end;o++)r.dataEach(i,o);else r&&r.progress&&r.progress(e,i)}}function Zs(t){return t.data.count()}function js(t,e,n){var i=e.uid,r=t._pipelineMap.get(i);!r.head&&(r.head=n),r.tail&&r.tail.pipe(n),r.tail=n,n.__idxInPipeline=r.count++,n.__pipeline=r}function Xs(t){y_=null;try{t(x_,__)}catch(e){}return y_}function Ys(t,e){for(var n in e.prototype)t[n]=F}function qs(t){return function(e,n,i){e=e&&e.toLowerCase(),wg.prototype[t].call(this,e,n,i)}}function $s(){wg.call(this)}function Ks(t,e,n){function r(t,e){return t.__prio-e.__prio}n=n||{},"string"==typeof e&&(e=ew[e]),this.id,this.group,this._dom=t;var o="canvas",a=this._zr=Ti(t,{renderer:n.renderer||o,devicePixelRatio:n.devicePixelRatio,width:n.width,height:n.height});this._throttledZrFlush=Ls(y(a.flush,a),17);var e=i(e);e&&Wx(e,!0),this._theme=e,this._chartsViews=[],this._chartsMap={},this._componentsViews=[],this._componentsMap={},this._coordSysMgr=new Ha;var s=this._api=gl(this);dn(tw,r),dn(K_,r),this._scheduler=new Es(this,s,K_,tw),wg.call(this),this._messageCenter=new $s,this._initEvents(),this.resize=y(this.resize,this),this._pendingActions=[],a.animation.on("frame",this._onframe,this),ol(a,this),R(this)}function Qs(t,e,n){var i,r=this._model,o=this._coordSysMgr.getCoordinateSystems();e=Wi(r,e);for(var a=0;a<o.length;a++){var s=o[a];if(s[t]&&null!=(i=s[t](r,e,n)))return i}}function Js(t){var e=t._model,n=t._scheduler;n.restorePipelines(e),n.prepareStageTasks(),al(t,"component",e,n),al(t,"chart",e,n),n.plan()}function tl(t,e,n,i,r){function o(i){i&&i.__alive&&i[e]&&i[e](i.__model,a,t._api,n)}var a=t._model;if(!i)return void A_(t._componentsViews.concat(t._chartsViews),o);var s={};s[i+"Id"]=n[i+"Id"],s[i+"Index"]=n[i+"Index"],s[i+"Name"]=n[i+"Name"];var l={mainType:i,query:s};r&&(l.subType=r);var u=n.excludeSeriesId;null!=u&&(u=N(Li(u))),a&&a.eachComponent(l,function(e){u&&null!=u.get(e.id)||o(t["series"===i?"_chartsMap":"_componentsMap"][e.__viewId])},t)}function el(t,e){var n=t._chartsMap,i=t._scheduler;e.eachSeries(function(t){i.updateStreamModes(t,n[t.__viewId])})}function nl(t,e){var n=t.type,i=t.escapeConnect,r=q_[n],o=r.actionInfo,l=(o.update||"update").split(":"),u=l.pop();l=null!=l[0]&&P_(l[0]),this[G_]=!0;var h=[t],c=!1;t.batch&&(c=!0,h=p(t.batch,function(e){return e=s(a({},e),t),e.batch=null,e}));var d,f=[],g="highlight"===n||"downplay"===n;A_(h,function(t){d=r.action(t,this._model,this._api),d=d||a({},t),d.type=o.event||d.type,f.push(d),g?tl(this,u,t,"series"):l&&tl(this,u,t,l.main,l.sub)},this),"none"===u||g||l||(this[U_]?(Js(this),X_.update.call(this,t),this[U_]=!1):X_[u].call(this,t)),d=c?{type:o.event||n,escapeConnect:i,batch:f}:f[0],this[G_]=!1,!e&&this._messageCenter.trigger(d.type,d)}function il(t){for(var e=this._pendingActions;e.length;){var n=e.shift();nl.call(this,n,t)}}function rl(t){!t&&this.trigger("updated")}function ol(t,e){t.on("rendered",function(){e.trigger("rendered"),!t.animation.isFinished()||e[U_]||e._scheduler.unfinished||e._pendingActions.length||e.trigger("finished")})}function al(t,e,n,i){function r(t){var e="_ec_"+t.id+"_"+t.type,r=s[e];if(!r){var h=P_(t.type),c=o?t_.getClass(h.main,h.sub):Ts.getClass(h.sub);r=new c,r.init(n,u),s[e]=r,a.push(r),l.add(r.group)}t.__viewId=r.__id=e,r.__alive=!0,r.__model=t,r.group.__ecComponentInfo={mainType:t.mainType,index:t.componentIndex},!o&&i.prepareView(r,t,n,u)}for(var o="component"===e,a=o?t._componentsViews:t._chartsViews,s=o?t._componentsMap:t._chartsMap,l=t._zr,u=t._api,h=0;h<a.length;h++)a[h].__alive=!1;o?n.eachComponent(function(t,e){"series"!==t&&r(e)}):n.eachSeries(r);for(var h=0;h<a.length;){var c=a[h];c.__alive?h++:(!o&&c.renderTask.dispose(),l.remove(c.group),c.dispose(n,u),a.splice(h,1),delete s[c.__id],c.__id=c.group.__ecComponentInfo=null)}}function sl(t){t.clearColorPalette(),t.eachSeries(function(t){t.clearColorPalette()})}function ll(t,e,n,i){ul(t,e,n,i),A_(t._chartsViews,function(t){t.__alive=!1}),hl(t,e,n,i),A_(t._chartsViews,function(t){t.__alive||t.remove(e,n)})}function ul(t,e,n,i,r){A_(r||t._componentsViews,function(t){var r=t.__model;t.render(r,e,n,i),pl(r,t)})}function hl(t,e,n,i,r){var o,a=t._scheduler;e.eachSeries(function(e){var n=t._chartsMap[e.__viewId];n.__alive=!0;var s=n.renderTask;a.updatePayload(s,i),r&&r.get(e.uid)&&s.dirty(),o|=s.perform(a.getPerformArgs(s)),n.group.silent=!!e.get("silent"),pl(e,n),fl(e,n)}),a.unfinished|=o,dl(t._zr,e),d_(t._zr.dom,e)}function cl(t,e){A_(J_,function(n){n(t,e)})}function dl(t,e){var n=t.storage,i=0;n.traverse(function(t){t.isGroup||i++}),i>e.get("hoverLayerThreshold")&&!Jp.node&&n.traverse(function(t){t.isGroup||(t.useHoverLayer=!0)})}function fl(t,e){var n=t.get("blendMode")||null;e.group.traverse(function(t){t.isGroup||t.style.blend!==n&&t.setStyle("blend",n),t.eachPendingDisplayable&&t.eachPendingDisplayable(function(t){t.setStyle("blend",n)})})}function pl(t,e){var n=t.get("z"),i=t.get("zlevel");e.group.traverse(function(t){"group"!==t.type&&(null!=n&&(t.z=n),null!=i&&(t.zlevel=i))})}function gl(t){var e=t._coordSysMgr;return a(new Fa(t),{getCoordinateSystems:y(e.getCoordinateSystems,e),getComponentByElement:function(e){for(;e;){var n=e.__ecComponentInfo;if(null!=n)return t._model.getComponent(n.mainType,n.index);e=e.parent}}})}function vl(t){function e(t,e){for(var n=0;n<t.length;n++){var i=t[n];i[o]=e}}var n=0,i=1,r=2,o="__connectUpdateStatus";A_($_,function(a,s){t._messageCenter.on(s,function(a){if(rw[t.group]&&t[o]!==n){if(a&&a.escapeConnect)return;var s=t.makeActionFromEvent(a),l=[];A_(iw,function(e){e!==t&&e.group===t.group&&l.push(e)}),e(l,n),A_(l,function(t){t[o]!==i&&t.dispatchAction(s)}),e(l,r)}})})}function ml(t,e,n){var i=wl(t);if(i)return i;var r=new Ks(t,e,n);return r.id="ec_"+ow++,iw[r.id]=r,Ui(t,sw,r.id),vl(r),r}function yl(t){if(_(t)){var e=t;t=null,A_(e,function(e){null!=e.group&&(t=e.group)}),t=t||"g_"+aw++,A_(e,function(e){e.group=t})}return rw[t]=!0,t}function xl(t){rw[t]=!1}function _l(t){"string"==typeof t?t=iw[t]:t instanceof Ks||(t=wl(t)),t instanceof Ks&&!t.isDisposed()&&t.dispose()}function wl(t){return iw[Zi(t,sw)]}function bl(t){return iw[t]}function Ml(t,e){ew[t]=e}function Sl(t){Q_.push(t)}function Il(t,e){Ll(K_,t,e,R_)}function Cl(t){J_.push(t)}function Tl(t,e,n){"function"==typeof e&&(n=e,e="");var i=k_(t)?t.type:[t,t={event:e}][0];t.event=(t.event||i).toLowerCase(),e=t.event,T_(Z_.test(i)&&Z_.test(e)),q_[i]||(q_[i]={action:n,actionInfo:t}),$_[e]=i}function Al(t,e){Ha.register(t,e)}function Dl(t){var e=Ha.get(t);return e?e.getDimensionsInfo?e.getDimensionsInfo():e.dimensions.slice():void 0}function kl(t,e){Ll(tw,t,e,B_,"layout")}function Pl(t,e){Ll(tw,t,e,V_,"visual")}function Ll(t,e,n,i,r){(D_(e)||k_(e))&&(n=e,e=i);var o=Es.wrapStageHandler(n,r);return o.__prio=e,o.__raw=n,t.push(o),o}function Ol(t,e){nw[t]=e}function El(t){return cx.extend(t)}function Rl(t){return t_.extend(t)}function zl(t){return Jx.extend(t)}function Bl(t){return Ts.extend(t)}function Nl(t){n("createCanvas",t)}function Vl(t,e,n){e.geoJson&&!e.features&&(n=e.specialAreas,e=e.geoJson),"string"==typeof e&&(e="undefined"!=typeof JSON&&JSON.parse?JSON.parse(e):new Function("return ("+e+");")()),lw[t]={geoJson:e,specialAreas:n}}function Fl(t){return lw[t]}function Hl(t){return t}function Wl(t,e,n,i,r){this._old=t,this._new=e,this._oldKeyGetter=n||Hl,this._newKeyGetter=i||Hl,this.context=r}function Gl(t,e,n,i,r){for(var o=0;o<t.length;o++){var a="_ec_"+r[i](t[o],o),s=e[a];null==s?(n.push(a),e[a]=o):(s.length||(e[a]=s=[s]),s.push(o))}}function Ul(t){var e={},n=e.encode={},i=N(),r=[],o=[];f(t.dimensions,function(e){var a=t.getDimensionInfo(e),s=a.coordDim;if(s){var l=n[s];n.hasOwnProperty(s)||(l=n[s]=[]),l[a.coordDimIndex]=e,a.isExtraCoord||(i.set(s,1),jl(a.type)&&(r[0]=e)),a.defaultTooltip&&o.push(e)}cw.each(function(t,e){var i=n[e];n.hasOwnProperty(e)||(i=n[e]=[]);var r=a.otherDims[e];null!=r&&r!==!1&&(i[r]=a.name)})});var a=[],s={};i.each(function(t,e){var i=n[e];s[e]=i[0],a=a.concat(i)}),e.dataDimsOnCoord=a,e.encodeFirstDimNotExtra=s;var l=n.label;l&&l.length&&(r=l.slice());var u=n.tooltip;return u&&u.length?o=u.slice():o.length||(o=r.slice()),n.defaultedLabel=r,n.defaultedTooltip=o,e}function Zl(t){return"category"===t?"ordinal":"time"===t?"time":"float"}function jl(t){return!("ordinal"===t||"time"===t)}function Xl(t){return t._rawCount>65535?vw:mw}function Yl(t){var e=t.constructor;return e===Array?t.slice():new e(t)}function ql(t,e){f(yw.concat(e.__wrappedMethods||[]),function(n){e.hasOwnProperty(n)&&(t[n]=e[n])}),t.__wrappedMethods=e.__wrappedMethods,f(xw,function(n){t[n]=i(e[n])}),t._calculationInfo=a(e._calculationInfo)}function $l(t){var e=t._invertedIndicesMap;f(e,function(n,i){var r=t._dimensionInfos[i],o=r.ordinalMeta;if(o){n=e[i]=new vw(o.categories.length);for(var a=0;a<n.length;a++)n[a]=0/0;for(var a=0;a<t._count;a++)n[t.get(i,a)]=a}})}function Kl(t,e,n){var i;if(null!=e){var r=t._chunkSize,o=Math.floor(n/r),a=n%r,s=t.dimensions[e],l=t._storage[s][o];if(l){i=l[a];var u=t._dimensionInfos[s].ordinalMeta;u&&u.categories.length&&(i=u.categories[i])}}return i}function Ql(t){return t}function Jl(t){return t<this._count&&t>=0?this._indices[t]:-1}function tu(t,e){var n=t._idList[e];return null==n&&(n=Kl(t,t._idDimIdx,e)),null==n&&(n=pw+e),n}function eu(t){return _(t)||(t=[t]),t}function nu(t,e){var n=t.dimensions,i=new _w(p(n,t.getDimensionInfo,t),t.hostModel);ql(i,t);for(var r=i._storage={},o=t._storage,a=0;a<n.length;a++){var s=n[a];o[s]&&(u(e,s)>=0?(r[s]=iu(o[s]),i._rawExtent[s]=ru(),i._extent[s]=null):r[s]=o[s])}return i}function iu(t){for(var e=new Array(t.length),n=0;n<t.length;n++)e[n]=Yl(t[n]);return e}function ru(){return[1/0,-1/0]}function ou(t,e,n){function r(t,e,n){null!=cw.get(e)?t.otherDims[e]=n:(t.coordDim=e,t.coordDimIndex=n,h.set(e,!0))}_a.isInstance(e)||(e=_a.seriesDataToSource(e)),n=n||{},t=(t||[]).slice();for(var o=(n.dimsDef||[]).slice(),l=N(n.encodeDef),u=N(),h=N(),c=[],d=au(e,t,o,n.dimCount),p=0;d>p;p++){var g=o[p]=a({},M(o[p])?o[p]:{name:o[p]}),v=g.name,m=c[p]={otherDims:{}};null!=v&&null==u.get(v)&&(m.name=m.displayName=v,u.set(v,p)),null!=g.type&&(m.type=g.type),null!=g.displayName&&(m.displayName=g.displayName)}l.each(function(t,e){t=Li(t).slice();var n=l.set(e,[]);f(t,function(t,i){b(t)&&(t=u.get(t)),null!=t&&d>t&&(n[i]=t,r(c[t],e,i))})});var y=0;f(t,function(t){var e,t,n,o;if(b(t))e=t,t={};else{e=t.name;var a=t.ordinalMeta;t.ordinalMeta=null,t=i(t),t.ordinalMeta=a,n=t.dimsDef,o=t.otherDims,t.name=t.coordDim=t.coordDimIndex=t.dimsDef=t.otherDims=null}var u=Li(l.get(e));if(!u.length)for(var h=0;h<(n&&n.length||1);h++){for(;y<c.length&&null!=c[y].coordDim;)y++;y<c.length&&u.push(y++)}f(u,function(i,a){var l=c[i];if(r(s(l,t),e,a),null==l.name&&n){var u=n[a];!M(u)&&(u={name:u}),l.name=l.displayName=u.name,l.defaultTooltip=u.defaultTooltip}o&&s(l.otherDims,o)})});var x=n.generateCoord,_=n.generateCoordCount,w=null!=_;_=x?_||1:0;for(var S=x||"value",I=0;d>I;I++){var m=c[I]=c[I]||{},C=m.coordDim;null==C&&(m.coordDim=su(S,h,w),m.coordDimIndex=0,(!x||0>=_)&&(m.isExtraCoord=!0),_--),null==m.name&&(m.name=su(m.coordDim,u)),null==m.type&&Pa(e,I,m.name)&&(m.type="ordinal")}return c}function au(t,e,n,i){var r=Math.max(t.dimensionsDetectCount||1,e.length,n.length,i||0);return f(e,function(t){var e=t.dimsDef;e&&(r=Math.max(r,e.length))}),r}function su(t,e,n){if(n||null!=e.get(t)){for(var i=0;null!=e.get(t+i);)i++;t+=i}return e.set(t,!0),t}function lu(t,e,n){n=n||{};var i,r,o,a,s=n.byIndex,l=n.stackedCoordDimension,u=!(!t||!t.get("stack"));if(f(e,function(t,n){b(t)&&(e[n]=t={name:t}),u&&!t.isExtraCoord&&(s||i||!t.ordinalMeta||(i=t),r||"ordinal"===t.type||"time"===t.type||l&&l!==t.coordDim||(r=t))}),!r||s||i||(s=!0),r){o="__\x00ecstackresult",a="__\x00ecstackedover",i&&(i.createInvertedIndices=!0);var h=r.coordDim,c=r.type,d=0;f(e,function(t){t.coordDim===h&&d++}),e.push({name:o,coordDim:h,coordDimIndex:d,type:c,isExtraCoord:!0,isCalculationCoord:!0}),d++,e.push({name:a,coordDim:a,coordDimIndex:d,type:c,isExtraCoord:!0,isCalculationCoord:!0})}return{stackedDimension:r&&r.name,stackedByDimension:i&&i.name,isStackedByIndex:s,stackedOverDimension:a,stackResultDimension:o}}function uu(t,e){return!!e&&e===t.getCalculationInfo("stackedDimension")}function hu(t,e){return uu(t,e)?t.getCalculationInfo("stackResultDimension"):e}function cu(t,e,n){n=n||{},_a.isInstance(t)||(t=_a.seriesDataToSource(t));var i,r=e.get("coordinateSystem"),o=Ha.get(r),a=ya(e);a&&(i=p(a.coordSysDims,function(t){var e={name:t},n=a.axisMap.get(t);if(n){var i=n.get("type");e.type=Zl(i)}return e})),i||(i=o&&(o.getDimensionsInfo?o.getDimensionsInfo():o.dimensions.slice())||["x","y"]);var s,l,u=Mw(t,{coordDimensions:i,generateCoord:n.generateCoord});a&&f(u,function(t,e){var n=t.coordDim,i=a.categoryAxisMap.get(n);i&&(null==s&&(s=e),t.ordinalMeta=i.getOrdinalMeta()),null!=t.otherDims.itemName&&(l=!0)}),l||null==s||(u[s].otherDims.itemName=0);var h=lu(e,u),c=new _w(u,e);c.setCalculationInfo(h);var d=null!=s&&du(t)?function(t,e,n,i){return i===s?n:this.defaultDimValueGetter(t,e,n,i)}:null;return c.hasItemOption=!1,c.initData(t,null,d),c}function du(t){if(t.sourceFormat===mx){var e=fu(t.data||[]);return null!=e&&!_(Ei(e))}}function fu(t){for(var e=0;e<t.length&&null==t[e];)e++;return t[e]}function pu(t){this._setting=t||{},this._extent=[1/0,-1/0],this._interval=0,this.init&&this.init.apply(this,arguments)}function gu(t){this.categories=t.categories||[],this._needCollect=t.needCollect,this._deduplication=t.deduplication,this._map}function vu(t){return t._map||(t._map=N(t.categories))}function mu(t){return M(t)&&null!=t.value?t.value:t+""}function yu(t,e,n,i){var r={},o=t[1]-t[0],a=r.interval=Qo(o/e,!0);null!=n&&n>a&&(a=r.interval=n),null!=i&&a>i&&(a=r.interval=i);var s=r.intervalPrecision=xu(a),l=r.niceTickExtent=[Tw(Math.ceil(t[0]/a)*a,s),Tw(Math.floor(t[1]/a)*a,s)];return wu(l,t),r}function xu(t){return Uo(t)+2}function _u(t,e,n){t[e]=Math.max(Math.min(t[e],n[1]),n[0])}function wu(t,e){!isFinite(t[0])&&(t[0]=e[0]),!isFinite(t[1])&&(t[1]=e[1]),_u(t,0,e),_u(t,1,e),t[0]>t[1]&&(t[0]=t[1])}function bu(t,e,n,i){var r=[];if(!t)return r;var o=1e4;e[0]<n[0]&&r.push(e[0]);for(var a=n[0];a<=n[1]&&(r.push(a),a=Tw(a+t,i),a!==r[r.length-1]);)if(r.length>o)return[];return e[1]>(r.length?r[r.length-1]:n[1])&&r.push(e[1]),r}function Mu(t){return t.get("stack")||kw+t.seriesIndex}function Su(t){return t.dim+t.index}function Iu(t,e){var n=[];return e.eachSeriesByType(t,function(t){ku(t)&&!Pu(t)&&n.push(t)}),n}function Cu(t){var e=[];return f(t,function(t){var n=t.getData(),i=t.coordinateSystem,r=i.getBaseAxis(),o=r.getExtent(),a="category"===r.type?r.getBandWidth():Math.abs(o[1]-o[0])/n.count(),s=Fo(t.get("barWidth"),a),l=Fo(t.get("barMaxWidth"),a),u=t.get("barGap"),h=t.get("barCategoryGap");e.push({bandWidth:a,barWidth:s,barMaxWidth:l,barGap:u,barCategoryGap:h,axisKey:Su(r),stackId:Mu(t)})}),Tu(e)}function Tu(t){var e={};f(t,function(t){var n=t.axisKey,i=t.bandWidth,r=e[n]||{bandWidth:i,remainedWidth:i,autoWidthCount:0,categoryGap:"20%",gap:"30%",stacks:{}},o=r.stacks;e[n]=r;var a=t.stackId;o[a]||r.autoWidthCount++,o[a]=o[a]||{width:0,maxWidth:0};var s=t.barWidth;s&&!o[a].width&&(o[a].width=s,s=Math.min(r.remainedWidth,s),r.remainedWidth-=s);var l=t.barMaxWidth;l&&(o[a].maxWidth=l);var u=t.barGap;null!=u&&(r.gap=u);var h=t.barCategoryGap;null!=h&&(r.categoryGap=h)});var n={};return f(e,function(t,e){n[e]={};var i=t.stacks,r=t.bandWidth,o=Fo(t.categoryGap,r),a=Fo(t.gap,1),s=t.remainedWidth,l=t.autoWidthCount,u=(s-o)/(l+(l-1)*a);
+u=Math.max(u,0),f(i,function(t){var e=t.maxWidth;e&&u>e&&(e=Math.min(e,s),t.width&&(e=Math.min(e,t.width)),s-=e,t.width=e,l--)}),u=(s-o)/(l+(l-1)*a),u=Math.max(u,0);var h,c=0;f(i,function(t){t.width||(t.width=u),h=t,c+=t.width*(1+a)}),h&&(c-=h.width*a);var d=-c/2;f(i,function(t,i){n[e][i]=n[e][i]||{offset:d,width:t.width},d+=t.width*(1+a)})}),n}function Au(t,e,n){if(t&&e){var i=t[Su(e)];return null!=i&&null!=n&&(i=i[Mu(n)]),i}}function Du(t,e){var n=Iu(t,e),i=Cu(n),r={};f(n,function(t){var e=t.getData(),n=t.coordinateSystem,o=n.getBaseAxis(),a=Mu(t),s=i[Su(o)][a],l=s.offset,u=s.width,h=n.getOtherAxis(o),c=t.get("barMinHeight")||0;r[a]=r[a]||[],e.setLayout({offset:l,size:u});for(var d=e.mapDimension(h.dim),f=e.mapDimension(o.dim),p=uu(e,d),g=h.isHorizontal(),v=Lu(o,h,p),m=0,y=e.count();y>m;m++){var x=e.get(d,m),_=e.get(f,m);if(!isNaN(x)){var w=x>=0?"p":"n",b=v;p&&(r[a][_]||(r[a][_]={p:v,n:v}),b=r[a][_][w]);var M,S,I,C;if(g){var T=n.dataToPoint([x,_]);M=b,S=T[1]+l,I=T[0]-v,C=u,Math.abs(I)<c&&(I=(0>I?-1:1)*c),p&&(r[a][_][w]+=I)}else{var T=n.dataToPoint([_,x]);M=T[0]+l,S=b,I=u,C=T[1]-v,Math.abs(C)<c&&(C=(0>=C?-1:1)*c),p&&(r[a][_][w]+=C)}e.setItemLayout(m,{x:M,y:S,width:I,height:C})}}},this)}function ku(t){return t.coordinateSystem&&"cartesian2d"===t.coordinateSystem.type}function Pu(t){return t.pipelineContext&&t.pipelineContext.large}function Lu(t,e,n){return u(t.getAxesOnZeroOf(),e)>=0||n?e.toGlobalCoord(e.dataToCoord(0)):e.getGlobalExtent()[0]}function Ou(t,e){return Xw(t,jw(e))}function Eu(t,e){var n,i,r,o=t.type,a=e.getMin(),s=e.getMax(),l=null!=a,u=null!=s,h=t.getExtent();"ordinal"===o?n=e.getCategories().length:(i=e.get("boundaryGap"),_(i)||(i=[i||0,i||0]),"boolean"==typeof i[0]&&(i=[0,0]),i[0]=Fo(i[0],1),i[1]=Fo(i[1],1),r=h[1]-h[0]||Math.abs(h[0])),null==a&&(a="ordinal"===o?n?0:0/0:h[0]-i[0]*r),null==s&&(s="ordinal"===o?n?n-1:0/0:h[1]+i[1]*r),"dataMin"===a?a=h[0]:"function"==typeof a&&(a=a({min:h[0],max:h[1]})),"dataMax"===s?s=h[1]:"function"==typeof s&&(s=s({min:h[0],max:h[1]})),(null==a||!isFinite(a))&&(a=0/0),(null==s||!isFinite(s))&&(s=0/0),t.setBlank(T(a)||T(s)||"ordinal"===o&&!t.getOrdinalMeta().categories.length),e.getNeedCrossZero()&&(a>0&&s>0&&!l&&(a=0),0>a&&0>s&&!u&&(s=0));var c=e.ecModel;if(c&&"time"===o){var d,p=Iu("bar",c);if(f(p,function(t){d|=t.getBaseAxis()===e.axis}),d){var g=Cu(p),v=Ru(a,s,e,g);a=v.min,s=v.max}}return[a,s]}function Ru(t,e,n,i){var r=n.axis.getExtent(),o=r[1]-r[0],a=Au(i,n.axis);if(void 0===a)return{min:t,max:e};var s=1/0;f(a,function(t){s=Math.min(t.offset,s)});var l=-1/0;f(a,function(t){l=Math.max(t.offset+t.width,l)}),s=Math.abs(s),l=Math.abs(l);var u=s+l,h=e-t,c=1-(s+l)/o,d=h/c-h;return e+=d*(l/u),t-=d*(s/u),{min:t,max:e}}function zu(t,e){var n=Eu(t,e),i=null!=e.getMin(),r=null!=e.getMax(),o=e.get("splitNumber");"log"===t.type&&(t.base=e.get("logBase"));var a=t.type;t.setExtent(n[0],n[1]),t.niceExtent({splitNumber:o,fixMin:i,fixMax:r,minInterval:"interval"===a||"time"===a?e.get("minInterval"):null,maxInterval:"interval"===a||"time"===a?e.get("maxInterval"):null});var s=e.get("interval");null!=s&&t.setInterval&&t.setInterval(s)}function Bu(t,e){if(e=e||t.get("type"))switch(e){case"category":return new Cw(t.getOrdinalMeta?t.getOrdinalMeta():t.getCategories(),[1/0,-1/0]);case"value":return new Dw;default:return(pu.getClass(e)||Dw).create(t)}}function Nu(t){var e=t.scale.getExtent(),n=e[0],i=e[1];return!(n>0&&i>0||0>n&&0>i)}function Vu(t){var e=t.getLabelModel().get("formatter"),n="category"===t.type?t.scale.getExtent()[0]:null;return"string"==typeof e?e=function(t){return function(e){return t.replace("{value}",null!=e?e:"")}}(e):"function"==typeof e?function(i,r){return null!=n&&(r=i-n),e(Fu(t,i),r)}:function(e){return t.scale.getLabel(e)}}function Fu(t,e){return"category"===t.type?t.scale.getLabel(e):e}function Hu(t){var e=t.model,n=t.scale;if(e.get("axisLabel.show")&&!n.isBlank()){var i,r,o="category"===t.type,a=n.getExtent();o?r=n.count():(i=n.getTicks(),r=i.length);var s,l=t.getLabelModel(),u=Vu(t),h=1;r>40&&(h=Math.ceil(r/40));for(var c=0;r>c;c+=h){var d=i?i[c]:a[0]+c,f=u(d),p=l.getTextRect(f),g=Wu(p,l.get("rotate")||0);s?s.union(g):s=g}return s}}function Wu(t,e){var n=e*Math.PI/180,i=t.plain(),r=i.width,o=i.height,a=r*Math.cos(n)+o*Math.sin(n),s=r*Math.sin(n)+o*Math.cos(n),l=new rn(i.x,i.y,a,s);return l}function Gu(t,e){if("image"!==this.type){var n=this.style,i=this.shape;i&&"line"===i.symbolType?n.stroke=t:this.__isEmptyBrush?(n.stroke=t,n.fill=e||"#fff"):(n.fill&&(n.fill=t),n.stroke&&(n.stroke=t)),this.dirty(!1)}}function Uu(t,e,n,i,r,o,a){var s=0===t.indexOf("empty");s&&(t=t.substr(5,1).toLowerCase()+t.substr(6));var l;return l=0===t.indexOf("image://")?jr(t.slice(8),new rn(e,n,i,r),a?"center":"cover"):0===t.indexOf("path://")?Zr(t.slice(7),{},new rn(e,n,i,r),a?"center":"cover"):new sb({shape:{symbolType:t,x:e,y:n,width:i,height:r}}),l.__isEmptyBrush=s,l.setColor=Gu,l.setColor(o),l}function Zu(t){return cu(t.getSource(),t)}function ju(t,e){var n=e;Lo.isInstance(e)||(n=new Lo(e),c(n,Jw));var i=Bu(n);return i.setExtent(t[0],t[1]),zu(i,n),i}function Xu(t){c(t,Jw)}function Yu(t,e){return Math.abs(t-e)<hb}function qu(t,e,n){var i=0,r=t[0];if(!r)return!1;for(var o=1;o<t.length;o++){var a=t[o];i+=Mr(r[0],r[1],a[0],a[1],e,n),r=a}var s=t[0];return Yu(r[0],s[0])&&Yu(r[1],s[1])||(i+=Mr(r[0],r[1],s[0],s[1],e,n)),0!==i}function $u(t,e,n){if(this.name=t,this.geometries=e,n)n=[n[0],n[1]];else{var i=this.getBoundingRect();n=[i.x+i.width/2,i.y+i.height/2]}this.center=n}function Ku(t){if(!t.UTF8Encoding)return t;var e=t.UTF8Scale;null==e&&(e=1024);for(var n=t.features,i=0;i<n.length;i++)for(var r=n[i],o=r.geometry,a=o.coordinates,s=o.encodeOffsets,l=0;l<a.length;l++){var u=a[l];if("Polygon"===o.type)a[l]=Qu(u,s[l],e);else if("MultiPolygon"===o.type)for(var h=0;h<u.length;h++){var c=u[h];u[h]=Qu(c,s[l][h],e)}}return t.UTF8Encoding=!1,t}function Qu(t,e,n){for(var i=[],r=e[0],o=e[1],a=0;a<t.length;a+=2){var s=t.charCodeAt(a)-64,l=t.charCodeAt(a+1)-64;s=s>>1^-(1&s),l=l>>1^-(1&l),s+=r,l+=o,r=s,o=l,i.push([s/n,l/n])}return i}function Ju(t){return"category"===t.type?eh(t):rh(t)}function th(t,e){return"category"===t.type?ih(t,e):{ticks:t.scale.getTicks()}}function eh(t){var e=t.getLabelModel(),n=nh(t,e);return!e.get("show")||t.scale.isBlank()?{labels:[],labelCategoryInterval:n.labelCategoryInterval}:n}function nh(t,e){var n=oh(t,"labels"),i=fh(e),r=ah(n,i);if(r)return r;var o,a;return w(i)?o=dh(t,i):(a="auto"===i?lh(t):i,o=ch(t,a)),sh(n,i,{labels:o,labelCategoryInterval:a})}function ih(t,e){var n=oh(t,"ticks"),i=fh(e),r=ah(n,i);if(r)return r;var o,a;if((!e.get("show")||t.scale.isBlank())&&(o=[]),w(i))o=dh(t,i,!0);else if("auto"===i){var s=nh(t,t.getLabelModel());a=s.labelCategoryInterval,o=p(s.labels,function(t){return t.tickValue})}else a=i,o=ch(t,a,!0);return sh(n,i,{ticks:o,tickCategoryInterval:a})}function rh(t){var e=t.scale.getTicks(),n=Vu(t);return{labels:p(e,function(e,i){return{formattedLabel:n(e,i),rawLabel:t.scale.getLabel(e),tickValue:e}})}}function oh(t,e){return db(t)[e]||(db(t)[e]=[])}function ah(t,e){for(var n=0;n<t.length;n++)if(t[n].key===e)return t[n].value}function sh(t,e,n){return t.push({key:e,value:n}),n}function lh(t){var e=db(t).autoInterval;return null!=e?e:db(t).autoInterval=t.calculateCategoryInterval()}function uh(t){var e=hh(t),n=Vu(t),i=(e.axisRotate-e.labelRotate)/180*Math.PI,r=t.scale,o=r.getExtent(),a=r.count();if(o[1]-o[0]<1)return 0;var s=1;a>40&&(s=Math.max(1,Math.floor(a/40)));for(var l=o[0],u=t.dataToCoord(l+1)-t.dataToCoord(l),h=Math.abs(u*Math.cos(i)),c=Math.abs(u*Math.sin(i)),d=0,f=0;l<=o[1];l+=s){var p=0,g=0,v=Sn(n(l),e.font,"center","top");p=1.3*v.width,g=1.3*v.height,d=Math.max(d,p,7),f=Math.max(f,g,7)}var m=d/h,y=f/c;isNaN(m)&&(m=1/0),isNaN(y)&&(y=1/0);var x=Math.max(0,Math.floor(Math.min(m,y))),_=db(t.model),w=_.lastAutoInterval,b=_.lastTickCount;return null!=w&&null!=b&&Math.abs(w-x)<=1&&Math.abs(b-a)<=1&&w>x?x=w:(_.lastTickCount=a,_.lastAutoInterval=x),x}function hh(t){var e=t.getLabelModel();return{axisRotate:t.getRotate?t.getRotate():t.isHorizontal&&!t.isHorizontal()?90:0,labelRotate:e.get("rotate")||0,font:e.getFont()}}function ch(t,e,n){function i(t){l.push(n?t:{formattedLabel:r(t),rawLabel:o.getLabel(t),tickValue:t})}var r=Vu(t),o=t.scale,a=o.getExtent(),s=t.getLabelModel(),l=[],u=Math.max((e||0)+1,1),h=a[0],c=o.count();0!==h&&u>1&&c/u>2&&(h=Math.round(Math.ceil(h/u)*u));var d={min:s.get("showMinLabel"),max:s.get("showMaxLabel")};d.min&&h!==a[0]&&i(a[0]);for(var f=h;f<=a[1];f+=u)i(f);return d.max&&f!==a[1]&&i(a[1]),l}function dh(t,e,n){var i=t.scale,r=Vu(t),o=[];return f(i.getTicks(),function(t){var a=i.getLabel(t);e(t,a)&&o.push(n?t:{formattedLabel:r(t),rawLabel:a,tickValue:t})}),o}function fh(t){var e=t.get("interval");return null==e?"auto":e}function ph(t,e){var n=t[1]-t[0],i=e,r=n/i/2;t[0]+=r,t[1]-=r}function gh(t,e,n,i,r){function o(t,e){return h?t>e:e>t}var a=e.length;if(t.onBand&&!i&&a){var s,l=t.getExtent();if(1===a)e[0].coord=l[0],s=e[1]={coord:l[0]};else{var u=e[1].coord-e[0].coord;f(e,function(t){t.coord-=u/2;var e=e||0;e%2>0&&(t.coord-=u/(2*(e+1)))}),s={coord:e[a-1].coord+u},e.push(s)}var h=l[0]>l[1];o(e[0].coord,l[0])&&(r?e[0].coord=l[0]:e.shift()),r&&o(l[0],e[0].coord)&&e.unshift({coord:l[0]}),o(l[1],s.coord)&&(r?s.coord=l[1]:e.pop()),r&&o(s.coord,l[1])&&e.push({coord:l[1]})}}function vh(t){return this._axes[t]}function mh(t){mb.call(this,t)}function yh(t,e){return e.type||(e.data?"category":"value")}function xh(t,e){return t.getCoordSysModel()===e}function _h(t,e,n){this._coordsMap={},this._coordsList=[],this._axesMap={},this._axesList=[],this._initCartesian(t,e,n),this.model=t}function wh(t,e,n){n.getAxesOnZeroOf=function(){return i?[i]:[]};var i,r=t[e],o=n.model,a=o.get("axisLine.onZero"),s=o.get("axisLine.onZeroAxisIndex");if(a){if(null!=s)return void(bh(r[s])&&(i=r[s]));for(var l in r)if(r.hasOwnProperty(l)&&bh(r[l])){i=r[l];break}}}function bh(t){return t&&"category"!==t.type&&"time"!==t.type&&Nu(t)}function Mh(t,e){var n=t.getExtent(),i=n[0]+n[1];t.toGlobalCoord="x"===t.dim?function(t){return t+e}:function(t){return i-t+e},t.toLocalCoord="x"===t.dim?function(t){return t-e}:function(t){return i-t+e}}function Sh(t){return p(Cb,function(e){var n=t.getReferringComponents(e)[0];return n})}function Ih(t){return"cartesian2d"===t.get("coordinateSystem")}function Ch(t,e){var n=t.mapDimension("defaultedLabel",!0),i=n.length;if(1===i)return fs(t,e,n[0]);if(i){for(var r=[],o=0;o<n.length;o++){var a=fs(t,e,n[o]);r.push(a)}return r.join(" ")}}function Th(t,e,n,i,r,o){var a=n.getModel("label"),s=n.getModel("emphasis.label");co(t,e,a,s,{labelFetcher:r,labelDataIndex:o,defaultText:Ch(r.getData(),o),isRectText:!0,autoColor:i}),Ah(t),Ah(e)}function Ah(t,e){"outside"===t.textPosition&&(t.textPosition=e)}function Dh(t,e,n){n.style.text=null,Mo(n,{shape:{width:0}},e,t,function(){n.parent&&n.parent.remove(n)})}function kh(t,e,n){n.style.text=null,Mo(n,{shape:{r:n.shape.r0}},e,t,function(){n.parent&&n.parent.remove(n)})}function Ph(t,e,n,i,r,o,a,l){var u=e.getItemVisual(n,"color"),h=e.getItemVisual(n,"opacity"),c=i.getModel("itemStyle"),d=i.getModel("emphasis.itemStyle").getBarItemStyle();l||t.setShape("r",c.get("barBorderRadius")||0),t.useStyle(s({fill:u,opacity:h},c.getBarItemStyle()));var f=i.getShallow("cursor");f&&t.attr("cursor",f);var p=a?r.height>0?"bottom":"top":r.width>0?"left":"right";l||Th(t.style,d,i,u,o,n,p),ho(t,d)}function Lh(t,e){var n=t.get(kb)||0;return Math.min(n,Math.abs(e.width),Math.abs(e.height))}function Oh(t,e,n){var i=t.getData(),r=[],o=i.getLayout("valueAxisHorizontal")?1:0;r[1-o]=i.getLayout("valueAxisStart");var a=new Ob({shape:{points:i.getLayout("largePoints")},incremental:!!n,__startPoint:r,__valueIdx:o});e.add(a),Eh(a,t,i)}function Eh(t,e,n){var i=n.getVisual("borderColor")||n.getVisual("color"),r=e.getModel("itemStyle").getItemStyle(["color","borderColor"]);t.useStyle(r),t.style.fill=null,t.style.stroke=i,t.style.lineWidth=n.getLayout("barWidth")}function Rh(t){var e={componentType:t.mainType};return e[t.mainType+"Index"]=t.componentIndex,e}function zh(t,e,n,i){var r,o,a=Xo(n-t.rotation),s=i[0]>i[1],l="start"===e&&!s||"start"!==e&&s;return Yo(a-Eb/2)?(o=l?"bottom":"top",r="center"):Yo(a-1.5*Eb)?(o=l?"top":"bottom",r="center"):(o="middle",r=1.5*Eb>a&&a>Eb/2?l?"left":"right":l?"right":"left"),{rotation:a,textAlign:r,textVerticalAlign:o}}function Bh(t){var e=t.get("tooltip");return t.get("silent")||!(t.get("triggerEvent")||e&&e.show)}function Nh(t,e,n){var i=t.get("axisLabel.showMinLabel"),r=t.get("axisLabel.showMaxLabel");e=e||[],n=n||[];var o=e[0],a=e[1],s=e[e.length-1],l=e[e.length-2],u=n[0],h=n[1],c=n[n.length-1],d=n[n.length-2];i===!1?(Vh(o),Vh(u)):Fh(o,a)&&(i?(Vh(a),Vh(h)):(Vh(o),Vh(u))),r===!1?(Vh(s),Vh(c)):Fh(l,s)&&(r?(Vh(l),Vh(d)):(Vh(s),Vh(c)))}function Vh(t){t&&(t.ignore=!0)}function Fh(t,e){var n=t&&t.getBoundingRect().clone(),i=e&&e.getBoundingRect().clone();if(n&&i){var r=pe([]);return ye(r,r,-t.rotation),n.applyTransform(ve([],r,t.getLocalTransform())),i.applyTransform(ve([],r,e.getLocalTransform())),n.intersect(i)}}function Hh(t){return"middle"===t||"center"===t}function Wh(t,e,n){var i=e.axis;if(e.get("axisTick.show")&&!i.scale.isBlank()){for(var r=e.getModel("axisTick"),o=r.getModel("lineStyle"),a=r.get("length"),l=i.getTicksCoords(),u=[],h=[],c=t._transform,d=[],f=0;f<l.length;f++){var p=l[f].coord;u[0]=p,u[1]=0,h[0]=p,h[1]=n.tickDirection*a,c&&(oe(u,u,c),oe(h,h,c));var g=new Iy(qr({anid:"tick_"+l[f].tickValue,shape:{x1:u[0],y1:u[1],x2:h[0],y2:h[1]},style:s(o.getLineStyle(),{stroke:e.get("axisLine.lineStyle.color")}),z2:2,silent:!0}));t.group.add(g),d.push(g)}return d}}function Gh(t,e,n){var i=e.axis,r=A(n.axisLabelShow,e.get("axisLabel.show"));if(r&&!i.scale.isBlank()){var o=e.getModel("axisLabel"),a=o.get("margin"),s=i.getViewLabels(),l=(A(n.labelRotate,o.get("rotate"))||0)*Eb/180,u=Bb(n.rotation,l,n.labelDirection),h=e.getCategories(!0),c=[],d=Bh(e),p=e.get("triggerEvent");return f(s,function(r,s){var l=r.tickValue,f=r.formattedLabel,g=r.rawLabel,v=o;h&&h[l]&&h[l].textStyle&&(v=new Lo(h[l].textStyle,o,e.ecModel));var m=v.getTextColor()||e.get("axisLine.lineStyle.color"),y=i.dataToCoord(l),x=[y,n.labelOffset+n.labelDirection*a],_=new py({anid:"label_"+l,position:x,rotation:u.rotation,silent:d,z2:10});fo(_.style,v,{text:f,textAlign:v.getShallow("align",!0)||u.textAlign,textVerticalAlign:v.getShallow("verticalAlign",!0)||v.getShallow("baseline",!0)||u.textVerticalAlign,textFill:"function"==typeof m?m("category"===i.type?g:"value"===i.type?l+"":l,s):m}),p&&(_.eventData=Rh(e),_.eventData.targetType="axisLabel",_.eventData.value=g),t._dumbGroup.add(_),_.updateTransform(),c.push(_),t.group.add(_),_.decomposeTransform()}),c}}function Uh(t,e){var n={axesInfo:{},seriesInvolved:!1,coordSysAxesInfo:{},coordSysMap:{}};return Zh(n,t,e),n.seriesInvolved&&Xh(n,t),n}function Zh(t,e,n){var i=e.getComponent("tooltip"),r=e.getComponent("axisPointer"),o=r.get("link",!0)||[],a=[];Nb(n.getCoordinateSystems(),function(n){function s(i,s,l){var h=l.model.getModel("axisPointer",r),d=h.get("show");if(d&&("auto"!==d||i||Jh(h))){null==s&&(s=h.get("triggerTooltip")),h=i?jh(l,c,r,e,i,s):h;var f=h.get("snap"),p=tc(l.model),g=s||f||"category"===l.type,v=t.axesInfo[p]={key:p,axis:l,coordSys:n,axisPointerModel:h,triggerTooltip:s,involveSeries:g,snap:f,useHandle:Jh(h),seriesModels:[]};u[p]=v,t.seriesInvolved|=g;var m=Yh(o,l);if(null!=m){var y=a[m]||(a[m]={axesInfo:{}});y.axesInfo[p]=v,y.mapper=o[m].mapper,v.linkGroup=y}}}if(n.axisPointerEnabled){var l=tc(n.model),u=t.coordSysAxesInfo[l]={};t.coordSysMap[l]=n;var h=n.model,c=h.getModel("tooltip",i);if(Nb(n.getAxes(),Vb(s,!1,null)),n.getTooltipAxes&&i&&c.get("show")){var d="axis"===c.get("trigger"),f="cross"===c.get("axisPointer.type"),p=n.getTooltipAxes(c.get("axisPointer.axis"));(d||f)&&Nb(p.baseAxes,Vb(s,f?"cross":!0,d)),f&&Nb(p.otherAxes,Vb(s,"cross",!1))}}})}function jh(t,e,n,r,o,a){var l=e.getModel("axisPointer"),u={};Nb(["type","snap","lineStyle","shadowStyle","label","animation","animationDurationUpdate","animationEasingUpdate","z"],function(t){u[t]=i(l.get(t))}),u.snap="category"!==t.type&&!!a,"cross"===l.get("type")&&(u.type="line");var h=u.label||(u.label={});if(null==h.show&&(h.show=!1),"cross"===o){var c=l.get("label.show");if(h.show=null!=c?c:!0,!a){var d=u.lineStyle=l.get("crossStyle");d&&s(h,d.textStyle)}}return t.model.getModel("axisPointer",new Lo(u,n,r))}function Xh(t,e){e.eachSeries(function(e){var n=e.coordinateSystem,i=e.get("tooltip.trigger",!0),r=e.get("tooltip.show",!0);n&&"none"!==i&&i!==!1&&"item"!==i&&r!==!1&&e.get("axisPointer.show",!0)!==!1&&Nb(t.coordSysAxesInfo[tc(n.model)],function(t){var i=t.axis;n.getAxis(i.dim)===i&&(t.seriesModels.push(e),null==t.seriesDataCount&&(t.seriesDataCount=0),t.seriesDataCount+=e.getData().count())})},this)}function Yh(t,e){for(var n=e.model,i=e.dim,r=0;r<t.length;r++){var o=t[r]||{};if(qh(o[i+"AxisId"],n.id)||qh(o[i+"AxisIndex"],n.componentIndex)||qh(o[i+"AxisName"],n.name))return r}}function qh(t,e){return"all"===t||_(t)&&u(t,e)>=0||t===e}function $h(t){var e=Kh(t);if(e){var n=e.axisPointerModel,i=e.axis.scale,r=n.option,o=n.get("status"),a=n.get("value");null!=a&&(a=i.parse(a));var s=Jh(n);null==o&&(r.status=s?"show":"hide");var l=i.getExtent().slice();l[0]>l[1]&&l.reverse(),(null==a||a>l[1])&&(a=l[1]),a<l[0]&&(a=l[0]),r.value=a,s&&(r.status=e.axis.scale.isBlank()?"hide":"show")}}function Kh(t){var e=(t.ecModel.getComponent("axisPointer")||{}).coordSysAxesInfo;return e&&e.axesInfo[tc(t)]}function Qh(t){var e=Kh(t);return e&&e.axisPointerModel}function Jh(t){return!!t.get("handle.show")}function tc(t){return t.type+"||"+t.id}function ec(t,e,n,i,r,o){var a=Fb.getAxisPointerClass(t.axisPointerClass);if(a){var s=Qh(e);s?(t._axisPointer||(t._axisPointer=new a)).render(e,s,i,o):nc(t,i)}}function nc(t,e,n){var i=t._axisPointer;i&&i.dispose(e,n),t._axisPointer=null}function ic(t,e,n){n=n||{};var i=t.coordinateSystem,r=e.axis,o={},a=r.getAxesOnZeroOf()[0],s=r.position,l=a?"onZero":s,u=r.dim,h=i.getRect(),c=[h.x,h.x+h.width,h.y,h.y+h.height],d={left:0,right:1,top:0,bottom:1,onZero:2},f=e.get("offset")||0,p="x"===u?[c[2]-f,c[3]+f]:[c[0]-f,c[1]+f];if(a){var g=a.toGlobalCoord(a.dataToCoord(0));p[d.onZero]=Math.max(Math.min(g,p[1]),p[0])}o.position=["y"===u?p[d[l]]:c[0],"x"===u?p[d[l]]:c[3]],o.rotation=Math.PI/2*("x"===u?0:1);var v={top:-1,bottom:1,left:-1,right:1};o.labelDirection=o.tickDirection=o.nameDirection=v[s],o.labelOffset=a?p[d[s]]-p[d.onZero]:0,e.get("axisTick.inside")&&(o.tickDirection=-o.tickDirection),A(n.labelInside,e.get("axisLabel.inside"))&&(o.labelDirection=-o.labelDirection);var m=e.get("axisLabel.rotate");return o.labelRotate="top"===l?-m:m,o.z2=1,o}function rc(t,e,n){nv.call(this),this.updateData(t,e,n)}function oc(t){return[t[0]/2,t[1]/2]}function ac(t,e){this.parent.drift(t,e)}function sc(t){this.group=new nv,this._symbolCtor=t||rc}function lc(t,e,n,i){return!(!e||isNaN(e[0])||isNaN(e[1])||i.isIgnore&&i.isIgnore(n)||i.clipShape&&!i.clipShape.contain(e[0],e[1])||"none"===t.getItemVisual(n,"symbol"))}function uc(t){return null==t||M(t)||(t={isIgnore:t}),t||{}}function hc(t){var e=t.hostModel;return{itemStyle:e.getModel("itemStyle").getItemStyle(["color"]),hoverItemStyle:e.getModel("emphasis.itemStyle").getItemStyle(),symbolRotate:e.get("symbolRotate"),symbolOffset:e.get("symbolOffset"),hoverAnimation:e.get("hoverAnimation"),labelModel:e.getModel("label"),hoverLabelModel:e.getModel("emphasis.label"),cursorStyle:e.get("cursor")}}function cc(t,e,n){var i,r=t.getBaseAxis(),o=t.getOtherAxis(r),a=dc(o,n),s=r.dim,l=o.dim,u=e.mapDimension(l),h=e.mapDimension(s),c="x"===l||"radius"===l?1:0,d=p(t.dimensions,function(t){return e.mapDimension(t)}),f=e.getCalculationInfo("stackResultDimension");return(i|=uu(e,d[0]))&&(d[0]=f),(i|=uu(e,d[1]))&&(d[1]=f),{dataDimsForPoint:d,valueStart:a,valueAxisDim:l,baseAxisDim:s,stacked:!!i,valueDim:u,baseDim:h,baseDataOffset:c,stackedOverDimension:e.getCalculationInfo("stackedOverDimension")}}function dc(t,e){var n=0,i=t.scale.getExtent();return"start"===e?n=i[0]:"end"===e?n=i[1]:i[0]>0?n=i[0]:i[1]<0&&(n=i[1]),n}function fc(t,e,n,i){var r=0/0;t.stacked&&(r=n.get(n.getCalculationInfo("stackedOverDimension"),i)),isNaN(r)&&(r=t.valueStart);var o=t.baseDataOffset,a=[];return a[o]=n.get(t.baseDim,i),a[1-o]=r,e.dataToPoint(a)}function pc(t,e){var n=[];return e.diff(t).add(function(t){n.push({cmd:"+",idx:t})}).update(function(t,e){n.push({cmd:"=",idx:e,idx1:t})}).remove(function(t){n.push({cmd:"-",idx:t})}).execute(),n}function gc(t){return isNaN(t[0])||isNaN(t[1])}function vc(t,e,n,i,r,o,a,s,l,u){return"none"!==u&&u?mc.apply(this,arguments):yc.apply(this,arguments)}function mc(t,e,n,i,r,o,a,s,l,u,h){for(var c=0,d=n,f=0;i>f;f++){var p=e[d];if(d>=r||0>d)break;if(gc(p)){if(h){d+=o;continue}break}if(d===n)t[o>0?"moveTo":"lineTo"](p[0],p[1]);else if(l>0){var g=e[c],v="y"===u?1:0,m=(p[v]-g[v])*l;nM(rM,g),rM[v]=g[v]+m,nM(oM,p),oM[v]=p[v]-m,t.bezierCurveTo(rM[0],rM[1],oM[0],oM[1],p[0],p[1])}else t.lineTo(p[0],p[1]);c=d,d+=o}return f}function yc(t,e,n,i,r,o,a,s,l,u,h){for(var c=0,d=n,f=0;i>f;f++){var p=e[d];if(d>=r||0>d)break;if(gc(p)){if(h){d+=o;continue}break}if(d===n)t[o>0?"moveTo":"lineTo"](p[0],p[1]),nM(rM,p);else if(l>0){var g=d+o,v=e[g];if(h)for(;v&&gc(e[g]);)g+=o,v=e[g];var m=.5,y=e[c],v=e[g];if(!v||gc(v))nM(oM,p);else{gc(v)&&!h&&(v=p),X(iM,v,y);var x,_;if("x"===u||"y"===u){var w="x"===u?0:1;x=Math.abs(p[w]-y[w]),_=Math.abs(p[w]-v[w])}else x=mg(p,y),_=mg(p,v);m=_/(_+x),eM(oM,p,iM,-l*(1-m))}Jb(rM,rM,s),tM(rM,rM,a),Jb(oM,oM,s),tM(oM,oM,a),t.bezierCurveTo(rM[0],rM[1],oM[0],oM[1],p[0],p[1]),eM(rM,p,iM,l*m)}else t.lineTo(p[0],p[1]);c=d,d+=o}return f}function xc(t,e){var n=[1/0,1/0],i=[-1/0,-1/0];if(e)for(var r=0;r<t.length;r++){var o=t[r];o[0]<n[0]&&(n[0]=o[0]),o[1]<n[1]&&(n[1]=o[1]),o[0]>i[0]&&(i[0]=o[0]),o[1]>i[1]&&(i[1]=o[1])}return{min:e?n:i,max:e?i:n}}function _c(t,e){if(t.length===e.length){for(var n=0;n<t.length;n++){var i=t[n],r=e[n];if(i[0]!==r[0]||i[1]!==r[1])return}return!0}}function wc(t){return"number"==typeof t?t:t?.5:0}function bc(t){var e=t.getGlobalExtent();if(t.onBand){var n=t.getBandWidth()/2-1,i=e[1]>e[0]?1:-1;e[0]+=i*n,e[1]-=i*n}return e}function Mc(t,e,n){if(!n.valueDim)return[];for(var i=[],r=0,o=e.count();o>r;r++)i.push(fc(n,t,e,r));return i}function Sc(t,e,n,i){var r=bc(t.getAxis("x")),o=bc(t.getAxis("y")),a=t.getBaseAxis().isHorizontal(),s=Math.min(r[0],r[1]),l=Math.min(o[0],o[1]),u=Math.max(r[0],r[1])-s,h=Math.max(o[0],o[1])-l;if(n)s-=.5,u+=.5,l-=.5,h+=.5;else{var c=i.get("lineStyle.width")||2,d=i.get("clipOverflow")?c/2:Math.max(u,h);a?(l-=d,h+=2*d):(s-=d,u+=2*d)}var f=new Sy({shape:{x:s,y:l,width:u,height:h}});return e&&(f.shape[a?"width":"height"]=0,So(f,{shape:{width:u,height:h}},i)),f}function Ic(t,e,n,i){var r=t.getAngleAxis(),o=t.getRadiusAxis(),a=o.getExtent().slice();a[0]>a[1]&&a.reverse();var s=r.getExtent(),l=Math.PI/180;n&&(a[0]-=.5,a[1]+=.5);var u=new yy({shape:{cx:Ho(t.cx,1),cy:Ho(t.cy,1),r0:Ho(a[0],1),r:Ho(a[1],1),startAngle:-s[0]*l,endAngle:-s[1]*l,clockwise:r.inverse}});return e&&(u.shape.endAngle=-s[0]*l,So(u,{shape:{endAngle:-s[1]*l}},i)),u}function Cc(t,e,n,i){return"polar"===t.type?Ic(t,e,n,i):Sc(t,e,n,i)}function Tc(t,e,n){for(var i=e.getBaseAxis(),r="x"===i.dim||"radius"===i.dim?0:1,o=[],a=0;a<t.length-1;a++){var s=t[a+1],l=t[a];o.push(l);var u=[];switch(n){case"end":u[r]=s[r],u[1-r]=l[1-r],o.push(u);break;case"middle":var h=(l[r]+s[r])/2,c=[];u[r]=c[r]=h,u[1-r]=l[1-r],c[1-r]=s[1-r],o.push(u),o.push(c);break;default:u[r]=l[r],u[1-r]=s[1-r],o.push(u)}}return t[a]&&o.push(t[a]),o}function Ac(t,e){var n=t.getVisual("visualMeta");if(n&&n.length&&t.count()&&"cartesian2d"===e.type){for(var i,r,o=n.length-1;o>=0;o--){var a=n[o].dimension,s=t.dimensions[a],l=t.getDimensionInfo(s);if(i=l&&l.coordDim,"x"===i||"y"===i){r=n[o];break}}if(r){var u=e.getAxis(i),h=p(r.stops,function(t){return{coord:u.toGlobalCoord(u.dataToCoord(t.value)),color:t.color}}),c=h.length,d=r.outerColors.slice();c&&h[0].coord>h[c-1].coord&&(h.reverse(),d.reverse());var g=10,v=h[0].coord-g,m=h[c-1].coord+g,y=m-v;if(.001>y)return"transparent";f(h,function(t){t.offset=(t.coord-v)/y}),h.push({offset:c?h[c-1].offset:.5,color:d[1]||"transparent"}),h.unshift({offset:c?h[0].offset:.5,color:d[0]||"transparent"});var x=new Py(0,0,0,0,h,!0);return x[i]=v,x[i+"2"]=m,x}}}function Dc(t,e,n){var i=t.get("showAllSymbol"),r="auto"===i;if(!i||r){var o=n.getAxesByScale("ordinal")[0];if(o&&(!r||!kc(o,e))){var a=e.mapDimension(o.dim),s={};return f(o.getViewLabels(),function(t){s[t.tickValue]=1}),function(t){return!s.hasOwnProperty(e.get(a,t))}}}}function kc(t,e){var n=t.getExtent(),i=Math.abs(n[1]-n[0])/t.scale.count();isNaN(i)&&(i=0);for(var r=e.count(),o=Math.max(1,Math.round(r/5)),a=0;r>a;a+=o)if(1.5*rc.getSymbolSize(e,a)[t.isHorizontal()?1:0]>i)return!1;return!0}function Pc(t,e,n,i){var r=e.getData(),o=this.dataIndex,a=r.getName(o),s=e.get("selectedOffset");i.dispatchAction({type:"pieToggleSelect",from:t,name:a,seriesId:e.id}),r.each(function(t){Lc(r.getItemGraphicEl(t),r.getItemLayout(t),e.isSelected(r.getName(t)),s,n)})}function Lc(t,e,n,i,r){var o=(e.startAngle+e.endAngle)/2,a=Math.cos(o),s=Math.sin(o),l=n?i:0,u=[a*l,s*l];r?t.animate().when(200,{position:u}).start("bounceOut"):t.attr("position",u)}function Oc(t,e){function n(){o.ignore=o.hoverIgnore,a.ignore=a.hoverIgnore}function i(){o.ignore=o.normalIgnore,a.ignore=a.normalIgnore}nv.call(this);var r=new yy({z2:2}),o=new My,a=new py;this.add(r),this.add(o),this.add(a),this.updateData(t,e,!0),this.on("emphasis",n).on("normal",i).on("mouseover",n).on("mouseout",i)}function Ec(t,e,n,i,r,o,a){function s(e,n,i){for(var r=e;n>r;r++)if(t[r].y+=i,r>e&&n>r+1&&t[r+1].y>t[r].y+t[r].height)return void l(r,i/2);l(n-1,i/2)}function l(e,n){for(var i=e;i>=0&&(t[i].y-=n,!(i>0&&t[i].y>t[i-1].y+t[i-1].height));i--);}function u(t,e,n,i,r,o){for(var a=o>0?e?Number.MAX_VALUE:0:e?Number.MAX_VALUE:0,s=0,l=t.length;l>s;s++)if("center"!==t[s].position){var u=Math.abs(t[s].y-i),h=t[s].len,c=t[s].len2,d=r+h>u?Math.sqrt((r+h+c)*(r+h+c)-u*u):Math.abs(t[s].x-n);e&&d>=a&&(d=a-10),!e&&a>=d&&(d=a+10),t[s].x=n+d*o,a=d}}t.sort(function(t,e){return t.y-e.y});for(var h,c=0,d=t.length,f=[],p=[],g=0;d>g;g++)h=t[g].y-c,0>h&&s(g,d,-h,r),c=t[g].y+t[g].height;0>a-c&&l(d-1,c-a);for(var g=0;d>g;g++)t[g].y>=n?p.push(t[g]):f.push(t[g]);u(f,!1,e,n,i,r),u(p,!0,e,n,i,r)}function Rc(t,e,n,i,r,o){for(var a=[],s=[],l=0;l<t.length;l++)t[l].x<e?a.push(t[l]):s.push(t[l]);Ec(s,e,n,i,1,r,o),Ec(a,e,n,i,-1,r,o);for(var l=0;l<t.length;l++){var u=t[l].linePoints;if(u){var h=u[1][0]-u[2][0];u[2][0]=t[l].x<e?t[l].x+3:t[l].x-3,u[1][1]=u[2][1]=t[l].y,u[1][0]=u[2][0]+h}}}function zc(t,e){function n(){o.ignore=o.hoverIgnore,a.ignore=a.hoverIgnore}function i(){o.ignore=o.normalIgnore,a.ignore=a.normalIgnore}nv.call(this);var r=new by,o=new My,a=new py;this.add(r),this.add(o),this.add(a),this.updateData(t,e,!0),this.on("emphasis",n).on("normal",i).on("mouseover",n).on("mouseout",i)}function Bc(t,e){return ca(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()})}function Nc(t,e){for(var n=t.mapDimension("value"),i=t.mapArray(n,function(t){return t}),r=[],o="ascending"===e,a=0,s=t.count();s>a;a++)r[a]=a;return"function"==typeof e?r.sort(e):"none"!==e&&r.sort(function(t,e){return o?i[t]-i[e]:i[e]-i[t]}),r}function Vc(t){t.each(function(e){var n,i,r,o,a=t.getItemModel(e),s=a.getModel("label"),l=s.get("position"),u=a.getModel("labelLine"),h=t.getItemLayout(e),c=h.points,d="inner"===l||"inside"===l||"center"===l;if(d)i=(c[0][0]+c[1][0]+c[2][0]+c[3][0])/4,r=(c[0][1]+c[1][1]+c[2][1]+c[3][1])/4,n="center",o=[[i,r],[i,r]];else{var f,p,g,v=u.get("length");"left"===l?(f=(c[3][0]+c[0][0])/2,p=(c[3][1]+c[0][1])/2,g=f-v,i=g-5,n="right"):(f=(c[1][0]+c[2][0])/2,p=(c[1][1]+c[2][1])/2,g=f+v,i=g+5,n="left");var m=p;o=[[f,p],[g,m]],r=m}h.label={linePoints:o,x:i,y:r,verticalAlign:"middle",textAlign:n,inside:d}})}function Fc(t,e,n){var i,r={},o="toggleSelected"===t;return n.eachComponent("legend",function(n){o&&null!=i?n[i?"select":"unSelect"](e.name):(n[t](e.name),i=n.isSelected(e.name));var a=n.getData();f(a,function(t){var e=t.get("name");if("\n"!==e&&""!==e){var i=n.isSelected(e);r[e]=r.hasOwnProperty(e)?r[e]&&i:i}})}),{name:e.name,selected:r}}function Hc(t,e,n){var i=e.getBoxLayoutParams(),r=e.get("padding"),o={width:n.getWidth(),height:n.getHeight()},a=ca(i,o,r);lx(e.get("orient"),t,e.get("itemGap"),a.width,a.height),da(t,i,o,r)}function Wc(t,e){var n=Ky(e.get("padding")),i=e.getItemStyle(["color","opacity"]);i.fill=e.get("backgroundColor");var t=new Sy({shape:{x:t.x-n[3],y:t.y-n[0],width:t.width+n[1]+n[3],height:t.height+n[0]+n[2],r:e.get("borderRadius")},style:i,silent:!0,z2:-1});return t}function Gc(t,e){e.dispatchAction({type:"legendToggleSelect",name:t})}function Uc(t,e,n,i){var r=n.getZr().storage.getDisplayList()[0];r&&r.useHoverLayer||n.dispatchAction({type:"highlight",seriesName:t.name,name:e,excludeSeriesId:i})}function Zc(t,e,n,i){var r=n.getZr().storage.getDisplayList()[0];r&&r.useHoverLayer||n.dispatchAction({type:"downplay",seriesName:t.name,name:e,excludeSeriesId:i})}function jc(t,e,n){var i=t.getOrient(),r=[1,1];r[i.index]=0,fa(e,n,{type:"box",ignoreSize:r})}function Xc(t,e,n,i,r){var o=t.axis;if(!o.scale.isBlank()&&o.containData(e)){if(!t.involveSeries)return void n.showPointer(t,e);var s=Yc(e,t),l=s.payloadBatch,u=s.snapToValue;l[0]&&null==r.seriesIndex&&a(r,l[0]),!i&&t.snap&&o.containData(u)&&null!=u&&(e=u),n.showPointer(t,e,l,r),n.showTooltip(t,s,u)}}function Yc(t,e){var n=e.axis,i=n.dim,r=t,o=[],a=Number.MAX_VALUE,s=-1;return FM(e.seriesModels,function(e){var l,u,h=e.getData().mapDimension(i,!0);if(e.getAxisTooltipData){var c=e.getAxisTooltipData(h,t,n);u=c.dataIndices,l=c.nestestValue}else{if(u=e.getData().indicesOfNearest(h[0],t,"category"===n.type?.5:null),!u.length)return;l=e.getData().get(h[0],u[0])}if(null!=l&&isFinite(l)){var d=t-l,f=Math.abs(d);a>=f&&((a>f||d>=0&&0>s)&&(a=f,s=d,r=l,o.length=0),FM(u,function(t){o.push({seriesIndex:e.seriesIndex,dataIndexInside:t,dataIndex:e.getData().getRawIndex(t)})}))}}),{payloadBatch:o,snapToValue:r}}function qc(t,e,n,i){t[e.key]={value:n,payloadBatch:i}}function $c(t,e,n,i){var r=n.payloadBatch,o=e.axis,a=o.model,s=e.axisPointerModel;if(e.triggerTooltip&&r.length){var l=e.coordSys.model,u=tc(l),h=t.map[u];h||(h=t.map[u]={coordSysId:l.id,coordSysIndex:l.componentIndex,coordSysType:l.type,coordSysMainType:l.mainType,dataByAxis:[]},t.list.push(h)),h.dataByAxis.push({axisDim:o.dim,axisIndex:a.componentIndex,axisType:a.type,axisId:a.id,value:i,valueLabelOpt:{precision:s.get("label.precision"),formatter:s.get("label.formatter")},seriesDataIndices:r.slice()})}}function Kc(t,e,n){var i=n.axesInfo=[];FM(e,function(e,n){var r=e.axisPointerModel.option,o=t[n];o?(!e.useHandle&&(r.status="show"),r.value=o.value,r.seriesDataIndices=(o.payloadBatch||[]).slice()):!e.useHandle&&(r.status="hide"),"show"===r.status&&i.push({axisDim:e.axis.dim,axisIndex:e.axis.model.componentIndex,value:r.value})})}function Qc(t,e,n,i){if(nd(e)||!t.list.length)return void i({type:"hideTip"});var r=((t.list[0].dataByAxis[0]||{}).seriesDataIndices||[])[0]||{};i({type:"showTip",escapeConnect:!0,x:e[0],y:e[1],tooltipOption:n.tooltipOption,position:n.position,dataIndexInside:r.dataIndexInside,dataIndex:r.dataIndex,seriesIndex:r.seriesIndex,dataByCoordSys:t.list})}function Jc(t,e,n){var i=n.getZr(),r="axisPointerLastHighlights",o=WM(i)[r]||{},a=WM(i)[r]={};FM(t,function(t){var e=t.axisPointerModel.option;"show"===e.status&&FM(e.seriesDataIndices,function(t){var e=t.seriesIndex+" | "+t.dataIndex;a[e]=t})});var s=[],l=[];f(o,function(t,e){!a[e]&&l.push(t)}),f(a,function(t,e){!o[e]&&s.push(t)}),l.length&&n.dispatchAction({type:"downplay",escapeConnect:!0,batch:l}),s.length&&n.dispatchAction({type:"highlight",escapeConnect:!0,batch:s})}function td(t,e){for(var n=0;n<(t||[]).length;n++){var i=t[n];if(e.axis.dim===i.axisDim&&e.axis.model.componentIndex===i.axisIndex)return i
+}}function ed(t){var e=t.axis.model,n={},i=n.axisDim=t.axis.dim;return n.axisIndex=n[i+"AxisIndex"]=e.componentIndex,n.axisName=n[i+"AxisName"]=e.name,n.axisId=n[i+"AxisId"]=e.id,n}function nd(t){return!t||null==t[0]||isNaN(t[0])||null==t[1]||isNaN(t[1])}function id(t,e,n){if(!Jp.node){var i=e.getZr();UM(i).records||(UM(i).records={}),rd(i,e);var r=UM(i).records[t]||(UM(i).records[t]={});r.handler=n}}function rd(t,e){function n(n,i){t.on(n,function(n){var r=ld(e);ZM(UM(t).records,function(t){t&&i(t,n,r.dispatchAction)}),od(r.pendings,e)})}UM(t).initialized||(UM(t).initialized=!0,n("click",x(sd,"click")),n("mousemove",x(sd,"mousemove")),n("globalout",ad))}function od(t,e){var n,i=t.showTip.length,r=t.hideTip.length;i?n=t.showTip[i-1]:r&&(n=t.hideTip[r-1]),n&&(n.dispatchAction=null,e.dispatchAction(n))}function ad(t,e,n){t.handler("leave",null,n)}function sd(t,e,n,i){e.handler(t,n,i)}function ld(t){var e={showTip:[],hideTip:[]},n=function(i){var r=e[i.type];r?r.push(i):(i.dispatchAction=n,t.dispatchAction(i))};return{dispatchAction:n,pendings:e}}function ud(t,e){if(!Jp.node){var n=e.getZr(),i=(UM(n).records||{})[t];i&&(UM(n).records[t]=null)}}function hd(){}function cd(t,e,n,i){dd(XM(n).lastProp,i)||(XM(n).lastProp=i,e?Mo(n,i,t):(n.stopAnimation(),n.attr(i)))}function dd(t,e){if(M(t)&&M(e)){var n=!0;return f(e,function(e,i){n=n&&dd(t[i],e)}),!!n}return t===e}function fd(t,e){t[e.get("label.show")?"show":"hide"]()}function pd(t){return{position:t.position.slice(),rotation:t.rotation||0}}function gd(t,e,n){var i=e.get("z"),r=e.get("zlevel");t&&t.traverse(function(t){"group"!==t.type&&(null!=i&&(t.z=i),null!=r&&(t.zlevel=r),t.silent=n)})}function vd(t){var e,n=t.get("type"),i=t.getModel(n+"Style");return"line"===n?(e=i.getLineStyle(),e.fill=null):"shadow"===n&&(e=i.getAreaStyle(),e.stroke=null),e}function md(t,e,n,i,r){var o=n.get("value"),a=xd(o,e.axis,e.ecModel,n.get("seriesDataIndices"),{precision:n.get("label.precision"),formatter:n.get("label.formatter")}),s=n.getModel("label"),l=Ky(s.get("padding")||0),u=s.getFont(),h=Sn(a,u),c=r.position,d=h.width+l[1]+l[3],f=h.height+l[0]+l[2],p=r.align;"right"===p&&(c[0]-=d),"center"===p&&(c[0]-=d/2);var g=r.verticalAlign;"bottom"===g&&(c[1]-=f),"middle"===g&&(c[1]-=f/2),yd(c,d,f,i);var v=s.get("backgroundColor");v&&"auto"!==v||(v=e.get("axisLine.lineStyle.color")),t.label={shape:{x:0,y:0,width:d,height:f,r:s.get("borderRadius")},position:c.slice(),style:{text:a,textFont:u,textFill:s.getTextColor(),textPosition:"inside",fill:v,stroke:s.get("borderColor")||"transparent",lineWidth:s.get("borderWidth")||0,shadowBlur:s.get("shadowBlur"),shadowColor:s.get("shadowColor"),shadowOffsetX:s.get("shadowOffsetX"),shadowOffsetY:s.get("shadowOffsetY")},z2:10}}function yd(t,e,n,i){var r=i.getWidth(),o=i.getHeight();t[0]=Math.min(t[0]+e,r)-e,t[1]=Math.min(t[1]+n,o)-n,t[0]=Math.max(t[0],0),t[1]=Math.max(t[1],0)}function xd(t,e,n,i,r){t=e.scale.parse(t);var o=e.scale.getLabel(t,{precision:r.precision}),a=r.formatter;if(a){var s={value:Fu(e,t),seriesData:[]};f(i,function(t){var e=n.getSeriesByIndex(t.seriesIndex),i=t.dataIndexInside,r=e&&e.getDataParams(i);r&&s.seriesData.push(r)}),b(a)?o=a.replace("{value}",o):w(a)&&(o=a(s))}return o}function _d(t,e,n){var i=fe();return ye(i,i,n.rotation),me(i,i,n.position),Co([t.dataToCoord(e),(n.labelOffset||0)+(n.labelDirection||1)*(n.labelMargin||0)],i)}function wd(t,e,n,i,r,o){var a=Rb.innerTextLayout(n.rotation,0,n.labelDirection);n.labelMargin=r.get("label.margin"),md(e,i,r,o,{position:_d(i.axis,t,n),align:a.textAlign,verticalAlign:a.textVerticalAlign})}function bd(t,e,n){return n=n||0,{x1:t[n],y1:t[1-n],x2:e[n],y2:e[1-n]}}function Md(t,e,n){return n=n||0,{x:t[n],y:t[1-n],width:e[n],height:e[1-n]}}function Sd(t,e){var n={};return n[e.dim+"AxisIndex"]=e.index,t.getCartesian(n)}function Id(t){return"x"===t.dim?0:1}function Cd(t){var e="cubic-bezier(0.23, 1, 0.32, 1)",n="left "+t+"s "+e+",top "+t+"s "+e;return p(tS,function(t){return t+"transition:"+n}).join(";")}function Td(t){var e=[],n=t.get("fontSize"),i=t.getTextColor();return i&&e.push("color:"+i),e.push("font:"+t.getFont()),n&&e.push("line-height:"+Math.round(3*n/2)+"px"),QM(["decoration","align"],function(n){var i=t.get(n);i&&e.push("text-"+n+":"+i)}),e.join(";")}function Ad(t){var e=[],n=t.get("transitionDuration"),i=t.get("backgroundColor"),r=t.getModel("textStyle"),o=t.get("padding");return n&&e.push(Cd(n)),i&&(Jp.canvasSupported?e.push("background-Color:"+i):(e.push("background-Color:#"+Ne(i)),e.push("filter:alpha(opacity=70)"))),QM(["width","color","radius"],function(n){var i="border-"+n,r=JM(i),o=t.get(r);null!=o&&e.push(i+":"+o+("color"===n?"":"px"))}),e.push(Td(r)),null!=o&&e.push("padding:"+Ky(o).join("px ")+"px"),e.join(";")+";"}function Dd(t,e){if(Jp.wxa)return null;var n=document.createElement("div"),i=this._zr=e.getZr();this.el=n,this._x=e.getWidth()/2,this._y=e.getHeight()/2,t.appendChild(n),this._container=t,this._show=!1,this._hideTimeout;var r=this;n.onmouseenter=function(){r._enterable&&(clearTimeout(r._hideTimeout),r._show=!0),r._inContent=!0},n.onmousemove=function(e){if(e=e||window.event,!r._enterable){var n=i.handler;vi(t,e,!0),n.dispatch("mousemove",e)}},n.onmouseleave=function(){r._enterable&&r._show&&r.hideLater(r._hideDelay),r._inContent=!1}}function kd(t){for(var e=t.pop();t.length;){var n=t.pop();n&&(Lo.isInstance(n)&&(n=n.get("tooltip",!0)),"string"==typeof n&&(n={formatter:n}),e=new Lo(n,e,e.ecModel))}return e}function Pd(t,e){return t.dispatchAction||y(e.dispatchAction,e)}function Ld(t,e,n,i,r,o,a){var s=Ed(n),l=s.width,u=s.height;return null!=o&&(t+l+o>i?t-=l+o:t+=o),null!=a&&(e+u+a>r?e-=u+a:e+=a),[t,e]}function Od(t,e,n,i,r){var o=Ed(n),a=o.width,s=o.height;return t=Math.min(t+a,i)-a,e=Math.min(e+s,r)-s,t=Math.max(t,0),e=Math.max(e,0),[t,e]}function Ed(t){var e=t.clientWidth,n=t.clientHeight;if(document.defaultView&&document.defaultView.getComputedStyle){var i=document.defaultView.getComputedStyle(t);i&&(e+=parseInt(i.paddingLeft,10)+parseInt(i.paddingRight,10)+parseInt(i.borderLeftWidth,10)+parseInt(i.borderRightWidth,10),n+=parseInt(i.paddingTop,10)+parseInt(i.paddingBottom,10)+parseInt(i.borderTopWidth,10)+parseInt(i.borderBottomWidth,10))}return{width:e,height:n}}function Rd(t,e,n){var i=n[0],r=n[1],o=5,a=0,s=0,l=e.width,u=e.height;switch(t){case"inside":a=e.x+l/2-i/2,s=e.y+u/2-r/2;break;case"top":a=e.x+l/2-i/2,s=e.y-r-o;break;case"bottom":a=e.x+l/2-i/2,s=e.y+u+o;break;case"left":a=e.x-i-o,s=e.y+u/2-r/2;break;case"right":a=e.x+l+o,s=e.y+u/2-r/2}return[a,s]}function zd(t){return"center"===t||"middle"===t}function Bd(t,e){aS[t]=e}function Nd(t){return aS[t]}function Vd(t){return 0===t.indexOf("my")}function Fd(t){this.model=t}function Hd(t){this.model=t}function Wd(t){var e={},n=[],i=[];return t.eachRawSeries(function(t){var r=t.coordinateSystem;if(!r||"cartesian2d"!==r.type&&"polar"!==r.type)n.push(t);else{var o=r.getBaseAxis();if("category"===o.type){var a=o.dim+"_"+o.index;e[a]||(e[a]={categoryAxis:o,valueAxis:r.getOtherAxis(o),series:[]},i.push({axisDim:o.dim,axisIndex:o.index})),e[a].series.push(t)}else n.push(t)}}),{seriesGroupByCategoryAxis:e,other:n,meta:i}}function Gd(t){var e=[];return f(t,function(t){var n=t.categoryAxis,i=t.valueAxis,r=i.dim,o=[" "].concat(p(t.series,function(t){return t.name})),a=[n.model.getCategories()];f(t.series,function(t){a.push(t.getRawData().mapArray(r,function(t){return t}))});for(var s=[o.join(vS)],l=0;l<a[0].length;l++){for(var u=[],h=0;h<a.length;h++)u.push(a[h][l]);s.push(u.join(vS))}e.push(s.join("\n"))}),e.join("\n\n"+gS+"\n\n")}function Ud(t){return p(t,function(t){var e=t.getRawData(),n=[t.name],i=[];return e.each(e.dimensions,function(){for(var t=arguments.length,r=arguments[t-1],o=e.getName(r),a=0;t-1>a;a++)i[a]=arguments[a];n.push((o?o+vS:"")+i.join(vS))}),n.join("\n")}).join("\n\n"+gS+"\n\n")}function Zd(t){var e=Wd(t);return{value:v([Gd(e.seriesGroupByCategoryAxis),Ud(e.other)],function(t){return t.replace(/[\n\t\s]/g,"")}).join("\n\n"+gS+"\n\n"),meta:e.meta}}function jd(t){return t.replace(/^\s\s*/,"").replace(/\s\s*$/,"")}function Xd(t){var e=t.slice(0,t.indexOf("\n"));return e.indexOf(vS)>=0?!0:void 0}function Yd(t){for(var e=t.split(/\n+/g),n=jd(e.shift()).split(mS),i=[],r=p(n,function(t){return{name:t,data:[]}}),o=0;o<e.length;o++){var a=jd(e[o]).split(mS);i.push(a.shift());for(var s=0;s<a.length;s++)r[s]&&(r[s].data[o]=a[s])}return{series:r,categories:i}}function qd(t){for(var e=t.split(/\n+/g),n=jd(e.shift()),i=[],r=0;r<e.length;r++){var o,a=jd(e[r]).split(mS),s="",l=!1;isNaN(a[0])?(l=!0,s=a[0],a=a.slice(1),i[r]={name:s,value:[]},o=i[r].value):o=i[r]=[];for(var u=0;u<a.length;u++)o.push(+a[u]);1===o.length&&(l?i[r].value=o[0]:i[r]=o[0])}return{name:n,data:i}}function $d(t,e){var n=t.split(new RegExp("\n*"+gS+"\n*","g")),i={series:[]};return f(n,function(t,n){if(Xd(t)){var r=Yd(t),o=e[n],a=o.axisDim+"Axis";o&&(i[a]=i[a]||[],i[a][o.axisIndex]={data:r.categories},i.series=i.series.concat(r.series))}else{var r=qd(t);i.series.push(r)}}),i}function Kd(t){this._dom=null,this.model=t}function Qd(t,e){return p(t,function(t,n){var i=e&&e[n];return M(i)&&!_(i)?(M(t)&&!_(t)&&(t=t.value),s({value:t},i)):t})}function Jd(t,e,n){var i=ef(t);i[e]=n}function tf(t,e,n){var i=ef(t),r=i[e];r===n&&(i[e]=null)}function ef(t){return t[yS]||(t[yS]={})}function nf(t){wg.call(this),this._zr=t,this.group=new nv,this._brushType,this._brushOption,this._panels,this._track=[],this._dragging,this._covers=[],this._creatingCover,this._creatingPanel,this._enableGlobalPan,this._uid="brushController_"+LS++,this._handlers={},_S(OS,function(t,e){this._handlers[e]=y(t,this)},this)}function rf(t,e){var n=t._zr;t._enableGlobalPan||Jd(n,AS,t._uid),_S(t._handlers,function(t,e){n.on(e,t)}),t._brushType=e.brushType,t._brushOption=r(i(PS),e,!0)}function of(t){var e=t._zr;tf(e,AS,t._uid),_S(t._handlers,function(t,n){e.off(n,t)}),t._brushType=t._brushOption=null}function af(t,e){var n=ES[e.brushType].createCover(t,e);return n.__brushOption=e,uf(n,e),t.group.add(n),n}function sf(t,e){var n=cf(e);return n.endCreating&&(n.endCreating(t,e),uf(e,e.__brushOption)),e}function lf(t,e){var n=e.__brushOption;cf(e).updateCoverShape(t,e,n.range,n)}function uf(t,e){var n=e.z;null==n&&(n=IS),t.traverse(function(t){t.z=n,t.z2=n})}function hf(t,e){cf(e).updateCommon(t,e),lf(t,e)}function cf(t){return ES[t.__brushOption.brushType]}function df(t,e,n){var i=t._panels;if(!i)return!0;var r,o=t._transform;return _S(i,function(t){t.isTargetByCursor(e,n,o)&&(r=t)}),r}function ff(t,e){var n=t._panels;if(!n)return!0;var i=e.__brushOption.panelId;return null!=i?n[i]:!0}function pf(t){var e=t._covers,n=e.length;return _S(e,function(e){t.group.remove(e)},t),e.length=0,!!n}function gf(t,e){var n=wS(t._covers,function(t){var e=t.__brushOption,n=i(e.range);return{brushType:e.brushType,panelId:e.panelId,range:n}});t.trigger("brush",n,{isEnd:!!e.isEnd,removeOnClick:!!e.removeOnClick})}function vf(t){var e=t._track;if(!e.length)return!1;var n=e[e.length-1],i=e[0],r=n[0]-i[0],o=n[1]-i[1],a=SS(r*r+o*o,.5);return a>CS}function mf(t){var e=t.length-1;return 0>e&&(e=0),[t[0],t[e]]}function yf(t,e,n,i){var r=new nv;return r.add(new Sy({name:"main",style:bf(n),silent:!0,draggable:!0,cursor:"move",drift:xS(t,e,r,"nswe"),ondragend:xS(gf,e,{isEnd:!0})})),_S(i,function(n){r.add(new Sy({name:n,style:{opacity:0},draggable:!0,silent:!0,invisible:!0,drift:xS(t,e,r,n),ondragend:xS(gf,e,{isEnd:!0})}))}),r}function xf(t,e,n,i){var r=i.brushStyle.lineWidth||0,o=MS(r,TS),a=n[0][0],s=n[1][0],l=a-r/2,u=s-r/2,h=n[0][1],c=n[1][1],d=h-o+r/2,f=c-o+r/2,p=h-a,g=c-s,v=p+r,m=g+r;wf(t,e,"main",a,s,p,g),i.transformable&&(wf(t,e,"w",l,u,o,m),wf(t,e,"e",d,u,o,m),wf(t,e,"n",l,u,v,o),wf(t,e,"s",l,f,v,o),wf(t,e,"nw",l,u,o,o),wf(t,e,"ne",d,u,o,o),wf(t,e,"sw",l,f,o,o),wf(t,e,"se",d,f,o,o))}function _f(t,e){var n=e.__brushOption,i=n.transformable,r=e.childAt(0);r.useStyle(bf(n)),r.attr({silent:!i,cursor:i?"move":"default"}),_S(["w","e","n","s","se","sw","ne","nw"],function(n){var r=e.childOfName(n),o=If(t,n);r&&r.attr({silent:!i,invisible:!i,cursor:i?kS[o]+"-resize":null})})}function wf(t,e,n,i,r,o,a){var s=e.childOfName(n);s&&s.setShape(kf(Df(t,e,[[i,r],[i+o,r+a]])))}function bf(t){return s({strokeNoScale:!0},t.brushStyle)}function Mf(t,e,n,i){var r=[bS(t,n),bS(e,i)],o=[MS(t,n),MS(e,i)];return[[r[0],o[0]],[r[1],o[1]]]}function Sf(t){return Io(t.group)}function If(t,e){if(e.length>1){e=e.split("");var n=[If(t,e[0]),If(t,e[1])];return("e"===n[0]||"w"===n[0])&&n.reverse(),n.join("")}var i={w:"left",e:"right",n:"top",s:"bottom"},r={left:"w",right:"e",top:"n",bottom:"s"},n=To(i[e],Sf(t));return r[n]}function Cf(t,e,n,i,r,o,a){var s=i.__brushOption,l=t(s.range),u=Af(n,o,a);_S(r.split(""),function(t){var e=DS[t];l[e[0]][e[1]]+=u[e[0]]}),s.range=e(Mf(l[0][0],l[1][0],l[0][1],l[1][1])),hf(n,i),gf(n,{isEnd:!1})}function Tf(t,e,n,i){var r=e.__brushOption.range,o=Af(t,n,i);_S(r,function(t){t[0]+=o[0],t[1]+=o[1]}),hf(t,e),gf(t,{isEnd:!1})}function Af(t,e,n){var i=t.group,r=i.transformCoordToLocal(e,n),o=i.transformCoordToLocal(0,0);return[r[0]-o[0],r[1]-o[1]]}function Df(t,e,n){var r=ff(t,e);return r&&r!==!0?r.clipPath(n,t._transform):i(n)}function kf(t){var e=bS(t[0][0],t[1][0]),n=bS(t[0][1],t[1][1]),i=MS(t[0][0],t[1][0]),r=MS(t[0][1],t[1][1]);return{x:e,y:n,width:i-e,height:r-n}}function Pf(t,e,n){if(t._brushType){var i=t._zr,r=t._covers,o=df(t,e,n);if(!t._dragging)for(var a=0;a<r.length;a++){var s=r[a].__brushOption;if(o&&(o===!0||s.panelId===o.panelId)&&ES[s.brushType].contain(r[a],n[0],n[1]))return}o&&i.setCursorStyle("crosshair")}}function Lf(t){var e=t.event;e.preventDefault&&e.preventDefault()}function Of(t,e,n){return t.childOfName("main").contain(e,n)}function Ef(t,e,n,r){var o,a=t._creatingCover,s=t._creatingPanel,l=t._brushOption;if(t._track.push(n.slice()),vf(t)||a){if(s&&!a){"single"===l.brushMode&&pf(t);var u=i(l);u.brushType=Rf(u.brushType,s),u.panelId=s===!0?null:s.panelId,a=t._creatingCover=af(t,u),t._covers.push(a)}if(a){var h=ES[Rf(t._brushType,s)],c=a.__brushOption;c.range=h.getCreatingRange(Df(t,a,t._track)),r&&(sf(t,a),h.updateCommon(t,a)),lf(t,a),o={isEnd:r}}}else r&&"single"===l.brushMode&&l.removeOnClick&&df(t,e,n)&&pf(t)&&(o={isEnd:r,removeOnClick:!0});return o}function Rf(t,e){return"auto"===t?e.defaultBrushType:t}function zf(t){if(this._dragging){Lf(t);var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY),n=Ef(this,t,e,!0);this._dragging=!1,this._track=[],this._creatingCover=null,n&&gf(this,n)}}function Bf(t){return{createCover:function(e,n){return yf(xS(Cf,function(e){var n=[e,[0,100]];return t&&n.reverse(),n},function(e){return e[t]}),e,n,[["w","e"],["n","s"]][t])},getCreatingRange:function(e){var n=mf(e),i=bS(n[0][t],n[1][t]),r=MS(n[0][t],n[1][t]);return[i,r]},updateCoverShape:function(e,n,i,r){var o,a=ff(e,n);if(a!==!0&&a.getLinearBrushOtherExtent)o=a.getLinearBrushOtherExtent(t,e._transform);else{var s=e._zr;o=[0,[s.getWidth(),s.getHeight()][1-t]]}var l=[i,o];t&&l.reverse(),xf(e,n,l,r)},updateCommon:_f,contain:Of}}function Nf(t,e,n){var i=e.getComponentByElement(t.topTarget),r=i&&i.coordinateSystem;return i&&i!==n&&!RS[i.mainType]&&r&&r.model!==n}function Vf(t){return t=Wf(t),function(e){return Do(e,t)}}function Ff(t,e){return t=Wf(t),function(n){var i=null!=e?e:n,r=i?t.width:t.height,o=i?t.x:t.y;return[o,o+(r||0)]}}function Hf(t,e,n){return t=Wf(t),function(i,r){return t.contain(r[0],r[1])&&!Nf(i,e,n)}}function Wf(t){return rn.create(t)}function Gf(t,e,n){var i=this._targetInfoList=[],r={},o=Zf(e,t);zS(WS,function(t,e){(!n||!n.include||BS(n.include,e)>=0)&&t(o,i,r)})}function Uf(t){return t[0]>t[1]&&t.reverse(),t}function Zf(t,e){return Wi(t,e,{includeMainTypes:FS})}function jf(t,e,n,i){var r=n.getAxis(["x","y"][t]),o=Uf(p([0,1],function(t){return e?r.coordToData(r.toLocalCoord(i[t])):r.toGlobalCoord(r.dataToCoord(i[t]))})),a=[];return a[t]=o,a[1-t]=[0/0,0/0],{values:o,xyMinMax:a}}function Xf(t,e,n,i){return[e[0]-i[t]*n[0],e[1]-i[t]*n[1]]}function Yf(t,e){var n=qf(t),i=qf(e),r=[n[0]/i[0],n[1]/i[1]];return isNaN(r[0])&&(r[0]=1),isNaN(r[1])&&(r[1]=1),r}function qf(t){return t?[t[0][1]-t[0][0],t[1][1]-t[1][0]]:[0/0,0/0]}function $f(t,e){var n=tp(t);XS(e,function(e,i){for(var r=n.length-1;r>=0;r--){var o=n[r];if(o[i])break}if(0>r){var a=t.queryComponents({mainType:"dataZoom",subType:"select",id:i})[0];if(a){var s=a.getPercentRange();n[0][i]={dataZoomId:i,start:s[0],end:s[1]}}}}),n.push(e)}function Kf(t){var e=tp(t),n=e[e.length-1];e.length>1&&e.pop();var i={};return XS(n,function(t,n){for(var r=e.length-1;r>=0;r--){var t=e[r][n];if(t){i[n]=t;break}}}),i}function Qf(t){t[YS]=null}function Jf(t){return tp(t).length}function tp(t){var e=t[YS];return e||(e=t[YS]=[{}]),e}function ep(t,e){var n=t[e]-t[1-e];return{span:Math.abs(n),sign:n>0?-1:0>n?1:e?-1:1}}function np(t,e){return Math.min(e[1],Math.max(e[0],t))}function ip(t){return u(KS,t)>=0}function rp(t,e){t=t.slice();var n=p(t,ua);e=(e||[]).slice();var i=p(e,ua);return function(r,o){f(t,function(t,a){for(var s={name:t,capital:n[a]},l=0;l<e.length;l++)s[e[l]]=t+i[l];r.call(o,s)})}}function op(t,e,n){function i(t,e){return u(e.nodes,t)>=0}function r(t,i){var r=!1;return e(function(e){f(n(t,e)||[],function(t){i.records[e.name][t]&&(r=!0)})}),r}function o(t,i){i.nodes.push(t),e(function(e){f(n(t,e)||[],function(t){i.records[e.name][t]=!0})})}return function(n){function a(t){!i(t,s)&&r(t,s)&&(o(t,s),l=!0)}var s={nodes:[],records:{}};if(e(function(t){s.records[t.name]={}}),!n)return s;o(n,s);var l;do l=!1,t(a);while(l);return s}}function ap(t,e,n){var i=[1/0,-1/0];return JS(n,function(t){var n=t.getData();n&&JS(n.mapDimension(e,!0),function(t){var e=n.getApproximateExtent(t);e[0]<i[0]&&(i[0]=e[0]),e[1]>i[1]&&(i[1]=e[1])})}),i[1]<i[0]&&(i=[0/0,0/0]),sp(t,i),i}function sp(t,e){var n=t.getAxisModel(),i=n.getMin(!0),r="category"===n.get("type"),o=r&&n.getCategories().length;null!=i&&"dataMin"!==i&&"function"!=typeof i?e[0]=i:r&&(e[0]=o>0?0:0/0);var a=n.getMax(!0);return null!=a&&"dataMax"!==a&&"function"!=typeof a?e[1]=a:r&&(e[1]=o>0?o-1:0/0),n.get("scale",!0)||(e[0]>0&&(e[0]=0),e[1]<0&&(e[1]=0)),e}function lp(t,e){var n=t.getAxisModel(),i=t._percentWindow,r=t._valueWindow;if(i){var o=Zo(r,[0,500]);o=Math.min(o,20);var a=e||0===i[0]&&100===i[1];n.setRange(a?null:+r[0].toFixed(o),a?null:+r[1].toFixed(o))}}function up(t){var e=t._minMaxSpan={},n=t._dataZoomModel;JS(["min","max"],function(i){e[i+"Span"]=n.get(i+"Span");var r=n.get(i+"ValueSpan");if(null!=r&&(e[i+"ValueSpan"]=r,r=t.getAxisModel().axis.scale.parse(r),null!=r)){var o=t._dataExtent;e[i+"Span"]=Vo(o[0]+r,o,[0,100],!0)}})}function hp(t){var e={};return nI(["start","end","startValue","endValue","throttle"],function(n){t.hasOwnProperty(n)&&(e[n]=t[n])}),e}function cp(t,e){var n=t._rangePropMode,i=t.get("rangeMode");nI([["start","startValue"],["end","endValue"]],function(t,r){var o=null!=e[t[0]],a=null!=e[t[1]];o&&!a?n[r]="percent":!o&&a?n[r]="value":i?n[r]=i[r]:o&&(n[r]="percent")})}function dp(t,e,n){(this._brushController=new nf(n.getZr())).on("brush",y(this._onBrush,this)).mount(),this._isZoomActive}function fp(t){var e={};return f(["xAxisIndex","yAxisIndex"],function(n){e[n]=t[n],null==e[n]&&(e[n]="all"),(e[n]===!1||"none"===e[n])&&(e[n]=[])}),e}function pp(t,e){t.setIconStatus("back",Jf(e)>1?"emphasis":"normal")}function gp(t,e,n,i,r){var o=n._isZoomActive;i&&"takeGlobalCursor"===i.type&&(o="dataZoomSelect"===i.key?i.dataZoomSelectActive:!1),n._isZoomActive=o,t.setIconStatus("zoom",o?"emphasis":"normal");var a=new Gf(fp(t.option),e,{include:["grid"]});n._brushController.setPanels(a.makePanelOpts(r,function(t){return t.xAxisDeclared&&!t.yAxisDeclared?"lineX":!t.xAxisDeclared&&t.yAxisDeclared?"lineY":"rect"})).enableBrush(o?{brushType:"auto",brushStyle:{lineWidth:0,fill:"rgba(0,0,0,0.2)"}}:!1)}function vp(t){this.model=t}function mp(t){return fI(t)}function yp(){if(!vI&&mI){vI=!0;var t=mI.styleSheets;t.length<31?mI.createStyleSheet().addRule(".zrvml","behavior:url(#default#VML)"):t[0].addRule(".zrvml","behavior:url(#default#VML)")}}function xp(t){return parseInt(t,10)}function _p(t,e){yp(),this.root=t,this.storage=e;var n=document.createElement("div"),i=document.createElement("div");n.style.cssText="display:inline-block;overflow:hidden;position:relative;width:300px;height:150px;",i.style.cssText="position:absolute;left:0;top:0;",t.appendChild(n),this._vmlRoot=i,this._vmlViewport=n,this.resize();var r=e.delFromStorage,o=e.addToStorage;e.delFromStorage=function(t){r.call(e,t),t&&t.onRemove&&t.onRemove(i)},e.addToStorage=function(t){t.onAdd&&t.onAdd(i),o.call(e,t)},this._firstPaint=!0}function wp(t){return function(){$g('In IE8.0 VML mode painter not support method "'+t+'"')}}function bp(t){return document.createElementNS(sC,t)}function Mp(t){return cC(1e4*t)/1e4}function Sp(t){return mC>t&&t>-mC}function Ip(t,e){var n=e?t.textFill:t.fill;return null!=n&&n!==hC}function Cp(t,e){var n=e?t.textStroke:t.stroke;return null!=n&&n!==hC}function Tp(t,e){e&&Ap(t,"transform","matrix("+uC.call(e,",")+")")}function Ap(t,e,n){(!n||"linear"!==n.type&&"radial"!==n.type)&&("string"==typeof n&&n.indexOf("NaN")>-1&&console.log(n),t.setAttribute(e,n))}function Dp(t,e,n){t.setAttributeNS("http://www.w3.org/1999/xlink",e,n)}function kp(t,e,n){if(Ip(e,n)){var i=n?e.textFill:e.fill;i="transparent"===i?hC:i,"none"!==t.getAttribute("clip-path")&&i===hC&&(i="rgba(0, 0, 0, 0.002)"),Ap(t,"fill",i),Ap(t,"fill-opacity",e.opacity)}else Ap(t,"fill",hC);if(Cp(e,n)){var r=n?e.textStroke:e.stroke;r="transparent"===r?hC:r,Ap(t,"stroke",r);var o=n?e.textStrokeWidth:e.lineWidth,a=!n&&e.strokeNoScale?e.host.getLineScale():1;Ap(t,"stroke-width",o/a),Ap(t,"paint-order",n?"stroke":"fill"),Ap(t,"stroke-opacity",e.opacity);var s=e.lineDash;s?(Ap(t,"stroke-dasharray",e.lineDash.join(",")),Ap(t,"stroke-dashoffset",cC(e.lineDashOffset||0))):Ap(t,"stroke-dasharray",""),e.lineCap&&Ap(t,"stroke-linecap",e.lineCap),e.lineJoin&&Ap(t,"stroke-linejoin",e.lineJoin),e.miterLimit&&Ap(t,"stroke-miterlimit",e.miterLimit)}else Ap(t,"stroke",hC)}function Pp(t){for(var e=[],n=t.data,i=t.len(),r=0;i>r;){var o=n[r++],a="",s=0;switch(o){case lC.M:a="M",s=2;break;case lC.L:a="L",s=2;break;case lC.Q:a="Q",s=4;break;case lC.C:a="C",s=6;break;case lC.A:var l=n[r++],u=n[r++],h=n[r++],c=n[r++],d=n[r++],f=n[r++],p=n[r++],g=n[r++],v=Math.abs(f),m=Sp(v-gC)&&!Sp(v),y=!1;y=v>=gC?!0:Sp(v)?!1:(f>-pC&&0>f||f>pC)==!!g;var x=Mp(l+h*fC(d)),_=Mp(u+c*dC(d));m&&(f=g?gC-1e-4:-gC+1e-4,y=!0,9===r&&e.push("M",x,_));var w=Mp(l+h*fC(d+f)),b=Mp(u+c*dC(d+f));e.push("A",Mp(h),Mp(c),cC(p*vC),+y,+g,w,b);break;case lC.Z:a="Z";break;case lC.R:var w=Mp(n[r++]),b=Mp(n[r++]),M=Mp(n[r++]),S=Mp(n[r++]);e.push("M",w,b,"L",w+M,b,"L",w+M,b+S,"L",w,b+S,"L",w,b)}a&&e.push(a);for(var I=0;s>I;I++)e.push(Mp(n[r++]))}return e.join(" ")}function Lp(t){return"middle"===t?"middle":"bottom"===t?"baseline":"hanging"}function Op(){}function Ep(t,e){for(var n=0,i=e.length,r=0,o=0;i>n;n++){var a=e[n];if(a.removed){for(var s=[],l=o;l<o+a.count;l++)s.push(l);a.indices=s,o+=a.count}else{for(var s=[],l=r;l<r+a.count;l++)s.push(l);a.indices=s,r+=a.count,a.added||(o+=a.count)}}return e}function Rp(t){return{newPos:t.newPos,components:t.components.slice(0)}}function zp(t,e,n,i,r){this._zrId=t,this._svgRoot=e,this._tagNames="string"==typeof n?[n]:n,this._markLabel=i,this._domName=r||"_dom",this.nextId=0}function Bp(t,e){zp.call(this,t,e,["linearGradient","radialGradient"],"__gradient_in_use__")}function Np(t,e){zp.call(this,t,e,"clipPath","__clippath_in_use__")}function Vp(t,e){zp.call(this,t,e,["filter"],"__filter_in_use__","_shadowDom")}function Fp(t){return t&&(t.shadowBlur||t.shadowOffsetX||t.shadowOffsetY||t.textShadowBlur||t.textShadowOffsetX||t.textShadowOffsetY)}function Hp(t){return parseInt(t,10)}function Wp(t){return t instanceof Lr?yC:t instanceof ai?xC:t instanceof py?_C:yC}function Gp(t,e){return e&&t&&e.parentNode!==t}function Up(t,e,n){if(Gp(t,e)&&n){var i=n.nextSibling;i?t.insertBefore(e,i):t.appendChild(e)}}function Zp(t,e){if(Gp(t,e)){var n=t.firstChild;n?t.insertBefore(e,n):t.appendChild(e)}}function jp(t,e){e&&t&&e.parentNode===t&&t.removeChild(e)}function Xp(t){return t.__textSvgEl}function Yp(t){return t.__svgEl}function qp(t){return function(){$g('In SVG mode painter not support method "'+t+'"')}}var $p=2311,Kp=function(){return $p++},Qp={};Qp="object"==typeof wx&&"function"==typeof wx.getSystemInfoSync?{browser:{},os:{},node:!1,wxa:!0,canvasSupported:!0,svgSupported:!1,touchEventsSupported:!0}:"undefined"==typeof document&&"undefined"!=typeof self?{browser:{},os:{},node:!1,worker:!0,canvasSupported:!0}:"undefined"==typeof navigator?{browser:{},os:{},node:!0,worker:!1,canvasSupported:!0,svgSupported:!0}:e(navigator.userAgent);var Jp=Qp,tg={"[object Function]":1,"[object RegExp]":1,"[object Date]":1,"[object Error]":1,"[object CanvasGradient]":1,"[object CanvasPattern]":1,"[object Image]":1,"[object Canvas]":1},eg={"[object Int8Array]":1,"[object Uint8Array]":1,"[object Uint8ClampedArray]":1,"[object Int16Array]":1,"[object Uint16Array]":1,"[object Int32Array]":1,"[object Uint32Array]":1,"[object Float32Array]":1,"[object Float64Array]":1},ng=Object.prototype.toString,ig=Array.prototype,rg=ig.forEach,og=ig.filter,ag=ig.slice,sg=ig.map,lg=ig.reduce,ug={},hg=function(){return ug.createCanvas()};ug.createCanvas=function(){return document.createElement("canvas")};var cg,dg="__ec_primitive__";B.prototype={constructor:B,get:function(t){return this.hasOwnProperty(t)?this[t]:null},set:function(t,e){return this[t]=e},each:function(t,e){void 0!==e&&(t=y(t,e));for(var n in this)this.hasOwnProperty(n)&&t(this[n],n)},removeKey:function(t){delete this[t]}};var fg=(Object.freeze||Object)({$override:n,clone:i,merge:r,mergeAll:o,extend:a,defaults:s,createCanvas:hg,getContext:l,indexOf:u,inherits:h,mixin:c,isArrayLike:d,each:f,map:p,reduce:g,filter:v,find:m,bind:y,curry:x,isArray:_,isFunction:w,isString:b,isObject:M,isBuiltInObject:S,isTypedArray:I,isDom:C,eqNaN:T,retrieve:A,retrieve2:D,retrieve3:k,slice:P,normalizeCssArray:L,assert:O,trim:E,setAsPrimitive:R,isPrimitive:z,createHashMap:N,concatArray:V,noop:F}),pg="undefined"==typeof Float32Array?Array:Float32Array,gg=Y,vg=q,mg=ee,yg=ne,xg=(Object.freeze||Object)({create:H,copy:W,clone:G,set:U,add:Z,scaleAndAdd:j,sub:X,len:Y,length:gg,lenSquare:q,lengthSquare:vg,mul:$,div:K,dot:Q,scale:J,normalize:te,distance:ee,dist:mg,distanceSquare:ne,distSquare:yg,negate:ie,lerp:re,applyTransform:oe,min:ae,max:se});le.prototype={constructor:le,_dragStart:function(t){var e=t.target;e&&e.draggable&&(this._draggingTarget=e,e.dragging=!0,this._x=t.offsetX,this._y=t.offsetY,this.dispatchToElement(ue(e,t),"dragstart",t.event))},_drag:function(t){var e=this._draggingTarget;if(e){var n=t.offsetX,i=t.offsetY,r=n-this._x,o=i-this._y;this._x=n,this._y=i,e.drift(r,o,t),this.dispatchToElement(ue(e,t),"drag",t.event);var a=this.findHover(n,i,e).target,s=this._dropTarget;this._dropTarget=a,e!==a&&(s&&a!==s&&this.dispatchToElement(ue(s,t),"dragleave",t.event),a&&a!==s&&this.dispatchToElement(ue(a,t),"dragenter",t.event))}},_dragEnd:function(t){var e=this._draggingTarget;e&&(e.dragging=!1),this.dispatchToElement(ue(e,t),"dragend",t.event),this._dropTarget&&this.dispatchToElement(ue(this._dropTarget,t),"drop",t.event),this._draggingTarget=null,this._dropTarget=null}};var _g=Array.prototype.slice,wg=function(){this._$handlers={}};wg.prototype={constructor:wg,one:function(t,e,n){var i=this._$handlers;if(!e||!t)return this;i[t]||(i[t]=[]);for(var r=0;r<i[t].length;r++)if(i[t][r].h===e)return this;return i[t].push({h:e,one:!0,ctx:n||this}),this},on:function(t,e,n){var i=this._$handlers;if(!e||!t)return this;i[t]||(i[t]=[]);for(var r=0;r<i[t].length;r++)if(i[t][r].h===e)return this;return i[t].push({h:e,one:!1,ctx:n||this}),this},isSilent:function(t){var e=this._$handlers;return e[t]&&e[t].length},off:function(t,e){var n=this._$handlers;if(!t)return this._$handlers={},this;if(e){if(n[t]){for(var i=[],r=0,o=n[t].length;o>r;r++)n[t][r].h!=e&&i.push(n[t][r]);n[t]=i}n[t]&&0===n[t].length&&delete n[t]}else delete n[t];return this},trigger:function(t){if(this._$handlers[t]){var e=arguments,n=e.length;n>3&&(e=_g.call(e,1));for(var i=this._$handlers[t],r=i.length,o=0;r>o;){switch(n){case 1:i[o].h.call(i[o].ctx);break;case 2:i[o].h.call(i[o].ctx,e[1]);break;case 3:i[o].h.call(i[o].ctx,e[1],e[2]);break;default:i[o].h.apply(i[o].ctx,e)}i[o].one?(i.splice(o,1),r--):o++}}return this},triggerWithContext:function(t){if(this._$handlers[t]){var e=arguments,n=e.length;n>4&&(e=_g.call(e,1,e.length-1));for(var i=e[e.length-1],r=this._$handlers[t],o=r.length,a=0;o>a;){switch(n){case 1:r[a].h.call(i);break;case 2:r[a].h.call(i,e[1]);break;case 3:r[a].h.call(i,e[1],e[2]);break;default:r[a].h.apply(i,e)}r[a].one?(r.splice(a,1),o--):a++}}return this}};var bg="silent";ce.prototype.dispose=function(){};var Mg=["click","dblclick","mousewheel","mouseout","mouseup","mousedown","mousemove","contextmenu"],Sg=function(t,e,n,i){wg.call(this),this.storage=t,this.painter=e,this.painterRoot=i,n=n||new ce,this.proxy=null,this._hovered={},this._lastTouchMoment,this._lastX,this._lastY,le.call(this),this.setHandlerProxy(n)};Sg.prototype={constructor:Sg,setHandlerProxy:function(t){this.proxy&&this.proxy.dispose(),t&&(f(Mg,function(e){t.on&&t.on(e,this[e],this)},this),t.handler=this),this.proxy=t},mousemove:function(t){var e=t.zrX,n=t.zrY,i=this._hovered,r=i.target;r&&!r.__zr&&(i=this.findHover(i.x,i.y),r=i.target);var o=this._hovered=this.findHover(e,n),a=o.target,s=this.proxy;s.setCursor&&s.setCursor(a?a.cursor:"default"),r&&a!==r&&this.dispatchToElement(i,"mouseout",t),this.dispatchToElement(o,"mousemove",t),a&&a!==r&&this.dispatchToElement(o,"mouseover",t)},mouseout:function(t){this.dispatchToElement(this._hovered,"mouseout",t);var e,n=t.toElement||t.relatedTarget;do n=n&&n.parentNode;while(n&&9!=n.nodeType&&!(e=n===this.painterRoot));!e&&this.trigger("globalout",{event:t})},resize:function(){this._hovered={}},dispatch:function(t,e){var n=this[t];n&&n.call(this,e)},dispose:function(){this.proxy.dispose(),this.storage=this.proxy=this.painter=null},setCursorStyle:function(t){var e=this.proxy;e.setCursor&&e.setCursor(t)},dispatchToElement:function(t,e,n){t=t||{};var i=t.target;if(!i||!i.silent){for(var r="on"+e,o=he(e,t,n);i&&(i[r]&&(o.cancelBubble=i[r].call(i,o)),i.trigger(e,o),i=i.parent,!o.cancelBubble););o.cancelBubble||(this.trigger(e,o),this.painter&&this.painter.eachOtherLayer(function(t){"function"==typeof t[r]&&t[r].call(t,o),t.trigger&&t.trigger(e,o)}))}},findHover:function(t,e,n){for(var i=this.storage.getDisplayList(),r={x:t,y:e},o=i.length-1;o>=0;o--){var a;if(i[o]!==n&&!i[o].ignore&&(a=de(i[o],t,e))&&(!r.topTarget&&(r.topTarget=i[o]),a!==bg)){r.target=i[o];break}}return r}},f(["click","mousedown","mouseup","mousewheel","dblclick","contextmenu"],function(t){Sg.prototype[t]=function(e){var n=this.findHover(e.zrX,e.zrY),i=n.target;if("mousedown"===t)this._downEl=i,this._downPoint=[e.zrX,e.zrY],this._upEl=i;else if("mouseup"===t)this._upEl=i;else if("click"===t){if(this._downEl!==this._upEl||!this._downPoint||mg(this._downPoint,[e.zrX,e.zrY])>4)return;this._downPoint=null}this.dispatchToElement(n,t,e)}}),c(Sg,wg),c(Sg,le);var Ig="undefined"==typeof Float32Array?Array:Float32Array,Cg=(Object.freeze||Object)({create:fe,identity:pe,copy:ge,mul:ve,translate:me,rotate:ye,scale:xe,invert:_e,clone:we}),Tg=pe,Ag=5e-5,Dg=function(t){t=t||{},t.position||(this.position=[0,0]),null==t.rotation&&(this.rotation=0),t.scale||(this.scale=[1,1]),this.origin=this.origin||null},kg=Dg.prototype;kg.transform=null,kg.needLocalTransform=function(){return be(this.rotation)||be(this.position[0])||be(this.position[1])||be(this.scale[0]-1)||be(this.scale[1]-1)},kg.updateTransform=function(){var t=this.parent,e=t&&t.transform,n=this.needLocalTransform(),i=this.transform;return n||e?(i=i||fe(),n?this.getLocalTransform(i):Tg(i),e&&(n?ve(i,t.transform,i):ge(i,t.transform)),this.transform=i,this.invTransform=this.invTransform||fe(),void _e(this.invTransform,i)):void(i&&Tg(i))
+},kg.getLocalTransform=function(t){return Dg.getLocalTransform(this,t)},kg.setTransform=function(t){var e=this.transform,n=t.dpr||1;e?t.setTransform(n*e[0],n*e[1],n*e[2],n*e[3],n*e[4],n*e[5]):t.setTransform(n,0,0,n,0,0)},kg.restoreTransform=function(t){var e=t.dpr||1;t.setTransform(e,0,0,e,0,0)};var Pg=[];kg.decomposeTransform=function(){if(this.transform){var t=this.parent,e=this.transform;t&&t.transform&&(ve(Pg,t.invTransform,e),e=Pg);var n=e[0]*e[0]+e[1]*e[1],i=e[2]*e[2]+e[3]*e[3],r=this.position,o=this.scale;be(n-1)&&(n=Math.sqrt(n)),be(i-1)&&(i=Math.sqrt(i)),e[0]<0&&(n=-n),e[3]<0&&(i=-i),r[0]=e[4],r[1]=e[5],o[0]=n,o[1]=i,this.rotation=Math.atan2(-e[1]/i,e[0]/n)}},kg.getGlobalScale=function(){var t=this.transform;if(!t)return[1,1];var e=Math.sqrt(t[0]*t[0]+t[1]*t[1]),n=Math.sqrt(t[2]*t[2]+t[3]*t[3]);return t[0]<0&&(e=-e),t[3]<0&&(n=-n),[e,n]},kg.transformCoordToLocal=function(t,e){var n=[t,e],i=this.invTransform;return i&&oe(n,n,i),n},kg.transformCoordToGlobal=function(t,e){var n=[t,e],i=this.transform;return i&&oe(n,n,i),n},Dg.getLocalTransform=function(t,e){e=e||[],Tg(e);var n=t.origin,i=t.scale||[1,1],r=t.rotation||0,o=t.position||[0,0];return n&&(e[4]-=n[0],e[5]-=n[1]),xe(e,e,i),r&&ye(e,e,r),n&&(e[4]+=n[0],e[5]+=n[1]),e[4]+=o[0],e[5]+=o[1],e};var Lg={linear:function(t){return t},quadraticIn:function(t){return t*t},quadraticOut:function(t){return t*(2-t)},quadraticInOut:function(t){return(t*=2)<1?.5*t*t:-.5*(--t*(t-2)-1)},cubicIn:function(t){return t*t*t},cubicOut:function(t){return--t*t*t+1},cubicInOut:function(t){return(t*=2)<1?.5*t*t*t:.5*((t-=2)*t*t+2)},quarticIn:function(t){return t*t*t*t},quarticOut:function(t){return 1- --t*t*t*t},quarticInOut:function(t){return(t*=2)<1?.5*t*t*t*t:-.5*((t-=2)*t*t*t-2)},quinticIn:function(t){return t*t*t*t*t},quinticOut:function(t){return--t*t*t*t*t+1},quinticInOut:function(t){return(t*=2)<1?.5*t*t*t*t*t:.5*((t-=2)*t*t*t*t+2)},sinusoidalIn:function(t){return 1-Math.cos(t*Math.PI/2)},sinusoidalOut:function(t){return Math.sin(t*Math.PI/2)},sinusoidalInOut:function(t){return.5*(1-Math.cos(Math.PI*t))},exponentialIn:function(t){return 0===t?0:Math.pow(1024,t-1)},exponentialOut:function(t){return 1===t?1:1-Math.pow(2,-10*t)},exponentialInOut:function(t){return 0===t?0:1===t?1:(t*=2)<1?.5*Math.pow(1024,t-1):.5*(-Math.pow(2,-10*(t-1))+2)},circularIn:function(t){return 1-Math.sqrt(1-t*t)},circularOut:function(t){return Math.sqrt(1- --t*t)},circularInOut:function(t){return(t*=2)<1?-.5*(Math.sqrt(1-t*t)-1):.5*(Math.sqrt(1-(t-=2)*t)+1)},elasticIn:function(t){var e,n=.1,i=.4;return 0===t?0:1===t?1:(!n||1>n?(n=1,e=i/4):e=i*Math.asin(1/n)/(2*Math.PI),-(n*Math.pow(2,10*(t-=1))*Math.sin(2*(t-e)*Math.PI/i)))},elasticOut:function(t){var e,n=.1,i=.4;return 0===t?0:1===t?1:(!n||1>n?(n=1,e=i/4):e=i*Math.asin(1/n)/(2*Math.PI),n*Math.pow(2,-10*t)*Math.sin(2*(t-e)*Math.PI/i)+1)},elasticInOut:function(t){var e,n=.1,i=.4;return 0===t?0:1===t?1:(!n||1>n?(n=1,e=i/4):e=i*Math.asin(1/n)/(2*Math.PI),(t*=2)<1?-.5*n*Math.pow(2,10*(t-=1))*Math.sin(2*(t-e)*Math.PI/i):n*Math.pow(2,-10*(t-=1))*Math.sin(2*(t-e)*Math.PI/i)*.5+1)},backIn:function(t){var e=1.70158;return t*t*((e+1)*t-e)},backOut:function(t){var e=1.70158;return--t*t*((e+1)*t+e)+1},backInOut:function(t){var e=2.5949095;return(t*=2)<1?.5*t*t*((e+1)*t-e):.5*((t-=2)*t*((e+1)*t+e)+2)},bounceIn:function(t){return 1-Lg.bounceOut(1-t)},bounceOut:function(t){return 1/2.75>t?7.5625*t*t:2/2.75>t?7.5625*(t-=1.5/2.75)*t+.75:2.5/2.75>t?7.5625*(t-=2.25/2.75)*t+.9375:7.5625*(t-=2.625/2.75)*t+.984375},bounceInOut:function(t){return.5>t?.5*Lg.bounceIn(2*t):.5*Lg.bounceOut(2*t-1)+.5}};Me.prototype={constructor:Me,step:function(t,e){if(this._initialized||(this._startTime=t+this._delay,this._initialized=!0),this._paused)return void(this._pausedTime+=e);var n=(t-this._startTime-this._pausedTime)/this._life;if(!(0>n)){n=Math.min(n,1);var i=this.easing,r="string"==typeof i?Lg[i]:i,o="function"==typeof r?r(n):n;return this.fire("frame",o),1==n?this.loop?(this.restart(t),"restart"):(this._needsRemove=!0,"destroy"):null}},restart:function(t){var e=(t-this._startTime-this._pausedTime)%this._life;this._startTime=t-e+this.gap,this._pausedTime=0,this._needsRemove=!1},fire:function(t,e){t="on"+t,this[t]&&this[t](this._target,e)},pause:function(){this._paused=!0},resume:function(){this._paused=!1}};var Og=function(){this.head=null,this.tail=null,this._len=0},Eg=Og.prototype;Eg.insert=function(t){var e=new Rg(t);return this.insertEntry(e),e},Eg.insertEntry=function(t){this.head?(this.tail.next=t,t.prev=this.tail,t.next=null,this.tail=t):this.head=this.tail=t,this._len++},Eg.remove=function(t){var e=t.prev,n=t.next;e?e.next=n:this.head=n,n?n.prev=e:this.tail=e,t.next=t.prev=null,this._len--},Eg.len=function(){return this._len},Eg.clear=function(){this.head=this.tail=null,this._len=0};var Rg=function(t){this.value=t,this.next,this.prev},zg=function(t){this._list=new Og,this._map={},this._maxSize=t||10,this._lastRemovedEntry=null},Bg=zg.prototype;Bg.put=function(t,e){var n=this._list,i=this._map,r=null;if(null==i[t]){var o=n.len(),a=this._lastRemovedEntry;if(o>=this._maxSize&&o>0){var s=n.head;n.remove(s),delete i[s.key],r=s.value,this._lastRemovedEntry=s}a?a.value=e:a=new Rg(e),a.key=t,n.insertEntry(a),i[t]=a}return r},Bg.get=function(t){var e=this._map[t],n=this._list;return null!=e?(e!==n.tail&&(n.remove(e),n.insertEntry(e)),e.value):void 0},Bg.clear=function(){this._list.clear(),this._map={}};var Ng={transparent:[0,0,0,0],aliceblue:[240,248,255,1],antiquewhite:[250,235,215,1],aqua:[0,255,255,1],aquamarine:[127,255,212,1],azure:[240,255,255,1],beige:[245,245,220,1],bisque:[255,228,196,1],black:[0,0,0,1],blanchedalmond:[255,235,205,1],blue:[0,0,255,1],blueviolet:[138,43,226,1],brown:[165,42,42,1],burlywood:[222,184,135,1],cadetblue:[95,158,160,1],chartreuse:[127,255,0,1],chocolate:[210,105,30,1],coral:[255,127,80,1],cornflowerblue:[100,149,237,1],cornsilk:[255,248,220,1],crimson:[220,20,60,1],cyan:[0,255,255,1],darkblue:[0,0,139,1],darkcyan:[0,139,139,1],darkgoldenrod:[184,134,11,1],darkgray:[169,169,169,1],darkgreen:[0,100,0,1],darkgrey:[169,169,169,1],darkkhaki:[189,183,107,1],darkmagenta:[139,0,139,1],darkolivegreen:[85,107,47,1],darkorange:[255,140,0,1],darkorchid:[153,50,204,1],darkred:[139,0,0,1],darksalmon:[233,150,122,1],darkseagreen:[143,188,143,1],darkslateblue:[72,61,139,1],darkslategray:[47,79,79,1],darkslategrey:[47,79,79,1],darkturquoise:[0,206,209,1],darkviolet:[148,0,211,1],deeppink:[255,20,147,1],deepskyblue:[0,191,255,1],dimgray:[105,105,105,1],dimgrey:[105,105,105,1],dodgerblue:[30,144,255,1],firebrick:[178,34,34,1],floralwhite:[255,250,240,1],forestgreen:[34,139,34,1],fuchsia:[255,0,255,1],gainsboro:[220,220,220,1],ghostwhite:[248,248,255,1],gold:[255,215,0,1],goldenrod:[218,165,32,1],gray:[128,128,128,1],green:[0,128,0,1],greenyellow:[173,255,47,1],grey:[128,128,128,1],honeydew:[240,255,240,1],hotpink:[255,105,180,1],indianred:[205,92,92,1],indigo:[75,0,130,1],ivory:[255,255,240,1],khaki:[240,230,140,1],lavender:[230,230,250,1],lavenderblush:[255,240,245,1],lawngreen:[124,252,0,1],lemonchiffon:[255,250,205,1],lightblue:[173,216,230,1],lightcoral:[240,128,128,1],lightcyan:[224,255,255,1],lightgoldenrodyellow:[250,250,210,1],lightgray:[211,211,211,1],lightgreen:[144,238,144,1],lightgrey:[211,211,211,1],lightpink:[255,182,193,1],lightsalmon:[255,160,122,1],lightseagreen:[32,178,170,1],lightskyblue:[135,206,250,1],lightslategray:[119,136,153,1],lightslategrey:[119,136,153,1],lightsteelblue:[176,196,222,1],lightyellow:[255,255,224,1],lime:[0,255,0,1],limegreen:[50,205,50,1],linen:[250,240,230,1],magenta:[255,0,255,1],maroon:[128,0,0,1],mediumaquamarine:[102,205,170,1],mediumblue:[0,0,205,1],mediumorchid:[186,85,211,1],mediumpurple:[147,112,219,1],mediumseagreen:[60,179,113,1],mediumslateblue:[123,104,238,1],mediumspringgreen:[0,250,154,1],mediumturquoise:[72,209,204,1],mediumvioletred:[199,21,133,1],midnightblue:[25,25,112,1],mintcream:[245,255,250,1],mistyrose:[255,228,225,1],moccasin:[255,228,181,1],navajowhite:[255,222,173,1],navy:[0,0,128,1],oldlace:[253,245,230,1],olive:[128,128,0,1],olivedrab:[107,142,35,1],orange:[255,165,0,1],orangered:[255,69,0,1],orchid:[218,112,214,1],palegoldenrod:[238,232,170,1],palegreen:[152,251,152,1],paleturquoise:[175,238,238,1],palevioletred:[219,112,147,1],papayawhip:[255,239,213,1],peachpuff:[255,218,185,1],peru:[205,133,63,1],pink:[255,192,203,1],plum:[221,160,221,1],powderblue:[176,224,230,1],purple:[128,0,128,1],red:[255,0,0,1],rosybrown:[188,143,143,1],royalblue:[65,105,225,1],saddlebrown:[139,69,19,1],salmon:[250,128,114,1],sandybrown:[244,164,96,1],seagreen:[46,139,87,1],seashell:[255,245,238,1],sienna:[160,82,45,1],silver:[192,192,192,1],skyblue:[135,206,235,1],slateblue:[106,90,205,1],slategray:[112,128,144,1],slategrey:[112,128,144,1],snow:[255,250,250,1],springgreen:[0,255,127,1],steelblue:[70,130,180,1],tan:[210,180,140,1],teal:[0,128,128,1],thistle:[216,191,216,1],tomato:[255,99,71,1],turquoise:[64,224,208,1],violet:[238,130,238,1],wheat:[245,222,179,1],white:[255,255,255,1],whitesmoke:[245,245,245,1],yellow:[255,255,0,1],yellowgreen:[154,205,50,1]},Vg=new zg(20),Fg=null,Hg=Ve,Wg=Fe,Gg=(Object.freeze||Object)({parse:Ee,lift:Be,toHex:Ne,fastLerp:Ve,fastMapToColor:Hg,lerp:Fe,mapToColor:Wg,modifyHSL:He,modifyAlpha:We,stringify:Ge}),Ug=Array.prototype.slice,Zg=function(t,e,n,i){this._tracks={},this._target=t,this._loop=e||!1,this._getter=n||Ue,this._setter=i||Ze,this._clipCount=0,this._delay=0,this._doneList=[],this._onframeList=[],this._clipList=[]};Zg.prototype={when:function(t,e){var n=this._tracks;for(var i in e)if(e.hasOwnProperty(i)){if(!n[i]){n[i]=[];var r=this._getter(this._target,i);if(null==r)continue;0!==t&&n[i].push({time:0,value:Je(r)})}n[i].push({time:t,value:e[i]})}return this},during:function(t){return this._onframeList.push(t),this},pause:function(){for(var t=0;t<this._clipList.length;t++)this._clipList[t].pause();this._paused=!0},resume:function(){for(var t=0;t<this._clipList.length;t++)this._clipList[t].resume();this._paused=!1},isPaused:function(){return!!this._paused},_doneCallback:function(){this._tracks={},this._clipList.length=0;for(var t=this._doneList,e=t.length,n=0;e>n;n++)t[n].call(this)},start:function(t,e){var n,i=this,r=0,o=function(){r--,r||i._doneCallback()};for(var a in this._tracks)if(this._tracks.hasOwnProperty(a)){var s=nn(this,t,o,this._tracks[a],a,e);s&&(this._clipList.push(s),r++,this.animation&&this.animation.addClip(s),n=s)}if(n){var l=n.onframe;n.onframe=function(t,e){l(t,e);for(var n=0;n<i._onframeList.length;n++)i._onframeList[n](t,e)}}return r||this._doneCallback(),this},stop:function(t){for(var e=this._clipList,n=this.animation,i=0;i<e.length;i++){var r=e[i];t&&r.onframe(this._target,1),n&&n.removeClip(r)}e.length=0},delay:function(t){return this._delay=t,this},done:function(t){return t&&this._doneList.push(t),this},getClips:function(){return this._clipList}};var jg=1;"undefined"!=typeof window&&(jg=Math.max(window.devicePixelRatio||1,1));var Xg=0,Yg=jg,qg=function(){};1===Xg?qg=function(){for(var t in arguments)throw new Error(arguments[t])}:Xg>1&&(qg=function(){for(var t in arguments)console.log(arguments[t])});var $g=qg,Kg=function(){this.animators=[]};Kg.prototype={constructor:Kg,animate:function(t,e){var n,i=!1,r=this,o=this.__zr;if(t){var a=t.split("."),s=r;i="shape"===a[0];for(var l=0,h=a.length;h>l;l++)s&&(s=s[a[l]]);s&&(n=s)}else n=r;if(!n)return void $g('Property "'+t+'" is not existed in element '+r.id);var c=r.animators,d=new Zg(n,e);return d.during(function(){r.dirty(i)}).done(function(){c.splice(u(c,d),1)}),c.push(d),o&&o.animation.addAnimator(d),d},stopAnimation:function(t){for(var e=this.animators,n=e.length,i=0;n>i;i++)e[i].stop(t);return e.length=0,this},animateTo:function(t,e,n,i,r,o){function a(){l--,l||r&&r()}b(n)?(r=i,i=n,n=0):w(i)?(r=i,i="linear",n=0):w(n)?(r=n,n=0):w(e)?(r=e,e=500):e||(e=500),this.stopAnimation(),this._animateToShallow("",this,t,e,n);var s=this.animators.slice(),l=s.length;l||r&&r();for(var u=0;u<s.length;u++)s[u].done(a).start(i,o)},_animateToShallow:function(t,e,n,i,r){var o={},a=0;for(var s in n)if(n.hasOwnProperty(s))if(null!=e[s])M(n[s])&&!d(n[s])?this._animateToShallow(t?t+"."+s:s,e[s],n[s],i,r):(o[s]=n[s],a++);else if(null!=n[s])if(t){var l={};l[t]={},l[t][s]=n[s],this.attr(l)}else this.attr(s,n[s]);return a>0&&this.animate(t,!1).when(null==i?500:i,o).delay(r||0),this}};var Qg=function(t){Dg.call(this,t),wg.call(this,t),Kg.call(this,t),this.id=t.id||Kp()};Qg.prototype={type:"element",name:"",__zr:null,ignore:!1,clipPath:null,isGroup:!1,drift:function(t,e){switch(this.draggable){case"horizontal":e=0;break;case"vertical":t=0}var n=this.transform;n||(n=this.transform=[1,0,0,1,0,0]),n[4]+=t,n[5]+=e,this.decomposeTransform(),this.dirty(!1)},beforeUpdate:function(){},afterUpdate:function(){},update:function(){this.updateTransform()},traverse:function(){},attrKV:function(t,e){if("position"===t||"scale"===t||"origin"===t){if(e){var n=this[t];n||(n=this[t]=[]),n[0]=e[0],n[1]=e[1]}}else this[t]=e},hide:function(){this.ignore=!0,this.__zr&&this.__zr.refresh()},show:function(){this.ignore=!1,this.__zr&&this.__zr.refresh()},attr:function(t,e){if("string"==typeof t)this.attrKV(t,e);else if(M(t))for(var n in t)t.hasOwnProperty(n)&&this.attrKV(n,t[n]);return this.dirty(!1),this},setClipPath:function(t){var e=this.__zr;e&&t.addSelfToZr(e),this.clipPath&&this.clipPath!==t&&this.removeClipPath(),this.clipPath=t,t.__zr=e,t.__clipTarget=this,this.dirty(!1)},removeClipPath:function(){var t=this.clipPath;t&&(t.__zr&&t.removeSelfFromZr(t.__zr),t.__zr=null,t.__clipTarget=null,this.clipPath=null,this.dirty(!1))},addSelfToZr:function(t){this.__zr=t;var e=this.animators;if(e)for(var n=0;n<e.length;n++)t.animation.addAnimator(e[n]);this.clipPath&&this.clipPath.addSelfToZr(t)},removeSelfFromZr:function(t){this.__zr=null;var e=this.animators;if(e)for(var n=0;n<e.length;n++)t.animation.removeAnimator(e[n]);this.clipPath&&this.clipPath.removeSelfFromZr(t)}},c(Qg,Kg),c(Qg,Dg),c(Qg,wg);var Jg=oe,tv=Math.min,ev=Math.max;rn.prototype={constructor:rn,union:function(t){var e=tv(t.x,this.x),n=tv(t.y,this.y);this.width=ev(t.x+t.width,this.x+this.width)-e,this.height=ev(t.y+t.height,this.y+this.height)-n,this.x=e,this.y=n},applyTransform:function(){var t=[],e=[],n=[],i=[];return function(r){if(r){t[0]=n[0]=this.x,t[1]=i[1]=this.y,e[0]=i[0]=this.x+this.width,e[1]=n[1]=this.y+this.height,Jg(t,t,r),Jg(e,e,r),Jg(n,n,r),Jg(i,i,r),this.x=tv(t[0],e[0],n[0],i[0]),this.y=tv(t[1],e[1],n[1],i[1]);var o=ev(t[0],e[0],n[0],i[0]),a=ev(t[1],e[1],n[1],i[1]);this.width=o-this.x,this.height=a-this.y}}}(),calculateTransform:function(t){var e=this,n=t.width/e.width,i=t.height/e.height,r=fe();return me(r,r,[-e.x,-e.y]),xe(r,r,[n,i]),me(r,r,[t.x,t.y]),r},intersect:function(t){if(!t)return!1;t instanceof rn||(t=rn.create(t));var e=this,n=e.x,i=e.x+e.width,r=e.y,o=e.y+e.height,a=t.x,s=t.x+t.width,l=t.y,u=t.y+t.height;return!(a>i||n>s||l>o||r>u)},contain:function(t,e){var n=this;return t>=n.x&&t<=n.x+n.width&&e>=n.y&&e<=n.y+n.height},clone:function(){return new rn(this.x,this.y,this.width,this.height)},copy:function(t){this.x=t.x,this.y=t.y,this.width=t.width,this.height=t.height},plain:function(){return{x:this.x,y:this.y,width:this.width,height:this.height}}},rn.create=function(t){return new rn(t.x,t.y,t.width,t.height)};var nv=function(t){t=t||{},Qg.call(this,t);for(var e in t)t.hasOwnProperty(e)&&(this[e]=t[e]);this._children=[],this.__storage=null,this.__dirty=!0};nv.prototype={constructor:nv,isGroup:!0,type:"group",silent:!1,children:function(){return this._children.slice()},childAt:function(t){return this._children[t]},childOfName:function(t){for(var e=this._children,n=0;n<e.length;n++)if(e[n].name===t)return e[n]},childCount:function(){return this._children.length},add:function(t){return t&&t!==this&&t.parent!==this&&(this._children.push(t),this._doAdd(t)),this},addBefore:function(t,e){if(t&&t!==this&&t.parent!==this&&e&&e.parent===this){var n=this._children,i=n.indexOf(e);i>=0&&(n.splice(i,0,t),this._doAdd(t))}return this},_doAdd:function(t){t.parent&&t.parent.remove(t),t.parent=this;var e=this.__storage,n=this.__zr;e&&e!==t.__storage&&(e.addToStorage(t),t instanceof nv&&t.addChildrenToStorage(e)),n&&n.refresh()},remove:function(t){var e=this.__zr,n=this.__storage,i=this._children,r=u(i,t);return 0>r?this:(i.splice(r,1),t.parent=null,n&&(n.delFromStorage(t),t instanceof nv&&t.delChildrenFromStorage(n)),e&&e.refresh(),this)},removeAll:function(){var t,e,n=this._children,i=this.__storage;for(e=0;e<n.length;e++)t=n[e],i&&(i.delFromStorage(t),t instanceof nv&&t.delChildrenFromStorage(i)),t.parent=null;return n.length=0,this},eachChild:function(t,e){for(var n=this._children,i=0;i<n.length;i++){var r=n[i];t.call(e,r,i)}return this},traverse:function(t,e){for(var n=0;n<this._children.length;n++){var i=this._children[n];t.call(e,i),"group"===i.type&&i.traverse(t,e)}return this},addChildrenToStorage:function(t){for(var e=0;e<this._children.length;e++){var n=this._children[e];t.addToStorage(n),n instanceof nv&&n.addChildrenToStorage(t)}},delChildrenFromStorage:function(t){for(var e=0;e<this._children.length;e++){var n=this._children[e];t.delFromStorage(n),n instanceof nv&&n.delChildrenFromStorage(t)}},dirty:function(){return this.__dirty=!0,this.__zr&&this.__zr.refresh(),this},getBoundingRect:function(t){for(var e=null,n=new rn(0,0,0,0),i=t||this._children,r=[],o=0;o<i.length;o++){var a=i[o];if(!a.ignore&&!a.invisible){var s=a.getBoundingRect(),l=a.getLocalTransform(r);l?(n.copy(s),n.applyTransform(l),e=e||n.clone(),e.union(n)):(e=e||s.clone(),e.union(s))}}return e||n}},h(nv,Qg);var iv=32,rv=7,ov=function(){this._roots=[],this._displayList=[],this._displayListLen=0};ov.prototype={constructor:ov,traverse:function(t,e){for(var n=0;n<this._roots.length;n++)this._roots[n].traverse(t,e)},getDisplayList:function(t,e){return e=e||!1,t&&this.updateDisplayList(e),this._displayList},updateDisplayList:function(t){this._displayListLen=0;for(var e=this._roots,n=this._displayList,i=0,r=e.length;r>i;i++)this._updateAndAddDisplayable(e[i],null,t);n.length=this._displayListLen,Jp.canvasSupported&&dn(n,fn)},_updateAndAddDisplayable:function(t,e,n){if(!t.ignore||n){t.beforeUpdate(),t.__dirty&&t.update(),t.afterUpdate();var i=t.clipPath;if(i){e=e?e.slice():[];for(var r=i,o=t;r;)r.parent=o,r.updateTransform(),e.push(r),o=r,r=r.clipPath}if(t.isGroup){for(var a=t._children,s=0;s<a.length;s++){var l=a[s];t.__dirty&&(l.__dirty=!0),this._updateAndAddDisplayable(l,e,n)}t.__dirty=!1}else t.__clipPaths=e,this._displayList[this._displayListLen++]=t}},addRoot:function(t){t.__storage!==this&&(t instanceof nv&&t.addChildrenToStorage(this),this.addToStorage(t),this._roots.push(t))},delRoot:function(t){if(null==t){for(var e=0;e<this._roots.length;e++){var n=this._roots[e];n instanceof nv&&n.delChildrenFromStorage(this)}return this._roots=[],this._displayList=[],void(this._displayListLen=0)}if(t instanceof Array)for(var e=0,i=t.length;i>e;e++)this.delRoot(t[e]);else{var r=u(this._roots,t);r>=0&&(this.delFromStorage(t),this._roots.splice(r,1),t instanceof nv&&t.delChildrenFromStorage(this))}},addToStorage:function(t){return t&&(t.__storage=this,t.dirty(!1)),this},delFromStorage:function(t){return t&&(t.__storage=null),this},dispose:function(){this._renderList=this._roots=null},displayableSortFunc:fn};var av={shadowBlur:1,shadowOffsetX:1,shadowOffsetY:1,textShadowBlur:1,textShadowOffsetX:1,textShadowOffsetY:1,textBoxShadowBlur:1,textBoxShadowOffsetX:1,textBoxShadowOffsetY:1},sv=function(t,e,n){return av.hasOwnProperty(e)?n*=t.dpr:n},lv=[["shadowBlur",0],["shadowOffsetX",0],["shadowOffsetY",0],["shadowColor","#000"],["lineCap","butt"],["lineJoin","miter"],["miterLimit",10]],uv=function(t,e){this.extendFrom(t,!1),this.host=e};uv.prototype={constructor:uv,host:null,fill:"#000",stroke:null,opacity:1,lineDash:null,lineDashOffset:0,shadowBlur:0,shadowOffsetX:0,shadowOffsetY:0,lineWidth:1,strokeNoScale:!1,text:null,font:null,textFont:null,fontStyle:null,fontWeight:null,fontSize:null,fontFamily:null,textTag:null,textFill:"#000",textStroke:null,textWidth:null,textHeight:null,textStrokeWidth:0,textLineHeight:null,textPosition:"inside",textRect:null,textOffset:null,textAlign:null,textVerticalAlign:null,textDistance:5,textShadowColor:"transparent",textShadowBlur:0,textShadowOffsetX:0,textShadowOffsetY:0,textBoxShadowColor:"transparent",textBoxShadowBlur:0,textBoxShadowOffsetX:0,textBoxShadowOffsetY:0,transformText:!1,textRotation:0,textOrigin:null,textBackgroundColor:null,textBorderColor:null,textBorderWidth:0,textBorderRadius:0,textPadding:null,rich:null,truncate:null,blend:null,bind:function(t,e,n){for(var i=this,r=n&&n.style,o=!r,a=0;a<lv.length;a++){var s=lv[a],l=s[0];(o||i[l]!==r[l])&&(t[l]=sv(t,l,i[l]||s[1]))}if((o||i.fill!==r.fill)&&(t.fillStyle=i.fill),(o||i.stroke!==r.stroke)&&(t.strokeStyle=i.stroke),(o||i.opacity!==r.opacity)&&(t.globalAlpha=null==i.opacity?1:i.opacity),(o||i.blend!==r.blend)&&(t.globalCompositeOperation=i.blend||"source-over"),this.hasStroke()){var u=i.lineWidth;t.lineWidth=u/(this.strokeNoScale&&e&&e.getLineScale?e.getLineScale():1)}},hasFill:function(){var t=this.fill;return null!=t&&"none"!==t},hasStroke:function(){var t=this.stroke;return null!=t&&"none"!==t&&this.lineWidth>0},extendFrom:function(t,e){if(t)for(var n in t)!t.hasOwnProperty(n)||e!==!0&&(e===!1?this.hasOwnProperty(n):null==t[n])||(this[n]=t[n])},set:function(t,e){"string"==typeof t?this[t]=e:this.extendFrom(t,!0)},clone:function(){var t=new this.constructor;return t.extendFrom(this,!0),t},getGradient:function(t,e,n){for(var i="radial"===e.type?gn:pn,r=i(t,e,n),o=e.colorStops,a=0;a<o.length;a++)r.addColorStop(o[a].offset,o[a].color);return r}};for(var hv=uv.prototype,cv=0;cv<lv.length;cv++){var dv=lv[cv];dv[0]in hv||(hv[dv[0]]=dv[1])}uv.getGradient=hv.getGradient;var fv=function(t,e){this.image=t,this.repeat=e,this.type="pattern"};fv.prototype.getCanvasPattern=function(t){return t.createPattern(this.image,this.repeat||"repeat")};var pv=function(t,e,n){var i;n=n||Yg,"string"==typeof t?i=mn(t,e,n):M(t)&&(i=t,t=i.id),this.id=t,this.dom=i;var r=i.style;r&&(i.onselectstart=vn,r["-webkit-user-select"]="none",r["user-select"]="none",r["-webkit-touch-callout"]="none",r["-webkit-tap-highlight-color"]="rgba(0,0,0,0)",r.padding=0,r.margin=0,r["border-width"]=0),this.domBack=null,this.ctxBack=null,this.painter=e,this.config=null,this.clearColor=0,this.motionBlur=!1,this.lastFrameAlpha=.7,this.dpr=n};pv.prototype={constructor:pv,__dirty:!0,__used:!1,__drawIndex:0,__startIndex:0,__endIndex:0,incremental:!1,getElementCount:function(){return this.__endIndex-this.__startIndex},initContext:function(){this.ctx=this.dom.getContext("2d"),this.ctx.dpr=this.dpr},createBackBuffer:function(){var t=this.dpr;this.domBack=mn("back-"+this.id,this.painter,t),this.ctxBack=this.domBack.getContext("2d"),1!=t&&this.ctxBack.scale(t,t)},resize:function(t,e){var n=this.dpr,i=this.dom,r=i.style,o=this.domBack;r&&(r.width=t+"px",r.height=e+"px"),i.width=t*n,i.height=e*n,o&&(o.width=t*n,o.height=e*n,1!=n&&this.ctxBack.scale(n,n))},clear:function(t,e){var n=this.dom,i=this.ctx,r=n.width,o=n.height,e=e||this.clearColor,a=this.motionBlur&&!t,s=this.lastFrameAlpha,l=this.dpr;if(a&&(this.domBack||this.createBackBuffer(),this.ctxBack.globalCompositeOperation="copy",this.ctxBack.drawImage(n,0,0,r/l,o/l)),i.clearRect(0,0,r,o),e&&"transparent"!==e){var u;e.colorStops?(u=e.__canvasGradient||uv.getGradient(i,e,{x:0,y:0,width:r,height:o}),e.__canvasGradient=u):e.image&&(u=fv.prototype.getCanvasPattern.call(e,i)),i.save(),i.fillStyle=u||e,i.fillRect(0,0,r,o),i.restore()}if(a){var h=this.domBack;i.save(),i.globalAlpha=s,i.drawImage(h,0,0,r,o),i.restore()}}};var gv="undefined"!=typeof window&&(window.requestAnimationFrame&&window.requestAnimationFrame.bind(window)||window.msRequestAnimationFrame&&window.msRequestAnimationFrame.bind(window)||window.mozRequestAnimationFrame||window.webkitRequestAnimationFrame)||function(t){setTimeout(t,16)},vv=new zg(50),mv={},yv=0,xv=5e3,_v=/\{([a-zA-Z0-9_]+)\|([^}]*)\}/g,wv="12px sans-serif",bv={};bv.measureText=function(t,e){var n=l();return n.font=e||wv,n.measureText(t)};var Mv={left:1,right:1,center:1},Sv={top:1,bottom:1,middle:1},Iv=new rn,Cv=function(){};Cv.prototype={constructor:Cv,drawRectText:function(t,e){var n=this.style;e=n.textRect||e,this.__dirty&&Hn(n,!0);var i=n.text;if(null!=i&&(i+=""),ri(i,n)){t.save();var r=this.transform;n.transformText?this.setTransform(t):r&&(Iv.copy(e),Iv.applyTransform(r),e=Iv),Gn(this,t,i,n,e),t.restore()}}},oi.prototype={constructor:oi,type:"displayable",__dirty:!0,invisible:!1,z:0,z2:0,zlevel:0,draggable:!1,dragging:!1,silent:!1,culling:!1,cursor:"pointer",rectHover:!1,progressive:!1,incremental:!1,inplace:!1,beforeBrush:function(){},afterBrush:function(){},brush:function(){},getBoundingRect:function(){},contain:function(t,e){return this.rectContain(t,e)},traverse:function(t,e){t.call(e,this)},rectContain:function(t,e){var n=this.transformCoordToLocal(t,e),i=this.getBoundingRect();return i.contain(n[0],n[1])},dirty:function(){this.__dirty=!0,this._rect=null,this.__zr&&this.__zr.refresh()},animateStyle:function(t){return this.animate("style",t)},attrKV:function(t,e){"style"!==t?Qg.prototype.attrKV.call(this,t,e):this.style.set(e)},setStyle:function(t,e){return this.style.set(t,e),this.dirty(!1),this},useStyle:function(t){return this.style=new uv(t,this),this.dirty(!1),this}},h(oi,Qg),c(oi,Cv),ai.prototype={constructor:ai,type:"image",brush:function(t,e){var n=this.style,i=n.image;n.bind(t,this,e);var r=this._image=xn(i,this._image,this,this.onload);if(r&&wn(r)){var o=n.x||0,a=n.y||0,s=n.width,l=n.height,u=r.width/r.height;if(null==s&&null!=l?s=l*u:null==l&&null!=s?l=s/u:null==s&&null==l&&(s=r.width,l=r.height),this.setTransform(t),n.sWidth&&n.sHeight){var h=n.sx||0,c=n.sy||0;t.drawImage(r,h,c,n.sWidth,n.sHeight,o,a,s,l)}else if(n.sx&&n.sy){var h=n.sx,c=n.sy,d=s-h,f=l-c;t.drawImage(r,h,c,d,f,o,a,s,l)}else t.drawImage(r,o,a,s,l);null!=n.text&&(this.restoreTransform(t),this.drawRectText(t,this.getBoundingRect()))}},getBoundingRect:function(){var t=this.style;return this._rect||(this._rect=new rn(t.x||0,t.y||0,t.width||0,t.height||0)),this._rect}},h(ai,oi);var Tv=1e5,Av=314159,Dv=.01,kv=.001,Pv=new rn(0,0,0,0),Lv=new rn(0,0,0,0),Ov=function(t,e,n){this.type="canvas";var i=!t.nodeName||"CANVAS"===t.nodeName.toUpperCase();this._opts=n=a({},n||{}),this.dpr=n.devicePixelRatio||Yg,this._singleCanvas=i,this.root=t;var r=t.style;r&&(r["-webkit-tap-highlight-color"]="transparent",r["-webkit-user-select"]=r["user-select"]=r["-webkit-touch-callout"]="none",t.innerHTML=""),this.storage=e;var o=this._zlevelList=[],s=this._layers={};if(this._layerConfig={},this._needsManuallyCompositing=!1,i){var l=t.width,u=t.height;null!=n.width&&(l=n.width),null!=n.height&&(u=n.height),this.dpr=n.devicePixelRatio||1,t.width=l*this.dpr,t.height=u*this.dpr,this._width=l,this._height=u;var h=new pv(t,this,this.dpr);h.__builtin__=!0,h.initContext(),s[Av]=h,h.zlevel=Av,o.push(Av),this._domRoot=t}else{this._width=this._getSize(0),this._height=this._getSize(1);var c=this._domRoot=di(this._width,this._height);t.appendChild(c)}this._hoverlayer=null,this._hoverElements=[]};Ov.prototype={constructor:Ov,getType:function(){return"canvas"},isSingleCanvas:function(){return this._singleCanvas},getViewportRoot:function(){return this._domRoot},getViewportRootOffset:function(){var t=this.getViewportRoot();return t?{offsetLeft:t.offsetLeft||0,offsetTop:t.offsetTop||0}:void 0},refresh:function(t){var e=this.storage.getDisplayList(!0),n=this._zlevelList;this._redrawId=Math.random(),this._paintList(e,t,this._redrawId);for(var i=0;i<n.length;i++){var r=n[i],o=this._layers[r];if(!o.__builtin__&&o.refresh){var a=0===i?this._backgroundColor:null;o.refresh(a)}}return this.refreshHover(),this},addHover:function(t,e){if(!t.__hoverMir){var n=new t.constructor({style:t.style,shape:t.shape});n.__from=t,t.__hoverMir=n,n.setStyle(e),this._hoverElements.push(n)}},removeHover:function(t){var e=t.__hoverMir,n=this._hoverElements,i=u(n,e);i>=0&&n.splice(i,1),t.__hoverMir=null},clearHover:function(){for(var t=this._hoverElements,e=0;e<t.length;e++){var n=t[e].__from;n&&(n.__hoverMir=null)}t.length=0},refreshHover:function(){var t=this._hoverElements,e=t.length,n=this._hoverlayer;if(n&&n.clear(),e){dn(t,this.storage.displayableSortFunc),n||(n=this._hoverlayer=this.getLayer(Tv));var i={};n.ctx.save();for(var r=0;e>r;){var o=t[r],a=o.__from;a&&a.__zr?(r++,a.invisible||(o.transform=a.transform,o.invTransform=a.invTransform,o.__clipPaths=a.__clipPaths,this._doPaintEl(o,n,!0,i))):(t.splice(r,1),a.__hoverMir=null,e--)}n.ctx.restore()}},getHoverLayer:function(){return this.getLayer(Tv)},_paintList:function(t,e,n){if(this._redrawId===n){e=e||!1,this._updateLayerStatus(t);var i=this._doPaintList(t,e);if(this._needsManuallyCompositing&&this._compositeManually(),!i){var r=this;gv(function(){r._paintList(t,e,n)})}}},_compositeManually:function(){var t=this.getLayer(Av).ctx,e=this._domRoot.width,n=this._domRoot.height;t.clearRect(0,0,e,n),this.eachBuiltinLayer(function(i){i.virtual&&t.drawImage(i.dom,0,0,e,n)})},_doPaintList:function(t,e){for(var n=[],i=0;i<this._zlevelList.length;i++){var r=this._zlevelList[i],o=this._layers[r];o.__builtin__&&o!==this._hoverlayer&&(o.__dirty||e)&&n.push(o)}for(var a=!0,s=0;s<n.length;s++){var o=n[s],l=o.ctx,u={};l.save();var h=e?o.__startIndex:o.__drawIndex,c=!e&&o.incremental&&Date.now,d=c&&Date.now(),p=o.zlevel===this._zlevelList[0]?this._backgroundColor:null;if(o.__startIndex===o.__endIndex)o.clear(!1,p);else if(h===o.__startIndex){var g=t[h];g.incremental&&g.notClear&&!e||o.clear(!1,p)}-1===h&&(console.error("For some unknown reason. drawIndex is -1"),h=o.__startIndex);for(var v=h;v<o.__endIndex;v++){var m=t[v];if(this._doPaintEl(m,o,e,u),m.__dirty=!1,c){var y=Date.now()-d;if(y>15)break}}o.__drawIndex=v,o.__drawIndex<o.__endIndex&&(a=!1),u.prevElClipPaths&&l.restore(),l.restore()}return Jp.wxa&&f(this._layers,function(t){t&&t.ctx&&t.ctx.draw&&t.ctx.draw()}),a},_doPaintEl:function(t,e,n,i){var r=e.ctx,o=t.transform;if(!(!e.__dirty&&!n||t.invisible||0===t.style.opacity||o&&!o[0]&&!o[3]||t.culling&&ui(t,this._width,this._height))){var a=t.__clipPaths;(!i.prevElClipPaths||hi(a,i.prevElClipPaths))&&(i.prevElClipPaths&&(e.ctx.restore(),i.prevElClipPaths=null,i.prevEl=null),a&&(r.save(),ci(a,r),i.prevElClipPaths=a)),t.beforeBrush&&t.beforeBrush(r),t.brush(r,i.prevEl||null),i.prevEl=t,t.afterBrush&&t.afterBrush(r)}},getLayer:function(t,e){this._singleCanvas&&!this._needsManuallyCompositing&&(t=Av);var n=this._layers[t];return n||(n=new pv("zr_"+t,this,this.dpr),n.zlevel=t,n.__builtin__=!0,this._layerConfig[t]&&r(n,this._layerConfig[t],!0),e&&(n.virtual=e),this.insertLayer(t,n),n.initContext()),n},insertLayer:function(t,e){var n=this._layers,i=this._zlevelList,r=i.length,o=null,a=-1,s=this._domRoot;if(n[t])return void $g("ZLevel "+t+" has been used already");if(!li(e))return void $g("Layer of zlevel "+t+" is not valid");if(r>0&&t>i[0]){for(a=0;r-1>a&&!(i[a]<t&&i[a+1]>t);a++);o=n[i[a]]}if(i.splice(a+1,0,t),n[t]=e,!e.virtual)if(o){var l=o.dom;l.nextSibling?s.insertBefore(e.dom,l.nextSibling):s.appendChild(e.dom)}else s.firstChild?s.insertBefore(e.dom,s.firstChild):s.appendChild(e.dom)},eachLayer:function(t,e){var n,i,r=this._zlevelList;for(i=0;i<r.length;i++)n=r[i],t.call(e,this._layers[n],n)},eachBuiltinLayer:function(t,e){var n,i,r,o=this._zlevelList;for(r=0;r<o.length;r++)i=o[r],n=this._layers[i],n.__builtin__&&t.call(e,n,i)},eachOtherLayer:function(t,e){var n,i,r,o=this._zlevelList;for(r=0;r<o.length;r++)i=o[r],n=this._layers[i],n.__builtin__||t.call(e,n,i)},getLayers:function(){return this._layers},_updateLayerStatus:function(t){function e(t){r&&(r.__endIndex!==t&&(r.__dirty=!0),r.__endIndex=t)}if(this.eachBuiltinLayer(function(t){t.__dirty=t.__used=!1}),this._singleCanvas)for(var n=1;n<t.length;n++){var i=t[n];if(i.zlevel!==t[n-1].zlevel||i.incremental){this._needsManuallyCompositing=!0;
+break}}for(var r=null,o=0,n=0;n<t.length;n++){var a,i=t[n],s=i.zlevel;i.incremental?(a=this.getLayer(s+kv,this._needsManuallyCompositing),a.incremental=!0,o=1):a=this.getLayer(s+(o>0?Dv:0),this._needsManuallyCompositing),a.__builtin__||$g("ZLevel "+s+" has been used by unkown layer "+a.id),a!==r&&(a.__used=!0,a.__startIndex!==n&&(a.__dirty=!0),a.__startIndex=n,a.__drawIndex=a.incremental?-1:n,e(n),r=a),i.__dirty&&(a.__dirty=!0,a.incremental&&a.__drawIndex<0&&(a.__drawIndex=n))}e(n),this.eachBuiltinLayer(function(t){!t.__used&&t.getElementCount()>0&&(t.__dirty=!0,t.__startIndex=t.__endIndex=t.__drawIndex=0),t.__dirty&&t.__drawIndex<0&&(t.__drawIndex=t.__startIndex)})},clear:function(){return this.eachBuiltinLayer(this._clearLayer),this},_clearLayer:function(t){t.clear()},setBackgroundColor:function(t){this._backgroundColor=t},configLayer:function(t,e){if(e){var n=this._layerConfig;n[t]?r(n[t],e,!0):n[t]=e;for(var i=0;i<this._zlevelList.length;i++){var o=this._zlevelList[i];if(o===t||o===t+Dv){var a=this._layers[o];r(a,n[t],!0)}}}},delLayer:function(t){var e=this._layers,n=this._zlevelList,i=e[t];i&&(i.dom.parentNode.removeChild(i.dom),delete e[t],n.splice(u(n,t),1))},resize:function(t,e){if(this._domRoot.style){var n=this._domRoot;n.style.display="none";var i=this._opts;if(null!=t&&(i.width=t),null!=e&&(i.height=e),t=this._getSize(0),e=this._getSize(1),n.style.display="",this._width!=t||e!=this._height){n.style.width=t+"px",n.style.height=e+"px";for(var r in this._layers)this._layers.hasOwnProperty(r)&&this._layers[r].resize(t,e);f(this._progressiveLayers,function(n){n.resize(t,e)}),this.refresh(!0)}this._width=t,this._height=e}else{if(null==t||null==e)return;this._width=t,this._height=e,this.getLayer(Av).resize(t,e)}return this},clearLayer:function(t){var e=this._layers[t];e&&e.clear()},dispose:function(){this.root.innerHTML="",this.root=this.storage=this._domRoot=this._layers=null},getRenderedCanvas:function(t){if(t=t||{},this._singleCanvas&&!this._compositeManually)return this._layers[Av].dom;var e=new pv("image",this,t.pixelRatio||this.dpr);if(e.initContext(),e.clear(!1,t.backgroundColor||this._backgroundColor),t.pixelRatio<=this.dpr){this.refresh();var n=e.dom.width,i=e.dom.height,r=e.ctx;this.eachLayer(function(t){t.__builtin__?r.drawImage(t.dom,0,0,n,i):t.renderToCanvas&&(e.ctx.save(),t.renderToCanvas(e.ctx),e.ctx.restore())})}else for(var o={},a=this.storage.getDisplayList(!0),s=0;s<a.length;s++){var l=a[s];this._doPaintEl(l,e,!0,o)}return e.dom},getWidth:function(){return this._width},getHeight:function(){return this._height},_getSize:function(t){var e=this._opts,n=["width","height"][t],i=["clientWidth","clientHeight"][t],r=["paddingLeft","paddingTop"][t],o=["paddingRight","paddingBottom"][t];if(null!=e[n]&&"auto"!==e[n])return parseFloat(e[n]);var a=this.root,s=document.defaultView.getComputedStyle(a);return(a[i]||si(s[n])||si(a.style[n]))-(si(s[r])||0)-(si(s[o])||0)|0},pathToImage:function(t,e){e=e||this.dpr;var n=document.createElement("canvas"),i=n.getContext("2d"),r=t.getBoundingRect(),o=t.style,a=o.shadowBlur*e,s=o.shadowOffsetX*e,l=o.shadowOffsetY*e,u=o.hasStroke()?o.lineWidth:0,h=Math.max(u/2,-s+a),c=Math.max(u/2,s+a),d=Math.max(u/2,-l+a),f=Math.max(u/2,l+a),p=r.width+h+c,g=r.height+d+f;n.width=p*e,n.height=g*e,i.scale(e,e),i.clearRect(0,0,p,g),i.dpr=e;var v={position:t.position,rotation:t.rotation,scale:t.scale};t.position=[h-r.x,d-r.y],t.rotation=0,t.scale=[1,1],t.updateTransform(),t&&t.brush(i);var m=ai,y=new m({style:{x:0,y:0,image:n}});return null!=v.position&&(y.position=t.position=v.position),null!=v.rotation&&(y.rotation=t.rotation=v.rotation),null!=v.scale&&(y.scale=t.scale=v.scale),y}};var Ev="undefined"!=typeof window&&!!window.addEventListener,Rv=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,zv=Ev?function(t){t.preventDefault(),t.stopPropagation(),t.cancelBubble=!0}:function(t){t.returnValue=!1,t.cancelBubble=!0},Bv=function(t){t=t||{},this.stage=t.stage||{},this.onframe=t.onframe||function(){},this._clips=[],this._running=!1,this._time,this._pausedTime,this._pauseStart,this._paused=!1,wg.call(this)};Bv.prototype={constructor:Bv,addClip:function(t){this._clips.push(t)},addAnimator:function(t){t.animation=this;for(var e=t.getClips(),n=0;n<e.length;n++)this.addClip(e[n])},removeClip:function(t){var e=u(this._clips,t);e>=0&&this._clips.splice(e,1)},removeAnimator:function(t){for(var e=t.getClips(),n=0;n<e.length;n++)this.removeClip(e[n]);t.animation=null},_update:function(){for(var t=(new Date).getTime()-this._pausedTime,e=t-this._time,n=this._clips,i=n.length,r=[],o=[],a=0;i>a;a++){var s=n[a],l=s.step(t,e);l&&(r.push(l),o.push(s))}for(var a=0;i>a;)n[a]._needsRemove?(n[a]=n[i-1],n.pop(),i--):a++;i=r.length;for(var a=0;i>a;a++)o[a].fire(r[a]);this._time=t,this.onframe(e),this.trigger("frame",e),this.stage.update&&this.stage.update()},_startLoop:function(){function t(){e._running&&(gv(t),!e._paused&&e._update())}var e=this;this._running=!0,gv(t)},start:function(){this._time=(new Date).getTime(),this._pausedTime=0,this._startLoop()},stop:function(){this._running=!1},pause:function(){this._paused||(this._pauseStart=(new Date).getTime(),this._paused=!0)},resume:function(){this._paused&&(this._pausedTime+=(new Date).getTime()-this._pauseStart,this._paused=!1)},clear:function(){this._clips=[]},isFinished:function(){return!this._clips.length},animate:function(t,e){e=e||{};var n=new Zg(t,e.loop,e.getter,e.setter);return this.addAnimator(n),n}},c(Bv,wg);var Nv=function(){this._track=[]};Nv.prototype={constructor:Nv,recognize:function(t,e,n){return this._doTrack(t,e,n),this._recognize(t)},clear:function(){return this._track.length=0,this},_doTrack:function(t,e,n){var i=t.touches;if(i){for(var r={points:[],touches:[],target:e,event:t},o=0,a=i.length;a>o;o++){var s=i[o],l=pi(n,s,{});r.points.push([l.zrX,l.zrY]),r.touches.push(s)}this._track.push(r)}},_recognize:function(t){for(var e in Vv)if(Vv.hasOwnProperty(e)){var n=Vv[e](this._track,t);if(n)return n}}};var Vv={pinch:function(t,e){var n=t.length;if(n){var i=(t[n-1]||{}).points,r=(t[n-2]||{}).points||i;if(r&&r.length>1&&i&&i.length>1){var o=xi(i)/xi(r);!isFinite(o)&&(o=1),e.pinchScale=o;var a=_i(i);return e.pinchX=a[0],e.pinchY=a[1],{type:"pinch",target:t[0].target,event:e}}}}},Fv=300,Hv=["click","dblclick","mousewheel","mouseout","mouseup","mousedown","mousemove","contextmenu"],Wv=["touchstart","touchend","touchmove"],Gv={pointerdown:1,pointerup:1,pointermove:1,pointerout:1},Uv=p(Hv,function(t){var e=t.replace("mouse","pointer");return Gv[e]?e:t}),Zv={mousemove:function(t){t=vi(this.dom,t),this.trigger("mousemove",t)},mouseout:function(t){t=vi(this.dom,t);var e=t.toElement||t.relatedTarget;if(e!=this.dom)for(;e&&9!=e.nodeType;){if(e===this.dom)return;e=e.parentNode}this.trigger("mouseout",t)},touchstart:function(t){t=vi(this.dom,t),t.zrByTouch=!0,this._lastTouchMoment=new Date,bi(this,t,"start"),Zv.mousemove.call(this,t),Zv.mousedown.call(this,t),Mi(this)},touchmove:function(t){t=vi(this.dom,t),t.zrByTouch=!0,bi(this,t,"change"),Zv.mousemove.call(this,t),Mi(this)},touchend:function(t){t=vi(this.dom,t),t.zrByTouch=!0,bi(this,t,"end"),Zv.mouseup.call(this,t),+new Date-this._lastTouchMoment<Fv&&Zv.click.call(this,t),Mi(this)},pointerdown:function(t){Zv.mousedown.call(this,t)},pointermove:function(t){Si(t)||Zv.mousemove.call(this,t)},pointerup:function(t){Zv.mouseup.call(this,t)},pointerout:function(t){Si(t)||Zv.mouseout.call(this,t)}};f(["click","mousedown","mouseup","mousewheel","dblclick","contextmenu"],function(t){Zv[t]=function(e){e=vi(this.dom,e),this.trigger(t,e)}});var jv=Ci.prototype;jv.dispose=function(){for(var t=Hv.concat(Wv),e=0;e<t.length;e++){var n=t[e];yi(this.dom,wi(n),this._handlers[n])}},jv.setCursor=function(t){this.dom.style&&(this.dom.style.cursor=t||"default")},c(Ci,wg);var Xv=!Jp.canvasSupported,Yv={canvas:Ov},qv={},$v="4.0.4",Kv=function(t,e,n){n=n||{},this.dom=e,this.id=t;var i=this,r=new ov,o=n.renderer;if(Xv){if(!Yv.vml)throw new Error("You need to require 'zrender/vml/vml' to support IE8");o="vml"}else o&&Yv[o]||(o="canvas");var a=new Yv[o](e,r,n,t);this.storage=r,this.painter=a;var s=Jp.node||Jp.worker?null:new Ci(a.getViewportRoot());this.handler=new Sg(r,a,s,a.root),this.animation=new Bv({stage:{update:y(this.flush,this)}}),this.animation.start(),this._needsRefresh;var l=r.delFromStorage,u=r.addToStorage;r.delFromStorage=function(t){l.call(r,t),t&&t.removeSelfFromZr(i)},r.addToStorage=function(t){u.call(r,t),t.addSelfToZr(i)}};Kv.prototype={constructor:Kv,getId:function(){return this.id},add:function(t){this.storage.addRoot(t),this._needsRefresh=!0},remove:function(t){this.storage.delRoot(t),this._needsRefresh=!0},configLayer:function(t,e){this.painter.configLayer&&this.painter.configLayer(t,e),this._needsRefresh=!0},setBackgroundColor:function(t){this.painter.setBackgroundColor&&this.painter.setBackgroundColor(t),this._needsRefresh=!0},refreshImmediately:function(){this._needsRefresh=!1,this.painter.refresh(),this._needsRefresh=!1},refresh:function(){this._needsRefresh=!0},flush:function(){var t;this._needsRefresh&&(t=!0,this.refreshImmediately()),this._needsRefreshHover&&(t=!0,this.refreshHoverImmediately()),t&&this.trigger("rendered")},addHover:function(t,e){this.painter.addHover&&(this.painter.addHover(t,e),this.refreshHover())},removeHover:function(t){this.painter.removeHover&&(this.painter.removeHover(t),this.refreshHover())},clearHover:function(){this.painter.clearHover&&(this.painter.clearHover(),this.refreshHover())},refreshHover:function(){this._needsRefreshHover=!0},refreshHoverImmediately:function(){this._needsRefreshHover=!1,this.painter.refreshHover&&this.painter.refreshHover()},resize:function(t){t=t||{},this.painter.resize(t.width,t.height),this.handler.resize()},clearAnimation:function(){this.animation.clear()},getWidth:function(){return this.painter.getWidth()},getHeight:function(){return this.painter.getHeight()},pathToImage:function(t,e){return this.painter.pathToImage(t,e)},setCursorStyle:function(t){this.handler.setCursorStyle(t)},findHover:function(t,e){return this.handler.findHover(t,e)},on:function(t,e,n){this.handler.on(t,e,n)},off:function(t,e){this.handler.off(t,e)},trigger:function(t,e){this.handler.trigger(t,e)},clear:function(){this.storage.delRoot(),this.painter.clear()},dispose:function(){this.animation.stop(),this.clear(),this.storage.dispose(),this.painter.dispose(),this.handler.dispose(),this.animation=this.storage=this.painter=this.handler=null,Pi(this.id)}};var Qv=(Object.freeze||Object)({version:$v,init:Ti,dispose:Ai,getInstance:Di,registerPainter:ki}),Jv=f,tm=M,em=_,nm="series\x00",im=["fontStyle","fontWeight","fontSize","fontFamily","rich","tag","color","textBorderColor","textBorderWidth","width","height","lineHeight","align","verticalAlign","baseline","shadowColor","shadowBlur","shadowOffsetX","shadowOffsetY","textShadowColor","textShadowBlur","textShadowOffsetX","textShadowOffsetY","backgroundColor","borderColor","borderWidth","borderRadius","padding"],rm=0,om=".",am="___EC__COMPONENT__CONTAINER___",sm=0,lm=function(t){for(var e=0;e<t.length;e++)t[e][1]||(t[e][1]=t[e][0]);return function(e,n,i){for(var r={},o=0;o<t.length;o++){var a=t[o][1];if(!(n&&u(n,a)>=0||i&&u(i,a)<0)){var s=e.getShallow(a);null!=s&&(r[t[o][0]]=s)}}return r}},um=lm([["lineWidth","width"],["stroke","color"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"]]),hm={getLineStyle:function(t){var e=um(this,t),n=this.getLineDash(e.lineWidth);return n&&(e.lineDash=n),e},getLineDash:function(t){null==t&&(t=1);var e=this.get("type"),n=Math.max(t,2),i=4*t;return"solid"===e||null==e?null:"dashed"===e?[i,i]:[n,n]}},cm=lm([["fill","color"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["opacity"],["shadowColor"]]),dm={getAreaStyle:function(t,e){return cm(this,t,e)}},fm=Math.pow,pm=Math.sqrt,gm=1e-8,vm=1e-4,mm=pm(3),ym=1/3,xm=H(),_m=H(),wm=H(),bm=Math.min,Mm=Math.max,Sm=Math.sin,Im=Math.cos,Cm=2*Math.PI,Tm=H(),Am=H(),Dm=H(),km=[],Pm=[],Lm={M:1,L:2,C:3,Q:4,A:5,Z:6,R:7},Om=[],Em=[],Rm=[],zm=[],Bm=Math.min,Nm=Math.max,Vm=Math.cos,Fm=Math.sin,Hm=Math.sqrt,Wm=Math.abs,Gm="undefined"!=typeof Float32Array,Um=function(t){this._saveData=!t,this._saveData&&(this.data=[]),this._ctx=null};Um.prototype={constructor:Um,_xi:0,_yi:0,_x0:0,_y0:0,_ux:0,_uy:0,_len:0,_lineDash:null,_dashOffset:0,_dashIdx:0,_dashSum:0,setScale:function(t,e){this._ux=Wm(1/Yg/t)||0,this._uy=Wm(1/Yg/e)||0},getContext:function(){return this._ctx},beginPath:function(t){return this._ctx=t,t&&t.beginPath(),t&&(this.dpr=t.dpr),this._saveData&&(this._len=0),this._lineDash&&(this._lineDash=null,this._dashOffset=0),this},moveTo:function(t,e){return this.addData(Lm.M,t,e),this._ctx&&this._ctx.moveTo(t,e),this._x0=t,this._y0=e,this._xi=t,this._yi=e,this},lineTo:function(t,e){var n=Wm(t-this._xi)>this._ux||Wm(e-this._yi)>this._uy||this._len<5;return this.addData(Lm.L,t,e),this._ctx&&n&&(this._needsDash()?this._dashedLineTo(t,e):this._ctx.lineTo(t,e)),n&&(this._xi=t,this._yi=e),this},bezierCurveTo:function(t,e,n,i,r,o){return this.addData(Lm.C,t,e,n,i,r,o),this._ctx&&(this._needsDash()?this._dashedBezierTo(t,e,n,i,r,o):this._ctx.bezierCurveTo(t,e,n,i,r,o)),this._xi=r,this._yi=o,this},quadraticCurveTo:function(t,e,n,i){return this.addData(Lm.Q,t,e,n,i),this._ctx&&(this._needsDash()?this._dashedQuadraticTo(t,e,n,i):this._ctx.quadraticCurveTo(t,e,n,i)),this._xi=n,this._yi=i,this},arc:function(t,e,n,i,r,o){return this.addData(Lm.A,t,e,n,n,i,r-i,0,o?0:1),this._ctx&&this._ctx.arc(t,e,n,i,r,o),this._xi=Vm(r)*n+t,this._yi=Fm(r)*n+t,this},arcTo:function(t,e,n,i,r){return this._ctx&&this._ctx.arcTo(t,e,n,i,r),this},rect:function(t,e,n,i){return this._ctx&&this._ctx.rect(t,e,n,i),this.addData(Lm.R,t,e,n,i),this},closePath:function(){this.addData(Lm.Z);var t=this._ctx,e=this._x0,n=this._y0;return t&&(this._needsDash()&&this._dashedLineTo(e,n),t.closePath()),this._xi=e,this._yi=n,this},fill:function(t){t&&t.fill(),this.toStatic()},stroke:function(t){t&&t.stroke(),this.toStatic()},setLineDash:function(t){if(t instanceof Array){this._lineDash=t,this._dashIdx=0;for(var e=0,n=0;n<t.length;n++)e+=t[n];this._dashSum=e}return this},setLineDashOffset:function(t){return this._dashOffset=t,this},len:function(){return this._len},setData:function(t){var e=t.length;this.data&&this.data.length==e||!Gm||(this.data=new Float32Array(e));for(var n=0;e>n;n++)this.data[n]=t[n];this._len=e},appendPath:function(t){t instanceof Array||(t=[t]);for(var e=t.length,n=0,i=this._len,r=0;e>r;r++)n+=t[r].len();Gm&&this.data instanceof Float32Array&&(this.data=new Float32Array(i+n));for(var r=0;e>r;r++)for(var o=t[r].data,a=0;a<o.length;a++)this.data[i++]=o[a];this._len=i},addData:function(t){if(this._saveData){var e=this.data;this._len+arguments.length>e.length&&(this._expandData(),e=this.data);for(var n=0;n<arguments.length;n++)e[this._len++]=arguments[n];this._prevCmd=t}},_expandData:function(){if(!(this.data instanceof Array)){for(var t=[],e=0;e<this._len;e++)t[e]=this.data[e];this.data=t}},_needsDash:function(){return this._lineDash},_dashedLineTo:function(t,e){var n,i,r=this._dashSum,o=this._dashOffset,a=this._lineDash,s=this._ctx,l=this._xi,u=this._yi,h=t-l,c=e-u,d=Hm(h*h+c*c),f=l,p=u,g=a.length;for(h/=d,c/=d,0>o&&(o=r+o),o%=r,f-=o*h,p-=o*c;h>0&&t>=f||0>h&&f>=t||0==h&&(c>0&&e>=p||0>c&&p>=e);)i=this._dashIdx,n=a[i],f+=h*n,p+=c*n,this._dashIdx=(i+1)%g,h>0&&l>f||0>h&&f>l||c>0&&u>p||0>c&&p>u||s[i%2?"moveTo":"lineTo"](h>=0?Bm(f,t):Nm(f,t),c>=0?Bm(p,e):Nm(p,e));h=f-t,c=p-e,this._dashOffset=-Hm(h*h+c*c)},_dashedBezierTo:function(t,e,n,i,r,o){var a,s,l,u,h,c=this._dashSum,d=this._dashOffset,f=this._lineDash,p=this._ctx,g=this._xi,v=this._yi,m=er,y=0,x=this._dashIdx,_=f.length,w=0;for(0>d&&(d=c+d),d%=c,a=0;1>a;a+=.1)s=m(g,t,n,r,a+.1)-m(g,t,n,r,a),l=m(v,e,i,o,a+.1)-m(v,e,i,o,a),y+=Hm(s*s+l*l);for(;_>x&&(w+=f[x],!(w>d));x++);for(a=(w-d)/y;1>=a;)u=m(g,t,n,r,a),h=m(v,e,i,o,a),x%2?p.moveTo(u,h):p.lineTo(u,h),a+=f[x]/y,x=(x+1)%_;x%2!==0&&p.lineTo(r,o),s=r-u,l=o-h,this._dashOffset=-Hm(s*s+l*l)},_dashedQuadraticTo:function(t,e,n,i){var r=n,o=i;n=(n+2*t)/3,i=(i+2*e)/3,t=(this._xi+2*t)/3,e=(this._yi+2*e)/3,this._dashedBezierTo(t,e,n,i,r,o)},toStatic:function(){var t=this.data;t instanceof Array&&(t.length=this._len,Gm&&(this.data=new Float32Array(t)))},getBoundingRect:function(){Om[0]=Om[1]=Rm[0]=Rm[1]=Number.MAX_VALUE,Em[0]=Em[1]=zm[0]=zm[1]=-Number.MAX_VALUE;for(var t=this.data,e=0,n=0,i=0,r=0,o=0;o<t.length;){var a=t[o++];switch(1==o&&(e=t[o],n=t[o+1],i=e,r=n),a){case Lm.M:i=t[o++],r=t[o++],e=i,n=r,Rm[0]=i,Rm[1]=r,zm[0]=i,zm[1]=r;break;case Lm.L:pr(e,n,t[o],t[o+1],Rm,zm),e=t[o++],n=t[o++];break;case Lm.C:gr(e,n,t[o++],t[o++],t[o++],t[o++],t[o],t[o+1],Rm,zm),e=t[o++],n=t[o++];break;case Lm.Q:vr(e,n,t[o++],t[o++],t[o],t[o+1],Rm,zm),e=t[o++],n=t[o++];break;case Lm.A:var s=t[o++],l=t[o++],u=t[o++],h=t[o++],c=t[o++],d=t[o++]+c,f=(t[o++],1-t[o++]);1==o&&(i=Vm(c)*u+s,r=Fm(c)*h+l),mr(s,l,u,h,c,d,f,Rm,zm),e=Vm(d)*u+s,n=Fm(d)*h+l;break;case Lm.R:i=e=t[o++],r=n=t[o++];var p=t[o++],g=t[o++];pr(i,r,i+p,r+g,Rm,zm);break;case Lm.Z:e=i,n=r}ae(Om,Om,Rm),se(Em,Em,zm)}return 0===o&&(Om[0]=Om[1]=Em[0]=Em[1]=0),new rn(Om[0],Om[1],Em[0]-Om[0],Em[1]-Om[1])},rebuildPath:function(t){for(var e,n,i,r,o,a,s=this.data,l=this._ux,u=this._uy,h=this._len,c=0;h>c;){var d=s[c++];switch(1==c&&(i=s[c],r=s[c+1],e=i,n=r),d){case Lm.M:e=i=s[c++],n=r=s[c++],t.moveTo(i,r);break;case Lm.L:o=s[c++],a=s[c++],(Wm(o-i)>l||Wm(a-r)>u||c===h-1)&&(t.lineTo(o,a),i=o,r=a);break;case Lm.C:t.bezierCurveTo(s[c++],s[c++],s[c++],s[c++],s[c++],s[c++]),i=s[c-2],r=s[c-1];break;case Lm.Q:t.quadraticCurveTo(s[c++],s[c++],s[c++],s[c++]),i=s[c-2],r=s[c-1];break;case Lm.A:var f=s[c++],p=s[c++],g=s[c++],v=s[c++],m=s[c++],y=s[c++],x=s[c++],_=s[c++],w=g>v?g:v,b=g>v?1:g/v,M=g>v?v/g:1,S=Math.abs(g-v)>.001,I=m+y;S?(t.translate(f,p),t.rotate(x),t.scale(b,M),t.arc(0,0,w,m,I,1-_),t.scale(1/b,1/M),t.rotate(-x),t.translate(-f,-p)):t.arc(f,p,w,m,I,1-_),1==c&&(e=Vm(m)*g+f,n=Fm(m)*v+p),i=Vm(I)*g+f,r=Fm(I)*v+p;break;case Lm.R:e=i=s[c],n=r=s[c+1],t.rect(s[c++],s[c++],s[c++],s[c++]);break;case Lm.Z:t.closePath(),i=e,r=n}}}},Um.CMD=Lm;var Zm=2*Math.PI,jm=2*Math.PI,Xm=Um.CMD,Ym=2*Math.PI,qm=1e-4,$m=[-1,-1,-1],Km=[-1,-1],Qm=fv.prototype.getCanvasPattern,Jm=Math.abs,ty=new Um(!0);Lr.prototype={constructor:Lr,type:"path",__dirtyPath:!0,strokeContainThreshold:5,brush:function(t,e){var n=this.style,i=this.path||ty,r=n.hasStroke(),o=n.hasFill(),a=n.fill,s=n.stroke,l=o&&!!a.colorStops,u=r&&!!s.colorStops,h=o&&!!a.image,c=r&&!!s.image;if(n.bind(t,this,e),this.setTransform(t),this.__dirty){var d;l&&(d=d||this.getBoundingRect(),this._fillGradient=n.getGradient(t,a,d)),u&&(d=d||this.getBoundingRect(),this._strokeGradient=n.getGradient(t,s,d))}l?t.fillStyle=this._fillGradient:h&&(t.fillStyle=Qm.call(a,t)),u?t.strokeStyle=this._strokeGradient:c&&(t.strokeStyle=Qm.call(s,t));var f=n.lineDash,p=n.lineDashOffset,g=!!t.setLineDash,v=this.getGlobalScale();i.setScale(v[0],v[1]),this.__dirtyPath||f&&!g&&r?(i.beginPath(t),f&&!g&&(i.setLineDash(f),i.setLineDashOffset(p)),this.buildPath(i,this.shape,!1),this.path&&(this.__dirtyPath=!1)):(t.beginPath(),this.path.rebuildPath(t)),o&&i.fill(t),f&&g&&(t.setLineDash(f),t.lineDashOffset=p),r&&i.stroke(t),f&&g&&t.setLineDash([]),null!=n.text&&(this.restoreTransform(t),this.drawRectText(t,this.getBoundingRect()))},buildPath:function(){},createPathProxy:function(){this.path=new Um},getBoundingRect:function(){var t=this._rect,e=this.style,n=!t;if(n){var i=this.path;i||(i=this.path=new Um),this.__dirtyPath&&(i.beginPath(),this.buildPath(i,this.shape,!1)),t=i.getBoundingRect()}if(this._rect=t,e.hasStroke()){var r=this._rectWithStroke||(this._rectWithStroke=t.clone());if(this.__dirty||n){r.copy(t);var o=e.lineWidth,a=e.strokeNoScale?this.getLineScale():1;e.hasFill()||(o=Math.max(o,this.strokeContainThreshold||4)),a>1e-10&&(r.width+=o/a,r.height+=o/a,r.x-=o/a/2,r.y-=o/a/2)}return r}return t},contain:function(t,e){var n=this.transformCoordToLocal(t,e),i=this.getBoundingRect(),r=this.style;if(t=n[0],e=n[1],i.contain(t,e)){var o=this.path.data;if(r.hasStroke()){var a=r.lineWidth,s=r.strokeNoScale?this.getLineScale():1;if(s>1e-10&&(r.hasFill()||(a=Math.max(a,this.strokeContainThreshold)),Pr(o,a/s,t,e)))return!0}if(r.hasFill())return kr(o,t,e)}return!1},dirty:function(t){null==t&&(t=!0),t&&(this.__dirtyPath=t,this._rect=null),this.__dirty=!0,this.__zr&&this.__zr.refresh(),this.__clipTarget&&this.__clipTarget.dirty()},animateShape:function(t){return this.animate("shape",t)},attrKV:function(t,e){"shape"===t?(this.setShape(e),this.__dirtyPath=!0,this._rect=null):oi.prototype.attrKV.call(this,t,e)},setShape:function(t,e){var n=this.shape;if(n){if(M(t))for(var i in t)t.hasOwnProperty(i)&&(n[i]=t[i]);else n[t]=e;this.dirty(!0)}return this},getLineScale:function(){var t=this.transform;return t&&Jm(t[0]-1)>1e-10&&Jm(t[3]-1)>1e-10?Math.sqrt(Jm(t[0]*t[3]-t[2]*t[1])):1}},Lr.extend=function(t){var e=function(e){Lr.call(this,e),t.style&&this.style.extendFrom(t.style,!1);var n=t.shape;if(n){this.shape=this.shape||{};var i=this.shape;for(var r in n)!i.hasOwnProperty(r)&&n.hasOwnProperty(r)&&(i[r]=n[r])}t.init&&t.init.call(this,e)};h(e,Lr);for(var n in t)"style"!==n&&"shape"!==n&&(e.prototype[n]=t[n]);return e},h(Lr,oi);var ey=Um.CMD,ny=[[],[],[]],iy=Math.sqrt,ry=Math.atan2,oy=function(t,e){var n,i,r,o,a,s,l=t.data,u=ey.M,h=ey.C,c=ey.L,d=ey.R,f=ey.A,p=ey.Q;for(r=0,o=0;r<l.length;){switch(n=l[r++],o=r,i=0,n){case u:i=1;break;case c:i=1;break;case h:i=3;break;case p:i=2;break;case f:var g=e[4],v=e[5],m=iy(e[0]*e[0]+e[1]*e[1]),y=iy(e[2]*e[2]+e[3]*e[3]),x=ry(-e[1]/y,e[0]/m);l[r]*=m,l[r++]+=g,l[r]*=y,l[r++]+=v,l[r++]*=m,l[r++]*=y,l[r++]+=x,l[r++]+=x,r+=2,o=r;break;case d:s[0]=l[r++],s[1]=l[r++],oe(s,s,e),l[o++]=s[0],l[o++]=s[1],s[0]+=l[r++],s[1]+=l[r++],oe(s,s,e),l[o++]=s[0],l[o++]=s[1]}for(a=0;i>a;a++){var s=ny[a];s[0]=l[r++],s[1]=l[r++],oe(s,s,e),l[o++]=s[0],l[o++]=s[1]}}},ay=["m","M","l","L","v","V","h","H","z","Z","c","C","q","Q","t","T","s","S","a","A"],sy=Math.sqrt,ly=Math.sin,uy=Math.cos,hy=Math.PI,cy=function(t){return Math.sqrt(t[0]*t[0]+t[1]*t[1])},dy=function(t,e){return(t[0]*e[0]+t[1]*e[1])/(cy(t)*cy(e))},fy=function(t,e){return(t[0]*e[1]<t[1]*e[0]?-1:1)*Math.acos(dy(t,e))},py=function(t){oi.call(this,t)};py.prototype={constructor:py,type:"text",brush:function(t,e){var n=this.style;this.__dirty&&Hn(n,!0),n.fill=n.stroke=n.shadowBlur=n.shadowColor=n.shadowOffsetX=n.shadowOffsetY=null;var i=n.text;null!=i&&(i+=""),n.bind(t,this,e),ri(i,n)&&(this.setTransform(t),Gn(this,t,i,n),this.restoreTransform(t))},getBoundingRect:function(){var t=this.style;if(this.__dirty&&Hn(t,!0),!this._rect){var e=t.text;null!=e?e+="":e="";var n=Sn(t.text+"",t.font,t.textAlign,t.textVerticalAlign,t.textPadding,t.rich);if(n.x+=t.x||0,n.y+=t.y||0,ti(t.textStroke,t.textStrokeWidth)){var i=t.textStrokeWidth;n.x-=i/2,n.y-=i/2,n.width+=i,n.height+=i}this._rect=n}return this._rect}},h(py,oi);var gy=Lr.extend({type:"circle",shape:{cx:0,cy:0,r:0},buildPath:function(t,e,n){n&&t.moveTo(e.cx+e.r,e.cy),t.arc(e.cx,e.cy,e.r,0,2*Math.PI,!0)}}),vy=[["shadowBlur",0],["shadowColor","#000"],["shadowOffsetX",0],["shadowOffsetY",0]],my=function(t){return Jp.browser.ie&&Jp.browser.version>=11?function(){var e,n=this.__clipPaths,i=this.style;if(n)for(var r=0;r<n.length;r++){var o=n[r],a=o&&o.shape,s=o&&o.type;if(a&&("sector"===s&&a.startAngle===a.endAngle||"rect"===s&&(!a.width||!a.height))){for(var l=0;l<vy.length;l++)vy[l][2]=i[vy[l][0]],i[vy[l][0]]=vy[l][1];e=!0;break}}if(t.apply(this,arguments),e)for(var l=0;l<vy.length;l++)i[vy[l][0]]=vy[l][2]}:t},yy=Lr.extend({type:"sector",shape:{cx:0,cy:0,r0:0,r:0,startAngle:0,endAngle:2*Math.PI,clockwise:!0},brush:my(Lr.prototype.brush),buildPath:function(t,e){var n=e.cx,i=e.cy,r=Math.max(e.r0||0,0),o=Math.max(e.r,0),a=e.startAngle,s=e.endAngle,l=e.clockwise,u=Math.cos(a),h=Math.sin(a);t.moveTo(u*r+n,h*r+i),t.lineTo(u*o+n,h*o+i),t.arc(n,i,o,a,s,!l),t.lineTo(Math.cos(s)*r+n,Math.sin(s)*r+i),0!==r&&t.arc(n,i,r,s,a,l),t.closePath()}}),xy=Lr.extend({type:"ring",shape:{cx:0,cy:0,r:0,r0:0},buildPath:function(t,e){var n=e.cx,i=e.cy,r=2*Math.PI;t.moveTo(n+e.r,i),t.arc(n,i,e.r,0,r,!1),t.moveTo(n+e.r0,i),t.arc(n,i,e.r0,0,r,!0)}}),_y=function(t,e){for(var n=t.length,i=[],r=0,o=1;n>o;o++)r+=ee(t[o-1],t[o]);var a=r/2;a=n>a?n:a;for(var o=0;a>o;o++){var s,l,u,h=o/(a-1)*(e?n:n-1),c=Math.floor(h),d=h-c,f=t[c%n];e?(s=t[(c-1+n)%n],l=t[(c+1)%n],u=t[(c+2)%n]):(s=t[0===c?c:c-1],l=t[c>n-2?n-1:c+1],u=t[c>n-3?n-1:c+2]);var p=d*d,g=d*p;i.push([Vr(s[0],f[0],l[0],u[0],d,p,g),Vr(s[1],f[1],l[1],u[1],d,p,g)])}return i},wy=function(t,e,n,i){var r,o,a,s,l=[],u=[],h=[],c=[];if(i){a=[1/0,1/0],s=[-1/0,-1/0];for(var d=0,f=t.length;f>d;d++)ae(a,a,t[d]),se(s,s,t[d]);ae(a,a,i[0]),se(s,s,i[1])}for(var d=0,f=t.length;f>d;d++){var p=t[d];if(n)r=t[d?d-1:f-1],o=t[(d+1)%f];else{if(0===d||d===f-1){l.push(G(t[d]));continue}r=t[d-1],o=t[d+1]}X(u,o,r),J(u,u,e);var g=ee(p,r),v=ee(p,o),m=g+v;0!==m&&(g/=m,v/=m),J(h,u,-g),J(c,u,v);var y=Z([],p,h),x=Z([],p,c);i&&(se(y,y,a),ae(y,y,s),se(x,x,a),ae(x,x,s)),l.push(y),l.push(x)}return n&&l.push(l.shift()),l},by=Lr.extend({type:"polygon",shape:{points:null,smooth:!1,smoothConstraint:null},buildPath:function(t,e){Fr(t,e,!0)}}),My=Lr.extend({type:"polyline",shape:{points:null,smooth:!1,smoothConstraint:null},style:{stroke:"#000",fill:null},buildPath:function(t,e){Fr(t,e,!1)}}),Sy=Lr.extend({type:"rect",shape:{r:0,x:0,y:0,width:0,height:0},buildPath:function(t,e){var n=e.x,i=e.y,r=e.width,o=e.height;e.r?Fn(t,e):t.rect(n,i,r,o),t.closePath()}}),Iy=Lr.extend({type:"line",shape:{x1:0,y1:0,x2:0,y2:0,percent:1},style:{stroke:"#000",fill:null},buildPath:function(t,e){var n=e.x1,i=e.y1,r=e.x2,o=e.y2,a=e.percent;0!==a&&(t.moveTo(n,i),1>a&&(r=n*(1-a)+r*a,o=i*(1-a)+o*a),t.lineTo(r,o))},pointAt:function(t){var e=this.shape;return[e.x1*(1-t)+e.x2*t,e.y1*(1-t)+e.y2*t]}}),Cy=[],Ty=Lr.extend({type:"bezier-curve",shape:{x1:0,y1:0,x2:0,y2:0,cpx1:0,cpy1:0,percent:1},style:{stroke:"#000",fill:null},buildPath:function(t,e){var n=e.x1,i=e.y1,r=e.x2,o=e.y2,a=e.cpx1,s=e.cpy1,l=e.cpx2,u=e.cpy2,h=e.percent;0!==h&&(t.moveTo(n,i),null==l||null==u?(1>h&&(cr(n,a,r,h,Cy),a=Cy[1],r=Cy[2],cr(i,s,o,h,Cy),s=Cy[1],o=Cy[2]),t.quadraticCurveTo(a,s,r,o)):(1>h&&(or(n,a,l,r,h,Cy),a=Cy[1],l=Cy[2],r=Cy[3],or(i,s,u,o,h,Cy),s=Cy[1],u=Cy[2],o=Cy[3]),t.bezierCurveTo(a,s,l,u,r,o)))},pointAt:function(t){return Hr(this.shape,t,!1)},tangentAt:function(t){var e=Hr(this.shape,t,!0);return te(e,e)}}),Ay=Lr.extend({type:"arc",shape:{cx:0,cy:0,r:0,startAngle:0,endAngle:2*Math.PI,clockwise:!0},style:{stroke:"#000",fill:null},buildPath:function(t,e){var n=e.cx,i=e.cy,r=Math.max(e.r,0),o=e.startAngle,a=e.endAngle,s=e.clockwise,l=Math.cos(o),u=Math.sin(o);t.moveTo(l*r+n,u*r+i),t.arc(n,i,r,o,a,!s)}}),Dy=Lr.extend({type:"compound",shape:{paths:null},_updatePathDirty:function(){for(var t=this.__dirtyPath,e=this.shape.paths,n=0;n<e.length;n++)t=t||e[n].__dirtyPath;this.__dirtyPath=t,this.__dirty=this.__dirty||t},beforeBrush:function(){this._updatePathDirty();for(var t=this.shape.paths||[],e=this.getGlobalScale(),n=0;n<t.length;n++)t[n].path||t[n].createPathProxy(),t[n].path.setScale(e[0],e[1])},buildPath:function(t,e){for(var n=e.paths||[],i=0;i<n.length;i++)n[i].buildPath(t,n[i].shape,!0)},afterBrush:function(){for(var t=this.shape.paths||[],e=0;e<t.length;e++)t[e].__dirtyPath=!1},getBoundingRect:function(){return this._updatePathDirty(),Lr.prototype.getBoundingRect.call(this)}}),ky=function(t){this.colorStops=t||[]};ky.prototype={constructor:ky,addColorStop:function(t,e){this.colorStops.push({offset:t,color:e})}};var Py=function(t,e,n,i,r,o){this.x=null==t?0:t,this.y=null==e?0:e,this.x2=null==n?1:n,this.y2=null==i?0:i,this.type="linear",this.global=o||!1,ky.call(this,r)};Py.prototype={constructor:Py},h(Py,ky);var Ly=function(t,e,n,i,r){this.x=null==t?.5:t,this.y=null==e?.5:e,this.r=null==n?.5:n,this.type="radial",this.global=r||!1,ky.call(this,i)};Ly.prototype={constructor:Ly},h(Ly,ky),Wr.prototype.incremental=!0,Wr.prototype.clearDisplaybles=function(){this._displayables=[],this._temporaryDisplayables=[],this._cursor=0,this.dirty(),this.notClear=!1},Wr.prototype.addDisplayable=function(t,e){e?this._temporaryDisplayables.push(t):this._displayables.push(t),this.dirty()},Wr.prototype.addDisplayables=function(t,e){e=e||!1;for(var n=0;n<t.length;n++)this.addDisplayable(t[n],e)},Wr.prototype.eachPendingDisplayable=function(t){for(var e=this._cursor;e<this._displayables.length;e++)t&&t(this._displayables[e]);for(var e=0;e<this._temporaryDisplayables.length;e++)t&&t(this._temporaryDisplayables[e])},Wr.prototype.update=function(){this.updateTransform();for(var t=this._cursor;t<this._displayables.length;t++){var e=this._displayables[t];e.parent=this,e.update(),e.parent=null}for(var t=0;t<this._temporaryDisplayables.length;t++){var e=this._temporaryDisplayables[t];e.parent=this,e.update(),e.parent=null}},Wr.prototype.brush=function(t){for(var e=this._cursor;e<this._displayables.length;e++){var n=this._displayables[e];n.beforeBrush&&n.beforeBrush(t),n.brush(t,e===this._cursor?null:this._displayables[e-1]),n.afterBrush&&n.afterBrush(t)}this._cursor=e;for(var e=0;e<this._temporaryDisplayables.length;e++){var n=this._temporaryDisplayables[e];n.beforeBrush&&n.beforeBrush(t),n.brush(t,0===e?null:this._temporaryDisplayables[e-1]),n.afterBrush&&n.afterBrush(t)}this._temporaryDisplayables=[],this.notClear=!0};var Oy=[];Wr.prototype.getBoundingRect=function(){if(!this._rect){for(var t=new rn(1/0,1/0,-1/0,-1/0),e=0;e<this._displayables.length;e++){var n=this._displayables[e],i=n.getBoundingRect().clone();n.needLocalTransform()&&i.applyTransform(n.getLocalTransform(Oy)),t.union(i)}this._rect=t}return this._rect},Wr.prototype.contain=function(t,e){var n=this.transformCoordToLocal(t,e),i=this.getBoundingRect();if(i.contain(n[0],n[1]))for(var r=0;r<this._displayables.length;r++){var o=this._displayables[r];if(o.contain(t,e))return!0}return!1},h(Wr,oi);var Ey=Math.round,Ry=Math.max,zy=Math.min,By={},Ny=Nr,Vy=(Object.freeze||Object)({extendShape:Gr,extendPath:Ur,makePath:Zr,makeImage:jr,mergePath:Ny,resizePath:Yr,subPixelOptimizeLine:qr,subPixelOptimizeRect:$r,subPixelOptimize:Kr,setHoverStyle:ho,setLabelStyle:co,setTextStyle:fo,setText:po,getFont:wo,updateProps:Mo,initProps:So,getTransform:Io,applyTransform:Co,transformDirection:To,groupTransition:Ao,clipPointsByRect:Do,clipRectByRect:ko,createIcon:Po,Group:nv,Image:ai,Text:py,Circle:gy,Sector:yy,Ring:xy,Polygon:by,Polyline:My,Rect:Sy,Line:Iy,BezierCurve:Ty,Arc:Ay,IncrementalDisplayable:Wr,CompoundPath:Dy,LinearGradient:Py,RadialGradient:Ly,BoundingRect:rn}),Fy=["textStyle","color"],Hy={getTextColor:function(t){var e=this.ecModel;return this.getShallow("color")||(!t&&e?e.get(Fy):null)},getFont:function(){return wo({fontStyle:this.getShallow("fontStyle"),fontWeight:this.getShallow("fontWeight"),fontSize:this.getShallow("fontSize"),fontFamily:this.getShallow("fontFamily")},this.ecModel)},getTextRect:function(t){return Sn(t,this.getFont(),this.getShallow("align"),this.getShallow("verticalAlign")||this.getShallow("baseline"),this.getShallow("padding"),this.getShallow("rich"),this.getShallow("truncateText"))}},Wy=lm([["fill","color"],["stroke","borderColor"],["lineWidth","borderWidth"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"],["textPosition"],["textAlign"]]),Gy={getItemStyle:function(t,e){var n=Wy(this,t,e),i=this.getBorderLineDash();return i&&(n.lineDash=i),n},getBorderLineDash:function(){var t=this.get("borderType");return"solid"===t||null==t?null:"dashed"===t?[5,5]:[1,1]}},Uy=c,Zy=Hi();Lo.prototype={constructor:Lo,init:null,mergeOption:function(t){r(this.option,t,!0)},get:function(t,e){return null==t?this.option:Oo(this.option,this.parsePath(t),!e&&Eo(this,t))},getShallow:function(t,e){var n=this.option,i=null==n?n:n[t],r=!e&&Eo(this,t);return null==i&&r&&(i=r.getShallow(t)),i},getModel:function(t,e){var n,i=null==t?this.option:Oo(this.option,t=this.parsePath(t));
+return e=e||(n=Eo(this,t))&&n.getModel(t),new Lo(i,e,this.ecModel)},isEmpty:function(){return null==this.option},restoreData:function(){},clone:function(){var t=this.constructor;return new t(i(this.option))},setReadOnly:function(){},parsePath:function(t){return"string"==typeof t&&(t=t.split(".")),t},customizeGetParent:function(t){Zy(this).getParent=t},isAnimationEnabled:function(){if(!Jp.node){if(null!=this.option.animation)return!!this.option.animation;if(this.parentModel)return this.parentModel.isAnimationEnabled()}}},Yi(Lo),qi(Lo),Uy(Lo,hm),Uy(Lo,dm),Uy(Lo,Hy),Uy(Lo,Gy);var jy=0,Xy=1e-4,Yy=9007199254740991,qy=/^(?:(\d{4})(?:[-\/](\d{1,2})(?:[-\/](\d{1,2})(?:[T ](\d{1,2})(?::(\d\d)(?::(\d\d)(?:[.,](\d+))?)?)?(Z|[\+\-]\d\d:?\d\d)?)?)?)?)?$/,$y=(Object.freeze||Object)({linearMap:Vo,parsePercent:Fo,round:Ho,asc:Wo,getPrecision:Go,getPrecisionSafe:Uo,getPixelPrecision:Zo,getPercentWithPrecision:jo,MAX_SAFE_INTEGER:Yy,remRadian:Xo,isRadianAroundZero:Yo,parseDate:qo,quantity:$o,nice:Qo,reformIntervals:Jo,isNumeric:ta}),Ky=L,Qy=/([&<>"'])/g,Jy={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"},tx=["a","b","c","d","e","f","g"],ex=function(t,e){return"{"+t+(null==e?"":e)+"}"},nx=kn,ix=Sn,rx=(Object.freeze||Object)({addCommas:ea,toCamelCase:na,normalizeCssArray:Ky,encodeHTML:ia,formatTpl:ra,formatTplSimple:oa,getTooltipMarker:aa,formatTime:la,capitalFirst:ua,truncateText:nx,getTextRect:ix}),ox=f,ax=["left","right","top","bottom","width","height"],sx=[["width","left","right"],["height","top","bottom"]],lx=ha,ux=(x(ha,"vertical"),x(ha,"horizontal"),{getBoxLayoutParams:function(){return{left:this.get("left"),top:this.get("top"),right:this.get("right"),bottom:this.get("bottom"),width:this.get("width"),height:this.get("height")}}}),hx=Hi(),cx=Lo.extend({type:"component",id:"",name:"",mainType:"",subType:"",componentIndex:0,defaultOption:null,ecModel:null,dependentModels:[],uid:null,layoutMode:null,$constructor:function(t,e,n,i){Lo.call(this,t,e,n,i),this.uid=Ro("ec_cpt_model")},init:function(t,e,n){this.mergeDefaultAndTheme(t,n)},mergeDefaultAndTheme:function(t,e){var n=this.layoutMode,i=n?pa(t):{},o=e.getTheme();r(t,o.get(this.mainType)),r(t,this.getDefaultOption()),n&&fa(t,i,n)},mergeOption:function(t){r(this.option,t,!0);var e=this.layoutMode;e&&fa(this.option,t,e)},optionUpdated:function(){},getDefaultOption:function(){var t=hx(this);if(!t.defaultOption){for(var e=[],n=this.constructor;n;){var i=n.prototype.defaultOption;i&&e.push(i),n=n.superClass}for(var o={},a=e.length-1;a>=0;a--)o=r(o,e[a],!0);t.defaultOption=o}return t.defaultOption},getReferringComponents:function(t){return this.ecModel.queryComponents({mainType:t,index:this.get(t+"Index",!0),id:this.get(t+"Id",!0)})}});Qi(cx,{registerWhenExtend:!0}),zo(cx),Bo(cx,va),c(cx,ux);var dx="";"undefined"!=typeof navigator&&(dx=navigator.platform||"");var fx={color:["#c23531","#2f4554","#61a0a8","#d48265","#91c7ae","#749f83","#ca8622","#bda29a","#6e7074","#546570","#c4ccd3"],gradientColor:["#f6efa6","#d88273","#bf444c"],textStyle:{fontFamily:dx.match(/^Win/)?"Microsoft YaHei":"sans-serif",fontSize:12,fontStyle:"normal",fontWeight:"normal"},blendMode:null,animation:"auto",animationDuration:1e3,animationDurationUpdate:300,animationEasing:"exponentialOut",animationEasingUpdate:"cubicOut",animationThreshold:2e3,progressiveThreshold:3e3,progressive:400,hoverLayerThreshold:3e3,useUTC:!1},px=Hi(),gx={clearColorPalette:function(){px(this).colorIdx=0,px(this).colorNameMap={}},getColorFromPalette:function(t,e,n){e=e||this;var i=px(e),r=i.colorIdx||0,o=i.colorNameMap=i.colorNameMap||{};if(o.hasOwnProperty(t))return o[t];var a=Li(this.get("color",!0)),s=this.get("colorLayer",!0),l=null!=n&&s?ma(s,n):a;if(l=l||a,l&&l.length){var u=l[r];return t&&(o[t]=u),i.colorIdx=(r+1)%l.length,u}}},vx={cartesian2d:function(t,e,n,i){var r=t.getReferringComponents("xAxis")[0],o=t.getReferringComponents("yAxis")[0];e.coordSysDims=["x","y"],n.set("x",r),n.set("y",o),xa(r)&&(i.set("x",r),e.firstCategoryDimIndex=0),xa(o)&&(i.set("y",o),e.firstCategoryDimIndex=1)},singleAxis:function(t,e,n,i){var r=t.getReferringComponents("singleAxis")[0];e.coordSysDims=["single"],n.set("single",r),xa(r)&&(i.set("single",r),e.firstCategoryDimIndex=0)},polar:function(t,e,n,i){var r=t.getReferringComponents("polar")[0],o=r.findAxisModel("radiusAxis"),a=r.findAxisModel("angleAxis");e.coordSysDims=["radius","angle"],n.set("radius",o),n.set("angle",a),xa(o)&&(i.set("radius",o),e.firstCategoryDimIndex=0),xa(a)&&(i.set("angle",a),e.firstCategoryDimIndex=1)},geo:function(t,e){e.coordSysDims=["lng","lat"]},parallel:function(t,e,n,i){var r=t.ecModel,o=r.getComponent("parallel",t.get("parallelIndex")),a=e.coordSysDims=o.dimensions.slice();f(o.parallelAxisIndex,function(t,o){var s=r.getComponent("parallelAxis",t),l=a[o];n.set(l,s),xa(s)&&null==e.firstCategoryDimIndex&&(i.set(l,s),e.firstCategoryDimIndex=o)})}},mx="original",yx="arrayRows",xx="objectRows",_x="keyedColumns",bx="unknown",Mx="typedArray",Sx="column",Ix="row";_a.seriesDataToSource=function(t){return new _a({data:t,sourceFormat:I(t)?Mx:mx,fromDataset:!1})},qi(_a);var Cx=Hi(),Tx="\x00_ec_inner",Ax=Lo.extend({init:function(t,e,n,i){n=n||{},this.option=null,this._theme=new Lo(n),this._optionManager=i},setOption:function(t,e){O(!(Tx in t),"please use chart.getOption()"),this._optionManager.setOption(t,e),this.resetOption(null)},resetOption:function(t){var e=!1,n=this._optionManager;if(!t||"recreate"===t){var i=n.mountOption("recreate"===t);this.option&&"recreate"!==t?(this.restoreData(),this.mergeOption(i)):Ra.call(this,i),e=!0}if(("timeline"===t||"media"===t)&&this.restoreData(),!t||"recreate"===t||"timeline"===t){var r=n.getTimelineOption(this);r&&(this.mergeOption(r),e=!0)}if(!t||"recreate"===t||"media"===t){var o=n.getMediaOption(this,this._api);o.length&&f(o,function(t){this.mergeOption(t,e=!0)},this)}return e},mergeOption:function(t){function e(e,i){var r=Li(t[e]),s=zi(o.get(e),r);Bi(s),f(s,function(t){var n=t.option;M(n)&&(t.keyInfo.mainType=e,t.keyInfo.subType=Ba(e,n,t.exist))});var l=za(o,i);n[e]=[],o.set(e,[]),f(s,function(t,i){var r=t.exist,s=t.option;if(O(M(s)||r,"Empty component definition"),s){var u=cx.getClass(e,t.keyInfo.subType,!0);if(r&&r instanceof u)r.name=t.keyInfo.name,r.mergeOption(s,this),r.optionUpdated(s,!1);else{var h=a({dependentModels:l,componentIndex:i},t.keyInfo);r=new u(s,this,this,h),a(r,h),r.init(s,this,this,h),r.optionUpdated(null,!0)}}else r.mergeOption({},this),r.optionUpdated({},!1);o.get(e)[i]=r,n[e][i]=r.option},this),"series"===e&&Na(this,o.get("series"))}var n=this.option,o=this._componentsMap,s=[];Ma(this),f(t,function(t,e){null!=t&&(cx.hasClass(e)?e&&s.push(e):n[e]=null==n[e]?i(t):r(n[e],t,!0))}),cx.topologicalTravel(s,cx.getAllClassMainTypes(),e,this),this._seriesIndicesMap=N(this._seriesIndices=this._seriesIndices||[])},getOption:function(){var t=i(this.option);return f(t,function(e,n){if(cx.hasClass(n)){for(var e=Li(e),i=e.length-1;i>=0;i--)Vi(e[i])&&e.splice(i,1);t[n]=e}}),delete t[Tx],t},getTheme:function(){return this._theme},getComponent:function(t,e){var n=this._componentsMap.get(t);return n?n[e||0]:void 0},queryComponents:function(t){var e=t.mainType;if(!e)return[];var n=t.index,i=t.id,r=t.name,o=this._componentsMap.get(e);if(!o||!o.length)return[];var a;if(null!=n)_(n)||(n=[n]),a=v(p(n,function(t){return o[t]}),function(t){return!!t});else if(null!=i){var s=_(i);a=v(o,function(t){return s&&u(i,t.id)>=0||!s&&t.id===i})}else if(null!=r){var l=_(r);a=v(o,function(t){return l&&u(r,t.name)>=0||!l&&t.name===r})}else a=o.slice();return Va(a,t)},findComponents:function(t){function e(t){var e=r+"Index",n=r+"Id",i=r+"Name";return!t||null==t[e]&&null==t[n]&&null==t[i]?null:{mainType:r,index:t[e],id:t[n],name:t[i]}}function n(e){return t.filter?v(e,t.filter):e}var i=t.query,r=t.mainType,o=e(i),a=o?this.queryComponents(o):this._componentsMap.get(r);return n(Va(a,t))},eachComponent:function(t,e,n){var i=this._componentsMap;if("function"==typeof t)n=e,e=t,i.each(function(t,i){f(t,function(t,r){e.call(n,i,t,r)})});else if(b(t))f(i.get(t),e,n);else if(M(t)){var r=this.findComponents(t);f(r,e,n)}},getSeriesByName:function(t){var e=this._componentsMap.get("series");return v(e,function(e){return e.name===t})},getSeriesByIndex:function(t){return this._componentsMap.get("series")[t]},getSeriesByType:function(t){var e=this._componentsMap.get("series");return v(e,function(e){return e.subType===t})},getSeries:function(){return this._componentsMap.get("series").slice()},getSeriesCount:function(){return this._componentsMap.get("series").length},eachSeries:function(t,e){f(this._seriesIndices,function(n){var i=this._componentsMap.get("series")[n];t.call(e,i,n)},this)},eachRawSeries:function(t,e){f(this._componentsMap.get("series"),t,e)},eachSeriesByType:function(t,e,n){f(this._seriesIndices,function(i){var r=this._componentsMap.get("series")[i];r.subType===t&&e.call(n,r,i)},this)},eachRawSeriesByType:function(t,e,n){return f(this.getSeriesByType(t),e,n)},isSeriesFiltered:function(t){return null==this._seriesIndicesMap.get(t.componentIndex)},getCurrentSeriesIndices:function(){return(this._seriesIndices||[]).slice()},filterSeries:function(t,e){var n=v(this._componentsMap.get("series"),t,e);Na(this,n)},restoreData:function(t){var e=this._componentsMap;Na(this,e.get("series"));var n=[];e.each(function(t,e){n.push(e)}),cx.topologicalTravel(n,cx.getAllClassMainTypes(),function(n){f(e.get(n),function(e){("series"!==n||!Oa(e,t))&&e.restoreData()})})}});c(Ax,gx);var Dx=["getDom","getZr","getWidth","getHeight","getDevicePixelRatio","dispatchAction","isDisposed","on","off","getDataURL","getConnectedDataURL","getModel","getOption","getViewOfComponentModel","getViewOfSeriesModel"],kx={};Ha.prototype={constructor:Ha,create:function(t,e){var n=[];f(kx,function(i){var r=i.create(t,e);n=n.concat(r||[])}),this._coordinateSystems=n},update:function(t,e){f(this._coordinateSystems,function(n){n.update&&n.update(t,e)})},getCoordinateSystems:function(){return this._coordinateSystems.slice()}},Ha.register=function(t,e){kx[t]=e},Ha.get=function(t){return kx[t]};var Px=f,Lx=i,Ox=p,Ex=r,Rx=/^(min|max)?(.+)$/;Wa.prototype={constructor:Wa,setOption:function(t,e){t&&f(Li(t.series),function(t){t&&t.data&&I(t.data)&&R(t.data)}),t=Lx(t,!0);var n=this._optionBackup,i=Ga.call(this,t,e,!n);this._newBaseOption=i.baseOption,n?(Xa(n.baseOption,i.baseOption),i.timelineOptions.length&&(n.timelineOptions=i.timelineOptions),i.mediaList.length&&(n.mediaList=i.mediaList),i.mediaDefault&&(n.mediaDefault=i.mediaDefault)):this._optionBackup=i},mountOption:function(t){var e=this._optionBackup;return this._timelineOptions=Ox(e.timelineOptions,Lx),this._mediaList=Ox(e.mediaList,Lx),this._mediaDefault=Lx(e.mediaDefault),this._currentMediaIndices=[],Lx(t?e.baseOption:this._newBaseOption)},getTimelineOption:function(t){var e,n=this._timelineOptions;if(n.length){var i=t.getComponent("timeline");i&&(e=Lx(n[i.getCurrentIndex()],!0))}return e},getMediaOption:function(){var t=this._api.getWidth(),e=this._api.getHeight(),n=this._mediaList,i=this._mediaDefault,r=[],o=[];if(!n.length&&!i)return o;for(var a=0,s=n.length;s>a;a++)Ua(n[a].query,t,e)&&r.push(a);return!r.length&&i&&(r=[-1]),r.length&&!ja(r,this._currentMediaIndices)&&(o=Ox(r,function(t){return Lx(-1===t?i.option:n[t].option)})),this._currentMediaIndices=r,o}};var zx=f,Bx=M,Nx=["areaStyle","lineStyle","nodeStyle","linkStyle","chordStyle","label","labelLine"],Vx=function(t,e){zx(ts(t.series),function(t){Bx(t)&&Ja(t)});var n=["xAxis","yAxis","radiusAxis","angleAxis","singleAxis","parallelAxis","radar"];e&&n.push("valueAxis","categoryAxis","logAxis","timeAxis"),zx(n,function(e){zx(ts(t[e]),function(t){t&&(Ka(t,"axisLabel"),Ka(t.axisPointer,"label"))})}),zx(ts(t.parallel),function(t){var e=t&&t.parallelAxisDefault;Ka(e,"axisLabel"),Ka(e&&e.axisPointer,"label")}),zx(ts(t.calendar),function(t){qa(t,"itemStyle"),Ka(t,"dayLabel"),Ka(t,"monthLabel"),Ka(t,"yearLabel")}),zx(ts(t.radar),function(t){Ka(t,"name")}),zx(ts(t.geo),function(t){Bx(t)&&(Qa(t),zx(ts(t.regions),function(t){Qa(t)}))}),zx(ts(t.timeline),function(t){Qa(t),qa(t,"label"),qa(t,"itemStyle"),qa(t,"controlStyle",!0);var e=t.data;_(e)&&f(e,function(t){M(t)&&(qa(t,"label"),qa(t,"itemStyle"))})}),zx(ts(t.toolbox),function(t){qa(t,"iconStyle"),zx(t.feature,function(t){qa(t,"iconStyle")})}),Ka(es(t.axisPointer),"label"),Ka(es(t.tooltip).axisPointer,"label")},Fx=[["x","left"],["y","top"],["x2","right"],["y2","bottom"]],Hx=["grid","geo","parallel","legend","toolbox","title","visualMap","dataZoom","timeline"],Wx=function(t,e){Vx(t,e),t.series=Li(t.series),f(t.series,function(t){if(M(t)){var e=t.type;if(("pie"===e||"gauge"===e)&&null!=t.clockWise&&(t.clockwise=t.clockWise),"gauge"===e){var n=ns(t,"pointer.color");null!=n&&is(t,"itemStyle.normal.color",n)}rs(t)}}),t.dataRange&&(t.visualMap=t.dataRange),f(Hx,function(e){var n=t[e];n&&(_(n)||(n=[n]),f(n,function(t){rs(t)}))})},Gx=function(t){var e=N();t.eachSeries(function(t){var n=t.get("stack");if(n){var i=e.get(n)||e.set(n,[]),r=t.getData(),o={stackResultDimension:r.getCalculationInfo("stackResultDimension"),stackedOverDimension:r.getCalculationInfo("stackedOverDimension"),stackedDimension:r.getCalculationInfo("stackedDimension"),stackedByDimension:r.getCalculationInfo("stackedByDimension"),isStackedByIndex:r.getCalculationInfo("isStackedByIndex"),data:r,seriesModel:t};if(!o.stackedDimension||!o.isStackedByIndex&&!o.stackedByDimension)return;i.length&&r.setCalculationInfo("stackedOnSeries",i[i.length-1].seriesModel),i.push(o)}}),e.each(os)},Ux=as.prototype;Ux.pure=!1,Ux.persistent=!0,Ux.getSource=function(){return this._source};var Zx={arrayRows_column:{pure:!0,count:function(){return Math.max(0,this._data.length-this._source.startIndex)},getItem:function(t){return this._data[t+this._source.startIndex]},appendData:us},arrayRows_row:{pure:!0,count:function(){var t=this._data[0];return t?Math.max(0,t.length-this._source.startIndex):0},getItem:function(t){t+=this._source.startIndex;for(var e=[],n=this._data,i=0;i<n.length;i++){var r=n[i];e.push(r?r[t]:null)}return e},appendData:function(){throw new Error('Do not support appendData when set seriesLayoutBy: "row".')}},objectRows:{pure:!0,count:ss,getItem:ls,appendData:us},keyedColumns:{pure:!0,count:function(){var t=this._source.dimensionsDefine[0].name,e=this._data[t];return e?e.length:0},getItem:function(t){for(var e=[],n=this._source.dimensionsDefine,i=0;i<n.length;i++){var r=this._data[n[i].name];e.push(r?r[t]:null)}return e},appendData:function(t){var e=this._data;f(t,function(t,n){for(var i=e[n]||(e[n]=[]),r=0;r<(t||[]).length;r++)i.push(t[r])})}},original:{count:ss,getItem:ls,appendData:us},typedArray:{persistent:!1,pure:!0,count:function(){return this._data?this._data.length/this._dimSize:0},getItem:function(t,e){t-=this._offset,e=e||[];for(var n=this._dimSize*t,i=0;i<this._dimSize;i++)e[i]=this._data[n+i];return e},appendData:function(t){this._data=t},clean:function(){this._offset+=this.count(),this._data=null}}},jx={arrayRows:hs,objectRows:function(t,e,n,i){return null!=n?t[i]:t},keyedColumns:hs,original:function(t,e,n){var i=Ei(t);return null!=n&&i instanceof Array?i[n]:i},typedArray:hs},Xx={arrayRows:cs,objectRows:function(t,e){return ds(t[e],this._dimensionInfos[e])},keyedColumns:cs,original:function(t,e,n,i){var r=t&&(null==t.value?t:t.value);return!this._rawData.pure&&Ri(t)&&(this.hasItemOption=!0),ds(r instanceof Array?r[i]:r,this._dimensionInfos[e])},typedArray:function(t,e,n,i){return t[i]}},Yx=/\{@(.+?)\}/g,qx={getDataParams:function(t,e){var n=this.getData(e),i=this.getRawValue(t,e),r=n.getRawIndex(t),o=n.getName(t),a=n.getRawDataItem(t),s=n.getItemVisual(t,"color");return{componentType:this.mainType,componentSubType:this.subType,seriesType:"series"===this.mainType?this.subType:null,seriesIndex:this.seriesIndex,seriesId:this.id,seriesName:this.name,name:o,dataIndex:r,data:a,dataType:e,value:i,color:s,marker:aa(s),$vars:["seriesName","name","value"]}},getFormattedLabel:function(t,e,n,i,r){e=e||"normal";var o=this.getData(n),a=o.getItemModel(t),s=this.getDataParams(t,n);null!=i&&s.value instanceof Array&&(s.value=s.value[i]);var l=a.get("normal"===e?[r||"label","formatter"]:[e,r||"label","formatter"]);if("function"==typeof l)return s.status=e,l(s);if("string"==typeof l){var u=ra(l,s);return u.replace(Yx,function(e,n){var i=n.length;return"["===n.charAt(0)&&"]"===n.charAt(i-1)&&(n=+n.slice(1,i-1)),fs(o,t,n)})}},getRawValue:function(t,e){return fs(this.getData(e),t)},formatTooltip:function(){}},$x=vs.prototype;$x.perform=function(t){function e(t){return!(t>=1)&&(t=1),t}var n=this._upstream,i=t&&t.skip;if(this._dirty&&n){var r=this.context;r.data=r.outputData=n.context.outputData}this.__pipeline&&(this.__pipeline.currentTask=this);var o;this._plan&&!i&&(o=this._plan(this.context));var a=e(this._modBy),s=this._modDataCount||0,l=e(t&&t.modBy),u=t&&t.modDataCount||0;(a!==l||s!==u)&&(o="reset");var h;(this._dirty||"reset"===o)&&(this._dirty=!1,h=ys(this,i)),this._modBy=l,this._modDataCount=u;var c=t&&t.step;if(this._dueEnd=n?n._outputDueEnd:this._count?this._count(this.context):1/0,this._progress){var d=this._dueIndex,f=Math.min(null!=c?this._dueIndex+c:1/0,this._dueEnd);if(!i&&(h||f>d)){var p=this._progress;if(_(p))for(var g=0;g<p.length;g++)ms(this,p[g],d,f,l,u);else ms(this,p,d,f,l,u)}this._dueIndex=f;var v=null!=this._settedOutputEnd?this._settedOutputEnd:f;this._outputDueEnd=v}else this._dueIndex=this._outputDueEnd=null!=this._settedOutputEnd?this._settedOutputEnd:this._dueEnd;return this.unfinished()};var Kx=function(){function t(){return n>i?i++:null}function e(){var t=i%a*r+Math.ceil(i/a),e=i>=n?null:o>t?t:i;return i++,e}var n,i,r,o,a,s={reset:function(l,u,h,c){i=l,n=u,r=h,o=c,a=Math.ceil(o/r),s.next=r>1&&o>0?e:t}};return s}();$x.dirty=function(){this._dirty=!0,this._onDirty&&this._onDirty(this.context)},$x.unfinished=function(){return this._progress&&this._dueIndex<this._dueEnd},$x.pipe=function(t){(this._downstream!==t||this._dirty)&&(this._downstream=t,t._upstream=this,t.dirty())},$x.dispose=function(){this._disposed||(this._upstream&&(this._upstream._downstream=null),this._downstream&&(this._downstream._upstream=null),this._dirty=!1,this._disposed=!0)},$x.getUpstream=function(){return this._upstream},$x.getDownstream=function(){return this._downstream},$x.setOutputEnd=function(t){this._outputDueEnd=this._settedOutputEnd=t};var Qx=Hi(),Jx=cx.extend({type:"series.__base__",seriesIndex:0,coordinateSystem:null,defaultOption:null,legendDataProvider:null,visualColorAccessPath:"itemStyle.color",layoutMode:null,init:function(t,e,n){this.seriesIndex=this.componentIndex,this.dataTask=gs({count:ws,reset:bs}),this.dataTask.context={model:this},this.mergeDefaultAndTheme(t,n),Sa(this);var i=this.getInitialData(t,n);Ss(i,this),this.dataTask.context.data=i,Qx(this).dataBeforeProcessed=i,xs(this)},mergeDefaultAndTheme:function(t,e){var n=this.layoutMode,i=n?pa(t):{},o=this.subType;cx.hasClass(o)&&(o+="Series"),r(t,e.getTheme().get(this.subType)),r(t,this.getDefaultOption()),Oi(t,"label",["show"]),this.fillDataTextStyle(t.data),n&&fa(t,i,n)},mergeOption:function(t,e){t=r(this.option,t,!0),this.fillDataTextStyle(t.data);var n=this.layoutMode;n&&fa(this.option,t,n),Sa(this);var i=this.getInitialData(t,e);Ss(i,this),this.dataTask.dirty(),this.dataTask.context.data=i,Qx(this).dataBeforeProcessed=i,xs(this)},fillDataTextStyle:function(t){if(t&&!I(t))for(var e=["show"],n=0;n<t.length;n++)t[n]&&t[n].label&&Oi(t[n],"label",e)},getInitialData:function(){},appendData:function(t){var e=this.getRawData();e.appendData(t.data)},getData:function(t){var e=Cs(this);if(e){var n=e.context.data;return null==t?n:n.getLinkedData(t)}return Qx(this).data},setData:function(t){var e=Cs(this);if(e){var n=e.context;n.data!==t&&e.modifyOutputEnd&&e.setOutputEnd(t.count()),n.outputData=t,e!==this.dataTask&&(n.data=t)}Qx(this).data=t},getSource:function(){return ba(this)},getRawData:function(){return Qx(this).dataBeforeProcessed},getBaseAxis:function(){var t=this.coordinateSystem;return t&&t.getBaseAxis&&t.getBaseAxis()},formatTooltip:function(t,e){function n(n){function i(t,n){var i=r.getDimensionInfo(n);if(i&&i.otherDims.tooltip!==!1){var o=i.type,l=aa({color:u,type:"subItem"}),h=(a?l+ia(i.displayName||"-")+": ":"")+ia("ordinal"===o?t+"":"time"===o?e?"":la("yyyy/MM/dd hh:mm:ss",t):ea(t));h&&s.push(h)}}var a=g(n,function(t,e,n){var i=r.getDimensionInfo(n);return t|=i&&i.tooltip!==!1&&null!=i.displayName},0),s=[];return o.length?f(o,function(e){i(fs(r,t,e),e)}):f(n,i),(a?"<br/>":"")+s.join(a?"<br/>":", ")}function i(t){return ia(ea(t))}var r=this.getData(),o=r.mapDimension("defaultedTooltip",!0),a=o.length,s=this.getRawValue(t),l=_(s),u=r.getItemVisual(t,"color");M(u)&&u.colorStops&&(u=(u.colorStops[0]||{}).color),u=u||"transparent";var h=a>1||l&&!a?n(s):i(a?fs(r,t,o[0]):l?s[0]:s),c=aa(u),d=r.getName(t),p=this.name;return Ni(this)||(p=""),p=p?ia(p)+(e?": ":"<br/>"):"",e?c+p+h:p+c+(d?ia(d)+": "+h:h)},isAnimationEnabled:function(){if(Jp.node)return!1;var t=this.getShallow("animation");return t&&this.getData().count()>this.getShallow("animationThreshold")&&(t=!1),t},restoreData:function(){this.dataTask.dirty()},getColorFromPalette:function(t,e,n){var i=this.ecModel,r=gx.getColorFromPalette.call(this,t,e,n);return r||(r=i.getColorFromPalette(t,e,n)),r},coordDimToDataDim:function(t){return this.getRawData().mapDimension(t,!0)},getProgressive:function(){return this.get("progressive")},getProgressiveThreshold:function(){return this.get("progressiveThreshold")},getAxisTooltipData:null,getTooltipPosition:null,pipeTask:null,preventIncremental:null,pipelineContext:null});c(Jx,qx),c(Jx,gx);var t_=function(){this.group=new nv,this.uid=Ro("viewComponent")};t_.prototype={constructor:t_,init:function(){},render:function(){},dispose:function(){}};var e_=t_.prototype;e_.updateView=e_.updateLayout=e_.updateVisual=function(){},Yi(t_),Qi(t_,{registerWhenExtend:!0});var n_=function(){var t=Hi();return function(e){var n=t(e),i=e.pipelineContext,r=n.large,o=n.progressiveRender,a=n.large=i.large,s=n.progressiveRender=i.progressiveRender;return!!(r^a||o^s)&&"reset"}},i_=Hi(),r_=n_();Ts.prototype={type:"chart",init:function(){},render:function(){},highlight:function(t,e,n,i){Ds(t.getData(),i,"emphasis")},downplay:function(t,e,n,i){Ds(t.getData(),i,"normal")},remove:function(){this.group.removeAll()},dispose:function(){},incrementalPrepareRender:null,incrementalRender:null,updateTransform:null};var o_=Ts.prototype;o_.updateView=o_.updateLayout=o_.updateVisual=function(t,e,n,i){this.render(t,e,n,i)},Yi(Ts,["dispose"]),Qi(Ts,{registerWhenExtend:!0}),Ts.markUpdateMethod=function(t,e){i_(t).updateMethod=e};var a_={incrementalPrepareRender:{progress:function(t,e){e.view.incrementalRender(t,e.model,e.ecModel,e.api,e.payload)}},render:{forceFirstProgress:!0,progress:function(t,e){e.view.render(e.model,e.ecModel,e.api,e.payload)}}},s_="\x00__throttleOriginMethod",l_="\x00__throttleRate",u_="\x00__throttleType",h_={createOnAllSeries:!0,performRawSeries:!0,reset:function(t,e){var n=t.getData(),i=(t.visualColorAccessPath||"itemStyle.color").split("."),r=t.get(i)||t.getColorFromPalette(t.name,null,e.getSeriesCount());if(n.setVisual("color",r),!e.isSeriesFiltered(t)){"function"!=typeof r||r instanceof ky||n.each(function(e){n.setItemVisual(e,"color",r(t.getDataParams(e)))});var o=function(t,e){var n=t.getItemModel(e),r=n.get(i,!0);null!=r&&t.setItemVisual(e,"color",r)};return{dataEach:n.hasItemOption?o:null}}}},c_={toolbox:{brush:{title:{rect:"矩形选择",polygon:"圈选",lineX:"横向选择",lineY:"纵向选择",keep:"保持选择",clear:"清除选择"}},dataView:{title:"数据视图",lang:["数据视图","关闭","刷新"]},dataZoom:{title:{zoom:"区域缩放",back:"区域缩放还原"}},magicType:{title:{line:"切换为折线图",bar:"切换为柱状图",stack:"切换为堆叠",tiled:"切换为平铺"}},restore:{title:"还原"},saveAsImage:{title:"保存为图片",lang:["右键另存为图片"]}},series:{typeNames:{pie:"饼图",bar:"柱状图",line:"折线图",scatter:"散点图",effectScatter:"涟漪散点图",radar:"雷达图",tree:"树图",treemap:"矩形树图",boxplot:"箱型图",candlestick:"K线图",k:"K线图",heatmap:"热力图",map:"地图",parallel:"平行坐标图",lines:"线图",graph:"关系图",sankey:"桑基图",funnel:"漏斗图",gauge:"仪表盘图",pictorialBar:"象形柱图",themeRiver:"主题河流图",sunburst:"旭日图"}},aria:{general:{withTitle:"这是一个关于“{title}”的图表。",withoutTitle:"这是一个图表，"},series:{single:{prefix:"",withName:"图表类型是{seriesType}，表示{seriesName}。",withoutName:"图表类型是{seriesType}。"},multiple:{prefix:"它由{seriesCount}个图表系列组成。",withName:"第{seriesId}个系列是一个表示{seriesName}的{seriesType}，",withoutName:"第{seriesId}个系列是一个{seriesType}，",separator:{middle:"；",end:"。"}}},data:{allData:"其数据是——",partialData:"其中，前{displayCnt}项是——",withName:"{name}的数据是{value}",withoutName:"{value}",separator:{middle:"，",end:""}}}},d_=function(t,e){function n(t,e){if("string"!=typeof t)return t;var n=t;return f(e,function(t,e){n=n.replace(new RegExp("\\{\\s*"+e+"\\s*\\}","g"),t)}),n}function i(t){var e=a.get(t);if(null==e){for(var n=t.split("."),i=c_.aria,r=0;r<n.length;++r)i=i[n[r]];return i}return e}function r(){var t=e.getModel("title").option;return t&&t.length&&(t=t[0]),t&&t.text}function o(t){return c_.series.typeNames[t]||"自定义图"}var a=e.getModel("aria");if(a.get("show")){if(a.get("description"))return void t.setAttribute("aria-label",a.get("description"));var s=0;e.eachSeries(function(){++s},this);var l,u=a.get("data.maxCount")||10,h=a.get("series.maxCount")||10,c=Math.min(s,h);if(!(1>s)){var d=r();l=d?n(i("general.withTitle"),{title:d}):i("general.withoutTitle");var p=[],g=s>1?"series.multiple.prefix":"series.single.prefix";l+=n(i(g),{seriesCount:s}),e.eachSeries(function(t,e){if(c>e){var r,a=t.get("name"),l="series."+(s>1?"multiple":"single")+".";r=i(a?l+"withName":l+"withoutName"),r=n(r,{seriesId:t.seriesIndex,seriesName:t.get("name"),seriesType:o(t.subType)});var h=t.getData();window.data=h,r+=h.count()>u?n(i("data.partialData"),{displayCnt:u}):i("data.allData");for(var d=[],f=0;f<h.count();f++)if(u>f){var g=h.getName(f),v=fs(h,f);d.push(n(i(g?"data.withName":"data.withoutName"),{name:g,value:v}))}r+=d.join(i("data.separator.middle"))+i("data.separator.end"),p.push(r)}}),l+=p.join(i("series.multiple.separator.middle"))+i("series.multiple.separator.end"),t.setAttribute("aria-label",l)}}},f_=Math.PI,p_=function(t,e){e=e||{},s(e,{text:"loading",color:"#c23531",textColor:"#000",maskColor:"rgba(255, 255, 255, 0.8)",zlevel:0});var n=new Sy({style:{fill:e.maskColor},zlevel:e.zlevel,z:1e4}),i=new Ay({shape:{startAngle:-f_/2,endAngle:-f_/2+.1,r:10},style:{stroke:e.color,lineCap:"round",lineWidth:5},zlevel:e.zlevel,z:10001}),r=new Sy({style:{fill:"none",text:e.text,textPosition:"right",textDistance:10,textFill:e.textColor},zlevel:e.zlevel,z:10001});i.animateShape(!0).when(1e3,{endAngle:3*f_/2}).start("circularInOut"),i.animateShape(!0).when(1e3,{startAngle:3*f_/2}).delay(300).start("circularInOut");var o=new nv;return o.add(i),o.add(r),o.add(n),o.resize=function(){var e=t.getWidth()/2,o=t.getHeight()/2;i.setShape({cx:e,cy:o});var a=i.shape.r;r.setShape({x:e-a,y:o-a,width:2*a,height:2*a}),n.setShape({x:0,y:0,width:t.getWidth(),height:t.getHeight()})},o.resize(),o},g_=Es.prototype;g_.restoreData=function(t,e){t.restoreData(e),this._stageTaskMap.each(function(t){var e=t.overallTask;e&&e.dirty()})},g_.getPerformArgs=function(t,e){if(t.__pipeline){var n=this._pipelineMap.get(t.__pipeline.id),i=n.context,r=!e&&n.progressiveEnabled&&(!i||i.progressiveRender)&&t.__idxInPipeline>n.blockIndex,o=r?n.step:null,a=i&&i.modDataCount,s=null!=a?Math.ceil(a/o):null;return{step:o,modBy:s,modDataCount:a}}},g_.getPipeline=function(t){return this._pipelineMap.get(t)},g_.updateStreamModes=function(t,e){var n=this._pipelineMap.get(t.uid),i=t.getData(),r=i.count(),o=n.progressiveEnabled&&e.incrementalPrepareRender&&r>=n.threshold,a=t.get("large")&&r>=t.get("largeThreshold"),s="mod"===t.get("progressiveChunkMode")?r:null;t.pipelineContext=n.context={progressiveRender:o,modDataCount:s,large:a}},g_.restorePipelines=function(t){var e=this,n=e._pipelineMap=N();t.eachSeries(function(t){var i=t.getProgressive(),r=t.uid;n.set(r,{id:r,head:null,tail:null,threshold:t.getProgressiveThreshold(),progressiveEnabled:i&&!(t.preventIncremental&&t.preventIncremental()),blockIndex:-1,step:Math.round(i||700),count:0}),js(e,t,t.dataTask)})},g_.prepareStageTasks=function(){var t=this._stageTaskMap,e=this.ecInstance.getModel(),n=this.api;f(this._allHandlers,function(i){var r=t.get(i.uid)||t.set(i.uid,[]);i.reset&&zs(this,i,r,e,n),i.overallReset&&Bs(this,i,r,e,n)},this)},g_.prepareView=function(t,e,n,i){var r=t.renderTask,o=r.context;o.model=e,o.ecModel=n,o.api=i,r.__block=!t.incrementalPrepareRender,js(this,e,r)},g_.performDataProcessorTasks=function(t,e){Rs(this,this._dataProcessorHandlers,t,e,{block:!0})},g_.performVisualTasks=function(t,e,n){Rs(this,this._visualHandlers,t,e,n)},g_.performSeriesTasks=function(t){var e;t.eachSeries(function(t){e|=t.dataTask.perform()}),this.unfinished|=e},g_.plan=function(){this._pipelineMap.each(function(t){var e=t.tail;do{if(e.__block){t.blockIndex=e.__idxInPipeline;break}e=e.getUpstream()}while(e)})};var v_=g_.updatePayload=function(t,e){"remain"!==e&&(t.context.payload=e)},m_=Us(0);Es.wrapStageHandler=function(t,e){return w(t)&&(t={overallReset:t,seriesType:Xs(t)}),t.uid=Ro("stageHandler"),e&&(t.visualType=e),t};var y_,x_={},__={};Ys(x_,Ax),Ys(__,Fa),x_.eachSeriesByType=x_.eachRawSeriesByType=function(t){y_=t},x_.eachComponent=function(t){"series"===t.mainType&&t.subType&&(y_=t.subType)};var w_=["#37A2DA","#32C5E9","#67E0E3","#9FE6B8","#FFDB5C","#ff9f7f","#fb7293","#E062AE","#E690D1","#e7bcf3","#9d96f5","#8378EA","#96BFFF"],b_={color:w_,colorLayer:[["#37A2DA","#ffd85c","#fd7b5f"],["#37A2DA","#67E0E3","#FFDB5C","#ff9f7f","#E062AE","#9d96f5"],["#37A2DA","#32C5E9","#9FE6B8","#FFDB5C","#ff9f7f","#fb7293","#e7bcf3","#8378EA","#96BFFF"],w_]},M_="#eee",S_=function(){return{axisLine:{lineStyle:{color:M_}},axisTick:{lineStyle:{color:M_}},axisLabel:{textStyle:{color:M_}},splitLine:{lineStyle:{type:"dashed",color:"#aaa"}},splitArea:{areaStyle:{color:M_}}}},I_=["#dd6b66","#759aa0","#e69d87","#8dc1a9","#ea7e53","#eedd78","#73a373","#73b9bc","#7289ab","#91ca8c","#f49f42"],C_={color:I_,backgroundColor:"#333",tooltip:{axisPointer:{lineStyle:{color:M_},crossStyle:{color:M_}}},legend:{textStyle:{color:M_}},textStyle:{color:M_},title:{textStyle:{color:M_}},toolbox:{iconStyle:{normal:{borderColor:M_}}},dataZoom:{textStyle:{color:M_}},visualMap:{textStyle:{color:M_}},timeline:{lineStyle:{color:M_},itemStyle:{normal:{color:I_[1]}},label:{normal:{textStyle:{color:M_}}},controlStyle:{normal:{color:M_,borderColor:M_}}},timeAxis:S_(),logAxis:S_(),valueAxis:S_(),categoryAxis:S_(),line:{symbol:"circle"},graph:{color:I_},gauge:{title:{textStyle:{color:M_}}},candlestick:{itemStyle:{normal:{color:"#FD1050",color0:"#0CF49B",borderColor:"#FD1050",borderColor0:"#0CF49B"}}}};C_.categoryAxis.splitLine.show=!1,cx.extend({type:"dataset",defaultOption:{seriesLayoutBy:Sx,sourceHeader:null,dimensions:null,source:null},optionUpdated:function(){wa(this)}}),t_.extend({type:"dataset"});var T_=O,A_=f,D_=w,k_=M,P_=cx.parseClassType,L_="4.1.0",O_={zrender:"4.0.4"},E_=1,R_=1e3,z_=5e3,B_=1e3,N_=2e3,V_=3e3,F_=4e3,H_=5e3,W_={PROCESSOR:{FILTER:R_,STATISTIC:z_},VISUAL:{LAYOUT:B_,GLOBAL:N_,CHART:V_,COMPONENT:F_,BRUSH:H_}},G_="__flagInMainProcess",U_="__optionUpdated",Z_=/^[a-zA-Z0-9_]+$/;$s.prototype.on=qs("on"),$s.prototype.off=qs("off"),$s.prototype.one=qs("one"),c($s,wg);var j_=Ks.prototype;j_._onframe=function(){if(!this._disposed){var t=this._scheduler;if(this[U_]){var e=this[U_].silent;this[G_]=!0,Js(this),X_.update.call(this),this[G_]=!1,this[U_]=!1,il.call(this,e),rl.call(this,e)}else if(t.unfinished){var n=E_,i=this._model,r=this._api;t.unfinished=!1;do{var o=+new Date;t.performSeriesTasks(i),t.performDataProcessorTasks(i),el(this,i),t.performVisualTasks(i),hl(this,this._model,r,"remain"),n-=+new Date-o}while(n>0&&t.unfinished);t.unfinished||this._zr.flush()}}},j_.getDom=function(){return this._dom},j_.getZr=function(){return this._zr},j_.setOption=function(t,e,n){var i;if(k_(e)&&(n=e.lazyUpdate,i=e.silent,e=e.notMerge),this[G_]=!0,!this._model||e){var r=new Wa(this._api),o=this._theme,a=this._model=new Ax(null,null,o,r);
+a.scheduler=this._scheduler,a.init(null,null,o,r)}this._model.setOption(t,Q_),n?(this[U_]={silent:i},this[G_]=!1):(Js(this),X_.update.call(this),this._zr.flush(),this[U_]=!1,this[G_]=!1,il.call(this,i),rl.call(this,i))},j_.setTheme=function(){console.log("ECharts#setTheme() is DEPRECATED in ECharts 3.0")},j_.getModel=function(){return this._model},j_.getOption=function(){return this._model&&this._model.getOption()},j_.getWidth=function(){return this._zr.getWidth()},j_.getHeight=function(){return this._zr.getHeight()},j_.getDevicePixelRatio=function(){return this._zr.painter.dpr||window.devicePixelRatio||1},j_.getRenderedCanvas=function(t){if(Jp.canvasSupported){t=t||{},t.pixelRatio=t.pixelRatio||1,t.backgroundColor=t.backgroundColor||this._model.get("backgroundColor");var e=this._zr;return e.painter.getRenderedCanvas(t)}},j_.getSvgDataUrl=function(){if(Jp.svgSupported){var t=this._zr,e=t.storage.getDisplayList();return f(e,function(t){t.stopAnimation(!0)}),t.painter.pathToDataUrl()}},j_.getDataURL=function(t){t=t||{};var e=t.excludeComponents,n=this._model,i=[],r=this;A_(e,function(t){n.eachComponent({mainType:t},function(t){var e=r._componentsMap[t.__viewId];e.group.ignore||(i.push(e),e.group.ignore=!0)})});var o="svg"===this._zr.painter.getType()?this.getSvgDataUrl():this.getRenderedCanvas(t).toDataURL("image/"+(t&&t.type||"png"));return A_(i,function(t){t.group.ignore=!1}),o},j_.getConnectedDataURL=function(t){if(Jp.canvasSupported){var e=this.group,n=Math.min,r=Math.max,o=1/0;if(rw[e]){var a=o,s=o,l=-o,u=-o,h=[],c=t&&t.pixelRatio||1;f(iw,function(o){if(o.group===e){var c=o.getRenderedCanvas(i(t)),d=o.getDom().getBoundingClientRect();a=n(d.left,a),s=n(d.top,s),l=r(d.right,l),u=r(d.bottom,u),h.push({dom:c,left:d.left,top:d.top})}}),a*=c,s*=c,l*=c,u*=c;var d=l-a,p=u-s,g=hg();g.width=d,g.height=p;var v=Ti(g);return A_(h,function(t){var e=new ai({style:{x:t.left*c-a,y:t.top*c-s,image:t.dom}});v.add(e)}),v.refreshImmediately(),g.toDataURL("image/"+(t&&t.type||"png"))}return this.getDataURL(t)}},j_.convertToPixel=x(Qs,"convertToPixel"),j_.convertFromPixel=x(Qs,"convertFromPixel"),j_.containPixel=function(t,e){var n,i=this._model;return t=Wi(i,t),f(t,function(t,i){i.indexOf("Models")>=0&&f(t,function(t){var r=t.coordinateSystem;if(r&&r.containPoint)n|=!!r.containPoint(e);else if("seriesModels"===i){var o=this._chartsMap[t.__viewId];o&&o.containPoint&&(n|=o.containPoint(e,t))}},this)},this),!!n},j_.getVisual=function(t,e){var n=this._model;t=Wi(n,t,{defaultMainType:"series"});var i=t.seriesModel,r=i.getData(),o=t.hasOwnProperty("dataIndexInside")?t.dataIndexInside:t.hasOwnProperty("dataIndex")?r.indexOfRawIndex(t.dataIndex):null;return null!=o?r.getItemVisual(o,e):r.getVisual(e)},j_.getViewOfComponentModel=function(t){return this._componentsMap[t.__viewId]},j_.getViewOfSeriesModel=function(t){return this._chartsMap[t.__viewId]};var X_={prepareAndUpdate:function(t){Js(this),X_.update.call(this,t)},update:function(t){var e=this._model,n=this._api,i=this._zr,r=this._coordSysMgr,o=this._scheduler;if(e){o.restoreData(e,t),o.performSeriesTasks(e),r.create(e,n),o.performDataProcessorTasks(e,t),el(this,e),r.update(e,n),sl(e),o.performVisualTasks(e,t),ll(this,e,n,t);var a=e.get("backgroundColor")||"transparent";if(Jp.canvasSupported)i.setBackgroundColor(a);else{var s=Ee(a);a=Ge(s,"rgb"),0===s[3]&&(a="transparent")}cl(e,n)}},updateTransform:function(t){var e=this._model,n=this,i=this._api;if(e){var r=[];e.eachComponent(function(o,a){var s=n.getViewOfComponentModel(a);if(s&&s.__alive)if(s.updateTransform){var l=s.updateTransform(a,e,i,t);l&&l.update&&r.push(s)}else r.push(s)});var o=N();e.eachSeries(function(r){var a=n._chartsMap[r.__viewId];if(a.updateTransform){var s=a.updateTransform(r,e,i,t);s&&s.update&&o.set(r.uid,1)}else o.set(r.uid,1)}),sl(e),this._scheduler.performVisualTasks(e,t,{setDirty:!0,dirtyMap:o}),hl(n,e,i,t,o),cl(e,this._api)}},updateView:function(t){var e=this._model;e&&(Ts.markUpdateMethod(t,"updateView"),sl(e),this._scheduler.performVisualTasks(e,t,{setDirty:!0}),ll(this,this._model,this._api,t),cl(e,this._api))},updateVisual:function(t){X_.update.call(this,t)},updateLayout:function(t){X_.update.call(this,t)}};j_.resize=function(t){this._zr.resize(t);var e=this._model;if(this._loadingFX&&this._loadingFX.resize(),e){var n=e.resetOption("media"),i=t&&t.silent;this[G_]=!0,n&&Js(this),X_.update.call(this),this[G_]=!1,il.call(this,i),rl.call(this,i)}},j_.showLoading=function(t,e){if(k_(t)&&(e=t,t=""),t=t||"default",this.hideLoading(),nw[t]){var n=nw[t](this._api,e),i=this._zr;this._loadingFX=n,i.add(n)}},j_.hideLoading=function(){this._loadingFX&&this._zr.remove(this._loadingFX),this._loadingFX=null},j_.makeActionFromEvent=function(t){var e=a({},t);return e.type=$_[t.type],e},j_.dispatchAction=function(t,e){if(k_(e)||(e={silent:!!e}),q_[t.type]&&this._model){if(this[G_])return void this._pendingActions.push(t);nl.call(this,t,e.silent),e.flush?this._zr.flush(!0):e.flush!==!1&&Jp.browser.weChat&&this._throttledZrFlush(),il.call(this,e.silent),rl.call(this,e.silent)}},j_.appendData=function(t){var e=t.seriesIndex,n=this.getModel(),i=n.getSeriesByIndex(e);i.appendData(t),this._scheduler.unfinished=!0},j_.on=qs("on"),j_.off=qs("off"),j_.one=qs("one");var Y_=["click","dblclick","mouseover","mouseout","mousemove","mousedown","mouseup","globalout","contextmenu"];j_._initEvents=function(){A_(Y_,function(t){this._zr.on(t,function(e){var n,i=this.getModel(),r=e.target;if("globalout"===t)n={};else if(r&&null!=r.dataIndex){var o=r.dataModel||i.getSeriesByIndex(r.seriesIndex);n=o&&o.getDataParams(r.dataIndex,r.dataType)||{}}else r&&r.eventData&&(n=a({},r.eventData));n&&(n.event=e,n.type=t,this.trigger(t,n))},this)},this),A_($_,function(t,e){this._messageCenter.on(e,function(t){this.trigger(e,t)},this)},this)},j_.isDisposed=function(){return this._disposed},j_.clear=function(){this.setOption({series:[]},!0)},j_.dispose=function(){if(!this._disposed){this._disposed=!0,Ui(this.getDom(),sw,"");var t=this._api,e=this._model;A_(this._componentsViews,function(n){n.dispose(e,t)}),A_(this._chartsViews,function(n){n.dispose(e,t)}),this._zr.dispose(),delete iw[this.id]}},c(Ks,wg);var q_={},$_={},K_=[],Q_=[],J_=[],tw=[],ew={},nw={},iw={},rw={},ow=new Date-0,aw=new Date-0,sw="_echarts_instance_",lw={},uw=xl;Pl(N_,h_),Sl(Wx),Il(z_,Gx),Ol("default",p_),Tl({type:"highlight",event:"highlight",update:"highlight"},F),Tl({type:"downplay",event:"downplay",update:"downplay"},F),Ml("light",b_),Ml("dark",C_);var hw={};Wl.prototype={constructor:Wl,add:function(t){return this._add=t,this},update:function(t){return this._update=t,this},remove:function(t){return this._remove=t,this},execute:function(){var t,e=this._old,n=this._new,i={},r={},o=[],a=[];for(Gl(e,i,o,"_oldKeyGetter",this),Gl(n,r,a,"_newKeyGetter",this),t=0;t<e.length;t++){var s=o[t],l=r[s];if(null!=l){var u=l.length;u?(1===u&&(r[s]=null),l=l.unshift()):r[s]=null,this._update&&this._update(l,t)}else this._remove&&this._remove(t)}for(var t=0;t<a.length;t++){var s=a[t];if(r.hasOwnProperty(s)){var l=r[s];if(null==l)continue;if(l.length)for(var h=0,u=l.length;u>h;h++)this._add&&this._add(l[h]);else this._add&&this._add(l)}}}};var cw=N(["tooltip","label","itemName","itemId","seriesName"]),dw=M,fw="undefined",pw="e\x00\x00",gw={"float":typeof Float64Array===fw?Array:Float64Array,"int":typeof Int32Array===fw?Array:Int32Array,ordinal:Array,number:Array,time:Array},vw=typeof Uint32Array===fw?Array:Uint32Array,mw=typeof Uint16Array===fw?Array:Uint16Array,yw=["hasItemOption","_nameList","_idList","_invertedIndicesMap","_rawData","_chunkSize","_chunkCount","_dimValueGetter","_count","_rawCount","_nameDimIdx","_idDimIdx"],xw=["_extent","_approximateExtent","_rawExtent"],_w=function(t,e){t=t||["x","y"];for(var n={},i=[],r={},o=0;o<t.length;o++){var a=t[o];b(a)&&(a={name:a});var s=a.name;a.type=a.type||"float",a.coordDim||(a.coordDim=s,a.coordDimIndex=0),a.otherDims=a.otherDims||{},i.push(s),n[s]=a,a.index=o,a.createInvertedIndices&&(r[s]=[])}this.dimensions=i,this._dimensionInfos=n,this.hostModel=e,this.dataType,this._indices=null,this._count=0,this._rawCount=0,this._storage={},this._nameList=[],this._idList=[],this._optionModels=[],this._visual={},this._layout={},this._itemVisuals=[],this.hasItemVisual={},this._itemLayouts=[],this._graphicEls=[],this._chunkSize=1e5,this._chunkCount=0,this._rawData,this._rawExtent={},this._extent={},this._approximateExtent={},this._dimensionsSummary=Ul(this),this._invertedIndicesMap=r,this._calculationInfo={}},ww=_w.prototype;ww.type="list",ww.hasItemOption=!0,ww.getDimension=function(t){return isNaN(t)||(t=this.dimensions[t]||t),t},ww.getDimensionInfo=function(t){return this._dimensionInfos[this.getDimension(t)]},ww.getDimensionsOnCoord=function(){return this._dimensionsSummary.dataDimsOnCoord.slice()},ww.mapDimension=function(t,e){var n=this._dimensionsSummary;if(null==e)return n.encodeFirstDimNotExtra[t];var i=n.encode[t];return e===!0?(i||[]).slice():i&&i[e]},ww.initData=function(t,e,n){var i=_a.isInstance(t)||d(t);i&&(t=new as(t,this.dimensions.length)),this._rawData=t,this._storage={},this._indices=null,this._nameList=e||[],this._idList=[],this._nameRepeatCount={},n||(this.hasItemOption=!1),this.defaultDimValueGetter=Xx[this._rawData.getSource().sourceFormat],this._dimValueGetter=n=n||this.defaultDimValueGetter,this._rawExtent={},this._initDataFromProvider(0,t.count()),t.pure&&(this.hasItemOption=!1)},ww.getProvider=function(){return this._rawData},ww.appendData=function(t){var e=this._rawData,n=this.count();e.appendData(t);var i=e.count();e.persistent||(i+=n),this._initDataFromProvider(n,i)},ww._initDataFromProvider=function(t,e){if(!(t>=e)){for(var n,i=this._chunkSize,r=this._rawData,o=this._storage,a=this.dimensions,s=a.length,l=this._dimensionInfos,u=this._nameList,h=this._idList,c=this._rawExtent,d=this._nameRepeatCount={},f=this._chunkCount,p=f-1,g=0;s>g;g++){var v=a[g];c[v]||(c[v]=ru());var m=l[v];0===m.otherDims.itemName&&(n=this._nameDimIdx=g),0===m.otherDims.itemId&&(this._idDimIdx=g);var y=gw[m.type];o[v]||(o[v]=[]);var x=o[v][p];if(x&&x.length<i){for(var _=new y(Math.min(e-p*i,i)),w=0;w<x.length;w++)_[w]=x[w];o[v][p]=_}for(var b=f*i;e>b;b+=i)o[v].push(new y(Math.min(e-b,i)));this._chunkCount=o[v].length}for(var M=new Array(s),S=t;e>S;S++){M=r.getItem(S,M);for(var I=Math.floor(S/i),C=S%i,b=0;s>b;b++){var v=a[b],T=o[v][I],A=this._dimValueGetter(M,v,S,b);T[C]=A;var D=c[v];A<D[0]&&(D[0]=A),A>D[1]&&(D[1]=A)}if(!r.pure){var k=u[S];if(M&&null==k)if(null!=M.name)u[S]=k=M.name;else if(null!=n){var P=a[n],L=o[P][I];if(L){k=L[C];var O=l[P].ordinalMeta;O&&O.categories.length&&(k=O.categories[k])}}var E=null==M?null:M.id;null==E&&null!=k&&(d[k]=d[k]||0,E=k,d[k]>0&&(E+="__ec__"+d[k]),d[k]++),null!=E&&(h[S]=E)}}!r.persistent&&r.clean&&r.clean(),this._rawCount=this._count=e,this._extent={},$l(this)}},ww.count=function(){return this._count},ww.getIndices=function(){var t,e=this._indices;if(e){var n=e.constructor,i=this._count;if(n===Array){t=new n(i);for(var r=0;i>r;r++)t[r]=e[r]}else t=new n(e.buffer,0,i)}else for(var n=Xl(this),t=new n(this.count()),r=0;r<t.length;r++)t[r]=r;return t},ww.get=function(t,e){if(!(e>=0&&e<this._count))return 0/0;var n=this._storage;if(!n[t])return 0/0;e=this.getRawIndex(e);var i=Math.floor(e/this._chunkSize),r=e%this._chunkSize,o=n[t][i],a=o[r];return a},ww.getByRawIndex=function(t,e){if(!(e>=0&&e<this._rawCount))return 0/0;var n=this._storage[t];if(!n)return 0/0;var i=Math.floor(e/this._chunkSize),r=e%this._chunkSize,o=n[i];return o[r]},ww._getFast=function(t,e){var n=Math.floor(e/this._chunkSize),i=e%this._chunkSize,r=this._storage[t][n];return r[i]},ww.getValues=function(t,e){var n=[];_(t)||(e=t,t=this.dimensions);for(var i=0,r=t.length;r>i;i++)n.push(this.get(t[i],e));return n},ww.hasValue=function(t){for(var e=this._dimensionsSummary.dataDimsOnCoord,n=this._dimensionInfos,i=0,r=e.length;r>i;i++)if("ordinal"!==n[e[i]].type&&isNaN(this.get(e[i],t)))return!1;return!0},ww.getDataExtent=function(t){t=this.getDimension(t);var e=this._storage[t],n=ru();if(!e)return n;var i,r=this.count(),o=!this._indices;if(o)return this._rawExtent[t].slice();if(i=this._extent[t])return i.slice();i=n;for(var a=i[0],s=i[1],l=0;r>l;l++){var u=this._getFast(t,this.getRawIndex(l));a>u&&(a=u),u>s&&(s=u)}return i=[a,s],this._extent[t]=i,i},ww.getApproximateExtent=function(t){return t=this.getDimension(t),this._approximateExtent[t]||this.getDataExtent(t)},ww.setApproximateExtent=function(t,e){e=this.getDimension(e),this._approximateExtent[e]=t.slice()},ww.getCalculationInfo=function(t){return this._calculationInfo[t]},ww.setCalculationInfo=function(t,e){dw(t)?a(this._calculationInfo,t):this._calculationInfo[t]=e},ww.getSum=function(t){var e=this._storage[t],n=0;if(e)for(var i=0,r=this.count();r>i;i++){var o=this.get(t,i);isNaN(o)||(n+=o)}return n},ww.getMedian=function(t){var e=[];this.each(t,function(t){isNaN(t)||e.push(t)});var n=[].concat(e).sort(function(t,e){return t-e}),i=this.count();return 0===i?0:i%2===1?n[(i-1)/2]:(n[i/2]+n[i/2-1])/2},ww.rawIndexOf=function(t,e){var n=t&&this._invertedIndicesMap[t],i=n[e];return null==i||isNaN(i)?-1:i},ww.indexOfName=function(t){for(var e=0,n=this.count();n>e;e++)if(this.getName(e)===t)return e;return-1},ww.indexOfRawIndex=function(t){if(!this._indices)return t;if(t>=this._rawCount||0>t)return-1;var e=this._indices,n=e[t];if(null!=n&&n<this._count&&n===t)return t;for(var i=0,r=this._count-1;r>=i;){var o=(i+r)/2|0;if(e[o]<t)i=o+1;else{if(!(e[o]>t))return o;r=o-1}}return-1},ww.indicesOfNearest=function(t,e,n){var i=this._storage,r=i[t],o=[];if(!r)return o;null==n&&(n=1/0);for(var a=Number.MAX_VALUE,s=-1,l=0,u=this.count();u>l;l++){var h=e-this.get(t,l),c=Math.abs(h);n>=h&&a>=c&&((a>c||h>=0&&0>s)&&(a=c,s=h,o.length=0),o.push(l))}return o},ww.getRawIndex=Ql,ww.getRawDataItem=function(t){if(this._rawData.persistent)return this._rawData.getItem(this.getRawIndex(t));for(var e=[],n=0;n<this.dimensions.length;n++){var i=this.dimensions[n];e.push(this.get(i,t))}return e},ww.getName=function(t){var e=this.getRawIndex(t);return this._nameList[e]||Kl(this,this._nameDimIdx,e)||""},ww.getId=function(t){return tu(this,this.getRawIndex(t))},ww.each=function(t,e,n,i){if(this._count){"function"==typeof t&&(i=n,n=e,e=t,t=[]),n=n||i||this,t=p(eu(t),this.getDimension,this);for(var r=t.length,o=0;o<this.count();o++)switch(r){case 0:e.call(n,o);break;case 1:e.call(n,this.get(t[0],o),o);break;case 2:e.call(n,this.get(t[0],o),this.get(t[1],o),o);break;default:for(var a=0,s=[];r>a;a++)s[a]=this.get(t[a],o);s[a]=o,e.apply(n,s)}}},ww.filterSelf=function(t,e,n,i){if(this._count){"function"==typeof t&&(i=n,n=e,e=t,t=[]),n=n||i||this,t=p(eu(t),this.getDimension,this);for(var r=this.count(),o=Xl(this),a=new o(r),s=[],l=t.length,u=0,h=t[0],c=0;r>c;c++){var d,f=this.getRawIndex(c);if(0===l)d=e.call(n,c);else if(1===l){var g=this._getFast(h,f);d=e.call(n,g,c)}else{for(var v=0;l>v;v++)s[v]=this._getFast(h,f);s[v]=c,d=e.apply(n,s)}d&&(a[u++]=f)}return r>u&&(this._indices=a),this._count=u,this._extent={},this.getRawIndex=this._indices?Jl:Ql,this}},ww.selectRange=function(t){if(this._count){var e=[];for(var n in t)t.hasOwnProperty(n)&&e.push(n);var i=e.length;if(i){var r=this.count(),o=Xl(this),a=new o(r),s=0,l=e[0],u=t[l][0],h=t[l][1],c=!1;if(!this._indices){var d=0;if(1===i){for(var f=this._storage[e[0]],p=0;p<this._chunkCount;p++)for(var g=f[p],v=Math.min(this._count-p*this._chunkSize,this._chunkSize),m=0;v>m;m++){var y=g[m];(y>=u&&h>=y||isNaN(y))&&(a[s++]=d),d++}c=!0}else if(2===i){for(var f=this._storage[l],x=this._storage[e[1]],_=t[e[1]][0],w=t[e[1]][1],p=0;p<this._chunkCount;p++)for(var g=f[p],b=x[p],v=Math.min(this._count-p*this._chunkSize,this._chunkSize),m=0;v>m;m++){var y=g[m],M=b[m];(y>=u&&h>=y||isNaN(y))&&(M>=_&&w>=M||isNaN(M))&&(a[s++]=d),d++}c=!0}}if(!c)if(1===i)for(var m=0;r>m;m++){var S=this.getRawIndex(m),y=this._getFast(l,S);(y>=u&&h>=y||isNaN(y))&&(a[s++]=S)}else for(var m=0;r>m;m++){for(var I=!0,S=this.getRawIndex(m),p=0;i>p;p++){var C=e[p],y=this._getFast(n,S);(y<t[C][0]||y>t[C][1])&&(I=!1)}I&&(a[s++]=this.getRawIndex(m))}return r>s&&(this._indices=a),this._count=s,this._extent={},this.getRawIndex=this._indices?Jl:Ql,this}}},ww.mapArray=function(t,e,n,i){"function"==typeof t&&(i=n,n=e,e=t,t=[]),n=n||i||this;var r=[];return this.each(t,function(){r.push(e&&e.apply(this,arguments))},n),r},ww.map=function(t,e,n,i){n=n||i||this,t=p(eu(t),this.getDimension,this);var r=nu(this,t);r._indices=this._indices,r.getRawIndex=r._indices?Jl:Ql;for(var o=r._storage,a=[],s=this._chunkSize,l=t.length,u=this.count(),h=[],c=r._rawExtent,d=0;u>d;d++){for(var f=0;l>f;f++)h[f]=this.get(t[f],d);h[l]=d;var g=e&&e.apply(n,h);if(null!=g){"object"!=typeof g&&(a[0]=g,g=a);for(var v=this.getRawIndex(d),m=Math.floor(v/s),y=v%s,x=0;x<g.length;x++){var _=t[x],w=g[x],b=c[_],M=o[_];M&&(M[m][y]=w),w<b[0]&&(b[0]=w),w>b[1]&&(b[1]=w)}}}return r},ww.downSample=function(t,e,n,i){for(var r=nu(this,[t]),o=r._storage,a=[],s=Math.floor(1/e),l=o[t],u=this.count(),h=this._chunkSize,c=r._rawExtent[t],d=new(Xl(this))(u),f=0,p=0;u>p;p+=s){s>u-p&&(s=u-p,a.length=s);for(var g=0;s>g;g++){var v=this.getRawIndex(p+g),m=Math.floor(v/h),y=v%h;a[g]=l[m][y]}var x=n(a),_=this.getRawIndex(Math.min(p+i(a,x)||0,u-1)),w=Math.floor(_/h),b=_%h;l[w][b]=x,x<c[0]&&(c[0]=x),x>c[1]&&(c[1]=x),d[f++]=_}return r._count=f,r._indices=d,r.getRawIndex=Jl,r},ww.getItemModel=function(t){var e=this.hostModel;return new Lo(this.getRawDataItem(t),e,e&&e.ecModel)},ww.diff=function(t){var e=this;return new Wl(t?t.getIndices():[],this.getIndices(),function(e){return tu(t,e)},function(t){return tu(e,t)})},ww.getVisual=function(t){var e=this._visual;return e&&e[t]},ww.setVisual=function(t,e){if(dw(t))for(var n in t)t.hasOwnProperty(n)&&this.setVisual(n,t[n]);else this._visual=this._visual||{},this._visual[t]=e},ww.setLayout=function(t,e){if(dw(t))for(var n in t)t.hasOwnProperty(n)&&this.setLayout(n,t[n]);else this._layout[t]=e},ww.getLayout=function(t){return this._layout[t]},ww.getItemLayout=function(t){return this._itemLayouts[t]},ww.setItemLayout=function(t,e,n){this._itemLayouts[t]=n?a(this._itemLayouts[t]||{},e):e},ww.clearItemLayouts=function(){this._itemLayouts.length=0},ww.getItemVisual=function(t,e,n){var i=this._itemVisuals[t],r=i&&i[e];return null!=r||n?r:this.getVisual(e)},ww.setItemVisual=function(t,e,n){var i=this._itemVisuals[t]||{},r=this.hasItemVisual;if(this._itemVisuals[t]=i,dw(e))for(var o in e)e.hasOwnProperty(o)&&(i[o]=e[o],r[o]=!0);else i[e]=n,r[e]=!0},ww.clearAllVisual=function(){this._visual={},this._itemVisuals=[],this.hasItemVisual={}};var bw=function(t){t.seriesIndex=this.seriesIndex,t.dataIndex=this.dataIndex,t.dataType=this.dataType};ww.setItemGraphicEl=function(t,e){var n=this.hostModel;e&&(e.dataIndex=t,e.dataType=this.dataType,e.seriesIndex=n&&n.seriesIndex,"group"===e.type&&e.traverse(bw,e)),this._graphicEls[t]=e},ww.getItemGraphicEl=function(t){return this._graphicEls[t]},ww.eachItemGraphicEl=function(t,e){f(this._graphicEls,function(n,i){n&&t&&t.call(e,n,i)})},ww.cloneShallow=function(t){if(!t){var e=p(this.dimensions,this.getDimensionInfo,this);t=new _w(e,this.hostModel)}if(t._storage=this._storage,ql(t,this),this._indices){var n=this._indices.constructor;t._indices=new n(this._indices)}else t._indices=null;return t.getRawIndex=t._indices?Jl:Ql,t},ww.wrapMethod=function(t,e){var n=this[t];"function"==typeof n&&(this.__wrappedMethods=this.__wrappedMethods||[],this.__wrappedMethods.push(t),this[t]=function(){var t=n.apply(this,arguments);return e.apply(this,[t].concat(P(arguments)))})},ww.TRANSFERABLE_METHODS=["cloneShallow","downSample","map"],ww.CHANGABLE_METHODS=["filterSelf","selectRange"];var Mw=function(t,e){return e=e||{},ou(e.coordDimensions||[],t,{dimsDef:e.dimensionsDefine||t.dimensionsDefine,encodeDef:e.encodeDefine||t.encodeDefine,dimCount:e.dimensionsCount,generateCoord:e.generateCoord,generateCoordCount:e.generateCoordCount})};pu.prototype.parse=function(t){return t},pu.prototype.getSetting=function(t){return this._setting[t]},pu.prototype.contain=function(t){var e=this._extent;return t>=e[0]&&t<=e[1]},pu.prototype.normalize=function(t){var e=this._extent;return e[1]===e[0]?.5:(t-e[0])/(e[1]-e[0])},pu.prototype.scale=function(t){var e=this._extent;return t*(e[1]-e[0])+e[0]},pu.prototype.unionExtent=function(t){var e=this._extent;t[0]<e[0]&&(e[0]=t[0]),t[1]>e[1]&&(e[1]=t[1])},pu.prototype.unionExtentFromData=function(t,e){this.unionExtent(t.getApproximateExtent(e))},pu.prototype.getExtent=function(){return this._extent.slice()},pu.prototype.setExtent=function(t,e){var n=this._extent;isNaN(t)||(n[0]=t),isNaN(e)||(n[1]=e)},pu.prototype.isBlank=function(){return this._isBlank},pu.prototype.setBlank=function(t){this._isBlank=t},pu.prototype.getLabel=null,Yi(pu),Qi(pu,{registerWhenExtend:!0}),gu.createByAxisModel=function(t){var e=t.option,n=e.data,i=n&&p(n,mu);return new gu({categories:i,needCollect:!i,deduplication:e.dedplication!==!1})};var Sw=gu.prototype;Sw.getOrdinal=function(t){return vu(this).get(t)},Sw.parseAndCollect=function(t){var e,n=this._needCollect;if("string"!=typeof t&&!n)return t;if(n&&!this._deduplication)return e=this.categories.length,this.categories[e]=t,e;var i=vu(this);return e=i.get(t),null==e&&(n?(e=this.categories.length,this.categories[e]=t,i.set(t,e)):e=0/0),e};var Iw=pu.prototype,Cw=pu.extend({type:"ordinal",init:function(t,e){(!t||_(t))&&(t=new gu({categories:t})),this._ordinalMeta=t,this._extent=e||[0,t.categories.length-1]},parse:function(t){return"string"==typeof t?this._ordinalMeta.getOrdinal(t):Math.round(t)},contain:function(t){return t=this.parse(t),Iw.contain.call(this,t)&&null!=this._ordinalMeta.categories[t]},normalize:function(t){return Iw.normalize.call(this,this.parse(t))},scale:function(t){return Math.round(Iw.scale.call(this,t))},getTicks:function(){for(var t=[],e=this._extent,n=e[0];n<=e[1];)t.push(n),n++;return t},getLabel:function(t){return this.isBlank()?void 0:this._ordinalMeta.categories[t]},count:function(){return this._extent[1]-this._extent[0]+1},unionExtentFromData:function(t,e){this.unionExtent(t.getApproximateExtent(e))},getOrdinalMeta:function(){return this._ordinalMeta},niceTicks:F,niceExtent:F});Cw.create=function(){return new Cw};var Tw=Ho,Aw=Ho,Dw=pu.extend({type:"interval",_interval:0,_intervalPrecision:2,setExtent:function(t,e){var n=this._extent;isNaN(t)||(n[0]=parseFloat(t)),isNaN(e)||(n[1]=parseFloat(e))},unionExtent:function(t){var e=this._extent;t[0]<e[0]&&(e[0]=t[0]),t[1]>e[1]&&(e[1]=t[1]),Dw.prototype.setExtent.call(this,e[0],e[1])},getInterval:function(){return this._interval},setInterval:function(t){this._interval=t,this._niceExtent=this._extent.slice(),this._intervalPrecision=xu(t)},getTicks:function(){return bu(this._interval,this._extent,this._niceExtent,this._intervalPrecision)},getLabel:function(t,e){if(null==t)return"";var n=e&&e.precision;return null==n?n=Uo(t)||0:"auto"===n&&(n=this._intervalPrecision),t=Aw(t,n,!0),ea(t)},niceTicks:function(t,e,n){t=t||5;var i=this._extent,r=i[1]-i[0];if(isFinite(r)){0>r&&(r=-r,i.reverse());var o=yu(i,t,e,n);this._intervalPrecision=o.intervalPrecision,this._interval=o.interval,this._niceExtent=o.niceTickExtent}},niceExtent:function(t){var e=this._extent;if(e[0]===e[1])if(0!==e[0]){var n=e[0];t.fixMax?e[0]-=n/2:(e[1]+=n/2,e[0]-=n/2)}else e[1]=1;var i=e[1]-e[0];isFinite(i)||(e[0]=0,e[1]=1),this.niceTicks(t.splitNumber,t.minInterval,t.maxInterval);var r=this._interval;t.fixMin||(e[0]=Aw(Math.floor(e[0]/r)*r)),t.fixMax||(e[1]=Aw(Math.ceil(e[1]/r)*r))}});Dw.create=function(){return new Dw};var kw="__ec_stack_",Pw=.5,Lw="undefined"!=typeof Float32Array?Float32Array:Array,Ow={seriesType:"bar",plan:n_(),reset:function(t){function e(t,e){for(var n,c=new Lw(2*t.count),d=[],f=[],p=0;null!=(n=t.next());)f[u]=e.get(a,n),f[1-u]=e.get(s,n),d=i.dataToPoint(f,null,d),c[p++]=d[0],c[p++]=d[1];e.setLayout({largePoints:c,barWidth:h,valueAxisStart:Lu(r,o,!1),valueAxisHorizontal:l})}if(ku(t)&&Pu(t)){var n=t.getData(),i=t.coordinateSystem,r=i.getBaseAxis(),o=i.getOtherAxis(r),a=n.mapDimension(o.dim),s=n.mapDimension(r.dim),l=o.isHorizontal(),u=l?0:1,h=Au(Cu([t]),r,t).width;return h>Pw||(h=Pw),{progress:e}}}},Ew=Dw.prototype,Rw=Math.ceil,zw=Math.floor,Bw=1e3,Nw=60*Bw,Vw=60*Nw,Fw=24*Vw,Hw=function(t,e,n,i){for(;i>n;){var r=n+i>>>1;t[r][1]<e?n=r+1:i=r}return n},Ww=Dw.extend({type:"time",getLabel:function(t){var e=this._stepLvl,n=new Date(t);return la(e[0],n,this.getSetting("useUTC"))},niceExtent:function(t){var e=this._extent;if(e[0]===e[1]&&(e[0]-=Fw,e[1]+=Fw),e[1]===-1/0&&1/0===e[0]){var n=new Date;e[1]=+new Date(n.getFullYear(),n.getMonth(),n.getDate()),e[0]=e[1]-Fw}this.niceTicks(t.splitNumber,t.minInterval,t.maxInterval);var i=this._interval;t.fixMin||(e[0]=Ho(zw(e[0]/i)*i)),t.fixMax||(e[1]=Ho(Rw(e[1]/i)*i))},niceTicks:function(t,e,n){t=t||10;var i=this._extent,r=i[1]-i[0],o=r/t;null!=e&&e>o&&(o=e),null!=n&&o>n&&(o=n);var a=Gw.length,s=Hw(Gw,o,0,a),l=Gw[Math.min(s,a-1)],u=l[1];if("year"===l[0]){var h=r/u,c=Qo(h/t,!0);u*=c}var d=this.getSetting("useUTC")?0:60*new Date(+i[0]||+i[1]).getTimezoneOffset()*1e3,f=[Math.round(Rw((i[0]-d)/u)*u+d),Math.round(zw((i[1]-d)/u)*u+d)];wu(f,i),this._stepLvl=l,this._interval=u,this._niceExtent=f},parse:function(t){return+qo(t)}});f(["contain","normalize"],function(t){Ww.prototype[t]=function(e){return Ew[t].call(this,this.parse(e))}});var Gw=[["hh:mm:ss",Bw],["hh:mm:ss",5*Bw],["hh:mm:ss",10*Bw],["hh:mm:ss",15*Bw],["hh:mm:ss",30*Bw],["hh:mm\nMM-dd",Nw],["hh:mm\nMM-dd",5*Nw],["hh:mm\nMM-dd",10*Nw],["hh:mm\nMM-dd",15*Nw],["hh:mm\nMM-dd",30*Nw],["hh:mm\nMM-dd",Vw],["hh:mm\nMM-dd",2*Vw],["hh:mm\nMM-dd",6*Vw],["hh:mm\nMM-dd",12*Vw],["MM-dd\nyyyy",Fw],["MM-dd\nyyyy",2*Fw],["MM-dd\nyyyy",3*Fw],["MM-dd\nyyyy",4*Fw],["MM-dd\nyyyy",5*Fw],["MM-dd\nyyyy",6*Fw],["week",7*Fw],["MM-dd\nyyyy",10*Fw],["week",14*Fw],["week",21*Fw],["month",31*Fw],["week",42*Fw],["month",62*Fw],["week",42*Fw],["quarter",380*Fw/4],["month",31*Fw*4],["month",31*Fw*5],["half-year",380*Fw/2],["month",31*Fw*8],["month",31*Fw*10],["year",380*Fw]];Ww.create=function(t){return new Ww({useUTC:t.ecModel.get("useUTC")})};var Uw=pu.prototype,Zw=Dw.prototype,jw=Uo,Xw=Ho,Yw=Math.floor,qw=Math.ceil,$w=Math.pow,Kw=Math.log,Qw=pu.extend({type:"log",base:10,$constructor:function(){pu.apply(this,arguments),this._originalScale=new Dw},getTicks:function(){var t=this._originalScale,e=this._extent,n=t.getExtent();return p(Zw.getTicks.call(this),function(i){var r=Ho($w(this.base,i));return r=i===e[0]&&t.__fixMin?Ou(r,n[0]):r,r=i===e[1]&&t.__fixMax?Ou(r,n[1]):r},this)},getLabel:Zw.getLabel,scale:function(t){return t=Uw.scale.call(this,t),$w(this.base,t)},setExtent:function(t,e){var n=this.base;t=Kw(t)/Kw(n),e=Kw(e)/Kw(n),Zw.setExtent.call(this,t,e)},getExtent:function(){var t=this.base,e=Uw.getExtent.call(this);e[0]=$w(t,e[0]),e[1]=$w(t,e[1]);var n=this._originalScale,i=n.getExtent();return n.__fixMin&&(e[0]=Ou(e[0],i[0])),n.__fixMax&&(e[1]=Ou(e[1],i[1])),e},unionExtent:function(t){this._originalScale.unionExtent(t);var e=this.base;t[0]=Kw(t[0])/Kw(e),t[1]=Kw(t[1])/Kw(e),Uw.unionExtent.call(this,t)},unionExtentFromData:function(t,e){this.unionExtent(t.getApproximateExtent(e))},niceTicks:function(t){t=t||10;var e=this._extent,n=e[1]-e[0];if(!(1/0===n||0>=n)){var i=$o(n),r=t/n*i;for(.5>=r&&(i*=10);!isNaN(i)&&Math.abs(i)<1&&Math.abs(i)>0;)i*=10;var o=[Ho(qw(e[0]/i)*i),Ho(Yw(e[1]/i)*i)];this._interval=i,this._niceExtent=o}},niceExtent:function(t){Zw.niceExtent.call(this,t);var e=this._originalScale;e.__fixMin=t.fixMin,e.__fixMax=t.fixMax}});f(["contain","normalize"],function(t){Qw.prototype[t]=function(e){return e=Kw(e)/Kw(this.base),Uw[t].call(this,e)}}),Qw.create=function(){return new Qw};var Jw={getMin:function(t){var e=this.option,n=t||null==e.rangeStart?e.min:e.rangeStart;return this.axis&&null!=n&&"dataMin"!==n&&"function"!=typeof n&&!T(n)&&(n=this.axis.scale.parse(n)),n},getMax:function(t){var e=this.option,n=t||null==e.rangeEnd?e.max:e.rangeEnd;return this.axis&&null!=n&&"dataMax"!==n&&"function"!=typeof n&&!T(n)&&(n=this.axis.scale.parse(n)),n},getNeedCrossZero:function(){var t=this.option;return null!=t.rangeStart||null!=t.rangeEnd?!1:!t.scale},getCoordSysModel:F,setRange:function(t,e){this.option.rangeStart=t,this.option.rangeEnd=e},resetRange:function(){this.option.rangeStart=this.option.rangeEnd=null}},tb=Gr({type:"triangle",shape:{cx:0,cy:0,width:0,height:0},buildPath:function(t,e){var n=e.cx,i=e.cy,r=e.width/2,o=e.height/2;t.moveTo(n,i-o),t.lineTo(n+r,i+o),t.lineTo(n-r,i+o),t.closePath()}}),eb=Gr({type:"diamond",shape:{cx:0,cy:0,width:0,height:0},buildPath:function(t,e){var n=e.cx,i=e.cy,r=e.width/2,o=e.height/2;t.moveTo(n,i-o),t.lineTo(n+r,i),t.lineTo(n,i+o),t.lineTo(n-r,i),t.closePath()}}),nb=Gr({type:"pin",shape:{x:0,y:0,width:0,height:0},buildPath:function(t,e){var n=e.x,i=e.y,r=e.width/5*3,o=Math.max(r,e.height),a=r/2,s=a*a/(o-a),l=i-o+a+s,u=Math.asin(s/a),h=Math.cos(u)*a,c=Math.sin(u),d=Math.cos(u),f=.6*a,p=.7*a;t.moveTo(n-h,l+s),t.arc(n,l,a,Math.PI-u,2*Math.PI+u),t.bezierCurveTo(n+h-c*f,l+s+d*f,n,i-p,n,i),t.bezierCurveTo(n,i-p,n-h+c*f,l+s+d*f,n-h,l+s),t.closePath()}}),ib=Gr({type:"arrow",shape:{x:0,y:0,width:0,height:0},buildPath:function(t,e){var n=e.height,i=e.width,r=e.x,o=e.y,a=i/3*2;t.moveTo(r,o),t.lineTo(r+a,o+n),t.lineTo(r,o+n/4*3),t.lineTo(r-a,o+n),t.lineTo(r,o),t.closePath()}}),rb={line:Iy,rect:Sy,roundRect:Sy,square:Sy,circle:gy,diamond:eb,pin:nb,arrow:ib,triangle:tb},ob={line:function(t,e,n,i,r){r.x1=t,r.y1=e+i/2,r.x2=t+n,r.y2=e+i/2},rect:function(t,e,n,i,r){r.x=t,r.y=e,r.width=n,r.height=i},roundRect:function(t,e,n,i,r){r.x=t,r.y=e,r.width=n,r.height=i,r.r=Math.min(n,i)/4},square:function(t,e,n,i,r){var o=Math.min(n,i);r.x=t,r.y=e,r.width=o,r.height=o},circle:function(t,e,n,i,r){r.cx=t+n/2,r.cy=e+i/2,r.r=Math.min(n,i)/2},diamond:function(t,e,n,i,r){r.cx=t+n/2,r.cy=e+i/2,r.width=n,r.height=i},pin:function(t,e,n,i,r){r.x=t+n/2,r.y=e+i/2,r.width=n,r.height=i},arrow:function(t,e,n,i,r){r.x=t+n/2,r.y=e+i/2,r.width=n,r.height=i},triangle:function(t,e,n,i,r){r.cx=t+n/2,r.cy=e+i/2,r.width=n,r.height=i}},ab={};f(rb,function(t,e){ab[e]=new t});var sb=Gr({type:"symbol",shape:{symbolType:"",x:0,y:0,width:0,height:0},beforeBrush:function(){var t=this.style,e=this.shape;"pin"===e.symbolType&&"inside"===t.textPosition&&(t.textPosition=["50%","40%"],t.textAlign="center",t.textVerticalAlign="middle")},buildPath:function(t,e,n){var i=e.symbolType,r=ab[i];"none"!==e.symbolType&&(r||(i="rect",r=ab[i]),ob[i](e.x,e.y,e.width,e.height,r.shape),r.buildPath(t,r.shape,n))}}),lb={isDimensionStacked:uu,enableDataStack:lu,getStackedDimension:hu},ub=(Object.freeze||Object)({createList:Zu,getLayoutRect:ca,dataStack:lb,createScale:ju,mixinAxisModelCommonMethods:Xu,completeDimensions:ou,createDimensions:Mw,createSymbol:Uu}),hb=1e-8;$u.prototype={constructor:$u,properties:null,getBoundingRect:function(){var t=this._rect;if(t)return t;for(var e=Number.MAX_VALUE,n=[e,e],i=[-e,-e],r=[],o=[],a=this.geometries,s=0;s<a.length;s++)if("polygon"===a[s].type){var l=a[s].exterior;fr(l,r,o),ae(n,n,r),se(i,i,o)}return 0===s&&(n[0]=n[1]=i[0]=i[1]=0),this._rect=new rn(n[0],n[1],i[0]-n[0],i[1]-n[1])},contain:function(t){var e=this.getBoundingRect(),n=this.geometries;if(!e.contain(t[0],t[1]))return!1;t:for(var i=0,r=n.length;r>i;i++)if("polygon"===n[i].type){var o=n[i].exterior,a=n[i].interiors;if(qu(o,t[0],t[1])){for(var s=0;s<(a?a.length:0);s++)if(qu(a[s]))continue t;return!0}}return!1},transformTo:function(t,e,n,i){var r=this.getBoundingRect(),o=r.width/r.height;n?i||(i=n/o):n=o*i;for(var a=new rn(t,e,n,i),s=r.calculateTransform(a),l=this.geometries,u=0;u<l.length;u++)if("polygon"===l[u].type){for(var h=l[u].exterior,c=l[u].interiors,d=0;d<h.length;d++)oe(h[d],h[d],s);for(var f=0;f<(c?c.length:0);f++)for(var d=0;d<c[f].length;d++)oe(c[f][d],c[f][d],s)}r=this._rect,r.copy(a),this.center=[r.x+r.width/2,r.y+r.height/2]}};var cb=function(t){return Ku(t),p(v(t.features,function(t){return t.geometry&&t.properties&&t.geometry.coordinates.length>0
+}),function(t){var e=t.properties,n=t.geometry,i=n.coordinates,r=[];"Polygon"===n.type&&r.push({type:"polygon",exterior:i[0],interiors:i.slice(1)}),"MultiPolygon"===n.type&&f(i,function(t){t[0]&&r.push({type:"polygon",exterior:t[0],interiors:t.slice(1)})});var o=new $u(e.name,r,e.cp);return o.properties=e,o})},db=Hi(),fb=[0,1],pb=function(t,e,n){this.dim=t,this.scale=e,this._extent=n||[0,0],this.inverse=!1,this.onBand=!1};pb.prototype={constructor:pb,contain:function(t){var e=this._extent,n=Math.min(e[0],e[1]),i=Math.max(e[0],e[1]);return t>=n&&i>=t},containData:function(t){return this.contain(this.dataToCoord(t))},getExtent:function(){return this._extent.slice()},getPixelPrecision:function(t){return Zo(t||this.scale.getExtent(),this._extent)},setExtent:function(t,e){var n=this._extent;n[0]=t,n[1]=e},dataToCoord:function(t,e){var n=this._extent,i=this.scale;return t=i.normalize(t),this.onBand&&"ordinal"===i.type&&(n=n.slice(),ph(n,i.count())),Vo(t,fb,n,e)},coordToData:function(t,e){var n=this._extent,i=this.scale;this.onBand&&"ordinal"===i.type&&(n=n.slice(),ph(n,i.count()));var r=Vo(t,n,fb,e);return this.scale.scale(r)},pointToData:function(){},getTicksCoords:function(t){t=t||{};var e=t.tickModel||this.getTickModel(),n=th(this,e),i=n.ticks,r=p(i,function(t){return{coord:this.dataToCoord(t),tickValue:t}},this),o=e.get("alignWithLabel");return gh(this,r,n.tickCategoryInterval,o,t.clamp),r},getViewLabels:function(){return Ju(this).labels},getLabelModel:function(){return this.model.getModel("axisLabel")},getTickModel:function(){return this.model.getModel("axisTick")},getBandWidth:function(){var t=this._extent,e=this.scale.getExtent(),n=e[1]-e[0]+(this.onBand?1:0);0===n&&(n=1);var i=Math.abs(t[1]-t[0]);return Math.abs(i)/n},isHorizontal:null,getRotate:null,calculateCategoryInterval:function(){return uh(this)}};var gb=cb,vb={};f(["map","each","filter","indexOf","inherits","reduce","filter","bind","curry","isArray","isString","isObject","isFunction","extend","defaults","clone","merge"],function(t){vb[t]=fg[t]});var mb=function(t){this._axes={},this._dimList=[],this.name=t||""};mb.prototype={constructor:mb,type:"cartesian",getAxis:function(t){return this._axes[t]},getAxes:function(){return p(this._dimList,vh,this)},getAxesByScale:function(t){return t=t.toLowerCase(),v(this.getAxes(),function(e){return e.scale.type===t})},addAxis:function(t){var e=t.dim;this._axes[e]=t,this._dimList.push(e)},dataToCoord:function(t){return this._dataCoordConvert(t,"dataToCoord")},coordToData:function(t){return this._dataCoordConvert(t,"coordToData")},_dataCoordConvert:function(t,e){for(var n=this._dimList,i=t instanceof Array?[]:{},r=0;r<n.length;r++){var o=n[r],a=this._axes[o];i[o]=a[e](t[o])}return i}},mh.prototype={constructor:mh,type:"cartesian2d",dimensions:["x","y"],getBaseAxis:function(){return this.getAxesByScale("ordinal")[0]||this.getAxesByScale("time")[0]||this.getAxis("x")},containPoint:function(t){var e=this.getAxis("x"),n=this.getAxis("y");return e.contain(e.toLocalCoord(t[0]))&&n.contain(n.toLocalCoord(t[1]))},containData:function(t){return this.getAxis("x").containData(t[0])&&this.getAxis("y").containData(t[1])},dataToPoint:function(t,e,n){var i=this.getAxis("x"),r=this.getAxis("y");return n=n||[],n[0]=i.toGlobalCoord(i.dataToCoord(t[0])),n[1]=r.toGlobalCoord(r.dataToCoord(t[1])),n},clampData:function(t,e){var n=this.getAxis("x").scale,i=this.getAxis("y").scale,r=n.getExtent(),o=i.getExtent(),a=n.parse(t[0]),s=i.parse(t[1]);return e=e||[],e[0]=Math.min(Math.max(Math.min(r[0],r[1]),a),Math.max(r[0],r[1])),e[1]=Math.min(Math.max(Math.min(o[0],o[1]),s),Math.max(o[0],o[1])),e},pointToData:function(t,e){var n=this.getAxis("x"),i=this.getAxis("y");return e=e||[],e[0]=n.coordToData(n.toLocalCoord(t[0])),e[1]=i.coordToData(i.toLocalCoord(t[1])),e},getOtherAxis:function(t){return this.getAxis("x"===t.dim?"y":"x")}},h(mh,mb);var yb=function(t,e,n,i,r){pb.call(this,t,e,n),this.type=i||"value",this.position=r||"bottom"};yb.prototype={constructor:yb,index:0,getAxesOnZeroOf:null,model:null,isHorizontal:function(){var t=this.position;return"top"===t||"bottom"===t},getGlobalExtent:function(t){var e=this.getExtent();return e[0]=this.toGlobalCoord(e[0]),e[1]=this.toGlobalCoord(e[1]),t&&e[0]>e[1]&&e.reverse(),e},getOtherAxis:function(){this.grid.getOtherAxis()},pointToData:function(t,e){return this.coordToData(this.toLocalCoord(t["x"===this.dim?0:1]),e)},toLocalCoord:null,toGlobalCoord:null},h(yb,pb);var xb={show:!0,zlevel:0,z:0,inverse:!1,name:"",nameLocation:"end",nameRotate:null,nameTruncate:{maxWidth:null,ellipsis:"...",placeholder:"."},nameTextStyle:{},nameGap:15,silent:!1,triggerEvent:!1,tooltip:{show:!1},axisPointer:{},axisLine:{show:!0,onZero:!0,onZeroAxisIndex:null,lineStyle:{color:"#333",width:1,type:"solid"},symbol:["none","none"],symbolSize:[10,15]},axisTick:{show:!0,inside:!1,length:5,lineStyle:{width:1}},axisLabel:{show:!0,inside:!1,rotate:0,showMinLabel:null,showMaxLabel:null,margin:8,fontSize:12},splitLine:{show:!0,lineStyle:{color:["#ccc"],width:1,type:"solid"}},splitArea:{show:!1,areaStyle:{color:["rgba(250,250,250,0.3)","rgba(200,200,200,0.3)"]}}},_b={};_b.categoryAxis=r({boundaryGap:!0,deduplication:null,splitLine:{show:!1},axisTick:{alignWithLabel:!1,interval:"auto"},axisLabel:{interval:"auto"}},xb),_b.valueAxis=r({boundaryGap:[0,0],splitNumber:5},xb),_b.timeAxis=s({scale:!0,min:"dataMin",max:"dataMax"},_b.valueAxis),_b.logAxis=s({scale:!0,logBase:10},_b.valueAxis);var wb=["value","category","time","log"],bb=function(t,e,n,i){f(wb,function(a){e.extend({type:t+"Axis."+a,mergeDefaultAndTheme:function(e,i){var o=this.layoutMode,s=o?pa(e):{},l=i.getTheme();r(e,l.get(a+"Axis")),r(e,this.getDefaultOption()),e.type=n(t,e),o&&fa(e,s,o)},optionUpdated:function(){var t=this.option;"category"===t.type&&(this.__ordinalMeta=gu.createByAxisModel(this))},getCategories:function(t){var e=this.option;return"category"===e.type?t?e.data:this.__ordinalMeta.categories:void 0},getOrdinalMeta:function(){return this.__ordinalMeta},defaultOption:o([{},_b[a+"Axis"],i],!0)})}),cx.registerSubTypeDefaulter(t+"Axis",x(n,t))},Mb=cx.extend({type:"cartesian2dAxis",axis:null,init:function(){Mb.superApply(this,"init",arguments),this.resetRange()},mergeOption:function(){Mb.superApply(this,"mergeOption",arguments),this.resetRange()},restoreData:function(){Mb.superApply(this,"restoreData",arguments),this.resetRange()},getCoordSysModel:function(){return this.ecModel.queryComponents({mainType:"grid",index:this.option.gridIndex,id:this.option.gridId})[0]}});r(Mb.prototype,Jw);var Sb={offset:0};bb("x",Mb,yh,Sb),bb("y",Mb,yh,Sb),cx.extend({type:"grid",dependencies:["xAxis","yAxis"],layoutMode:"box",coordinateSystem:null,defaultOption:{show:!1,zlevel:0,z:0,left:"10%",top:60,right:"10%",bottom:60,containLabel:!1,backgroundColor:"rgba(0,0,0,0)",borderWidth:1,borderColor:"#ccc"}});var Ib=_h.prototype;Ib.type="grid",Ib.axisPointerEnabled=!0,Ib.getRect=function(){return this._rect},Ib.update=function(t,e){var n=this._axesMap;this._updateScale(t,this.model),f(n.x,function(t){zu(t.scale,t.model)}),f(n.y,function(t){zu(t.scale,t.model)}),f(n.x,function(t){wh(n,"y",t)}),f(n.y,function(t){wh(n,"x",t)}),this.resize(this.model,e)},Ib.resize=function(t,e,n){function i(){f(o,function(t){var e=t.isHorizontal(),n=e?[0,r.width]:[0,r.height],i=t.inverse?1:0;t.setExtent(n[i],n[1-i]),Mh(t,e?r.x:r.y)})}var r=ca(t.getBoxLayoutParams(),{width:e.getWidth(),height:e.getHeight()});this._rect=r;var o=this._axesList;i(),!n&&t.get("containLabel")&&(f(o,function(t){if(!t.model.get("axisLabel.inside")){var e=Hu(t);if(e){var n=t.isHorizontal()?"height":"width",i=t.model.get("axisLabel.margin");r[n]-=e[n]+i,"top"===t.position?r.y+=e.height+i:"left"===t.position&&(r.x+=e.width+i)}}}),i())},Ib.getAxis=function(t,e){var n=this._axesMap[t];if(null!=n){if(null==e)for(var i in n)if(n.hasOwnProperty(i))return n[i];return n[e]}},Ib.getAxes=function(){return this._axesList.slice()},Ib.getCartesian=function(t,e){if(null!=t&&null!=e){var n="x"+t+"y"+e;return this._coordsMap[n]}M(t)&&(e=t.yAxisIndex,t=t.xAxisIndex);for(var i=0,r=this._coordsList;i<r.length;i++)if(r[i].getAxis("x").index===t||r[i].getAxis("y").index===e)return r[i]},Ib.getCartesians=function(){return this._coordsList.slice()},Ib.convertToPixel=function(t,e,n){var i=this._findConvertTarget(t,e);return i.cartesian?i.cartesian.dataToPoint(n):i.axis?i.axis.toGlobalCoord(i.axis.dataToCoord(n)):null},Ib.convertFromPixel=function(t,e,n){var i=this._findConvertTarget(t,e);return i.cartesian?i.cartesian.pointToData(n):i.axis?i.axis.coordToData(i.axis.toLocalCoord(n)):null},Ib._findConvertTarget=function(t,e){var n,i,r=e.seriesModel,o=e.xAxisModel||r&&r.getReferringComponents("xAxis")[0],a=e.yAxisModel||r&&r.getReferringComponents("yAxis")[0],s=e.gridModel,l=this._coordsList;if(r)n=r.coordinateSystem,u(l,n)<0&&(n=null);else if(o&&a)n=this.getCartesian(o.componentIndex,a.componentIndex);else if(o)i=this.getAxis("x",o.componentIndex);else if(a)i=this.getAxis("y",a.componentIndex);else if(s){var h=s.coordinateSystem;h===this&&(n=this._coordsList[0])}return{cartesian:n,axis:i}},Ib.containPoint=function(t){var e=this._coordsList[0];return e?e.containPoint(t):void 0},Ib._initCartesian=function(t,e){function n(n){return function(a,s){if(xh(a,t,e)){var l=a.get("position");"x"===n?"top"!==l&&"bottom"!==l&&(l="bottom",i[l]&&(l="top"===l?"bottom":"top")):"left"!==l&&"right"!==l&&(l="left",i[l]&&(l="left"===l?"right":"left")),i[l]=!0;var u=new yb(n,Bu(a),[0,0],a.get("type"),l),h="category"===u.type;u.onBand=h&&a.get("boundaryGap"),u.inverse=a.get("inverse"),a.axis=u,u.model=a,u.grid=this,u.index=s,this._axesList.push(u),r[n][s]=u,o[n]++}}}var i={left:!1,right:!1,top:!1,bottom:!1},r={x:{},y:{}},o={x:0,y:0};return e.eachComponent("xAxis",n("x"),this),e.eachComponent("yAxis",n("y"),this),o.x&&o.y?(this._axesMap=r,void f(r.x,function(e,n){f(r.y,function(i,r){var o="x"+n+"y"+r,a=new mh(o);a.grid=this,a.model=t,this._coordsMap[o]=a,this._coordsList.push(a),a.addAxis(e),a.addAxis(i)},this)},this)):(this._axesMap={},void(this._axesList=[]))},Ib._updateScale=function(t,e){function n(t,e){f(t.mapDimension(e.dim,!0),function(n){e.scale.unionExtentFromData(t,hu(t,n))})}f(this._axesList,function(t){t.scale.setExtent(1/0,-1/0)}),t.eachSeries(function(i){if(Ih(i)){var r=Sh(i,t),o=r[0],a=r[1];if(!xh(o,e,t)||!xh(a,e,t))return;var s=this.getCartesian(o.componentIndex,a.componentIndex),l=i.getData(),u=s.getAxis("x"),h=s.getAxis("y");"list"===l.type&&(n(l,u,i),n(l,h,i))}},this)},Ib.getTooltipAxes=function(t){var e=[],n=[];return f(this.getCartesians(),function(i){var r=null!=t&&"auto"!==t?i.getAxis(t):i.getBaseAxis(),o=i.getOtherAxis(r);u(e,r)<0&&e.push(r),u(n,o)<0&&n.push(o)}),{baseAxes:e,otherAxes:n}};var Cb=["xAxis","yAxis"];_h.create=function(t,e){var n=[];return t.eachComponent("grid",function(i,r){var o=new _h(i,t,e);o.name="grid_"+r,o.resize(i,e,!0),i.coordinateSystem=o,n.push(o)}),t.eachSeries(function(e){if(Ih(e)){var n=Sh(e,t),i=n[0],r=n[1],o=i.getCoordSysModel(),a=o.coordinateSystem;e.coordinateSystem=a.getCartesian(i.componentIndex,r.componentIndex)}}),n},_h.dimensions=_h.prototype.dimensions=mh.prototype.dimensions,Ha.register("cartesian2d",_h);var Tb=Jx.extend({type:"series.__base_bar__",getInitialData:function(){return cu(this.getSource(),this)},getMarkerPosition:function(t){var e=this.coordinateSystem;if(e){var n=e.dataToPoint(e.clampData(t)),i=this.getData(),r=i.getLayout("offset"),o=i.getLayout("size"),a=e.getBaseAxis().isHorizontal()?0:1;return n[a]+=r+o/2,n}return[0/0,0/0]},defaultOption:{zlevel:0,z:2,coordinateSystem:"cartesian2d",legendHoverLink:!0,barMinHeight:0,barMinAngle:0,large:!1,largeThreshold:400,progressive:3e3,progressiveChunkMode:"mod",itemStyle:{},emphasis:{}}});Tb.extend({type:"series.bar",dependencies:["grid","polar"],brushSelector:"rect",getProgressive:function(){return this.get("large")?this.get("progressive"):!1},getProgressiveThreshold:function(){var t=this.get("progressiveThreshold"),e=this.get("largeThreshold");return e>t&&(t=e),t}});var Ab=lm([["fill","color"],["stroke","borderColor"],["lineWidth","borderWidth"],["stroke","barBorderColor"],["lineWidth","barBorderWidth"],["opacity"],["shadowBlur"],["shadowOffsetX"],["shadowOffsetY"],["shadowColor"]]),Db={getBarItemStyle:function(t){var e=Ab(this,t);if(this.getBorderLineDash){var n=this.getBorderLineDash();n&&(e.lineDash=n)}return e}},kb=["itemStyle","barBorderWidth"];a(Lo.prototype,Db),Bl({type:"bar",render:function(t,e,n){this._updateDrawMode(t);var i=t.get("coordinateSystem");return("cartesian2d"===i||"polar"===i)&&(this._isLargeDraw?this._renderLarge(t,e,n):this._renderNormal(t,e,n)),this.group},incrementalPrepareRender:function(t){this._clear(),this._updateDrawMode(t)},incrementalRender:function(t,e){this._incrementalRenderLarge(t,e)},_updateDrawMode:function(t){var e=t.pipelineContext.large;(null==this._isLargeDraw||e^this._isLargeDraw)&&(this._isLargeDraw=e,this._clear())},_renderNormal:function(t){var e,n=this.group,i=t.getData(),r=this._data,o=t.coordinateSystem,a=o.getBaseAxis();"cartesian2d"===o.type?e=a.isHorizontal():"polar"===o.type&&(e="angle"===a.dim);var s=t.isAnimationEnabled()?t:null;i.diff(r).add(function(r){if(i.hasValue(r)){var a=i.getItemModel(r),l=Lb[o.type](i,r,a),u=Pb[o.type](i,r,a,l,e,s);i.setItemGraphicEl(r,u),n.add(u),Ph(u,i,r,a,l,t,e,"polar"===o.type)}}).update(function(a,l){var u=r.getItemGraphicEl(l);if(!i.hasValue(a))return void n.remove(u);var h=i.getItemModel(a),c=Lb[o.type](i,a,h);u?Mo(u,{shape:c},s,a):u=Pb[o.type](i,a,h,c,e,s,!0),i.setItemGraphicEl(a,u),n.add(u),Ph(u,i,a,h,c,t,e,"polar"===o.type)}).remove(function(t){var e=r.getItemGraphicEl(t);"cartesian2d"===o.type?e&&Dh(t,s,e):e&&kh(t,s,e)}).execute(),this._data=i},_renderLarge:function(t){this._clear(),Oh(t,this.group)},_incrementalRenderLarge:function(t,e){Oh(e,this.group,!0)},dispose:F,remove:function(t){this._clear(t)},_clear:function(t){var e=this.group,n=this._data;t&&t.get("animation")&&n&&!this._isLargeDraw?n.eachItemGraphicEl(function(e){"sector"===e.type?kh(e.dataIndex,t,e):Dh(e.dataIndex,t,e)}):e.removeAll(),this._data=null}});var Pb={cartesian2d:function(t,e,n,i,r,o,s){var l=new Sy({shape:a({},i)});if(o){var u=l.shape,h=r?"height":"width",c={};u[h]=0,c[h]=i[h],Vy[s?"updateProps":"initProps"](l,{shape:c},o,e)}return l},polar:function(t,e,n,i,r,o,a){var l=i.startAngle<i.endAngle,u=new yy({shape:s({clockwise:l},i)});if(o){var h=u.shape,c=r?"r":"endAngle",d={};h[c]=r?0:i.startAngle,d[c]=i[c],Vy[a?"updateProps":"initProps"](u,{shape:d},o,e)}return u}},Lb={cartesian2d:function(t,e,n){var i=t.getItemLayout(e),r=Lh(n,i),o=i.width>0?1:-1,a=i.height>0?1:-1;return{x:i.x+o*r/2,y:i.y+a*r/2,width:i.width-o*r,height:i.height-a*r}},polar:function(t,e){var n=t.getItemLayout(e);return{cx:n.cx,cy:n.cy,r0:n.r0,r:n.r,startAngle:n.startAngle,endAngle:n.endAngle}}},Ob=Lr.extend({type:"largeBar",shape:{points:[]},buildPath:function(t,e){for(var n=e.points,i=this.__startPoint,r=this.__valueIdx,o=0;o<n.length;o+=2)i[this.__valueIdx]=n[o+r],t.moveTo(i[0],i[1]),t.lineTo(n[o],n[o+1])}}),Eb=Math.PI,Rb=function(t,e){this.opt=e,this.axisModel=t,s(e,{labelOffset:0,nameDirection:1,tickDirection:1,labelDirection:1,silent:!0}),this.group=new nv;var n=new nv({position:e.position.slice(),rotation:e.rotation});n.updateTransform(),this._transform=n.transform,this._dumbGroup=n};Rb.prototype={constructor:Rb,hasBuilder:function(t){return!!zb[t]},add:function(t){zb[t].call(this)},getGroup:function(){return this.group}};var zb={axisLine:function(){var t=this.opt,e=this.axisModel;if(e.get("axisLine.show")){var n=this.axisModel.axis.getExtent(),i=this._transform,r=[n[0],0],o=[n[1],0];i&&(oe(r,r,i),oe(o,o,i));var s=a({lineCap:"round"},e.getModel("axisLine.lineStyle").getLineStyle());this.group.add(new Iy(qr({anid:"line",shape:{x1:r[0],y1:r[1],x2:o[0],y2:o[1]},style:s,strokeContainThreshold:t.strokeContainThreshold||5,silent:!0,z2:1})));var l=e.get("axisLine.symbol"),u=e.get("axisLine.symbolSize"),h=e.get("axisLine.symbolOffset")||0;if("number"==typeof h&&(h=[h,h]),null!=l){"string"==typeof l&&(l=[l,l]),("string"==typeof u||"number"==typeof u)&&(u=[u,u]);var c=u[0],d=u[1];f([{rotate:t.rotation+Math.PI/2,offset:h[0],r:0},{rotate:t.rotation-Math.PI/2,offset:h[1],r:Math.sqrt((r[0]-o[0])*(r[0]-o[0])+(r[1]-o[1])*(r[1]-o[1]))}],function(e,n){if("none"!==l[n]&&null!=l[n]){var i=Uu(l[n],-c/2,-d/2,c,d,s.stroke,!0),o=e.r+e.offset,a=[r[0]+o*Math.cos(t.rotation),r[1]-o*Math.sin(t.rotation)];i.attr({rotation:e.rotate,position:a,silent:!0}),this.group.add(i)}},this)}}},axisTickLabel:function(){var t=this.axisModel,e=this.opt,n=Wh(this,t,e),i=Gh(this,t,e);Nh(t,i,n)},axisName:function(){var t=this.opt,e=this.axisModel,n=A(t.axisName,e.get("name"));if(n){var i,r=e.get("nameLocation"),o=t.nameDirection,s=e.getModel("nameTextStyle"),l=e.get("nameGap")||0,u=this.axisModel.axis.getExtent(),h=u[0]>u[1]?-1:1,c=["start"===r?u[0]-h*l:"end"===r?u[1]+h*l:(u[0]+u[1])/2,Hh(r)?t.labelOffset+o*l:0],d=e.get("nameRotate");null!=d&&(d=d*Eb/180);var f;Hh(r)?i=Bb(t.rotation,null!=d?d:t.rotation,o):(i=zh(t,r,d||0,u),f=t.axisNameAvailableWidth,null!=f&&(f=Math.abs(f/Math.sin(i.rotation)),!isFinite(f)&&(f=null)));var p=s.getFont(),g=e.get("nameTruncate",!0)||{},v=g.ellipsis,m=A(t.nameTruncateMaxWidth,g.maxWidth,f),y=null!=v&&null!=m?nx(n,m,p,v,{minChar:2,placeholder:g.placeholder}):n,x=e.get("tooltip",!0),_=e.mainType,w={componentType:_,name:n,$vars:["name"]};w[_+"Index"]=e.componentIndex;var b=new py({anid:"name",__fullText:n,__truncatedText:y,position:c,rotation:i.rotation,silent:Bh(e),z2:1,tooltip:x&&x.show?a({content:n,formatter:function(){return n},formatterParams:w},x):null});fo(b.style,s,{text:y,textFont:p,textFill:s.getTextColor()||e.get("axisLine.lineStyle.color"),textAlign:i.textAlign,textVerticalAlign:i.textVerticalAlign}),e.get("triggerEvent")&&(b.eventData=Rh(e),b.eventData.targetType="axisName",b.eventData.name=n),this._dumbGroup.add(b),b.updateTransform(),this.group.add(b),b.decomposeTransform()}}},Bb=Rb.innerTextLayout=function(t,e,n){var i,r,o=Xo(e-t);return Yo(o)?(r=n>0?"top":"bottom",i="center"):Yo(o-Eb)?(r=n>0?"bottom":"top",i="center"):(r="middle",i=o>0&&Eb>o?n>0?"right":"left":n>0?"left":"right"),{rotation:o,textAlign:i,textVerticalAlign:r}},Nb=f,Vb=x,Fb=Rl({type:"axis",_axisPointer:null,axisPointerClass:null,render:function(t,e,n,i){this.axisPointerClass&&$h(t),Fb.superApply(this,"render",arguments),ec(this,t,e,n,i,!0)},updateAxisPointer:function(t,e,n,i){ec(this,t,e,n,i,!1)},remove:function(t,e){var n=this._axisPointer;n&&n.remove(e),Fb.superApply(this,"remove",arguments)},dispose:function(t,e){nc(this,e),Fb.superApply(this,"dispose",arguments)}}),Hb=[];Fb.registerAxisPointerClass=function(t,e){Hb[t]=e},Fb.getAxisPointerClass=function(t){return t&&Hb[t]};var Wb=["axisLine","axisTickLabel","axisName"],Gb=["splitArea","splitLine"],Ub=Fb.extend({type:"cartesianAxis",axisPointerClass:"CartesianAxisPointer",render:function(t,e,n,i){this.group.removeAll();var r=this._axisGroup;if(this._axisGroup=new nv,this.group.add(this._axisGroup),t.get("show")){var o=t.getCoordSysModel(),a=ic(o,t),s=new Rb(t,a);f(Wb,s.add,s),this._axisGroup.add(s.getGroup()),f(Gb,function(e){t.get(e+".show")&&this["_"+e](t,o)},this),Ao(r,this._axisGroup,t),Ub.superCall(this,"render",t,e,n,i)}},remove:function(){this._splitAreaColors=null},_splitLine:function(t,e){var n=t.axis;if(!n.scale.isBlank()){var i=t.getModel("splitLine"),r=i.getModel("lineStyle"),o=r.get("color");o=_(o)?o:[o];for(var a=e.coordinateSystem.getRect(),l=n.isHorizontal(),u=0,h=n.getTicksCoords({tickModel:i}),c=[],d=[],f=r.getLineStyle(),p=0;p<h.length;p++){var g=n.toGlobalCoord(h[p].coord);l?(c[0]=g,c[1]=a.y,d[0]=g,d[1]=a.y+a.height):(c[0]=a.x,c[1]=g,d[0]=a.x+a.width,d[1]=g);var v=u++%o.length,m=h[p].tickValue;this._axisGroup.add(new Iy(qr({anid:null!=m?"line_"+h[p].tickValue:null,shape:{x1:c[0],y1:c[1],x2:d[0],y2:d[1]},style:s({stroke:o[v]},f),silent:!0})))}}},_splitArea:function(t,e){var n=t.axis;if(!n.scale.isBlank()){var i=t.getModel("splitArea"),r=i.getModel("areaStyle"),o=r.get("color"),a=e.coordinateSystem.getRect(),l=n.getTicksCoords({tickModel:i,clamp:!0});if(l.length){var u=o.length,h=this._splitAreaColors,c=N(),d=0;if(h)for(var f=0;f<l.length;f++){var p=h.get(l[f].tickValue);if(null!=p){d=(p+(u-1)*f)%u;break}}var g=n.toGlobalCoord(l[0].coord),v=r.getAreaStyle();o=_(o)?o:[o];for(var f=1;f<l.length;f++){var m,y,x,w,b=n.toGlobalCoord(l[f].coord);n.isHorizontal()?(m=g,y=a.y,x=b-m,w=a.height,g=m+x):(m=a.x,y=g,x=a.width,w=b-y,g=y+w);var M=l[f-1].tickValue;null!=M&&c.set(M,d),this._axisGroup.add(new Sy({anid:null!=M?"area_"+M:null,shape:{x:m,y:y,width:x,height:w},style:s({fill:o[d]},v),silent:!0})),d=(d+1)%u}this._splitAreaColors=c}}}});Ub.extend({type:"xAxis"}),Ub.extend({type:"yAxis"}),Rl({type:"grid",render:function(t){this.group.removeAll(),t.get("show")&&this.group.add(new Sy({shape:t.coordinateSystem.getRect(),style:s({fill:t.get("backgroundColor")},t.getItemStyle()),silent:!0,z2:-1}))}}),Sl(function(t){t.xAxis&&t.yAxis&&!t.grid&&(t.grid={})}),kl(x(Du,"bar")),kl(Ow),Pl({seriesType:"bar",reset:function(t){t.getData().setVisual("legendSymbol","roundRect")}}),Jx.extend({type:"series.line",dependencies:["grid","polar"],getInitialData:function(){return cu(this.getSource(),this)},defaultOption:{zlevel:0,z:2,coordinateSystem:"cartesian2d",legendHoverLink:!0,hoverAnimation:!0,clipOverflow:!0,label:{position:"top"},lineStyle:{width:2,type:"solid"},step:!1,smooth:!1,smoothMonotone:null,symbol:"emptyCircle",symbolSize:4,symbolRotate:null,showSymbol:!0,showAllSymbol:"auto",connectNulls:!1,sampling:"none",animationEasing:"linear",progressive:0,hoverLayerThreshold:1/0}});var Zb=rc.prototype,jb=rc.getSymbolSize=function(t,e){var n=t.getItemVisual(e,"symbolSize");return n instanceof Array?n.slice():[+n,+n]};Zb._createSymbol=function(t,e,n,i,r){this.removeAll();var o=e.getItemVisual(n,"color"),a=Uu(t,-1,-1,2,2,o,r);a.attr({z2:100,culling:!0,scale:oc(i)}),a.drift=ac,this._symbolType=t,this.add(a)},Zb.stopSymbolAnimation=function(t){this.childAt(0).stopAnimation(t)},Zb.getSymbolPath=function(){return this.childAt(0)},Zb.getScale=function(){return this.childAt(0).scale},Zb.highlight=function(){this.childAt(0).trigger("emphasis")},Zb.downplay=function(){this.childAt(0).trigger("normal")},Zb.setZ=function(t,e){var n=this.childAt(0);n.zlevel=t,n.z=e},Zb.setDraggable=function(t){var e=this.childAt(0);e.draggable=t,e.cursor=t?"move":"pointer"},Zb.updateData=function(t,e,n){this.silent=!1;var i=t.getItemVisual(e,"symbol")||"circle",r=t.hostModel,o=jb(t,e),a=i!==this._symbolType;if(a){var s=t.getItemVisual(e,"symbolKeepAspect");this._createSymbol(i,t,e,o,s)}else{var l=this.childAt(0);l.silent=!1,Mo(l,{scale:oc(o)},r,e)}if(this._updateCommon(t,e,o,n),a){var l=this.childAt(0),u=n&&n.fadeIn,h={scale:l.scale.slice()};u&&(h.style={opacity:l.style.opacity}),l.scale=[0,0],u&&(l.style.opacity=0),So(l,h,r,e)}this._seriesModel=r};var Xb=["itemStyle"],Yb=["emphasis","itemStyle"],qb=["label"],$b=["emphasis","label"];Zb._updateCommon=function(t,e,n,i){function r(e){return b?t.getName(e):Ch(t,e)}var o=this.childAt(0),s=t.hostModel,l=t.getItemVisual(e,"color");"image"!==o.type&&o.useStyle({strokeNoScale:!0});var u=i&&i.itemStyle,h=i&&i.hoverItemStyle,c=i&&i.symbolRotate,d=i&&i.symbolOffset,f=i&&i.labelModel,p=i&&i.hoverLabelModel,g=i&&i.hoverAnimation,v=i&&i.cursorStyle;if(!i||t.hasItemOption){var m=i&&i.itemModel?i.itemModel:t.getItemModel(e);u=m.getModel(Xb).getItemStyle(["color"]),h=m.getModel(Yb).getItemStyle(),c=m.getShallow("symbolRotate"),d=m.getShallow("symbolOffset"),f=m.getModel(qb),p=m.getModel($b),g=m.getShallow("hoverAnimation"),v=m.getShallow("cursor")}else h=a({},h);var y=o.style;o.attr("rotation",(c||0)*Math.PI/180||0),d&&o.attr("position",[Fo(d[0],n[0]),Fo(d[1],n[1])]),v&&o.attr("cursor",v),o.setColor(l,i&&i.symbolInnerColor),o.setStyle(u);var x=t.getItemVisual(e,"opacity");null!=x&&(y.opacity=x);var _=t.getItemVisual(e,"liftZ"),w=o.__z2Origin;null!=_?null==w&&(o.__z2Origin=o.z2,o.z2+=_):null!=w&&(o.z2=w,o.__z2Origin=null);var b=i&&i.useNameLabel;co(y,h,f,p,{labelFetcher:s,labelDataIndex:e,defaultText:r,isRectText:!0,autoColor:l}),o.off("mouseover").off("mouseout").off("emphasis").off("normal"),o.hoverStyle=h,ho(o);var M=oc(n);if(g&&s.isAnimationEnabled()){var S=function(){if(!this.incremental){var t=M[1]/M[0];this.animateTo({scale:[Math.max(1.1*M[0],M[0]+3),Math.max(1.1*M[1],M[1]+3*t)]},400,"elasticOut")}},I=function(){this.incremental||this.animateTo({scale:M},400,"elasticOut")};o.on("mouseover",S).on("mouseout",I).on("emphasis",S).on("normal",I)}},Zb.fadeOut=function(t,e){var n=this.childAt(0);this.silent=n.silent=!0,!(e&&e.keepLabel)&&(n.style.text=null),Mo(n,{style:{opacity:0},scale:[0,0]},this._seriesModel,this.dataIndex,t)},h(rc,nv);var Kb=sc.prototype;Kb.updateData=function(t,e){e=uc(e);var n=this.group,i=t.hostModel,r=this._data,o=this._symbolCtor,a=hc(t);r||n.removeAll(),t.diff(r).add(function(i){var r=t.getItemLayout(i);if(lc(t,r,i,e)){var s=new o(t,i,a);s.attr("position",r),t.setItemGraphicEl(i,s),n.add(s)}}).update(function(s,l){var u=r.getItemGraphicEl(l),h=t.getItemLayout(s);return lc(t,h,s,e)?(u?(u.updateData(t,s,a),Mo(u,{position:h},i)):(u=new o(t,s),u.attr("position",h)),n.add(u),void t.setItemGraphicEl(s,u)):void n.remove(u)}).remove(function(t){var e=r.getItemGraphicEl(t);e&&e.fadeOut(function(){n.remove(e)})}).execute(),this._data=t},Kb.isPersistent=function(){return!0},Kb.updateLayout=function(){var t=this._data;t&&t.eachItemGraphicEl(function(e,n){var i=t.getItemLayout(n);e.attr("position",i)})},Kb.incrementalPrepareUpdate=function(t){this._seriesScope=hc(t),this._data=null,this.group.removeAll()},Kb.incrementalUpdate=function(t,e,n){function i(t){t.isGroup||(t.incremental=t.useHoverLayer=!0)}n=uc(n);for(var r=t.start;r<t.end;r++){var o=e.getItemLayout(r);if(lc(e,o,r,n)){var a=new this._symbolCtor(e,r,this._seriesScope);a.traverse(i),a.attr("position",o),this.group.add(a),e.setItemGraphicEl(r,a)}}},Kb.remove=function(t){var e=this.group,n=this._data;n&&t?n.eachItemGraphicEl(function(t){t.fadeOut(function(){e.remove(t)})}):e.removeAll()};var Qb=function(t,e,n,i,r,o,a,s){for(var l=pc(t,e),u=[],h=[],c=[],d=[],f=[],p=[],g=[],v=cc(r,e,a),m=cc(o,t,s),y=0;y<l.length;y++){var x=l[y],_=!0;switch(x.cmd){case"=":var w=t.getItemLayout(x.idx),b=e.getItemLayout(x.idx1);(isNaN(w[0])||isNaN(w[1]))&&(w=b.slice()),u.push(w),h.push(b),c.push(n[x.idx]),d.push(i[x.idx1]),g.push(e.getRawIndex(x.idx1));break;case"+":var M=x.idx;u.push(r.dataToPoint([e.get(v.dataDimsForPoint[0],M),e.get(v.dataDimsForPoint[1],M)])),h.push(e.getItemLayout(M).slice()),c.push(fc(v,r,e,M)),d.push(i[M]),g.push(e.getRawIndex(M));break;case"-":var M=x.idx,S=t.getRawIndex(M);S!==M?(u.push(t.getItemLayout(M)),h.push(o.dataToPoint([t.get(m.dataDimsForPoint[0],M),t.get(m.dataDimsForPoint[1],M)])),c.push(n[M]),d.push(fc(m,o,t,M)),g.push(S)):_=!1}_&&(f.push(x),p.push(p.length))}p.sort(function(t,e){return g[t]-g[e]});for(var I=[],C=[],T=[],A=[],D=[],y=0;y<p.length;y++){var M=p[y];I[y]=u[M],C[y]=h[M],T[y]=c[M],A[y]=d[M],D[y]=f[M]}return{current:I,next:C,stackedOnCurrent:T,stackedOnNext:A,status:D}},Jb=ae,tM=se,eM=j,nM=W,iM=[],rM=[],oM=[],aM=Lr.extend({type:"ec-polyline",shape:{points:[],smooth:0,smoothConstraint:!0,smoothMonotone:null,connectNulls:!1},style:{fill:null,stroke:"#000"},brush:my(Lr.prototype.brush),buildPath:function(t,e){var n=e.points,i=0,r=n.length,o=xc(n,e.smoothConstraint);if(e.connectNulls){for(;r>0&&gc(n[r-1]);r--);for(;r>i&&gc(n[i]);i++);}for(;r>i;)i+=vc(t,n,i,r,r,1,o.min,o.max,e.smooth,e.smoothMonotone,e.connectNulls)+1}}),sM=Lr.extend({type:"ec-polygon",shape:{points:[],stackedOnPoints:[],smooth:0,stackedOnSmooth:0,smoothConstraint:!0,smoothMonotone:null,connectNulls:!1},brush:my(Lr.prototype.brush),buildPath:function(t,e){var n=e.points,i=e.stackedOnPoints,r=0,o=n.length,a=e.smoothMonotone,s=xc(n,e.smoothConstraint),l=xc(i,e.smoothConstraint);if(e.connectNulls){for(;o>0&&gc(n[o-1]);o--);for(;o>r&&gc(n[r]);r++);}for(;o>r;){var u=vc(t,n,r,o,o,1,s.min,s.max,e.smooth,a,e.connectNulls);vc(t,i,r+u-1,u,o,-1,l.min,l.max,e.stackedOnSmooth,a,e.connectNulls),r+=u+1,t.closePath()}}});Ts.extend({type:"line",init:function(){var t=new nv,e=new sc;this.group.add(e.group),this._symbolDraw=e,this._lineGroup=t},render:function(t,e,n){var i=t.coordinateSystem,r=this.group,o=t.getData(),a=t.getModel("lineStyle"),l=t.getModel("areaStyle"),u=o.mapArray(o.getItemLayout),h="polar"===i.type,c=this._coordSys,d=this._symbolDraw,f=this._polyline,p=this._polygon,g=this._lineGroup,v=t.get("animation"),m=!l.isEmpty(),y=l.get("origin"),x=cc(i,o,y),_=Mc(i,o,x),w=t.get("showSymbol"),b=w&&!h&&Dc(t,o,i),M=this._data;M&&M.eachItemGraphicEl(function(t,e){t.__temp&&(r.remove(t),M.setItemGraphicEl(e,null))}),w||d.remove(),r.add(g);var S=!h&&t.get("step");f&&c.type===i.type&&S===this._step?(m&&!p?p=this._newPolygon(u,_,i,v):p&&!m&&(g.remove(p),p=this._polygon=null),g.setClipPath(Cc(i,!1,!1,t)),w&&d.updateData(o,{isIgnore:b,clipShape:Cc(i,!1,!0,t)}),o.eachItemGraphicEl(function(t){t.stopAnimation(!0)}),_c(this._stackedOnPoints,_)&&_c(this._points,u)||(v?this._updateAnimation(o,_,i,n,S,y):(S&&(u=Tc(u,i,S),_=Tc(_,i,S)),f.setShape({points:u}),p&&p.setShape({points:u,stackedOnPoints:_})))):(w&&d.updateData(o,{isIgnore:b,clipShape:Cc(i,!1,!0,t)}),S&&(u=Tc(u,i,S),_=Tc(_,i,S)),f=this._newPolyline(u,i,v),m&&(p=this._newPolygon(u,_,i,v)),g.setClipPath(Cc(i,!0,!1,t)));var I=Ac(o,i)||o.getVisual("color");f.useStyle(s(a.getLineStyle(),{fill:"none",stroke:I,lineJoin:"bevel"}));var C=t.get("smooth");if(C=wc(t.get("smooth")),f.setShape({smooth:C,smoothMonotone:t.get("smoothMonotone"),connectNulls:t.get("connectNulls")}),p){var T=o.getCalculationInfo("stackedOnSeries"),A=0;p.useStyle(s(l.getAreaStyle(),{fill:I,opacity:.7,lineJoin:"bevel"})),T&&(A=wc(T.get("smooth"))),p.setShape({smooth:C,stackedOnSmooth:A,smoothMonotone:t.get("smoothMonotone"),connectNulls:t.get("connectNulls")})}this._data=o,this._coordSys=i,this._stackedOnPoints=_,this._points=u,this._step=S,this._valueOrigin=y},dispose:function(){},highlight:function(t,e,n,i){var r=t.getData(),o=Fi(r,i);if(!(o instanceof Array)&&null!=o&&o>=0){var a=r.getItemGraphicEl(o);if(!a){var s=r.getItemLayout(o);if(!s)return;a=new rc(r,o),a.position=s,a.setZ(t.get("zlevel"),t.get("z")),a.ignore=isNaN(s[0])||isNaN(s[1]),a.__temp=!0,r.setItemGraphicEl(o,a),a.stopSymbolAnimation(!0),this.group.add(a)}a.highlight()}else Ts.prototype.highlight.call(this,t,e,n,i)},downplay:function(t,e,n,i){var r=t.getData(),o=Fi(r,i);if(null!=o&&o>=0){var a=r.getItemGraphicEl(o);a&&(a.__temp?(r.setItemGraphicEl(o,null),this.group.remove(a)):a.downplay())}else Ts.prototype.downplay.call(this,t,e,n,i)},_newPolyline:function(t){var e=this._polyline;return e&&this._lineGroup.remove(e),e=new aM({shape:{points:t},silent:!0,z2:10}),this._lineGroup.add(e),this._polyline=e,e},_newPolygon:function(t,e){var n=this._polygon;return n&&this._lineGroup.remove(n),n=new sM({shape:{points:t,stackedOnPoints:e},silent:!0}),this._lineGroup.add(n),this._polygon=n,n},_updateAnimation:function(t,e,n,i,r,o){var a=this._polyline,s=this._polygon,l=t.hostModel,u=Qb(this._data,t,this._stackedOnPoints,e,this._coordSys,n,this._valueOrigin,o),h=u.current,c=u.stackedOnCurrent,d=u.next,f=u.stackedOnNext;r&&(h=Tc(u.current,n,r),c=Tc(u.stackedOnCurrent,n,r),d=Tc(u.next,n,r),f=Tc(u.stackedOnNext,n,r)),a.shape.__points=u.current,a.shape.points=h,Mo(a,{shape:{points:d}},l),s&&(s.setShape({points:h,stackedOnPoints:c}),Mo(s,{shape:{points:d,stackedOnPoints:f}},l));for(var p=[],g=u.status,v=0;v<g.length;v++){var m=g[v].cmd;if("="===m){var y=t.getItemGraphicEl(g[v].idx1);y&&p.push({el:y,ptIdx:v})}}a.animators&&a.animators.length&&a.animators[0].during(function(){for(var t=0;t<p.length;t++){var e=p[t].el;e.attr("position",a.shape.__points[p[t].ptIdx])}})},remove:function(){var t=this.group,e=this._data;this._lineGroup.removeAll(),this._symbolDraw.remove(!0),e&&e.eachItemGraphicEl(function(n,i){n.__temp&&(t.remove(n),e.setItemGraphicEl(i,null))
+}),this._polyline=this._polygon=this._coordSys=this._points=this._stackedOnPoints=this._data=null}});var lM=function(t,e,n){return{seriesType:t,performRawSeries:!0,reset:function(t,i){function r(e,n){if("function"==typeof s){var i=t.getRawValue(n),r=t.getDataParams(n);e.setItemVisual(n,"symbolSize",s(i,r))}if(e.hasItemOption){var o=e.getItemModel(n),a=o.getShallow("symbol",!0),l=o.getShallow("symbolSize",!0),u=o.getShallow("symbolKeepAspect",!0);null!=a&&e.setItemVisual(n,"symbol",a),null!=l&&e.setItemVisual(n,"symbolSize",l),null!=u&&e.setItemVisual(n,"symbolKeepAspect",u)}}var o=t.getData(),a=t.get("symbol")||e,s=t.get("symbolSize"),l=t.get("symbolKeepAspect");if(o.setVisual({legendSymbol:n||a,symbol:a,symbolSize:s,symbolKeepAspect:l}),!i.isSeriesFiltered(t)){var u="function"==typeof s;return{dataEach:o.hasItemOption||u?r:null}}}}},uM=function(t){return{seriesType:t,plan:n_(),reset:function(t){function e(t,e){for(var n=t.end-t.start,r=o&&new Float32Array(n*s),l=t.start,u=0,h=[],c=[];l<t.end;l++){var d;if(1===s){var f=e.get(a[0],l);d=!isNaN(f)&&i.dataToPoint(f,null,c)}else{var f=h[0]=e.get(a[0],l),p=h[1]=e.get(a[1],l);d=!isNaN(f)&&!isNaN(p)&&i.dataToPoint(h,null,c)}o?(r[u++]=d?d[0]:0/0,r[u++]=d?d[1]:0/0):e.setItemLayout(l,d&&d.slice()||[0/0,0/0])}o&&e.setLayout("symbolPoints",r)}var n=t.getData(),i=t.coordinateSystem,r=t.pipelineContext,o=r.large;if(i){var a=p(i.dimensions,function(t){return n.mapDimension(t)}).slice(0,2),s=a.length,l=n.getCalculationInfo("stackResultDimension");return uu(n,a[0])&&(a[0]=l),uu(n,a[1])&&(a[1]=l),s&&{progress:e}}}}},hM={average:function(t){for(var e=0,n=0,i=0;i<t.length;i++)isNaN(t[i])||(e+=t[i],n++);return 0===n?0/0:e/n},sum:function(t){for(var e=0,n=0;n<t.length;n++)e+=t[n]||0;return e},max:function(t){for(var e=-1/0,n=0;n<t.length;n++)t[n]>e&&(e=t[n]);return isFinite(e)?e:0/0},min:function(t){for(var e=1/0,n=0;n<t.length;n++)t[n]<e&&(e=t[n]);return isFinite(e)?e:0/0},nearest:function(t){return t[0]}},cM=function(t){return Math.round(t.length/2)},dM=function(t){return{seriesType:t,modifyOutputEnd:!0,reset:function(t){var e=t.getData(),n=t.get("sampling"),i=t.coordinateSystem;if("cartesian2d"===i.type&&n){var r=i.getBaseAxis(),o=i.getOtherAxis(r),a=r.getExtent(),s=a[1]-a[0],l=Math.round(e.count()/s);if(l>1){var u;"string"==typeof n?u=hM[n]:"function"==typeof n&&(u=n),u&&t.setData(e.downSample(e.mapDimension(o.dim),1/l,u,cM))}}}}};Pl(lM("line","circle","line")),kl(uM("line")),Il(W_.PROCESSOR.STATISTIC,dM("line"));var fM=function(t,e,n){e=_(e)&&{coordDimensions:e}||a({},e);var i=t.getSource(),r=Mw(i,e),o=new _w(r,t);return o.initData(i,n),o},pM={updateSelectedMap:function(t){this._targetList=_(t)?t.slice():[],this._selectTargetMap=g(t||[],function(t,e){return t.set(e.name,e),t},N())},select:function(t,e){var n=null!=e?this._targetList[e]:this._selectTargetMap.get(t),i=this.get("selectedMode");"single"===i&&this._selectTargetMap.each(function(t){t.selected=!1}),n&&(n.selected=!0)},unSelect:function(t,e){var n=null!=e?this._targetList[e]:this._selectTargetMap.get(t);n&&(n.selected=!1)},toggleSelected:function(t,e){var n=null!=e?this._targetList[e]:this._selectTargetMap.get(t);return null!=n?(this[n.selected?"unSelect":"select"](t,e),n.selected):void 0},isSelected:function(t,e){var n=null!=e?this._targetList[e]:this._selectTargetMap.get(t);return n&&n.selected}},gM=zl({type:"series.pie",init:function(t){gM.superApply(this,"init",arguments),this.legendDataProvider=function(){return this.getRawData()},this.updateSelectedMap(this._createSelectableList()),this._defaultLabelLine(t)},mergeOption:function(t){gM.superCall(this,"mergeOption",t),this.updateSelectedMap(this._createSelectableList())},getInitialData:function(){return fM(this,["value"])},_createSelectableList:function(){for(var t=this.getRawData(),e=t.mapDimension("value"),n=[],i=0,r=t.count();r>i;i++)n.push({name:t.getName(i),value:t.get(e,i),selected:ps(t,i,"selected")});return n},getDataParams:function(t){var e=this.getData(),n=gM.superCall(this,"getDataParams",t),i=[];return e.each(e.mapDimension("value"),function(t){i.push(t)}),n.percent=jo(i,t,e.hostModel.get("percentPrecision")),n.$vars.push("percent"),n},_defaultLabelLine:function(t){Oi(t,"labelLine",["show"]);var e=t.labelLine,n=t.emphasis.labelLine;e.show=e.show&&t.label.show,n.show=n.show&&t.emphasis.label.show},defaultOption:{zlevel:0,z:2,legendHoverLink:!0,hoverAnimation:!0,center:["50%","50%"],radius:[0,"75%"],clockwise:!0,startAngle:90,minAngle:0,selectedOffset:10,hoverOffset:10,avoidLabelOverlap:!0,percentPrecision:2,stillShowZeroSum:!0,label:{rotate:!1,show:!0,position:"outer"},labelLine:{show:!0,length:15,length2:15,smooth:!1,lineStyle:{width:1,type:"solid"}},itemStyle:{borderWidth:1},animationType:"expansion",animationEasing:"cubicOut"}});c(gM,pM);var vM=Oc.prototype;vM.updateData=function(t,e,n){function i(){o.stopAnimation(!0),o.animateTo({shape:{r:h.r+l.get("hoverOffset")}},300,"elasticOut")}function r(){o.stopAnimation(!0),o.animateTo({shape:{r:h.r}},300,"elasticOut")}var o=this.childAt(0),l=t.hostModel,u=t.getItemModel(e),h=t.getItemLayout(e),c=a({},h);if(c.label=null,n){o.setShape(c);var d=l.getShallow("animationType");"scale"===d?(o.shape.r=h.r0,So(o,{shape:{r:h.r}},l,e)):(o.shape.endAngle=h.startAngle,Mo(o,{shape:{endAngle:h.endAngle}},l,e))}else Mo(o,{shape:c},l,e);var f=t.getItemVisual(e,"color");o.useStyle(s({lineJoin:"bevel",fill:f},u.getModel("itemStyle").getItemStyle())),o.hoverStyle=u.getModel("emphasis.itemStyle").getItemStyle();var p=u.getShallow("cursor");p&&o.attr("cursor",p),Lc(this,t.getItemLayout(e),l.isSelected(null,e),l.get("selectedOffset"),l.get("animation")),o.off("mouseover").off("mouseout").off("emphasis").off("normal"),u.get("hoverAnimation")&&l.isAnimationEnabled()&&o.on("mouseover",i).on("mouseout",r).on("emphasis",i).on("normal",r),this._updateLabel(t,e),ho(this)},vM._updateLabel=function(t,e){var n=this.childAt(1),i=this.childAt(2),r=t.hostModel,o=t.getItemModel(e),a=t.getItemLayout(e),s=a.label,l=t.getItemVisual(e,"color");Mo(n,{shape:{points:s.linePoints||[[s.x,s.y],[s.x,s.y],[s.x,s.y]]}},r,e),Mo(i,{style:{x:s.x,y:s.y}},r,e),i.attr({rotation:s.rotation,origin:[s.x,s.y],z2:10});var u=o.getModel("label"),h=o.getModel("emphasis.label"),c=o.getModel("labelLine"),d=o.getModel("emphasis.labelLine"),l=t.getItemVisual(e,"color");co(i.style,i.hoverStyle={},u,h,{labelFetcher:t.hostModel,labelDataIndex:e,defaultText:t.getName(e),autoColor:l,useInsideStyle:!!s.inside},{textAlign:s.textAlign,textVerticalAlign:s.verticalAlign,opacity:t.getItemVisual(e,"opacity")}),i.ignore=i.normalIgnore=!u.get("show"),i.hoverIgnore=!h.get("show"),n.ignore=n.normalIgnore=!c.get("show"),n.hoverIgnore=!d.get("show"),n.setStyle({stroke:l,opacity:t.getItemVisual(e,"opacity")}),n.setStyle(c.getModel("lineStyle").getLineStyle()),n.hoverStyle=d.getModel("lineStyle").getLineStyle();var f=c.get("smooth");f&&f===!0&&(f=.4),n.setShape({smooth:f})},h(Oc,nv);var mM=(Ts.extend({type:"pie",init:function(){var t=new nv;this._sectorGroup=t},render:function(t,e,n,i){if(!i||i.from!==this.uid){var r=t.getData(),o=this._data,a=this.group,s=e.get("animation"),l=!o,u=t.get("animationType"),h=x(Pc,this.uid,t,s,n),c=t.get("selectedMode");if(r.diff(o).add(function(t){var e=new Oc(r,t);l&&"scale"!==u&&e.eachChild(function(t){t.stopAnimation(!0)}),c&&e.on("click",h),r.setItemGraphicEl(t,e),a.add(e)}).update(function(t,e){var n=o.getItemGraphicEl(e);n.updateData(r,t),n.off("click"),c&&n.on("click",h),a.add(n),r.setItemGraphicEl(t,n)}).remove(function(t){var e=o.getItemGraphicEl(t);a.remove(e)}).execute(),s&&l&&r.count()>0&&"scale"!==u){var d=r.getItemLayout(0),f=Math.max(n.getWidth(),n.getHeight())/2,p=y(a.removeClipPath,a);a.setClipPath(this._createClipPath(d.cx,d.cy,f,d.startAngle,d.clockwise,p,t))}this._data=r}},dispose:function(){},_createClipPath:function(t,e,n,i,r,o,a){var s=new yy({shape:{cx:t,cy:e,r0:0,r:n,startAngle:i,endAngle:i,clockwise:r}});return So(s,{shape:{endAngle:i+(r?1:-1)*Math.PI*2}},a,o),s},containPoint:function(t,e){var n=e.getData(),i=n.getItemLayout(0);if(i){var r=t[0]-i.cx,o=t[1]-i.cy,a=Math.sqrt(r*r+o*o);return a<=i.r&&a>=i.r0}}}),function(t,e){f(e,function(e){e.update="updateView",Tl(e,function(n,i){var r={};return i.eachComponent({mainType:"series",subType:t,query:n},function(t){t[e.method]&&t[e.method](n.name,n.dataIndex);var i=t.getData();i.each(function(e){var n=i.getName(e);r[n]=t.isSelected(n)||!1})}),{name:n.name,selected:r}})})}),yM=function(t){return{getTargetSeries:function(e){var n={},i=N();return e.eachSeriesByType(t,function(t){t.__paletteScope=n,i.set(t.uid,t)}),i},reset:function(t){var e=t.getRawData(),n={},i=t.getData();i.each(function(t){var e=i.getRawIndex(t);n[e]=t}),e.each(function(r){var o=n[r],a=null!=o&&i.getItemVisual(o,"color",!0);if(a)e.setItemVisual(r,"color",a);else{var s=e.getItemModel(r),l=s.get("itemStyle.color")||t.getColorFromPalette(e.getName(r)||r+"",t.__paletteScope,e.count());e.setItemVisual(r,"color",l),null!=o&&i.setItemVisual(o,"color",l)}})}}},xM=function(t,e,n,i){var r,o,a=t.getData(),s=[],l=!1;a.each(function(n){var i,u,h,c,d=a.getItemLayout(n),f=a.getItemModel(n),p=f.getModel("label"),g=p.get("position")||f.get("emphasis.label.position"),v=f.getModel("labelLine"),m=v.get("length"),y=v.get("length2"),x=(d.startAngle+d.endAngle)/2,_=Math.cos(x),w=Math.sin(x);r=d.cx,o=d.cy;var b="inside"===g||"inner"===g;if("center"===g)i=d.cx,u=d.cy,c="center";else{var M=(b?(d.r+d.r0)/2*_:d.r*_)+r,S=(b?(d.r+d.r0)/2*w:d.r*w)+o;if(i=M+3*_,u=S+3*w,!b){var I=M+_*(m+e-d.r),C=S+w*(m+e-d.r),T=I+(0>_?-1:1)*y,A=C;i=T+(0>_?-5:5),u=A,h=[[M,S],[I,C],[T,A]]}c=b?"center":_>0?"left":"right"}var D=p.getFont(),k=p.get("rotate")?0>_?-x+Math.PI:-x:0,P=t.getFormattedLabel(n,"normal")||a.getName(n),L=Sn(P,D,c,"top");l=!!k,d.label={x:i,y:u,position:g,height:L.height,len:m,len2:y,linePoints:h,textAlign:c,verticalAlign:"middle",rotation:k,inside:b},b||s.push(d.label)}),!l&&t.get("avoidLabelOverlap")&&Rc(s,r,o,e,n,i)},_M=2*Math.PI,wM=Math.PI/180,bM=function(t,e,n){e.eachSeriesByType(t,function(t){var e=t.getData(),i=e.mapDimension("value"),r=t.get("center"),o=t.get("radius");_(o)||(o=[0,o]),_(r)||(r=[r,r]);var a=n.getWidth(),s=n.getHeight(),l=Math.min(a,s),u=Fo(r[0],a),h=Fo(r[1],s),c=Fo(o[0],l/2),d=Fo(o[1],l/2),f=-t.get("startAngle")*wM,p=t.get("minAngle")*wM,g=0;e.each(i,function(t){!isNaN(t)&&g++});var v=e.getSum(i),m=Math.PI/(v||g)*2,y=t.get("clockwise"),x=t.get("roseType"),w=t.get("stillShowZeroSum"),b=e.getDataExtent(i);b[0]=0;var M=_M,S=0,I=f,C=y?1:-1;if(e.each(i,function(t,n){var i;if(isNaN(t))return void e.setItemLayout(n,{angle:0/0,startAngle:0/0,endAngle:0/0,clockwise:y,cx:u,cy:h,r0:c,r:x?0/0:d});i="area"!==x?0===v&&w?m:t*m:_M/g,p>i?(i=p,M-=p):S+=t;var r=I+C*i;e.setItemLayout(n,{angle:i,startAngle:I,endAngle:r,clockwise:y,cx:u,cy:h,r0:c,r:x?Vo(t,b,[c,d]):d}),I=r}),_M>M&&g)if(.001>=M){var T=_M/g;e.each(i,function(t,n){if(!isNaN(t)){var i=e.getItemLayout(n);i.angle=T,i.startAngle=f+C*n*T,i.endAngle=f+C*(n+1)*T}})}else m=M/S,I=f,e.each(i,function(t,n){if(!isNaN(t)){var i=e.getItemLayout(n),r=i.angle===p?p:t*m;i.startAngle=I,i.endAngle=I+C*r,I+=C*r}});xM(t,d,a,s)})},MM=function(t){return{seriesType:t,reset:function(t,e){var n=e.findComponents({mainType:"legend"});if(n&&n.length){var i=t.getData();i.filterSelf(function(t){for(var e=i.getName(t),r=0;r<n.length;r++)if(!n[r].isSelected(e))return!1;return!0})}}}};mM("pie",[{type:"pieToggleSelect",event:"pieselectchanged",method:"toggleSelected"},{type:"pieSelect",event:"pieselected",method:"select"},{type:"pieUnSelect",event:"pieunselected",method:"unSelect"}]),Pl(yM("pie")),kl(x(bM,"pie")),Il(MM("pie"));var SM=zl({type:"series.funnel",init:function(t){SM.superApply(this,"init",arguments),this.legendDataProvider=function(){return this.getRawData()},this._defaultLabelLine(t)},getInitialData:function(){return fM(this,["value"])},_defaultLabelLine:function(t){Oi(t,"labelLine",["show"]);var e=t.labelLine,n=t.emphasis.labelLine;e.show=e.show&&t.label.show,n.show=n.show&&t.emphasis.label.show},getDataParams:function(t){var e=this.getData(),n=SM.superCall(this,"getDataParams",t),i=e.mapDimension("value"),r=e.getSum(i);return n.percent=r?+(e.get(i,t)/r*100).toFixed(2):0,n.$vars.push("percent"),n},defaultOption:{zlevel:0,z:2,legendHoverLink:!0,left:80,top:60,right:80,bottom:60,minSize:"0%",maxSize:"100%",sort:"descending",gap:0,funnelAlign:"center",label:{show:!0,position:"outer"},labelLine:{show:!0,length:20,lineStyle:{width:1,type:"solid"}},itemStyle:{borderColor:"#fff",borderWidth:1},emphasis:{label:{show:!0}}}}),IM=zc.prototype,CM=["itemStyle","opacity"];IM.updateData=function(t,e,n){var i=this.childAt(0),r=t.hostModel,o=t.getItemModel(e),a=t.getItemLayout(e),l=t.getItemModel(e).get(CM);l=null==l?1:l,i.useStyle({}),n?(i.setShape({points:a.points}),i.setStyle({opacity:0}),So(i,{style:{opacity:l}},r,e)):Mo(i,{style:{opacity:l},shape:{points:a.points}},r,e);var u=o.getModel("itemStyle"),h=t.getItemVisual(e,"color");i.setStyle(s({lineJoin:"round",fill:h},u.getItemStyle(["opacity"]))),i.hoverStyle=u.getModel("emphasis").getItemStyle(),this._updateLabel(t,e),ho(this)},IM._updateLabel=function(t,e){var n=this.childAt(1),i=this.childAt(2),r=t.hostModel,o=t.getItemModel(e),a=t.getItemLayout(e),s=a.label,l=t.getItemVisual(e,"color");Mo(n,{shape:{points:s.linePoints||s.linePoints}},r,e),Mo(i,{style:{x:s.x,y:s.y}},r,e),i.attr({rotation:s.rotation,origin:[s.x,s.y],z2:10});var u=o.getModel("label"),h=o.getModel("emphasis.label"),c=o.getModel("labelLine"),d=o.getModel("emphasis.labelLine"),l=t.getItemVisual(e,"color");co(i.style,i.hoverStyle={},u,h,{labelFetcher:t.hostModel,labelDataIndex:e,defaultText:t.getName(e),autoColor:l,useInsideStyle:!!s.inside},{textAlign:s.textAlign,textVerticalAlign:s.verticalAlign}),i.ignore=i.normalIgnore=!u.get("show"),i.hoverIgnore=!h.get("show"),n.ignore=n.normalIgnore=!c.get("show"),n.hoverIgnore=!d.get("show"),n.setStyle({stroke:l}),n.setStyle(c.getModel("lineStyle").getLineStyle()),n.hoverStyle=d.getModel("lineStyle").getLineStyle()},h(zc,nv);var TM=(Ts.extend({type:"funnel",render:function(t){var e=t.getData(),n=this._data,i=this.group;e.diff(n).add(function(t){var n=new zc(e,t);e.setItemGraphicEl(t,n),i.add(n)}).update(function(t,r){var o=n.getItemGraphicEl(r);o.updateData(e,t),i.add(o),e.setItemGraphicEl(t,o)}).remove(function(t){var e=n.getItemGraphicEl(t);i.remove(e)}).execute(),this._data=e},remove:function(){this.group.removeAll(),this._data=null},dispose:function(){}}),function(t,e){t.eachSeriesByType("funnel",function(t){var n=t.getData(),i=n.mapDimension("value"),r=t.get("sort"),o=Bc(t,e),a=Nc(n,r),s=[Fo(t.get("minSize"),o.width),Fo(t.get("maxSize"),o.width)],l=n.getDataExtent(i),u=t.get("min"),h=t.get("max");null==u&&(u=Math.min(l[0],0)),null==h&&(h=l[1]);var c=t.get("funnelAlign"),d=t.get("gap"),f=(o.height-d*(n.count()-1))/n.count(),p=o.y,g=function(t,e){var r,a=n.get(i,t)||0,l=Vo(a,[u,h],s,!0);switch(c){case"left":r=o.x;break;case"center":r=o.x+(o.width-l)/2;break;case"right":r=o.x+o.width-l}return[[r,e],[r+l,e]]};"ascending"===r&&(f=-f,d=-d,p+=o.height,a=a.reverse());for(var v=0;v<a.length;v++){var m=a[v],y=a[v+1],x=n.getItemModel(m),_=x.get("itemStyle.height");null==_?_=f:(_=Fo(_,o.height),"ascending"===r&&(_=-_));var w=g(m,p),b=g(y,p+_);p+=_+d,n.setItemLayout(m,{points:w.concat(b.slice().reverse())})}Vc(n)})});Pl(yM("funnel")),kl(TM),Il(MM("funnel")),El({type:"title",layoutMode:{type:"box",ignoreSize:!0},defaultOption:{zlevel:0,z:6,show:!0,text:"",target:"blank",subtext:"",subtarget:"blank",left:0,top:0,backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",borderWidth:0,padding:5,itemGap:10,textStyle:{fontSize:18,fontWeight:"bolder",color:"#333"},subtextStyle:{color:"#aaa"}}}),Rl({type:"title",render:function(t,e,n){if(this.group.removeAll(),t.get("show")){var i=this.group,r=t.getModel("textStyle"),o=t.getModel("subtextStyle"),a=t.get("textAlign"),s=t.get("textBaseline"),l=new py({style:fo({},r,{text:t.get("text"),textFill:r.getTextColor()},{disableBox:!0}),z2:10}),u=l.getBoundingRect(),h=t.get("subtext"),c=new py({style:fo({},o,{text:h,textFill:o.getTextColor(),y:u.height+t.get("itemGap"),textVerticalAlign:"top"},{disableBox:!0}),z2:10}),d=t.get("link"),f=t.get("sublink");l.silent=!d,c.silent=!f,d&&l.on("click",function(){window.open(d,"_"+t.get("target"))}),f&&c.on("click",function(){window.open(f,"_"+t.get("subtarget"))}),i.add(l),h&&i.add(c);var p=i.getBoundingRect(),g=t.getBoxLayoutParams();g.width=p.width,g.height=p.height;var v=ca(g,{width:n.getWidth(),height:n.getHeight()},t.get("padding"));a||(a=t.get("left")||t.get("right"),"middle"===a&&(a="center"),"right"===a?v.x+=v.width:"center"===a&&(v.x+=v.width/2)),s||(s=t.get("top")||t.get("bottom"),"center"===s&&(s="middle"),"bottom"===s?v.y+=v.height:"middle"===s&&(v.y+=v.height/2),s=s||"top"),i.attr("position",[v.x,v.y]);var m={textAlign:a,textVerticalAlign:s};l.setStyle(m),c.setStyle(m),p=i.getBoundingRect();var y=v.margin,x=t.getItemStyle(["color","opacity"]);x.fill=t.get("backgroundColor");var _=new Sy({shape:{x:p.x-y[3],y:p.y-y[0],width:p.width+y[1]+y[3],height:p.height+y[0]+y[2],r:t.get("borderRadius")},style:x,silent:!0});$r(_),i.add(_)}}});var AM=El({type:"legend.plain",dependencies:["series"],layoutMode:{type:"box",ignoreSize:!0},init:function(t,e,n){this.mergeDefaultAndTheme(t,n),t.selected=t.selected||{}},mergeOption:function(t){AM.superCall(this,"mergeOption",t)},optionUpdated:function(){this._updateData(this.ecModel);var t=this._data;if(t[0]&&"single"===this.get("selectedMode")){for(var e=!1,n=0;n<t.length;n++){var i=t[n].get("name");if(this.isSelected(i)){this.select(i),e=!0;break}}!e&&this.select(t[0].get("name"))}},_updateData:function(t){var e=[],n=[];t.eachRawSeries(function(i){var r=i.name;n.push(r);var o;if(i.legendDataProvider){var a=i.legendDataProvider(),s=a.mapArray(a.getName);t.isSeriesFiltered(i)||(n=n.concat(s)),s.length?e=e.concat(s):o=!0}else o=!0;o&&Ni(i)&&e.push(i.name)}),this._availableNames=n;var i=this.get("data")||e,r=p(i,function(t){return("string"==typeof t||"number"==typeof t)&&(t={name:t}),new Lo(t,this,this.ecModel)},this);this._data=r},getData:function(){return this._data},select:function(t){var e=this.option.selected,n=this.get("selectedMode");if("single"===n){var i=this._data;f(i,function(t){e[t.get("name")]=!1})}e[t]=!0},unSelect:function(t){"single"!==this.get("selectedMode")&&(this.option.selected[t]=!1)},toggleSelected:function(t){var e=this.option.selected;e.hasOwnProperty(t)||(e[t]=!0),this[e[t]?"unSelect":"select"](t)},isSelected:function(t){var e=this.option.selected;return!(e.hasOwnProperty(t)&&!e[t])&&u(this._availableNames,t)>=0},defaultOption:{zlevel:0,z:4,show:!0,orient:"horizontal",left:"center",top:0,align:"auto",backgroundColor:"rgba(0,0,0,0)",borderColor:"#ccc",borderRadius:0,borderWidth:0,padding:5,itemGap:10,itemWidth:25,itemHeight:14,inactiveColor:"#ccc",textStyle:{color:"#333"},selectedMode:!0,tooltip:{show:!1}}});Tl("legendToggleSelect","legendselectchanged",x(Fc,"toggleSelected")),Tl("legendSelect","legendselected",x(Fc,"select")),Tl("legendUnSelect","legendunselected",x(Fc,"unSelect"));var DM=x,kM=f,PM=nv,LM=Rl({type:"legend.plain",newlineDisabled:!1,init:function(){this.group.add(this._contentGroup=new PM),this._backgroundEl},getContentGroup:function(){return this._contentGroup},render:function(t,e,n){if(this.resetInner(),t.get("show",!0)){var i=t.get("align");i&&"auto"!==i||(i="right"===t.get("left")&&"vertical"===t.get("orient")?"right":"left"),this.renderInner(i,t,e,n);var r=t.getBoxLayoutParams(),o={width:n.getWidth(),height:n.getHeight()},a=t.get("padding"),l=ca(r,o,a),u=this.layoutInner(t,i,l),h=ca(s({width:u.width,height:u.height},r),o,a);this.group.attr("position",[h.x-u.x,h.y-u.y]),this.group.add(this._backgroundEl=Wc(u,t))}},resetInner:function(){this.getContentGroup().removeAll(),this._backgroundEl&&this.group.remove(this._backgroundEl)},renderInner:function(t,e,n,i){var r=this.getContentGroup(),o=N(),a=e.get("selectedMode"),s=[];n.eachRawSeries(function(t){!t.get("legendHoverLink")&&s.push(t.id)}),kM(e.getData(),function(l,u){var h=l.get("name");if(!this.newlineDisabled&&(""===h||"\n"===h))return void r.add(new PM({newline:!0}));var c=n.getSeriesByName(h)[0];if(!o.get(h))if(c){var d=c.getData(),f=d.getVisual("color");"function"==typeof f&&(f=f(c.getDataParams(0)));var p=d.getVisual("legendSymbol")||"roundRect",g=d.getVisual("symbol"),v=this._createItem(h,u,l,e,p,g,t,f,a);v.on("click",DM(Gc,h,i)).on("mouseover",DM(Uc,c,null,i,s)).on("mouseout",DM(Zc,c,null,i,s)),o.set(h,!0)}else n.eachRawSeries(function(n){if(!o.get(h)&&n.legendDataProvider){var r=n.legendDataProvider(),c=r.indexOfName(h);if(0>c)return;var d=r.getItemVisual(c,"color"),f="roundRect",p=this._createItem(h,u,l,e,f,null,t,d,a);p.on("click",DM(Gc,h,i)).on("mouseover",DM(Uc,n,h,i,s)).on("mouseout",DM(Zc,n,h,i,s)),o.set(h,!0)}},this)},this)},_createItem:function(t,e,n,i,r,o,s,l,u){var h=i.get("itemWidth"),c=i.get("itemHeight"),d=i.get("inactiveColor"),f=i.get("symbolKeepAspect"),p=i.isSelected(t),g=new PM,v=n.getModel("textStyle"),m=n.get("icon"),y=n.getModel("tooltip"),x=y.parentModel;if(r=m||r,g.add(Uu(r,0,0,h,c,p?l:d,null==f?!0:f)),!m&&o&&(o!==r||"none"==o)){var _=.8*c;"none"===o&&(o="circle"),g.add(Uu(o,(h-_)/2,(c-_)/2,_,_,p?l:d,null==f?!0:f))}var w="left"===s?h+5:-5,b=s,M=i.get("formatter"),S=t;"string"==typeof M&&M?S=M.replace("{name}",null!=t?t:""):"function"==typeof M&&(S=M(t)),g.add(new py({style:fo({},v,{text:S,x:w,y:c/2,textFill:p?v.getTextColor():d,textAlign:b,textVerticalAlign:"middle"})}));var I=new Sy({shape:g.getBoundingRect(),invisible:!0,tooltip:y.get("show")?a({content:t,formatter:x.get("formatter",!0)||function(){return t},formatterParams:{componentType:"legend",legendIndex:i.componentIndex,name:t,$vars:["name"]}},y.option):null});return g.add(I),g.eachChild(function(t){t.silent=!0}),I.silent=!u,this.getContentGroup().add(g),ho(g),g.__legendDataIndex=e,g},layoutInner:function(t,e,n){var i=this.getContentGroup();lx(t.get("orient"),i,t.get("itemGap"),n.width,n.height);var r=i.getBoundingRect();return i.attr("position",[-r.x,-r.y]),this.group.getBoundingRect()}}),OM=function(t){var e=t.findComponents({mainType:"legend"});e&&e.length&&t.filterSeries(function(t){for(var n=0;n<e.length;n++)if(!e[n].isSelected(t.name))return!1;return!0})};Il(OM),cx.registerSubTypeDefaulter("legend",function(){return"plain"});var EM=AM.extend({type:"legend.scroll",setScrollDataIndex:function(t){this.option.scrollDataIndex=t},defaultOption:{scrollDataIndex:0,pageButtonItemGap:5,pageButtonGap:null,pageButtonPosition:"end",pageFormatter:"{current}/{total}",pageIcons:{horizontal:["M0,0L12,-10L12,10z","M0,0L-12,-10L-12,10z"],vertical:["M0,0L20,0L10,-20z","M0,0L20,0L10,20z"]},pageIconColor:"#2f4554",pageIconInactiveColor:"#aaa",pageIconSize:15,pageTextStyle:{color:"#333"},animationDurationUpdate:800},init:function(t,e,n,i){var r=pa(t);EM.superCall(this,"init",t,e,n,i),jc(this,t,r)},mergeOption:function(t,e){EM.superCall(this,"mergeOption",t,e),jc(this,this.option,t)},getOrient:function(){return"vertical"===this.get("orient")?{index:1,name:"vertical"}:{index:0,name:"horizontal"}}}),RM=nv,zM=["width","height"],BM=["x","y"],NM=LM.extend({type:"legend.scroll",newlineDisabled:!0,init:function(){NM.superCall(this,"init"),this._currentIndex=0,this.group.add(this._containerGroup=new RM),this._containerGroup.add(this.getContentGroup()),this.group.add(this._controllerGroup=new RM),this._showController},resetInner:function(){NM.superCall(this,"resetInner"),this._controllerGroup.removeAll(),this._containerGroup.removeClipPath(),this._containerGroup.__rectSize=null},renderInner:function(t,e,n,i){function r(t,n){var r=t+"DataIndex",l=Po(e.get("pageIcons",!0)[e.getOrient().name][n],{onclick:y(o._pageGo,o,r,e,i)},{x:-s[0]/2,y:-s[1]/2,width:s[0],height:s[1]});l.name=t,a.add(l)}var o=this;NM.superCall(this,"renderInner",t,e,n,i);var a=this._controllerGroup,s=e.get("pageIconSize",!0);_(s)||(s=[s,s]),r("pagePrev",0);var l=e.getModel("pageTextStyle");a.add(new py({name:"pageText",style:{textFill:l.getTextColor(),font:l.getFont(),textVerticalAlign:"middle",textAlign:"center"},silent:!0})),r("pageNext",1)},layoutInner:function(t,e,n){var i=this.getContentGroup(),r=this._containerGroup,o=this._controllerGroup,a=t.getOrient().index,s=zM[a],l=zM[1-a],u=BM[1-a];lx(t.get("orient"),i,t.get("itemGap"),a?n.width:null,a?null:n.height),lx("horizontal",o,t.get("pageButtonItemGap",!0));var h=i.getBoundingRect(),c=o.getBoundingRect(),d=this._showController=h[s]>n[s],f=[-h.x,-h.y];f[a]=i.position[a];var p=[0,0],g=[-c.x,-c.y],v=D(t.get("pageButtonGap",!0),t.get("itemGap",!0));if(d){var m=t.get("pageButtonPosition",!0);"end"===m?g[a]+=n[s]-c[s]:p[a]+=c[s]+v}g[1-a]+=h[l]/2-c[l]/2,i.attr("position",f),r.attr("position",p),o.attr("position",g);var y=this.group.getBoundingRect(),y={x:0,y:0};if(y[s]=d?n[s]:h[s],y[l]=Math.max(h[l],c[l]),y[u]=Math.min(0,c[u]+g[1-a]),r.__rectSize=n[s],d){var x={x:0,y:0};x[s]=Math.max(n[s]-c[s]-v,0),x[l]=y[l],r.setClipPath(new Sy({shape:x})),r.__rectSize=x[s]}else o.eachChild(function(t){t.attr({invisible:!0,silent:!0})});var _=this._getPageInfo(t);return null!=_.pageIndex&&Mo(i,{position:_.contentPosition},d?t:!1),this._updatePageInfoView(t,_),y},_pageGo:function(t,e,n){var i=this._getPageInfo(e)[t];null!=i&&n.dispatchAction({type:"legendScroll",scrollDataIndex:i,legendId:e.id})},_updatePageInfoView:function(t,e){var n=this._controllerGroup;f(["pagePrev","pageNext"],function(i){var r=null!=e[i+"DataIndex"],o=n.childOfName(i);o&&(o.setStyle("fill",r?t.get("pageIconColor",!0):t.get("pageIconInactiveColor",!0)),o.cursor=r?"pointer":"default")});var i=n.childOfName("pageText"),r=t.get("pageFormatter"),o=e.pageIndex,a=null!=o?o+1:0,s=e.pageCount;i&&r&&i.setStyle("text",b(r)?r.replace("{current}",a).replace("{total}",s):r({current:a,total:s}))},_getPageInfo:function(t){function e(t){var e=t.getBoundingRect().clone();return e[f]+=t.position[h],e}var n,i,r,o,a=t.get("scrollDataIndex",!0),s=this.getContentGroup(),l=s.getBoundingRect(),u=this._containerGroup.__rectSize,h=t.getOrient().index,c=zM[h],d=zM[1-h],f=BM[h],p=s.position.slice();this._showController?s.eachChild(function(t){t.__legendDataIndex===a&&(o=t)}):o=s.childAt(0);var g=u?Math.ceil(l[c]/u):0;if(o){var v=o.getBoundingRect(),m=o.position[h]+v[f];p[h]=-m-l[f],n=Math.floor(g*(m+v[f]+u/2)/l[c]),n=l[c]&&g?Math.max(0,Math.min(g-1,n)):-1;var y={x:0,y:0};y[c]=u,y[d]=l[d],y[f]=-p[h]-l[f];var x,_=s.children();if(s.eachChild(function(t,n){var i=e(t);i.intersect(y)&&(null==x&&(x=n),r=t.__legendDataIndex),n===_.length-1&&i[f]+i[c]<=y[f]+y[c]&&(r=null)}),null!=x){var w=_[x],b=e(w);if(y[f]=b[f]+b[c]-y[c],0>=x&&b[f]>=y[f])i=null;else{for(;x>0&&e(_[x-1]).intersect(y);)x--;i=_[x].__legendDataIndex}}}return{contentPosition:p,pageIndex:n,pageCount:g,pagePrevDataIndex:i,pageNextDataIndex:r}}});Tl("legendScroll","legendscroll",function(t,e){var n=t.scrollDataIndex;null!=n&&e.eachComponent({mainType:"legend",subType:"scroll",query:t},function(t){t.setScrollDataIndex(n)})});var VM=function(t,e){var n,i=[],r=t.seriesIndex;if(null==r||!(n=e.getSeriesByIndex(r)))return{point:[]};var o=n.getData(),a=Fi(o,t);if(null==a||0>a||_(a))return{point:[]};var s=o.getItemGraphicEl(a),l=n.coordinateSystem;if(n.getTooltipPosition)i=n.getTooltipPosition(a)||[];else if(l&&l.dataToPoint)i=l.dataToPoint(o.getValues(p(l.dimensions,function(t){return o.mapDimension(t)}),a,!0))||[];else if(s){var u=s.getBoundingRect().clone();u.applyTransform(s.transform),i=[u.x+u.width/2,u.y+u.height/2]}return{point:i,el:s}},FM=f,HM=x,WM=Hi(),GM=function(t,e,n){var i=t.currTrigger,r=[t.x,t.y],o=t,a=t.dispatchAction||y(n.dispatchAction,n),s=e.getComponent("axisPointer").coordSysAxesInfo;if(s){nd(r)&&(r=VM({seriesIndex:o.seriesIndex,dataIndex:o.dataIndex},e).point);var l=nd(r),u=o.axesInfo,h=s.axesInfo,c="leave"===i||nd(r),d={},f={},p={list:[],map:{}},g={showPointer:HM(qc,f),showTooltip:HM($c,p)};FM(s.coordSysMap,function(t,e){var n=l||t.containPoint(r);FM(s.coordSysAxesInfo[e],function(t){var e=t.axis,i=td(u,t);if(!c&&n&&(!u||i)){var o=i&&i.value;null!=o||l||(o=e.pointToData(r)),null!=o&&Xc(t,o,g,!1,d)}})});var v={};return FM(h,function(t,e){var n=t.linkGroup;n&&!f[e]&&FM(n.axesInfo,function(e,i){var r=f[i];if(e!==t&&r){var o=r.value;n.mapper&&(o=t.axis.scale.parse(n.mapper(o,ed(e),ed(t)))),v[t.key]=o}})}),FM(v,function(t,e){Xc(h[e],t,g,!0,d)}),Kc(f,h,d),Qc(p,r,t,a),Jc(h,a,n),d}},UM=(El({type:"axisPointer",coordSysAxesInfo:null,defaultOption:{show:"auto",triggerOn:null,zlevel:0,z:50,type:"line",snap:!1,triggerTooltip:!0,value:null,status:null,link:[],animation:null,animationDurationUpdate:200,lineStyle:{color:"#aaa",width:1,type:"solid"},shadowStyle:{color:"rgba(150,150,150,0.3)"},label:{show:!0,formatter:null,precision:"auto",margin:3,color:"#fff",padding:[5,7,5,7],backgroundColor:"auto",borderColor:null,borderWidth:0,shadowBlur:3,shadowColor:"#aaa"},handle:{show:!1,icon:"M10.7,11.9v-1.3H9.3v1.3c-4.9,0.3-8.8,4.4-8.8,9.4c0,5,3.9,9.1,8.8,9.4h1.3c4.9-0.3,8.8-4.4,8.8-9.4C19.5,16.3,15.6,12.2,10.7,11.9z M13.3,24.4H6.7v-1.2h6.6z M13.3,22H6.7v-1.2h6.6z M13.3,19.6H6.7v-1.2h6.6z",size:45,margin:50,color:"#333",shadowBlur:3,shadowColor:"#aaa",shadowOffsetX:0,shadowOffsetY:2,throttle:40}}}),Hi()),ZM=f,jM=Rl({type:"axisPointer",render:function(t,e,n){var i=e.getComponent("tooltip"),r=t.get("triggerOn")||i&&i.get("triggerOn")||"mousemove|click";id("axisPointer",n,function(t,e,n){"none"!==r&&("leave"===t||r.indexOf(t)>=0)&&n({type:"updateAxisPointer",currTrigger:t,x:e&&e.offsetX,y:e&&e.offsetY})})},remove:function(t,e){ud(e.getZr(),"axisPointer"),jM.superApply(this._model,"remove",arguments)},dispose:function(t,e){ud("axisPointer",e),jM.superApply(this._model,"dispose",arguments)}}),XM=Hi(),YM=i,qM=y;hd.prototype={_group:null,_lastGraphicKey:null,_handle:null,_dragging:!1,_lastValue:null,_lastStatus:null,_payloadInfo:null,animationThreshold:15,render:function(t,e,n,i){var r=e.get("value"),o=e.get("status");if(this._axisModel=t,this._axisPointerModel=e,this._api=n,i||this._lastValue!==r||this._lastStatus!==o){this._lastValue=r,this._lastStatus=o;var a=this._group,s=this._handle;if(!o||"hide"===o)return a&&a.hide(),void(s&&s.hide());a&&a.show(),s&&s.show();var l={};this.makeElOption(l,r,t,e,n);var u=l.graphicKey;u!==this._lastGraphicKey&&this.clear(n),this._lastGraphicKey=u;var h=this._moveAnimation=this.determineAnimation(t,e);if(a){var c=x(cd,e,h);this.updatePointerEl(a,l,c,e),this.updateLabelEl(a,l,c,e)}else a=this._group=new nv,this.createPointerEl(a,l,t,e),this.createLabelEl(a,l,t,e),n.getZr().add(a);gd(a,e,!0),this._renderHandle(r)}},remove:function(t){this.clear(t)},dispose:function(t){this.clear(t)},determineAnimation:function(t,e){var n=e.get("animation"),i=t.axis,r="category"===i.type,o=e.get("snap");if(!o&&!r)return!1;if("auto"===n||null==n){var a=this.animationThreshold;if(r&&i.getBandWidth()>a)return!0;if(o){var s=Kh(t).seriesDataCount,l=i.getExtent();return Math.abs(l[0]-l[1])/s>a}return!1}return n===!0},makeElOption:function(){},createPointerEl:function(t,e){var n=e.pointer;if(n){var i=XM(t).pointerEl=new Vy[n.type](YM(e.pointer));t.add(i)}},createLabelEl:function(t,e,n,i){if(e.label){var r=XM(t).labelEl=new Sy(YM(e.label));t.add(r),fd(r,i)}},updatePointerEl:function(t,e,n){var i=XM(t).pointerEl;i&&(i.setStyle(e.pointer.style),n(i,{shape:e.pointer.shape}))},updateLabelEl:function(t,e,n,i){var r=XM(t).labelEl;r&&(r.setStyle(e.label.style),n(r,{shape:e.label.shape,position:e.label.position}),fd(r,i))},_renderHandle:function(t){if(!this._dragging&&this.updateHandleTransform){var e=this._axisPointerModel,n=this._api.getZr(),i=this._handle,r=e.getModel("handle"),o=e.get("status");if(!r.get("show")||!o||"hide"===o)return i&&n.remove(i),void(this._handle=null);var a;this._handle||(a=!0,i=this._handle=Po(r.get("icon"),{cursor:"move",draggable:!0,onmousemove:function(t){zv(t.event)},onmousedown:qM(this._onHandleDragMove,this,0,0),drift:qM(this._onHandleDragMove,this),ondragend:qM(this._onHandleDragEnd,this)}),n.add(i)),gd(i,e,!1);
+var s=["color","borderColor","borderWidth","opacity","shadowColor","shadowBlur","shadowOffsetX","shadowOffsetY"];i.setStyle(r.getItemStyle(null,s));var l=r.get("size");_(l)||(l=[l,l]),i.attr("scale",[l[0]/2,l[1]/2]),Os(this,"_doDispatchAxisPointer",r.get("throttle")||0,"fixRate"),this._moveHandleToValue(t,a)}},_moveHandleToValue:function(t,e){cd(this._axisPointerModel,!e&&this._moveAnimation,this._handle,pd(this.getHandleTransform(t,this._axisModel,this._axisPointerModel)))},_onHandleDragMove:function(t,e){var n=this._handle;if(n){this._dragging=!0;var i=this.updateHandleTransform(pd(n),[t,e],this._axisModel,this._axisPointerModel);this._payloadInfo=i,n.stopAnimation(),n.attr(pd(i)),XM(n).lastProp=null,this._doDispatchAxisPointer()}},_doDispatchAxisPointer:function(){var t=this._handle;if(t){var e=this._payloadInfo,n=this._axisModel;this._api.dispatchAction({type:"updateAxisPointer",x:e.cursorPoint[0],y:e.cursorPoint[1],tooltipOption:e.tooltipOption,axesInfo:[{axisDim:n.axis.dim,axisIndex:n.componentIndex}]})}},_onHandleDragEnd:function(){this._dragging=!1;var t=this._handle;if(t){var e=this._axisPointerModel.get("value");this._moveHandleToValue(e),this._api.dispatchAction({type:"hideTip"})}},getHandleTransform:null,updateHandleTransform:null,clear:function(t){this._lastValue=null,this._lastStatus=null;var e=t.getZr(),n=this._group,i=this._handle;e&&n&&(this._lastGraphicKey=null,n&&e.remove(n),i&&e.remove(i),this._group=null,this._handle=null,this._payloadInfo=null)},doClear:function(){},buildLabel:function(t,e,n){return n=n||0,{x:t[n],y:t[1-n],width:e[n],height:e[1-n]}}},hd.prototype.constructor=hd,Yi(hd);var $M=hd.extend({makeElOption:function(t,e,n,i,r){var o=n.axis,a=o.grid,s=i.get("type"),l=Sd(a,o).getOtherAxis(o).getGlobalExtent(),u=o.toGlobalCoord(o.dataToCoord(e,!0));if(s&&"none"!==s){var h=vd(i),c=KM[s](o,u,l,h);c.style=h,t.graphicKey=c.type,t.pointer=c}var d=ic(a.model,n);wd(e,t,d,n,i,r)},getHandleTransform:function(t,e,n){var i=ic(e.axis.grid.model,e,{labelInside:!1});return i.labelMargin=n.get("handle.margin"),{position:_d(e.axis,t,i),rotation:i.rotation+(i.labelDirection<0?Math.PI:0)}},updateHandleTransform:function(t,e,n){var i=n.axis,r=i.grid,o=i.getGlobalExtent(!0),a=Sd(r,i).getOtherAxis(i).getGlobalExtent(),s="x"===i.dim?0:1,l=t.position;l[s]+=e[s],l[s]=Math.min(o[1],l[s]),l[s]=Math.max(o[0],l[s]);var u=(a[1]+a[0])/2,h=[u,u];h[s]=l[s];var c=[{verticalAlign:"middle"},{align:"center"}];return{position:l,rotation:t.rotation,cursorPoint:h,tooltipOption:c[s]}}}),KM={line:function(t,e,n,i){var r=bd([e,n[0]],[e,n[1]],Id(t));return qr({shape:r,style:i}),{type:"Line",shape:r}},shadow:function(t,e,n){var i=Math.max(1,t.getBandWidth()),r=n[1]-n[0];return{type:"Rect",shape:Md([e-i/2,n[0]],[i,r],Id(t))}}};Fb.registerAxisPointerClass("CartesianAxisPointer",$M),Sl(function(t){if(t){(!t.axisPointer||0===t.axisPointer.length)&&(t.axisPointer={});var e=t.axisPointer.link;e&&!_(e)&&(t.axisPointer.link=[e])}}),Il(W_.PROCESSOR.STATISTIC,function(t,e){t.getComponent("axisPointer").coordSysAxesInfo=Uh(t,e)}),Tl({type:"updateAxisPointer",event:"updateAxisPointer",update:":updateAxisPointer"},GM),El({type:"tooltip",dependencies:["axisPointer"],defaultOption:{zlevel:0,z:8,show:!0,showContent:!0,trigger:"item",triggerOn:"mousemove|click",alwaysShowContent:!1,displayMode:"single",confine:!1,showDelay:0,hideDelay:100,transitionDuration:.4,enterable:!1,backgroundColor:"rgba(50,50,50,0.7)",borderColor:"#333",borderRadius:4,borderWidth:0,padding:5,extraCssText:"",axisPointer:{type:"line",axis:"auto",animation:"auto",animationDurationUpdate:200,animationEasingUpdate:"exponentialOut",crossStyle:{color:"#999",width:1,type:"dashed",textStyle:{}}},textStyle:{color:"#fff",fontSize:14}}});var QM=f,JM=na,tS=["","-webkit-","-moz-","-o-"],eS="position:absolute;display:block;border-style:solid;white-space:nowrap;z-index:9999999;";Dd.prototype={constructor:Dd,_enterable:!0,update:function(){var t=this._container,e=t.currentStyle||document.defaultView.getComputedStyle(t),n=t.style;"absolute"!==n.position&&"absolute"!==e.position&&(n.position="relative")},show:function(t){clearTimeout(this._hideTimeout);var e=this.el;e.style.cssText=eS+Ad(t)+";left:"+this._x+"px;top:"+this._y+"px;"+(t.get("extraCssText")||""),e.style.display=e.innerHTML?"block":"none",this._show=!0},setContent:function(t){this.el.innerHTML=null==t?"":t},setEnterable:function(t){this._enterable=t},getSize:function(){var t=this.el;return[t.clientWidth,t.clientHeight]},moveTo:function(t,e){var n,i=this._zr;i&&i.painter&&(n=i.painter.getViewportRootOffset())&&(t+=n.offsetLeft,e+=n.offsetTop);var r=this.el.style;r.left=t+"px",r.top=e+"px",this._x=t,this._y=e},hide:function(){this.el.style.display="none",this._show=!1},hideLater:function(t){!this._show||this._inContent&&this._enterable||(t?(this._hideDelay=t,this._show=!1,this._hideTimeout=setTimeout(y(this.hide,this),t)):this.hide())},isShow:function(){return this._show}};var nS=y,iS=f,rS=Fo,oS=new Sy({shape:{x:-1,y:-1,width:2,height:2}});Rl({type:"tooltip",init:function(t,e){if(!Jp.node){var n=new Dd(e.getDom(),e);this._tooltipContent=n}},render:function(t,e,n){if(!Jp.node&&!Jp.wxa){this.group.removeAll(),this._tooltipModel=t,this._ecModel=e,this._api=n,this._lastDataByCoordSys=null,this._alwaysShowContent=t.get("alwaysShowContent");var i=this._tooltipContent;i.update(),i.setEnterable(t.get("enterable")),this._initGlobalListener(),this._keepShow()}},_initGlobalListener:function(){var t=this._tooltipModel,e=t.get("triggerOn");id("itemTooltip",this._api,nS(function(t,n,i){"none"!==e&&(e.indexOf(t)>=0?this._tryShow(n,i):"leave"===t&&this._hide(i))},this))},_keepShow:function(){var t=this._tooltipModel,e=this._ecModel,n=this._api;if(null!=this._lastX&&null!=this._lastY&&"none"!==t.get("triggerOn")){var i=this;clearTimeout(this._refreshUpdateTimeout),this._refreshUpdateTimeout=setTimeout(function(){i.manuallyShowTip(t,e,n,{x:i._lastX,y:i._lastY})})}},manuallyShowTip:function(t,e,n,i){if(i.from!==this.uid&&!Jp.node){var r=Pd(i,n);this._ticket="";var o=i.dataByCoordSys;if(i.tooltip&&null!=i.x&&null!=i.y){var a=oS;a.position=[i.x,i.y],a.update(),a.tooltip=i.tooltip,this._tryShow({offsetX:i.x,offsetY:i.y,target:a},r)}else if(o)this._tryShow({offsetX:i.x,offsetY:i.y,position:i.position,event:{},dataByCoordSys:i.dataByCoordSys,tooltipOption:i.tooltipOption},r);else if(null!=i.seriesIndex){if(this._manuallyAxisShowTip(t,e,n,i))return;var s=VM(i,e),l=s.point[0],u=s.point[1];null!=l&&null!=u&&this._tryShow({offsetX:l,offsetY:u,position:i.position,target:s.el,event:{}},r)}else null!=i.x&&null!=i.y&&(n.dispatchAction({type:"updateAxisPointer",x:i.x,y:i.y}),this._tryShow({offsetX:i.x,offsetY:i.y,position:i.position,target:n.getZr().findHover(i.x,i.y).target,event:{}},r))}},manuallyHideTip:function(t,e,n,i){var r=this._tooltipContent;!this._alwaysShowContent&&this._tooltipModel&&r.hideLater(this._tooltipModel.get("hideDelay")),this._lastX=this._lastY=null,i.from!==this.uid&&this._hide(Pd(i,n))},_manuallyAxisShowTip:function(t,e,n,i){var r=i.seriesIndex,o=i.dataIndex,a=e.getComponent("axisPointer").coordSysAxesInfo;if(null!=r&&null!=o&&null!=a){var s=e.getSeriesByIndex(r);if(s){var l=s.getData(),t=kd([l.getItemModel(o),s,(s.coordinateSystem||{}).model,t]);if("axis"===t.get("trigger"))return n.dispatchAction({type:"updateAxisPointer",seriesIndex:r,dataIndex:o,position:i.position}),!0}}},_tryShow:function(t,e){var n=t.target,i=this._tooltipModel;if(i){this._lastX=t.offsetX,this._lastY=t.offsetY;var r=t.dataByCoordSys;r&&r.length?this._showAxisTooltip(r,t):n&&null!=n.dataIndex?(this._lastDataByCoordSys=null,this._showSeriesItemTooltip(t,n,e)):n&&n.tooltip?(this._lastDataByCoordSys=null,this._showComponentItemTooltip(t,n,e)):(this._lastDataByCoordSys=null,this._hide(e))}},_showOrMove:function(t,e){var n=t.get("showDelay");e=y(e,this),clearTimeout(this._showTimout),n>0?this._showTimout=setTimeout(e,n):e()},_showAxisTooltip:function(t,e){var n=this._ecModel,i=this._tooltipModel,r=[e.offsetX,e.offsetY],o=[],a=[],s=kd([e.tooltipOption,i]);iS(t,function(t){iS(t.dataByAxis,function(t){var e=n.getComponent(t.axisDim+"Axis",t.axisIndex),i=t.value,r=[];if(e&&null!=i){var s=xd(i,e.axis,n,t.seriesDataIndices,t.valueLabelOpt);f(t.seriesDataIndices,function(o){var l=n.getSeriesByIndex(o.seriesIndex),u=o.dataIndexInside,h=l&&l.getDataParams(u);h.axisDim=t.axisDim,h.axisIndex=t.axisIndex,h.axisType=t.axisType,h.axisId=t.axisId,h.axisValue=Fu(e.axis,i),h.axisValueLabel=s,h&&(a.push(h),r.push(l.formatTooltip(u,!0)))});var l=s;o.push((l?ia(l)+"<br />":"")+r.join("<br />"))}})},this),o.reverse(),o=o.join("<br /><br />");var l=e.position;this._showOrMove(s,function(){this._updateContentNotChangedOnAxis(t)?this._updatePosition(s,l,r[0],r[1],this._tooltipContent,a):this._showTooltipContent(s,o,a,Math.random(),r[0],r[1],l)})},_showSeriesItemTooltip:function(t,e,n){var i=this._ecModel,r=e.seriesIndex,o=i.getSeriesByIndex(r),a=e.dataModel||o,s=e.dataIndex,l=e.dataType,u=a.getData(),h=kd([u.getItemModel(s),a,o&&(o.coordinateSystem||{}).model,this._tooltipModel]),c=h.get("trigger");if(null==c||"item"===c){var d=a.getDataParams(s,l),f=a.formatTooltip(s,!1,l),p="item_"+a.name+"_"+s;this._showOrMove(h,function(){this._showTooltipContent(h,f,d,p,t.offsetX,t.offsetY,t.position,t.target)}),n({type:"showTip",dataIndexInside:s,dataIndex:u.getRawIndex(s),seriesIndex:r,from:this.uid})}},_showComponentItemTooltip:function(t,e,n){var i=e.tooltip;if("string"==typeof i){var r=i;i={content:r,formatter:r}}var o=new Lo(i,this._tooltipModel,this._ecModel),a=o.get("content"),s=Math.random();this._showOrMove(o,function(){this._showTooltipContent(o,a,o.get("formatterParams")||{},s,t.offsetX,t.offsetY,t.position,e)}),n({type:"showTip",from:this.uid})},_showTooltipContent:function(t,e,n,i,r,o,a,s){if(this._ticket="",t.get("showContent")&&t.get("show")){var l=this._tooltipContent,u=t.get("formatter");a=a||t.get("position");var h=e;if(u&&"string"==typeof u)h=ra(u,n,!0);else if("function"==typeof u){var c=nS(function(e,i){e===this._ticket&&(l.setContent(i),this._updatePosition(t,a,r,o,l,n,s))},this);this._ticket=i,h=u(n,i,c)}l.setContent(h),l.show(t),this._updatePosition(t,a,r,o,l,n,s)}},_updatePosition:function(t,e,n,i,r,o,a){var s=this._api.getWidth(),l=this._api.getHeight();e=e||t.get("position");var u=r.getSize(),h=t.get("align"),c=t.get("verticalAlign"),d=a&&a.getBoundingRect().clone();if(a&&d.applyTransform(a.transform),"function"==typeof e&&(e=e([n,i],o,r.el,d,{viewSize:[s,l],contentSize:u.slice()})),_(e))n=rS(e[0],s),i=rS(e[1],l);else if(M(e)){e.width=u[0],e.height=u[1];var f=ca(e,{width:s,height:l});n=f.x,i=f.y,h=null,c=null}else if("string"==typeof e&&a){var p=Rd(e,d,u);n=p[0],i=p[1]}else{var p=Ld(n,i,r.el,s,l,h?null:20,c?null:20);n=p[0],i=p[1]}if(h&&(n-=zd(h)?u[0]/2:"right"===h?u[0]:0),c&&(i-=zd(c)?u[1]/2:"bottom"===c?u[1]:0),t.get("confine")){var p=Od(n,i,r.el,s,l);n=p[0],i=p[1]}r.moveTo(n,i)},_updateContentNotChangedOnAxis:function(t){var e=this._lastDataByCoordSys,n=!!e&&e.length===t.length;return n&&iS(e,function(e,i){var r=e.dataByAxis||{},o=t[i]||{},a=o.dataByAxis||[];n&=r.length===a.length,n&&iS(r,function(t,e){var i=a[e]||{},r=t.seriesDataIndices||[],o=i.seriesDataIndices||[];n&=t.value===i.value&&t.axisType===i.axisType&&t.axisId===i.axisId&&r.length===o.length,n&&iS(r,function(t,e){var i=o[e];n&=t.seriesIndex===i.seriesIndex&&t.dataIndex===i.dataIndex})})}),this._lastDataByCoordSys=t,!!n},_hide:function(t){this._lastDataByCoordSys=null,t({type:"hideTip",from:this.uid})},dispose:function(t,e){Jp.node||Jp.wxa||(this._tooltipContent.hide(),ud("itemTooltip",e))}}),Tl({type:"showTip",event:"showTip",update:"tooltip:manuallyShowTip"},function(){}),Tl({type:"hideTip",event:"hideTip",update:"tooltip:manuallyHideTip"},function(){});var aS={},sS=El({type:"toolbox",layoutMode:{type:"box",ignoreSize:!0},optionUpdated:function(){sS.superApply(this,"optionUpdated",arguments),f(this.option.feature,function(t,e){var n=Nd(e);n&&r(t,n.defaultOption)})},defaultOption:{show:!0,z:6,zlevel:0,orient:"horizontal",left:"right",top:"top",backgroundColor:"transparent",borderColor:"#ccc",borderRadius:0,borderWidth:0,padding:5,itemSize:15,itemGap:8,showTitle:!0,iconStyle:{borderColor:"#666",color:"none"},emphasis:{iconStyle:{borderColor:"#3E98C5"}}}});Rl({type:"toolbox",render:function(t,e,n,i){function r(r,a){var s,c=h[r],d=h[a],f=l[c],p=new Lo(f,t,t.ecModel);if(c&&!d){if(Vd(c))s={model:p,onclick:p.option.onclick,featureName:c};else{var g=Nd(c);if(!g)return;s=new g(p,e,n)}u[c]=s}else{if(s=u[d],!s)return;s.model=p,s.ecModel=e,s.api=n}return!c&&d?void(s.dispose&&s.dispose(e,n)):!p.get("show")||s.unusable?void(s.remove&&s.remove(e,n)):(o(p,s,c),p.setIconStatus=function(t,e){var n=this.option,i=this.iconPaths;n.iconStatus=n.iconStatus||{},n.iconStatus[t]=e,i[t]&&i[t].trigger(e)},void(s.render&&s.render(p,e,n,i)))}function o(i,r,o){var l=i.getModel("iconStyle"),u=i.getModel("emphasis.iconStyle"),h=r.getIcons?r.getIcons():i.get("icon"),c=i.get("title")||{};if("string"==typeof h){var d=h,p=c;h={},c={},h[o]=d,c[o]=p}var g=i.iconPaths={};f(h,function(o,h){var d=Po(o,{},{x:-s/2,y:-s/2,width:s,height:s});d.setStyle(l.getItemStyle()),d.hoverStyle=u.getItemStyle(),ho(d),t.get("showTitle")&&(d.__title=c[h],d.on("mouseover",function(){var t=u.getItemStyle();d.setStyle({text:c[h],textPosition:t.textPosition||"bottom",textFill:t.fill||t.stroke||"#000",textAlign:t.textAlign||"center"})}).on("mouseout",function(){d.setStyle({textFill:null})})),d.trigger(i.get("iconStatus."+h)||"normal"),a.add(d),d.on("click",y(r.onclick,r,e,n,h)),g[h]=d})}var a=this.group;if(a.removeAll(),t.get("show")){var s=+t.get("itemSize"),l=t.get("feature")||{},u=this._features||(this._features={}),h=[];f(l,function(t,e){h.push(e)}),new Wl(this._featureNames||[],h).add(r).update(r).remove(x(r,null)).execute(),this._featureNames=h,Hc(a,t,n),a.add(Wc(a.getBoundingRect(),t)),a.eachChild(function(t){var e=t.__title,i=t.hoverStyle;if(i&&e){var r=Sn(e,Vn(i)),o=t.position[0]+a.position[0],l=t.position[1]+a.position[1]+s,u=!1;l+r.height>n.getHeight()&&(i.textPosition="top",u=!0);var h=u?-5-r.height:s+8;o+r.width/2>n.getWidth()?(i.textPosition=["100%",h],i.textAlign="right"):o-r.width/2<0&&(i.textPosition=[0,h],i.textAlign="left")}})}},updateView:function(t,e,n,i){f(this._features,function(t){t.updateView&&t.updateView(t.model,e,n,i)})},remove:function(t,e){f(this._features,function(n){n.remove&&n.remove(t,e)}),this.group.removeAll()},dispose:function(t,e){f(this._features,function(n){n.dispose&&n.dispose(t,e)})}});var lS=c_.toolbox.saveAsImage;Fd.defaultOption={show:!0,icon:"M4.7,22.9L29.3,45.5L54.7,23.4M4.6,43.6L4.6,58L53.8,58L53.8,43.6M29.2,45.1L29.2,0",title:lS.title,type:"png",name:"",excludeComponents:["toolbox"],pixelRatio:1,lang:lS.lang.slice()},Fd.prototype.unusable=!Jp.canvasSupported;var uS=Fd.prototype;uS.onclick=function(t,e){var n=this.model,i=n.get("name")||t.get("title.0.text")||"echarts",r=document.createElement("a"),o=n.get("type",!0)||"png";r.download=i+"."+o,r.target="_blank";var a=e.getConnectedDataURL({type:o,backgroundColor:n.get("backgroundColor",!0)||t.get("backgroundColor")||"#fff",excludeComponents:n.get("excludeComponents"),pixelRatio:n.get("pixelRatio")});if(r.href=a,"function"!=typeof MouseEvent||Jp.browser.ie||Jp.browser.edge)if(window.navigator.msSaveOrOpenBlob){for(var s=atob(a.split(",")[1]),l=s.length,u=new Uint8Array(l);l--;)u[l]=s.charCodeAt(l);var h=new Blob([u]);window.navigator.msSaveOrOpenBlob(h,i+"."+o)}else{var c=n.get("lang"),d='<body style="margin:0;"><img src="'+a+'" style="max-width:100%;" title="'+(c&&c[0]||"")+'" /></body>',f=window.open();f.document.write(d)}else{var p=new MouseEvent("click",{view:window,bubbles:!0,cancelable:!1});r.dispatchEvent(p)}},Bd("saveAsImage",Fd);var hS=c_.toolbox.magicType;Hd.defaultOption={show:!0,type:[],icon:{line:"M4.1,28.9h7.1l9.3-22l7.4,38l9.7-19.7l3,12.8h14.9M4.1,58h51.4",bar:"M6.7,22.9h10V48h-10V22.9zM24.9,13h10v35h-10V13zM43.2,2h10v46h-10V2zM3.1,58h53.7",stack:"M8.2,38.4l-8.4,4.1l30.6,15.3L60,42.5l-8.1-4.1l-21.5,11L8.2,38.4z M51.9,30l-8.1,4.2l-13.4,6.9l-13.9-6.9L8.2,30l-8.4,4.2l8.4,4.2l22.2,11l21.5-11l8.1-4.2L51.9,30z M51.9,21.7l-8.1,4.2L35.7,30l-5.3,2.8L24.9,30l-8.4-4.1l-8.3-4.2l-8.4,4.2L8.2,30l8.3,4.2l13.9,6.9l13.4-6.9l8.1-4.2l8.1-4.1L51.9,21.7zM30.4,2.2L-0.2,17.5l8.4,4.1l8.3,4.2l8.4,4.2l5.5,2.7l5.3-2.7l8.1-4.2l8.1-4.2l8.1-4.1L30.4,2.2z",tiled:"M2.3,2.2h22.8V25H2.3V2.2z M35,2.2h22.8V25H35V2.2zM2.3,35h22.8v22.8H2.3V35z M35,35h22.8v22.8H35V35z"},title:i(hS.title),option:{},seriesIndex:{}};var cS=Hd.prototype;cS.getIcons=function(){var t=this.model,e=t.get("icon"),n={};return f(t.get("type"),function(t){e[t]&&(n[t]=e[t])}),n};var dS={line:function(t,e,n,i){return"bar"===t?r({id:e,type:"line",data:n.get("data"),stack:n.get("stack"),markPoint:n.get("markPoint"),markLine:n.get("markLine")},i.get("option.line")||{},!0):void 0},bar:function(t,e,n,i){return"line"===t?r({id:e,type:"bar",data:n.get("data"),stack:n.get("stack"),markPoint:n.get("markPoint"),markLine:n.get("markLine")},i.get("option.bar")||{},!0):void 0},stack:function(t,e,n,i){return"line"===t||"bar"===t?r({id:e,stack:"__ec_magicType_stack__"},i.get("option.stack")||{},!0):void 0},tiled:function(t,e,n,i){return"line"===t||"bar"===t?r({id:e,stack:""},i.get("option.tiled")||{},!0):void 0}},fS=[["line","bar"],["stack","tiled"]];cS.onclick=function(t,e,n){var i=this.model,r=i.get("seriesIndex."+n);if(dS[n]){var o={series:[]},a=function(e){var r=e.subType,a=e.id,l=dS[n](r,a,e,i);l&&(s(l,e.option),o.series.push(l));var u=e.coordinateSystem;if(u&&"cartesian2d"===u.type&&("line"===n||"bar"===n)){var h=u.getAxesByScale("ordinal")[0];if(h){var c=h.dim,d=c+"Axis",f=t.queryComponents({mainType:d,index:e.get(name+"Index"),id:e.get(name+"Id")})[0],p=f.componentIndex;o[d]=o[d]||[];for(var g=0;p>=g;g++)o[d][p]=o[d][p]||{};o[d][p].boundaryGap="bar"===n?!0:!1}}};f(fS,function(t){u(t,n)>=0&&f(t,function(t){i.setIconStatus(t,"normal")})}),i.setIconStatus(n,"emphasis"),t.eachComponent({mainType:"series",query:null==r?null:{seriesIndex:r}},a),e.dispatchAction({type:"changeMagicType",currentType:n,newOption:o})}},Tl({type:"changeMagicType",event:"magicTypeChanged",update:"prepareAndUpdate"},function(t,e){e.mergeOption(t.newOption)}),Bd("magicType",Hd);var pS=c_.toolbox.dataView,gS=new Array(60).join("-"),vS="    ",mS=new RegExp("["+vS+"]+","g");Kd.defaultOption={show:!0,readOnly:!1,optionToContent:null,contentToOption:null,icon:"M17.5,17.3H33 M17.5,17.3H33 M45.4,29.5h-28 M11.5,2v56H51V14.8L38.4,2H11.5z M38.4,2.2v12.7H51 M45.4,41.7h-28",title:i(pS.title),lang:i(pS.lang),backgroundColor:"#fff",textColor:"#000",textareaColor:"#fff",textareaBorderColor:"#333",buttonColor:"#c23531",buttonTextColor:"#fff"},Kd.prototype.onclick=function(t,e){function n(){i.removeChild(o),x._dom=null}var i=e.getDom(),r=this.model;this._dom&&i.removeChild(this._dom);var o=document.createElement("div");o.style.cssText="position:absolute;left:5px;top:5px;bottom:5px;right:5px;",o.style.backgroundColor=r.get("backgroundColor")||"#fff";var a=document.createElement("h4"),s=r.get("lang")||[];a.innerHTML=s[0]||r.get("title"),a.style.cssText="margin: 10px 20px;",a.style.color=r.get("textColor");var l=document.createElement("div"),u=document.createElement("textarea");l.style.cssText="display:block;width:100%;overflow:auto;";var h=r.get("optionToContent"),c=r.get("contentToOption"),d=Zd(t);if("function"==typeof h){var f=h(e.getOption());"string"==typeof f?l.innerHTML=f:C(f)&&l.appendChild(f)}else l.appendChild(u),u.readOnly=r.get("readOnly"),u.style.cssText="width:100%;height:100%;font-family:monospace;font-size:14px;line-height:1.6rem;",u.style.color=r.get("textColor"),u.style.borderColor=r.get("textareaBorderColor"),u.style.backgroundColor=r.get("textareaColor"),u.value=d.value;var p=d.meta,g=document.createElement("div");g.style.cssText="position:absolute;bottom:0;left:0;right:0;";var v="float:right;margin-right:20px;border:none;cursor:pointer;padding:2px 5px;font-size:12px;border-radius:3px",m=document.createElement("div"),y=document.createElement("div");v+=";background-color:"+r.get("buttonColor"),v+=";color:"+r.get("buttonTextColor");var x=this;mi(m,"click",n),mi(y,"click",function(){var t;try{t="function"==typeof c?c(l,e.getOption()):$d(u.value,p)}catch(i){throw n(),new Error("Data view format error "+i)}t&&e.dispatchAction({type:"changeDataView",newOption:t}),n()}),m.innerHTML=s[1],y.innerHTML=s[2],y.style.cssText=v,m.style.cssText=v,!r.get("readOnly")&&g.appendChild(y),g.appendChild(m),mi(u,"keydown",function(t){if(9===(t.keyCode||t.which)){var e=this.value,n=this.selectionStart,i=this.selectionEnd;this.value=e.substring(0,n)+vS+e.substring(i),this.selectionStart=this.selectionEnd=n+1,zv(t)}}),o.appendChild(a),o.appendChild(l),o.appendChild(g),l.style.height=i.clientHeight-80+"px",i.appendChild(o),this._dom=o},Kd.prototype.remove=function(t,e){this._dom&&e.getDom().removeChild(this._dom)},Kd.prototype.dispose=function(t,e){this.remove(t,e)},Bd("dataView",Kd),Tl({type:"changeDataView",event:"dataViewChanged",update:"prepareAndUpdate"},function(t,e){var n=[];f(t.newOption.series,function(t){var i=e.getSeriesByName(t.name)[0];if(i){var r=i.get("data");n.push({name:t.name,data:Qd(t.data,r)})}else n.push(a({type:"scatter"},t))}),e.mergeOption(s({series:n},t.newOption))});var yS="\x00_ec_interaction_mutex";Tl({type:"takeGlobalCursor",event:"globalCursorTaken",update:"update"},function(){});var xS=x,_S=f,wS=p,bS=Math.min,MS=Math.max,SS=Math.pow,IS=1e4,CS=6,TS=6,AS="globalPan",DS={w:[0,0],e:[0,1],n:[1,0],s:[1,1]},kS={w:"ew",e:"ew",n:"ns",s:"ns",ne:"nesw",sw:"nesw",nw:"nwse",se:"nwse"},PS={brushStyle:{lineWidth:2,stroke:"rgba(0,0,0,0.3)",fill:"rgba(0,0,0,0.1)"},transformable:!0,brushMode:"single",removeOnClick:!1},LS=0;nf.prototype={constructor:nf,enableBrush:function(t){return this._brushType&&of(this),t.brushType&&rf(this,t),this},setPanels:function(t){if(t&&t.length){var e=this._panels={};f(t,function(t){e[t.panelId]=i(t)})}else this._panels=null;return this},mount:function(t){t=t||{},this._enableGlobalPan=t.enableGlobalPan;var e=this.group;return this._zr.add(e),e.attr({position:t.position||[0,0],rotation:t.rotation||0,scale:t.scale||[1,1]}),this._transform=e.getLocalTransform(),this},eachCover:function(t,e){_S(this._covers,t,e)},updateCovers:function(t){function e(t,e){return(null!=t.id?t.id:s+e)+"-"+t.brushType}function n(t,n){return e(t.__brushOption,n)}function o(e,n){var i=t[e];if(null!=n&&l[n]===c)u[e]=l[n];else{var r=u[e]=null!=n?(l[n].__brushOption=i,l[n]):sf(h,af(h,i));hf(h,r)}}function a(t){l[t]!==c&&h.group.remove(l[t])}t=p(t,function(t){return r(i(PS),t,!0)});var s="\x00-brush-index-",l=this._covers,u=this._covers=[],h=this,c=this._creatingCover;return new Wl(l,t,n,e).add(o).update(o).remove(a).execute(),this},unmount:function(){return this.enableBrush(!1),pf(this),this._zr.remove(this.group),this},dispose:function(){this.unmount(),this.off()}},c(nf,wg);var OS={mousedown:function(t){if(this._dragging)zf.call(this,t);else if(!t.target||!t.target.draggable){Lf(t);var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY);this._creatingCover=null;var n=this._creatingPanel=df(this,t,e);n&&(this._dragging=!0,this._track=[e.slice()])}},mousemove:function(t){var e=this.group.transformCoordToLocal(t.offsetX,t.offsetY);if(Pf(this,t,e),this._dragging){Lf(t);var n=Ef(this,t,e,!1);n&&gf(this,n)}},mouseup:zf},ES={lineX:Bf(0),lineY:Bf(1),rect:{createCover:function(t,e){return yf(xS(Cf,function(t){return t},function(t){return t}),t,e,["w","e","n","s","se","sw","ne","nw"])},getCreatingRange:function(t){var e=mf(t);return Mf(e[1][0],e[1][1],e[0][0],e[0][1])},updateCoverShape:function(t,e,n,i){xf(t,e,n,i)},updateCommon:_f,contain:Of},polygon:{createCover:function(t,e){var n=new nv;return n.add(new My({name:"main",style:bf(e),silent:!0})),n},getCreatingRange:function(t){return t},endCreating:function(t,e){e.remove(e.childAt(0)),e.add(new by({name:"main",draggable:!0,drift:xS(Tf,t,e),ondragend:xS(gf,t,{isEnd:!0})}))},updateCoverShape:function(t,e,n){e.childAt(0).setShape({points:Df(t,e,n)})},updateCommon:_f,contain:Of}},RS={axisPointer:1,tooltip:1,brush:1},zS=f,BS=u,NS=x,VS=["dataToPoint","pointToData"],FS=["grid","xAxis","yAxis","geo","graph","polar","radiusAxis","angleAxis","bmap"],HS=Gf.prototype;HS.setOutputRanges=function(t,e){this.matchOutputRanges(t,e,function(t,e,n){if((t.coordRanges||(t.coordRanges=[])).push(e),!t.coordRange){t.coordRange=e;var i=ZS[t.brushType](0,n,e);t.__rangeOffset={offset:jS[t.brushType](i.values,t.range,[1,1]),xyMinMax:i.xyMinMax}}})},HS.matchOutputRanges=function(t,e,n){zS(t,function(t){var i=this.findTargetInfo(t,e);i&&i!==!0&&f(i.coordSyses,function(i){var r=ZS[t.brushType](1,i,t.range);n(t,r.values,i,e)})},this)},HS.setInputRanges=function(t,e){zS(t,function(t){var n=this.findTargetInfo(t,e);if(t.range=t.range||[],n&&n!==!0){t.panelId=n.panelId;var i=ZS[t.brushType](0,n.coordSys,t.coordRange),r=t.__rangeOffset;t.range=r?jS[t.brushType](i.values,r.offset,Yf(i.xyMinMax,r.xyMinMax)):i.values}},this)},HS.makePanelOpts=function(t,e){return p(this._targetInfoList,function(n){var i=n.getPanelRect();return{panelId:n.panelId,defaultBrushType:e&&e(n),clipPath:Vf(i),isTargetByCursor:Hf(i,t,n.coordSysModel),getLinearBrushOtherExtent:Ff(i)}})},HS.controlSeries=function(t,e,n){var i=this.findTargetInfo(t,n);return i===!0||i&&BS(i.coordSyses,e.coordinateSystem)>=0},HS.findTargetInfo=function(t,e){for(var n=this._targetInfoList,i=Zf(e,t),r=0;r<n.length;r++){var o=n[r],a=t.panelId;if(a){if(o.panelId===a)return o}else for(var r=0;r<GS.length;r++)if(GS[r](i,o))return o}return!0};var WS={grid:function(t,e){var n=t.xAxisModels,i=t.yAxisModels,r=t.gridModels,o=N(),a={},s={};(n||i||r)&&(zS(n,function(t){var e=t.axis.grid.model;o.set(e.id,e),a[e.id]=!0}),zS(i,function(t){var e=t.axis.grid.model;o.set(e.id,e),s[e.id]=!0}),zS(r,function(t){o.set(t.id,t),a[t.id]=!0,s[t.id]=!0}),o.each(function(t){var r=t.coordinateSystem,o=[];zS(r.getCartesians(),function(t){(BS(n,t.getAxis("x").model)>=0||BS(i,t.getAxis("y").model)>=0)&&o.push(t)}),e.push({panelId:"grid--"+t.id,gridModel:t,coordSysModel:t,coordSys:o[0],coordSyses:o,getPanelRect:US.grid,xAxisDeclared:a[t.id],yAxisDeclared:s[t.id]})}))},geo:function(t,e){zS(t.geoModels,function(t){var n=t.coordinateSystem;e.push({panelId:"geo--"+t.id,geoModel:t,coordSysModel:t,coordSys:n,coordSyses:[n],getPanelRect:US.geo})})}},GS=[function(t,e){var n=t.xAxisModel,i=t.yAxisModel,r=t.gridModel;return!r&&n&&(r=n.axis.grid.model),!r&&i&&(r=i.axis.grid.model),r&&r===e.gridModel},function(t,e){var n=t.geoModel;return n&&n===e.geoModel}],US={grid:function(){return this.coordSys.grid.getRect().clone()},geo:function(){var t=this.coordSys,e=t.getBoundingRect().clone();return e.applyTransform(Io(t)),e}},ZS={lineX:NS(jf,0),lineY:NS(jf,1),rect:function(t,e,n){var i=e[VS[t]]([n[0][0],n[1][0]]),r=e[VS[t]]([n[0][1],n[1][1]]),o=[Uf([i[0],r[0]]),Uf([i[1],r[1]])];return{values:o,xyMinMax:o}},polygon:function(t,e,n){var i=[[1/0,-1/0],[1/0,-1/0]],r=p(n,function(n){var r=e[VS[t]](n);return i[0][0]=Math.min(i[0][0],r[0]),i[1][0]=Math.min(i[1][0],r[1]),i[0][1]=Math.max(i[0][1],r[0]),i[1][1]=Math.max(i[1][1],r[1]),r});return{values:r,xyMinMax:i}}},jS={lineX:NS(Xf,0),lineY:NS(Xf,1),rect:function(t,e,n){return[[t[0][0]-n[0]*e[0][0],t[0][1]-n[0]*e[0][1]],[t[1][0]-n[1]*e[1][0],t[1][1]-n[1]*e[1][1]]]},polygon:function(t,e,n){return p(t,function(t,i){return[t[0]-n[0]*e[i][0],t[1]-n[1]*e[i][1]]})}},XS=f,YS="\x00_ec_hist_store",qS=function(t,e,n,i,r,o){e[0]=np(e[0],n),e[1]=np(e[1],n),t=t||0;var a=n[1]-n[0];null!=r&&(r=np(r,[0,a])),null!=o&&(o=Math.max(o,null!=r?r:0)),"all"===i&&(r=o=Math.abs(e[1]-e[0]),i=0);var s=ep(e,i);e[i]+=t;var l=r||0,u=n.slice();s.sign<0?u[0]+=l:u[1]-=l,e[i]=np(e[i],u);var h=ep(e,i);null!=r&&(h.sign!==s.sign||h.span<r)&&(e[1-i]=e[i]+s.sign*r);var h=ep(e,i);return null!=o&&h.span>o&&(e[1-i]=e[i]+h.sign*o),e};cx.registerSubTypeDefaulter("dataZoom",function(){return"slider"});var $S=["x","y","z","radius","angle","single"],KS=["cartesian2d","polar","singleAxis"],QS=rp($S,["axisIndex","axis","index","id"]),JS=f,tI=Wo,eI=function(t,e,n,i){this._dimName=t,this._axisIndex=e,this._valueWindow,this._percentWindow,this._dataExtent,this._minMaxSpan,this.ecModel=i,this._dataZoomModel=n};eI.prototype={constructor:eI,hostedBy:function(t){return this._dataZoomModel===t},getDataValueWindow:function(){return this._valueWindow.slice()},getDataPercentWindow:function(){return this._percentWindow.slice()},getTargetSeriesModels:function(){var t=[],e=this.ecModel;return e.eachSeries(function(n){if(ip(n.get("coordinateSystem"))){var i=this._dimName,r=e.queryComponents({mainType:i+"Axis",index:n.get(i+"AxisIndex"),id:n.get(i+"AxisId")})[0];this._axisIndex===(r&&r.componentIndex)&&t.push(n)}},this),t},getAxisModel:function(){return this.ecModel.getComponent(this._dimName+"Axis",this._axisIndex)},getOtherAxisModel:function(){var t,e,n=this._dimName,i=this.ecModel,r=this.getAxisModel(),o="x"===n||"y"===n;o?(e="gridIndex",t="x"===n?"y":"x"):(e="polarIndex",t="angle"===n?"radius":"angle");var a;return i.eachComponent(t+"Axis",function(t){(t.get(e)||0)===(r.get(e)||0)&&(a=t)}),a},getMinMaxSpan:function(){return i(this._minMaxSpan)},calculateDataWindow:function(t){var e=this._dataExtent,n=this.getAxisModel(),i=n.axis.scale,r=this._dataZoomModel.getRangePropMode(),o=[0,100],a=[t.start,t.end],s=[];return JS(["startValue","endValue"],function(e){s.push(null!=t[e]?i.parse(t[e]):null)}),JS([0,1],function(t){var n=s[t],l=a[t];"percent"===r[t]?(null==l&&(l=o[t]),n=i.parse(Vo(l,o,e,!0))):l=Vo(n,e,o,!0),s[t]=n,a[t]=l}),{valueWindow:tI(s),percentWindow:tI(a)}},reset:function(t){if(t===this._dataZoomModel){var e=this.getTargetSeriesModels();this._dataExtent=ap(this,this._dimName,e);var n=this.calculateDataWindow(t.option);this._valueWindow=n.valueWindow,this._percentWindow=n.percentWindow,up(this),lp(this)}},restore:function(t){t===this._dataZoomModel&&(this._valueWindow=this._percentWindow=null,lp(this,!0))},filterData:function(t){function e(t){return t>=o[0]&&t<=o[1]}if(t===this._dataZoomModel){var n=this._dimName,i=this.getTargetSeriesModels(),r=t.get("filterMode"),o=this._valueWindow;"none"!==r&&JS(i,function(t){var i=t.getData(),a=i.mapDimension(n,!0);"weakFilter"===r?i.filterSelf(function(t){for(var e,n,r,s=0;s<a.length;s++){var l=i.get(a[s],t),u=!isNaN(l),h=l<o[0],c=l>o[1];if(u&&!h&&!c)return!0;u&&(r=!0),h&&(e=!0),c&&(n=!0)}return r&&e&&n}):JS(a,function(n){if("empty"===r)t.setData(i.map(n,function(t){return e(t)?t:0/0}));else{var a={};a[n]=o,i.selectRange(a)}}),JS(a,function(t){i.setApproximateExtent(o,t)})})}}};var nI=f,iI=QS,rI=El({type:"dataZoom",dependencies:["xAxis","yAxis","zAxis","radiusAxis","angleAxis","singleAxis","series"],defaultOption:{zlevel:0,z:4,orient:null,xAxisIndex:null,yAxisIndex:null,filterMode:"filter",throttle:null,start:0,end:100,startValue:null,endValue:null,minSpan:null,maxSpan:null,minValueSpan:null,maxValueSpan:null,rangeMode:null},init:function(t,e,n){this._dataIntervalByAxis={},this._dataInfo={},this._axisProxies={},this.textStyleModel,this._autoThrottle=!0,this._rangePropMode=["percent","percent"];var i=hp(t);this.mergeDefaultAndTheme(t,n),this.doInit(i)},mergeOption:function(t){var e=hp(t);r(this.option,t,!0),this.doInit(e)},doInit:function(t){var e=this.option;Jp.canvasSupported||(e.realtime=!1),this._setDefaultThrottle(t),cp(this,t),nI([["start","startValue"],["end","endValue"]],function(t,n){"value"===this._rangePropMode[n]&&(e[t[0]]=null)},this),this.textStyleModel=this.getModel("textStyle"),this._resetTarget(),this._giveAxisProxies()},_giveAxisProxies:function(){var t=this._axisProxies;this.eachTargetAxis(function(e,n,i,r){var o=this.dependentModels[e.axis][n],a=o.__dzAxisProxy||(o.__dzAxisProxy=new eI(e.name,n,this,r));t[e.name+"_"+n]=a},this)},_resetTarget:function(){var t=this.option,e=this._judgeAutoMode();iI(function(e){var n=e.axisIndex;t[n]=Li(t[n])},this),"axisIndex"===e?this._autoSetAxisIndex():"orient"===e&&this._autoSetOrient()
+},_judgeAutoMode:function(){var t=this.option,e=!1;iI(function(n){null!=t[n.axisIndex]&&(e=!0)},this);var n=t.orient;return null==n&&e?"orient":e?void 0:(null==n&&(t.orient="horizontal"),"axisIndex")},_autoSetAxisIndex:function(){var t=!0,e=this.get("orient",!0),n=this.option,i=this.dependentModels;if(t){var r="vertical"===e?"y":"x";i[r+"Axis"].length?(n[r+"AxisIndex"]=[0],t=!1):nI(i.singleAxis,function(i){t&&i.get("orient",!0)===e&&(n.singleAxisIndex=[i.componentIndex],t=!1)})}t&&iI(function(e){if(t){var i=[],r=this.dependentModels[e.axis];if(r.length&&!i.length)for(var o=0,a=r.length;a>o;o++)"category"===r[o].get("type")&&i.push(o);n[e.axisIndex]=i,i.length&&(t=!1)}},this),t&&this.ecModel.eachSeries(function(t){this._isSeriesHasAllAxesTypeOf(t,"value")&&iI(function(e){var i=n[e.axisIndex],r=t.get(e.axisIndex),o=t.get(e.axisId),a=t.ecModel.queryComponents({mainType:e.axis,index:r,id:o})[0];r=a.componentIndex,u(i,r)<0&&i.push(r)})},this)},_autoSetOrient:function(){var t;this.eachTargetAxis(function(e){!t&&(t=e.name)},this),this.option.orient="y"===t?"vertical":"horizontal"},_isSeriesHasAllAxesTypeOf:function(t,e){var n=!0;return iI(function(i){var r=t.get(i.axisIndex),o=this.dependentModels[i.axis][r];o&&o.get("type")===e||(n=!1)},this),n},_setDefaultThrottle:function(t){if(t.hasOwnProperty("throttle")&&(this._autoThrottle=!1),this._autoThrottle){var e=this.ecModel.option;this.option.throttle=e.animation&&e.animationDurationUpdate>0?100:20}},getFirstTargetAxisModel:function(){var t;return iI(function(e){if(null==t){var n=this.get(e.axisIndex);n.length&&(t=this.dependentModels[e.axis][n[0]])}},this),t},eachTargetAxis:function(t,e){var n=this.ecModel;iI(function(i){nI(this.get(i.axisIndex),function(r){t.call(e,i,r,this,n)},this)},this)},getAxisProxy:function(t,e){return this._axisProxies[t+"_"+e]},getAxisModel:function(t,e){var n=this.getAxisProxy(t,e);return n&&n.getAxisModel()},setRawRange:function(t,e){var n=this.option;nI([["start","startValue"],["end","endValue"]],function(e){(null!=t[e[0]]||null!=t[e[1]])&&(n[e[0]]=t[e[0]],n[e[1]]=t[e[1]])},this),!e&&cp(this,t)},getPercentRange:function(){var t=this.findRepresentativeAxisProxy();return t?t.getDataPercentWindow():void 0},getValueRange:function(t,e){if(null!=t||null!=e)return this.getAxisProxy(t,e).getDataValueWindow();var n=this.findRepresentativeAxisProxy();return n?n.getDataValueWindow():void 0},findRepresentativeAxisProxy:function(t){if(t)return t.__dzAxisProxy;var e=this._axisProxies;for(var n in e)if(e.hasOwnProperty(n)&&e[n].hostedBy(this))return e[n];for(var n in e)if(e.hasOwnProperty(n)&&!e[n].hostedBy(this))return e[n]},getRangePropMode:function(){return this._rangePropMode.slice()}}),oI=t_.extend({type:"dataZoom",render:function(t,e,n){this.dataZoomModel=t,this.ecModel=e,this.api=n},getTargetCoordInfo:function(){function t(t,e,n,i){for(var r,o=0;o<n.length;o++)if(n[o].model===t){r=n[o];break}r||n.push(r={model:t,axisModels:[],coordIndex:i}),r.axisModels.push(e)}var e=this.dataZoomModel,n=this.ecModel,i={};return e.eachTargetAxis(function(e,r){var o=n.getComponent(e.axis,r);if(o){var a=o.getCoordSysModel();a&&t(a,o,i[a.mainType]||(i[a.mainType]=[]),a.componentIndex)}},this),i}});rI.extend({type:"dataZoom.select"}),oI.extend({type:"dataZoom.select"}),Il({getTargetSeries:function(t){var e=N();return t.eachComponent("dataZoom",function(t){t.eachTargetAxis(function(t,n,i){var r=i.getAxisProxy(t.name,n);f(r.getTargetSeriesModels(),function(t){e.set(t.uid,t)})})}),e},modifyOutputEnd:!0,overallReset:function(t,e){t.eachComponent("dataZoom",function(t){t.eachTargetAxis(function(t,n,i){i.getAxisProxy(t.name,n).reset(i,e)}),t.eachTargetAxis(function(t,n,i){i.getAxisProxy(t.name,n).filterData(i,e)})}),t.eachComponent("dataZoom",function(t){var e=t.findRepresentativeAxisProxy(),n=e.getDataPercentWindow(),i=e.getDataValueWindow();t.setRawRange({start:n[0],end:n[1],startValue:i[0],endValue:i[1]},!0)})}}),Tl("dataZoom",function(t,e){var n=op(y(e.eachComponent,e,"dataZoom"),QS,function(t,e){return t.get(e.axisIndex)}),i=[];e.eachComponent({mainType:"dataZoom",query:t},function(t){i.push.apply(i,n(t).nodes)}),f(i,function(e){e.setRawRange({start:t.start,end:t.end,startValue:t.startValue,endValue:t.endValue})})});var aI=c_.toolbox.dataZoom,sI=f,lI="\x00_ec_\x00toolbox-dataZoom_";dp.defaultOption={show:!0,icon:{zoom:"M0,13.5h26.9 M13.5,26.9V0 M32.1,13.5H58V58H13.5 V32.1",back:"M22,1.4L9.9,13.5l12.3,12.3 M10.3,13.5H54.9v44.6 H10.3v-26"},title:i(aI.title)};var uI=dp.prototype;uI.render=function(t,e,n,i){this.model=t,this.ecModel=e,this.api=n,gp(t,e,this,i,n),pp(t,e)},uI.onclick=function(t,e,n){hI[n].call(this)},uI.remove=function(){this._brushController.unmount()},uI.dispose=function(){this._brushController.dispose()};var hI={zoom:function(){var t=!this._isZoomActive;this.api.dispatchAction({type:"takeGlobalCursor",key:"dataZoomSelect",dataZoomSelectActive:t})},back:function(){this._dispatchZoomAction(Kf(this.ecModel))}};uI._onBrush=function(t,e){function n(t,e,n){var a=e.getAxis(t),s=a.model,l=i(t,s,o),u=l.findRepresentativeAxisProxy(s).getMinMaxSpan();(null!=u.minValueSpan||null!=u.maxValueSpan)&&(n=qS(0,n.slice(),a.scale.getExtent(),0,u.minValueSpan,u.maxValueSpan)),l&&(r[l.id]={dataZoomId:l.id,startValue:n[0],endValue:n[1]})}function i(t,e,n){var i;return n.eachComponent({mainType:"dataZoom",subType:"select"},function(n){var r=n.getAxisModel(t,e.componentIndex);r&&(i=n)}),i}if(e.isEnd&&t.length){var r={},o=this.ecModel;this._brushController.updateCovers([]);var a=new Gf(fp(this.model.option),o,{include:["grid"]});a.matchOutputRanges(t,o,function(t,e,i){if("cartesian2d"===i.type){var r=t.brushType;"rect"===r?(n("x",i,e[0]),n("y",i,e[1])):n({lineX:"x",lineY:"y"}[r],i,e)}}),$f(o,r),this._dispatchZoomAction(r)}},uI._dispatchZoomAction=function(t){var e=[];sI(t,function(t){e.push(i(t))}),e.length&&this.api.dispatchAction({type:"dataZoom",from:this.uid,batch:e})},Bd("dataZoom",dp),Sl(function(t){function e(t,e){if(e){var r=t+"Index",o=e[r];null==o||"all"==o||_(o)||(o=o===!1||"none"===o?[]:[o]),n(t,function(e,n){if(null==o||"all"==o||-1!==u(o,n)){var a={type:"select",$fromToolbox:!0,id:lI+t+n};a[r]=n,i.push(a)}})}}function n(e,n){var i=t[e];_(i)||(i=i?[i]:[]),sI(i,n)}if(t){var i=t.dataZoom||(t.dataZoom=[]);_(i)||(t.dataZoom=i=[i]);var r=t.toolbox;if(r&&(_(r)&&(r=r[0]),r&&r.feature)){var o=r.feature.dataZoom;e("xAxis",o),e("yAxis",o)}}});var cI=c_.toolbox.restore;vp.defaultOption={show:!0,icon:"M3.8,33.4 M47,18.9h9.8V8.7 M56.3,20.1 C52.1,9,40.5,0.6,26.8,2.1C12.6,3.7,1.6,16.2,2.1,30.6 M13,41.1H3.1v10.2 M3.7,39.9c4.2,11.1,15.8,19.5,29.5,18 c14.2-1.6,25.2-14.1,24.7-28.5",title:cI.title};var dI=vp.prototype;dI.onclick=function(t,e){Qf(t),e.dispatchAction({type:"restore",from:this.uid})},Bd("restore",vp),Tl({type:"restore",event:"restore",update:"prepareAndUpdate"},function(t,e){e.resetOption("recreate")});var fI,pI="urn:schemas-microsoft-com:vml",gI="undefined"==typeof window?null:window,vI=!1,mI=gI&&gI.document;if(mI&&!Jp.canvasSupported)try{!mI.namespaces.zrvml&&mI.namespaces.add("zrvml",pI),fI=function(t){return mI.createElement("<zrvml:"+t+' class="zrvml">')}}catch(yI){fI=function(t){return mI.createElement("<"+t+' xmlns="'+pI+'" class="zrvml">')}}var xI=Um.CMD,_I=Math.round,wI=Math.sqrt,bI=Math.abs,MI=Math.cos,SI=Math.sin,II=Math.max;if(!Jp.canvasSupported){var CI=",",TI="progid:DXImageTransform.Microsoft",AI=21600,DI=AI/2,kI=1e5,PI=1e3,LI=function(t){t.style.cssText="position:absolute;left:0;top:0;width:1px;height:1px;",t.coordsize=AI+","+AI,t.coordorigin="0,0"},OI=function(t){return String(t).replace(/&/g,"&amp;").replace(/"/g,"&quot;")},EI=function(t,e,n){return"rgb("+[t,e,n].join(",")+")"},RI=function(t,e){e&&t&&e.parentNode!==t&&t.appendChild(e)},zI=function(t,e){e&&t&&e.parentNode===t&&t.removeChild(e)},BI=function(t,e,n){return(parseFloat(t)||0)*kI+(parseFloat(e)||0)*PI+n},NI=function(t,e){return"string"==typeof t?t.lastIndexOf("%")>=0?parseFloat(t)/100*e:parseFloat(t):t},VI=function(t,e,n){var i=Ee(e);n=+n,isNaN(n)&&(n=1),i&&(t.color=EI(i[0],i[1],i[2]),t.opacity=n*i[3])},FI=function(t){var e=Ee(t);return[EI(e[0],e[1],e[2]),e[3]]},HI=function(t,e,n){var i=e.fill;if(null!=i)if(i instanceof ky){var r,o=0,a=[0,0],s=0,l=1,u=n.getBoundingRect(),h=u.width,c=u.height;if("linear"===i.type){r="gradient";var d=n.transform,f=[i.x*h,i.y*c],p=[i.x2*h,i.y2*c];d&&(oe(f,f,d),oe(p,p,d));var g=p[0]-f[0],v=p[1]-f[1];o=180*Math.atan2(g,v)/Math.PI,0>o&&(o+=360),1e-6>o&&(o=0)}else{r="gradientradial";var f=[i.x*h,i.y*c],d=n.transform,m=n.scale,y=h,x=c;a=[(f[0]-u.x)/y,(f[1]-u.y)/x],d&&oe(f,f,d),y/=m[0]*AI,x/=m[1]*AI;var _=II(y,x);s=0/_,l=2*i.r/_-s}var w=i.colorStops.slice();w.sort(function(t,e){return t.offset-e.offset});for(var b=w.length,M=[],S=[],I=0;b>I;I++){var C=w[I],T=FI(C.color);S.push(C.offset*l+s+" "+T[0]),(0===I||I===b-1)&&M.push(T)}if(b>=2){var A=M[0][0],D=M[1][0],k=M[0][1]*e.opacity,P=M[1][1]*e.opacity;t.type=r,t.method="none",t.focus="100%",t.angle=o,t.color=A,t.color2=D,t.colors=S.join(","),t.opacity=P,t.opacity2=k}"radial"===r&&(t.focusposition=a.join(","))}else VI(t,i,e.opacity)},WI=function(t,e){null!=e.lineDash&&(t.dashstyle=e.lineDash.join(" ")),null==e.stroke||e.stroke instanceof ky||VI(t,e.stroke,e.opacity)},GI=function(t,e,n,i){var r="fill"==e,o=t.getElementsByTagName(e)[0];null!=n[e]&&"none"!==n[e]&&(r||!r&&n.lineWidth)?(t[r?"filled":"stroked"]="true",n[e]instanceof ky&&zI(t,o),o||(o=mp(e)),r?HI(o,n,i):WI(o,n),RI(t,o)):(t[r?"filled":"stroked"]="false",zI(t,o))},UI=[[],[],[]],ZI=function(t,e){var n,i,r,o,a,s,l=xI.M,u=xI.C,h=xI.L,c=xI.A,d=xI.Q,f=[],p=t.data,g=t.len();for(o=0;g>o;){switch(r=p[o++],i="",n=0,r){case l:i=" m ",n=1,a=p[o++],s=p[o++],UI[0][0]=a,UI[0][1]=s;break;case h:i=" l ",n=1,a=p[o++],s=p[o++],UI[0][0]=a,UI[0][1]=s;break;case d:case u:i=" c ",n=3;var v,m,y=p[o++],x=p[o++],_=p[o++],w=p[o++];r===d?(v=_,m=w,_=(_+2*y)/3,w=(w+2*x)/3,y=(a+2*y)/3,x=(s+2*x)/3):(v=p[o++],m=p[o++]),UI[0][0]=y,UI[0][1]=x,UI[1][0]=_,UI[1][1]=w,UI[2][0]=v,UI[2][1]=m,a=v,s=m;break;case c:var b=0,M=0,S=1,I=1,C=0;e&&(b=e[4],M=e[5],S=wI(e[0]*e[0]+e[1]*e[1]),I=wI(e[2]*e[2]+e[3]*e[3]),C=Math.atan2(-e[1]/I,e[0]/S));var T=p[o++],A=p[o++],D=p[o++],k=p[o++],P=p[o++]+C,L=p[o++]+P+C;o++;var O=p[o++],E=T+MI(P)*D,R=A+SI(P)*k,y=T+MI(L)*D,x=A+SI(L)*k,z=O?" wa ":" at ";Math.abs(E-y)<1e-4&&(Math.abs(L-P)>.01?O&&(E+=270/AI):Math.abs(R-A)<1e-4?O&&T>E||!O&&E>T?x-=270/AI:x+=270/AI:O&&A>R||!O&&R>A?y+=270/AI:y-=270/AI),f.push(z,_I(((T-D)*S+b)*AI-DI),CI,_I(((A-k)*I+M)*AI-DI),CI,_I(((T+D)*S+b)*AI-DI),CI,_I(((A+k)*I+M)*AI-DI),CI,_I((E*S+b)*AI-DI),CI,_I((R*I+M)*AI-DI),CI,_I((y*S+b)*AI-DI),CI,_I((x*I+M)*AI-DI)),a=y,s=x;break;case xI.R:var B=UI[0],N=UI[1];B[0]=p[o++],B[1]=p[o++],N[0]=B[0]+p[o++],N[1]=B[1]+p[o++],e&&(oe(B,B,e),oe(N,N,e)),B[0]=_I(B[0]*AI-DI),N[0]=_I(N[0]*AI-DI),B[1]=_I(B[1]*AI-DI),N[1]=_I(N[1]*AI-DI),f.push(" m ",B[0],CI,B[1]," l ",N[0],CI,B[1]," l ",N[0],CI,N[1]," l ",B[0],CI,N[1]);break;case xI.Z:f.push(" x ")}if(n>0){f.push(i);for(var V=0;n>V;V++){var F=UI[V];e&&oe(F,F,e),f.push(_I(F[0]*AI-DI),CI,_I(F[1]*AI-DI),n-1>V?CI:"")}}}return f.join("")};Lr.prototype.brushVML=function(t){var e=this.style,n=this._vmlEl;n||(n=mp("shape"),LI(n),this._vmlEl=n),GI(n,"fill",e,this),GI(n,"stroke",e,this);var i=this.transform,r=null!=i,o=n.getElementsByTagName("stroke")[0];if(o){var a=e.lineWidth;if(r&&!e.strokeNoScale){var s=i[0]*i[3]-i[1]*i[2];a*=wI(bI(s))}o.weight=a+"px"}var l=this.path||(this.path=new Um);this.__dirtyPath&&(l.beginPath(),this.buildPath(l,this.shape),l.toStatic(),this.__dirtyPath=!1),n.path=ZI(l,this.transform),n.style.zIndex=BI(this.zlevel,this.z,this.z2),RI(t,n),null!=e.text?this.drawRectText(t,this.getBoundingRect()):this.removeRectText(t)},Lr.prototype.onRemove=function(t){zI(t,this._vmlEl),this.removeRectText(t)},Lr.prototype.onAdd=function(t){RI(t,this._vmlEl),this.appendRectText(t)};var jI=function(t){return"object"==typeof t&&t.tagName&&"IMG"===t.tagName.toUpperCase()};ai.prototype.brushVML=function(t){var e,n,i=this.style,r=i.image;if(jI(r)){var o=r.src;if(o===this._imageSrc)e=this._imageWidth,n=this._imageHeight;else{var a=r.runtimeStyle,s=a.width,l=a.height;a.width="auto",a.height="auto",e=r.width,n=r.height,a.width=s,a.height=l,this._imageSrc=o,this._imageWidth=e,this._imageHeight=n}r=o}else r===this._imageSrc&&(e=this._imageWidth,n=this._imageHeight);if(r){var u=i.x||0,h=i.y||0,c=i.width,d=i.height,f=i.sWidth,p=i.sHeight,g=i.sx||0,v=i.sy||0,m=f&&p,y=this._vmlEl;y||(y=mI.createElement("div"),LI(y),this._vmlEl=y);var x,_=y.style,w=!1,b=1,M=1;if(this.transform&&(x=this.transform,b=wI(x[0]*x[0]+x[1]*x[1]),M=wI(x[2]*x[2]+x[3]*x[3]),w=x[1]||x[2]),w){var S=[u,h],I=[u+c,h],C=[u,h+d],T=[u+c,h+d];oe(S,S,x),oe(I,I,x),oe(C,C,x),oe(T,T,x);var A=II(S[0],I[0],C[0],T[0]),D=II(S[1],I[1],C[1],T[1]),k=[];k.push("M11=",x[0]/b,CI,"M12=",x[2]/M,CI,"M21=",x[1]/b,CI,"M22=",x[3]/M,CI,"Dx=",_I(u*b+x[4]),CI,"Dy=",_I(h*M+x[5])),_.padding="0 "+_I(A)+"px "+_I(D)+"px 0",_.filter=TI+".Matrix("+k.join("")+", SizingMethod=clip)"}else x&&(u=u*b+x[4],h=h*M+x[5]),_.filter="",_.left=_I(u)+"px",_.top=_I(h)+"px";var P=this._imageEl,L=this._cropEl;P||(P=mI.createElement("div"),this._imageEl=P);var O=P.style;if(m){if(e&&n)O.width=_I(b*e*c/f)+"px",O.height=_I(M*n*d/p)+"px";else{var E=new Image,R=this;E.onload=function(){E.onload=null,e=E.width,n=E.height,O.width=_I(b*e*c/f)+"px",O.height=_I(M*n*d/p)+"px",R._imageWidth=e,R._imageHeight=n,R._imageSrc=r},E.src=r}L||(L=mI.createElement("div"),L.style.overflow="hidden",this._cropEl=L);var z=L.style;z.width=_I((c+g*c/f)*b),z.height=_I((d+v*d/p)*M),z.filter=TI+".Matrix(Dx="+-g*c/f*b+",Dy="+-v*d/p*M+")",L.parentNode||y.appendChild(L),P.parentNode!=L&&L.appendChild(P)}else O.width=_I(b*c)+"px",O.height=_I(M*d)+"px",y.appendChild(P),L&&L.parentNode&&(y.removeChild(L),this._cropEl=null);var B="",N=i.opacity;1>N&&(B+=".Alpha(opacity="+_I(100*N)+") "),B+=TI+".AlphaImageLoader(src="+r+", SizingMethod=scale)",O.filter=B,y.style.zIndex=BI(this.zlevel,this.z,this.z2),RI(t,y),null!=i.text&&this.drawRectText(t,this.getBoundingRect())}},ai.prototype.onRemove=function(t){zI(t,this._vmlEl),this._vmlEl=null,this._cropEl=null,this._imageEl=null,this.removeRectText(t)},ai.prototype.onAdd=function(t){RI(t,this._vmlEl),this.appendRectText(t)};var XI,YI="normal",qI={},$I=0,KI=100,QI=document.createElement("div"),JI=function(t){var e=qI[t];if(!e){$I>KI&&($I=0,qI={});var n,i=QI.style;try{i.font=t,n=i.fontFamily.split(",")[0]}catch(r){}e={style:i.fontStyle||YI,variant:i.fontVariant||YI,weight:i.fontWeight||YI,size:0|parseFloat(i.fontSize||12),family:n||"Microsoft YaHei"},qI[t]=e,$I++}return e};bn("measureText",function(t,e){var n=mI;XI||(XI=n.createElement("div"),XI.style.cssText="position:absolute;top:-20000px;left:0;padding:0;margin:0;border:none;white-space:pre;",mI.body.appendChild(XI));try{XI.style.font=e}catch(i){}return XI.innerHTML="",XI.appendChild(n.createTextNode(t)),{width:XI.offsetWidth}});for(var tC=new rn,eC=function(t,e,n,i){var r=this.style;this.__dirty&&Hn(r,!0);var o=r.text;if(null!=o&&(o+=""),o){if(r.rich){var a=Bn(o,r);o=[];for(var s=0;s<a.lines.length;s++){for(var l=a.lines[s].tokens,u=[],h=0;h<l.length;h++)u.push(l[h].text);o.push(u.join(""))}o=o.join("\n")}var c,d,f=r.textAlign,p=r.textVerticalAlign,g=JI(r.font),v=g.style+" "+g.variant+" "+g.weight+" "+g.size+'px "'+g.family+'"';n=n||Sn(o,v,f,p);var m=this.transform;if(m&&!i&&(tC.copy(e),tC.applyTransform(m),e=tC),i)c=e.x,d=e.y;else{var y=r.textPosition,x=r.textDistance;if(y instanceof Array)c=e.x+NI(y[0],e.width),d=e.y+NI(y[1],e.height),f=f||"left";else{var _=Dn(y,e,x);c=_.x,d=_.y,f=f||_.textAlign,p=p||_.textVerticalAlign}}c=Tn(c,n.width,f),d=An(d,n.height,p),d+=n.height/2;var w,b,M,S=mp,I=this._textVmlEl;I?(M=I.firstChild,w=M.nextSibling,b=w.nextSibling):(I=S("line"),w=S("path"),b=S("textpath"),M=S("skew"),b.style["v-text-align"]="left",LI(I),w.textpathok=!0,b.on=!0,I.from="0 0",I.to="1000 0.05",RI(I,M),RI(I,w),RI(I,b),this._textVmlEl=I);var C=[c,d],T=I.style;m&&i?(oe(C,C,m),M.on=!0,M.matrix=m[0].toFixed(3)+CI+m[2].toFixed(3)+CI+m[1].toFixed(3)+CI+m[3].toFixed(3)+",0,0",M.offset=(_I(C[0])||0)+","+(_I(C[1])||0),M.origin="0 0",T.left="0px",T.top="0px"):(M.on=!1,T.left=_I(c)+"px",T.top=_I(d)+"px"),b.string=OI(o);try{b.style.font=v}catch(A){}GI(I,"fill",{fill:r.textFill,opacity:r.opacity},this),GI(I,"stroke",{stroke:r.textStroke,opacity:r.opacity,lineDash:r.lineDash},this),I.style.zIndex=BI(this.zlevel,this.z,this.z2),RI(t,I)}},nC=function(t){zI(t,this._textVmlEl),this._textVmlEl=null},iC=function(t){RI(t,this._textVmlEl)},rC=[Cv,oi,ai,Lr,py],oC=0;oC<rC.length;oC++){var aC=rC[oC].prototype;aC.drawRectText=eC,aC.removeRectText=nC,aC.appendRectText=iC}py.prototype.brushVML=function(t){var e=this.style;null!=e.text?this.drawRectText(t,{x:e.x||0,y:e.y||0,width:0,height:0},this.getBoundingRect(),!0):this.removeRectText(t)},py.prototype.onRemove=function(t){this.removeRectText(t)},py.prototype.onAdd=function(t){this.appendRectText(t)}}_p.prototype={constructor:_p,getType:function(){return"vml"},getViewportRoot:function(){return this._vmlViewport},getViewportRootOffset:function(){var t=this.getViewportRoot();return t?{offsetLeft:t.offsetLeft||0,offsetTop:t.offsetTop||0}:void 0},refresh:function(){var t=this.storage.getDisplayList(!0,!0);this._paintList(t)},_paintList:function(t){for(var e=this._vmlRoot,n=0;n<t.length;n++){var i=t[n];i.invisible||i.ignore?(i.__alreadyNotVisible||i.onRemove(e),i.__alreadyNotVisible=!0):(i.__alreadyNotVisible&&i.onAdd(e),i.__alreadyNotVisible=!1,i.__dirty&&(i.beforeBrush&&i.beforeBrush(),(i.brushVML||i.brush).call(i,e),i.afterBrush&&i.afterBrush())),i.__dirty=!1}this._firstPaint&&(this._vmlViewport.appendChild(e),this._firstPaint=!1)},resize:function(t,e){var t=null==t?this._getWidth():t,e=null==e?this._getHeight():e;if(this._width!=t||this._height!=e){this._width=t,this._height=e;var n=this._vmlViewport.style;n.width=t+"px",n.height=e+"px"}},dispose:function(){this.root.innerHTML="",this._vmlRoot=this._vmlViewport=this.storage=null},getWidth:function(){return this._width},getHeight:function(){return this._height},clear:function(){this._vmlViewport&&this.root.removeChild(this._vmlViewport)},_getWidth:function(){var t=this.root,e=t.currentStyle;return(t.clientWidth||xp(e.width))-xp(e.paddingLeft)-xp(e.paddingRight)|0},_getHeight:function(){var t=this.root,e=t.currentStyle;return(t.clientHeight||xp(e.height))-xp(e.paddingTop)-xp(e.paddingBottom)|0}},f(["getLayer","insertLayer","eachLayer","eachBuiltinLayer","eachOtherLayer","getLayers","modLayer","delLayer","clearLayer","toDataURL","pathToImage"],function(t){_p.prototype[t]=wp(t)}),ki("vml",_p);var sC="http://www.w3.org/2000/svg",lC=Um.CMD,uC=Array.prototype.join,hC="none",cC=Math.round,dC=Math.sin,fC=Math.cos,pC=Math.PI,gC=2*Math.PI,vC=180/pC,mC=1e-4,yC={};yC.brush=function(t){var e=t.style,n=t.__svgEl;n||(n=bp("path"),t.__svgEl=n),t.path||t.createPathProxy();var i=t.path;if(t.__dirtyPath){i.beginPath(),t.buildPath(i,t.shape),t.__dirtyPath=!1;var r=Pp(i);r.indexOf("NaN")<0&&Ap(n,"d",r)}kp(n,e),Tp(n,t.transform),null!=e.text&&bC(t,t.getBoundingRect())};var xC={};xC.brush=function(t){var e=t.style,n=e.image;if(n instanceof HTMLImageElement){var i=n.src;n=i}if(n){var r=e.x||0,o=e.y||0,a=e.width,s=e.height,l=t.__svgEl;l||(l=bp("image"),t.__svgEl=l),n!==t.__imageSrc&&(Dp(l,"href",n),t.__imageSrc=n),Ap(l,"width",a),Ap(l,"height",s),Ap(l,"x",r),Ap(l,"y",o),Tp(l,t.transform),null!=e.text&&bC(t,t.getBoundingRect())}};var _C={},wC=new rn,bC=function(t,e,n){var i=t.style;t.__dirty&&Hn(i,!0);var r=i.text;if(null!=r){r+="";var o=t.__textSvgEl;o||(o=bp("text"),t.__textSvgEl=o);var a,s,l=i.textPosition,u=i.textDistance,h=i.textAlign||"left";"number"==typeof i.fontSize&&(i.fontSize+="px");var c=i.font||[i.fontStyle||"",i.fontWeight||"",i.fontSize||"",i.fontFamily||""].join(" ")||wv,d=Lp(i.textVerticalAlign);n=Sn(r,c,h,d);var f=n.lineHeight;if(l instanceof Array)a=e.x+l[0],s=e.y+l[1];else{var p=Dn(l,e,u);a=p.x,s=p.y,d=Lp(p.textVerticalAlign),h=p.textAlign}Ap(o,"alignment-baseline",d),c&&(o.style.font=c);var g=i.textPadding;if(Ap(o,"x",a),Ap(o,"y",s),kp(o,i,!0),t instanceof py||t.style.transformText)Tp(o,t.transform);else{if(t.transform)wC.copy(e),wC.applyTransform(t.transform),e=wC;else{var v=t.transformCoordToGlobal(e.x,e.y);e.x=v[0],e.y=v[1]}var m=i.textOrigin;"center"===m?(a=n.width/2+a,s=n.height/2+s):m&&(a=m[0]+a,s=m[1]+s);var y=-i.textRotation||0,x=fe();ye(x,t.transform,y),Tp(o,x)}var _=r.split("\n"),w=_.length,b=h;"left"===b?(b="start",g&&(a+=g[3])):"right"===b?(b="end",g&&(a-=g[1])):"center"===b&&(b="middle",g&&(a+=(g[3]-g[1])/2));var M=0;if("baseline"===d?(M=-n.height+f,g&&(M-=g[2])):"middle"===d?(M=(-n.height+f)/2,g&&(s+=(g[0]-g[2])/2)):g&&(M+=g[0]),t.__text!==r||t.__textFont!==c){var S=t.__tspanList||[];t.__tspanList=S;for(var I=0;w>I;I++){var C=S[I];C?C.innerHTML="":(C=S[I]=bp("tspan"),o.appendChild(C),Ap(C,"alignment-baseline",d),Ap(C,"text-anchor",b)),Ap(C,"x",a),Ap(C,"y",s+I*f+M),C.appendChild(document.createTextNode(_[I]))}for(;I<S.length;I++)o.removeChild(S[I]);S.length=w,t.__text=r,t.__textFont=c}else if(t.__tspanList.length)for(var T=t.__tspanList.length,I=0;T>I;++I){var C=t.__tspanList[I];C&&(Ap(C,"x",a),Ap(C,"y",s+I*f+M))}}};_C.drawRectText=bC,_C.brush=function(t){var e=t.style;null!=e.text&&(e.textPosition=[0,0],bC(t,{x:e.x||0,y:e.y||0,width:0,height:0},t.getBoundingRect()))},Op.prototype={diff:function(t,e,n){function i(){for(var n=-1*s;s>=n;n+=2){var i,l=u[n-1],h=u[n+1],c=(h?h.newPos:0)-n;l&&(u[n-1]=void 0);var d=l&&l.newPos+1<o,f=h&&c>=0&&a>c;if(d||f){if(!d||f&&l.newPos<h.newPos?(i=Rp(h),r.pushComponent(i.components,void 0,!0)):(i=l,i.newPos++,r.pushComponent(i.components,!0,void 0)),c=r.extractCommon(i,e,t,n),i.newPos+1>=o&&c+1>=a)return Ep(r,i.components,e,t);u[n]=i}else u[n]=void 0}s++}n||(n=function(t,e){return t===e}),this.equals=n;var r=this;t=t.slice(),e=e.slice();var o=e.length,a=t.length,s=1,l=o+a,u=[{newPos:-1,components:[]}],h=this.extractCommon(u[0],e,t,0);if(u[0].newPos+1>=o&&h+1>=a){for(var c=[],d=0;d<e.length;d++)c.push(d);return[{indices:c,count:e.length}]}for(;l>=s;){var f=i();if(f)return f}},pushComponent:function(t,e,n){var i=t[t.length-1];i&&i.added===e&&i.removed===n?t[t.length-1]={count:i.count+1,added:e,removed:n}:t.push({count:1,added:e,removed:n})},extractCommon:function(t,e,n,i){for(var r=e.length,o=n.length,a=t.newPos,s=a-i,l=0;r>a+1&&o>s+1&&this.equals(e[a+1],n[s+1]);)a++,s++,l++;return l&&t.components.push({count:l}),t.newPos=a,s},tokenize:function(t){return t.slice()},join:function(t){return t.slice()}};var MC=new Op,SC=function(t,e,n){return MC.diff(t,e,n)},IC="0",CC="1";zp.prototype.createElement=bp,zp.prototype.getDefs=function(t){var e=this._svgRoot,n=this._svgRoot.getElementsByTagName("defs");return 0===n.length?t?(n=e.insertBefore(this.createElement("defs"),e.firstChild),n.contains||(n.contains=function(t){var e=n.children;if(!e)return!1;for(var i=e.length-1;i>=0;--i)if(e[i]===t)return!0;return!1}),n):null:n[0]},zp.prototype.update=function(t,e){if(t){var n=this.getDefs(!1);if(t[this._domName]&&n.contains(t[this._domName]))"function"==typeof e&&e(t);else{var i=this.add(t);i&&(t[this._domName]=i)}}},zp.prototype.addDom=function(t){var e=this.getDefs(!0);e.appendChild(t)},zp.prototype.removeDom=function(t){var e=this.getDefs(!1);e&&t[this._domName]&&(e.removeChild(t[this._domName]),t[this._domName]=null)},zp.prototype.getDoms=function(){var t=this.getDefs(!1);if(!t)return[];var e=[];return f(this._tagNames,function(n){var i=t.getElementsByTagName(n);e=e.concat([].slice.call(i))}),e},zp.prototype.markAllUnused=function(){var t=this.getDoms(),e=this;f(t,function(t){t[e._markLabel]=IC})},zp.prototype.markUsed=function(t){t&&(t[this._markLabel]=CC)},zp.prototype.removeUnused=function(){var t=this.getDefs(!1);if(t){var e=this.getDoms(),n=this;f(e,function(e){e[n._markLabel]!==CC&&t.removeChild(e)})}},zp.prototype.getSvgProxy=function(t){return t instanceof Lr?yC:t instanceof ai?xC:t instanceof py?_C:yC},zp.prototype.getTextSvgElement=function(t){return t.__textSvgEl},zp.prototype.getSvgElement=function(t){return t.__svgEl},h(Bp,zp),Bp.prototype.addWithoutUpdate=function(t,e){if(e&&e.style){var n=this;f(["fill","stroke"],function(i){if(e.style[i]&&("linear"===e.style[i].type||"radial"===e.style[i].type)){var r,o=e.style[i],a=n.getDefs(!0);o._dom?(r=o._dom,a.contains(o._dom)||n.addDom(r)):r=n.add(o),n.markUsed(e);var s=r.getAttribute("id");t.setAttribute(i,"url(#"+s+")")}})}},Bp.prototype.add=function(t){var e;if("linear"===t.type)e=this.createElement("linearGradient");else{if("radial"!==t.type)return $g("Illegal gradient type."),null;e=this.createElement("radialGradient")}return t.id=t.id||this.nextId++,e.setAttribute("id","zr"+this._zrId+"-gradient-"+t.id),this.updateDom(t,e),this.addDom(e),e},Bp.prototype.update=function(t){var e=this;zp.prototype.update.call(this,t,function(){var n=t.type,i=t._dom.tagName;"linear"===n&&"linearGradient"===i||"radial"===n&&"radialGradient"===i?e.updateDom(t,t._dom):(e.removeDom(t),e.add(t))})},Bp.prototype.updateDom=function(t,e){if("linear"===t.type)e.setAttribute("x1",t.x),e.setAttribute("y1",t.y),e.setAttribute("x2",t.x2),e.setAttribute("y2",t.y2);else{if("radial"!==t.type)return void $g("Illegal gradient type.");e.setAttribute("cx",t.x),e.setAttribute("cy",t.y),e.setAttribute("r",t.r)}t.global?e.setAttribute("gradientUnits","userSpaceOnUse"):e.setAttribute("gradientUnits","objectBoundingBox"),e.innerHTML="";for(var n=t.colorStops,i=0,r=n.length;r>i;++i){var o=this.createElement("stop");o.setAttribute("offset",100*n[i].offset+"%"),o.setAttribute("stop-color",n[i].color),e.appendChild(o)}t._dom=e},Bp.prototype.markUsed=function(t){if(t.style){var e=t.style.fill;e&&e._dom&&zp.prototype.markUsed.call(this,e._dom),e=t.style.stroke,e&&e._dom&&zp.prototype.markUsed.call(this,e._dom)}},h(Np,zp),Np.prototype.update=function(t){var e=this.getSvgElement(t);e&&this.updateDom(e,t.__clipPaths,!1);var n=this.getTextSvgElement(t);n&&this.updateDom(n,t.__clipPaths,!0),this.markUsed(t)},Np.prototype.updateDom=function(t,e,n){if(e&&e.length>0){var i,r,o=this.getDefs(!0),a=e[0],s=n?"_textDom":"_dom";a[s]?(r=a[s].getAttribute("id"),i=a[s],o.contains(i)||o.appendChild(i)):(r="zr"+this._zrId+"-clip-"+this.nextId,++this.nextId,i=this.createElement("clipPath"),i.setAttribute("id",r),o.appendChild(i),a[s]=i);var l=this.getSvgProxy(a);if(a.transform&&a.parent.invTransform&&!n){var u=Array.prototype.slice.call(a.transform);ve(a.transform,a.parent.invTransform,a.transform),l.brush(a),a.transform=u}else l.brush(a);var h=this.getSvgElement(a);i.innerHTML="",i.appendChild(h.cloneNode()),t.setAttribute("clip-path","url(#"+r+")"),e.length>1&&this.updateDom(i,e.slice(1),n)}else t&&t.setAttribute("clip-path","none")},Np.prototype.markUsed=function(t){var e=this;t.__clipPaths&&t.__clipPaths.length>0&&f(t.__clipPaths,function(t){t._dom&&zp.prototype.markUsed.call(e,t._dom),t._textDom&&zp.prototype.markUsed.call(e,t._textDom)})},h(Vp,zp),Vp.prototype.addWithoutUpdate=function(t,e){if(e&&Fp(e.style)){var n,i=e.style;if(i._shadowDom){n=i._shadowDom;var r=this.getDefs(!0);r.contains(i._shadowDom)||this.addDom(n)}else n=this.add(e);this.markUsed(e);var o=n.getAttribute("id");t.style.filter="url(#"+o+")"}},Vp.prototype.add=function(t){var e=this.createElement("filter"),n=t.style;return n._shadowDomId=n._shadowDomId||this.nextId++,e.setAttribute("id","zr"+this._zrId+"-shadow-"+n._shadowDomId),this.updateDom(t,e),this.addDom(e),e},Vp.prototype.update=function(t,e){var n=e.style;if(Fp(n)){var i=this;zp.prototype.update.call(this,e,function(t){i.updateDom(e,t._shadowDom)})}else this.remove(t,n)},Vp.prototype.remove=function(t,e){null!=e._shadowDomId&&(this.removeDom(e),t.style.filter="")},Vp.prototype.updateDom=function(t,e){var n=e.getElementsByTagName("feDropShadow");n=0===n.length?this.createElement("feDropShadow"):n[0];var i,r,o,a,s=t.style,l=t.scale?t.scale[0]||1:1,u=t.scale?t.scale[1]||1:1;if(s.shadowBlur||s.shadowOffsetX||s.shadowOffsetY)i=s.shadowOffsetX||0,r=s.shadowOffsetY||0,o=s.shadowBlur,a=s.shadowColor;else{if(!s.textShadowBlur)return void this.removeDom(e,s);i=s.textShadowOffsetX||0,r=s.textShadowOffsetY||0,o=s.textShadowBlur,a=s.textShadowColor}n.setAttribute("dx",i/l),n.setAttribute("dy",r/u),n.setAttribute("flood-color",a);var h=o/2/l,c=o/2/u,d=h+" "+c;n.setAttribute("stdDeviation",d),e.setAttribute("x","-100%"),e.setAttribute("y","-100%"),e.setAttribute("width",Math.ceil(o/2*200)+"%"),e.setAttribute("height",Math.ceil(o/2*200)+"%"),e.appendChild(n),s._shadowDom=e},Vp.prototype.markUsed=function(t){var e=t.style;e&&e._shadowDom&&zp.prototype.markUsed.call(this,e._shadowDom)};var TC=function(t,e,n,i){this.root=t,this.storage=e,this._opts=n=a({},n||{});var r=bp("svg");r.setAttribute("xmlns","http://www.w3.org/2000/svg"),r.setAttribute("version","1.1"),r.setAttribute("baseProfile","full"),r.style.cssText="user-select:none;position:absolute;left:0;top:0;",this.gradientManager=new Bp(i,r),this.clipPathManager=new Np(i,r),this.shadowManager=new Vp(i,r);var o=document.createElement("div");o.style.cssText="overflow:hidden;position:relative",this._svgRoot=r,this._viewport=o,t.appendChild(o),o.appendChild(r),this.resize(n.width,n.height),this._visibleList=[]};TC.prototype={constructor:TC,getType:function(){return"svg"},getViewportRoot:function(){return this._viewport},getViewportRootOffset:function(){var t=this.getViewportRoot();return t?{offsetLeft:t.offsetLeft||0,offsetTop:t.offsetTop||0}:void 0},refresh:function(){var t=this.storage.getDisplayList(!0);this._paintList(t)},setBackgroundColor:function(t){this._viewport.style.background=t},_paintList:function(t){this.gradientManager.markAllUnused(),this.clipPathManager.markAllUnused(),this.shadowManager.markAllUnused();var e,n=this._svgRoot,i=this._visibleList,r=t.length,o=[];for(e=0;r>e;e++){var a=t[e],s=Wp(a),l=Yp(a)||Xp(a);a.invisible||(a.__dirty&&(s&&s.brush(a),this.clipPathManager.update(a),a.style&&(this.gradientManager.update(a.style.fill),this.gradientManager.update(a.style.stroke),this.shadowManager.update(l,a)),a.__dirty=!1),o.push(a))}var u,h=SC(i,o);for(e=0;e<h.length;e++){var c=h[e];if(c.removed)for(var d=0;d<c.count;d++){var a=i[c.indices[d]],l=Yp(a),f=Xp(a);jp(n,l),jp(n,f)}}for(e=0;e<h.length;e++){var c=h[e];if(c.added)for(var d=0;d<c.count;d++){var a=o[c.indices[d]],l=Yp(a),f=Xp(a);u?Up(n,l,u):Zp(n,l),l?Up(n,f,l):u?Up(n,f,u):Zp(n,f),Up(n,f,l),u=f||l||u,this.gradientManager.addWithoutUpdate(l,a),this.shadowManager.addWithoutUpdate(u,a),this.clipPathManager.markUsed(a)}else if(!c.removed)for(var d=0;d<c.count;d++){var a=o[c.indices[d]];u=l=Xp(a)||Yp(a)||u,this.gradientManager.markUsed(a),this.gradientManager.addWithoutUpdate(l,a),this.shadowManager.markUsed(a),this.shadowManager.addWithoutUpdate(l,a),this.clipPathManager.markUsed(a)}}this.gradientManager.removeUnused(),this.clipPathManager.removeUnused(),this.shadowManager.removeUnused(),this._visibleList=o},_getDefs:function(t){var e=this._svgRoot,n=this._svgRoot.getElementsByTagName("defs");if(0===n.length){if(t){var n=e.insertBefore(bp("defs"),e.firstChild);return n.contains||(n.contains=function(t){var e=n.children;if(!e)return!1;for(var i=e.length-1;i>=0;--i)if(e[i]===t)return!0;return!1}),n}return null}return n[0]},resize:function(t,e){var n=this._viewport;n.style.display="none";var i=this._opts;if(null!=t&&(i.width=t),null!=e&&(i.height=e),t=this._getSize(0),e=this._getSize(1),n.style.display="",this._width!==t||this._height!==e){this._width=t,this._height=e;var r=n.style;r.width=t+"px",r.height=e+"px";var o=this._svgRoot;o.setAttribute("width",t),o.setAttribute("height",e)}},getWidth:function(){return this._width},getHeight:function(){return this._height},_getSize:function(t){var e=this._opts,n=["width","height"][t],i=["clientWidth","clientHeight"][t],r=["paddingLeft","paddingTop"][t],o=["paddingRight","paddingBottom"][t];if(null!=e[n]&&"auto"!==e[n])return parseFloat(e[n]);var a=this.root,s=document.defaultView.getComputedStyle(a);return(a[i]||Hp(s[n])||Hp(a.style[n]))-(Hp(s[r])||0)-(Hp(s[o])||0)|0
+},dispose:function(){this.root.innerHTML="",this._svgRoot=this._viewport=this.storage=null},clear:function(){this._viewport&&this.root.removeChild(this._viewport)},pathToDataUrl:function(){this.refresh();var t=this._svgRoot.outerHTML;return"data:image/svg+xml;charset=UTF-8,"+t}},f(["getLayer","insertLayer","eachLayer","eachBuiltinLayer","eachOtherLayer","getLayers","modLayer","delLayer","clearLayer","toDataURL","pathToImage"],function(t){TC.prototype[t]=qp(t)}),ki("svg",TC),t.version=L_,t.dependencies=O_,t.PRIORITY=W_,t.init=ml,t.connect=yl,t.disConnect=xl,t.disconnect=uw,t.dispose=_l,t.getInstanceByDom=wl,t.getInstanceById=bl,t.registerTheme=Ml,t.registerPreprocessor=Sl,t.registerProcessor=Il,t.registerPostUpdate=Cl,t.registerAction=Tl,t.registerCoordinateSystem=Al,t.getCoordinateSystemDimensions=Dl,t.registerLayout=kl,t.registerVisual=Pl,t.registerLoading=Ol,t.extendComponentModel=El,t.extendComponentView=Rl,t.extendSeriesModel=zl,t.extendChartView=Bl,t.setCanvasCreator=Nl,t.registerMap=Vl,t.getMap=Fl,t.dataTool=hw,t.zrender=Qv,t.graphic=Vy,t.number=$y,t.format=rx,t.throttle=Ls,t.helper=ub,t.matrix=Cg,t.vector=xg,t.color=Gg,t.parseGeoJSON=cb,t.parseGeoJson=gb,t.util=vb,t.List=_w,t.Model=Lo,t.Axis=pb,t.env=Jp});
\ No newline at end of file
diff --git a/tools/external_converter_v2/parser/frontend/dash_board/static/js/cytoscape_functional_for_optimization.js b/tools/external_converter_v2/parser/frontend/dash_board/static/js/cytoscape_functional_for_optimization.js
index 9a9992d..fdbbb74 100644
--- a/tools/external_converter_v2/parser/frontend/dash_board/static/js/cytoscape_functional_for_optimization.js
+++ b/tools/external_converter_v2/parser/frontend/dash_board/static/js/cytoscape_functional_for_optimization.js
@@ -31,117 +31,68 @@ cy_graph.filter(function(element, i){
 });
 
 // memory bar draw
-var MemoryChart = echarts.init(document.getElementById('memory_bar'));
-var memory_bar_colors = ['#50AE28', '#89CD6B', '#1B5C00', '#398D6B'];
-var memory_option = {
-	color: memory_bar_colors,
-    tooltip : {
-        trigger: 'axis'
+var MemoryChart = echarts.init(document.getElementById('memory_bar'), 'default');
+memory_option = {
+    title : {
+        text: 'Anakin memory optimization result',
+        subtext: 'Total memory size ('+ mem_info.total_mem + 'MB)',
+        x:'center'
     },
-	legend: {
-        data: ['System Used', 'Model Used', 'Temp Space', 'Sum Used']
+    tooltip : {
+        trigger: 'item',
+        formatter: "{a} <br/>{b} : {c} MB ({d}%)"
     },
-    toolbox: {
-        show : true,
-        feature : {
-            dataView : {show: true, readOnly: false},
-            magicType : {show: true, type: ['line', 'bar']},
-            restore : {show: true},
-            saveAsImage : {show: true}
-        }
+    legend: {
+        //orient : 'vertical',
+		orient: 'horizontal',
+        x : 'center',
+		y : 'bottom',
+        data:['temp_mem','system_mem','model_mem']
     },
-    calculable : true,
-	grid: {
-		show: false,
-	},
-    xAxis : [
-        {
-            type : 'category',
-			name : 'Version',
-            data : ['TensorRT','anakin_v2'],
-			axisLine: {
-                lineStyle: {
-                    color: memory_bar_colors[0]
-                }
-            },
-        }
-    ],
-    yAxis : [
-        {
-            type : 'value',
-			name : 'MB',
-			axisLabel: {
-                formatter: '{value} MB'
-            },
-			splitLine: {show: false},
-			axisLine: {
-                lineStyle: {
-                    color: memory_bar_colors[0]
-                }
-            }
-
-        }
-    ],
+    toolbox: { 
+		show : true, 
+		feature : { 
+			dataView : {show: true, readOnly: false}, 
+			restore : {show: true}, 
+			saveAsImage : {show: true} 
+		} 
+	},	
+    calculable : false,
     series : [
-		{
-			name: 'System Used',
-			type: 'bar',
-			stack: 'Sum Used',
-			barWidth: '15%',
-			data:[1297, 371],
-			label: {
-                normal: {
-                    show: true,
-                    position: 'inside'
-                }
-            },
-		},
         {
-            name:'Model Used',
-            type:'bar',
-			stack: 'Sum Used',
-			barWidth: '15%',
-            data:[0, 52],
-			label: {
-                normal: {
-                    show: true,
-                    position: 'inside'
-                }
-            },
-        },
-		{
-            name:'Temp Space',
-            type:'bar',
-			stack: 'Sum Used',
-			barWidth: '15%',
-            data:[0, 38],
-			label: {
-                normal: {
-                    show: true,
-                    position: 'inside'
-                }
-            },
-        },
-		{
-			name: 'Sum Used',
-            type: 'line',
-            data:[1297, 461], 
-			barWidth: '5%',
-			symbol: 'circle',
-			lineStyle: {
-				normal: {
-					width: 1,
-					type: 'dashed',
-				}
-			},
-			markPoint: {
-                data: [
-                    {type: 'max'}, {type: 'min'}
-                ]
-            },
-		}
-	]
+            name:'memory type',
+            type:'pie',
+			selectedMode: 'single',
+            radius : '55%',
+            center: ['50%', '60%'],
+            data:[
+                {
+					value: mem_info.temp_mem, 
+					name:'temp_mem',
+					itemStyle: {
+						color: '#89CD6B'
+					},
+					selected:true
+				},
+                {
+					value: mem_info.system_mem, 
+					name:'system_mem',
+					itemStyle: {
+						color: '#1B5C00'
+					}
+				},
+                {
+					value: mem_info.model_mem, 
+					name:'model_mem',
+					itemStyle: {
+						color: '#50AE28'
+					}
+				},
+            ]
+        }
+    ]
 };
+                    
 
 MemoryChart.setOption(memory_option);
 
diff --git a/tools/external_converter_v2/parser/frontend/dash_board/templates/index.html b/tools/external_converter_v2/parser/frontend/dash_board/templates/index.html
index dfa9cfa..6b1cdff 100644
--- a/tools/external_converter_v2/parser/frontend/dash_board/templates/index.html
+++ b/tools/external_converter_v2/parser/frontend/dash_board/templates/index.html
@@ -9,7 +9,7 @@
 <link rel="stylesheet" href="/static/cytoscape/qtip2/jquery.qtip.css"/>
 <script src="/static/bootstraptest/jquery.min.js"></script>
 <script src="/static/bootstraptest/js/bootstrap.min.js"></script>
-<script src="/static/echart/echarts.min.js"></script>
+<script src="/static/echart/echarts.min.js"></script> 
 <script src="/static/cytoscape/cytoscape.min.js"></script>
 <script src="/static/cytoscape/dagre.js"></script>
 <script src="/static/cytoscape/cytoscape-dagre.js"></script>
@@ -27,8 +27,8 @@
 	{% if not disable_optimization %}
     	<li><a href="/optimization">After Optimizer</a>
 	{% endif %}
-	<li><a href="http://icode.baidu.com/repos/baidu/sys-hic-gpu/anakin2/tree/master" target="_blank"> Anakin source </a>
-    <li><a href="http://gitlab.baidu.com/cuichaowen/external_converter_v2" target="_blank">Anakin Parser</a>
+	<li><a href="https://github.com/PaddlePaddle/Anakin" target="_blank"> Anakin source </a>
+    <li><a href="https://github.com/PaddlePaddle/Anakin/tree/master/tools/external_converter_v2" target="_blank">Anakin Parser</a>
   </ul>
   <ul>
     <li><a href="#configuration">Configuration</a>
diff --git a/tools/external_converter_v2/parser/frontend/dash_board/templates/optimization.html b/tools/external_converter_v2/parser/frontend/dash_board/templates/optimization.html
index 921fccf..0ecab20 100644
--- a/tools/external_converter_v2/parser/frontend/dash_board/templates/optimization.html
+++ b/tools/external_converter_v2/parser/frontend/dash_board/templates/optimization.html
@@ -9,7 +9,7 @@
 <link rel="stylesheet" href="/static/cytoscape/qtip2/jquery.qtip.css"/>
 <script src="/static/bootstraptest/jquery.min.js"></script>
 <script src="/static/bootstraptest/js/bootstrap.min.js"></script>
-<script src="/static/echart/echarts.min.js"></script>
+<script src="/static/echart/echarts.min.js"></script> 
 <script src="/static/cytoscape/cytoscape.min.js"></script>
 <script src="/static/cytoscape/dagre.js"></script>
 <script src="/static/cytoscape/cytoscape-dagre.js"></script>
@@ -26,8 +26,8 @@
   <ul>
 	<li><a href="/">Home</a>
     <li><a class=active data-default="true" href="/optimization">After Optimizer</a>
-	<li><a href="http://icode.baidu.com/repos/baidu/sys-hic-gpu/anakin2/tree/master" target="_blank"> Anakin source </a>
-    <li><a href="http://gitlab.baidu.com/cuichaowen/external_converter_v2" target="_blank">Anakin Parser</a>
+	<li><a href="https://github.com/PaddlePaddle/Anakin" target="_blank"> Anakin source </a>
+    <li><a href="https://github.com/PaddlePaddle/Anakin/tree/master/tools/external_converter_v2" target="_blank">Anakin Parser</a>
   </ul>
   <ul>
     <li><a href="#configuration">Configuration</a>
@@ -263,7 +263,7 @@
 		});
 		//console.log( 'tapped ' + node.id() );
 	});
-
+	var mem_info = {{ mem_info | tojson | safe }};
 </script>
 <script src="/static/js/cytoscape_functional.js"></script>
 <script src="/static/js/cytoscape_functional_for_optimization.js"> </script>
diff --git a/tools/external_converter_v2/parser/graph.py b/tools/external_converter_v2/parser/graph.py
index 7972a40..7d07770 100644
--- a/tools/external_converter_v2/parser/graph.py
+++ b/tools/external_converter_v2/parser/graph.py
@@ -4,7 +4,6 @@
 
 from utils import *
 from proto import *
-from kill_caffe import *
 from logger import *
 from frontend import RunServerOnGraph
 
@@ -20,6 +19,7 @@ class Graph(object):
         """
         self.save_file_path = config.SavePath + config.ResultName + ".anakin.bin"
         if config.framework == 'CAFFE':
+            from kill_caffe import CaffeParser
             self.parser = CaffeParser(config.framework_config_dict)
         elif config.framework == 'PADDLE':
             pass
@@ -29,6 +29,9 @@ class Graph(object):
             pass
         elif config.framework == 'MXNET':
             pass
+        elif config.framework == 'FLUID':
+            from kill_fluid import FluidParser
+            self.parser = FluidParser(config.framework_config_dict)
         else:
             raise NameError('ERROR: GrapProtoIO not support %s model.' % (config.framework))
         self.graph_io = self.parser()
diff --git a/tools/external_converter_v2/parser/graph_io.py b/tools/external_converter_v2/parser/graph_io.py
index e04f6ef..d88219b 100644
--- a/tools/external_converter_v2/parser/graph_io.py
+++ b/tools/external_converter_v2/parser/graph_io.py
@@ -113,13 +113,13 @@ class TensorProtoIO(object):
         return self.tensor_proto
 
 
-class OpProtoIO(object):
+class OpsProtoIO(object):
     """
     """
     def __init__(self):
         """
         """
-        self.op_proto = OpProto()
+        self.op_proto = OpsProto()
 
     def set_name(self, op_name):
         self.op_proto.name = op_name
@@ -159,7 +159,7 @@ class NodeProtoIO(object):
     def add_out(self, node_name):
         self.node_proto.outs.append(node_name)
 
-    def set_op(self, operator=OpProto()):
+    def set_op(self, operator=OpsProto()):
         self.node_proto.Op.CopyFrom(operator)
 
     def add_attr(self, value_name, data, data_type_str):
@@ -213,6 +213,22 @@ class GraphProtoIO(object):
     def add_node(self, node=NodeProtoIO()):
         self.graph_proto.nodes.extend([node])
 
+    def rm_node(self, node):
+        if node in self.graph_proto.nodes:
+            index = -1
+            for idx, tmp_node in enumerate(self.graph_proto.nodes):
+                if tmp_node == node:
+                    index = idx
+                    break
+            if index >= 0:
+                del self.graph_proto.nodes[index]
+        else:
+            raise NameError('ERROR: (%s) node not exist.' % ( node ) )
+
+    def find_node_proto(self, node_name):
+        for node in self.graph_proto.nodes:
+            if node.name == node_name:
+                return node
     def get_edge_nexts(self, node_name_0):
         """
         get edge's next node_name
@@ -262,6 +278,35 @@ class GraphProtoIO(object):
     def add_in(self, node_name):
         self.graph_proto.ins.append(node_name)
 
+    def rm_in(self, node_name):
+        graph_ins = list(self.graph_proto.ins)
+        for in_name in graph_ins:
+            if node_name == in_name:
+                idx = graph_ins.index(in_name)
+                del graph_ins[idx]
+        self.graph_proto.ins[:] = graph_ins
+        print 'self.graph_proto.ins[:]'
+        print self.graph_proto.ins[:]
+
+    def ins(self):
+        return list(self.graph_proto.ins)
+
+    def outs(self):
+        return list(self.graph_proto.outs)
+
+    def add_out_fluid(self, output_node_name, in_node_name):
+        """
+        add output node for graph
+        """
+        nodeIO = NodeProtoIO()
+        nodeIO.set_name(output_node_name)
+        nodeIO.add_in(in_node_name)
+        opIO = OpsProtoIO()
+        opIO.set_name("Output")
+        nodeIO.set_op(opIO())
+        self.add_node(nodeIO())
+        self.graph_proto.outs.append(output_node_name)
+
     def add_out(self, output_node_name, in_node_name):
         """
         add output node for graph
@@ -269,7 +314,7 @@ class GraphProtoIO(object):
         nodeIO = NodeProtoIO()
         nodeIO.set_name(output_node_name)
         nodeIO.add_in(in_node_name)
-        opIO = OpProtoIO()
+        opIO = OpsProtoIO()
         opIO.set_name("Output")
         nodeIO.set_op(opIO())
         self.add_out_edge(in_node_name, output_node_name)
@@ -277,5 +322,13 @@ class GraphProtoIO(object):
         self.add_node(nodeIO())
         self.graph_proto.outs.append(output_node_name)
 
+    def rm_out(self, node_name):
+        graph_outs = list(self.graph_proto.outs)
+        for out_name in graph_outs:
+            if node_name == out_name:
+                idx = graph_outs.index(out_name)
+                del graph_outs[idx]
+        self.graph_proto.outs[:] = graph_outs
+
     def __call__(self):
         return self.graph_proto
diff --git a/tools/external_converter_v2/parser/graph_to_json.py b/tools/external_converter_v2/parser/graph_to_json.py
index eb0f385..e4306e1 100644
--- a/tools/external_converter_v2/parser/graph_to_json.py
+++ b/tools/external_converter_v2/parser/graph_to_json.py
@@ -5,7 +5,7 @@
 import random
 from utils import *
 from proto import *
-from kill_caffe import *
+#from kill_caffe import *
 from logger import *
 from graph_io import GraphProtoIO
 
@@ -195,5 +195,21 @@ class GraphToJson(object):
                                                   edges=self.create_edges())
         return elements()
 
+    def create_mem_info(self):
+        """
+        create memory optimization information
+        """
+        temp_mem_used = self.graph_proto.summary.temp_mem_used
+        system_mem_used = self.graph_proto.summary.system_mem_used
+        model_mem_used = self.graph_proto.summary.model_mem_used
+        sum_mem = self.graph_proto.summary.temp_mem_used + \
+				self.graph_proto.summary.system_mem_used + \
+				self.graph_proto.summary.model_mem_used
+        mem_info =  CreateJson(temp_mem=temp_mem_used, 
+							   system_mem=system_mem_used, 
+							   model_mem=model_mem_used,
+							   total_mem=sum_mem)
+        return mem_info()
+
     def __call__(self):
-        return self.create_elements(), self.create_attr()
+        return self.create_elements(), self.create_attr(), self.create_mem_info()
diff --git a/tools/external_converter_v2/parser/kill_caffe/caffe_layer_param_transmit.py b/tools/external_converter_v2/parser/kill_caffe/caffe_layer_param_transmit.py
index af8112d..a16fdcf 100755
--- a/tools/external_converter_v2/parser/kill_caffe/caffe_layer_param_transmit.py
+++ b/tools/external_converter_v2/parser/kill_caffe/caffe_layer_param_transmit.py
@@ -9,8 +9,7 @@ try:
     from google.protobuf.pyext._message import RepeatedScalarContainer as repeat_container # 3.5.1 + 
 except ImportError:
     pass
-from ..operations import OpParam
-from ..operations import OpsRegister
+from ..operations import OpsParam, OpsRegister
 from ..logger import *
 from ..pbs import *
 
@@ -463,12 +462,13 @@ def Parser_power(args):
     OpsRegister()["Power"].power = power_param.power
 
 
-@ParserFeedDecorator("PReLU")
+@ParserFeedDecorator("Activation")
 def Parser_prelu(args):
     layer = args[1]
     # parser caffe parameter
     prelu_param = layer.prelu_param
-    OpsRegister()["PReLU"].channel_shared = prelu_param.channel_shared
+    OpsRegister()["Activation"].type = "PReLU"
+    OpsRegister()["Activation"].channel_shared = prelu_param.channel_shared
 
 
 @ParserFeedDecorator("RNN")
@@ -1002,6 +1002,7 @@ def Parser_priorbox(args):
     OpsRegister()["PriorBox"].step_h = prior_box_param.step_h
     OpsRegister()["PriorBox"].step_w = prior_box_param.step_w
     OpsRegister()["PriorBox"].offset = prior_box_param.offset
+    OpsRegister()["PriorBox"].order = ['MIN', 'MAX', 'COM']
 
 
 @ParserFeedDecorator("DetectionOutput")
@@ -1035,6 +1036,7 @@ def Parser_argmax(args):
     OpsRegister()["Argmax"].out_max_val = argmax_param.out_max_val
     OpsRegister()["Argmax"].top_k = argmax_param.top_k
     OpsRegister()["Argmax"].axis = argmax_param.axis
+    OpsRegister()["Argmax"].axis_term = True
 
 
 @ParserFeedDecorator("Normalize")
@@ -1050,66 +1052,66 @@ def Parser_normalize(args):
 
 # caffe layer parameter parser map
 CAFFE_LAYER_PARSER = {
-                "Split": OpParam().set_parser(Parser_split),
-                "Accuracy": OpParam().set_parser(NotNeededInInference),
-                "ArgMax": OpParam().set_parser(NotNeededInInference),
-                "BatchNorm": OpParam().set_parser(Parser_batch_norm),
-                "Bias": OpParam().set_parser(NotNeededInInference),
-                "Concat": OpParam().set_parser(Parser_concat),
-                "ContrastiveLoss": OpParam().set_parser(NotNeededInInference),
-                "Convolution": OpParam().set_parser(Parser_convolution),
-                "ConvolutionDepthwise": OpParam().set_parser(Parser_convolution),
-                "Deconvolution": OpParam().set_parser(Parser_deconvolution),
-                "DeformableConvolution": OpParam().set_parser(Parser_deformable_convolution),
-                "Crop": OpParam().set_parser(Parser_crop),
-                "Data": OpParam().set_parser(NotNeededInInference),
-                "Dropout": OpParam().set_parser(Parser_dropout),
-                "DummyData": OpParam().set_parser(NotNeededInInference),
-                "Eltwise": OpParam().set_parser(Parser_eltwise),
-                "ELU": OpParam().set_parser(Parser_elu),
-                "Embed": OpParam().set_parser(Parser_embed),
-                "Exp": OpParam().set_parser(Parser_exp),
-                "Flatten": OpParam().set_parser(Parser_flatten),
-                "HDF5Data": OpParam().set_parser(NotNeededInInference),
-                "HDF5Output": OpParam().set_parser(NotNeededInInference),
-                "HingeLoss": OpParam().set_parser(NotNeededInInference),
-                "ImageData": OpParam().set_parser(NotNeededInInference),
-                "InfogainLoss": OpParam().set_parser(NotNeededInInference),
-                "InnerProduct": OpParam().set_parser(Parser_innerproduct),
-                "Input": OpParam().set_parser(Parser_input),
-                "Log": OpParam().set_parser(Parser_log),
-                "LRN": OpParam().set_parser(Parser_lrn),
-                "MemoryData": OpParam().set_parser(NotNeededInInference),
-                "MVN": OpParam().set_parser(Parser_mvn),
-                "Parameter": OpParam().set_parser(NotNeededInInference),
-                "Pooling": OpParam().set_parser(Parser_pooling),
-                "Power": OpParam().set_parser(Parser_power),
-                "PReLU": OpParam().set_parser(Parser_prelu),
-                "Permute": OpParam().set_parser(Parser_permute),
-                "Python": OpParam().set_parser(NotNeededInInference),
-                "Recurrent": OpParam().set_parser(Parser_rnn_ori),
-                "RNN": OpParam().set_parser(Parser_rnn_ori),
-                "LSTM": OpParam().set_parser(Parser_rnn_lstm),
-                "Reduction": OpParam().set_parser(NotNeededInInference),
-                "ReLU": OpParam().set_parser(Parser_relu),
-                "Reshape": OpParam().set_parser(Parser_reshape),
-                "Scale": OpParam().set_parser(Parser_scale),
-                "Sigmoid": OpParam().set_parser(Parser_sigmoid),
-                "Softmax": OpParam().set_parser(Parser_softmax),
-                "SPP": OpParam().set_parser(Parser_spp),
-                "Slice": OpParam().set_parser(Parser_slice),
-                "TanH": OpParam().set_parser(Parser_tanh),
-                "Threshold": OpParam().set_parser(NotNeededInInference),
-                "Tile": OpParam().set_parser(NotNeededInInference),
-                "WindowData": OpParam().set_parser(NotNeededInInference),
-                "RPNProposalSSD": OpParam().set_parser(Parser_rpn_proposal_ssd), # adu add
-                "RCNNDetOutputWithAttr": OpParam().set_parser(Parser_rcnn_net_output_with_attr), # adu add
-                "DFMBPSROIAlign": OpParam().set_parser(Parser_dfmbps_roi_align), # adu add
-                "RCNNProposal": OpParam().set_parser(Parser_rcnn_proposal), # adu add
-                "ProposalImgScaleToCamCoords": OpParam().set_parser(Parser_proposal_img_scale_to_cam_coords), # adu add
-                "Axpy": OpParam().set_parser(Parser_axpy), # vis add
-                "PriorBox": OpParam().set_parser(Parser_priorbox), # vis add
-                "DetectionOutput": OpParam().set_parser(Parser_detectionoutput), # vis add
-                "ArgMax": OpParam().set_parser(Parser_argmax),
-                "Normalize": OpParam().set_parser(Parser_normalize)
+                "Split": OpsParam().set_parser(Parser_split),
+                "Accuracy": OpsParam().set_parser(NotNeededInInference),
+                "ArgMax": OpsParam().set_parser(NotNeededInInference),
+                "BatchNorm": OpsParam().set_parser(Parser_batch_norm),
+                "Bias": OpsParam().set_parser(NotNeededInInference),
+                "Concat": OpsParam().set_parser(Parser_concat),
+                "ContrastiveLoss": OpsParam().set_parser(NotNeededInInference),
+                "Convolution": OpsParam().set_parser(Parser_convolution),
+                "ConvolutionDepthwise": OpsParam().set_parser(Parser_convolution),
+                "Deconvolution": OpsParam().set_parser(Parser_deconvolution),
+                "DeformableConvolution": OpsParam().set_parser(Parser_deformable_convolution),
+                "Crop": OpsParam().set_parser(Parser_crop),
+                "Data": OpsParam().set_parser(NotNeededInInference),
+                "Dropout": OpsParam().set_parser(Parser_dropout),
+                "DummyData": OpsParam().set_parser(NotNeededInInference),
+                "Eltwise": OpsParam().set_parser(Parser_eltwise),
+                "ELU": OpsParam().set_parser(Parser_elu),
+                "Embed": OpsParam().set_parser(Parser_embed),
+                "Exp": OpsParam().set_parser(Parser_exp),
+                "Flatten": OpsParam().set_parser(Parser_flatten),
+                "HDF5Data": OpsParam().set_parser(NotNeededInInference),
+                "HDF5Output": OpsParam().set_parser(NotNeededInInference),
+                "HingeLoss": OpsParam().set_parser(NotNeededInInference),
+                "ImageData": OpsParam().set_parser(NotNeededInInference),
+                "InfogainLoss": OpsParam().set_parser(NotNeededInInference),
+                "InnerProduct": OpsParam().set_parser(Parser_innerproduct),
+                "Input": OpsParam().set_parser(Parser_input),
+                "Log": OpsParam().set_parser(Parser_log),
+                "LRN": OpsParam().set_parser(Parser_lrn),
+                "MemoryData": OpsParam().set_parser(NotNeededInInference),
+                "MVN": OpsParam().set_parser(Parser_mvn),
+                "Parameter": OpsParam().set_parser(NotNeededInInference),
+                "Pooling": OpsParam().set_parser(Parser_pooling),
+                "Power": OpsParam().set_parser(Parser_power),
+                "PReLU": OpsParam().set_parser(Parser_prelu),
+                "Permute": OpsParam().set_parser(Parser_permute),
+                "Python": OpsParam().set_parser(NotNeededInInference),
+                "Recurrent": OpsParam().set_parser(Parser_rnn_ori),
+                "RNN": OpsParam().set_parser(Parser_rnn_ori),
+                "LSTM": OpsParam().set_parser(Parser_rnn_lstm),
+                "Reduction": OpsParam().set_parser(NotNeededInInference),
+                "ReLU": OpsParam().set_parser(Parser_relu),
+                "Reshape": OpsParam().set_parser(Parser_reshape),
+                "Scale": OpsParam().set_parser(Parser_scale),
+                "Sigmoid": OpsParam().set_parser(Parser_sigmoid),
+                "Softmax": OpsParam().set_parser(Parser_softmax),
+                "SPP": OpsParam().set_parser(Parser_spp),
+                "Slice": OpsParam().set_parser(Parser_slice),
+                "TanH": OpsParam().set_parser(Parser_tanh),
+                "Threshold": OpsParam().set_parser(NotNeededInInference),
+                "Tile": OpsParam().set_parser(NotNeededInInference),
+                "WindowData": OpsParam().set_parser(NotNeededInInference),
+                "RPNProposalSSD": OpsParam().set_parser(Parser_rpn_proposal_ssd), # adu add
+                "RCNNDetOutputWithAttr": OpsParam().set_parser(Parser_rcnn_net_output_with_attr), # adu add
+                "DFMBPSROIAlign": OpsParam().set_parser(Parser_dfmbps_roi_align), # adu add
+                "RCNNProposal": OpsParam().set_parser(Parser_rcnn_proposal), # adu add
+                "ProposalImgScaleToCamCoords": OpsParam().set_parser(Parser_proposal_img_scale_to_cam_coords), # adu add
+                "Axpy": OpsParam().set_parser(Parser_axpy), # vis add
+                "PriorBox": OpsParam().set_parser(Parser_priorbox), # vis add
+                "DetectionOutput": OpsParam().set_parser(Parser_detectionoutput), # vis add
+                "ArgMax": OpsParam().set_parser(Parser_argmax),
+                "Normalize": OpsParam().set_parser(Parser_normalize)
                 }
diff --git a/tools/external_converter_v2/parser/kill_caffe/parser_caffe.py b/tools/external_converter_v2/parser/kill_caffe/parser_caffe.py
index 1b12fe3..f433be3 100644
--- a/tools/external_converter_v2/parser/kill_caffe/parser_caffe.py
+++ b/tools/external_converter_v2/parser/kill_caffe/parser_caffe.py
@@ -222,7 +222,7 @@ class CaffeParser:
         """
         # create node scale
         scale_nodeIO = NodeProtoIO() # init a NodeProtoIO 
-        scale_opIO = OpProtoIO() # init a OpProtoIO 
+        scale_opIO = OpsProtoIO() # init a OpsProtoIO 
         scale_nodeIO.set_name(batchnorm_name + "_scale") # set node name 
         scale_opIO.set_name("Scale") # set op
         # change edge for graph_io
@@ -243,7 +243,7 @@ class CaffeParser:
         """
         """
         node_io = NodeProtoIO()
-        op_io = OpProtoIO()
+        op_io = OpsProtoIO()
         inputs = list(self.net_parameter.input)
         if len(inputs):
             input_dim = map(int, list(self.net_parameter.input_dim))
@@ -343,7 +343,7 @@ class CaffeParser:
             logger(verbose.INFO).feed(" Dectect [%s:\t%s] " % (source_layer_type, source_layer_name))
             # construct the node_io and op_io
             nodeIO = NodeProtoIO() # init a NodeProtoIO
-            opIO = OpProtoIO() # init a OpProtoIO
+            opIO = OpsProtoIO() # init a OpsProtoIO
             nodeIO.set_name(source_layer_name) # set node name
             opIO.set_name(source_layer_type) # set op name 
 
@@ -441,7 +441,7 @@ class CaffeParser:
             logger(verbose.INFO).feed(" Dectect [%s:\t%s] " % (source_layer_type, source_layer_name))
             # construct the node_io and op_io
             nodeIO = NodeProtoIO() # init a NodeProtoIO
-            opIO = OpProtoIO() # init a OpProtoIO
+            opIO = OpsProtoIO() # init a OpsProtoIO
             nodeIO.set_name(source_layer_name) # set node name
             opIO.set_name(source_layer_type) # set op name
             # set link edge
diff --git a/tools/external_converter_v2/parser/kill_fluid/__init__.py b/tools/external_converter_v2/parser/kill_fluid/__init__.py
new file mode 100644
index 0000000..4d8ee7a
--- /dev/null
+++ b/tools/external_converter_v2/parser/kill_fluid/__init__.py
@@ -0,0 +1,5 @@
+#! /usr/bin/env python
+# Copyright (c) 2017, Cuichaowen. All rights reserved.
+# -*- coding: utf-8 -*-
+
+from parser_fluid import *
diff --git a/tools/external_converter_v2/parser/kill_fluid/fluid_debugger.py b/tools/external_converter_v2/parser/kill_fluid/fluid_debugger.py
new file mode 100644
index 0000000..4c03212
--- /dev/null
+++ b/tools/external_converter_v2/parser/kill_fluid/fluid_debugger.py
@@ -0,0 +1,37 @@
+from ..proto import *
+from ..graph_io import *
+import copy
+import paddle.fluid as fluid
+import numpy as np
+from paddle.fluid.core import VarDesc, AttrType
+
+
+class Fluid_debugger:
+
+	def var_names_of_fetch(self, fetch_targets):
+		var_names_list = []
+		for var in fetch_targets:
+			var_names_list.append(var.name)
+		return var_names_list
+
+	def fetch_tmp_vars(self, block, fetch_targets, var_names_list = None):
+		fetch_var = block.var('fetch')
+		old_fetch_names = self.var_names_of_fetch(fetch_targets)
+		new_fetch_vars = []
+		for var_name in old_fetch_names:
+			var = block.var(var_name)
+			new_fetch_vars.append(var)
+		i = len(new_fetch_vars)
+		if var_names_list is None:
+			var_names_list = block.vars.keys()
+		for var_name in var_names_list:
+			if '.tmp_' in var_name and var_name not in old_fetch_names:
+				var = block.var(var_name)
+				new_fetch_vars.append(var)
+				block.append_op(
+					type='fetch',
+					inputs={'X': [var_name]},
+					outputs={'Out': [fetch_var]},
+					attrs={'col': i})
+				i = i + 1
+		return new_fetch_vars
diff --git a/tools/external_converter_v2/parser/kill_fluid/fluid_helper.py b/tools/external_converter_v2/parser/kill_fluid/fluid_helper.py
new file mode 100644
index 0000000..5df2683
--- /dev/null
+++ b/tools/external_converter_v2/parser/kill_fluid/fluid_helper.py
@@ -0,0 +1,509 @@
+from ..proto import *
+from ..graph_io import *
+import paddle.fluid as fluid
+import numpy as np
+from paddle.fluid.core import VarDesc, AttrType
+
+
+def union(list_a, list_b):
+	return list(set(list_a).union(set(list_b)))
+
+def difference(list_a, list_b):
+	return list(set(list_a).difference(set(list_b)))
+
+
+class Edge_for_fluid:
+
+	def __init__(self, param, target, var):
+		self.param = param
+		self.target = target
+		self.var = var
+
+
+class Fluid_edger:
+
+	def __init__(self, param = None, target = None, var = None):
+		self.edges = []
+		if param is not None and target is not None:
+			edge = Edge_for_fluid(param, target, var)
+			self.edges.append(edge)
+
+	def __call__(self):
+		return self.all_targets()
+
+	def add(self, param, target, var = None):
+		edge = Edge_for_fluid(param, target, var)
+		self.edges.append(edge)
+
+	def rm_edges_by_param(self, param):
+		for edge in self.edges:
+			if edge.param == param:
+				edge_idx = self.edges.index(edge)
+				del self.edges[edge_idx]
+
+	def rm(self, target):
+		res = -1
+		for edge in self.edges:
+			if target == edge.target:
+				edge_idx = self.edges.index(edge)
+				del self.edges[edge_idx]
+				res = res + 1
+		if res != 0:
+			pass
+
+	def mv(self, old_target, new_target):
+		res = -1
+		for edge in self.edges:
+			if old_target == edge.target:
+				edge.target = new_target
+				res = res + 1
+		if res != 0:
+			pass
+
+	def all_params(self):
+		params = []
+		for edge in self.edges:
+			if edge.param not in params:
+				params.append(edge.param)
+		return params
+
+	def all_targets(self):
+		targets = []
+		for edge in self.edges:
+			targets.append(edge.target)
+		return targets
+
+	def targets(self, param):
+		targets = []
+		for edge in self.edges:
+			if edge.param == param:
+				targets.append(edge.target)
+		return targets
+
+	def target(self, param, idx = 0):
+		return self.targets(param)[idx]
+
+	def clear(self):
+		targets_list = self.all_targets()
+		for target in targets_list:
+			self.rm(target)
+
+	def targets_with_params(self):
+		list_of_targets_and_params = []
+		for edge in self.edges:
+			target_and_param = [edge.target, edge.param]
+			list_of_targets_and_params.append(target_and_param)
+		return list_of_targets_and_params
+
+	def vars_by_target(self, target):
+		vars = []
+		for edge in self.edges:
+			if edge.target == target and edge.var is not None:
+				vars.append(edge.var)
+		return vars
+
+	def __getitem__(self, idx):
+		if idx < len(self.edges):
+			return self.edges[idx]
+		return None
+
+
+class Fluid_helper:
+
+	def __init__(self, scope, block):
+		self.scope = scope
+		self.block = block
+
+	def args_by_input_param(self, op, param_name):
+		if param_name in op.input_names:
+			return op.input(param_name)
+		else:
+			raise NameError('ERROR: param_name %s is not exists.' % ( param_name ) )
+
+	def args_by_output_param(self, op, param_name):
+		if param_name in op.output_names:
+			return op.output(param_name)
+		else:
+			raise NameError('ERROR: param_name %s is not exists.' % ( param_name ) )
+
+	def var_by_input_param(self, op, param_name, var_idx = 0):
+		var_name = self.args_by_input_param(op, param_name)[var_idx]
+		var = self.block.var(var_name)
+		return var
+
+	def var_by_output_param(self, op, param_name, var_idx = 0):
+		var_name = self.args_by_output_param(op, param_name)[var_idx]
+		var = self.block.var(var_name)
+		return var
+
+	def var_name_by_param(self, op, param_name, var_idx = 0):
+		if param_name not in op.input_names + op.output_names:
+			raise NameError('ERROR: param_name %s is not exists.' % ( param_name ) )
+		elif param_name in op.input_names:
+			if len(op.input(param_name)) > 0:
+				var_name_unicode = op.input(param_name)[var_idx]
+			else:
+				raise NameError('ERROR: param %s has not var.' % ( param_name ) )
+		elif param_name in op.output_names:
+			if len(op.output(param_name)) > 0:
+				var_name_unicode = op.output(param_name)[var_idx]
+			else:
+				raise NameError('ERROR: param %s has not var.' % ( param_name ) )
+		var = self.block.var(var_name_unicode)
+		var_name = var.name
+		return var_name
+
+	def var_by_param(self, op, param_name, var_idx = 0):
+		var_name = self.var_name_by_param(op, param_name, var_idx)
+		var = self.block.var(var_name)
+		return var
+
+	def shape_by_var_name(self, var_name, layout = 'NCHW'):
+		var = self.block.var(var_name)
+		long_tuple = var.shape
+		long_list = list(long_tuple)
+		if layout == 'NCHW':
+			int_list_4d = map(int, [1]*(4-len(long_list)) + long_list)
+			return int_list_4d
+		elif layout == 'UNMODIFIED':
+			return long_list
+		else:
+			raise NameError('ERROR: layout %s is not implemented yet.' % ( layout ) )
+
+	def np_data_by_var_name(self, var_name):
+		numpy_array = fluid.executor.fetch_var(var_name, self.scope, True)
+		return numpy_array
+
+	def dtype_by_var_name(self, var_name):
+		var = self.block.var(var_name)
+		fluid_var_type = var.dtype
+		dtype = ANAKIN_TENSOR_DTYPE[fluid_var_type]
+		return dtype
+
+	def is_persistable_param(self, op, param_name, var_idx = 0):
+		var = self.var_by_param(op, param_name, var_idx)
+		is_persistable_var = var.persistable
+		return is_persistable_var
+
+	def var_shape_by_param(self, transpose, op, param_name, var_idx = 0, layout = 'NCHW'):
+		if transpose is True:
+			raise NameError('ERROR: var_shape transpose is not implemented yet.')
+		else:
+			var_name = self.var_name_by_param(op, param_name, var_idx)
+			shape = self.shape_by_var_name(var_name, layout)
+			return shape
+
+	def data_with_shape_by_param(self,
+								 op,
+								 param_name,
+								 transpose = False,
+								 axes = None,
+								 var_idx = 0,
+								 is_flat_list = True,
+								 layout = 'NCHW'):
+
+		np.set_printoptions(threshold=np.inf, suppress=True)
+
+		var_name = self.var_name_by_param(op, param_name, var_idx)
+		np_array = self.np_data_by_var_name(var_name)
+		if transpose is True:
+			np_array = np.transpose(np_array, axes)
+		np_shape = np.shape(np_array)
+		if layout == 'NCHW':
+			np_shape = map(int, [1]*(4-len(np_shape)) + list(np_shape))
+		if is_flat_list is True:
+			flat_list = list(np_array.flatten())
+			return [flat_list, np_shape]
+		else:
+			return [np_array, np_shape]
+
+	def np_param(self,
+				 op,
+				 param_name,
+				 transpose = False,
+				 axes = None,
+				 var_idx = 0):
+
+		[data, np_shape] = self.data_with_shape_by_param(op, param_name, transpose, \
+			axes, var_idx, False)
+		return data
+
+	def dtype_by_param(self, op, param_name, var_idx = 0):
+		var_name = self.var_name_by_param(op, param_name, var_idx)
+		dtype = self.dtype_by_var_name(var_name)
+		return dtype
+
+	def is_list_type(self, op, attr_name):
+		if op.has_attr(attr_name):
+			fluid_attr_type = op.attr_type(attr_name)
+			if fluid_attr_type in ANAKIN_ATTR_IS_LIST.keys():
+				return ANAKIN_ATTR_IS_LIST[fluid_attr_type]
+			else:
+				return False # AttrType.LONG
+		else:
+			raise NameError('ERROR: attr_name %s is not exists.' % ( attr_name ) )
+
+	def dtype_of_attr(self, op, attr_name):
+		if op.has_attr(attr_name):
+			fluid_attr_type = op.attr_type(attr_name)
+			if fluid_attr_type in ANAKIN_ATTR_DTYPE.keys():
+				return ANAKIN_ATTR_DTYPE[fluid_attr_type]
+			else:
+				return INT32 # AttrType.LONG
+		else:
+			raise NameError('ERROR: attr_name %s is not exists.' % ( attr_name ) )
+
+	def attr_data_required(self, op, attr_name):
+		data = op.attr(attr_name)
+		is_list = self.is_list_type(op, attr_name)
+		dtype = self.dtype_of_attr(op, attr_name)
+		if dtype not in [INT32, FLOAT, STR]:
+			return data
+		elif dtype == INT32:
+			return map(int, data) if is_list else int(data)
+		elif dtype == FLOAT:
+			return map(float, data) if is_list else float(data)
+		elif dtype == STR:
+			return bytes(data)
+
+	def attr_data(self, op, attr_name, default_value = 0, type = None):
+		if op.has_attr(attr_name):
+			return self.attr_data_required(op, attr_name)
+		else:
+			#raise NameError('ERROR: attr_name %s is not exists.' % ( attr_name ) )
+			return default_value
+
+	def param_tensor_sh(self,
+						op,
+						param_name,
+						transpose = False,
+						axes = None,
+						reshape = None,
+						var_idx = 0,
+						layout = 'NCHW'):
+
+		tensor = TensorProtoIO()
+		[flat_data, shape] = self.data_with_shape_by_param(op, param_name, transpose, \
+			axes, var_idx, True, layout)
+		dtype = self.dtype_by_param(op, param_name, var_idx)
+		tensor.set_data_type(dtype)
+		if dtype in ANAKIN_TENSOR_DTYPESTR.keys():
+			tensor.set_data(flat_data, ANAKIN_TENSOR_DTYPESTR[dtype])
+			#pass #debug
+		else:
+			raise NameError('ERROR: Unknown data type (%s)' % ( dtype ) )
+		if reshape is not None:
+			tensor.set_shape(reshape)
+		else:
+			tensor.set_shape(shape)
+		return [tensor, shape]
+
+	def param_tensor(self,
+					 op,
+					 param_name,
+					 transpose = False,
+					 axes = None,
+					 reshape = None,
+					 var_idx = 0,
+					 layout = 'NCHW'):
+
+		[tensor, shape] = self.param_tensor_sh(op, param_name, transpose, axes, \
+			reshape, var_idx, layout)
+		return tensor
+
+	def create_tensor(self, data_list, data_shape, dtype):
+		tensor = TensorProtoIO()
+		tensor.set_data_type(dtype)
+		tensor.set_data(data_list, ANAKIN_TENSOR_DTYPESTR[dtype])
+		tensor.set_shape(data_shape)
+		return tensor
+
+	def gru_tensor_convert(self, origin_h2h, origin_i2h, origin_b, offset=[2, 1, 0]):
+		hidden_size = int(origin_b.size // 3)
+		word_size = int(origin_i2h.size // hidden_size // 3)
+		tar_h2h=np.array(origin_h2h.flatten().tolist()[2*hidden_size*hidden_size:]\
+			+np.array(origin_h2h.flatten().tolist()[:2*hidden_size*hidden_size])\
+			.reshape(hidden_size,2,hidden_size)[:,[1,0],:].flatten().tolist())\
+		.reshape(1,1,hidden_size,3*hidden_size)
+		tar_i2h=origin_i2h.reshape(word_size,3,hidden_size)[:,offset,:]\
+		.reshape(1,1,word_size,3*hidden_size)
+		tar_b=origin_b.reshape(3, hidden_size)[offset, :].reshape(1,1,1,3 * hidden_size)
+		tar_i2h_h2h=np.concatenate([tar_i2h.flatten(),tar_h2h.flatten()])\
+		.reshape(1,1,1,3*hidden_size*hidden_size+3*word_size*hidden_size)
+		return tar_i2h_h2h, tar_b
+
+	def lstm_fc_tensor_merge_convert(self, origin_lstm_w, origin_lstm_b, origin_fc_w, origin_fc_b):
+
+		layer_size = int (origin_fc_b.size // 4)
+		input_size = int (origin_fc_w.size // origin_fc_b.size)
+		lstm_bias_num = int (origin_lstm_b.size // layer_size)
+		tar_w = np.vstack((np.hstack((origin_fc_w[:, 1 * layer_size : 2 * layer_size],
+									  origin_fc_w[:, 2 * layer_size : 3 * layer_size],
+									  origin_fc_w[:, : 1 * layer_size],
+									  origin_fc_w[:, 3 * layer_size :])),
+						   np.hstack((origin_lstm_w[:, 1 * layer_size : 2 * layer_size],
+									  origin_lstm_w[:, 2 * layer_size : 3 * layer_size],
+									  origin_lstm_w[:, : 1 * layer_size],
+									  origin_lstm_w[:, 3 * layer_size : ]))))
+		split_fc_bc = origin_fc_b.flatten()[: 1 * layer_size]
+		split_fc_bi = origin_fc_b.flatten()[1 * layer_size : 2 * layer_size]
+		split_fc_bf = origin_fc_b.flatten()[2 * layer_size : 3 * layer_size]
+		split_fc_bo = origin_fc_b.flatten()[3 * layer_size : 4*layer_size]
+		split_lstm_bc = origin_lstm_b.flatten()[: 1 * layer_size]
+		split_lstm_bi = origin_lstm_b.flatten()[1 * layer_size: 2 * layer_size]
+		split_lstm_bf = origin_lstm_b.flatten()[2 * layer_size: 3 * layer_size]
+		split_lstm_bo = origin_lstm_b.flatten()[3 * layer_size: 4 * layer_size]
+		split_lstm_bc = np.add(split_lstm_bc, split_fc_bc)
+		split_lstm_bi = np.add(split_lstm_bi, split_fc_bi)
+		split_lstm_bf = np.add(split_lstm_bf, split_fc_bf)
+		split_lstm_bo = np.add(split_lstm_bo, split_fc_bo)
+
+		if lstm_bias_num == 4:
+			tar_b = np.array(split_lstm_bi.flatten().tolist()
+							 + split_lstm_bf.flatten().tolist()
+							 + split_lstm_bc.flatten().tolist()
+							 + split_lstm_bo.flatten().tolist())
+		else:
+			split_lstm_wic = origin_lstm_b.flatten()[4 * layer_size : 5 * layer_size]
+			split_lstm_wfc = origin_lstm_b.flatten()[5 * layer_size : 6 * layer_size]
+			split_lstm_woc = origin_lstm_b.flatten()[6 * layer_size :]
+			tar_b = np.array(split_lstm_bi.flatten().tolist()
+							 + split_lstm_bf.flatten().tolist()
+							 + split_lstm_bc.flatten().tolist()
+							 + split_lstm_bo.flatten().tolist()
+							 + split_lstm_wic.flatten().tolist()
+							 + split_lstm_wfc.flatten().tolist()
+							 + split_lstm_woc.flatten().tolist())
+
+		return tar_w.reshape(input_size+ layer_size, 4 * layer_size, 1, 1),\
+			   tar_b.reshape(1, origin_lstm_b.size, 1, 1)
+
+
+class Fluid_comparator:
+
+	def __init__(self, helper):
+		self.helper = helper
+		self.only_list = ['feed', 'fetch']
+
+	def compare_by_param(self, op_a, op_b, param):
+		is_weight_a = self.helper.is_persistable_param(op_a, param)
+		is_weight_b = self.helper.is_persistable_param(op_b, param)
+		if is_weight_a and is_weight_b:
+			np_a = self.helper.np_param(op_a, param)
+			np_b = self.helper.np_param(op_b, param)
+			if (np_a == np_b).all() == True:
+				return True
+			else:
+				return False
+		elif is_weight_a is is_weight_b:
+			return True
+		else:
+			return False
+
+	def have_same_weights(self, op_a, op_b):
+		is_same = True
+		if op_a.input_names == op_b.input_names:
+			params = op_a.input_names
+			for param in params:
+				if self.compare_by_param(op_a, op_b, param) is False:
+					is_same = False
+			return is_same
+		else:
+			return False
+
+	def compare_by_attr(self, op_a, op_b, attr_name):
+		data_a = self.helper.attr_data(op_a, attr_name)
+		data_b = self.helper.attr_data(op_b, attr_name)
+		return data_a == data_b
+
+	def have_same_attrs(self, op_a, op_b):
+		is_same = True
+		if op_a.attr_names == op_b.attr_names:
+			attrs = op_a.attr_names
+			for attr in attrs:
+				if self.compare_by_attr(op_a, op_b, attr) is False:
+					is_same = False
+			return is_same
+		else:
+			return False
+
+	def brothers(self, op_list):
+		is_same = True
+		if len(op_list) > 1:
+			idx = 0
+			for op_b in op_list[1:]:
+				if op_b.type not in self.only_list:
+					idx = op_list.index(op_b)
+					op_a = op_list[idx - 1]
+					if op_a.type not in self.only_list:
+						same_weights = self.have_same_weights(op_a, op_b)
+						same_attrs = self.have_same_attrs(op_a, op_b)
+						if (same_weights and same_attrs) is False:
+							is_same = False
+					else:
+						raise NameError('ERROR: %s is in only_list.' % ( op_a.type ))
+				else:
+					raise NameError('ERROR: %s is in only_list.' % ( op_b.type ))
+			return is_same
+		else:
+			raise NameError('ERROR: Members of op_list must be greater than 2.')
+
+
+ANAKIN_TENSOR_DTYPE = {
+	VarDesc.VarType.BOOL: BOOLEN,
+	VarDesc.VarType.INT32: INT32,
+	VarDesc.VarType.FP16: FLOAT16,
+	VarDesc.VarType.FP32: FLOAT,
+	VarDesc.VarType.FP64: DOUBLE,
+}
+
+ANAKIN_TENSOR_DTYPESTR = {
+	STR: "string",
+	INT32: "int",
+	FLOAT: "float",
+	BOOLEN: "bool",
+}
+
+ANAKIN_ATTR_DTYPE = {
+	AttrType.INT: INT32,
+	AttrType.INTS: INT32,
+	AttrType.FLOAT: FLOAT,
+	AttrType.FLOATS: FLOAT,
+	AttrType.STRING: STR,
+	AttrType.STRINGS: STR,
+	AttrType.BOOL: BOOLEN,
+	AttrType.BOOLS: BOOLEN,
+}
+
+ANAKIN_ATTR_IS_LIST = {
+	AttrType.INT: False,
+	AttrType.INTS: True,
+	AttrType.FLOAT: False,
+	AttrType.FLOATS: True,
+	AttrType.STRING: False,
+	AttrType.STRINGS: True,
+	AttrType.BOOL: False,
+	AttrType.BOOLS: True,
+}
+
+APPEND_BIAS_OP_TYPE = [
+	'FC',
+	'mul',
+	'sequence_conv',
+	'conv2d',
+	'conv2d_transpose',
+	'depthwise_conv2d',
+	'elementwise_mul',
+]
+
+APPEND_ACT_OP_TYPE = [
+	'FC',
+	'mul',
+	'sequence_conv',
+	'conv2d',
+	'conv2d_transpose',
+	'batch_norm',
+	'layer_norm',
+	'row_conv',
+	'reshape',
+]
diff --git a/tools/external_converter_v2/parser/kill_fluid/fluid_layer_param_transmit.py b/tools/external_converter_v2/parser/kill_fluid/fluid_layer_param_transmit.py
new file mode 100644
index 0000000..475a9ac
--- /dev/null
+++ b/tools/external_converter_v2/parser/kill_fluid/fluid_layer_param_transmit.py
@@ -0,0 +1,484 @@
+from ..operations import OpsParam, OpsRegister
+from ..logger import *
+from ..proto import *
+from fluid_helper import *
+
+
+def ParserFeedDecorator(OpName):
+	def warpper(Parser):
+		def warpper_args(args):
+			Parser(args)
+			OpsRegister()[OpName].feed_node_attr(args[0])
+			args[2].set_name(OpName)
+			args[0].set_op(args[2]())
+		return warpper_args
+	return warpper
+
+# common 
+def NotNeededInInference(args):
+	# args is tuple object
+	node_io = args[0]
+	layer = args[1]
+
+@ParserFeedDecorator("Input")
+def Parser_feed(args):
+	private_data = args[4]
+	input_shape = private_data['input_shape']
+	OpsRegister()["Input"].input_shape = input_shape
+
+@ParserFeedDecorator("Convolution")
+def Parser_conv2d(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	[weights_tensor, weights_shape] = helper.param_tensor_sh(op, 'Filter')
+	OpsRegister()["Convolution"].weight_1 = weights_tensor
+	OpsRegister()["Convolution"].filter_num = weights_shape[0]
+	OpsRegister()["Convolution"].kernel_size = weights_shape[-2:]
+	OpsRegister()["Convolution"].strides = helper.attr_data(op, 'strides')
+	OpsRegister()["Convolution"].padding = helper.attr_data(op, 'paddings')
+	OpsRegister()["Convolution"].dilation_rate = helper.attr_data(op, 'dilations')
+	OpsRegister()["Convolution"].group = helper.attr_data(op, 'groups')
+	OpsRegister()["Convolution"].axis = 1
+	if 'bias' in private_data.keys():
+		OpsRegister()["Convolution"].bias_term = True
+		OpsRegister()["Convolution"].weight_2 = private_data['bias']
+	else:
+		OpsRegister()["Convolution"].bias_term = False
+
+@ParserFeedDecorator("ReLU")
+def Parser_relu(args):
+	OpsRegister()["ReLU"].alpha = 0.0
+
+@ParserFeedDecorator("Pooling")
+def Parser_pool2d(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Pooling"].pool_size = helper.attr_data(op, 'ksize')
+	OpsRegister()["Pooling"].strides = helper.attr_data(op, 'strides')
+	OpsRegister()["Pooling"].padding = helper.attr_data(op, 'paddings')
+	OpsRegister()["Pooling"].global_pooling = helper.attr_data(op, 'global_pooling')
+	if helper.attr_data(op, 'pooling_type') == 'max':
+		OpsRegister()["Pooling"].method = "MAX"
+	elif helper.attr_data(op, 'pooling_type') in ['average', 'avg']:
+		OpsRegister()["Pooling"].method = "AVG"
+	if helper.attr_data(op, 'ceil_mode') == False:
+		OpsRegister()["Pooling"].cmp_out_shape_floor_as_conv = True
+	else:
+		OpsRegister()["Pooling"].cmp_out_shape_floor_as_conv = False
+
+@ParserFeedDecorator("Dense")
+def Parser_mul(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	weights_needs_trans = True
+	[weights_tensor, weights_shape] = helper.param_tensor_sh(op, 'Y', weights_needs_trans)
+	OpsRegister()["Dense"].weight_1 = weights_tensor
+	OpsRegister()["Dense"].out_dim = weights_shape[2]
+	OpsRegister()["Dense"].axis = helper.attr_data(op, 'x_num_col_dims')
+	if 'bias' in private_data.keys():
+		OpsRegister()["Dense"].bias_term = True
+		OpsRegister()["Dense"].weight_2 = private_data['bias']
+	else:
+		OpsRegister()["Dense"].bias_term = False
+
+@ParserFeedDecorator("Softmax")
+def Parser_softmax(args):
+	private_data = args[4]
+	if 'axis' in private_data.keys():
+		axis = private_data['axis']
+	else:
+		axis = 1
+	OpsRegister()["Softmax"].axis = axis
+
+@ParserFeedDecorator("Activation")
+def Parser_sigmoid(args):
+	OpsRegister()["Activation"].type = "Sigmoid"
+
+@ParserFeedDecorator("Axpy")
+def Parser_axpy(args):
+	pass
+
+@ParserFeedDecorator("BatchNorm")
+def Parser_batch_norm(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["BatchNorm"].weight_1 = helper.param_tensor(op, 'Mean')
+	OpsRegister()["BatchNorm"].weight_2 = helper.param_tensor(op, 'Variance')
+	OpsRegister()["BatchNorm"].weight_3 = helper.create_tensor([1], [1, 1, 1, 1], FLOAT)
+	OpsRegister()["BatchNorm"].momentum = helper.attr_data(op, 'momentum')
+	OpsRegister()["BatchNorm"].epsilon = helper.attr_data(op, 'epsilon')
+
+@ParserFeedDecorator("Scale")
+def Parser_scale_disc_bn(args):
+	op = args[1]
+	helper = args[3]
+	mean = helper.np_param(op, 'Mean')
+	var = helper.np_param(op, 'Variance')
+	alpha = helper.np_param(op, 'Scale')
+	beta = helper.np_param(op, 'Bias')
+	eps = helper.attr_data(op, 'epsilon')
+	var = np.sqrt(var + eps)
+	np_scale = alpha / var
+	np_bias = beta - (alpha * mean / var)
+	np_scale_shape = map(int, [1]*(4-len(np_scale.shape)) + list(np_scale.shape))
+	np_bias_shape = map(int, [1]*(4-len(np_bias.shape)) + list(np_bias.shape))
+	np_scale_tensor = helper.create_tensor(list(np_scale.flatten()), np_scale_shape, FLOAT)
+	np_bias_tensor = helper.create_tensor(list(np_bias.flatten()), np_bias_shape, FLOAT)
+	OpsRegister()["Scale"].bias_term = True
+	OpsRegister()["Scale"].weight_1 = np_scale_tensor
+	OpsRegister()["Scale"].weight_2 = np_bias_tensor
+	OpsRegister()["Scale"].axis = 1
+	OpsRegister()["Scale"].num_axes = 1
+
+@ParserFeedDecorator("Scale")
+def Parser_scale_of_bn(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Scale"].weight_1 = helper.param_tensor(op, 'Scale')
+	OpsRegister()["Scale"].axis = 1
+	OpsRegister()["Scale"].num_axes = 1
+	has_bias = helper.is_persistable_param(op, 'Bias')
+	if has_bias is True:
+		OpsRegister()["Scale"].bias_term = True
+		OpsRegister()["Scale"].weight_2 = helper.param_tensor(op, 'Bias')
+	else:
+		OpsRegister()["Scale"].bias_term = False
+
+@ParserFeedDecorator("Split")
+def Parser_split(args):
+	private_data = args[4]
+	split_num = private_data['split_num']
+	OpsRegister()["Split"].split_num = split_num
+
+@ParserFeedDecorator("Reshape")		# NMT
+def Parser_reshape(args):
+	op = args[1]
+	helper = args[3]
+	shape = helper.attr_data(op, 'shape')
+	shape = map(int, shape + [1] * (4 - len(shape)))
+	OpsRegister()["Reshape"].dims = shape
+
+@ParserFeedDecorator("Concat")
+def Parser_concat(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Concat"].axis = helper.attr_data(op, 'axis')
+
+@ParserFeedDecorator("Concat")
+def Parser_concat_btw_priorbox_boxcoder(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Concat"].axis = 3
+
+@ParserFeedDecorator("Permute")
+def Parser_transpose(args):
+	op = args[1]
+	helper = args[3]
+	fluid_dims = helper.attr_data(op, 'axis')
+	n = 4 - len(fluid_dims)
+	dims = range(0, n)
+	tail_dims = [i + n for i in fluid_dims]
+	dims.extend(tail_dims)
+	OpsRegister()["Permute"].dims = dims
+
+
+########## SSD Model ##########
+
+@ParserFeedDecorator("PriorBox")
+def Parser_prior_box(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["PriorBox"].min_size = helper.attr_data(op, 'min_sizes')
+	OpsRegister()["PriorBox"].max_size = helper.attr_data(op, 'max_sizes')
+	OpsRegister()["PriorBox"].aspect_ratio = helper.attr_data(op, 'aspect_ratios')
+	OpsRegister()["PriorBox"].is_flip = helper.attr_data(op, 'flip')
+	OpsRegister()["PriorBox"].is_clip = helper.attr_data(op, 'clip')
+	OpsRegister()["PriorBox"].variance = helper.attr_data(op, 'variances')
+	OpsRegister()["PriorBox"].img_h = 0
+	OpsRegister()["PriorBox"].img_w = 0
+	OpsRegister()["PriorBox"].step_h = helper.attr_data(op, 'step_h')
+	OpsRegister()["PriorBox"].step_w = helper.attr_data(op, 'step_w')
+	OpsRegister()["PriorBox"].offset = helper.attr_data(op, 'offset')
+	OpsRegister()["PriorBox"].order = ['MIN', 'COM', 'MAX']
+
+@ParserFeedDecorator("box_coder")
+def Parser_box_coder(args):
+	pass
+
+@ParserFeedDecorator("DetectionOutput")
+def Parser_multiclass_nms(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	OpsRegister()["DetectionOutput"].share_location = True
+	OpsRegister()["DetectionOutput"].variance_encode_in_target = False
+	OpsRegister()["DetectionOutput"].class_num = 0
+	OpsRegister()["DetectionOutput"].background_id = helper.attr_data(op, 'background_label')
+	OpsRegister()["DetectionOutput"].keep_top_k = helper.attr_data(op, 'keep_top_k')
+	OpsRegister()["DetectionOutput"].conf_thresh = helper.attr_data(op, 'score_threshold')
+	OpsRegister()["DetectionOutput"].nms_top_k = helper.attr_data(op, 'nms_top_k')
+	OpsRegister()["DetectionOutput"].nms_thresh = helper.attr_data(op, 'nms_threshold')
+	OpsRegister()["DetectionOutput"].nms_eta = helper.attr_data(op, 'nms_eta')
+	if 'code_type' in private_data.keys():
+		if private_data['code_type'] == 'decode_center_size':
+			OpsRegister()["DetectionOutput"].code_type = "CENTER_SIZE"
+	else:
+		OpsRegister()["DetectionOutput"].code_type = "CORNER"
+
+
+########## VIS Model ##########
+
+@ParserFeedDecorator("Im2Sequence")
+def Parser_im2sequence(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Im2Sequence"].paddings = helper.attr_data(op, 'paddings')
+	OpsRegister()["Im2Sequence"].strides = helper.attr_data(op, 'strides')
+	OpsRegister()["Im2Sequence"].window_size = helper.attr_data(op, 'kernels')
+	OpsRegister()["Im2Sequence"].dilations = helper.attr_data(op, 'dilations', [1, 1])
+
+@ParserFeedDecorator("Cast")
+def Parser_cast(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Cast"].in_type = helper.attr_data(op, 'in_dtype')
+	OpsRegister()["Cast"].out_type = helper.attr_data(op, 'out_dtype')
+
+@ParserFeedDecorator("Argmax") # new256
+def Parser_top_k(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["Argmax"].out_max_val = True
+	OpsRegister()["Argmax"].top_k = helper.attr_data(op, 'k')
+	OpsRegister()["Argmax"].axis_term = False
+
+@ParserFeedDecorator("CtcAlign")
+def Parser_ctc_align(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["CtcAlign"].merge_repeated = helper.attr_data(op, 'merge_repeated')
+	OpsRegister()["CtcAlign"].blank = helper.attr_data(op, 'blank')
+
+@ParserFeedDecorator("Eltwise")
+def Parser_sum(args):
+	OpsRegister()["Eltwise"].type = "Add"
+	OpsRegister()["Eltwise"].coeff = [1.0, 1.0]
+
+@ParserFeedDecorator("LRN")
+def Parser_lrn(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["LRN"].local_size = helper.attr_data(op, 'n')
+	OpsRegister()["LRN"].alpha = helper.attr_data(op, 'alpha')
+	OpsRegister()["LRN"].beta = helper.attr_data(op, 'beta')
+	OpsRegister()["LRN"].norm_region = "ACROSS_CHANNELS"
+	OpsRegister()["LRN"].k = helper.attr_data(op, 'k')
+
+@ParserFeedDecorator("Gru")
+def Parser_gru(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	OpsRegister()["Gru"].is_reverse = helper.attr_data(op, 'is_reverse')
+	OpsRegister()["Gru"].gate_activation = helper.attr_data(op, 'gate_activation') + '_fluid'
+	OpsRegister()["Gru"].activation = helper.attr_data(op, 'activation') + '_fluid'
+	OpsRegister()["Gru"].gru_formula = "gru_origin"
+	if bool(private_data) is True:
+		ori_bx = private_data['np_bias_x']
+		ori_bh = helper.np_param(op, 'Bias')
+		ori_b = ori_bx + ori_bh
+		ori_wx = private_data['np_weight_x']
+		ori_wh = helper.np_param(op, 'Weight')
+		new_tensors = helper.gru_tensor_convert(ori_wh, ori_wx, ori_b)
+		weights = []
+		for tensor in new_tensors:
+			weights.append(helper.create_tensor(list(tensor.flatten()), list(np.shape(tensor)), FLOAT))
+		OpsRegister()["Gru"].weight_1 = weights[0]
+		OpsRegister()["Gru"].weight_2 = weights[1]
+	else:
+		OpsRegister()["Gru"].weight_1 = helper.param_tensor(op, 'Weight')
+		OpsRegister()["Gru"].weight_2 = helper.create_tensor([0], [-1], FLOAT)
+
+@ParserFeedDecorator("LSTM")
+def Parser_lstm(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	OpsRegister()["LSTM"].candidate_activation = helper.attr_data(op, 'candidate_activation')
+	OpsRegister()["LSTM"].cell_activation = helper.attr_data(op, 'cell_activation')
+	OpsRegister()["LSTM"].gate_activation = helper.attr_data(op, 'gate_activation')
+	OpsRegister()["LSTM"].is_reverse = helper.attr_data(op, 'is_reverse')
+	OpsRegister()["LSTM"].use_peepholes = helper.attr_data(op, 'use_peepholes')
+	OpsRegister()["LSTM"].num_direction = 1
+	OpsRegister()["LSTM"].dropout_param = 1.0
+	OpsRegister()["LSTM"].num_layers = 1
+	OpsRegister()["LSTM"].input_activation = "null"
+	if bool(private_data) is True:
+		np_fc_bias = private_data['np_flat_fc_bias']
+		np_fc_weight = private_data['np_flat_fc_weight']
+		np_lstm_bias = helper.np_param(op, 'Bias')
+		np_lstm_weight = helper.np_param(op, 'Weight')
+		np_tensors = helper.lstm_fc_tensor_merge_convert(np_lstm_weight, np_lstm_bias, \
+			np_fc_weight, np_fc_bias)
+		np_weight = np_tensors[0]
+		np_bias = np_tensors[1]
+		np_weight_shape = map(int, [1]*(4-len(np_weight.shape)) + list(np_weight.shape))
+		np_bias_shape = map(int, [1]*(4-len(np_bias.shape)) + list(np_bias.shape))
+		np_weight_tensor = helper.create_tensor(list(np_weight.flatten()), np_weight_shape, FLOAT)
+		np_bias_tensor = helper.create_tensor(list(np_bias.flatten()), np_bias_shape, FLOAT)
+		OpsRegister()["LSTM"].weight_1 = np_weight_tensor
+		OpsRegister()["LSTM"].weight_2 = np_bias_tensor
+	else:
+		OpsRegister()["LSTM"].weight_1 = helper.param_tensor(op, 'Weight')
+		OpsRegister()["LSTM"].weight_2 = helper.create_tensor([0], [-1], FLOAT)
+
+
+
+############### RNN ###############
+
+@ParserFeedDecorator("Embedding")
+def Parser_lookup_table(args):
+	op = args[1]
+	helper = args[3]
+	[weights_tensor, weights_shape] = helper.param_tensor_sh(op, 'W')
+	OpsRegister()["Embedding"].weight_1 = weights_tensor
+	OpsRegister()["Embedding"].padding_idx = helper.attr_data(op, 'padding_idx')
+	OpsRegister()["Embedding"].word_num = weights_shape[2]
+	OpsRegister()["Embedding"].emb_dim = weights_shape[3]
+
+@ParserFeedDecorator("SequencePool")
+def Parser_sequence_pool(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["SequencePool"].pooltype = helper.attr_data(op, 'pooltype')
+
+@ParserFeedDecorator("Activation")
+def Parser_tanh(args):
+	OpsRegister()["Activation"].type = "TanH"
+
+@ParserFeedDecorator("SequenceConv")
+def Parser_sequence_conv(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	[weights_tensor, weights_shape] = helper.param_tensor_sh(op, 'Filter')
+	OpsRegister()["SequenceConv"].weight_1 = weights_tensor
+	OpsRegister()["SequenceConv"].filter_num = weights_shape[0]
+	OpsRegister()["SequenceConv"].kernel_size = weights_shape[-2:]
+	OpsRegister()["SequenceConv"].padding_trainable = helper.attr_data(op, 'paddingTrainable')
+	OpsRegister()["SequenceConv"].context_stride = helper.attr_data(op, 'contextStride')
+	OpsRegister()["SequenceConv"].context_start = helper.attr_data(op, 'contextStart')
+	OpsRegister()["SequenceConv"].context_length = helper.attr_data(op, 'contextLength')
+	if 'bias' in private_data.keys():
+		OpsRegister()["SequenceConv"].bias_term = True
+		OpsRegister()["SequenceConv"].weight_2 = private_data['bias']
+	else:
+		OpsRegister()["SequenceConv"].bias_term = False
+
+@ParserFeedDecorator("CrfDecoding")
+def Parser_crf_decoding(args):
+	op = args[1]
+	helper = args[3]
+	[weights_tensor, weights_shape] = helper.param_tensor_sh(op, 'Transition')
+	OpsRegister()["CrfDecoding"].weight_1 = weights_tensor
+
+@ParserFeedDecorator("MatMul")
+def Parser_matmul(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	if 'coeff' in private_data.keys():
+		coeff = private_data['coeff']
+	else:
+		coeff = 1.0
+	OpsRegister()["MatMul"].transpose_x = helper.attr_data(op, 'transpose_X')
+	OpsRegister()["MatMul"].transpose_y = helper.attr_data(op, 'transpose_Y')
+	OpsRegister()["MatMul"].coeff = coeff
+
+@ParserFeedDecorator("Scale")
+def Parser_scale(args):
+	op = args[1]
+	helper = args[3]
+	scale_val = helper.attr_data(op, 'scale')
+	OpsRegister()["Scale"].axis = 0
+	OpsRegister()["Scale"].num_axes = 0
+	OpsRegister()["Scale"].bias_term = False
+	OpsRegister()["Scale"].weight_1 = helper.create_tensor([scale_val], [1, 1, 1, 1], FLOAT)
+
+@ParserFeedDecorator("LayerNorm")
+def Parser_layer_norm(args):
+	op = args[1]
+	helper = args[3]
+	OpsRegister()["LayerNorm"].weight_1 = helper.param_tensor(op, 'Scale')
+	OpsRegister()["LayerNorm"].weight_2 = helper.param_tensor(op, 'Bias')
+	OpsRegister()["LayerNorm"].begin_norm_axis = helper.attr_data(op, 'begin_norm_axis')
+	OpsRegister()["LayerNorm"].eps = helper.attr_data(op, 'epsilon')
+
+@ParserFeedDecorator("Scale")
+def Parser_dropout(args):
+	op = args[1]
+	helper = args[3]
+	scale_val = 1 - helper.attr_data(op, 'dropout_prob')
+	OpsRegister()["Scale"].axis = 0
+	OpsRegister()["Scale"].num_axes = 0
+	OpsRegister()["Scale"].bias_term = False
+	OpsRegister()["Scale"].weight_1 = helper.create_tensor([scale_val], [1, 1, 1, 1], FLOAT)
+
+@ParserFeedDecorator("Scale")
+def Parser_elementwise_mul(args):
+	op = args[1]
+	helper = args[3]
+	private_data = args[4]
+	OpsRegister()["Scale"].weight_1 = helper.param_tensor(op, 'Y')
+	OpsRegister()["Scale"].axis = helper.attr_data(op, 'axis')
+	OpsRegister()["Scale"].num_axes = 1
+	if 'bias' in private_data.keys():
+		OpsRegister()["Scale"].bias_term = True
+		OpsRegister()["Scale"].weight_2 = private_data['bias']
+	else:
+		OpsRegister()["Scale"].bias_term = False
+
+
+FLUID_NODE_FILLER = {
+	"feed":OpsParam().set_parser(Parser_feed),
+	"conv2d":OpsParam().set_parser(Parser_conv2d),
+	"elementwise_add":OpsParam().set_parser(Parser_sum),
+	"relu":OpsParam().set_parser(Parser_relu),
+	"pool2d":OpsParam().set_parser(Parser_pool2d),
+	"mul":OpsParam().set_parser(Parser_mul),
+	"softmax":OpsParam().set_parser(Parser_softmax),
+	"sigmoid":OpsParam().set_parser(Parser_sigmoid),
+	"axpy":OpsParam().set_parser(Parser_axpy),
+	"batch_norm":OpsParam().set_parser(Parser_batch_norm),
+	"disc_bn":OpsParam().set_parser(Parser_scale_disc_bn),
+	"scale_of_bn":OpsParam().set_parser(Parser_scale_of_bn),
+	"elementwise_mul":OpsParam().set_parser(Parser_elementwise_mul),
+	"split":OpsParam().set_parser(Parser_split),
+	"depthwise_conv2d":OpsParam().set_parser(Parser_conv2d),
+	"reshape":OpsParam().set_parser(Parser_reshape),
+	"concat":OpsParam().set_parser(Parser_concat),
+	"transpose":OpsParam().set_parser(Parser_transpose),
+	"prior_box":OpsParam().set_parser(Parser_prior_box),
+	"box_coder":OpsParam().set_parser(Parser_box_coder),
+	"multiclass_nms":OpsParam().set_parser(Parser_multiclass_nms),
+	"concat_btw_priorbox_boxcoder":OpsParam().set_parser(Parser_concat_btw_priorbox_boxcoder),
+	"im2sequence":OpsParam().set_parser(Parser_im2sequence),
+	"gru":OpsParam().set_parser(Parser_gru),
+	"sum":OpsParam().set_parser(Parser_sum),
+	"lrn":OpsParam().set_parser(Parser_lrn),
+	"top_k":OpsParam().set_parser(Parser_top_k),
+	"ctc_align":OpsParam().set_parser(Parser_ctc_align),
+	"cast":OpsParam().set_parser(Parser_cast),
+	"lookup_table":OpsParam().set_parser(Parser_lookup_table),
+	"sequence_pool":OpsParam().set_parser(Parser_sequence_pool),
+	"tanh":OpsParam().set_parser(Parser_tanh),
+	"sequence_conv":OpsParam().set_parser(Parser_sequence_conv),
+	"crf_decoding":OpsParam().set_parser(Parser_crf_decoding),
+	"lstm":OpsParam().set_parser(Parser_lstm),
+	"matmul":OpsParam().set_parser(Parser_matmul),
+	"layer_norm":OpsParam().set_parser(Parser_layer_norm),
+	"dropout":OpsParam().set_parser(Parser_dropout),
+	"scale":OpsParam().set_parser(Parser_scale),
+}
diff --git a/tools/external_converter_v2/parser/kill_fluid/parser_fluid.py b/tools/external_converter_v2/parser/kill_fluid/parser_fluid.py
new file mode 100644
index 0000000..6c0271b
--- /dev/null
+++ b/tools/external_converter_v2/parser/kill_fluid/parser_fluid.py
@@ -0,0 +1,814 @@
+import numpy as np
+import paddle.fluid as fluid
+import os
+from ..graph_io import *
+from ..logger import *
+from ..proto import *
+from fluid_layer_param_transmit import *
+
+class FluidParser:
+
+	def __init__(self, fluid_config_dict):
+		# anakin graph model io
+		self.graphIO = None
+		# config info
+		self.ProtoPaths = fluid_config_dict['ProtoPaths']
+		self.PrototxtPath = fluid_config_dict['PrototxtPath'] 
+		self.ModelPath = fluid_config_dict['ModelPath']
+		self.NetType = fluid_config_dict['NetType']
+		self.Debug = fluid_config_dict['Debug']
+		# config fluid
+		self.place = fluid.CPUPlace()
+		self.exe = fluid.Executor(self.place)
+		self.scope = fluid.core.Scope()
+		# in and out edges of node
+		self.ins = {}
+		self.outs = {}
+		# inplaced main node
+		self.inplace_nodes = {}
+		self.graph_ins = []
+		self.graph_outs = []
+
+	def __call__(self):
+		return self._Parsing()
+
+	def _NameNodeMid(self, op):
+		first_outparam = op.output_names[0]
+		arg_name = str(op.output(first_outparam)[0]).split('.')[0]
+		#new_name = op.type + '_' + bytes(op.idx)
+		new_name = op.type + '#' + bytes(op.idx) + '(' + arg_name + ')'
+		return new_name
+
+	def _NameNodeIn(self, in_name):
+		new_name = 'input_' + bytes(self.graph_ins.index(in_name))
+		return new_name
+
+	def _NameNodeOut(self, out_name):
+		new_name = out_name + '_gout'
+		return new_name
+
+	def _AddPairEdges(self, start_node_name, end_node_name, out_param, in_param):
+		self.outs[start_node_name].add(out_param, end_node_name)
+		self.ins[end_node_name].add(in_param, start_node_name)
+
+	def _RmPairEdges(self, start_node_name, end_node_name):
+		self.outs[start_node_name].rm(end_node_name)
+		self.ins[end_node_name].rm(start_node_name)
+
+	def _InitEdges(self, node_name):
+		self.ins[node_name] = Fluid_edger()
+		self.outs[node_name] = Fluid_edger()
+
+	def _ClearEdges(self, node_name):
+		if node_name.startswith('input_') is False:
+			del self.ins[node_name]
+		if node_name.endswith('_gout') is False:
+			del self.outs[node_name]
+
+	def _GetOp(self, ops, mid_node_name):
+		mid_op = None
+		for op in ops:
+			node_name = self._NameNodeMid(op)
+			if mid_node_name == node_name:
+				mid_op = op
+		return mid_op
+
+	def _OpTypes(self, ops):
+		types_cache = []
+		for op in ops:
+			if op.type not in types_cache:
+				types_cache.append(op.type)
+		return types_cache
+
+	def _AddProtoNode(self, node_name, op_of_node, helper, private_data, op_type = None):
+		nodeIO = NodeProtoIO()
+		opIO = OpsProtoIO()
+		nodeIO.set_name(node_name)
+		if op_type is None:
+			op_type = op_of_node.type
+		FLUID_NODE_FILLER[op_type](nodeIO, op_of_node, opIO, helper, private_data)
+		self.graphIO.add_node(nodeIO())
+
+	def _RmProtoNode(self, node_name):
+		self.graphIO.rm_node(self.graphIO.find_node_proto(node_name))
+
+	def _InplaceNodes(self, position):
+		inplace_heads = self.inplace_nodes.keys()
+		inplace_mids = []
+		inplace_ends = []
+		for main_node_name in self.inplace_nodes.keys():
+			mid_nodes_name = self.inplace_nodes[main_node_name][1: -1]
+			inplace_mids.extend(mid_nodes_name)
+		for main_node_name in self.inplace_nodes.keys():
+			end_node_name = self.inplace_nodes[main_node_name][-1]
+			inplace_ends.append(end_node_name)
+		if position == 'Head':
+			return inplace_heads
+		elif position == 'Mid':
+			return inplace_mids
+		elif position == 'End':
+			return inplace_ends
+		elif position == 'All':
+			return inplace_heads + inplace_mids + inplace_ends
+
+	def _EdgeInplace(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type not in ['feed', 'fetch']:
+				if len(source_op.input_arg_names) == 1 \
+				and source_op.input_arg_names == source_op.output_arg_names:
+					source_node_name = self._NameNodeMid(source_op)
+					inplace_arg = source_op.input_arg_names[0]
+					for tmp_op in source_ops:
+						if tmp_op.idx != source_op.idx and inplace_arg in tmp_op.output_arg_names:
+							main_node_name = self._NameNodeMid(tmp_op)
+							if main_node_name not in self.inplace_nodes.keys():
+								self.inplace_nodes[main_node_name] = [main_node_name]
+							self.inplace_nodes[main_node_name].append(source_node_name)
+		for main_node_name in self.inplace_nodes.keys():
+			inplace_list = self.inplace_nodes[main_node_name]
+			for inplace_node in inplace_list:
+				idx = inplace_list.index(inplace_node)
+				if idx != 0:
+					self.ins[inplace_node] = Fluid_edger('_In', inplace_list[idx - 1])
+				if idx != len(inplace_list) - 1:
+					self.outs[inplace_node] = Fluid_edger('_Out', inplace_list[idx + 1])
+
+	def _GetDebugOuts(self, source_ops, helper):
+		if self.Debug == 'DEBUG':
+			debug_fetch_list = []
+			for source_op in source_ops:
+				if source_op.type == 'fetch':
+					var_name = source_op.input_arg_names[0]
+					for tmp_op in source_ops:
+						if tmp_op.idx != source_op.idx and var_name in tmp_op.input_arg_names:
+							if var_name not in debug_fetch_list:
+								debug_fetch_list.append(var_name)
+						elif tmp_op.type == 'gru' and var_name in tmp_op.output_arg_names:
+							if var_name not in debug_fetch_list:
+								debug_fetch_list.append(var_name)
+						else:
+							pass
+			return debug_fetch_list
+		else:
+			return []
+
+	def _ParseBase(self, source_ops, helper, sub_graph_nodes = []):
+		# Create the original base graph as described in fluid program.
+		self.graphIO = GraphProtoIO()
+		self.graphIO.set_name('default_graph_name')
+		debug_fetch_list = self._GetDebugOuts(source_ops, helper)
+		self._EdgeInplace(source_ops, helper)
+		for source_op in source_ops:
+			if source_op.type not in ['feed', 'fetch']:
+				main_node_name = self._NameNodeMid(source_op)
+				in_edges = Fluid_edger()
+				out_edges = Fluid_edger()
+				for param in source_op.input_names:
+					for idx in range(0, len(helper.args_by_input_param(source_op, param))):
+						arg = helper.var_name_by_param(source_op, param, idx)
+						for tmp_op in source_ops:
+							if tmp_op.idx != source_op.idx and arg in tmp_op.output_arg_names:
+								if tmp_op.type == 'feed':
+									if arg not in self.graph_ins:
+										self.graph_ins.append(arg)
+										self.graphIO.add_in(self._NameNodeIn(arg))
+									in_edges.add(param, self._NameNodeIn(arg), arg)
+								else:
+									tmp_node_name = self._NameNodeMid(tmp_op)
+									if tmp_node_name in self.inplace_nodes.keys():
+										inplace_node_name = self.inplace_nodes[tmp_node_name][-1]
+										in_edges.add(param, inplace_node_name, arg)
+									elif tmp_node_name not in self._InplaceNodes('All'):
+										in_edges.add(param, tmp_node_name, arg)
+				for param in source_op.output_names:
+					for idx in range(0, len(helper.args_by_output_param(source_op, param))):
+						arg = helper.var_name_by_param(source_op, param, idx)
+						for tmp_op in source_ops:
+							if tmp_op.idx != source_op.idx and arg in tmp_op.input_arg_names:
+								if tmp_op.type == 'fetch':
+									if arg not in debug_fetch_list:
+										arg_node_name = self._NameNodeOut(arg)
+										logger(verbose.WARNING).feed("output of graph: ", arg_node_name)
+										if arg not in self.graph_outs:
+											self.graph_outs.append(arg)
+											self.graphIO.add_out_fluid(arg_node_name, main_node_name)
+										out_edges.add(param, arg_node_name, arg)
+										self.ins[arg_node_name] = Fluid_edger(bytes(source_op.idx), \
+											main_node_name)
+								else:
+									out_edges.add(param, self._NameNodeMid(tmp_op), arg)
+				self._AddProtoNode(main_node_name, source_op, helper, {})
+				if main_node_name not in self._InplaceNodes('Mid'):
+					if main_node_name not in self._InplaceNodes('End'):
+						self.ins[main_node_name] = in_edges
+					if main_node_name not in self._InplaceNodes('Head'):
+						if main_node_name not in self._InplaceNodes('End'):
+							self.outs[main_node_name] = out_edges
+					else:
+						inplace_node_name = self.inplace_nodes[main_node_name][-1]
+						self.outs[inplace_node_name] = out_edges
+						for redundant_target in self.inplace_nodes[main_node_name][1:]:
+							self.outs[inplace_node_name].rm(redundant_target)
+
+	def _PrintEdge(self, node, target, direction):
+		var_name = 'Unknown'
+		if direction == 'in':
+			var = self.ins[node].vars_by_target(target)
+		elif direction == 'out':
+			var = self.outs[node].vars_by_target(target)
+		if len(var) > 0:
+			var_name = var[0]
+		print node + ",\t" + target + ",\t" + var_name
+
+	def _Graph(self, need_print = False):
+		for node in self.ins.keys():
+			targets_list = self.ins[node]()
+			for target in targets_list:
+				self.graphIO.add_in_edge(target, node)
+		for node in self.outs.keys():
+			targets_list = self.outs[node]()
+			for target in targets_list:
+				self.graphIO.add_out_edge(node, target)
+				if need_print is True:
+					self._PrintEdge(node, target, 'out')
+
+	def _ReplaceInputs(self, source_ops, helper, reshape_dict = {}, layout = 'NCHW'):
+		for source_op in source_ops:
+			if source_op.type in ['feed']:
+				out_edges = Fluid_edger()
+				for param in source_op.output_names:
+					private_data = {}
+					arg = helper.var_name_by_param(source_op, param)
+					input_node_name = self._NameNodeIn(arg)
+					for tmp_op in source_ops:
+						if tmp_op.idx != source_op.idx and arg in tmp_op.input_arg_names:
+							out_edges.add(param, self._NameNodeMid(tmp_op))
+					arg_idx = source_op.output_arg_names.index(arg)
+					shape = helper.var_shape_by_param(False, source_op, "Out", arg_idx, 'UNMODIFIED')
+					if shape[0] == -1:
+						shape[0] = 1
+					if layout == 'NCHW':
+						shape = map(int, [1] * (4 - len(shape)) + shape)
+					if input_node_name in reshape_dict.keys():
+						shape = reshape_dict[input_node_name]
+					private_data['input_shape'] = shape
+					self.outs[input_node_name] = out_edges
+					self._AddProtoNode(input_node_name, source_op, helper, private_data)
+
+	def _InsertSplit(self, source_ops, helper):
+		# If a layer has two identical output tensors, add a split layer.
+		for node in self.outs.keys():
+			if node.startswith('split#') is False:
+				out_edges = self.outs[node]
+				for param in out_edges.all_params():
+					out_targets_list = out_edges.targets(param)
+					if len(out_targets_list) > 1:
+						private_data = {}
+						private_data['split_num'] = len(out_targets_list)
+						split_node_name = 'split#' + bytes(out_edges.all_params().index(param)) + '#' + node
+						self._InitEdges(split_node_name)
+						for out_target in out_targets_list:
+							self.outs[node].rm(out_target)
+							self.ins[out_target].mv(node, split_node_name)
+							self.outs[split_node_name].add('_Out', out_target)
+						self._AddPairEdges(node, split_node_name, param, '_In')
+						self._AddProtoNode(split_node_name, None, helper, private_data, 'split')
+
+	def _Subgraph(self, starts, ends):
+		out_idx = {}
+		results = union(starts, ends)
+		def outs(node):
+			if node in self.outs.keys():
+				return self.outs[node]()
+			else:
+				return []
+		def next_out(node):
+			next_out = ''
+			if len(outs(node)) == 0:
+				return -1
+			elif node not in out_idx.keys():
+				out_idx[node] = 0
+			if out_idx[node] < len(outs(node)):
+				next_out = outs(node)[out_idx[node]]
+				out_idx[node] += 1
+			return next_out
+		for start in starts:
+			cache = [start]
+			while len(cache) > 0:
+				target = next_out(cache[-1])
+				while target != -1 and target not in results:
+					if bool(target) is True:
+						cache.append(target)
+						target = next_out(target)
+					else:
+						if cache[-1] in results:
+							results = union(results, cache)
+						break
+				if target in results:
+					cache.append(target)
+					results = union(results, cache)
+				cache.pop()
+		return results
+
+	def _CropGraph(self, ins_of_graph, outs_of_graph, helper):
+		def all_nodes():
+			all_nodes = []
+			for main_node in self.ins.keys():
+				all_nodes.extend(self.ins[main_node].all_targets())
+			for main_node in self.outs.keys():
+				all_nodes.extend(self.outs[main_node].all_targets())
+			return list(set(all_nodes))
+		stayed_nodes = self._Subgraph(ins_of_graph, outs_of_graph)
+		all_nodes = all_nodes()
+		extra_nodes = difference(all_nodes, stayed_nodes)
+		for node_name in extra_nodes:
+			self._RmProtoNode(node_name)
+			self._ClearEdges(node_name)
+			if node_name in self.graphIO.ins():
+				self.graphIO.rm_in(node_name)
+			if node_name in self.graphIO.outs():
+				self.graphIO.rm_out(node_name)
+		for node_name in outs_of_graph:
+			if node_name not in self.graphIO.outs():
+				out_node_name = node_name + '_crop_out'
+				self.ins[out_node_name] = Fluid_edger('_In', node_name)
+				self.outs[node_name] = Fluid_edger('_Out', out_node_name)
+				self.graphIO.add_out_fluid(out_node_name, node_name)
+		for node_name in ins_of_graph:
+			if node_name not in self.graphIO.ins():
+				in_node_name = node_name + '_crop_in'
+				private_data = {'input_shape': [-1, -1, -1, -1]}
+				self.ins[node_name] = Fluid_edger('_In', in_node_name)
+				self.outs[in_node_name] = Fluid_edger('_Out', node_name)
+				self._AddProtoNode(in_node_name, None, helper, private_data, 'feed')
+
+	def _IntegrateNodes(self, main_op, main_node_name, sec_node_name, helper, private_data):
+		# Merge secondary nodes to the primary node and process the edges.
+		self._RmProtoNode(main_node_name)
+		self._RmProtoNode(sec_node_name)
+		target_nodes_names = self.outs[sec_node_name]()
+		for target_node_name in target_nodes_names:
+			self.ins[target_node_name].mv(sec_node_name, main_node_name)
+			self.outs[main_node_name].mv(sec_node_name, target_node_name)
+			self.ins[target_node_name].rm(sec_node_name)
+			self.outs[sec_node_name].rm(target_node_name)
+		self.ins[sec_node_name].rm(main_node_name)
+		self.outs[main_node_name].rm(sec_node_name)
+		self._AddProtoNode(main_node_name, main_op, helper, private_data)
+
+	def _DealWithBias(self, source_ops, helper):
+		# In fluid, the bias parameter of the conv2d is split into elementwise_add.
+		for source_op in source_ops:
+			if source_op.type in APPEND_BIAS_OP_TYPE:
+				private_data = {}
+				main_node_name = self._NameNodeMid(source_op)
+				if main_node_name in self.outs.keys():
+					tmp_nodes_names = self.outs[main_node_name]()
+					if len(tmp_nodes_names) == 1 and tmp_nodes_names[0].startswith('elementwise_add'):
+						elt_node_name = tmp_nodes_names[0]
+						elt_op = self._GetOp(source_ops, elt_node_name)
+						has_weights = helper.is_persistable_param(elt_op, 'Y')
+						if self._NameNodeMid(elt_op) == elt_node_name and has_weights:
+							[elt_tensor, shape] = helper.param_tensor_sh(elt_op, 'Y')
+							new_shape = [1, shape[3], 1, 1]
+							elt_tensor.set_shape(new_shape)
+							private_data['bias'] = elt_tensor
+							self._IntegrateNodes(source_op, main_node_name, elt_node_name, helper, private_data)
+
+	def _DealWithBatchnorm(self, source_ops, helper):
+		# In anakin, the scale part of batchnorm layer is independent.
+		for source_op in source_ops:
+			if source_op.type == 'batch_norm':
+				discrete_flag = True
+				main_node_name = self._NameNodeMid(source_op)
+				input_name = self.ins[main_node_name].target('X')
+				has_scale = helper.is_persistable_param(source_op, 'Scale')
+				if input_name.startswith('elementwise_add'):
+					elt_op = self._GetOp(source_ops, input_name)
+					x_of_elt = self.ins[input_name].target('X')
+					has_weights = helper.is_persistable_param(elt_op, 'Y')
+					if x_of_elt.startswith('conv2d') and has_weights:
+						discrete_flag = False
+				elif input_name.startswith('conv2d'):
+					discrete_flag = False
+				if discrete_flag is True:
+					self._RmProtoNode(main_node_name)
+					self._AddProtoNode(main_node_name, source_op, helper, {}, 'disc_bn')
+				elif has_scale is True:
+					append_node_name = main_node_name + '__scale'
+					tmp_all_targets_params = self.outs[main_node_name].targets_with_params()
+					self._InitEdges(append_node_name)
+					for [tmp_node_name, tmp_param_name] in tmp_all_targets_params:
+						self.outs[append_node_name].add(tmp_param_name, tmp_node_name)
+						self.ins[tmp_node_name].mv(main_node_name, append_node_name)
+						self.outs[main_node_name].rm(tmp_node_name)
+						self.ins[tmp_node_name].rm(main_node_name)
+					self.outs[main_node_name].add('_Scale_out', append_node_name)
+					self.ins[append_node_name].add('_Ins', main_node_name)
+					self._AddProtoNode(append_node_name, source_op, helper, {}, 'scale_of_bn')
+
+	def _DealWithAxpy(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'elementwise_mul':
+				mul_node_name = self._NameNodeMid(source_op)
+				out_targets = self.outs[mul_node_name]()
+				if len(out_targets) == 1 and out_targets[0].startswith('elementwise_add'):
+					add_node_name = out_targets[0]
+					self._RmProtoNode(add_node_name)
+					a_node_name = self.ins[mul_node_name].target('Y')
+					x_node_name = self.ins[mul_node_name].target('X')
+					y_node_name = self.ins[add_node_name].target('X')
+					self._ClearEdges(mul_node_name)
+					self.ins[add_node_name].clear()
+					self.outs[a_node_name].mv(mul_node_name, add_node_name)
+					self.outs[x_node_name].mv(mul_node_name, add_node_name)
+					self.ins[add_node_name].add('A', a_node_name)
+					self.ins[add_node_name].add('X', x_node_name)
+					self.ins[add_node_name].add('Y', y_node_name)
+					self._RmProtoNode(mul_node_name)
+					self._AddProtoNode(add_node_name, None, helper, {}, 'axpy')
+
+	def _DealWithPriorBox(self, source_ops, helper):
+		nodes_to_del = []
+		for source_op in source_ops:
+			if source_op.type == 'prior_box':
+				pb_node_name = self._NameNodeMid(source_op)
+				br_node_name = self.outs[pb_node_name].target('Boxes')
+				vr_node_name = self.outs[pb_node_name].target('Variances')
+				bc_node_name = self.outs[br_node_name].target('Out')
+				vc_node_name = self.outs[vr_node_name].target('Out')
+				boxcoder_node_name = self.outs[bc_node_name].target('Out')
+				self.outs[pb_node_name].mv(br_node_name, bc_node_name)
+				self.outs[pb_node_name].rm(vr_node_name)
+				self.ins[bc_node_name].mv(br_node_name, pb_node_name)
+				self.ins[boxcoder_node_name].rm(vc_node_name)
+				for node_name in [br_node_name, vr_node_name, vc_node_name]:
+					if node_name not in nodes_to_del:
+						nodes_to_del.append(node_name)
+				input_node_name = self.ins[pb_node_name].target('Input')
+				image_node_name = self.ins[pb_node_name].target('Image')
+				self.ins[pb_node_name].rm(input_node_name)
+				self.ins[pb_node_name].rm(image_node_name)
+				self.ins[pb_node_name].add('Input', input_node_name)
+				self.ins[pb_node_name].add('Image', image_node_name)
+				self._RmProtoNode(bc_node_name)
+				self._AddProtoNode(bc_node_name, None, helper, {}, 'concat_btw_priorbox_boxcoder')
+		for node_name in nodes_to_del:
+			self._RmProtoNode(node_name)
+			self._ClearEdges(node_name)
+
+	def _DealWithDetectionOutput(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'box_coder':
+				bc_node_name = self._NameNodeMid(source_op)
+				out_targets = self.outs[bc_node_name]()
+				if len(out_targets) == 1 and out_targets[0].startswith('multiclass_nms'):
+					private_data = {}
+					private_data['code_type'] = helper.attr_data(source_op, 'code_type')
+					bc_out_arg = helper.var_name_by_param(source_op, 'OutputBox')
+					for tmp_op in source_ops:
+						if tmp_op.idx != source_op.idx and bc_out_arg in tmp_op.input_arg_names:
+							nms_op = tmp_op
+					nms_node_name = out_targets[0]
+					loc_node_name = self.ins[bc_node_name].target('TargetBox')
+					conf_node_name = self.ins[nms_node_name].target('Scores')
+					box_node_name = self.ins[bc_node_name].target('PriorBox')
+					self._ClearEdges(bc_node_name)
+					self.ins[nms_node_name].clear()
+					self.outs[loc_node_name].mv(bc_node_name, nms_node_name)
+					self.outs[box_node_name].mv(bc_node_name, nms_node_name)
+					self.ins[nms_node_name].add('mbox_loc', loc_node_name)
+					self.ins[nms_node_name].add('mbox_conf_flatten', conf_node_name)
+					self.ins[nms_node_name].add('mbox_prior_box', box_node_name)
+					self._RmProtoNode(bc_node_name)
+					self._RmProtoNode(nms_node_name)
+					self._AddProtoNode(nms_node_name, nms_op, helper, private_data, 'multiclass_nms')
+
+	def _DealWithMultiFC(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'sum':
+				sum_node_name = self._NameNodeMid(source_op)
+				mul_names_list = self.ins[sum_node_name].targets('X')
+				elt_node_name = self.outs[sum_node_name].target('Out')
+				if elt_node_name.startswith('elementwise_add') and len(mul_names_list) > 1:
+					elt_op = self._GetOp(source_ops, elt_node_name)
+					elt_has_weights = helper.is_persistable_param(elt_op, 'Y')
+					fc_flag = True
+					for mul_node_name in mul_names_list:
+						if mul_node_name.startswith('mul') is False:
+							fc_flags = False
+					if fc_flag and elt_has_weights:
+						private_data = {}
+						first_mul_name = mul_names_list[0]
+						first_mul_op = self._GetOp(source_ops, first_mul_name)
+						in_of_mul_name = self.ins[first_mul_name].target('X')
+						out_of_elt_name = self.outs[elt_node_name].target('Out')
+						self.outs[sum_node_name].mv(elt_node_name, out_of_elt_name)
+						self.ins[out_of_elt_name].mv(elt_node_name, sum_node_name)
+						self._ClearEdges(elt_node_name)
+						[elt_tensor, shape] = helper.param_tensor_sh(elt_op, 'Y')
+						new_shape = [1, shape[3], 1, 1]
+						elt_tensor.set_shape(new_shape)
+						private_data['bias'] = elt_tensor
+						self._RmProtoNode(elt_node_name)
+						self._RmProtoNode(first_mul_name)
+						self._AddProtoNode(first_mul_name, first_mul_op, helper, private_data)
+
+	def _DealWithGru(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'gru':
+				private_data = {}
+				gru_flags = [False, False]
+				gru_node_name = self._NameNodeMid(source_op)
+				gru_op = self._GetOp(source_ops, gru_node_name)
+				input_list_of_gru = self.ins[gru_node_name].targets('Input')
+				if len(input_list_of_gru) == 1 and input_list_of_gru[0].startswith('elementwise_add'):
+					elt_node_name = input_list_of_gru[0]
+					elt_op = self._GetOp(source_ops, elt_node_name)
+					has_weights = helper.is_persistable_param(elt_op, 'Y')
+					if has_weights is True:
+						private_data['np_bias_x'] = helper.np_param(elt_op, 'Y')
+						gru_flags[0] = True
+					input_list_of_elt = self.ins[elt_node_name].targets('X')
+					if len(input_list_of_elt) == 1 and input_list_of_elt[0].startswith('mul'):
+						mul_node_name = input_list_of_elt[0]
+						mul_op = self._GetOp(source_ops, mul_node_name)
+						if helper.var_name_by_param(mul_op, 'Y').startswith('fc'):
+							if helper.attr_data(mul_op, 'x_num_col_dims') == 1:
+								input_list_of_mul = self.ins[mul_node_name].targets('X')
+								input_name_of_mul = input_list_of_mul[0]
+								private_data['np_weight_x'] = helper.np_param(mul_op, 'Y')
+								gru_flags[1] = True
+							else:
+								raise NameError('ERROR: Axis of GRU_FC must be 1.')
+				if gru_flags == [True, True]:
+					self.outs[input_name_of_mul].mv(mul_node_name, gru_node_name)
+					self.ins[gru_node_name].mv(elt_node_name, input_name_of_mul)
+					for node_to_del_name in [mul_node_name, elt_node_name, gru_node_name]:
+						self._RmProtoNode(node_to_del_name)
+						if node_to_del_name is not gru_node_name:
+							self._ClearEdges(node_to_del_name)
+					self._AddProtoNode(gru_node_name, gru_op, helper, private_data)
+
+	def _SearchBilstm(self, source_ops, helper):
+		comp = Fluid_comparator(helper)
+		lstm_ops = []
+		for source_op in source_ops:
+			if source_op.type == 'lstm':
+				lstm_ops.append(source_op)
+		if len(lstm_ops) == 2:
+			lstm_a = lstm_ops[0]
+			lstm_b = lstm_ops[1]
+			same_bias = comp.compare_by_param(lstm_a, lstm_b, 'Bias')
+			same_weight = comp.compare_by_param(lstm_a, lstm_b, 'Weight')
+			if same_bias and same_weight:
+				return True
+			else:
+				return False
+		else:
+			return False
+
+	def _DealWithLstm(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'lstm':
+				private_data = {}
+				lstm_flags = [True, False, False]
+				lstm_node_name = self._NameNodeMid(source_op)
+				lstm_op = self._GetOp(source_ops, lstm_node_name)
+				input_list_of_lstm = self.ins[lstm_node_name].targets('Input')
+				if lstm_flags[0] is True and len(input_list_of_lstm) == 1:
+					if input_list_of_lstm[0].split('#')[0] == 'elementwise_add':
+						elt_node_name = input_list_of_lstm[0]
+						elt_op = self._GetOp(source_ops, elt_node_name)
+						has_weights = helper.is_persistable_param(elt_op, 'Y')
+						if has_weights is True:
+							private_data['np_flat_fc_bias'] = helper.np_param(elt_op, 'Y')
+							lstm_flags[1] = True
+						input_list_of_elt = self.ins[elt_node_name].targets('X')
+				if lstm_flags[1] is True and len(input_list_of_elt) == 1:
+					if input_list_of_elt[0].split('#')[0] == 'mul':
+						mul_node_name = input_list_of_elt[0]
+						mul_op = self._GetOp(source_ops, mul_node_name)
+						if helper.var_name_by_param(mul_op, 'Y').startswith('fc'):
+							if helper.attr_data(mul_op, 'x_num_col_dims') == 1:
+								input_list_of_mul = self.ins[mul_node_name].targets('X')
+								input_name_of_mul = input_list_of_mul[0]
+								private_data['np_flat_fc_weight'] = helper.np_param(mul_op, 'Y')
+								lstm_flags[2] = True
+							else:
+								raise NameError('ERROR: Axis of LSTM_FC must be 1.')
+				if lstm_flags == [True, True, True]:
+					self.outs[input_name_of_mul].mv(mul_node_name, lstm_node_name)
+					self.ins[lstm_node_name].mv(elt_node_name, input_name_of_mul)
+					for node_to_del_name in [mul_node_name, elt_node_name, lstm_node_name]:
+						self._RmProtoNode(node_to_del_name)
+						if node_to_del_name is not lstm_node_name:
+							self._ClearEdges(node_to_del_name)
+					self._AddProtoNode(lstm_node_name, lstm_op, helper, private_data)
+
+	def _DealWithCast(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'cast':
+				if helper.attr_data(source_op, 'out_dtype') == 5:
+					cast_node_name = self._NameNodeMid(source_op)
+					input_name_of_cast = self.ins[cast_node_name].target('X')
+					if input_name_of_cast.startswith('top_k') is False:
+						output_name_of_cast = self.outs[cast_node_name].target('Out')
+						self.outs[input_name_of_cast].mv(cast_node_name, output_name_of_cast)
+						self.ins[output_name_of_cast].mv(cast_node_name, input_name_of_cast)
+						self._RmProtoNode(cast_node_name)
+						self._ClearEdges(cast_node_name)
+				else:
+					raise NameError('The out type of cast must be float32.')
+
+	def _DealWithArgmax(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'top_k':
+				private_data = {}
+				topk_node_name = self._NameNodeMid(source_op)
+				out_list = self.outs[topk_node_name].targets('Out')
+				indices_list = self.outs[topk_node_name].targets('Indices')
+				if len(indices_list) > 0:
+					if len(out_list) == 1 and indices_list[0].startswith('cast'):
+						private_data['out_max_val'] = True
+						cast_node_name = indices_list[0]
+						output_name_of_cast = self.outs[cast_node_name].target('Out')
+						if output_name_of_cast == out_list[0] and out_list[0].startswith('concat'):
+							concat_node_name = out_list[0]
+							output_name_of_concat = self.outs[concat_node_name].target('Out')
+							self.outs[topk_node_name].rm(cast_node_name)
+							self.outs[topk_node_name].mv(concat_node_name, output_name_of_concat)
+							self.ins[output_name_of_concat].mv(concat_node_name, topk_node_name)
+							for node_to_del_name in [concat_node_name, cast_node_name]:
+								self._RmProtoNode(node_to_del_name)
+								self._ClearEdges(node_to_del_name)
+					elif len(out_list) == 0:
+						private_data['out_max_val'] = False
+						self._DealWithCast(source_ops, helper)
+					else:
+						raise NameError('ERROR: Unknown top_k layer.')
+					self._RmProtoNode(topk_node_name)
+					self._AddProtoNode(topk_node_name, source_op, helper, private_data)
+
+	def _DealWithReshape(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'reshape':
+				reshape_node_name = self._NameNodeMid(source_op)
+				if reshape_node_name in self.ins:
+					shape_inputs = self.ins[reshape_node_name].targets('Shape')
+					tensor_inputs = self.ins[reshape_node_name].targets('X')
+					if len(shape_inputs) == 1 and len(tensor_inputs) == 1:
+						self.ins[reshape_node_name].rm(shape_inputs[0])
+						self.ins[reshape_node_name].add('Shape', shape_inputs[0])
+				else:
+					pass
+
+	def _DealWithSoftmax(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'softmax':
+				softmax_node_name = self._NameNodeMid(source_op)
+				outs_of_softmax = self.outs[softmax_node_name].targets('Out')
+				ins_of_softmax = self.ins[softmax_node_name].targets('X')
+				def prune(reshape_node_name):
+					branch = []
+					branch.append(reshape_node_name)
+					shape_inputs = self.ins[reshape_node_name].targets('Shape')
+					tensor_input = self.ins[reshape_node_name].target('X')
+					tensor_output = self.outs[reshape_node_name].target('Out')
+					if len(shape_inputs) == 1:
+						branch.append(shape_inputs[0])
+					if len(branch) == 2 and branch[1].split('#')[0] == 'split':
+						split_node_name = branch[1]
+						self.outs[split_node_name].rm(reshape_node_name)
+						self.ins[reshape_node_name].rm(split_node_name)
+						if len(self.outs[split_node_name].targets('_Out')) == 0:
+							input_of_split = self.ins[split_node_name].target('_In')
+							branch.append(input_of_split)
+							self._RmProtoNode(split_node_name)
+							self._ClearEdges(split_node_name)
+					elif len(branch) == 2 and branch[1].startswith('input'):
+						raise NameError('ERROR: None-split input of Softmax has not supported.')
+					self.outs[tensor_input].mv(reshape_node_name, tensor_output)
+					self.ins[tensor_output].mv(reshape_node_name, tensor_input)
+					self._RmProtoNode(reshape_node_name)
+					self._ClearEdges(reshape_node_name)
+					if len(branch) == 3 and branch[2].startswith('input'):
+						input_node_name = branch[2]
+						self._RmProtoNode(input_node_name)
+						self._ClearEdges(input_node_name)
+				if outs_of_softmax[0].split('#')[0] == 'reshape' and \
+				ins_of_softmax[0].split('#')[0] == 'reshape':
+					private_data = {}
+					private_data['axis'] = 3
+					prune(outs_of_softmax[0])
+					prune(ins_of_softmax[0])
+					self._RmProtoNode(softmax_node_name)
+					self._AddProtoNode(softmax_node_name, source_op, helper, private_data)
+
+	def _DealWithMatmal(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'matmul':
+				matmul_node_name = self._NameNodeMid(source_op)
+				x_input_name = self.ins[matmul_node_name].target('X')
+				y_input_name = self.ins[matmul_node_name].target('Y')
+				flag = False
+				coeff = 1.0
+				for node_name in [x_input_name, y_input_name]:
+					if node_name.startswith('scale') or node_name.startswith('dropout'):
+						op = self._GetOp(source_ops, node_name)
+						if node_name.startswith('scale'):
+							scale = helper.attr_data(op, 'scale')
+						elif node_name.startswith('dropout'):
+							scale = 1 - helper.attr_data(op, 'dropout_prob')
+						input_node = self.ins[node_name].target('X')
+						self.outs[input_node].mv(node_name, matmul_node_name)
+						self.ins[matmul_node_name].mv(node_name, input_node)
+						self._RmProtoNode(node_name)
+						self._ClearEdges(node_name)
+						coeff = coeff * scale
+						flag = True
+				if flag is True:
+					private_data = {}
+					private_data['coeff'] = coeff
+					self._RmProtoNode(matmul_node_name)
+					self._AddProtoNode(matmul_node_name, source_op, helper, private_data)
+
+	def _DealWithDiscBatchNorm(self, source_ops, helper):
+		for source_op in source_ops:
+			if source_op.type == 'batch_norm':
+				discrete_flag = True
+				bn_node_name = self._NameNodeMid(source_op)
+				input_name = self.ins[bn_node_name].target('X')
+				if input_name.startswith('elementwise_add'):
+					input_of_elt = self.ins[input_name].target('X')
+					if input_of_elt.startswith('conv2d'):
+						discrete_flag = False
+				elif input_name.startswith('conv2d'):
+					discrete_flag = False
+				if discrete_flag is True:
+					self._RmProtoNode(bn_node_name)
+					self._AddProtoNode(bn_node_name, source_op, helper, {}, 'disc_bn')
+
+	def _InsertCommonLayer(self,
+						   source_ops,
+						   in_target,
+						   in_param,
+						   out_target,
+						   out_param,
+						   layer_type,
+						   private_data,
+						   helper):
+
+		if in_target in self.ins[out_target].all_targets() and \
+		out_target in self.outs[in_target].all_targets():
+			main_layer = layer_type + '_after_' + in_target
+			self.ins[out_target].mv(in_target, main_layer)
+			self.outs[in_target].mv(out_target, main_layer)
+			self.ins[main_layer] = Fluid_edger(in_param, in_target)
+			self.outs[main_layer] = Fluid_edger(out_param, out_target)
+			self._AddProtoNode(main_layer, None, helper, private_data, layer_type)
+		else:
+			raise NameError('ERROR: Usage of InsertCommonLayer has not supported.')
+
+	def _ParseNetwork(self, source_ops, helper):
+		self._ParseBase(source_ops, helper)
+		if self.NetType == "FLUIDBASE":
+			pass
+		elif self.NetType == "OCR":
+			reshape_dict = {}
+			reshape_dict['input_0'] = [1, 1, 48, 1500]
+			self._ReplaceInputs(source_ops, helper, reshape_dict)
+			self._InsertSplit(source_ops, helper)
+			self._DealWithGru(source_ops, helper)
+			self._DealWithBias(source_ops, helper)
+			self._DealWithBatchnorm(source_ops, helper)
+			self._DealWithMultiFC(source_ops, helper)
+			self._DealWithArgmax(source_ops, helper)
+		else:
+			self._ReplaceInputs(source_ops, helper)
+			self._InsertSplit(source_ops, helper)
+			self._DealWithBias(source_ops, helper)
+			self._DealWithBatchnorm(source_ops, helper)
+			if self.NetType == "VGG":
+				pass
+			elif self.NetType == "SeResnext50":
+				self._DealWithAxpy(source_ops, helper)
+		self._Graph()
+
+
+
+	def _Parsing(self):
+		with fluid.scope_guard(self.scope):
+			if os.path.exists(self.ModelPath + 'model') and os.path.exists(self.ModelPath + 'params'):
+				[self.net_program, feed_target_names, fetch_targets] = \
+				fluid.io.load_inference_model(self.ModelPath, self.exe, 'model', 'params')
+			else:
+				[self.net_program, feed_target_names, fetch_targets] = \
+				fluid.io.load_inference_model(self.ModelPath, self.exe)
+
+			global_block = self.net_program.global_block()
+			source_ops = list(global_block.ops)
+			helper = Fluid_helper(self.scope, global_block)
+
+			self._ParseNetwork(source_ops, helper)
+			return self.graphIO
diff --git a/tools/external_converter_v2/parser/operations/__init__.py b/tools/external_converter_v2/parser/operations/__init__.py
index 1a82466..8bd8f79 100644
--- a/tools/external_converter_v2/parser/operations/__init__.py
+++ b/tools/external_converter_v2/parser/operations/__init__.py
@@ -2,6 +2,6 @@
 # Copyright (c) 2017, Cuichaowen. All rights reserved.
 # -*- coding: utf-8 -*-
 
-from op import OpParam
-from op import OpsRegister
+from op import OpsParam, OpsRegister
 import ops
+import ops_fluid
diff --git a/tools/external_converter_v2/parser/operations/op.py b/tools/external_converter_v2/parser/operations/op.py
index 61031ab..27cd03e 100644
--- a/tools/external_converter_v2/parser/operations/op.py
+++ b/tools/external_converter_v2/parser/operations/op.py
@@ -4,7 +4,7 @@
 from ..logger import *
 
 
-class OpParam(object):
+class OpsParam(object):
     """
     """
     def __init__(self):
@@ -55,7 +55,7 @@ class OpsRegister(object):
     @staticmethod
     def Register(name):
         if name not in OpsRegister():
-            OpsRegister.instance[name] = OpParam()
+            OpsRegister.instance[name] = OpsParam()
         return OpsRegister.instance[name]
 
     @staticmethod
@@ -82,4 +82,4 @@ class OpsRegister(object):
         """
         if name in self:
             return OpsRegister.instance[name]
-        return OpParam()
+        return OpsParam()
diff --git a/tools/external_converter_v2/parser/operations/ops.py b/tools/external_converter_v2/parser/operations/ops.py
index e52272d..5325e8c 100755
--- a/tools/external_converter_v2/parser/operations/ops.py
+++ b/tools/external_converter_v2/parser/operations/ops.py
@@ -1,8 +1,7 @@
 #! /usr/bin/env python
 # Copyright (c) 2017, Cuichaowen. All rights reserved.
 # -*- coding: utf-8 -*-
-from op import OpParam
-from op import OpsRegister
+from op import OpsParam, OpsRegister
 from op_io import *
 
 ############################# IO define ##############################
@@ -256,7 +255,8 @@ OpsRegister.Register("PriorBox").set_attr(min_size=list(),
                                           img_w=int(), 
                                           step_h=float(), 
                                           step_w=float(), 
-                                          offset=float())
+                                          offset=float(),
+                                          order=list())
 
 # enum code_type {
 #	 CORNER,
@@ -281,10 +281,70 @@ OpsRegister.Register("DetectionOutput").set_attr(share_location=bool(),
 
 OpsRegister.Register("Argmax").set_attr(out_max_val=bool(), 
                                         top_k=int(), 
-                                        axis=int())
+                                        axis=int(),
+                                        axis_term=bool())
 
 
-OpsRegister.Register("Normalize").set_attr(is_across_spatial=bool(), 
-                                           is_shared_channel=bool(), 
-                                           eps=float(), 
-                                           p=int())
+########### OCR Op define #############
+
+OpsRegister.Register("Im2Sequence").set_attr(paddings=list(),
+                                             strides=list(),
+                                             window_size=list(),
+                                             dilations=list())
+
+
+OpsRegister.Register("Cast").set_attr(in_type=int(),
+                                      out_type=int())
+
+
+OpsRegister.Register("Gru").set_attr(is_reverse=bool(),
+                                     gate_activation="sigmoid",
+                                     activation="relu",
+                                     gru_formula="")
+
+OpsRegister.Register("CtcAlign").set_attr(merge_repeated=bool(),
+                                          blank=int())
+
+
+########### RNN Op define #############
+
+
+OpsRegister.Register("Embedding").set_attr(word_num=int(),
+                                           emb_dim=int(),
+                       padding_idx=int())
+
+
+OpsRegister.Register("SequencePool").set_attr(pooltype="LAST")
+
+
+OpsRegister.Register("SequenceConv").set_attr(filter_num=int(),
+                                              kernel_size=list(), 
+                                              padding_trainable=bool(),
+                                              context_stride=int(),
+                                              context_start=int(),
+                                              context_length=int())
+
+OpsRegister.Register("CrfDecoding").set_attr()
+
+
+OpsRegister.Register("LSTM").set_attr(candidate_activation="tanh",
+                                      cell_activation="tanh",
+                                      gate_activation="sigmoid",
+                                      is_reverse=bool(),
+                                      use_peepholes=bool(),
+                                      num_direction=int(),
+                                      dropout_param=float(),
+                                      num_layers=int(),
+                                      input_activation="null")
+
+
+OpsRegister.Register("MatMul").set_attr(transpose_x=bool(),
+                                        transpose_y=bool(),
+                                        coeff=float())
+
+
+OpsRegister.Register("LayerNorm").set_attr(is_across_spatial=bool(),
+                                           is_shared_channel=bool(),
+                                           begin_norm_axis=int(),
+                                           eps=float())
+
diff --git a/tools/external_converter_v2/parser/operations/ops_fluid.py b/tools/external_converter_v2/parser/operations/ops_fluid.py
new file mode 100755
index 0000000..a802e28
--- /dev/null
+++ b/tools/external_converter_v2/parser/operations/ops_fluid.py
@@ -0,0 +1,34 @@
+#! /usr/bin/env python
+# Copyright (c) 2017, Cuichaowen. All rights reserved.
+# -*- coding: utf-8 -*-
+from op import OpsParam, OpsRegister
+from op_io import *
+
+
+OpsRegister.Register("elementwise_mul").set_attr()
+OpsRegister.Register("depthwise_conv2d").set_attr()
+OpsRegister.Register("transpose").set_attr()
+OpsRegister.Register("reshape").set_attr()
+OpsRegister.Register("concat").set_attr()
+OpsRegister.Register("box_coder").set_attr()
+
+OpsRegister.Register("im2sequence").set_attr()
+OpsRegister.Register("sum").set_attr()
+OpsRegister.Register("top_k").set_attr()
+OpsRegister.Register("ctc_align").set_attr()
+OpsRegister.Register("cast").set_attr()
+OpsRegister.Register("elementwise_add_fulid").set_attr()
+
+OpsRegister.Register("lookup_table").set_attr()
+OpsRegister.Register("lstm").set_attr()
+OpsRegister.Register("sequence_pool").set_attr()
+OpsRegister.Register("tanh").set_attr()
+
+OpsRegister.Register("sequence_conv").set_attr()
+OpsRegister.Register("stanh").set_attr()
+
+
+OpsRegister.Register("matmul").set_attr()
+OpsRegister.Register("layer_norm").set_attr()
+OpsRegister.Register("dropout").set_attr()
+OpsRegister.Register("scale").set_attr()
diff --git a/tools/external_converter_v2/parser/pbs/__init__.py b/tools/external_converter_v2/parser/pbs/__init__.py
index f57645a..40e5a38 100644
--- a/tools/external_converter_v2/parser/pbs/__init__.py
+++ b/tools/external_converter_v2/parser/pbs/__init__.py
@@ -7,7 +7,3 @@ try:
 except ImportError:
     raise ImportError(' No module named caffe_pb2 . ')
 
-try:
-    from caffe_yolo_pb2 import *
-except ImportError:
-    raise ImportError(' No module named caffe_yolo_pb2 . ')
diff --git a/tools/external_converter_v2/parser/proto/node.proto b/tools/external_converter_v2/parser/proto/node.proto
index c5cb59a..fc26b87 100644
--- a/tools/external_converter_v2/parser/proto/node.proto
+++ b/tools/external_converter_v2/parser/proto/node.proto
@@ -38,6 +38,6 @@ message NodeProto {
     bool need_wait = 12;
 
     // Operator of node.
-    OpProto Op = 15;
+    OpsProto Op = 15;
 };
 
diff --git a/tools/external_converter_v2/parser/proto/operator.proto b/tools/external_converter_v2/parser/proto/operator.proto
index 222b93f..5ff6131 100644
--- a/tools/external_converter_v2/parser/proto/operator.proto
+++ b/tools/external_converter_v2/parser/proto/operator.proto
@@ -1,7 +1,7 @@
 syntax = "proto3";
 
 // define an operation of anain.
-message OpProto {
+message OpsProto {
     // operator name.
     string name = 1;
 
diff --git a/utils/logger/log_utils.h b/utils/logger/log_utils.h
new file mode 100644
index 0000000..287b6ef
--- /dev/null
+++ b/utils/logger/log_utils.h
@@ -0,0 +1,229 @@
+/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+   
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License. 
+*/
+
+#ifndef LOG_UTILS_H
+#define LOG_UTILS_H
+
+#include <algorithm>
+#include <atomic>
+#include <chrono>
+#include <cstdio>
+#include <cstdlib>
+#include <cstring>
+#include <cstddef>
+#include <mutex>
+#include <regex>
+#include <string>
+#include <thread>
+#include <vector>
+#include <cstdarg>
+#include <sstream>
+#include <string>
+#include <stdio.h>
+#include <stdlib.h>
+#include <signal.h>
+#include <sys/stat.h> // mkdir
+#include <unistd.h>   // STDERR_FILENO
+#include "anakin_config.h"
+
+// Disable all warnings from gcc/clang:
+#if defined(__clang__)
+        #pragma clang system_header
+#elif defined(__GNUC__)
+        #pragma GCC system_header
+#endif
+
+
+namespace logger {
+
+
+#define LOGGER_CONCAT(str1,str2)  str1##str2
+
+/// \brief intercept the our own abort signal
+///
+/// for usage: signal(SIGABRT, SIG_DFL);
+/// SIG_DFL:default signal handle invoke param
+#define LOGGER_CATCH_SIGABRT 1
+
+#define SUPPORT_PTHREADS  1 // support for pthreads
+
+#ifdef TARGET_ANDRIOD
+	#define STACKTRACES 0
+#else
+	#define STACKTRACES 1
+#endif
+
+#ifdef __linux__
+  #include <linux/limits.h> // PATH_MAX
+  #include <pthread.h>
+  #include <sys/utsname.h>  // For uname.
+
+#if STACKTRACES
+  #include <cxxabi.h>    // for __cxa_demangle for gcc
+  #include <dlfcn.h>     // for dladdr
+  #include <execinfo.h>  // for backtrace
+#endif //STACKTRACES
+
+#if SUPPORT_PTHREADS
+  /// @brief
+  /// On Linux, the default thread name is the same as the name of the binary.
+  /// Additionally, all new threads inherit the name of the thread it got forked from.
+  /// For this reason, we use the Thread Local Storage for storing thread names on Linux.
+  /// There are many language-specific(c/c++,java,python,perl,objective-c...) and
+  /// OS implementions(linux ,window) for TLS.
+  #define LOGGER_TLS_NAMES 1
+#endif // SUPPORT_PTHREADS
+
+#endif
+
+
+#ifndef PATH_MAX
+        #define PATH_MAX 1024
+#endif
+
+#ifdef __APPLE__
+        #include "TargetConditionals.h"
+#endif
+
+#ifdef  __COUNTER__
+  #define LOGGER_ADD_LINE(str)    LOGGER_CONCAT(str,__COUNTER__)
+#else
+  #define LOGGER_ADD_LINE(str)    LOGGER_CONCAT(str,__LINE__)
+#endif
+
+namespace core {
+
+    enum  VerBoseType: int
+    {
+        Verbose_OFF     = -9, ///< log off
+        Verbose_FATAL   = -3, ///< log info fatal
+        Verbose_ERROR   = -2, ///< log info ERROR
+        Verbose_WARNING = -1, ///< log info WARNING
+        Verbose_INFO    = 0,  ///< log info normal
+        Verbose_0       = 0,  ///< verbose  0
+        Verbose_1       =1,
+        Verbose_2,
+        Verbose_3,
+        Verbose_4,
+        Verbose_5,
+        Verbose_6,
+        Verbose_7,
+        Verbose_8,
+        Verbose_9,
+        Verbose_Max     =9    ///< max level verbose
+    };
+
+    enum FileMode: int {
+        CREATE,              ///< CREATE A NEW LOG FILE
+        APPEND,              ///< APPEND TO LOCAL FILE(EXISTED!)
+    };
+
+    ///< logger start time record
+    static const auto startTime = std::chrono::steady_clock::now();
+
+    #if STACKTRACES
+    namespace {
+        template <class T>
+        std::string type_name()
+        {
+           int status = -1;
+           char* demangled = abi::__cxa_demangle(typeid(T).name(), 0, 0, &status);
+           return std::string(status == 0 ? demangled : strdup(typeid(T).name()));
+        }
+    }
+    using PairList = std::vector< std::pair<std::string,std::string> >;
+    static const PairList replaceList={
+           { type_name<std::string>(),    "std::string"    },
+           { type_name<std::wstring>(),   "std::wstring"   },
+           { type_name<std::u16string>(), "std::u16string" },
+           { type_name<std::u32string>(), "std::u32string" },
+           { "std::__1::",                "std::"          },
+           { "__thiscall ",               ""               },
+           { "__cdecl ",                  ""               },
+    };
+	#else
+	namespace {
+        template <class T>
+        std::string type_name() { return std::string(""); }
+    }
+    using PairList = std::vector< std::pair<std::string,std::string> >;
+    static const PairList replaceList={};
+    #endif
+
+    class ErrContext;
+    struct Callback;
+    using CallbackVec = std::vector<Callback>;
+
+    namespace  LoggerConfig
+    {
+		 static bool logtostderr = false;
+         static bool colorstderr = true;                    ///< true default
+         static bool terminalSupportColor;                  ///< true if terminal support color(win does not support it)
+         static unsigned flushBufferInMs = 0;               ///< flush buffer on every line (if x) in x ms later or flush everything immediatly(if 0)
+         static bool needFlush = false;
+         static std::thread* flushThread = nullptr;         ///< for periodic flushing (a guard thread)
+         static std::recursive_mutex  rsMutex;              ///< synchronization primitive used to protect shared data
+         static VerBoseType currentVerbos = Verbose_0;
+         static VerBoseType currentMaxVerbos = Verbose_OFF;
+         static const bool splitFileName = true;            ///< if split the fileName without the path? true ==> pure fileName without path "/"
+         static char  projectPath;                          ///< project root path
+		 static const char* userName;						///< machine user name , used for log file name.
+		 static const char* programName;					///< program name get from argv[0]
+		 static const char* hostName;						///< host machine name used for log file name.
+	     
+         //static pthread_once_t pthreadKeyOnce = PTHREAD_ONCE_INIT;
+         #ifdef LOGGER_TLS_NAMES
+         static __thread char*  pthreadKeyName;
+         #endif
+
+         static __thread  ErrContext* pthreadErrCtPtr;
+         const static int threadNameWidth = 16;             ///< Width of the column containing the thread name
+         static const int filenNameWidth  = 23;             ///< Width of the column containing the file name
+
+         static std::recursive_mutex  callbackMutex;
+         static CallbackVec           callbackVecs;         ///< call back struct vector
+
+	 	 /// return the current max verbos	
+	 	 static VerBoseType current_verbosity_cutoff(){
+		 	 return currentVerbos> currentMaxVerbos ? 
+			 	 currentVerbos : currentMaxVerbos;
+	 	 }
+
+         static void init(){
+
+             if (const char* term = getenv("TERM")) {
+                if( 0 == strcmp(term, "cygwin")
+                            || 0 == strcmp(term, "linux")
+                            || 0 == strcmp(term, "screen")
+                            || 0 == strcmp(term, "xterm")
+                            || 0 == strcmp(term, "xterm-256color")
+                            || 0 == strcmp(term, "xterm-color")){
+                        terminalSupportColor = true;
+                    }
+             } else {
+                terminalSupportColor = false;
+             }
+
+         } // init LoggerConfig
+    }// namespace LoggerConfig
+} // namespace core
+
+
+} // namespace logger
+
+
+
+
+#endif // LOG_UTILS_H
diff --git a/utils/logger/logger.h b/utils/logger/logger.h
index 830193c..379220f 100644
--- a/utils/logger/logger.h
+++ b/utils/logger/logger.h
@@ -1,7 +1,9 @@
 /* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
+
        http://www.apache.org/licenses/LICENSE-2.0
    
    Unless required by applicable law or agreed to in writing, software
@@ -10,164 +12,133 @@
    See the License for the specific language governing permissions and
    limitations under the License. 
 */
+
 #ifndef LOGGER_H
 #define LOGGER_H
 
+#define LOGGER_SHUTDOWN 0
+
+#include "anakin_config.h"
 #include "logger_core.h"
 
+#define SCOPE_LOGGER_CORE_FUNC 		logger::core::funcRegister
+#define SCOPE_LOGGER_CORE      		logger::core
+#define SCOPE_LOGGER_CORE_CONFIG	logger::core::LoggerConfig
+
 namespace logger {
 
-/// logger inital api
-inline void init(const char* argv0){
-#ifndef LOGGER_SHUTDOWN 
-    core::initial(argv0); 
-#endif 
-}
 
-} /* namespace logger */
+    inline void init(const char* argv0){
+#if not LOGGER_SHUTDOWN
+        SCOPE_LOGGER_CORE_FUNC::initial(argv0);
+#endif
+
+    }
+
+} // namespace logger
+
 
 namespace {
 
-/// judge x if false or true
-#define LOGGER_IS_FALSE(x) (__builtin_expect(x,0)) 
-#define LOGGER_IS_TRUE(x)  (__builtin_expect(!!(x),1))
-
-#define LOGGER_CHECK_SYMBOL_WARP(name, symbol)                                                        \
-    template <typename T1, typename T2>                                                               \
-    inline std::string* name(const char* expr, const T1& lvalue, const char* op, const T2& rvalue){    \
-        if(LOGGER_IS_TRUE(lvalue symbol rvalue)){return nullptr;}                   \
-        std::ostringstream ss;                                                      \
-        ss<<"Check failed:"<< expr <<" ("<<lvalue<<" "<<op<<" "<<rvalue<<") ";      \
-        return new std::string(ss.str());                                           \
-    }                                                                               \
-    inline std::string* name(const char* expr, int lvalue, const char* op, int rvalue){      \
-        return name<int,int>(expr, lvalue, op, rvalue);                             \
-    }                                                                               \
-    inline std::string* name(const char* expr, char lvalue, const char* op, char rvalue){    \
-        return name<char,char>(expr, lvalue, op, rvalue);                           \
-    }                                                                               \
-    inline std::string* name(const char* expr, std::string lvalue, const char* op, std::string rvalue){    \
-        return name<std::string,std::string>(expr, lvalue, op, rvalue);             \
-    }
+#define CHECK_SYMBOL_WARP(name, symbol)    											\
+    template <typename T1, typename T2>    											\
+    inline std::string * name(const char* expr, const T1& lvalue, const char* op, const T2& rvalue){	\
+        if(LOGGER_IS_TRUE(lvalue symbol rvalue)){return nullptr;}					\
+        std::ostringstream ss;														\
+        ss<<"Check failed:"<< expr <<" ("<<lvalue<<" "<<op<<" "<<rvalue<<") ";		\
+        return new std::string(ss.str());											\
+    }																				\
+    inline std::string * name(const char* expr, int lvalue, const char* op, int rvalue){	\
+        return name<int,int>(expr, lvalue, op, rvalue);								\
+    }																				\
+	inline std::string * name(const char* expr, char lvalue, const char* op, char rvalue){    \
+		return name<char,char>(expr, lvalue, op, rvalue);                           \
+	}																				\
+	inline std::string * name(const char* expr, std::string lvalue, const char* op, std::string rvalue){    \
+		return name<std::string,std::string>(expr, lvalue, op, rvalue);             \
+	}	
+	
+
+CHECK_SYMBOL_WARP(CHECK_EQ_IMPL, ==)
+CHECK_SYMBOL_WARP(CHECK_LE_IMPL, <=)
+CHECK_SYMBOL_WARP(CHECK_GE_IMPL, >=)
+CHECK_SYMBOL_WARP(CHECK_NE_IMPL, !=)
+CHECK_SYMBOL_WARP(CHECK_LT_IMPL, <)
+CHECK_SYMBOL_WARP(CHECK_GT_IMPL, >)
+#undef CHECK_SYMBOL_WARP
+
+/// usage: LOG_S(INFO)<<"function? "<<comevalue<<std::endl;
+#define VLOG_IF_S(verbose, cond)																						\
+  (SCOPE_LOGGER_CORE::verbose > SCOPE_LOGGER_CORE_CONFIG::current_verbosity_cutoff()									\
+			 || (cond)==false) ? (void)0																				\
+			 :SCOPE_LOGGER_CORE::voidify() & SCOPE_LOGGER_CORE::loggerMsg(SCOPE_LOGGER_CORE::verbose, __FILE__, __LINE__)
+#define LOG_IF_S(verbose_name, cond) VLOG_IF_S(Verbose_##verbose_name, cond)
+#define VLOG_S(verbose) VLOG_IF_S(verbose, true)
+#define LOG_S(verbose_name) VLOG_S(Verbose_##verbose_name)
+
+/// usage: ABORT_S()<<"error:"<<msg;
+#define ABORT_S() SCOPE_LOGGER_CORE::loggerMsg("Abort: ", __FILE__, __LINE__)
+
+#define CHECK_WITH_INFO_S(cond, info)\
+    LOGGER_IS_TRUE((cond)==true)?(void)0\
+	:SCOPE_LOGGER_CORE::voidify() & SCOPE_LOGGER_CORE::loggerMsg("Check failed: " info " ", __FILE__, __LINE__)
+#define CHECK_S(cond) CHECK_WITH_INFO_S(cond, #cond)
+#define CHECK_NOTNULL_S(x) CHECK_WITH_INFO_S((x) != nullptr, #x" != nullptr")
+
+#define CHECK_OP_S(func_name, expr1,op,expr2)					 \
+    while(auto errStr = func_name(#expr1 " " #op " " #expr2, expr1, #op, expr2)) \
+        SCOPE_LOGGER_CORE::loggerMsg(errStr->c_str(), __FILE__, __LINE__)
+
+#define CHECK_EQ_S(A,B) CHECK_OP_S(CHECK_EQ_IMPL,A,==,B)
+#define CHECK_NE_S(A,B) CHECK_OP_S(CHECK_NE_IMPL,A,!=,B)
+#define CHECK_LE_S(A,B) CHECK_OP_S(CHECK_LE_IMPL,A,<=,B)
+#define CHECK_LT_S(A,B) CHECK_OP_S(CHECK_LT_IMPL,A,<,B)
+#define CHECK_GE_S(A,B) CHECK_OP_S(CHECK_GE_IMPL,A,>=,B)
+#define CHECK_GT_S(A,B) CHECK_OP_S(CHECK_GT_IMPL,A,>,B)
+
+}  // namespace non-name
+
+#if LOGGER_SHUTDOWN
+	#undef ENABLE_DEBUG // turn to release mode.
+#endif
 
 
-LOGGER_CHECK_SYMBOL_WARP(CHECK_EQ_IMPL, ==)
-LOGGER_CHECK_SYMBOL_WARP(CHECK_LE_IMPL, <=)
-LOGGER_CHECK_SYMBOL_WARP(CHECK_GE_IMPL, >=)
-LOGGER_CHECK_SYMBOL_WARP(CHECK_NE_IMPL, !=)
-LOGGER_CHECK_SYMBOL_WARP(CHECK_LT_IMPL, <)
-LOGGER_CHECK_SYMBOL_WARP(CHECK_GT_IMPL, >)
-
-//#undef LOGGER_CHECK_SYMBOL_WARP
-
-#define LOGGER_VLOG_IF(verbose, cond)                                                   	\
-                 (::logger::verbose > ::logger::utils::sys::get_max_logger_verbose_level()  \
-                 || (cond)==false) ? (void)0                                            	\
-                 : ::logger::core::voidify() & ::logger::core::LoggerMsg<logger::verbose>(__FILE__, __LINE__)
-
-#define LOGGER_LOG_IF(verbose_name, cond) LOGGER_VLOG_IF(Verbose_##verbose_name, cond)
-#define LOGGER_VLOG(verbose) LOGGER_LOG_IF(verbose, true)
-#define LOGGER_LOG(verbose) LOGGER_VLOG(verbose)
-
-#define LOGGER_CHECK_WITH_INFO(cond, info)                          \
-                 LOGGER_IS_TRUE((cond)==true) ? (void)0             \
-                 : ::logger::core::voidify() &                        \
-                 ::logger::core::LoggerMsg<::logger::Verbose_FATAL>(    \
-                         "Check failed: " info " ", __FILE__, __LINE__)
-
-#define LOGGER_CHECK(cond) LOGGER_CHECK_WITH_INFO(cond, #cond)
-#define LOGGER_CHECK_NOTNULL(x) LOGGER_CHECK_WITH_INFO((x) != nullptr, #x" != nullptr")
-
-#define LOGGER_CHECK_OP(func_name, expr1, op, expr2)                            \
-    while(auto errStr = func_name(#expr1 " " #op " " #expr2, expr1, #op, expr2))  \
-                 ::logger::core::LoggerMsg<::logger::Verbose_FATAL>(errStr->c_str(), __FILE__, __LINE__)
-
-#define LOGGER_CHECK_EQ(A, B) LOGGER_CHECK_OP(CHECK_EQ_IMPL, A, ==, B)
-#define LOGGER_CHECK_NE(A, B) LOGGER_CHECK_OP(CHECK_NE_IMPL, A, !=, B)
-#define LOGGER_CHECK_LE(A, B) LOGGER_CHECK_OP(CHECK_LE_IMPL, A, <=, B)
-#define LOGGER_CHECK_LT(A, B) LOGGER_CHECK_OP(CHECK_LT_IMPL, A,  <, B)
-#define LOGGER_CHECK_GE(A, B) LOGGER_CHECK_OP(CHECK_GE_IMPL, A, >=, B)
-#define LOGGER_CHECK_GT(A, B) LOGGER_CHECK_OP(CHECK_GT_IMPL, A,  >, B)
-
-} /* namespace anonymous */
-
-#ifdef USE_LOGGER
-    #ifdef LOGGER_SHUTDOWN
-        #define VLOG_IF(verbose, cond)       LOGGER_LOG_IF(verbose, false)
-        #define LOG_IF(verbose, cond)        LOGGER_LOG_IF(verbose, false)
-        #define VLOG(verbose)                LOGGER_LOG_IF(verbose,false)
-        #define LOG(verbose)                 LOGGER_LOG_IF(verbose,false)
-        #define CHECK(cond)                  LOGGER_CHECK(true)
-        #define CHECK_NOTNULL(x)             LOGGER_CHECK(true)
-        #define CHECK_EQ(a, b)               LOGGER_CHECK(true) 
-        #define CHECK_NE(a, b)               LOGGER_CHECK(true) 
-        #define CHECK_LT(a, b)               LOGGER_CHECK(true) 
-        #define CHECK_LE(a, b)               LOGGER_CHECK(true) 
-        #define CHECK_GT(a, b)               LOGGER_CHECK(true) 
-        #define CHECK_GE(a, b)               LOGGER_CHECK(true) 
-        #define DVLOG_IF(verbose, cond)      LOGGER_LOG_IF(verbose, false)
-        #define DLOG_IF(verbose, cond)       LOGGER_LOG_IF(verbose, false)
-        #define DVLOG(verbose)               DVLOG_IF(verbose,false)
-        #define DLOG(verbose)                DLOG_IF(verbose,false)
-        #define DCHECK(cond)                 LOGGER_CHECK(true)
-        #define DCHECK_NOTNULL(x)            LOGGER_CHECK(true)
-        #define DCHECK_EQ(a, b)              LOGGER_CHECK(true)
-        #define DCHECK_NE(a, b)              LOGGER_CHECK(true)
-        #define DCHECK_LT(a, b)              LOGGER_CHECK(true)
-        #define DCHECK_LE(a, b)              LOGGER_CHECK(true)
-        #define DCHECK_GT(a, b)              LOGGER_CHECK(true)
-        #define DCHECK_GE(a, b)              LOGGER_CHECK(true)
-
-    #else
-        #define VLOG_IF(verbose, cond)       LOGGER_LOG_IF(verbose, cond)
-        #define LOG_IF(verbose, cond)        LOGGER_LOG_IF(verbose, cond)
-        #define VLOG(verbose)                LOGGER_LOG_IF(verbose, true)
-        #define LOG(verbose)                 LOGGER_LOG_IF(verbose, true)
-        #define CHECK(cond)                  LOGGER_CHECK(cond)
-        #define CHECK_NOTNULL(x)             LOGGER_CHECK(x!=nullptr)
-        #define CHECK_EQ(a, b)               LOGGER_CHECK_EQ(a, b)
-        #define CHECK_NE(a, b)               LOGGER_CHECK_NE(a, b)
-        #define CHECK_LT(a, b)               LOGGER_CHECK_LT(a, b)
-        #define CHECK_LE(a, b)               LOGGER_CHECK_LE(a, b)
-        #define CHECK_GT(a, b)               LOGGER_CHECK_GT(a, b)
-        #define CHECK_GE(a, b)               LOGGER_CHECK_GE(a, b)
-
-        #ifdef ENABLE_DEBUG
-            #define DVLOG_IF(verbose, cond)       LOGGER_LOG_IF(verbose, cond)
-            #define DLOG_IF(verbose, cond)        LOGGER_LOG_IF(verbose, cond)
-            #define DVLOG(verbose)                LOGGER_VLOG(verbose)
-            #define DLOG(verbose)                 LOGGER_LOG(verbose)
-            #define DCHECK(cond)                  LOGGER_CHECK(cond)
-            #define DCHECK_NOTNULL(x)             LOGGER_CHECK_NOTNULL(x)
-            #define DCHECK_EQ(a, b)               LOGGER_CHECK_EQ(a, b)
-            #define DCHECK_NE(a, b)               LOGGER_CHECK_NE(a, b)
-            #define DCHECK_LT(a, b)               LOGGER_CHECK_LT(a, b)
-            #define DCHECK_LE(a, b)               LOGGER_CHECK_LE(a, b)
-            #define DCHECK_GT(a, b)               LOGGER_CHECK_GT(a, b)
-            #define DCHECK_GE(a, b)               LOGGER_CHECK_GE(a, b)
-        #else
-            #define DVLOG_IF(verbose, cond)       LOGGER_LOG_IF(verbose, false)
-            #define DLOG_IF(verbose, cond)        LOGGER_LOG_IF(verbose, false)
-            #define DVLOG(verbose)                DVLOG_IF(verbose,false)
-            #define DLOG(verbose)                 DLOG_IF(verbose,false)
-            #define DCHECK(cond)                  LOGGER_CHECK(true)
-            #define DCHECK_NOTNULL(x)             LOGGER_CHECK(true)
-            #define DCHECK_EQ(a, b)               LOGGER_CHECK(true)
-            #define DCHECK_NE(a, b)               LOGGER_CHECK(true)
-            #define DCHECK_LT(a, b)               LOGGER_CHECK(true)
-            #define DCHECK_LE(a, b)               LOGGER_CHECK(true)
-            #define DCHECK_GT(a, b)               LOGGER_CHECK(true)
-            #define DCHECK_GE(a, b)               LOGGER_CHECK(true)
-        #endif
-
-    #endif  // LOGGER_SHUTDOWN end
-
-#else // use glog instead
+#ifdef  ENABLE_DEBUG
+#define DVLOG_IF_S(verbose, cond)     	VLOG_IF_S(verbose, cond)
+#define DLOG_IF_S(verbose_name, cond) 	LOG_IF_S(verbose_name, cond)
+#define DVLOG_S(verbose)              	VLOG_S(verbose)
+#define DLOG_S(verbose_name)          	LOG_S(verbose_name)
+#define DCHECK_S(cond)                  CHECK_S(cond)
+#define DCHECK_NOTNULL_S(x)             CHECK_NOTNULL_S(x)
+#define DCHECK_EQ_S(a, b)               CHECK_EQ_S(a, b)
+#define DCHECK_NE_S(a, b)               CHECK_NE_S(a, b)
+#define DCHECK_LT_S(a, b)               CHECK_LT_S(a, b)
+#define DCHECK_LE_S(a, b)               CHECK_LE_S(a, b)
+#define DCHECK_GT_S(a, b)               CHECK_GT_S(a, b)
+#define DCHECK_GE_S(a, b)               CHECK_GE_S(a, b)
+#else //BUILD_RELEASE
+// log nothing
+#define DVLOG_IF_S(verbose, cond)     VLOG_IF_S(verbose, false)
+#define DLOG_IF_S(verbose_name, cond) DVLOG_IF_S(Verbose_##verbose_name, cond)
+#define DVLOG_S(verbose)              DVLOG_IF_S(verbose,false)
+#define DLOG_S(verbose_name)          DVLOG_S(Verbose_##verbose_name)
+#define DCHECK_S(cond)                CHECK_S(true || (cond) == true)
+#define DCHECK_NOTNULL_S(x)           CHECK_S(true || (x) != nullptr)
+#define DCHECK_EQ_S(a, b)             CHECK_S(true || (a) == (b))
+#define DCHECK_NE_S(a, b)             CHECK_S(true || (a) != (b))
+#define DCHECK_LT_S(a, b)             CHECK_S(true || (a) < (b))
+#define DCHECK_LE_S(a, b)             CHECK_S(true || (a) <= (b))
+#define DCHECK_GT_S(a, b)             CHECK_S(true || (a) > (b))
+#define DCHECK_GE_S(a, b)             CHECK_S(true || (a) >= (b))
+#endif
 
-#undef VLOG_IF
-#undef LOG_IF
-#undef VLOG
+
+// use local simple logger instead
+#ifndef USE_GLOG
 #undef LOG
+#undef VLOG
+#undef LOG_IF
+#undef VLOG_IF
 #undef CHECK
 #undef CHECK_NOTNULL
 #undef CHECK_EQ
@@ -176,22 +147,63 @@ LOGGER_CHECK_SYMBOL_WARP(CHECK_GT_IMPL, >)
 #undef CHECK_LE
 #undef CHECK_GT
 #undef CHECK_GE
-
-#undef DVLOG_IF
-#undef DLOG_IF
-#undef DVLOG
 #undef DLOG
+#undef DVLOG
+#undef DLOG_IF
+#undef DVLOG_IF
 #undef DCHECK
 #undef DCHECK_NOTNULL
-#undef DCHECK_EQ              
-#undef DCHECK_NE              
-#undef DCHECK_LT              
-#undef DCHECK_LE              
-#undef DCHECK_GT              
-#undef DCHECK_GE              
+#undef DCHECK_EQ
+#undef DCHECK_NE
+#undef DCHECK_LT
+#undef DCHECK_LE
+#undef DCHECK_GT
+#undef DCHECK_GE
+#undef VLOG_IS_ON
+
+#if LOGGER_SHUTDOWN // if  LOGGER_SHUTDOWN , turn to release mode.
+#define LOG            DLOG_S
+#define VLOG           DLOG_S
+#define LOG_IF         DLOG_IF_S
+#define VLOG_IF        DVLOG_IF_S
+#define CHECK(cond)    DCHECK_S((cond))
+#define CHECK_NOTNULL  DCHECK_NOTNULL_S
+#define CHECK_EQ       DCHECK_EQ_S
+#define CHECK_NE       DCHECK_NE_S
+#define CHECK_LT       DCHECK_LT_S
+#define CHECK_LE       DCHECK_LE_S
+#define CHECK_GT       DCHECK_GT_S
+#define CHECK_GE       DCHECK_GE_S
+#else
+#define LOG            LOG_S
+#define VLOG           LOG_S
+#define LOG_IF         LOG_IF_S
+#define VLOG_IF        VLOG_IF_S
+#define CHECK(cond)    CHECK_S((cond))
+#define CHECK_NOTNULL  CHECK_NOTNULL_S
+#define CHECK_EQ       CHECK_EQ_S
+#define CHECK_NE       CHECK_NE_S
+#define CHECK_LT       CHECK_LT_S
+#define CHECK_LE       CHECK_LE_S
+#define CHECK_GT       CHECK_GT_S
+#define CHECK_GE       CHECK_GE_S
+#endif
 
+#define DLOG           DLOG_S
+#define DVLOG          DVLOG_S
+#define DLOG_IF        DLOG_IF_S
+#define DVLOG_IF       DVLOG_IF_S
+#define DCHECK         DCHECK_S
+#define DCHECK_NOTNULL DCHECK_NOTNULL_S
+#define DCHECK_EQ      DCHECK_EQ_S
+#define DCHECK_NE      DCHECK_NE_S
+#define DCHECK_LT      DCHECK_LT_S
+#define DCHECK_LE      DCHECK_LE_S
+#define DCHECK_GT      DCHECK_GT_S
+#define DCHECK_GE      DCHECK_GE_S
+#define VLOG_IS_ON(verbose) ((verbose) <= SCOPE_LOGGER_CORE_CONFIG::current_verbosity_cutoff())
 #endif
 
 
 
-#endif // LOGGER_H end
+#endif // LOGGER_H
diff --git a/utils/logger/logger_core.h b/utils/logger/logger_core.h
index 87d15ac..0e8ec45 100644
--- a/utils/logger/logger_core.h
+++ b/utils/logger/logger_core.h
@@ -1,8 +1,10 @@
 /* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
-       http://www.apache.org/licenses/LICENSE-2.0
+
+   http://www.apache.org/licenses/LICENSE-2.0
    
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
@@ -10,194 +12,1169 @@
    See the License for the specific language governing permissions and
    limitations under the License. 
 */
-#ifndef ANAKIN_LOGGER_CORE_H
-#define ANAKIN_LOGGER_CORE_H
 
-#include "logger_utils.h"
+#ifndef LOGGER_CORE_H
+#define LOGGER_CORE_H
+#include "log_utils.h"
 
 namespace logger {
 
-namespace core {
+namespace  core {
+
+using namespace std::chrono;
+#if defined(__clang__) || defined(__GNUC__)
+/// @brief check the printf var format
+/// @param formatArgs  format args list e.g. 1,2,3,... formatArgs+1
+/// @param firstArg  first format args list, 1 or 2 or ...
+#define LOGGER_CHECK_PRINTF(formatArgs,firstArg)  __attribute__((__format__ (__printf__, formatArgs, firstArg)))
+#else
+#define LOGGER_CHECK_PRINTF(formatArgs,firstArg)
+#endif
+//#define LOGGER_NORET __attribute__((noreturn))
+#define LOGGER_NORET
+
+
+/// judge x if false or true
+#define LOGGER_IS_FALSE(x) (__builtin_expect(x,0))
+#define LOGGER_IS_TRUE(x)  (__builtin_expect(!!(x),1))
+
+/// __PRETTY_FUNCTION__ (c++)return the type signature of the function as well as its bare name.
+#define LOGGER_PRETTY_FUNC  __PRETTY_FUNCTION__
 
 /**
- *  \brief logger init func
+ *  @brief  text class: hold char* type
  *
  */
-inline void initial(const char* argv0){ 
-    utils::sys::init(); 
-    utils::sys::set_max_logger_verbose_level(Verbose_Max);
-    // get host and user info.  
-    utils::sys::get_username(); 
-    utils::sys::get_program_name(argv0); 
-    utils::sys::get_hostname(); 
-#if LOGGER_TLS_NAMES 
-    utils::sys::set_thread_name("main_thread"); // set main thread name = "main_thread" 
-#endif 
-    // log to file
-    utils::sys::add_sys_log_file("./log"); 
-    utils::sys::set_file_barrier_size_in_GB(10);
-
-    
-    utils::sys::install_logger_signal_handlers();
-    utils::sys::file_flush_all();
-}
+class text {
+public:
+    explicit text(char* str): str_(str) {}
+    ~text() {
+        free(str_);
+    }
+
+    text(text&& another) {
+        str_ = another.str_;
+        another.str_ = nullptr;
+    }
+
+    text(text&) = delete;
+    text& operator =(text& a) = delete;
+
+    const char* c_str() const {
+        return str_;
+    }
+    bool empty() const {
+        return str_ == nullptr || *str_ == '\0';
+    }
+
+    char* pop() {
+        auto result = str_;
+        str_ = nullptr;
+        return result;
+    }
+private:
+    char* str_;
+};
+/**
+ *  @brief  basic message struct
+ *
+ */
+struct Message {
+    VerBoseType   verbose;   // Already part of preamble
+    const char* filename;    // Already part of preamble
+    unsigned    line;        // Already part of preamble
+    const char* preamble;    // Date, time, uptime, thread, file:line, verbose.
+    const char* prefix;      // Assertion failure info goes here (or "").
+    const char* message;     // User message goes here.
+};
 
 /**
- * \brief dispatch message class
+ *  @brief  basic message struct
+ *
  */
-template<VerBoseType Verbose>
-class LoggerDispatchMsg {
+class ErrContext {
 public:
-    void operator()(const char* expression, const char* file, unsigned line, const char* msg) {
-        log_msg_dispatch(expression, file, line, msg);
+    ErrContext(const char* file, unsigned line, const char* descr)
+        : file_(file), line_(line), descr_(descr) {
+        ErrContext*& head = LoggerConfig::pthreadErrCtPtr;
+        previous_ = head;
+        head = this;   ///< add head in construction
     }
+    ~ErrContext() {
+        LoggerConfig::pthreadErrCtPtr = previous_;    ///< remove head
+    }
+    /// desable assign and copy (lvalue && rvalue)
+    ErrContext(const ErrContext&) = delete;
+    ErrContext(ErrContext&&) = delete;
+    ErrContext& operator=(const ErrContext&) = delete;
+    ErrContext& operator=(ErrContext&&) = delete;
 
-private:
-    /// compose the target log msg with non-Fatal log
-    /// note: 
-    ///    this api can accept c-format(printf) input msg
-    inline void log_msg_dispatch(const char* expr, 
-								 const char* file, 
-								 unsigned line, 
-								 const char* msg) {
-		char header[128];
-        utils::sys::add_log_header<Verbose>(header, sizeof(header), file, line);
-		send_msg(false, expr, header, msg, DevType<__ERR>());
-		send_msg(false, expr, header, msg, DevType<__FILE>());
-    }
-
-	inline void send_msg(bool exception, const char* expr, const char* header, const char* msg, DevType<__ERR>) {
-  		std::lock_guard<std::recursive_mutex> lock(utils::SYSResource::Global().mut);
-  		if (Verbose <= utils::sys::get_max_logger_verbose_level()) {
-  		    if (utils::sys::colorful_shell_access()) {
-  		        if (Verbose > Verbose_WARNING) {
-  		            fprintf(stderr, "%s%s%s%s%s%s%s%s%s\n",
-  		                    Color<RESET>::str,
-  		                    Color<DIM>::str,
-  		                    header,
-  		                    Color<RESET>::str,
-  		                    Color<BOLD>::str,
-  		                    Verbose == Verbose_INFO ? Color<BOLD>::str : Color<LIGHT_GRAY>::str,
-  		                    expr,
-  		                    msg,
-  		                    Color<RESET>::str);
-  		        } else {
-  		          fprintf(stderr, "%s%s%s%s%s%s%s\n",
-  		                  Color<RESET>::str,
-  		                  Color<BOLD>::str,
-  		                  Verbose == Verbose_WARNING ? Color<YELLOW>::str : \
-                          (Verbose == Verbose_FATAL ? Color<BOLD_RED>::str : Color<RED>::str),
-  		                  header,
-  		                  expr,
-  		                  msg,
-  		                  Color<RESET>::str);
-  		        }
-  		    } else {
-  		        fprintf(stderr, "%s%s%s\n", header, expr, msg);
-  		    }
-
-            // here use file flush to flush everything
-            //fflush(stderr);
-            utils::sys::file_flush_all();
-  		} // if Verbose <= LoggerConfig::currentVerbos	
-
-		if (exception) {
-    		_stack_trace_inf = utils::sys::stack_trace(5); 
-    		if (!_stack_trace_inf.empty()) {
-    	    	if (utils::sys::colorful_shell_access()) {
-    	        	fprintf(stderr," %s%s%s >>>>> Fatal error: stack trace: <<<<<< \n %s \n %s\n",
-    	                    Color<RESET>::str,
-    	                    Color<BOLD>::str,
-    	                    Color<GREEN>::str,
-    	                    _stack_trace_inf.c_str(),
-    	                    Color<RESET>::str);
-    	    	} else {
-    	        	fprintf(stderr,"  >>>>> Fatal error: stack trace: <<<<<< \n %s \n", _stack_trace_inf.c_str());
-    	    	}
-    	    	fflush(stderr);
-    		}
-		}
-	}
-
-	inline void send_msg(bool exception, const char* expr, const char* header, const char* msg, DevType<__FILE>) {
-        utils::sys::write_file_log(Verbose, expr, header, msg);
-
-  		if (exception) {
-            utils::sys::write_file_log(Verbose, " >>>>> Fatal error: stack trace: <<<<< \n ", "", _stack_trace_inf.c_str());
-            utils::sys::file_flush_target(Verbose);
-
-    		if (exception) {
- #if LOGGER_CATCH_SIGABRT && !defined(_WIN32) 
-                // Make sure we don't catch our own abort: 
-                signal(SIGABRT, SIG_DFL);
- #endif
-      			abort();
-    		}
-  		}
-	}
+    ErrContext* previous() const {
+        return previous_;
+    }
+public:
+    const char* file_;
+    unsigned    line_;
+    const char* descr_;
+    ErrContext* previous_;
+};
+/// used for callback
+typedef void (*log_handler_t)(void* user_data, const Message& message);
+typedef void (*close_handler_t)(void* user_data);
+typedef void (*flush_handler_t)(void* user_data);
 
-private:
-    std::string _stack_trace_inf{""};
+/**
+ *  @brief  basic callback struct
+ *
+ */
+class Callback {
+public:
+    ~Callback() {
+        //close(user_data);
+    }
+    std::string     id;
+    log_handler_t   callback;
+    void*           user_data;
+    VerBoseType     verbose; // not change!
+    close_handler_t close;
+    flush_handler_t flush;
+};
+/// \brief the signal to set the signal handler to.
+///
+/// It can be an implementation-defined value or one of the following values:
+/// SIGABRT
+/// SIGFPE
+/// SIGILL
+/// SIGINT
+/// SIGSEGV
+/// SIGTERM
+struct SignalOwn {
+    int sigNum;
+    const char* sigName;
 };
 
-template<>
-inline void LoggerDispatchMsg<Verbose_FATAL>::log_msg_dispatch(const char* expr, 
-															   const char* file, 
-															   unsigned line, 
-															   const char* msg) {
-	char header[128]; 
-    utils::sys::add_log_header<Verbose_FATAL>(header, sizeof(header), file, line);
-	send_msg(true, expr, header, msg, DevType<__ERR>());
-	send_msg(true, expr, header, msg, DevType<__FILE>());
-}
+// those signal causes the process to terminate.
+static const SignalOwn LOCAL_SIGS[] = {
+#if LOGGER_CATCH_SIGABRT
+    { SIGABRT, "SIGABRT" }, // The SIGABRT signal is sent to a process to tell it to abort( abort().), also can be signal from others.
+#endif
+    { SIGBUS,  "SIGBUS"  }, // incorrect memory access alignment or non-existent physical address
+    { SIGFPE,  "SIGFPE"  }, // (floating-point exception) erroneous arithmetic operation, such as division by zero.
+    { SIGILL,  "SIGILL"  }, // illegal instruction
+    { SIGINT,  "SIGINT"  }, // Terminal interrupt signal.
+    { SIGSEGV, "SIGSEGV" }, // Invalid memory reference.
+    { SIGTERM, "SIGTERM" }, // Termination signal.
+    { SIGPIPE, "SIGPIPE" }, // Write on a pipe with no one to read it.
+};
 
+/**
+ *  @brief  func register
+ *
+ */
+namespace funcRegister {
+/****************************************************************************/
+/*                            logger init                                   */
+/***************t************************************************************/
+void initial(const char* argv0);
+/****************************************************************************/
+/*                            function register                             */
+/***************t************************************************************/
+inline const char* black();
+inline const char* red();
+inline const char* green();
+inline const char* yellow();
+inline const char* blue();
+inline const char* purple();
+inline const char* cyan();
+inline const char* light_gray();
+inline const char* white();
+inline const char* light_red();
+inline const char* dim();
+// msg format
+inline const char* bold();
+inline const char* underline();
+inline const char* blink();
+// colorful terminal should end whit reset!
+inline const char* reset();
 
+/****************************************************************************/
+/*                            log file manipulate                           */
+/***************t************************************************************/
+void get_username();
+void get_program_name(const char* argv0);
+void get_hostname();
+void flush_callback();
+void on_callback_change();
+bool remove_callback(const char* id);
+void add_callback(const char* id,
+                  log_handler_t callback,
+                  void* user_data,
+                  VerBoseType verbose,
+                  close_handler_t on_close,
+                  flush_handler_t on_flush);
+void add_sys_log_file(std::string log_dir);
+bool logger_to_file(const char* path, FileMode fileMode, VerBoseType verbose);
+void file_log(void* user_data, const Message& message);
+void file_close(void* user_data);
+void file_flush(void* user_data);
+const char* filename(const char* path);
+
+/****************************************************************************/
+/*                            error context manipulate                      */
+/***************t************************************************************/
+text get_error_context();
+text get_error_context_for(const ErrContext* head);
+/****************************************************************************/
+/*                            stack tracing manipulate                      */
+/***************t************************************************************/
+void do_replacements(const PairList& replacements, std::string& str);
+std::string set_friendly_stacktrace(const std::string& input);
+std::string stacktrace_as_stdstring(int skip);
+text stacktrace(int skip);
+/****************************************************************************/
+/*                            multi pthread manipulate                      */
+/***************t************************************************************/
+void set_thread_name(const char* name);
+void get_thread_name(char* buffer, unsigned long long length, bool right_align_hext_id);
+/****************************************************************************/
+/*                            log stderr manipulate                         */
+/****************************************************************************/
+void print_preamble(char* out_buff, size_t out_buff_size, VerBoseType    verbose, const char* file,
+                    unsigned line);
+void log_message(int stack_trace_skip, Message& message, bool abort_if_fatal);
+void log_to_all(int            stack_trace_skip,
+                VerBoseType    verbose,
+                const char*    file,
+                unsigned       line,
+                const char*    prefix,
+                const char*    buff);
+text vtextprintf(const char* format, va_list vlist);
+/// attribute fmtArg check shuld +1 when used in class(skip the "this" point)
+/// but for class , static members is the same as non-members,record as below:
+/// + non-member functions work with 1,2
+/// + static member functions work with 1,2
+/// + non-static member functions treat 'this' as #1, so need 2,3
+text textprintf(const char* format, ...) LOGGER_CHECK_PRINTF(1, 2);
+void log(VerBoseType verbose, const char* file, unsigned line, const char* format,
+         ...) LOGGER_CHECK_PRINTF(4, 5);
+LOGGER_NORET void log_and_abort(int stack_trace_skip, const char* expr, const char* file,
+                                unsigned line, const char* format, ...) LOGGER_CHECK_PRINTF(5, 6);
+/****************************************************************************/
+/*                             signal manipulate                            */
+/****************************************************************************/
+void write_to_stderr(const char* data, size_t size);
+void write_to_stderr(const char* data);
+void call_default_signal_handler(int signal_number);
+void logger_signal_handler(int signal_number, siginfo_t*, void*);
+void install_logger_signal_handlers();
+}
 /**
- * \brief logger central class
+ *  @brief  logger class
+ *
  */
-template<VerBoseType Verbose>
-class LoggerMsg {
+class loggerMsg {
 public:
-    LoggerMsg(const char* file, unsigned line)
-        :_file(file), _line(line) {}
-    LoggerMsg(const char* expression, const char* file, unsigned line)
-        :_expression(expression), _file(file), _line(line) {}
+    loggerMsg(VerBoseType verbose, const char* file, unsigned line)
+        : verbose_(verbose), file_(file), line_(line), isAbort_(false) {}
 
-    ~LoggerMsg() {
-        const char* msg = std::string(_msg.str()).c_str();
-        this->_dispatch(_expression.c_str(), _file.c_str(), _line, msg);
-    }
+    loggerMsg(const char* expression, const char* file, unsigned line)
+        : expression_(expression), file_(file), line_(line), isAbort_(true) {}
+    ~loggerMsg();
 
-    template<typename T> 
-    LoggerMsg& operator<<(const T& var) {
-        _msg << var;
+    template<typename T>
+    loggerMsg& operator<<(const T& var) {
+        ss_ << var;
         return *this;
     }
-
-    /// access for std::endl and other std io
-    LoggerMsg& operator<<(std::ostream&(*func)(std::ostream&)) {
-        func(_msg);
+    // access for std::endl and other io
+    loggerMsg& operator<<(std::ostream & (*func)(std::ostream&)) {
+        func(ss_);
         return *this;
     }
-
 private:
-    std::string _expression;
-    std::string _file;
-    unsigned _line;
-    std::ostringstream _msg;
-    LoggerDispatchMsg<Verbose> _dispatch;
+    bool isAbort_;
+    VerBoseType verbose_;
+    const char* expression_;
+    const char* file_;
+    unsigned    line_;
+    std::ostringstream ss_;
 };
-
-/// turn class LoggerMsg instance into void function, it's a little trick.
-class voidify { 
-public: 
-    voidify(){} 
-    template<VerBoseType Verbose>
-    void operator&(const LoggerMsg<Verbose>&){} 
+/**
+ * @brief voidify the class such as logger for macro defines
+ *
+ * usage: voidify()(loggerMsg(...)).
+ */
+class voidify {
+public:
+    voidify() {}
+    void operator&(const loggerMsg&) {}
 };
 
-} /* namespace core */
+using CallbackVec = std::vector<Callback>;
+using StrPair     = std::pair<std::string, std::string>;
+using StrPairList = std::vector<StrPair>;
+
+#define INNER_LOG(verbose,...)                                           \
+        ((verbose) > LoggerConfig::current_verbosity_cutoff()) ? (void)0       \
+                : funcRegister::log(verbose, __FILE__, __LINE__, __VA_ARGS__)
+#define IN_LOG(verbose_name, ...) INNER_LOG(Verbose_##verbose_name, __VA_ARGS__)
+
+} // namespace core
+
+}  // namespace logger
+
+namespace logger {
+
+namespace core {
+
+namespace funcRegister {
+
+inline const char* black()      {
+    return LoggerConfig::terminalSupportColor ? "\e[30m" : "";
+}
+inline const char* red()        {
+    return LoggerConfig::terminalSupportColor ? "\e[31m" : "";
+}
+inline const char* b_red()  {
+    return LoggerConfig::terminalSupportColor ? "\e[41m" : "";
+}
+inline const char* green()      {
+    return LoggerConfig::terminalSupportColor ? "\e[32m" : "";
+}
+inline const char* yellow()     {
+    return LoggerConfig::terminalSupportColor ? "\e[33m" : "";
+}
+inline const char* blue()       {
+    return LoggerConfig::terminalSupportColor ? "\e[34m" : "";
+}
+inline const char* purple()     {
+    return LoggerConfig::terminalSupportColor ? "\e[35m" : "";
+}
+inline const char* cyan()       {
+    return LoggerConfig::terminalSupportColor ? "\e[36m" : "";
+}
+inline const char* light_gray() {
+    return LoggerConfig::terminalSupportColor ? "\e[37m" : "";
+}
+inline const char* white()      {
+    return LoggerConfig::terminalSupportColor ? "\e[37m" : "";
+}
+inline const char* light_red()  {
+    return LoggerConfig::terminalSupportColor ? "\e[91m" : "";
+}
+inline const char* dim()        {
+    return LoggerConfig::terminalSupportColor ? "\e[2m"  : "";
+}
+inline const char* bold()       {
+    return LoggerConfig::terminalSupportColor ? "\e[1m" : "";
+}
+inline const char* underline()  {
+    return LoggerConfig::terminalSupportColor ? "\e[4m" : "";
+}
+inline const char* blink()      {
+    return LoggerConfig::terminalSupportColor ? "\e[5m" : "";
+}
+inline const char* reset()      {
+    return LoggerConfig::terminalSupportColor ? "\e[0m" : "";
+}
+
+inline void get_username() {
+    const char* user = getenv("USER");
+
+    if (user != NULL) {
+        LoggerConfig::userName = user;
+    } else {
+        LoggerConfig::userName = "invalid-user";
+    }
+}
+
+inline void get_program_name(const char* argv0) {
+    const char* slash = strrchr(argv0, '/');
+    LoggerConfig::programName = slash ? slash + 1 : argv0;
+}
+
+inline void get_hostname() {
+#if defined __linux__ || defined __APPLE__
+    struct utsname buf;
+
+    if (0 != uname(&buf)) {
+        // ensure null termination on failure
+        *buf.nodename = '\0';
+    }
+
+    LoggerConfig::hostName = strdup(buf.nodename);
+#else
+# warning There is no way to retrieve the host name(not support os windows).
+    LoggerConfig::hostName = "(unknown)";
+#endif
+}
+
+// @brief same as glog...
+// If no base filename for logs of this severity has been set, use a default base filename of
+// "<program name>.<hostname>.<user name>.log.<severity level>.".  So
+// logfiles will have names like
+// webserver.examplehost.root.log.INFO.19990817-150000.4354 or ....thread_name, where
+// 19990817 is a date (1999 August 17), 150000 is a time (15:00:00),
+// and 4354 is the pid of the logging process or thread_name of the logging thread.
+// The date & time reflect when the file was created for output.
+// Where does the file get put?  Successively try the directories
+// "/tmp", and "." , "/tmp" is default path for logging.
+// add_sys_log_file will be invoked in the end of initial function.
+inline void add_sys_log_file(std::string log_dir = "/tmp") {
+    // default filename
+    std::string filename = "";
+    filename += std::string(LoggerConfig::programName) + ".";
+    filename += std::string(LoggerConfig::hostName) + ".";
+    filename += std::string(LoggerConfig::userName) + ".";
+    filename += "log.";
+    // now we get <program name>.<hostname>.<user name>.log.
+    filename = log_dir + "/" + filename;
+
+    long long ms_since_epoch = duration_cast<milliseconds>
+                               (system_clock::now().time_since_epoch()).count();
+    time_t sec_since_epoch = time_t(ms_since_epoch / 1000);
+    tm time_info;
+    localtime_r(&sec_since_epoch, &time_info);
+
+    char thread_name[LoggerConfig::threadNameWidth + 1] = {0};
+    get_thread_name(thread_name, LoggerConfig::threadNameWidth + 1, true);
+
+    char buff[20 + LoggerConfig::threadNameWidth];
+    int buff_size = sizeof(buff) / sizeof(char);
+    snprintf(buff, buff_size, ".%04d%02d%02d-%02d%02d%02d.%s",
+             1900 + time_info.tm_year, 1 + time_info.tm_mon, time_info.tm_mday,
+             time_info.tm_hour, time_info.tm_min, time_info.tm_sec, thread_name);
+
+    auto get_log_filename = [&](std::string verbose_str) -> const char* {
+        //printf("path :: %s \n ",(filename + verbose_str + std::string(buff)).c_str());  // for debug
+        return strdup((filename + verbose_str + std::string(buff)).c_str());
+    };
+
+    // create the log file with diff verbose
+    logger_to_file(get_log_filename("FATAL"), FileMode::CREATE, VerBoseType::Verbose_FATAL);
+    logger_to_file(get_log_filename("ERROR"), FileMode::CREATE, VerBoseType::Verbose_ERROR);
+    logger_to_file(get_log_filename("WARNING"), FileMode::CREATE, VerBoseType::Verbose_WARNING);
+    logger_to_file(get_log_filename("INFO"), FileMode::CREATE, VerBoseType::Verbose_INFO);
+    //logger_to_file(get_log_filename("Verbose_0"),FileMode::CREATE,VerBoseType::Verbose_0);
+}
+
+inline void flush_callback() {
+    std::lock_guard<std::recursive_mutex> lock(LoggerConfig::callbackMutex);
+    fflush(stderr); // fflush to terminal first
+
+    for (const auto& callback : LoggerConfig::callbackVecs) {
+        if (callback.flush) {
+            callback.flush(callback.user_data);
+        }
+    }
+
+    LoggerConfig::needFlush = false;
+
+}
+
+inline void on_callback_change() {
+    LoggerConfig::currentMaxVerbos = Verbose_OFF; // min verbos value
+
+    for (const auto& callback : LoggerConfig::callbackVecs) {
+        LoggerConfig::currentMaxVerbos = std::max(LoggerConfig::currentMaxVerbos, callback.verbose);
+    }
+}
+
+inline bool remove_callback(const char* id) {
+    std::lock_guard<std::recursive_mutex> lock(LoggerConfig::callbackMutex);
+    auto it = std::find_if(begin(LoggerConfig::callbackVecs),
+    end(LoggerConfig::callbackVecs), [&](const Callback & c) {
+        return c.id == id;
+    });
+
+    if (it != LoggerConfig::callbackVecs.end()) {
+        if (it->close) {
+            it->close(it->user_data);    // close file ptr
+        }
+
+        LoggerConfig::callbackVecs.erase(it);
+        on_callback_change();
+        return true;
+    } else {
+        IN_LOG(ERROR, "Failed to locate callback with id '%s'\n", id);
+        return false;
+    }
+}
+
+inline void add_callback(const char* id,
+                         log_handler_t callback,
+                         void* user_data,
+                         VerBoseType verbose,
+                         close_handler_t on_close,
+                         flush_handler_t on_flush) {
+    std::lock_guard<std::recursive_mutex> lock(LoggerConfig::callbackMutex);
+    LoggerConfig::callbackVecs.push_back(Callback{id, callback, user_data, verbose, on_close, on_flush});
+    on_callback_change();
+}
+
+inline bool logger_to_file(const char* path, FileMode fileMode, VerBoseType verbose) {
+    char* file_path = strdup(path);
+
+    for (char* p = strchr(file_path + 1, '/'); p != NULL; p = strchr(p + 1, '/')) {
+        *p = '\0';
+        struct stat st;
+
+        if ((stat(file_path, &st) == 0) && (((st.st_mode) & S_IFMT) == S_IFDIR)) {
+            // file_path exists and is a directory. do nothing
+            *p = '/';
+            continue;
+        } else {
+            if (mkdir(file_path, 0755) == -1) {
+                IN_LOG(ERROR, "Failed to ceate the path '%s'\n", file_path);
+                return false;
+            }
+        }
+
+        *p = '/';
+    }
+
+    free(file_path);
+    const char* modeStr = (fileMode == FileMode::CREATE ? "w" : "a");
+    auto file = fopen(path, modeStr);
+
+    if (!file) {
+        IN_LOG(ERROR, "Failed to open '%s'\n", path);
+        return false;
+    }
+
+    // add new callback int to vector static
+    add_callback(path, file_log, file, verbose, file_close, file_flush);
+
+    if (fileMode == FileMode::APPEND) {
+        fprintf(file, "\n\n\n\n\n");
+        fflush(file);
+    }
+
+    fprintf(file, "File verbosity level: %d\n", verbose);
+    auto PREAMBLE_EXPLAIN = textprintf("  v  |     time     |  uptime  | %s | %s:line ] ",
+                                       " thread name/id", "file");
+    fprintf(file, "%s\n", PREAMBLE_EXPLAIN.c_str());
+    fflush(file);
+    IN_LOG(INFO, "Logging to '%s', FileMode: '%s', VerBoseType: %d\n", path, modeStr, verbose);
+    fflush(stderr);
+
+    return true;
+}
+
+inline void file_log(void* user_data, const Message& message) {
+    FILE* file = reinterpret_cast<FILE*>(user_data);
+    fprintf(file, "%s%s%s\n", message.preamble, message.prefix, message.message);
+
+    if (LoggerConfig::flushBufferInMs) {
+        fflush(file);
+    }
+}
+
+inline void file_close(void* user_data) {
+    FILE* file = reinterpret_cast<FILE*>(user_data);
+    fclose(file);
+}
+
+inline void file_flush(void* user_data) {
+    FILE* file = reinterpret_cast<FILE*>(user_data);
+    fflush(file);
+}
+
+inline const char* filename(const char* path) {
+    for (auto ptr = path; *ptr; ++ptr) {
+        if (*ptr == '/' || *ptr == '\\') {
+            path = ptr + 1;
+        }
+    }
+
+    return path;
+}
+
+inline void log(VerBoseType verbose, const char* file, unsigned line, const char* format, ...) {
+    va_list vlist;
+    va_start(vlist, format);
+    auto buff = vtextprintf(format, vlist);
+    log_to_all(2, verbose, file, line, "", buff.c_str());
+    va_end(vlist);
+}
+
+inline void log_and_abort(int stack_trace_skip, const char* expr, const char* file, unsigned line,
+                          const char* format, ...) {
+    va_list vlist;
+    va_start(vlist, format);
+    auto buff = vtextprintf(format, vlist);
+    log_to_all(stack_trace_skip + 1, Verbose_FATAL, file, line, expr,
+               buff.c_str()); // will invoke the abort().
+    va_end(vlist);
+}
+
+inline void log_to_all(int  stack_trace_skip,
+                       VerBoseType    verbose,
+                       const char*    file,
+                       unsigned       line,
+                       const char*    prefix,
+                       const char*    buff) {
+    char preamble_buff[128];
+    print_preamble(preamble_buff, sizeof(preamble_buff), verbose, file, line);
+    auto message = Message{verbose, file, line, preamble_buff, prefix, buff};
+    log_message(stack_trace_skip + 1, message, true);
+}
+
+inline text get_error_context() {
+    return get_error_context_for(LoggerConfig::pthreadErrCtPtr);
+}
+inline text get_error_context_for(const ErrContext* head) {
+    std::vector<const ErrContext*> stack;
+
+    while (head) {
+        stack.push_back(head);
+        head = head->previous_;
+    }
+
+    std::reverse(stack.begin(), stack.end());
+
+    std::string result;
+
+    if (!stack.empty()) {
+        result += "------------------------------------------------\n";
+
+        for (auto entry : stack) {
+            const auto description = std::string(entry->descr_) + ":";
+            auto prefix = textprintf("[ErrorContext] %*s:%-5u %-20s ",
+                                     LoggerConfig::filenNameWidth, filename(entry->file_),
+                                     entry->line_, description.c_str());
+            result += prefix.c_str();
+            //entry->print_value(result); /// ??? meaning??
+            result += "\n";
+        }
+
+        result += "------------------------------------------------";
+    }
+
+    return text(strdup(result.c_str()));
+}
+
+#if STACKTRACES
+inline void do_replacements(const PairList& replacements, std::string& str) {
+    for (auto&& pair : replacements) {
+        if (pair.first.size() <= pair.second.size()) {
+            // On gcc, "type_name<std::string>()" is "std::string"
+            continue;
+        }
+
+        size_t it;
+
+        while ((it = str.find(pair.first)) != std::string::npos) { // find first
+            str.replace(it, pair.first.size(), pair.second);
+        }
+    }
+}
+inline std::string set_friendly_stacktrace(const std::string& input) {
+    std::string output = input;
+
+    //do_replacements(s_user_stack_cleanups, output); // ????? s_user_stack_cleanups
+    do_replacements(replaceList, output);
+
+    try {
+        std::regex std_allocator_re(R"(,\s*std::allocator<[^<>]+>)");
+        output = std::regex_replace(output, std_allocator_re, std::string(""));
+        std::regex template_spaces_re(R"(<\s*([^<> ]+)\s*>)");
+        output = std::regex_replace(output, template_spaces_re, std::string("<$1>"));
+    } catch (std::regex_error&) {/*may throw exception*/}
+
+    return output;
+}
+
+// we use libstdc++'s abi::__cxa_demangle() to set friendly demangled stack trace.
+// Example:
+//
+// | Mangled Name  | abi::__cxa_demangle()
+// |---------------|-----------------------
+// | _Z1fv         | f()
+// | _Z1fi         | f(int)
+// | _Z3foo3bar    | foo(bar)
+// | _Z1fIiEvi     | void f<int>(int)
+// | _ZN1N1fE      | N::f
+// | _ZN3Foo3BarEv | Foo::Bar()
+// | _Zrm1XS_"     | operator%(X, X)
+// | _ZN3FooC1Ev   | Foo::Foo()
+// | _Z1fSs        | f(std::basic_string<char,
+// |               |   std::char_traits<char>,
+// |               |   std::allocator<char> >)
+inline std::string stacktrace_as_stdstring(int skip) {
+    void* callstack[256];
+    const auto max_frames = sizeof(callstack) / sizeof(callstack[0]);
+    int num_frames = backtrace(callstack, max_frames);
+    char** symbols = backtrace_symbols(callstack, num_frames);
+
+    std::string result;
+
+    // reverse the stack trace result
+    for (int i = num_frames - 1; i >= skip; --i) {
+        char buf[1024];
+
+        // @brief typedef struct {
+        //          const char *dli_fname;  /* Pathname of shared object that contains address */
+        //          void       *dli_fbase;  /* Address at which shared object is loaded */
+        //          const char *dli_sname;  /* Name of nearest symbol with address lower than addr */
+        //          void       *dli_saddr;  /* Exact address of symbol named in dli_sname */
+        //         } Dl_info;
+        // If no symbol matching addr could be found, then dli_sname and dli_saddr are set to NULL.
+        // The function dladdr() takes a function pointer and tries to resolve name and file where it is located
+        Dl_info info;
+
+        if (dladdr(callstack[i], &info) && info.dli_sname) {
+            char* demangled = NULL;
+            int status = -1;
+
+            if (info.dli_sname[0] == '_') {
+                demangled = abi::__cxa_demangle(info.dli_sname, 0, 0, &status);
+            }
+
+            int sourcep = 0;
+            char syscmd[1024];
+
+            while (symbols[0][sourcep] != '(' && symbols[0][sourcep] != ' '
+                    && symbols[0][sourcep] != 0) {
+                sourcep++;
+            }
+
+            snprintf(syscmd, sizeof(syscmd), "addr2line -e %.*s %p", sourcep, symbols[0], callstack[i],
+                     sourcep);
+
+            FILE* pf = NULL;
+            char pbuffer[1024] = {0};
+            pf = popen(syscmd, "r");
+
+            if (pf != NULL) {
+                int endIndex = fread(pbuffer, sizeof(pbuffer), 1, pf);;
+                pbuffer[1023] = 0;
+                sourcep=0;
+                while(pbuffer[sourcep]!=0&&pbuffer[sourcep]!='\n')
+                    sourcep++;
+                pbuffer[sourcep]=0;
+                pclose(pf);
+            }
+
+            snprintf(buf, sizeof(buf), " %-3d %*p %s + %zd [%s]\n",
+                     i - skip, int(2 + sizeof(void*) * 2), callstack[i],
+                     status == 0 ? demangled :
+                     info.dli_sname == 0 ? symbols[i] : info.dli_sname,
+                     static_cast<char*>(callstack[i]) - static_cast<char*>(info.dli_saddr),
+                     pbuffer);
+            free(demangled);
+        } else {
+            snprintf(buf, sizeof(buf), "%-3d %*p %s\n", i - skip, int(2 + sizeof(void*) * 2), callstack[i],
+                     symbols[i]);
+        }
+
+        result += buf;
+    }//for
+
+    free(symbols);
+
+    if (num_frames == max_frames) {
+        result = "[logger truncated]\n" + result;
+    }
+
+    if (!result.empty() && result[result.size() - 1] == '\n') {
+        result.resize(result.size() - 1);
+    }
+
+    return set_friendly_stacktrace(result);
+}
+#else //STACKTRACES
+inline void do_replacements(const PairList& replacements, std::string& str) {}
+inline std::string set_friendly_stacktrace(const std::string& input) {
+    return "";
+}
+inline std::string stacktrace_as_stdstring(int) {
+#warning "Logger warning: No stacktraces available on this platform [ DISABLED ]"
+    return "";
+}
+#endif //STACKTRACES
+
+inline text stacktrace(int skip) {
+    auto str = stacktrace_as_stdstring(skip + 1);
+    return text(strdup(str.c_str()));
+}
+
+inline void set_thread_name(const char* name) {
+#ifdef LOGGER_TLS_NAMES
+    LoggerConfig::pthreadKeyName = strdup(
+                                       name);  // name must call free(LoggerConfig::pthreadKeyName) to release the mem in the end
+#else
+#ifdef __APPLE__
+    pthread_setname_np(name);
+#else
+    pthread_setname_np(pthread_self(), name);
+#endif
+#endif
+}
+
+inline void get_thread_name(char* buffer, unsigned long long length, bool right_align_hext_id) {
+    if (length == 0u) {
+        IN_LOG(ERROR, "get_thread_name get 0 length buffer. ");
+    }
+
+    if (buffer == nullptr) {
+        IN_LOG(ERROR, "get_thread_name get nullptr buffer. ");
+    }
+
+#if SUPPORT_PTHREADS
+    auto thread = pthread_self();
+#if LOGGER_TLS_NAMES
+
+    if (const char* name = LoggerConfig::pthreadKeyName) {
+        snprintf(buffer, length, "%s", name);
+    } else {
+        buffer[0] = 0;
+    }
+
+#else
+    pthread_getname_np(thread, buffer, length);
+#endif
+
+    if (buffer[0] == 0) {
+#ifdef __APPLE__
+        uint64_t thread_id;
+        pthread_threadid_np(thread, &thread_id);
+#else
+        uint64_t thread_id = thread;
+#endif
+
+        if (right_align_hext_id) {
+            snprintf(buffer, length, "%*X", length - 1, static_cast<unsigned>(thread_id));
+        } else {
+            snprintf(buffer, length, "%X", static_cast<unsigned>(thread_id));
+        }
+    }
+
+#else // SUPPORT_PTHREADS
+    buffer[0] = 0;
+#endif // SUPPORT_PTHREADS
+}
+
+inline text vtextprintf(const char* format, va_list vlist) {
+    char* buff = nullptr;
+    int result = vasprintf(&buff, format, vlist);
+
+    if (result == -1) {
+        IN_LOG(ERROR, "Bad string format: '%s'\n", format);
+        //fprintf(stderr,"Bad string format: '%s'\n", format);
+        //fflush(stderr);
+    }
+
+    //CHECK_F(result ==-1, "Bad string format: '%s'", format);
+    return text(buff);
+}
+
+inline text textprintf(const char* format, ...) {
+    va_list vlist;
+    va_start(vlist, format);
+    auto result = vtextprintf(format, vlist);
+    va_end(vlist);
+    return result;
+}
+
+inline void print_preamble(char* out_buff,
+                           size_t out_buff_size,
+                           VerBoseType    verbose,
+                           const char* file,
+                           unsigned line) {
+    long long ms_since_epoch = duration_cast<milliseconds>
+                               (system_clock::now().time_since_epoch()).count();
+    time_t sec_since_epoch = time_t(ms_since_epoch / 1000);
+    tm time_info;
+    localtime_r(&sec_since_epoch, &time_info);
+
+    auto uptime_ms = duration_cast<milliseconds>(steady_clock::now() - startTime).count();
+    auto uptime_sec = uptime_ms / 1000.0;
+
+    char thread_name[LoggerConfig::threadNameWidth + 1] = {0};
+    get_thread_name(thread_name, LoggerConfig::threadNameWidth + 1, true);
+
+    if (LoggerConfig::splitFileName) {
+        file = filename(file);
+    }
+
+    char level_buff[6];
+
+    if (verbose <= Verbose_FATAL) {
+        snprintf(level_buff, sizeof(level_buff) - 1, "FTL");
+    } else if (verbose == Verbose_ERROR) {
+        snprintf(level_buff, sizeof(level_buff) - 1, "ERR");
+    } else if (verbose == Verbose_WARNING) {
+        snprintf(level_buff, sizeof(level_buff) - 1, "WAN");
+    } else {
+        snprintf(level_buff, sizeof(level_buff) - 1, "%3d", verbose);
+    }
+
+    snprintf(out_buff, out_buff_size, "%4s| %02d:%02d:%02d.%05lld| %.3fs| %s| %s:%u] ",
+             level_buff,
+             time_info.tm_hour, time_info.tm_min, time_info.tm_sec, ms_since_epoch % 1000,
+             uptime_sec,
+             thread_name,
+             file,
+             line);
+
+    /*snprintf(out_buff, out_buff_size, "%04d-%02d-%02d %02d:%02d:%02d.%05lld (%8.3fs) [%-*s]%*s:%-5u %4s| ",
+             1900 + time_info.tm_year, 1 + time_info.tm_mon, time_info.tm_mday,
+             time_info.tm_hour, time_info.tm_min, time_info.tm_sec, ms_since_epoch % 1000,
+             uptime_sec,
+             LoggerConfig::threadNameWidth, thread_name,
+             LoggerConfig::filenNameWidth,file,
+       line, level_buff);*/
+}
+
+inline void log_message(int stack_trace_skip, Message& message, bool abort_if_fatal) {
+    const auto verbosity = message.verbose;
+    std::lock_guard<std::recursive_mutex> lock(LoggerConfig::rsMutex);
+
+    if (verbosity <= LoggerConfig::currentVerbos) {
+        if (LoggerConfig::colorstderr && LoggerConfig::terminalSupportColor) {
+            if (verbosity > Verbose_WARNING) {
+                fprintf(stderr, "%s%s%s%s%s%s%s%s%s\n",
+                        reset(),
+                        dim(),
+                        message.preamble,
+                        reset(),
+                        bold(),
+                        verbosity == Verbose_INFO ? bold() : light_gray(),
+                        message.prefix,
+                        message.message,
+                        reset());
+            } else {
+                fprintf(stderr, "%s%s%s%s%s%s%s\n",
+                        reset(),
+                        bold(),
+                        verbosity == Verbose_WARNING ? yellow() : (verbosity == Verbose_FATAL ? b_red() : red()),
+                        message.preamble,
+                        message.prefix,
+                        message.message,
+                        reset());
+            }
+        } else {
+            fprintf(stderr, "%s%s%s\n",
+                    message.preamble, message.prefix, message.message);
+        }
+
+        if (LoggerConfig::flushBufferInMs == 0) {
+            fflush(stderr);
+        } else {
+            LoggerConfig::needFlush = true;
+        }
+    } // if verbosity <= LoggerConfig::currentVerbos
+
+    if (verbosity == Verbose_FATAL) {
+        auto st = stacktrace(stack_trace_skip + 2); // friendly message of stack trace
+
+        if (!st.empty()) {
+            if (LoggerConfig::colorstderr && LoggerConfig::terminalSupportColor) {
+                fprintf(stderr, " %s%s%s*** %s fatal error: stack trace: ***\n %s \n %s",
+                        reset(),
+                        bold(),
+                        red(),
+                        message.prefix,
+                        st.c_str(),
+                        reset());
+            } else {
+                fprintf(stderr, " *** %s fatal error stack trace: ***:\n %s \n", message.prefix, st.c_str());
+            }
+
+            fflush(stderr);
+        }
+
+        auto ec = get_error_context(); // new start 2016/12/4
+
+        if (!ec.empty()) {
+            //fprintf(stderr,"error %s\n", ec.c_str());
+            //fflush(stderr);
+            IN_LOG(ERROR, "%s", ec.c_str());
+        }
+    }
+
+
 
-} /* namespace logger */
+    for (auto& p : LoggerConfig::callbackVecs) {
+        if (verbosity <= p.verbose) {
+            p.callback(p.user_data, message); // log to file
 
+            if (LoggerConfig::flushBufferInMs == 0) {
+                // fflush(file)
+                if (p.flush) {
+                    p.flush(p.user_data);
+                }
+            } else {
+                LoggerConfig::needFlush = true;
+            }
+        }
+    }
+
+    if (LoggerConfig::flushBufferInMs > 0 && !LoggerConfig::flushThread) {
+        // create the guard thread preiodic flushing
+        LoggerConfig::flushThread = new std::thread([]() {
+            for (;;) {
+                if (LoggerConfig::needFlush) {
+                    // if flushBufferInMs >0 flush everything!
+                    flush_callback();
+                }
+
+                std::this_thread::sleep_for(std::chrono::milliseconds(LoggerConfig::flushBufferInMs));
+            }
+        });
+    }
+
+    if (verbosity == Verbose_FATAL) {
+        flush_callback();
+
+        /*if (s_fatal_handler) {
+            s_fatal_handler(message);
+            flush_callback();
+        }*/
+
+        if (abort_if_fatal) {
+#if LOGGER_CATCH_SIGABRT && !defined(_WIN32)
+            // Make sure we don't catch our own abort:
+            signal(SIGABRT, SIG_DFL);
 #endif
+            abort();
+        }
+    }
+}
+
+inline void write_to_stderr(const char* data, size_t size) {
+    auto result = write(STDERR_FILENO, data, size);
+    (void)result; // Ignore errors.
+}
+
+inline void write_to_stderr(const char* data) {
+    write_to_stderr(data, strlen(data));
+}
+
+inline void call_default_signal_handler(int signal_number) {
+    struct sigaction sig_action;
+    memset(&sig_action, 0, sizeof(sig_action));
+    sigemptyset(&sig_action.sa_mask);
+    sig_action.sa_handler = SIG_DFL; // set sig_del for default signal handle
+    sigaction(signal_number, &sig_action, NULL);
+    // send signal to a process . not kill the pthread
+    kill(getpid(), signal_number);
+}
+
+inline void logger_signal_handler(int signal_number, siginfo_t*, void*) {
+    const char* signal_name = "UNKNOWN SIGNAL";
+
+    for (const auto& s : LOCAL_SIGS) {
+        if (s.sigNum == signal_number) {
+            signal_name = s.sigName;
+            break;
+        }
+    }
+
+    // thread safety
+    if (LoggerConfig::terminalSupportColor && LoggerConfig::colorstderr) {
+        write_to_stderr(reset());
+        write_to_stderr(bold());
+        write_to_stderr(blink());
+        write_to_stderr(light_red());
+    }
+
+    write_to_stderr("\n");
+    write_to_stderr("logger caught a signal: ");
+    write_to_stderr(signal_name);
+    write_to_stderr("\n");
+
+    if (LoggerConfig::terminalSupportColor && LoggerConfig::colorstderr) {
+        write_to_stderr(reset());
+    }
+
+    // unsafe things
+    flush_callback();
+    char preamble_buff[128];
+    print_preamble(preamble_buff, sizeof(preamble_buff), Verbose_FATAL, "", 0);
+    auto message = Message{Verbose_FATAL, "", 0, preamble_buff, "Signal caught: ", signal_name};
+
+    try {
+        log_message(2, message,
+                    false); // may throw some runtime exception to disable signal handler, set false to use our defined signal func.
+    } catch (...) {
+        write_to_stderr("Exception caught and ignored by logger signal handler.\n");
+    }
+
+    call_default_signal_handler(signal_number);
+}
+
+inline void install_logger_signal_handlers() {
+    struct sigaction sig_action;
+    memset(&sig_action, 0, sizeof(sig_action));
+    sigemptyset(&sig_action.sa_mask);
+    sig_action.sa_flags |= SA_SIGINFO;
+    sig_action.sa_sigaction = &logger_signal_handler;
+
+    for (const auto& s : LOCAL_SIGS) {
+        if (sigaction(s.sigNum, &sig_action, NULL) == -1) {
+            fprintf(stderr, "Failed to install handler for %s\n", s.sigName);
+        }
+    }
+}
+/**
+ *  \brief logger init func
+ *
+ */
+inline void initial(const char* argv0) {
+    LoggerConfig::init();
+    // get host and user info.
+    get_username();
+    get_program_name(argv0);
+    get_hostname();
+#if LOGGER_TLS_NAMES
+    set_thread_name("main_thread"); // set main thread name = "main_thread"
+#endif
+
+    if (!LoggerConfig::logtostderr) {
+        add_sys_log_file("./log");
+    }
+
+    auto PREAMBLE_EXPLAIN = textprintf("  v  |     time     |  uptime  | %s | %s:line ] ",
+                                       " thread name/id", "file");
+
+    if (LoggerConfig::currentVerbos >= Verbose_INFO) {
+        if (LoggerConfig::colorstderr && LoggerConfig::terminalSupportColor) {
+            fprintf(stderr, "%s%s%s\n", reset(), dim(), PREAMBLE_EXPLAIN.c_str());
+        } else {
+            fprintf(stderr, "%s", PREAMBLE_EXPLAIN.c_str());
+        }
+
+        fflush(stderr);
+    }
+
+    IN_LOG(INFO, "Current Verbose Level: %d", LoggerConfig::currentVerbos);
+    IN_LOG(INFO, "-----------start logging------------");
+    //fprintf(stderr,"stderr verbosity: %d\n", LoggerConfig::currentVerbos);
+    //fprintf(stderr,"-----------------------------------\n");
+    //fflush(stderr);
+    install_logger_signal_handlers();
+    flush_callback();
+
+}
+
+
+} // namespace funcRegister
+
+inline loggerMsg::~loggerMsg() {
+    auto message = ss_.str();
+
+    if (isAbort_) {
+        funcRegister::log_and_abort(1, expression_, file_, line_, "%s", message.c_str());
+    } else {
+        funcRegister::log(verbose_, file_, line_, "%s", message.c_str());
+    }
+}
+
+} // namespace core
+
+} // namespace logger
+
+
+#endif // LOGGER_CORE_H
diff --git a/utils/logger/logger_utils.h b/utils/logger/logger_utils.h
deleted file mode 100644
index 1742f82..0000000
--- a/utils/logger/logger_utils.h
+++ /dev/null
@@ -1,914 +0,0 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-       http://www.apache.org/licenses/LICENSE-2.0
-   
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License. 
-*/
-#ifndef LOGGER_UTILS_H
-#define LOGGER_UTILS_H
-
-#include <algorithm>
-#include <atomic>
-#include <chrono>
-#include <cstdio>
-#include <cstdlib>
-#include <cstring>
-#include <mutex>
-#include <regex>
-#include <string>
-#include <thread>
-#include <vector>
-#include <cstdarg>
-#include <sstream>
-#include <string>
-#include <stdio.h>
-#include <stdlib.h>
-#include <signal.h>
-#include <sys/types.h>
-#include <sys/stat.h> // mkdir
-#include <unistd.h>   // STDERR_FILENO
-
-#include "anakin_config.h"
-
-// Disable all warnings from gcc/clang:
-#if defined(__clang__)
-        #pragma clang system_header
-#elif defined(__GNUC__)
-        #pragma GCC system_header
-#endif
-
-#define LOGGER_CONCAT(str1,str2)  str1##str2
-
-/// \brief intercept the our own abort signal
-///
-/// for usage: signal(SIGABRT, SIG_DFL);
-/// SIG_DFL:default signal handle invoke param
-#define LOGGER_CATCH_SIGABRT 1
-
-#if defined __linux__ || defined __APPLE__
-#include <pthread.h>
-#include <sys/utsname.h>  // For uname.
-#ifdef ENABLE_STACKTRACES
-#include <cxxabi.h>    // for __cxa_demangle for gcc
-#include <dlfcn.h>     // for dladdr
-#include <execinfo.h>  // for backtrace
-#endif //ENABLE_STACKTRACES
-#endif
-
-#if defined(_WIN32) || (defined(__APPLE__) && !TARGET_OS_IPHONE) || defined(__linux__)
-#   if defined(__APPLE__)
-#       define LOGGER_THREAD_LOCAL __thread
-#       define LOGGER_TLS_NAMES 1
-#   else
-#       define LOGGER_THREAD_LOCAL thread_local
-#       define LOGGER_TLS_NAMES 1
-#   endif
-#else
-#   error " Anakin can't detect thread local storage."
-#   define LOGGER_THREAD_LOCAL
-#   define LOGGER_TLS_NAMES 0
-#endif
-
-#ifdef  __COUNTER__
-  #define LOGGER_ADD_LINE(str)    LOGGER_CONCAT(str,__COUNTER__)
-#else
-  #define LOGGER_ADD_LINE(str)    LOGGER_CONCAT(str,__LINE__)
-#endif
-
-#if defined(__clang__) || defined(__GNUC__)
-   /// @brief check the printf var format
-   /// @param formatArgs  format args list e.g. 1,2,3,... formatArgs+1
-   /// @param firstArg  first format args list, 1 or 2 or ...
-   #define LOGGER_CHECK_PRINTF(formatArgs,firstArg)  __attribute__((__format__ (__printf__, formatArgs, firstArg)))
-#else
-   #define LOGGER_CHECK_PRINTF(formatArgs,firstArg)
-#endif
-
-namespace logger {
-
-enum  VerBoseType {
-    Verbose_OFF     = -9, ///< log off
-    Verbose_FATAL   = -3, ///< log info fatal
-    Verbose_ERROR   = -2, ///< log info ERROR
-    Verbose_WARNING = -1, ///< log info WARNING
-    Verbose_INFO    = 0,  ///< log info normal
-    Verbose_0       = 0,  ///< verbose  0
-    Verbose_1       =1,
-    Verbose_2,
-    Verbose_3,
-    Verbose_4,
-    Verbose_5,
-    Verbose_6,
-    Verbose_7,
-    Verbose_8,
-    Verbose_9,
-    Verbose_Max           ///< max level verbose
-};
-
-// out device type
-enum DevOutT {
-    __OUT,  ///< stdout
-    __ERR,  ///< stderr
-    __FILE, ///< file
-};
-
-// device type
-template<DevOutT D>
-struct DevType{};
-
-template<>
-struct DevType<__OUT> {};
-
-template<>
-struct DevType<__ERR> {};
-
-template<>
-struct DevType<__FILE> {};
-
-enum ColorEnum {
-	RED = 0,
-	BLACK,
-	BOLD_RED,
-	GREEN,
-	YELLOW,
-	BLUE,
-	PURPLE,
-	CYAN,
-	LIGHT_GRAY,
-	WHITE,
-	LIGHT_RED,
-	DIM,
-	BOLD,
-	UNDERLINE,
-	BLINK,
-	RESET	
-};
-
-template<ColorEnum C>
-struct Color {
-	static constexpr char* str = "";
-};
-
-template<> struct Color<RED> { static constexpr char* str = "\e[31m"; };
-template<> struct Color<BLACK> { static constexpr char* str = "\e[30m"; };
-template<> struct Color<BOLD_RED> { static constexpr char* str = "\e[41m"; };
-template<> struct Color<GREEN> { static constexpr char* str = "\e[32m"; };
-template<> struct Color<YELLOW> { static constexpr char* str = "\e[33m"; };
-template<> struct Color<BLUE> { static constexpr char* str = "\e[34m"; };
-template<> struct Color<PURPLE> { static constexpr char* str = "\e[35m"; };
-template<> struct Color<CYAN> { static constexpr char* str = "\e[36m"; };
-template<> struct Color<LIGHT_GRAY> { static constexpr char* str = "\e[37m"; };
-template<> struct Color<WHITE> { static constexpr char* str = "\e[37m"; };
-template<> struct Color<LIGHT_RED> { static constexpr char* str = "\e[91m"; };
-template<> struct Color<DIM> { static constexpr char* str = "\e[2m"; };
-template<> struct Color<BOLD> { static constexpr char* str = "\e[1m"; };
-template<> struct Color<UNDERLINE> { static constexpr char* str = "\e[4m"; };
-template<> struct Color<BLINK> { static constexpr char* str = "\e[5m"; };
-template<> struct Color<RESET> { static constexpr char* str = "\e[0m"; };
-
-namespace utils {
-
-/// file i/o mode
-struct FileMode {
-    enum mode_t {
-        CREATE,
-        APPEND
-    };
-    FileMode(mode_t mode):_mode(mode) {}
-    const char* c_str() {
-        return _mode == CREATE ? "w" : "a";
-    }
-    operator FileMode::mode_t() {
-        return _mode;
-    }
-    mode_t _mode;
-};
-
-template <class T>
-std::string type_name() {
-#ifdef ENABLE_STACKTRACES
-   int status = -1;
-   char* demangled = abi::__cxa_demangle(typeid(T).name(), 0, 0, &status);
-   return std::string(status == 0 ? demangled : strdup(typeid(T).name()));
-#else
-    return "Invalid-Type";
-#endif
-}
-
-// declare class and class member
-class sys {
-public:
-    static void set_max_logger_verbose_level(VerBoseType verbose);
-    static VerBoseType get_max_logger_verbose_level();
-    /****************************************************************************/ 
-    /*                     system custom signal manipulate                      */ 
-    /***************t************************************************************/	
-    static void write_to_stderr(const char* data, size_t size);
-    static void write_to_stderr(const char* data);
-    static void install_logger_signal_handlers();
-    
-    /****************************************************************************/ 
-    /*                     system file manipulate                               */ 
-    /***************t************************************************************/	
-    static size_t get_file_barrier_size_in_GB();
-    static void set_file_barrier_size_in_GB(size_t limit_size_in_GB);
-    static void write_file_log(VerBoseType verbose, 
-                               const char* expr, 
-                               const char* header, 
-                               const char* msg);
-    static void write_file_log_with_format(VerBoseType verbose, 
-                                           const char* expr, 
-                                           const char* header, 
-                                           const char* format, ...) LOGGER_CHECK_PRINTF(4, 5);
-    static void add_file_stream(VerBoseType verbose, void* handle);
-    static void file_flush_all();
-    static void file_flush_target(VerBoseType verbose);
-    static bool logger_to_file(std::string path, FileMode fileMode, VerBoseType verbose);
-    static void add_sys_log_file(std::string log_dir);
-    
-    /****************************************************************************/ 
-    /*                     system get basic env info                            */ 
-    /***************t************************************************************/	
-    static bool colorful_shell_access();
-    static void get_username();
-    static void get_program_name(const char* argv0);
-    static void get_hostname();
-    static const char* get_file_name(const char*);
-    static char* pick_format(const char* format, va_list vlist);
-    static void set_thread_name(const char* name);
-    static void get_thread_name(char* buffer, unsigned long long length, bool right_align_hext_id);
-    static void init();
-
-    template<VerBoseType Verbose>
-    static void add_log_header(char* header, int header_len, const char* file, unsigned line);
-    
-    
-    /****************************************************************************/ 
-    /*                     system stack tracing manipulate                      */ 
-    /***************t************************************************************/	
-    static void transform_stacktrace(std::string& msg);
-    static std::string stack_trace(int skip);
-};
-
-#define INNER_LOG(Verbose, ...) \
-    do {\
-        char header[128];\
-        sys::add_log_header<Verbose>(header, sizeof(header), __FILE__, __LINE__);\
-        ((Verbose) > sys::get_max_logger_verbose_level()) ? \
-        (void)0 : sys::write_file_log_with_format(Verbose, "", header, __VA_ARGS__);\
-    } while(0)
-
-#define IN_LOG(verbose_name, ...) INNER_LOG(Verbose_##verbose_name, __VA_ARGS__)
-
-class FileStream;
-void custom_singal_handler(int signal_number, siginfo_t*, void*);
-
-class SYSResource {
-public:
-    static SYSResource& Global() {
-        static SYSResource _ins;
-        return _ins;
-    }
-
-    friend class sys;
-    friend class FileStream;
-    friend void custom_singal_handler(int signal_number, siginfo_t*, void*);
-
-private:
-    SYSResource() {
-        init_flush_thread();
-    }
-    ~SYSResource() {}
-
-    void init_flush_thread() {
-        std::lock_guard<std::recursive_mutex> lock(this->mut);
-        flushFileThread = new std::thread([&, this](){ 
-            for (;;) { 
-                if (this->needFlushFile) {
-                    // if flushFileBufferInMs >0 flush everything!
-                    sys::file_flush_all(); 
-                } 
-                std::this_thread::sleep_for(std::chrono::milliseconds(flushFileBufferInMs)); 
-            }
-         });
-    }
-
-private:
-    /// basic info
-    bool logtostderr{false};
-    bool colorstderr{true};
-    /// true if terminal support color(win does not support it)
-    bool terminalSupportColor{false};
-
-    /// flush buffer on every line (if x) in x ms later or flush everything immediatly(if 0)
-    unsigned flushFileBufferInMs{0};
-    bool needFlushFile{true};
-    std::thread* flushFileThread{nullptr};
-    size_t fileBarrierSizeInGB{10}; // default 1 GPU
-
-    std::string userName;    ///< machine user name , used for log file name.
-    std::string programName; ///< program name get from argv[0]
-    std::string hostName;    ///< host machine name used for log file name.
-
-    VerBoseType currentMaxVerbos{Verbose_Max};   ///< current max verbose level
-
-public:
-    std::recursive_mutex mut; // this can be access by other class or function
-};
-
-
-// namespace holding static resource it looks a little bit trick
-namespace SYSStaticRes {
-#ifdef LOGGER_TLS_NAMES 
-    static LOGGER_THREAD_LOCAL std::string  threadName; ///< customed thread name
-#endif
-    static const auto startTime = std::chrono::steady_clock::now();
-    static const int threadNameWidth = 16;
-};
-
-/**
- * \brief  log file stream class
- */
-class FileStream {
-public:
-    static FileStream& Global() {
-        static FileStream _ins;
-        return _ins;
-    }
-
-    void add_file_stream(VerBoseType verbose, void* handle) {
-        std::lock_guard<std::recursive_mutex> lock(_file_stream_mut);
-        _file_stream_res.push_back(Callback{verbose, handle});
-    }
-
-    void write_file_log(VerBoseType verbose, const char* expr, const char* header, const char* msg) {
-        std::lock_guard<std::recursive_mutex> lock(_file_stream_mut);
-        for(auto& file : _file_stream_res) {
-            if(verbose <= file._verbose) {
-                FILE* file_p = reinterpret_cast<FILE*>(file._handle);
-                int file_desc;
-                if((file_desc = fileno(file_p)) == -1) {
-                    IN_LOG(FATAL, "fileno error code: %d", file_desc);
-                }
-                struct stat st; 
-                fstat(file_desc, &st); 
-                size_t size = st.st_size / (1024*1024*1024);
-                size_t barrier_size = sys::get_file_barrier_size_in_GB();
-                if(size > barrier_size) {
-                    std::fseek(file_p, 0, SEEK_SET); // seek to start
-                }
-                fprintf(file_p, "%s%s%s\n", header, expr, msg);
-                if (SYSResource::Global().flushFileBufferInMs == 0) { 
-                    fflush(file_p);
-                } else {
-                    SYSResource::Global().needFlushFile = true;
-                }
-            }
-        }
-    }
-   
-	~FileStream(){
-		close(); 
-	}
-
-	void flush_all() {
-        std::lock_guard<std::recursive_mutex> lock(_file_stream_mut);
-        fflush(stderr);
-        for(auto& file : _file_stream_res) {
-            FILE* file_p = reinterpret_cast<FILE*>(file._handle); 
-            fflush(file_p);
-        }
-	}
-
-    void flush_target(VerBoseType verbose){
-        std::lock_guard<std::recursive_mutex> lock(_file_stream_mut);
-        for(auto& file : _file_stream_res) {
-            if(file._verbose == verbose) {
-                FILE* file_p = reinterpret_cast<FILE*>(file._handle); 
-                fflush(file_p);
-            }
-        }
-    }
-
-private:
-    FileStream() {}
-   
-    void close() {
-        for(auto& file : _file_stream_res) {
-            FILE* file_p = reinterpret_cast<FILE*>(file._handle); 
-            fclose(file_p);
-        }
-	}
-    
-private:
-	struct Callback {
-        Callback(VerBoseType v, void* h):_verbose(v), _handle(h){}
-        VerBoseType _verbose{Verbose_OFF};
-		void* _handle{nullptr}; /// < file handle
-	};
-    std::vector<Callback> _file_stream_res; /// < file stream resource for log
-    std::recursive_mutex  _file_stream_mut;
-};
-
-class CustomSignal {
-public:
-    static CustomSignal& Global() {
-        static CustomSignal _ins;
-        return _ins;
-    }
-
-    void call_default_signal_handler(int signal_number) { 
-        struct sigaction sig_action; 
-        memset(&sig_action, 0, sizeof(sig_action)); 
-        sigemptyset(&sig_action.sa_mask); 
-        sig_action.sa_handler = SIG_DFL; // set sig_del for default signal handle 
-        sigaction(signal_number, &sig_action, NULL); 
-        // send signal to a process . not kill the pthread 
-        kill(getpid(), signal_number);
-    }
-
-    inline std::string get_custom_name_by_id(int signal_number) {
-        for(auto& s : local_singals) {
-            if(s.num == signal_number) {
-                return s.name;
-            }
-        } 
-        return "";
-    }
-
-    void install_custom_signal_handlers() { 
-        struct sigaction sig_action; 
-        memset(&sig_action, 0, sizeof(sig_action)); 
-        sigemptyset(&sig_action.sa_mask); 
-        sig_action.sa_flags |= SA_SIGINFO; 
-        sig_action.sa_sigaction = &custom_singal_handler; 
-        for (const auto& sg : local_singals) { 
-            if(sigaction(sg.num, &sig_action, NULL) == -1){ 
-                fprintf(stderr,"Failed to install handler for %s\n", sg.name.c_str()); 
-            } 
-        }
-    }
-
-private: 
-    CustomSignal() {}
-    ~CustomSignal() {}
-
-    struct SignalOwn { 
-        int num; 
-        std::string name; 
-    }; 
-    // those signal causes the process to terminate.  
-    std::vector<SignalOwn> local_singals { 
-#if LOGGER_CATCH_SIGABRT 
-        { SIGABRT, "SIGABRT" }, // The SIGABRT signal is sent to a process to tell it to abort( abort().), also can be signal from others.  
-#endif 
-        { SIGBUS,  "SIGBUS"  }, // incorrect memory access alignment or non-existent physical address 
-        { SIGFPE,  "SIGFPE"  }, // (floating-point exception) erroneous arithmetic operation, such as division by zero.  
-        { SIGILL,  "SIGILL"  }, // illegal instructionw
-        { SIGINT,  "SIGINT"  }, // Terminal interrupt signal.  
-        { SIGSEGV, "SIGSEGV" }, // Invalid memory reference.  
-        { SIGTERM, "SIGTERM" }, // Termination signal.  
-        { SIGPIPE, "SIGPIPE" }, // Write on a pipe with no one to read it.
-      };
-};
-
-// logger custom signal handler 
-inline void custom_singal_handler(int signal_number, siginfo_t*, void*) {
-    std::string signal_name("UNKNOWN SIGNAL");
-    signal_name = CustomSignal::Global().get_custom_name_by_id(signal_number);
-
-    if(sys::colorful_shell_access()) {
-        sys::write_to_stderr(Color<RESET>::str);
-        sys::write_to_stderr(Color<BOLD>::str);
-        sys::write_to_stderr(Color<CYAN>::str);
-    }
-    sys::write_to_stderr("\n"); 
-    sys::write_to_stderr("logger caught a signal: "); 
-    sys::write_to_stderr(signal_name.c_str()); 
-    sys::write_to_stderr("\n");
-    if(sys::colorful_shell_access()) {
-        sys::write_to_stderr(Color<RESET>::str);
-    }
-
-    sys::file_flush_all();
-
-    char header[128];
-    sys::add_log_header<Verbose_FATAL>(header, sizeof(header), "", 0);
-    sys::write_file_log_with_format(Verbose_FATAL, "", header, "Signal caught:", signal_name.c_str());
-    auto st = sys::stack_trace(3); 
-    if (!st.empty()) {
-    	if (sys::colorful_shell_access()) {
-        	fprintf(stderr," %s%s%s  >>>>> Fatal error: stack trace: <<<<<< \n %s \n %s\n",
-                    Color<RESET>::str,
-                    Color<BOLD>::str,
-                    Color<GREEN>::str,
-                    st.c_str(),
-                    Color<RESET>::str);
-    	} else {
-        	fprintf(stderr," >>>>> Fatal error: stack trace: <<<<<< \n %s \n", st.c_str());
-    	}
-    	fflush(stderr);
-        sys::write_file_log(Verbose_FATAL, "", "", st.c_str());
-    }
-
-    CustomSignal::Global().call_default_signal_handler(signal_number);
-}
-
-// definition for sys member functions
-inline void sys::set_max_logger_verbose_level(VerBoseType verbose = Verbose_0) {
-    SYSResource::Global().currentMaxVerbos = verbose;
-}
-inline VerBoseType sys::get_max_logger_verbose_level() {
-    return SYSResource::Global().currentMaxVerbos;
-}
-/****************************************************************************/ 
-/*                     system custom signal manipulate                      */ 
-/***************t************************************************************/	
-inline void sys::write_to_stderr(const char* data, size_t size) {
-    auto result = write(STDERR_FILENO, data, size); 
-    (void)result; // Ignore errors.
-} 
-inline void sys::write_to_stderr(const char* data) {
-    sys::write_to_stderr(data, strlen(data));
-}
-inline void sys::install_logger_signal_handlers() {
-    CustomSignal::Global().install_custom_signal_handlers();
-}
-
-/****************************************************************************/ 
-/*                     system file manipulate                               */ 
-/***************t************************************************************/	
-inline size_t sys::get_file_barrier_size_in_GB() {
-    return SYSResource::Global().fileBarrierSizeInGB;
-}
-inline void sys::set_file_barrier_size_in_GB(size_t limit_size_in_GB) {
-    SYSResource::Global().fileBarrierSizeInGB = limit_size_in_GB;
-}
-inline void sys::write_file_log(VerBoseType verbose, 
-                                const char* expr, 
-                                const char* header, 
-                                const char* msg) {
-    FileStream::Global().write_file_log(verbose, expr, header, msg);
-}
-inline void sys::write_file_log_with_format(VerBoseType verbose, 
-                                            const char* expr, 
-                                            const char* header, 
-                                            const char* format, ...) {
-    va_list vlist; 
-    va_start(vlist, format); 
-    auto msg = sys::pick_format(format, vlist);
-    FileStream::Global().write_file_log(verbose, expr, header, msg);
-    //free(msg);
-    //msg = nullptr;
-    va_end(vlist);
-}
-inline void sys::add_file_stream(VerBoseType verbose, void* handle) {
-    FileStream::Global().add_file_stream(verbose, handle);
-}
-inline void sys::file_flush_all() {
-    FileStream::Global().flush_all();
-}
-inline void sys::file_flush_target(VerBoseType verbose){
-    FileStream::Global().flush_target(verbose);
-} 
-inline bool sys::logger_to_file(std::string path, FileMode fileMode, VerBoseType verbose) { 
-    char* file_path = strdup(path.c_str()); 
-    for (char* p = strchr(file_path + 1, '/'); p!=NULL; p = strchr(p + 1, '/')){ 
-        *p = '\0'; 
-        struct stat st; 
-        if((stat(file_path, &st) == 0) && (((st.st_mode) & S_IFMT) == S_IFDIR)){ 
-            // file_path exists and is a directory. do nothing 
-            *p = '/'; 
-            continue; 
-        } 
-        else { 
-            if(mkdir(file_path,0755)==-1){ 
-                IN_LOG(ERROR,"Failed to ceate the path '%s'\n", file_path); 
-                return false; 
-            } 
-        } 
-        *p = '/'; 
-    } 
-    free(file_path); 
-    auto file = fopen(path.c_str(), fileMode.c_str()); 
-    if(!file){ 
-        IN_LOG(ERROR, "Failed to open '%s'\n", path.c_str()); 
-        return false; 
-    } 
-    // register to file stream
-    sys::add_file_stream(verbose, file);
-    if (fileMode == FileMode::APPEND) { 
-        fprintf(file,"\n\n\n\n\n"); 
-        fflush(file); 
-    } 
-    fprintf(file, "File log level: %d\n", verbose); 
-    fprintf(file, " V  |     time     |  uptime  | %s | %s:line ] \n", " thread name/id", "File"); 
-    fflush(file); 
-    IN_LOG(INFO, "Logging to '%s', FileMode: '%s', Level: %d\n", path.c_str(), fileMode.c_str(), verbose); 
-    fflush(stderr);
-    return true; 
-}
-/// @brief same as glog.
-/// If no base filename for logs of this severity has been set, use a default base filename of
-/// "<program name>.<hostname>.<user name>.log.<severity level>.".  So
-/// logfiles will have names like
-/// webserver.examplehost.root.log.INFO.19990817-150000.4354 or ....thread_name, where
-/// 19990817 is a date (1999 August 17), 150000 is a time (15:00:00),
-/// and 4354 is the pid of the logging process or thread_name of the logging thread.
-/// The date & time reflect when the file was created for output.
-/// Where does the file get put?  Successively try the directories
-/// "/tmp", and "." , "/tmp" is default path for logging.
-/// add_sys_log_file will be invoked in the end of initial function.
-inline void sys::add_sys_log_file(std::string log_dir = "/tmp"){
-    // default filename
-    std::string filename = ""; 
-    filename += SYSResource::Global().programName + "."; 
-    filename += SYSResource::Global().hostName + "."; 
-    filename += SYSResource::Global().userName + "."; 
-    filename += "log.";
-    filename = log_dir + "/" + filename; 
-    long long ms_since_epoch = \
-                               std::chrono::duration_cast<std::chrono::milliseconds>(\
-                                       std::chrono::system_clock::now().time_since_epoch()).count(); 
-    time_t sec_since_epoch = time_t(ms_since_epoch / 1000); 
-    tm time_info; 
-    localtime_r(&sec_since_epoch, &time_info); 
-                        
-    char thread_name[SYSStaticRes::threadNameWidth + 1] = {0}; 
-    get_thread_name(thread_name, SYSStaticRes::threadNameWidth + 1, true); 
-                                
-    char buff[20 + SYSStaticRes::threadNameWidth]; 
-    int buff_size = sizeof(buff)/sizeof(char); 
-    snprintf(buff, buff_size, ".%04d%02d%02d-%02d%02d%02d.%s", 
-                              1900 + time_info.tm_year, 1 + time_info.tm_mon, time_info.tm_mday, 
-                              time_info.tm_hour, time_info.tm_min, time_info.tm_sec, thread_name);
-
-    auto get_log_filename = [&](std::string verbose_str) -> std::string { 
-        //printf("path :: %s \n ",(filename + verbose_str + std::string(buff)).c_str());  // for debug 
-        return std::string(filename + verbose_str) + std::string(buff);
-    };
-
-    // create the log file with diff verbose 
-    sys::logger_to_file(get_log_filename("FATAL"),FileMode::CREATE,VerBoseType::Verbose_FATAL); 
-    sys::logger_to_file(get_log_filename("ERROR"),FileMode::CREATE,VerBoseType::Verbose_ERROR); 
-    sys::logger_to_file(get_log_filename("WARNING"),FileMode::CREATE,VerBoseType::Verbose_WARNING); 
-    sys::logger_to_file(get_log_filename("INFO"),FileMode::CREATE,VerBoseType::Verbose_INFO);
-}
-
-/****************************************************************************/ 
-/*                     system get basic env info                            */ 
-/***************t************************************************************/	
-inline bool sys::colorful_shell_access() {
-    return SYSResource::Global().colorstderr \
-        && SYSResource::Global().terminalSupportColor;
-}
-inline void sys::get_username() { 
-    const char* user = getenv("USER"); 
-    if (user != NULL) { 
-        SYSResource::Global().userName = user; 
-    } else { 
-        SYSResource::Global().userName = "invalid-user"; 
-    } 
-}
-inline void sys::get_program_name(const char* argv0) { 
-    const char* slash = strrchr(argv0, '/');
-    SYSResource::Global().programName = slash ? slash+1 : argv0; 
-}
-inline void sys::get_hostname() { 
-#if defined __linux__ || defined __APPLE__ 
-    struct utsname buf; 
-    if(0 != uname(&buf)){ 
-        // ensure null termination on failure 
-        *buf.nodename = '\0'; 
-    } 
-    SYSResource::Global().hostName = strdup(buf.nodename);
-#else
-    # warning There is no way to retrieve the host name(not support os windows).
-    SYSResource::Global().hostName = "(unknown)";
-#endif  
-}
-inline char* sys::pick_format(const char* format, va_list vlist) { 
-	char* msg = nullptr;
-	int result = vasprintf(&msg, format, vlist);
-	if(result == -1){
-		IN_LOG(ERROR, "Bad string format: '%s'\n", format);
-	}
-	return msg; 
-}
-inline void sys::set_thread_name(const char* name) { 
-#ifdef LOGGER_TLS_NAMES 
-    SYSStaticRes::threadName = std::string(name); 
-#else 
-#ifdef __APPLE__ 
-    pthread_setname_np(name); 
-#else 
-    pthread_setname_np(pthread_self(), name); 
-#endif 
-#endif
-}
-inline void sys::get_thread_name(char* buffer, unsigned long long length, bool right_align_hext_id = true) {
-    if(length == 0u){
-	    IN_LOG(ERROR, "get_thread_name get 0 length buffer. ");
-	}
-	if(buffer == nullptr){
-	    IN_LOG(ERROR, "get_thread_name get nullptr buffer. ");
-	} 
-#ifdef SUPPORT_PTHREADS 
-    auto thread = pthread_self(); 
-#ifdef LOGGER_TLS_NAMES 
-    if (const char* name = SYSStaticRes::threadName.c_str()) { 
-        snprintf(buffer, length, "%s", name); 
-    } else { 
-        buffer[0] = 0; 
-    } 
-#else 
-    pthread_getname_np(thread, buffer, length); 
-#endif 
-    if (buffer[0] == 0) { 
-#ifdef __APPLE__ 
-        uint64_t thread_id; 
-        pthread_threadid_np(thread, &thread_id); 
-#else 
-        uint64_t thread_id = thread; 
-#endif 
-        if (right_align_hext_id) { 
-            snprintf(buffer, length, "%*X", (unsigned)length - 1, static_cast<unsigned>(thread_id)); 
-        } else { 
-            snprintf(buffer, length, "%X", static_cast<unsigned>(thread_id)); 
-        } 
-    } 
-#else // SUPPORT_PTHREADS 
-    buffer[0] = 0; 
-#endif // SUPPORT_PTHREADS
-}
-inline const char* sys::get_file_name(const char* path) { 
-    for (auto ptr = path; *ptr; ++ptr) { 
-        if (*ptr == '/' || *ptr == '\\') { 
-            path = ptr + 1; 
-        } 
-    } 
-    return path;
-}
-inline void sys::init() {
-    if(const char* term = getenv("TERM")) {
-        if( 0 == strcmp(term, "cygwin") || 0 == strcmp(term, "linux")
-                                        || 0 == strcmp(term, "screen")
-                                        || 0 == strcmp(term, "xterm")
-                                        || 0 == strcmp(term, "xterm-256color")
-                                        || 0 == strcmp(term, "xterm-color")) {
-                    SYSResource::Global().terminalSupportColor = true; 
-        } else {
-            SYSResource::Global().terminalSupportColor = false;
-        }
-    }
-}
-template<VerBoseType Verbose>
-inline void sys::add_log_header(char* header, int header_len, const char* file, unsigned line) { 
-    long long ms_since_epoch = \
-                  std::chrono::duration_cast<std::chrono::milliseconds>(\
-                          std::chrono::system_clock::now().time_since_epoch()).count();
-    time_t sec_since_epoch = time_t(ms_since_epoch / 1000);
-    tm time_info;
-    localtime_r(&sec_since_epoch, &time_info);
-
-    auto uptime_ms = \
-                  std::chrono::duration_cast<std::chrono::milliseconds>(\
-                          std::chrono::steady_clock::now() - SYSStaticRes::startTime).count();
-    auto uptime_sec = uptime_ms / 1000.0;
-
-    char thread_name[SYSStaticRes::threadNameWidth + 1] = {0};
-    sys::get_thread_name(thread_name, SYSStaticRes::threadNameWidth + 1, true);
-
-    file = sys::get_file_name(file);
-
-    char level_buff[6];
-    if (Verbose <= Verbose_FATAL) { 
-        snprintf(level_buff, sizeof(level_buff) - 1, "Ftl");
-    } else if (Verbose == Verbose_ERROR) { 
-        snprintf(level_buff, sizeof(level_buff) - 1, "Err"); 
-    } else if (Verbose == Verbose_WARNING) { 
-        snprintf(level_buff, sizeof(level_buff) - 1, "War"); 
-    } else if (Verbose == Verbose_INFO) {
-        snprintf(level_buff, sizeof(level_buff) - 1, "Inf");
-    } else { 
-        snprintf(level_buff, sizeof(level_buff) - 1, "%3d", Verbose);
-    }
-    // fill the header
-    snprintf(header, header_len, "%4s| %02d:%02d:%02d.%05lld| %.3fs| %s| %s:%u] ",
-             level_buff,
-             time_info.tm_hour, time_info.tm_min, time_info.tm_sec, ms_since_epoch % 1000,
-             uptime_sec,
-             thread_name,
-             file,
-             line); 
-}
-
-/****************************************************************************/ 
-/*                     system stack tracing manipulate                      */ 
-/***************t************************************************************/	
-inline void sys::transform_stacktrace(std::string& msg) {
-#ifdef ENABLE_STACKTRACES
-    std::vector< std::pair<std::string,std::string> > patterns={
-       { type_name<std::string>(),    "std::string"    },
-       { type_name<std::wstring>(),   "std::wstring"   },
-       { type_name<std::u16string>(), "std::u16string" },
-       { type_name<std::u32string>(), "std::u32string" },
-       { "std::__1::",                "std::"          },
-       { "__thiscall ",               ""               },
-       { "__cdecl ",                  ""               },
-    };
-    for(auto& pattern : patterns) {
-        if(pattern.first.size() > pattern.second.size()) {
-            size_t pos; 
-            while((pos=msg.find(pattern.first)) != std::string::npos) {
-                msg.replace(pos, pattern.first.size(), pattern.second);
-            }
-        }
-    }
-    try {
-        std::regex std_allocator_re(R"(,\s*std::allocator<[^<>]+>)");
-        msg = std::regex_replace(msg, std_allocator_re, std::string(""));
-        std::regex template_spaces_re(R"(<\s*([^<> ]+)\s*>)");
-        msg = std::regex_replace(msg, template_spaces_re, std::string("<$1>"));
-    } catch (std::regex_error&) {/*may throw exception*/}
-#endif
-}
-/// we use libstdc++'s abi::__cxa_demangle() to set friendly demangled stack trace.
-/// Example:
-///
-///     | Mangled Name  | abi::__cxa_demangle()
-///     |---------------|-----------------------
-///     | _Z1fv         | f()
-///     | _Z1fi         | f(int)
-///     | _Z3foo3bar    | foo(bar)
-///     | _Z1fIiEvi     | void f<int>(int)
-///     | _ZN1N1fE      | N::f
-///     | _ZN3Foo3BarEv | Foo::Bar()
-///     | _Zrm1XS_"     | operator%(X, X)
-///     | _ZN3FooC1Ev   | Foo::Foo()
-///     | _Z1fSs        | f(std::basic_string<char,
-///     |               |   std::char_traits<char>,
-///     |               |   std::allocator<char> >)
-inline std::string sys::stack_trace(int skip) { 
-#ifdef ENABLE_STACKTRACES
-    void* callstack[256];  // max trace deep [256]
-    const auto max_frames = sizeof(callstack) / sizeof(callstack[0]); 
-    int num_frames = backtrace(callstack, max_frames); 
-    char** symbols = backtrace_symbols(callstack, num_frames);
-    std::string result;
-    // reverse the stack trace result
-    for (int i = num_frames - 1; i >= skip; i--) {
-        char buf[1024]; // frame buffer
-        // typedef struct {
-        //          const char *dli_fname;  /* Pathname of shared object that contains address */
-        //          void       *dli_fbase;  /* Address at which shared object is loaded */
-        //          const char *dli_sname;  /* Name of nearest symbol with address lower than addr */
-        //          void       *dli_saddr;  /* Exact address of symbol named in dli_sname */
-        // } Dl_info;
-        // If no symbol matching addr could be found, then dli_sname and dli_saddr are set to NULL.
-        // The function dladdr() takes a function pointer and tries to resolve name and file where it is located
-        Dl_info info;
-        if (dladdr(callstack[i], &info) && info.dli_sname) { 
-            char* demangled = NULL; 
-            int status = -1; 
-            if (info.dli_sname[0] == '_') { 
-                demangled = abi::__cxa_demangle(info.dli_sname, 0, 0, &status); 
-            } 
-            snprintf(buf, sizeof(buf), " %-3d %*p -> %s + %zd\n", 
-                                       i - skip, int(2 + sizeof(void*) * 2), callstack[i], 
-                                       status == 0 ? demangled : 
-                                       info.dli_sname == 0 ? symbols[i] : info.dli_sname, 
-                                       static_cast<char*>(callstack[i]) - static_cast<char*>(info.dli_saddr)); 
-            free(demangled); 
-        } else { 
-            snprintf(buf, sizeof(buf), "%-3d %*p -> %s\n",
-                                       i - skip, int(2 + sizeof(void*) * 2), callstack[i], 
-                                       symbols[i]); 
-        } 
-        result += buf;
-    } // for
-    free(symbols);
-    if (num_frames == max_frames) {
-        result = "[logger truncated]\n" + result;
-    }
-    if (!result.empty() && result[result.size() - 1] == '\n') {
-        result.resize(result.size() - 1);
-    }
-    sys::transform_stacktrace(result);
-    return result;
-#else
-    return "";
-#endif
-}
-
-} /* namespace utils */
-
-} /* namespace logger */
-
-#endif
diff --git a/utils/unit_test/aktest.h b/utils/unit_test/aktest.h
index 9170088..49170d4 100644
--- a/utils/unit_test/aktest.h
+++ b/utils/unit_test/aktest.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/utils/unit_test/engine_test.h b/utils/unit_test/engine_test.h
index b85944a..f1b2394 100644
--- a/utils/unit_test/engine_test.h
+++ b/utils/unit_test/engine_test.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/utils/unit_test/tensor_ops.h b/utils/unit_test/tensor_ops.h
index e9e5724..1e130cc 100644
--- a/utils/unit_test/tensor_ops.h
+++ b/utils/unit_test/tensor_ops.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/utils/unit_test/test_base.h b/utils/unit_test/test_base.h
index 10cdbf1..2285dc8 100644
--- a/utils/unit_test/test_base.h
+++ b/utils/unit_test/test_base.h
@@ -1,4 +1,4 @@
-/* Copyright (c) 2018 Baidu, Inc. All Rights Reserved.
+/* Copyright (c) 2018 Anakin Authors, Inc. All Rights Reserved.
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
